{
  "title": "John Abramson: Big Pharma | Lex Fridman Podcast #263",
  "id": "arrokG3wCdE",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:02.920\n The jury found Pfizer guilty of fraud\n\n00:02.920 --> 00:04.600\n and racketeering violations.\n\n00:04.600 --> 00:06.520\n How does Big Pharma affect your mind?\n\n00:06.520 --> 00:08.800\n Everyone's allowed their own opinion.\n\n00:08.800 --> 00:11.920\n I don't think everyone's allowed their own scientific facts.\n\n00:11.920 --> 00:13.800\n Does Pfizer play by the rules?\n\n00:13.800 --> 00:16.440\n Pfizer isn't battling the FDA.\n\n00:16.440 --> 00:18.780\n Pfizer has joined the FDA.\n\n00:21.440 --> 00:24.320\n The following is a conversation with John Abramson,\n\n00:24.320 --> 00:26.520\n faculty at Harvard Medical School,\n\n00:26.520 --> 00:29.160\n a family physician for over two decades,\n\n00:29.160 --> 00:32.160\n and author of the new book, Sickening,\n\n00:32.160 --> 00:35.000\n about how Big Pharma broke American healthcare\n\n00:35.000 --> 00:37.360\n and how we can fix it.\n\n00:37.360 --> 00:40.200\n This conversation with John Abramson\n\n00:40.200 --> 00:43.680\n is a critical exploration of the pharmaceutical industry.\n\n00:43.680 --> 00:45.400\n I wanted to talk to John\n\n00:45.400 --> 00:48.160\n in order to provide a countervailing perspective\n\n00:48.160 --> 00:50.700\n to the one expressed in my podcast episode\n\n00:50.700 --> 00:55.080\n with the CEO of Pfizer, Albert Borla.\n\n00:55.080 --> 00:58.920\n And here, please allow me to say a few additional words\n\n00:58.920 --> 01:01.880\n about this episode with the Pfizer CEO,\n\n01:01.880 --> 01:04.920\n and in general, about why I do these conversations\n\n01:04.920 --> 01:06.820\n and how I approach them.\n\n01:06.820 --> 01:10.520\n If this is not interesting to you, please skip ahead.\n\n01:10.520 --> 01:13.080\n What do I hope to do with this podcast?\n\n01:13.080 --> 01:15.600\n I want to understand human nature,\n\n01:15.600 --> 01:18.040\n the best and the worst of it.\n\n01:18.040 --> 01:19.840\n I want to understand how power, money,\n\n01:19.840 --> 01:21.840\n and fame changes people.\n\n01:21.840 --> 01:24.620\n I want to understand why atrocities are committed\n\n01:24.620 --> 01:27.240\n by crowds that believe they're doing good.\n\n01:27.240 --> 01:30.720\n All this, ultimately, because I want to understand\n\n01:30.720 --> 01:33.240\n how we can build a better world together,\n\n01:33.240 --> 01:35.400\n to find hope for the future,\n\n01:35.400 --> 01:38.520\n and to rediscover each time,\n\n01:38.520 --> 01:40.880\n through the exploration of ideas,\n\n01:40.880 --> 01:43.340\n just how beautiful this life is.\n\n01:43.340 --> 01:45.360\n This, our human civilization,\n\n01:45.360 --> 01:47.640\n in all of its full complexity,\n\n01:47.640 --> 01:49.280\n the forces of good and evil,\n\n01:49.280 --> 01:52.300\n of war and peace, of hate and love.\n\n01:53.400 --> 01:55.560\n I don't think I can do this with a heart and mind\n\n01:55.560 --> 01:59.040\n that is not open, fragile, and willing to empathize\n\n01:59.040 --> 02:00.920\n with all human beings,\n\n02:00.920 --> 02:03.440\n even those in the darkest corners of our world.\n\n02:04.400 --> 02:06.760\n To attack is easy.\n\n02:06.760 --> 02:09.520\n To understand is hard.\n\n02:09.520 --> 02:11.800\n And I choose the hard path.\n\n02:11.800 --> 02:13.840\n I have learned over the past few months\n\n02:13.840 --> 02:17.360\n that this path involves me getting more and more attacked\n\n02:17.360 --> 02:19.000\n from all sides.\n\n02:19.000 --> 02:21.600\n I will get attacked when I host people\n\n02:21.600 --> 02:24.500\n like Jay Bhattacharya or Francis Collins,\n\n02:24.500 --> 02:28.120\n Jamie Merzl or Vincent Ricanello,\n\n02:28.120 --> 02:31.840\n when I stand for my friend, Joe Rogan,\n\n02:31.840 --> 02:34.720\n when I host tech leaders like Mark Zuckerberg,\n\n02:34.720 --> 02:36.400\n Elon Musk, and others,\n\n02:36.400 --> 02:40.800\n when I eventually talk to Vladimir Putin, Barack Obama,\n\n02:40.800 --> 02:43.840\n and other figures that have turned the tides of history.\n\n02:44.920 --> 02:49.920\n I have and I will get called stupid, naive, weak,\n\n02:50.800 --> 02:52.520\n and I will take these words\n\n02:52.520 --> 02:57.200\n with respect, humility, and love, and I will get better.\n\n02:57.200 --> 03:00.680\n I will listen, think, learn, and improve.\n\n03:00.680 --> 03:04.520\n One thing I can promise is there's no amount of money\n\n03:04.520 --> 03:06.920\n or fame that can buy my opinion\n\n03:06.920 --> 03:09.280\n or make me go against my principles.\n\n03:09.280 --> 03:13.480\n There's no amount of pressure that can break my integrity.\n\n03:13.480 --> 03:16.120\n There's nothing in this world I need\n\n03:16.120 --> 03:18.540\n that I don't already have.\n\n03:18.540 --> 03:21.440\n Life itself is the fundamental gift.\n\n03:21.440 --> 03:23.480\n Everything else is just the bonus.\n\n03:24.520 --> 03:26.640\n That is freedom.\n\n03:26.640 --> 03:28.680\n That is happiness.\n\n03:28.680 --> 03:31.720\n If I die today, I will die a happy man.\n\n03:33.040 --> 03:35.960\n Now, a few comments about my approach\n\n03:35.960 --> 03:39.560\n and lessons learned from the Albert Bourla conversation.\n\n03:39.560 --> 03:41.880\n The goal was to reveal as much as I could\n\n03:41.880 --> 03:43.920\n about the human being before me\n\n03:43.920 --> 03:48.120\n and to give him the opportunity to contemplate in long form\n\n03:48.120 --> 03:49.920\n the complexities of his role,\n\n03:49.920 --> 03:53.200\n including the tension between making money\n\n03:53.200 --> 03:55.320\n and helping people, the corruption\n\n03:55.320 --> 03:58.180\n that so often permeates human institutions,\n\n03:58.180 --> 04:00.800\n the crafting of narratives through advertisements,\n\n04:00.800 --> 04:02.400\n and so on.\n\n04:02.400 --> 04:04.040\n I only had one hour,\n\n04:04.040 --> 04:07.440\n and so this wasn't the time to address these issues deeply\n\n04:07.440 --> 04:10.200\n but to show if Albert struggled with them\n\n04:10.200 --> 04:12.240\n in the privacy of his own mind,\n\n04:12.240 --> 04:16.280\n and if he would let down the veil of political speak\n\n04:16.280 --> 04:19.400\n for a time to let me connect with a man\n\n04:19.400 --> 04:22.560\n who decades ago chose to become a veterinarian,\n\n04:22.560 --> 04:24.840\n who wanted to help lessen the amount of suffering\n\n04:24.840 --> 04:26.300\n in the world.\n\n04:26.300 --> 04:28.400\n I had no pressure placed on me.\n\n04:28.400 --> 04:29.760\n There were no rules.\n\n04:29.760 --> 04:32.120\n The questions I was asking were all mine\n\n04:32.120 --> 04:34.120\n and not seen by Pfizer folks.\n\n04:34.120 --> 04:38.700\n I had no care whether I ever talked to another CEO again.\n\n04:38.700 --> 04:41.820\n None of this was part of the calculation\n\n04:41.820 --> 04:44.140\n in my limited brain computer.\n\n04:44.140 --> 04:45.920\n I didn't want to grill him.\n\n04:45.920 --> 04:48.920\n The way politicians grill CEOs in Congress,\n\n04:48.920 --> 04:51.400\n I thought that this approach is easy,\n\n04:51.400 --> 04:56.240\n self serving, dehumanizing, and it reveals nothing.\n\n04:56.240 --> 04:59.000\n I wanted to reveal the genuine intellectual struggle,\n\n04:59.000 --> 05:01.400\n vision, and motivation of a human being,\n\n05:01.400 --> 05:04.280\n and if that fails, I trusted the listener\n\n05:04.280 --> 05:08.080\n to draw their own conclusion and insights from the result,\n\n05:08.080 --> 05:10.080\n whether it's the words spoken\n\n05:10.080 --> 05:14.480\n or the words left unspoken or simply the silence.\n\n05:14.480 --> 05:15.800\n And that's just it.\n\n05:15.800 --> 05:20.800\n I fundamentally trust the intelligence of the listener, you.\n\n05:21.920 --> 05:24.880\n In fact, if I criticize the person too hard\n\n05:24.880 --> 05:26.840\n or celebrate the person too much,\n\n05:26.840 --> 05:29.320\n I feel I fail to give the listener\n\n05:29.320 --> 05:32.800\n a picture of the human being that is uncontaminated\n\n05:32.800 --> 05:35.440\n by my opinion or the opinion of the crowd.\n\n05:36.480 --> 05:39.320\n I trust that you have the fortitude and the courage\n\n05:39.320 --> 05:43.280\n to use your own mind, to empathize, and to think.\n\n05:43.280 --> 05:46.400\n Two practical lessons I took away.\n\n05:46.400 --> 05:48.520\n First, I will more strongly push\n\n05:48.520 --> 05:52.000\n for longer conversations of three, four, or more hours\n\n05:52.000 --> 05:53.480\n versus just one hour.\n\n05:53.480 --> 05:56.000\n 60 minutes is too short for the guest to relax\n\n05:56.000 --> 05:58.280\n and to think slowly and deeply,\n\n05:58.280 --> 06:00.880\n and for me to ask many follow up questions\n\n06:00.880 --> 06:03.000\n or follow interesting tangents.\n\n06:03.000 --> 06:05.920\n Ultimately, I think it's in the interest of everyone,\n\n06:05.920 --> 06:09.640\n including the guest, that we talk in true long form\n\n06:09.640 --> 06:11.600\n for many hours.\n\n06:11.600 --> 06:13.840\n Second, these conversations with leaders\n\n06:13.840 --> 06:16.160\n can be aided by further conversations\n\n06:16.160 --> 06:18.760\n with people who wrote books about those leaders\n\n06:18.760 --> 06:20.440\n or their industries.\n\n06:20.440 --> 06:22.440\n Those that can steel man each perspective\n\n06:22.440 --> 06:25.160\n and attempt to give an objective analysis.\n\n06:25.160 --> 06:26.840\n I think of Teddy Roosevelt's speech\n\n06:26.840 --> 06:28.520\n about the man in the arena.\n\n06:28.520 --> 06:32.400\n I want to talk to both the men and women in the arena\n\n06:32.400 --> 06:36.120\n and the critics and the supporters in the stands.\n\n06:36.120 --> 06:38.880\n For the former, I lean toward wanting to understand\n\n06:38.880 --> 06:43.360\n one human being's struggle with the ideas.\n\n06:43.360 --> 06:45.960\n For the latter, I lean towards understanding\n\n06:45.960 --> 06:48.400\n the ideas themselves.\n\n06:48.400 --> 06:50.320\n That's why I wanted to have this conversation\n\n06:50.320 --> 06:53.640\n with John Abramson, who is an outspoken critic\n\n06:53.640 --> 06:55.600\n of the pharmaceutical industry.\n\n06:55.600 --> 06:58.840\n I hope it helps add context and depth\n\n06:58.840 --> 07:02.320\n to the conversation I had with the Pfizer CEO.\n\n07:02.320 --> 07:06.680\n In the end, I may do worse than I could have or should have.\n\n07:06.680 --> 07:10.080\n Always, I will listen to the criticisms without ego\n\n07:10.080 --> 07:13.640\n and I promise I will work hard to improve.\n\n07:14.640 --> 07:18.960\n But let me say finally that cynicism is easy.\n\n07:20.040 --> 07:23.600\n Optimism, true optimism is hard.\n\n07:24.480 --> 07:28.160\n It is the belief that we can and we will\n\n07:28.160 --> 07:32.720\n build a better world and that we can only do it together.\n\n07:32.720 --> 07:35.000\n This is the fight worth fighting.\n\n07:35.000 --> 07:36.520\n So here we go.\n\n07:36.520 --> 07:39.160\n Once more into the breach, dear friends.\n\n07:39.160 --> 07:40.080\n I love you all.\n\n07:41.680 --> 07:43.880\n This is the Lex Friedman podcast.\n\n07:43.880 --> 07:46.000\n To support it, please check out our sponsors\n\n07:46.000 --> 07:47.280\n in the description.\n\n07:47.280 --> 07:51.320\n And now, here's my conversation with John Abramson.\n\n07:52.320 --> 07:55.200\n Your faculty at Harvard Medical School,\n\n07:55.200 --> 07:57.800\n your family physician for over two decades,\n\n07:57.800 --> 08:01.120\n rated one of the best family physicians in Massachusetts,\n\n08:01.120 --> 08:03.400\n you wrote the book, Overdose to America,\n\n08:03.400 --> 08:07.360\n and the new book coming out now called Sickening\n\n08:07.360 --> 08:10.080\n about how Big Pharma broke American healthcare,\n\n08:10.080 --> 08:14.720\n including science and research, and how we can fix it.\n\n08:14.720 --> 08:18.720\n First question, what is the biggest problem with Big Pharma\n\n08:18.720 --> 08:21.800\n that it fixed would be the most impactful?\n\n08:21.800 --> 08:24.920\n So if you can snap your fingers and fix one thing,\n\n08:24.920 --> 08:26.760\n what would be the most impactful, you think?\n\n08:26.760 --> 08:30.040\n The biggest problem is the way they\n\n08:30.040 --> 08:35.040\n determine the content, the accuracy,\n\n08:35.560 --> 08:39.560\n and the completeness of what doctors believe\n\n08:39.560 --> 08:42.520\n to be the full range of knowledge\n\n08:42.520 --> 08:46.000\n that they need to best take care of their patients.\n\n08:46.000 --> 08:51.000\n So that with the knowledge having been taken over\n\n08:51.440 --> 08:53.840\n by the commercial interests, primarily\n\n08:53.840 --> 08:57.400\n the pharmaceutical industry, the purpose of that knowledge\n\n08:57.400 --> 09:00.720\n is to maximize the profits that get returned\n\n09:00.720 --> 09:04.920\n to investors and shareholders, and not to optimize\n\n09:04.920 --> 09:07.220\n the health of the American people.\n\n09:07.220 --> 09:11.440\n So rebalancing that equation would be the most important\n\n09:11.440 --> 09:15.120\n thing to do to get our healthcare back aimed\n\n09:15.120 --> 09:16.440\n in the right direction.\n\n09:16.440 --> 09:20.680\n Okay, so there's a tension between helping people\n\n09:20.680 --> 09:24.520\n and making money, so if we look at particularly\n\n09:24.520 --> 09:28.600\n the task of helping people in medicine, in healthcare,\n\n09:29.680 --> 09:34.680\n is it possible if money is the primary sort of mechanism\n\n09:35.440 --> 09:38.300\n by which you achieve that as a motivator,\n\n09:38.300 --> 09:39.840\n is it possible to get that right?\n\n09:39.840 --> 09:43.120\n I think it is, Lex, but I think it is not possible\n\n09:43.120 --> 09:46.760\n without guardrails that maintain the integrity\n\n09:46.760 --> 09:48.760\n and the balance of the knowledge.\n\n09:48.760 --> 09:52.000\n Without those guardrails, it's like trying to play\n\n09:52.000 --> 09:54.840\n a professional basketball game without referees\n\n09:54.840 --> 09:57.600\n and having players call their own fouls.\n\n09:57.600 --> 10:01.000\n But the players are paid to win, and you can't count\n\n10:01.000 --> 10:03.760\n on them to call their own fouls, so we have referees\n\n10:03.760 --> 10:05.080\n who are in charge.\n\n10:05.080 --> 10:08.180\n We don't have those referees in American healthcare.\n\n10:08.180 --> 10:13.180\n That's the biggest way that American healthcare\n\n10:13.800 --> 10:17.520\n is distinguished from healthcare in other wealthy nations.\n\n10:17.520 --> 10:19.680\n So okay, you mentioned Milton Friedman,\n\n10:19.680 --> 10:24.280\n and you mentioned his book called Capitalism and Freedom.\n\n10:24.280 --> 10:27.220\n He writes that there are only three legitimate functions\n\n10:27.220 --> 10:30.120\n of government to preserve law and order,\n\n10:30.120 --> 10:33.800\n to enforce private contracts, and to ensure\n\n10:33.800 --> 10:35.820\n that private markets work.\n\n10:36.840 --> 10:40.160\n You said that that was a radical idea at the time,\n\n10:40.160 --> 10:41.840\n but we're failing on all three.\n\n10:41.840 --> 10:43.720\n How are we failing?\n\n10:43.720 --> 10:47.560\n And also maybe the bigger picture is what are the strengths\n\n10:47.560 --> 10:50.880\n and weaknesses of capitalism when it comes to medicine\n\n10:50.880 --> 10:51.840\n and healthcare?\n\n10:51.840 --> 10:53.120\n Can we separate those out?\n\n10:53.120 --> 10:55.200\n Because those are two huge questions.\n\n10:55.200 --> 10:58.080\n So how we're failing on all three,\n\n10:58.080 --> 11:03.080\n and these are the minimal functions that our guru\n\n11:03.320 --> 11:06.740\n of free market capitalism said the government\n\n11:06.740 --> 11:10.100\n should perform, so this is the absolute baseline.\n\n11:11.240 --> 11:14.800\n On preserving law and order, the drug companies\n\n11:14.800 --> 11:19.800\n routinely violate the law in terms of their marketing,\n\n11:20.160 --> 11:25.160\n and in terms of their presentation\n\n11:26.360 --> 11:29.160\n of the results of their trials.\n\n11:29.160 --> 11:32.920\n I know this because I was an expert in litigation\n\n11:32.920 --> 11:34.640\n for about 10 years.\n\n11:35.860 --> 11:40.000\n I presented some of what I learned in civil litigation\n\n11:40.000 --> 11:42.440\n to the FBI and the Department of Justice,\n\n11:42.440 --> 11:46.360\n and that case led to the biggest criminal fine\n\n11:46.360 --> 11:49.040\n in US history as of 2009.\n\n11:49.880 --> 11:54.880\n And I testified in a federal trial in 2010,\n\n11:56.120 --> 12:00.020\n and the jury found Pfizer guilty of fraud\n\n12:00.020 --> 12:02.360\n and racketeering violations.\n\n12:02.360 --> 12:07.360\n In terms of violating the law, it's a routine occurrence.\n\n12:07.480 --> 12:10.800\n The drug companies have paid $38 billion worth of fines\n\n12:10.800 --> 12:14.460\n from I think 1991 to 2017.\n\n12:15.760 --> 12:20.760\n It's never been enough to stop the misrepresentation\n\n12:21.360 --> 12:25.640\n of their data, and rarely are the fines greater\n\n12:25.640 --> 12:27.280\n than the profits that were made.\n\n12:29.520 --> 12:34.160\n Executives have not gone to jail for misrepresenting data\n\n12:34.160 --> 12:38.460\n that have involved even tens of thousands of deaths\n\n12:38.460 --> 12:42.120\n in the case of Vioxx, OxyContin as well.\n\n12:42.120 --> 12:45.520\n And when companies plead guilty to felonies,\n\n12:45.520 --> 12:48.360\n which is not an unusual occurrence,\n\n12:48.360 --> 12:51.240\n the government usually allows the companies,\n\n12:51.240 --> 12:56.000\n the parent companies, to allow subsidiaries to take the plea\n\n12:56.000 --> 12:58.880\n so that they are not one step closer\n\n12:58.880 --> 13:01.260\n to getting disbarred from Medicare,\n\n13:01.260 --> 13:03.360\n not being able to participate in Medicare.\n\n13:03.360 --> 13:08.360\n So in that sense, there is a mechanism\n\n13:11.000 --> 13:15.020\n that is appearing to impose law and order\n\n13:15.020 --> 13:18.140\n on drug company behavior, but it's clearly not enough.\n\n13:18.140 --> 13:19.480\n It's not working.\n\n13:19.480 --> 13:24.480\n Can you actually speak to human nature here?\n\n13:24.580 --> 13:26.320\n Are people corrupt?\n\n13:26.320 --> 13:28.400\n Are people malevolent?\n\n13:28.400 --> 13:32.880\n Are people ignorant that work at the low level\n\n13:32.880 --> 13:36.480\n and at the high level at Pfizer, for example,\n\n13:36.480 --> 13:40.440\n at big pharma companies, how is this possible?\n\n13:40.440 --> 13:43.280\n So I believe, just on a small tangent,\n\n13:43.280 --> 13:45.240\n that most people are good.\n\n13:45.240 --> 13:48.920\n And I actually believe if you join big pharma,\n\n13:48.920 --> 13:52.600\n so a company like Pfizer, your life trajectory\n\n13:52.600 --> 13:56.320\n often involves dreaming and wanting\n\n13:56.320 --> 13:58.920\n and enjoying helping people.\n\n13:58.920 --> 13:59.760\n Yes.\n\n13:59.760 --> 14:03.440\n And so, and then we look at the outcomes\n\n14:03.440 --> 14:07.040\n that you're describing, and it looks,\n\n14:07.040 --> 14:09.400\n and that's why the narrative takes hold\n\n14:09.400 --> 14:14.400\n that Pfizer CEO, Al Bobrola, who I talked to, is malevolent.\n\n14:15.440 --> 14:19.520\n The sense is these companies are evil.\n\n14:19.520 --> 14:24.520\n So if the different parts, the people, are good\n\n14:24.520 --> 14:27.380\n and they want to do good, how are we getting these outcomes?\n\n14:27.380 --> 14:32.380\n Yeah, I think it has to do with the cultural milieu\n\n14:33.140 --> 14:35.320\n that this is unfolding in.\n\n14:35.320 --> 14:40.320\n And we need to look at sociology to understand this,\n\n14:41.440 --> 14:46.440\n that when the cultural milieu is set up\n\n14:49.340 --> 14:52.560\n to maximize the returns on investment\n\n14:52.560 --> 14:55.440\n for shareholders and other venture capitalists\n\n14:55.440 --> 14:57.520\n and hedge funds and so forth,\n\n14:57.520 --> 15:00.640\n when that defines the culture\n\n15:00.640 --> 15:04.240\n and the higher up you are in the corporation,\n\n15:04.240 --> 15:09.240\n the more you're in on the game of getting rewarded\n\n15:10.080 --> 15:13.040\n for maximizing the profits of the investors,\n\n15:13.040 --> 15:14.860\n that's the culture they live in.\n\n15:15.760 --> 15:19.700\n And it becomes normative behavior\n\n15:19.700 --> 15:25.640\n to do things with science that look normal\n\n15:25.640 --> 15:28.520\n in that environment and are shared values\n\n15:28.520 --> 15:31.240\n within that environment by good people\n\n15:31.240 --> 15:34.920\n whose self evaluation becomes modified\n\n15:34.920 --> 15:37.680\n by the goals that are shared by the people around them.\n\n15:39.080 --> 15:44.080\n And within that milieu, you have one set of standards,\n\n15:44.760 --> 15:48.680\n and then the rest of good American people\n\n15:48.680 --> 15:50.720\n have the expectation that the drug companies\n\n15:50.720 --> 15:53.480\n are trying to make money, but that they're playing\n\n15:53.480 --> 15:58.480\n by rules that aren't part of the insider milieu.\n\n15:59.560 --> 16:02.920\n That's fascinating, the game they're playing\n\n16:02.920 --> 16:07.480\n modifies the culture of inside the meetings,\n\n16:07.480 --> 16:09.460\n inside the rooms, day to day,\n\n16:10.620 --> 16:12.440\n that there's a bubble that forms.\n\n16:12.440 --> 16:15.660\n Like we're all in bubbles of different sizes.\n\n16:15.660 --> 16:18.840\n And that bubble allows you to drift in terms\n\n16:18.840 --> 16:23.080\n of what you see as ethical and unethical.\n\n16:24.200 --> 16:28.520\n Because you see the game as just part of the game.\n\n16:28.520 --> 16:30.500\n So marketing is just part of the game.\n\n16:32.040 --> 16:35.280\n Paying the fines is just part of the game of science.\n\n16:36.520 --> 16:40.880\n And without guardrails, it becomes\n\n16:40.880 --> 16:42.200\n even more part of the game.\n\n16:42.200 --> 16:44.660\n You keep moving in that direction.\n\n16:44.660 --> 16:48.160\n If you're not bumping up against guardrails.\n\n16:48.160 --> 16:49.900\n And I think that's how we've gotten\n\n16:49.900 --> 16:52.220\n to the extreme situation we're in now.\n\n16:53.400 --> 16:57.200\n So, like I mentioned, I spoke with Pfizer CEO,\n\n16:57.200 --> 17:00.960\n Albert Berla, and I'd like to raise with you\n\n17:00.960 --> 17:02.920\n some of the concerns I raised with him.\n\n17:03.840 --> 17:07.120\n So one, you already mentioned, I raised the concern\n\n17:07.120 --> 17:11.220\n that Pfizer's engaged in aggressive advertising campaigns.\n\n17:11.220 --> 17:14.240\n As you can imagine, he said no.\n\n17:15.520 --> 17:16.540\n What do you think?\n\n17:18.440 --> 17:20.320\n I think you're both right.\n\n17:21.360 --> 17:23.720\n I think that the, I agree with you,\n\n17:23.720 --> 17:26.280\n that the aggressive advertising campaigns\n\n17:27.780 --> 17:30.540\n do not add value to society.\n\n17:30.540 --> 17:34.980\n And I agree with him that they're, for the most part, legal.\n\n17:34.980 --> 17:37.000\n And it's the way the game is played.\n\n17:37.000 --> 17:38.640\n Right, so, sorry to interrupt,\n\n17:38.640 --> 17:42.320\n but oftentimes his responses are,\n\n17:44.880 --> 17:47.640\n especially now, he's been CEO for only like two years,\n\n17:47.640 --> 17:50.560\n three years, he says Pfizer was a different company,\n\n17:50.560 --> 17:53.880\n we've made mistakes, right, in the past.\n\n17:53.880 --> 17:56.380\n We don't make mistakes anymore.\n\n17:56.380 --> 18:00.380\n That there's rules, and we play by the rules.\n\n18:00.380 --> 18:02.800\n So like, with every concern raised,\n\n18:02.800 --> 18:06.060\n there's very, very strict rules, as he says.\n\n18:06.060 --> 18:08.520\n In fact, he says sometimes way too strict.\n\n18:08.520 --> 18:10.200\n And we play by them.\n\n18:10.200 --> 18:12.180\n And so in that sense, advertisement,\n\n18:12.180 --> 18:14.320\n it doesn't seem like it's too aggressive,\n\n18:14.320 --> 18:16.020\n because it's playing by the rules.\n\n18:17.600 --> 18:19.800\n And relative to the other, again, it's the game.\n\n18:19.800 --> 18:22.160\n Relative to the other companies,\n\n18:22.160 --> 18:23.880\n it's actually not that aggressive.\n\n18:24.920 --> 18:26.480\n Relative to the other big pharma companies.\n\n18:26.480 --> 18:29.560\n Yes, yes, I hope we can quickly get back\n\n18:29.560 --> 18:31.280\n to whether or not they're playing by the rules,\n\n18:31.280 --> 18:32.760\n but in general.\n\n18:32.760 --> 18:34.360\n But let's just look at the question\n\n18:34.360 --> 18:36.640\n of advertising specifically.\n\n18:36.640 --> 18:39.620\n I think that's a good example of what it looks like\n\n18:39.620 --> 18:43.120\n from within that culture, and from outside that culture.\n\n18:44.880 --> 18:49.800\n He's saying that we follow the law on our advertising.\n\n18:49.800 --> 18:51.520\n We state the side effects,\n\n18:51.520 --> 18:53.960\n and we state the FDA approved indications,\n\n18:53.960 --> 18:57.720\n and we do what the law says we have to do for advertising.\n\n18:57.720 --> 19:01.780\n And I have not, I've not been an expert in litigation\n\n19:01.780 --> 19:04.960\n for a few years, and I don't know what's going on currently,\n\n19:04.960 --> 19:07.080\n but let's take him at his word.\n\n19:07.080 --> 19:09.920\n It could be true, it might not be, but it could be.\n\n19:09.920 --> 19:14.920\n But if that's true, in his world, in his culture,\n\n19:15.480 --> 19:17.280\n that's ethical business behavior.\n\n19:18.160 --> 19:22.560\n From a common sense person's point of view,\n\n19:22.560 --> 19:27.200\n a drug company paying highly skilled media folks\n\n19:27.200 --> 19:30.440\n to take the information about the drug\n\n19:30.440 --> 19:34.400\n and create the illusion, the emotional impact,\n\n19:34.400 --> 19:38.000\n and the takeaway message for viewers of advertisements\n\n19:38.000 --> 19:41.200\n that grossly exaggerate the benefit of the drug\n\n19:41.200 --> 19:45.400\n and minimize the harms, it's sociopathic behavior\n\n19:45.400 --> 19:49.960\n to have viewers of ads leave the ad\n\n19:49.960 --> 19:52.960\n with an unrealistic impression\n\n19:52.960 --> 19:56.200\n of the benefits and harms of the drug.\n\n19:56.200 --> 19:58.880\n And yet he's playing by the rules,\n\n19:58.880 --> 20:01.320\n he's doing his job as CEO\n\n20:01.320 --> 20:04.560\n to maximize the effect of his advertising,\n\n20:04.560 --> 20:07.640\n and if he doesn't do it, this is a key point,\n\n20:07.640 --> 20:11.940\n if he doesn't do it, he'll get fired and the next guy will.\n\n20:11.940 --> 20:13.620\n So the people that survive in the company,\n\n20:13.620 --> 20:16.720\n the people that get raises in the company,\n\n20:16.720 --> 20:19.200\n move up in the company are the ones that play by the rules,\n\n20:19.200 --> 20:21.560\n and that's how the game solidifies itself.\n\n20:21.560 --> 20:24.360\n But the game is within the bounds of the law.\n\n20:24.360 --> 20:26.960\n Sometimes, most of the time, not always.\n\n20:26.960 --> 20:29.240\n We'll return to that question.\n\n20:29.240 --> 20:31.680\n I'm actually more concerned\n\n20:31.680 --> 20:34.360\n about the effect of advertisement\n\n20:34.360 --> 20:39.360\n in a kind of much larger scale\n\n20:39.520 --> 20:43.040\n on the people that are getting funded\n\n20:43.040 --> 20:46.320\n by the advertisement in self censorship,\n\n20:46.320 --> 20:50.920\n just like more subtle, more passive pressure\n\n20:50.920 --> 20:52.980\n to not say anything negative.\n\n20:52.980 --> 20:57.980\n Because I've seen this, and I've been saddened by it,\n\n20:57.980 --> 21:02.980\n that people sacrifice integrity in small ways\n\n21:03.160 --> 21:05.740\n when they're being funded by a particular company.\n\n21:06.600 --> 21:09.440\n They don't see themselves as doing so,\n\n21:09.440 --> 21:12.880\n but you can just clearly see that the space of opinions\n\n21:12.880 --> 21:15.240\n that they're willing to engage in,\n\n21:15.240 --> 21:18.480\n or a space of ideas they're willing to play with,\n\n21:18.480 --> 21:22.460\n is one that doesn't include negative,\n\n21:22.460 --> 21:25.560\n anything that could possibly be negative about the company.\n\n21:25.560 --> 21:27.160\n They just choose not to.\n\n21:27.160 --> 21:28.880\n Because, you know, why?\n\n21:28.880 --> 21:30.620\n And that's really sad to me,\n\n21:30.620 --> 21:33.640\n that if you give me a hundred bucks,\n\n21:33.640 --> 21:36.360\n I'm less likely to say something negative about you.\n\n21:38.520 --> 21:39.920\n That makes me sad.\n\n21:39.920 --> 21:42.600\n Because the reason I wouldn't say something negative\n\n21:42.600 --> 21:45.600\n about you, I prefer, is the pressure of friendship\n\n21:45.600 --> 21:48.360\n and human connection, those kinds of things.\n\n21:48.360 --> 21:50.700\n So I understand that.\n\n21:50.700 --> 21:52.160\n That's also a problem, by the way,\n\n21:52.160 --> 21:54.340\n sort of having dinners and shaking hands,\n\n21:54.340 --> 21:56.260\n and oh, aren't we friends?\n\n21:56.260 --> 21:58.520\n But the fact that money has that effect\n\n21:58.520 --> 22:00.220\n is really sad to me.\n\n22:00.220 --> 22:04.120\n On the news media, on the journalists, on scientists,\n\n22:05.320 --> 22:06.920\n that's scary to me.\n\n22:06.920 --> 22:09.240\n But of course, the direct advertisement to consumers,\n\n22:09.240 --> 22:11.320\n like you said, is a potentially very negative effect.\n\n22:11.320 --> 22:14.480\n I wanted to ask if what you think\n\n22:14.480 --> 22:17.100\n is the most negative impact of advertisement,\n\n22:17.100 --> 22:20.320\n is it that direct to consumer on television?\n\n22:20.320 --> 22:22.300\n Is it advertisement of the doctors?\n\n22:22.300 --> 22:24.780\n Which I'm surprised to learn,\n\n22:24.780 --> 22:26.320\n I was vaguely looking at,\n\n22:26.320 --> 22:31.320\n is more spent on advertising to doctors than to consumers.\n\n22:32.680 --> 22:34.040\n That's really confusing to me.\n\n22:34.040 --> 22:35.640\n It's fascinating, actually.\n\n22:35.640 --> 22:38.960\n And then also, obviously, the law side of things\n\n22:38.960 --> 22:40.960\n is the lobbying dollars,\n\n22:40.960 --> 22:42.660\n which I think is less than all of those.\n\n22:42.660 --> 22:44.680\n But anyway, it's in the ballpark.\n\n22:44.680 --> 22:46.540\n What concerns you most?\n\n22:46.540 --> 22:49.760\n Well, it's the whole nexus of influence.\n\n22:49.760 --> 22:53.960\n There's not one thing, and they don't invest all their,\n\n22:53.960 --> 22:55.560\n they don't put all their eggs in one basket.\n\n22:55.560 --> 23:00.560\n It's a whole surround sound program here.\n\n23:01.160 --> 23:04.480\n But in terms of advertisements,\n\n23:04.480 --> 23:06.120\n let's take the advertisement.\n\n23:06.120 --> 23:09.640\n Trulicity is a diabetes drug,\n\n23:09.640 --> 23:12.560\n for type two diabetes, an injectable drug.\n\n23:12.560 --> 23:15.680\n And it lowers blood sugar just about as well\n\n23:15.680 --> 23:18.520\n as Metformin does.\n\n23:18.520 --> 23:21.060\n Metformin costs about $4 a month.\n\n23:21.060 --> 23:25.760\n Trulicity costs, I think, $6,200 a year.\n\n23:25.760 --> 23:29.480\n So $48 a year versus $6,200.\n\n23:29.480 --> 23:31.600\n Trulicity has distinguished itself\n\n23:31.600 --> 23:35.080\n because the manufacturer did a study\n\n23:35.080 --> 23:37.340\n that showed that it significantly reduces\n\n23:37.340 --> 23:41.080\n the risk of cardiovascular disease in diabetics.\n\n23:41.080 --> 23:44.380\n And they got approval on the basis of that study,\n\n23:44.380 --> 23:47.560\n that very large study being statistically significant.\n\n23:47.560 --> 23:52.560\n So the ads obviously extol the virtues of Trulicity\n\n23:53.360 --> 23:56.840\n because it reduces the risk of heart disease and stroke,\n\n23:56.840 --> 23:59.360\n and that's one of the major morbidities,\n\n23:59.360 --> 24:01.600\n risks of type two diabetes.\n\n24:01.600 --> 24:03.680\n What the ad doesn't say is that you have to treat\n\n24:03.680 --> 24:08.120\n 323 people to prevent one nonfatal event\n\n24:08.120 --> 24:10.240\n at a cost of $2.7 million.\n\n24:11.600 --> 24:13.840\n And even more importantly than that,\n\n24:13.840 --> 24:17.720\n what the ad doesn't say is that the evidence shows\n\n24:17.720 --> 24:22.040\n that engaging in an active, healthy lifestyle program\n\n24:22.040 --> 24:24.600\n reduces the risk of heart disease and strokes\n\n24:24.600 --> 24:27.460\n far more than Trulicity does.\n\n24:28.640 --> 24:32.160\n Now, to be fair to the company, the sponsor,\n\n24:32.160 --> 24:37.160\n there's never been a study that compared Trulicity\n\n24:37.440 --> 24:39.760\n to lifestyle changes.\n\n24:39.760 --> 24:42.680\n But that's part of the problem of our advertising.\n\n24:42.680 --> 24:45.360\n You would think in a rational society\n\n24:45.360 --> 24:50.320\n that was way out on a limb as a lone country\n\n24:50.320 --> 24:52.320\n besides New Zealand that allows\n\n24:52.320 --> 24:54.360\n direct to consumer advertising,\n\n24:54.360 --> 24:59.120\n that part of allowing direct to consumer advertising\n\n24:59.120 --> 25:03.080\n would be to mandate that the companies establish\n\n25:03.080 --> 25:05.520\n whether their drug is better than,\n\n25:05.520 --> 25:07.960\n say, healthy lifestyle adoption\n\n25:07.960 --> 25:11.820\n to prevent the problems that they claim to be preventing.\n\n25:11.820 --> 25:13.800\n But we don't require that.\n\n25:13.800 --> 25:17.560\n So the companies can afford to do very large studies\n\n25:17.560 --> 25:19.560\n so that very small differences\n\n25:19.560 --> 25:21.840\n become statistically significant.\n\n25:21.840 --> 25:23.880\n And their studies are asking the question,\n\n25:23.880 --> 25:25.640\n how can we sell more drug?\n\n25:25.640 --> 25:27.320\n They're not asking the question,\n\n25:27.320 --> 25:30.620\n how can we prevent cardiovascular disease\n\n25:30.620 --> 25:32.720\n in people with type 2 diabetes?\n\n25:32.720 --> 25:34.240\n And that's how we get off in this,\n\n25:34.240 --> 25:38.560\n we're now in the extreme arm of this distortion\n\n25:38.560 --> 25:41.400\n of our medical knowledge of studying\n\n25:41.400 --> 25:45.480\n how to sell more drugs than how to make people more healthy.\n\n25:45.480 --> 25:48.920\n That's a really great thing to compare to,\n\n25:48.920 --> 25:51.400\n is lifestyle changes.\n\n25:51.400 --> 25:53.240\n Because that should be the bar.\n\n25:53.240 --> 25:56.680\n If you do some basic diet, exercise,\n\n25:56.680 --> 25:58.420\n all those kinds of things,\n\n25:58.420 --> 26:00.240\n how does this drug compare to that?\n\n26:00.240 --> 26:01.420\n Right, right.\n\n26:01.420 --> 26:04.080\n And that study was done, actually, in the 90s.\n\n26:04.080 --> 26:06.080\n It's called the Diabetes Prevention Program.\n\n26:06.080 --> 26:09.160\n It was federally funded by the NIH\n\n26:09.160 --> 26:13.240\n so that there wasn't this drug company imperative\n\n26:13.240 --> 26:15.840\n to just try to prove your drug was better than nothing.\n\n26:16.800 --> 26:19.660\n And it was a very well designed study,\n\n26:19.660 --> 26:22.440\n randomized controlled trial\n\n26:22.440 --> 26:25.000\n in people who were at high risk of diabetes,\n\n26:25.000 --> 26:26.840\n so called pre diabetics.\n\n26:26.840 --> 26:30.040\n And they were randomized to three different groups,\n\n26:30.040 --> 26:33.760\n a placebo group, a group that got treated with metformin,\n\n26:34.760 --> 26:36.200\n and a group that got treated\n\n26:36.200 --> 26:38.860\n with intensive lifestyle counseling.\n\n26:38.860 --> 26:42.200\n So this study really tested\n\n26:42.200 --> 26:46.000\n whether you can get people in a randomized controlled trial\n\n26:46.000 --> 26:49.280\n assigned to intensive lifestyle changes,\n\n26:49.280 --> 26:50.680\n whether that works.\n\n26:50.680 --> 26:54.640\n Now the common wisdom amongst physicians,\n\n26:54.640 --> 26:56.080\n and I think in general,\n\n26:56.080 --> 26:57.960\n is that you can't get people to change.\n\n26:57.960 --> 26:59.240\n You know, you can do whatever you want,\n\n26:59.240 --> 27:00.320\n you can stand on your head,\n\n27:00.320 --> 27:02.640\n you can beg and plead, people won't change.\n\n27:02.640 --> 27:05.040\n So give it up and let's just move on with the drugs\n\n27:05.040 --> 27:06.440\n and not waste any time.\n\n27:06.440 --> 27:08.280\n Except this study that was published\n\n27:08.280 --> 27:11.080\n in the New England Journal, I think in 2002,\n\n27:11.080 --> 27:12.900\n shows that's wrong.\n\n27:12.900 --> 27:16.200\n That the people who were in the intensive lifestyle group\n\n27:16.200 --> 27:18.080\n ended up losing 10 pounds,\n\n27:18.080 --> 27:21.240\n exercising five times a week, maintaining it,\n\n27:21.240 --> 27:26.240\n and reduced their risk of getting diabetes by 58%,\n\n27:26.320 --> 27:27.920\n compared to the metformin group,\n\n27:27.920 --> 27:32.000\n which reduced its risk of getting diabetes by 31%.\n\n27:32.000 --> 27:34.920\n So that exact study was done\n\n27:34.920 --> 27:38.520\n and it showed that lifestyle intervention is the winner.\n\n27:38.520 --> 27:43.520\n Who, as a small tangent, is the leader,\n\n27:44.840 --> 27:49.140\n who is supposed to fight for the side of lifestyle changes?\n\n27:49.140 --> 27:54.140\n Where's the big pharma version of lifestyle changes?\n\n27:54.600 --> 27:57.240\n Who's supposed to have the big bully pulpit,\n\n27:57.240 --> 28:00.040\n the big money behind lifestyle changes?\n\n28:00.040 --> 28:03.400\n In your sense, because that seems to be missing\n\n28:03.400 --> 28:06.280\n in a lot of our discussions about health policy.\n\n28:06.280 --> 28:08.080\n Right, that's exactly right.\n\n28:08.080 --> 28:12.800\n And the answer is that we assume\n\n28:12.800 --> 28:15.760\n that the market has to solve all of these problems.\n\n28:15.760 --> 28:18.320\n And the market can't solve all of these problems.\n\n28:18.320 --> 28:23.240\n There needs to be some way of protecting the public interest\n\n28:23.240 --> 28:26.520\n for things that aren't financially driven.\n\n28:26.520 --> 28:28.760\n So that the overriding question has to be\n\n28:28.760 --> 28:31.420\n how best to improve Americans health,\n\n28:31.420 --> 28:36.200\n not companies funding studies to try and prove\n\n28:36.200 --> 28:39.240\n that their new inexpensive drug is better\n\n28:39.240 --> 28:40.880\n and should be used.\n\n28:40.880 --> 28:45.460\n Well, some of that is also people sort of like yourself.\n\n28:45.460 --> 28:48.800\n I mean, it's funny, you spoke with Joe Rogan.\n\n28:48.800 --> 28:50.960\n He constantly espouses lifestyle changes.\n\n28:50.960 --> 28:55.960\n So some of it is almost like understanding the problems\n\n28:55.960 --> 28:58.160\n that big pharma is creating in society\n\n28:58.160 --> 29:02.440\n and then sort of these influential voices\n\n29:02.440 --> 29:03.560\n speaking up against it.\n\n29:03.560 --> 29:08.600\n So whether they're scientists or just regular communicators.\n\n29:08.600 --> 29:11.320\n Yeah, I think you gotta tip your hat to Joe\n\n29:11.320 --> 29:13.120\n for getting that message out.\n\n29:13.120 --> 29:17.360\n And he clearly believes it and does his best.\n\n29:17.360 --> 29:21.040\n But it's not coming out in the legitimate avenues,\n\n29:21.040 --> 29:26.040\n in the legitimate channels that are evidence based medicine\n\n29:26.040 --> 29:31.040\n and from the sources that the docs are trained to listen to\n\n29:32.040 --> 29:34.320\n and modify their patient care on.\n\n29:34.320 --> 29:36.480\n Now, it's not 100%.\n\n29:36.480 --> 29:40.160\n I mean, there are articles in the big journals\n\n29:40.160 --> 29:42.160\n about the benefits of lifestyle,\n\n29:42.160 --> 29:45.800\n but they don't carry the same gravitas\n\n29:45.800 --> 29:48.240\n as the randomized controlled trials\n\n29:48.240 --> 29:50.320\n that test this drug against placebo\n\n29:50.320 --> 29:52.360\n or this drug against another drug.\n\n29:52.360 --> 29:55.680\n So the Joe Rogans of the world keep going.\n\n29:55.680 --> 29:57.040\n I tip my hat.\n\n29:57.040 --> 30:00.920\n But it's not gonna carry the day for most of the people\n\n30:00.920 --> 30:04.240\n until it has the legitimacy of the medical establishment.\n\n30:04.240 --> 30:05.960\n Yeah, like something that the doctors\n\n30:05.960 --> 30:07.160\n really pay attention to.\n\n30:07.160 --> 30:09.700\n Well, there's an entire mechanism established\n\n30:09.700 --> 30:11.320\n for testing drugs.\n\n30:11.320 --> 30:14.400\n There's not an entire mechanism established\n\n30:14.400 --> 30:17.600\n in terms of scientific rigor of testing lifestyle changes.\n\n30:17.600 --> 30:20.520\n I mean, it's more difficult.\n\n30:20.520 --> 30:23.440\n I mean, everything's difficult in science.\n\n30:23.440 --> 30:27.120\n That science that involves humans, especially.\n\n30:27.120 --> 30:30.640\n But it's just, these studies are very expensive.\n\n30:30.640 --> 30:31.960\n They're difficult.\n\n30:31.960 --> 30:33.400\n It's difficult to find conclusions\n\n30:33.400 --> 30:35.480\n and to control all the variables.\n\n30:35.480 --> 30:37.360\n And so it's very easy to dismiss them\n\n30:37.360 --> 30:40.960\n unless you really do a huge study that's very well funded.\n\n30:40.960 --> 30:42.840\n And so maybe the doctors just lean\n\n30:42.840 --> 30:45.740\n towards the simpler studies over and over,\n\n30:45.740 --> 30:48.040\n which is what the drug companies fund.\n\n30:48.040 --> 30:50.400\n They can control more variables.\n\n30:50.400 --> 30:53.680\n See, but the control there is sometimes\n\n30:56.960 --> 31:00.920\n by hiding things too, right?\n\n31:00.920 --> 31:03.480\n So sometimes you can just say\n\n31:03.480 --> 31:06.420\n that this is a well controlled study\n\n31:06.420 --> 31:09.240\n by pretending there's a bunch of other stuff.\n\n31:09.240 --> 31:13.280\n It's just ignoring the stuff that could be correlated.\n\n31:13.280 --> 31:15.560\n It could be the real cause of the effects you're seeing,\n\n31:15.560 --> 31:17.360\n all that kind of stuff.\n\n31:17.360 --> 31:21.720\n So money can buy ignorance, I suppose, in science.\n\n31:21.720 --> 31:24.720\n It buys the kind of blinders that are on\n\n31:24.720 --> 31:28.040\n that don't look outside the reductionist model.\n\n31:28.040 --> 31:31.480\n And that's another issue is that we kind of,\n\n31:31.480 --> 31:34.320\n nobody says to doctors in training,\n\n31:34.320 --> 31:39.320\n only listen to reductionist studies and conclusions\n\n31:39.360 --> 31:42.080\n and methods of promoting health.\n\n31:42.080 --> 31:43.980\n Nobody says that explicitly.\n\n31:43.980 --> 31:47.640\n But the respectable science\n\n31:47.640 --> 31:49.760\n has to do with controlling the factors.\n\n31:49.760 --> 31:54.200\n And I mean, it just doesn't make sense to me.\n\n31:54.200 --> 31:55.440\n I'm gonna pick on trulicity\n\n31:55.440 --> 31:57.240\n because it's such an obvious example,\n\n31:57.240 --> 32:01.320\n but it's not more egregious than many others.\n\n32:01.320 --> 32:03.720\n It doesn't make sense to me to allow a drug\n\n32:03.720 --> 32:06.960\n to be advertised as preventing cardiovascular disease\n\n32:06.960 --> 32:09.960\n when you haven't included lifestyle changes\n\n32:09.960 --> 32:11.660\n as an arm in the study.\n\n32:11.660 --> 32:15.980\n It's just so crystal clear that the purpose of that study\n\n32:15.980 --> 32:17.420\n is to sell trulicity.\n\n32:17.420 --> 32:20.400\n It's not to prevent cardiovascular disease.\n\n32:21.280 --> 32:24.720\n If we were in charge, I would try to convince you\n\n32:24.720 --> 32:27.640\n that anywhere that study, the results of that study\n\n32:27.640 --> 32:31.040\n were presented to physicians,\n\n32:31.040 --> 32:33.560\n it would be stamped in big red letters,\n\n32:33.560 --> 32:37.680\n this study did not compare trulicity to lifestyle changes.\n\n32:37.680 --> 32:38.960\n They need to know that.\n\n32:38.960 --> 32:40.640\n And the docs are kind of trained,\n\n32:40.640 --> 32:42.680\n these blinders get put on,\n\n32:42.680 --> 32:46.320\n and they're trained to kind of forget that that's not there.\n\n32:46.320 --> 32:48.240\n Do you think, so first of all,\n\n32:48.240 --> 32:51.320\n that's a small or big change to advertisement\n\n32:51.320 --> 32:53.100\n that seems obvious to say,\n\n32:54.080 --> 32:56.500\n like in force that it should be compared\n\n32:56.500 --> 32:57.700\n to lifestyle changes.\n\n32:59.040 --> 33:01.240\n Do you think advertisements, period,\n\n33:01.240 --> 33:04.200\n in the United States for pharmaceutical drugs\n\n33:04.200 --> 33:05.920\n should be banned?\n\n33:05.920 --> 33:07.520\n I think they can't be banned.\n\n33:07.520 --> 33:09.200\n So it doesn't matter what I think.\n\n33:09.200 --> 33:13.200\n Okay, let's say you were a dictator,\n\n33:13.200 --> 33:15.200\n and two, why can't they be banned?\n\n33:15.200 --> 33:16.720\n Okay.\n\n33:16.720 --> 33:17.700\n Answer either one.\n\n33:18.700 --> 33:22.800\n I believe, I've been told by lawyers who I trust,\n\n33:22.800 --> 33:27.280\n that the freedom of speech in the U.S. Constitution\n\n33:27.280 --> 33:29.360\n is such that you can't ban them,\n\n33:29.360 --> 33:33.300\n that you could ban cigarettes and alcohol,\n\n33:33.300 --> 33:35.640\n which have no therapeutic use,\n\n33:35.640 --> 33:37.680\n but drugs have a therapeutic use,\n\n33:37.680 --> 33:41.600\n and advertisements about them can't be banned.\n\n33:41.600 --> 33:43.680\n Let's assume that they can't be,\n\n33:43.680 --> 33:45.860\n because we know they won't be anyway,\n\n33:46.860 --> 33:49.120\n but let's assume they can't be,\n\n33:49.120 --> 33:51.840\n and especially our Supreme Court now\n\n33:51.840 --> 33:55.900\n would be unlikely to take that seriously.\n\n33:55.900 --> 33:57.360\n But that's not the issue.\n\n33:57.360 --> 34:00.260\n The issue is that if the drug companies\n\n34:00.260 --> 34:02.640\n want to spend their money advertising,\n\n34:02.640 --> 34:06.880\n they should have to have independent analysis\n\n34:06.880 --> 34:10.440\n of the message that the viewers are left with\n\n34:10.440 --> 34:13.400\n about the drug, so that it's realistic.\n\n34:13.400 --> 34:15.520\n What's the chance the drug will help them?\n\n34:15.520 --> 34:19.000\n Well, in true city, it's one out of 323.\n\n34:19.000 --> 34:21.120\n 322 people aren't gonna benefit\n\n34:21.120 --> 34:23.700\n from the cardiovascular reduction, risk reduction.\n\n34:25.080 --> 34:26.880\n What's the true cost?\n\n34:26.880 --> 34:30.640\n When drugs advertise that you may be able to get this\n\n34:30.640 --> 34:33.900\n for a $25 copay or something,\n\n34:33.900 --> 34:35.960\n tens of thousands of dollars a year drug,\n\n34:35.960 --> 34:40.120\n for a $25 copay, what an enormous disservice that is\n\n34:40.120 --> 34:42.600\n to misrepresent the cost to society.\n\n34:42.600 --> 34:44.040\n That should not be allowed.\n\n34:44.040 --> 34:48.680\n So you should have to make it clear to the viewers\n\n34:48.680 --> 34:49.960\n how many people are gonna benefit,\n\n34:49.960 --> 34:51.680\n what's your chance of benefiting?\n\n34:51.680 --> 34:53.560\n How does it compare to lifestyle changes\n\n34:53.560 --> 34:55.860\n or less expensive therapies?\n\n34:55.860 --> 34:58.440\n What do you give up if you use a less expensive therapy\n\n34:58.440 --> 34:59.960\n or gain, perhaps?\n\n34:59.960 --> 35:01.160\n And how much it costs.\n\n35:01.160 --> 35:02.280\n How much it costs.\n\n35:02.280 --> 35:03.560\n Now, that can go either way,\n\n35:03.560 --> 35:06.760\n because if you say Humira costs $72,000\n\n35:06.760 --> 35:08.960\n and it's no more effective as a first line drug\n\n35:08.960 --> 35:12.320\n than methotrexate, which costs $480,\n\n35:12.320 --> 35:15.040\n people might say, I want the expensive drug\n\n35:15.040 --> 35:17.740\n because I can get it for a $25 copay.\n\n35:17.740 --> 35:21.640\n So you'd have to temper that a little bit.\n\n35:21.640 --> 35:25.560\n Oh, you mean people are so, they don't care.\n\n35:25.560 --> 35:26.400\n They don't care.\n\n35:26.400 --> 35:29.440\n Their insurance is gonna cover it and it's a $25 copay,\n\n35:29.440 --> 35:31.840\n but we could figure out how to deal with that.\n\n35:31.840 --> 35:35.240\n The main point is that if we assume\n\n35:35.240 --> 35:38.760\n that advertisements are gonna keep going, and they are,\n\n35:38.760 --> 35:43.760\n we could require that there be outside evaluation\n\n35:45.480 --> 35:48.900\n of the message that reasonable, unbiased viewers\n\n35:48.900 --> 35:50.980\n take away from the ads,\n\n35:50.980 --> 35:54.220\n and the ads would have to tell the truth about the drug.\n\n35:55.720 --> 36:00.720\n And the truth should have sub truth guardrails,\n\n36:00.720 --> 36:03.700\n meaning like the cost that we talked about,\n\n36:03.700 --> 36:07.060\n the effects compared to things that actually,\n\n36:07.060 --> 36:11.820\n lifestyle changes, just these details,\n\n36:11.820 --> 36:16.500\n very strict guardrails of what actually has to be specified.\n\n36:16.500 --> 36:19.380\n And I would make it against the law\n\n36:19.380 --> 36:23.340\n to have family picnics or dogs catching Frisbees in the ads.\n\n36:23.340 --> 36:28.340\n So, you mean 95% of the ads, yes.\n\n36:28.340 --> 36:32.620\n I mean, there's something dark and inauthentic\n\n36:32.620 --> 36:34.500\n about those advertisements, but they seem,\n\n36:34.500 --> 36:36.240\n I mean, I'm sure they're being done\n\n36:36.240 --> 36:38.640\n because they work for the target audience.\n\n36:43.500 --> 36:45.120\n And then the doctors too.\n\n36:46.060 --> 36:48.740\n Can you really buy a doctor's opinion?\n\n36:48.740 --> 36:51.300\n Why does it have such an effect on doctors?\n\n36:52.260 --> 36:55.460\n Advertisement to doctors, like you as a physician,\n\n36:55.460 --> 36:58.460\n again, like from everything I've seen, people love you.\n\n36:58.460 --> 37:03.460\n And I've just, people should definitely look you up from,\n\n37:04.880 --> 37:09.300\n there's a bunch of videos of you giving talks on YouTube,\n\n37:09.300 --> 37:14.300\n and it's just, it's so refreshing to hear\n\n37:14.700 --> 37:17.460\n just the clarity of thought about health policy,\n\n37:17.460 --> 37:19.660\n about healthcare, just the way you think\n\n37:19.660 --> 37:20.660\n throughout the years.\n\n37:20.660 --> 37:21.500\n Thank you.\n\n37:21.500 --> 37:23.700\n So like, it's easy to think about like,\n\n37:23.700 --> 37:25.360\n maybe you're criticizing Big Pharma,\n\n37:25.360 --> 37:28.820\n that's one part of the message that you're talking about,\n\n37:28.820 --> 37:33.020\n but that's not like, your brilliance actually shines\n\n37:33.020 --> 37:35.440\n in the positive, in the solutions and how to do it.\n\n37:35.440 --> 37:40.440\n So as a doctor, what affects your mind?\n\n37:40.900 --> 37:43.120\n And how does Big Pharma affect your mind?\n\n37:43.120 --> 37:46.500\n Number one, the information that comes through\n\n37:46.500 --> 37:50.300\n legitimate sources that doctors have been taught\n\n37:50.300 --> 37:52.560\n to rely on, evidence based medicine,\n\n37:52.560 --> 37:55.420\n the articles in peer reviewed journals,\n\n37:55.420 --> 37:57.020\n the guidelines that are issued.\n\n37:57.020 --> 37:59.220\n Now, those are problematic,\n\n37:59.220 --> 38:03.240\n because when an article is peer reviewed\n\n38:03.240 --> 38:05.100\n and published in a respected journal,\n\n38:06.340 --> 38:10.340\n people and doctors obviously assume\n\n38:10.340 --> 38:15.340\n that the peer reviewers have had access to the data\n\n38:15.820 --> 38:18.420\n and they've independently analyzed the data,\n\n38:18.420 --> 38:21.900\n and they corroborate the findings in the manuscript\n\n38:21.900 --> 38:25.740\n that was submitted, or they give feedback to the authors\n\n38:25.740 --> 38:28.220\n and say, we disagree with you on this point,\n\n38:28.220 --> 38:30.740\n and would you please check our analysis\n\n38:30.740 --> 38:32.420\n and if you agree with us, make it.\n\n38:32.420 --> 38:35.580\n That's what they assume the peer review process is,\n\n38:35.580 --> 38:36.900\n but it's not.\n\n38:36.900 --> 38:39.220\n The peer reviewers don't have the data.\n\n38:39.220 --> 38:41.800\n The peer reviewers have the manuscript\n\n38:41.800 --> 38:44.340\n that's been submitted by the,\n\n38:44.340 --> 38:49.340\n usually in conjunction with or by the drug company\n\n38:49.340 --> 38:51.500\n that manufactures the drug.\n\n38:51.500 --> 38:56.500\n So peer reviewers are unable to perform the job\n\n38:57.320 --> 38:59.700\n that doctors think they're performing\n\n38:59.700 --> 39:03.260\n to vet the data to assure that it's accurate\n\n39:03.260 --> 39:05.060\n and reasonably complete.\n\n39:05.060 --> 39:06.300\n They can't do it.\n\n39:07.300 --> 39:09.460\n And then we have the clinical practice guidelines,\n\n39:09.460 --> 39:11.280\n which are increasingly more important\n\n39:11.280 --> 39:15.840\n as the information, the flow of information\n\n39:15.840 --> 39:18.660\n keeps getting brisker and brisker,\n\n39:18.660 --> 39:22.020\n and docs need to get to the bottom line quickly.\n\n39:22.020 --> 39:25.680\n Clinical practice guidelines become much more important.\n\n39:25.680 --> 39:28.780\n And we assume that the authors\n\n39:28.780 --> 39:30.380\n of those clinical practice guidelines\n\n39:30.380 --> 39:32.380\n have independently analyzed the data\n\n39:32.380 --> 39:35.880\n from the clinical trials and make their recommendations\n\n39:35.880 --> 39:39.140\n that set the standards of care based on their analysis.\n\n39:39.140 --> 39:40.860\n That's not what happens.\n\n39:40.860 --> 39:44.180\n The experts who write the clinical trials\n\n39:44.180 --> 39:49.180\n rely almost entirely on the publications\n\n39:49.460 --> 39:51.940\n presenting the results of the clinical trials,\n\n39:51.940 --> 39:52.980\n which are peer reviewed,\n\n39:52.980 --> 39:56.340\n but the peer reviewers haven't had access to the data.\n\n39:56.340 --> 40:01.140\n So we've got a system of the highest level of evidence\n\n40:01.140 --> 40:03.780\n that doctors have been trained over and over again\n\n40:03.780 --> 40:06.420\n to rely on to practice evidence based medicine\n\n40:06.420 --> 40:10.860\n to be good doctors that has not been verified.\n\n40:10.860 --> 40:14.300\n Do you think that data that's coming\n\n40:14.300 --> 40:17.100\n from the pharma companies,\n\n40:17.100 --> 40:18.160\n do you think there,\n\n40:19.420 --> 40:22.520\n what level of manipulation is going on with that data?\n\n40:22.520 --> 40:25.940\n Is it at the study design level?\n\n40:25.940 --> 40:28.140\n Is it at literally there's some data\n\n40:28.140 --> 40:33.140\n that you just keep off, keep out of the charts,\n\n40:33.860 --> 40:38.580\n keep out of the aggregate analysis that you then publish?\n\n40:38.580 --> 40:41.380\n Or is it the worst case,\n\n40:41.380 --> 40:44.640\n which is just change some of the numbers?\n\n40:44.640 --> 40:45.480\n It happened.\n\n40:45.480 --> 40:46.300\n All three happened.\n\n40:46.300 --> 40:48.540\n I can't, I don't know what the denominator is,\n\n40:48.540 --> 40:51.660\n but I spent about 10 years in litigation.\n\n40:51.660 --> 40:54.900\n And for example, in Vioxx,\n\n40:54.900 --> 40:57.380\n which was withdrawn from the market in 2004\n\n40:57.380 --> 41:01.220\n in the biggest drug recall in American history,\n\n41:02.280 --> 41:06.080\n the problem was that it got recalled\n\n41:06.080 --> 41:08.580\n when a study that Merck sponsored\n\n41:08.580 --> 41:10.580\n showed that Vioxx doubled the risk,\n\n41:10.580 --> 41:12.740\n more than doubled the risk of heart attacks,\n\n41:12.740 --> 41:16.760\n strokes, and blood clots, serious blood clots.\n\n41:16.760 --> 41:18.100\n It got pulled then.\n\n41:18.100 --> 41:20.660\n But there was a study, a bigger study\n\n41:20.660 --> 41:22.740\n that had been published in 2000\n\n41:22.740 --> 41:24.660\n in the New England Journal of Medicine\n\n41:24.660 --> 41:28.580\n that showed that Vioxx was a better drug\n\n41:28.580 --> 41:32.820\n for arthritis and pain,\n\n41:32.820 --> 41:34.240\n not because it was more effective.\n\n41:34.240 --> 41:36.440\n It's no more effective than Aleve or Advil,\n\n41:37.460 --> 41:40.220\n but because it was less likely\n\n41:40.220 --> 41:43.220\n to cause serious GI complications,\n\n41:43.220 --> 41:45.100\n bleeds and perforations in the gut.\n\n41:46.180 --> 41:48.140\n Now, in that study that was published\n\n41:48.140 --> 41:51.620\n in the New England Journal that was never corrected,\n\n41:51.620 --> 41:55.960\n it was a little bit modified 15 months\n\n41:55.960 --> 41:57.540\n after the drug was taken off the market,\n\n41:57.540 --> 42:01.540\n but never corrected, Merck left out three heart attacks.\n\n42:01.540 --> 42:05.600\n And the FDA knew that Merck left out three heart attacks,\n\n42:05.600 --> 42:10.400\n and the FDA's analysis of the data from that study\n\n42:10.400 --> 42:14.680\n said that the FDA wasn't gonna do the analysis\n\n42:14.680 --> 42:16.920\n without the three heart attacks in it.\n\n42:16.920 --> 42:19.640\n And the important part of this story\n\n42:19.640 --> 42:23.080\n is that there were 12 authors listed on that study\n\n42:23.080 --> 42:24.320\n in the New England Journal.\n\n42:24.320 --> 42:26.240\n Two were Merck employees.\n\n42:26.240 --> 42:27.760\n They knew about the three heart attacks\n\n42:27.760 --> 42:29.600\n that had been omitted.\n\n42:29.600 --> 42:34.440\n The other 10 authors, the academic authors,\n\n42:34.440 --> 42:35.420\n didn't know about it.\n\n42:35.420 --> 42:37.080\n They hadn't seen that data.\n\n42:38.000 --> 42:41.940\n So Merck just, they had an excuse.\n\n42:41.940 --> 42:44.240\n It's complicated, and the FDA didn't accept it,\n\n42:44.240 --> 42:46.800\n so there's no reason to go into it.\n\n42:46.800 --> 42:48.800\n But Merck just left out the three heart attacks.\n\n42:48.800 --> 42:50.000\n And the three heart attacks,\n\n42:50.000 --> 42:52.720\n it may seem three heart attacks in a 10,000 person study\n\n42:52.720 --> 42:54.160\n may seem like nothing,\n\n42:54.160 --> 42:57.540\n except they completely changed the statistics\n\n42:57.540 --> 43:00.020\n so that had the three heart attacks been included,\n\n43:00.020 --> 43:02.600\n the only conclusion that Merck could have made\n\n43:02.600 --> 43:04.700\n was that Vioxx significantly increased\n\n43:04.700 --> 43:06.360\n the risk of heart attack.\n\n43:06.360 --> 43:09.600\n And they abbreviated their endpoint\n\n43:09.600 --> 43:12.380\n from heart attack, strokes, and blood clots\n\n43:12.380 --> 43:13.800\n to just heart attacks.\n\n43:13.800 --> 43:14.720\n Yeah.\n\n43:14.720 --> 43:17.120\n So those are, maybe in their mind,\n\n43:17.120 --> 43:18.300\n they're also playing by the rules\n\n43:18.300 --> 43:20.400\n because of some technical excuse that you mentioned\n\n43:20.400 --> 43:21.400\n that was rejected.\n\n43:22.240 --> 43:24.040\n How can this, because this is crossing the line.\n\n43:24.040 --> 43:25.080\n No, no, let me interrupt.\n\n43:25.080 --> 43:28.080\n No, that's not true.\n\n43:28.080 --> 43:30.440\n The study was completed.\n\n43:30.440 --> 43:33.480\n The blind was broken, meaning they looked at the data.\n\n43:34.460 --> 43:37.400\n In March of 2000, the article was published\n\n43:37.400 --> 43:40.120\n in the New England Journal in November of 2000.\n\n43:40.120 --> 43:45.120\n In March of 2000, there was an email by the head scientist\n\n43:45.960 --> 43:48.200\n that was published in the Wall Street Journal\n\n43:49.680 --> 43:53.840\n that said the day that the data were unblinded,\n\n43:53.840 --> 43:57.700\n that it's a shame that the cardiovascular events are there,\n\n43:58.660 --> 44:03.660\n but the drug will do well and we will do well.\n\n44:08.680 --> 44:10.840\n But removing the three heart attacks,\n\n44:10.840 --> 44:12.360\n how does that happen?\n\n44:12.360 --> 44:16.840\n Like who has to convince themselves?\n\n44:16.840 --> 44:18.560\n Is this pure malevolence?\n\n44:19.520 --> 44:21.440\n You have to be the judge of that,\n\n44:21.440 --> 44:24.560\n but the person who was in charge of the Data Safety\n\n44:24.560 --> 44:28.440\n Monitoring Board issued a letter that said\n\n44:28.440 --> 44:32.400\n they'll stop counting cardiovascular events\n\n44:32.400 --> 44:35.120\n a month before the trial is over\n\n44:35.120 --> 44:38.420\n and they'll continue counting GI events.\n\n44:38.420 --> 44:43.360\n And that person got a contract to consult with Merck\n\n44:43.360 --> 44:47.580\n for $5,000 a day, I think for 12 days a year,\n\n44:47.580 --> 44:52.400\n for one or two years that was signed, that contract\n\n44:53.880 --> 44:58.220\n was signed within two weeks of the decision\n\n44:58.220 --> 45:00.480\n to stop counting heart attacks.\n\n45:00.480 --> 45:03.140\n I wanna understand that man or woman.\n\n45:04.440 --> 45:08.040\n I wanna, I want, it's the, I've been reading a lot\n\n45:08.040 --> 45:10.960\n about Nazi Germany and thinking a lot\n\n45:10.960 --> 45:15.960\n about the good Germans because I want to understand\n\n45:15.960 --> 45:20.000\n so that we can each encourage each other\n\n45:20.000 --> 45:23.800\n to take the small heroic actions that prevents that.\n\n45:23.800 --> 45:27.140\n Because it feels to me, removing malevolence\n\n45:27.140 --> 45:31.240\n from the table where it's just a pure psychopathic person,\n\n45:31.240 --> 45:34.120\n that there's just a momentum created\n\n45:34.120 --> 45:35.680\n by the game like you mentioned.\n\n45:35.680 --> 45:40.680\n And so it takes reversing the momentum within the company,\n\n45:40.680 --> 45:45.680\n I think requires many small acts of heroism.\n\n45:46.880 --> 45:50.640\n Not gigantic, I'm going to leave and become a whistleblower\n\n45:50.640 --> 45:52.480\n and publish a book about it.\n\n45:52.480 --> 45:57.060\n But small, quiet acts of pressuring against this.\n\n45:57.060 --> 45:59.200\n Like, what are we doing here?\n\n45:59.200 --> 46:00.480\n We're trying to help people.\n\n46:00.480 --> 46:01.680\n Is this the right thing to do?\n\n46:01.680 --> 46:03.380\n Looking in the mirror constantly asking,\n\n46:03.380 --> 46:05.240\n is this the right thing to do?\n\n46:05.240 --> 46:07.620\n I mean, that's how, that's what integrity is.\n\n46:07.620 --> 46:11.220\n Acknowledging the pressures you're under\n\n46:11.220 --> 46:13.100\n and then still be able to zoom out\n\n46:13.100 --> 46:15.300\n and think what is the right thing to do here.\n\n46:16.620 --> 46:21.180\n But the data, hiding the data makes it too easy\n\n46:21.180 --> 46:22.660\n to live in ignorance.\n\n46:22.660 --> 46:25.420\n So like within those, inside those companies.\n\n46:29.540 --> 46:34.540\n So your idea is that the reviewers should see the data.\n\n46:34.760 --> 46:36.380\n That's one step.\n\n46:36.380 --> 46:39.740\n So to even push back on that idea is,\n\n46:40.980 --> 46:43.340\n I assume you mean the data remains private\n\n46:43.340 --> 46:47.040\n except to the peer reviews, reviewers.\n\n46:47.040 --> 46:49.620\n The problem with, of course, as you probably know\n\n46:49.620 --> 46:52.040\n is the peer review process is not perfect.\n\n46:53.060 --> 46:55.460\n You know, it's individuals.\n\n46:55.460 --> 46:58.740\n It feels like there should be a lot more eyes on the data\n\n46:58.740 --> 47:00.440\n than just the peer reviewers.\n\n47:00.440 --> 47:03.500\n Yes, this is not a hard problem to solve.\n\n47:03.500 --> 47:06.660\n When a study is completed,\n\n47:06.660 --> 47:09.020\n a clinical study report is made.\n\n47:10.220 --> 47:12.300\n And it's usually several thousand pages.\n\n47:12.300 --> 47:15.940\n And what it does is it takes the raw patient data\n\n47:15.940 --> 47:20.940\n and it tabulates it in the ways it's supposedly and usually\n\n47:22.060 --> 47:25.620\n in the ways that the company has pre specified.\n\n47:25.620 --> 47:28.420\n So that you then end up with a searchable,\n\n47:28.420 --> 47:30.740\n let's say 3000 page document.\n\n47:30.740 --> 47:35.740\n As I became more experienced as an expert in litigation,\n\n47:36.160 --> 47:39.680\n I could go through those documents pretty quickly.\n\n47:39.680 --> 47:42.040\n Quickly may mean 20 hours or 40 hours,\n\n47:42.040 --> 47:44.360\n but it doesn't mean three months of my work.\n\n47:45.280 --> 47:49.120\n And see if the companies,\n\n47:49.120 --> 47:51.640\n if the way the company has analyzed the data\n\n47:51.640 --> 47:53.640\n is consistent with the way,\n\n47:53.640 --> 47:55.800\n with their statistical analysis plan\n\n47:55.800 --> 48:00.080\n and their pre specified outcome measures.\n\n48:00.080 --> 48:01.280\n It's not hard.\n\n48:01.280 --> 48:02.800\n And I think you're right.\n\n48:02.800 --> 48:06.200\n Peer reviewers, I don't peer review clinical trials,\n\n48:06.200 --> 48:09.320\n but I peer review other kinds of articles.\n\n48:09.320 --> 48:11.520\n I have to do one on the airplane on the way home.\n\n48:11.520 --> 48:12.360\n And it's hard.\n\n48:12.360 --> 48:15.640\n I mean, we're just ordinary mortal people volunteering to.\n\n48:15.640 --> 48:19.160\n Unpaid, the motivation is not clear.\n\n48:19.160 --> 48:22.080\n The motivation is to keep,\n\n48:23.520 --> 48:27.920\n to be a good citizen in the medical community\n\n48:27.920 --> 48:31.120\n and to be on friendly terms with the journals\n\n48:31.120 --> 48:33.280\n so that if you wanna get published,\n\n48:33.280 --> 48:37.320\n there's sort of an unspoken incentive.\n\n48:37.320 --> 48:39.840\n As somebody who enjoys game theory,\n\n48:39.840 --> 48:42.200\n I feel like that motivation is good,\n\n48:42.200 --> 48:43.700\n but it could be a lot better.\n\n48:44.560 --> 48:46.540\n Yes, you should get more recognition\n\n48:46.540 --> 48:50.280\n or in some way academic credit for it.\n\n48:50.280 --> 48:53.000\n It should go to your career advancement.\n\n48:53.000 --> 48:54.400\n If it's an important paper\n\n48:54.400 --> 48:56.600\n and you recognize it's an important paper\n\n48:56.600 --> 48:58.440\n as a great peer reviewer,\n\n48:58.440 --> 49:01.240\n that this is not in that area\n\n49:01.240 --> 49:05.920\n where it's like clearly a piece of crap paper\n\n49:05.920 --> 49:08.320\n or clearly an awesome paper\n\n49:08.320 --> 49:10.880\n that doesn't have controversial aspects to it\n\n49:10.880 --> 49:13.120\n and it's just a beautiful piece of work.\n\n49:13.120 --> 49:14.640\n Okay, those are easy.\n\n49:14.640 --> 49:17.720\n And then there is like the very difficult gray area,\n\n49:17.720 --> 49:20.240\n which may require many, many days of work\n\n49:20.240 --> 49:21.920\n on your part as a peer reviewer.\n\n49:21.920 --> 49:24.400\n So it's not just a couple hours,\n\n49:24.400 --> 49:27.280\n but really seriously reading.\n\n49:27.280 --> 49:30.720\n Like some papers can take months to really understand.\n\n49:30.720 --> 49:33.600\n So if you really wanna struggle,\n\n49:33.600 --> 49:35.920\n there has to be an incentive for that struggle.\n\n49:35.920 --> 49:40.920\n Yes, and billions of dollars ride on some of these studies.\n\n49:41.280 --> 49:44.680\n And lives, right, not to mention.\n\n49:44.680 --> 49:49.680\n Right, but it would be easy to have full time statisticians\n\n49:49.680 --> 49:53.840\n hired by the journals or shared by the journals\n\n49:55.280 --> 50:00.280\n who were independent of any other financial incentive\n\n50:00.280 --> 50:04.000\n to go over these kind of methodological issues\n\n50:04.000 --> 50:08.880\n and take responsibility for certifying the analyses\n\n50:08.880 --> 50:11.200\n that are done and then pass it on\n\n50:11.200 --> 50:14.080\n to the volunteer peer reviewers.\n\n50:14.080 --> 50:15.920\n See, I believe even in this,\n\n50:15.920 --> 50:19.400\n in the sort of capitalism or even social capital,\n\n50:19.400 --> 50:23.560\n after watching Twitter in the time of COVID\n\n50:23.560 --> 50:27.440\n and just looking at people that investigate themselves,\n\n50:27.440 --> 50:30.040\n I believe in the citizenry.\n\n50:30.040 --> 50:32.440\n People, if you give them access to the data,\n\n50:32.440 --> 50:35.880\n like these like citizen scientists arise.\n\n50:35.880 --> 50:38.360\n A lot of them on the, it's kind of funny,\n\n50:39.320 --> 50:40.960\n a lot of people that are just really used\n\n50:40.960 --> 50:41.960\n to working with data,\n\n50:43.160 --> 50:44.600\n they don't know anything about medicine\n\n50:44.600 --> 50:46.800\n and they don't have actually the biases\n\n50:46.800 --> 50:48.880\n that a lot of doctors and medical\n\n50:48.880 --> 50:51.040\n and a lot of the people that read these papers,\n\n50:51.040 --> 50:53.240\n they'll just go raw into the data\n\n50:53.240 --> 50:56.120\n and look at it with like they're bored almost\n\n50:56.120 --> 50:58.320\n and they do incredible analysis.\n\n50:58.320 --> 51:01.080\n So I, you know, there's some argument to be made\n\n51:01.080 --> 51:04.080\n for a lot of this data to become public,\n\n51:04.080 --> 51:07.120\n like deanonymized, no, sorry, anonymized,\n\n51:08.360 --> 51:11.120\n all that kind of stuff, but for a lot of it to be public,\n\n51:11.120 --> 51:13.360\n especially when you're talking about things\n\n51:14.520 --> 51:16.960\n as impactful as some of these drugs.\n\n51:16.960 --> 51:19.960\n I agree 100%, so let's turn the micro,\n\n51:19.960 --> 51:22.160\n let's get a little bit more granular.\n\n51:22.160 --> 51:24.200\n On the peer review issue,\n\n51:24.200 --> 51:27.800\n we're talking about pre publication transparencies\n\n51:27.800 --> 51:29.600\n and that is critically important.\n\n51:29.600 --> 51:33.600\n Once a paper is published, the horses are out of the barn\n\n51:33.600 --> 51:34.840\n and docs are gonna read it,\n\n51:34.840 --> 51:36.800\n take it as evidence based medicine.\n\n51:36.800 --> 51:41.040\n The economists call what then happens as stickiness\n\n51:41.040 --> 51:43.360\n that the docs hold on to their beliefs\n\n51:43.360 --> 51:47.280\n and my own voice inside says,\n\n51:47.280 --> 51:52.000\n once doctors start doing things to their patients bodies,\n\n51:52.000 --> 51:53.640\n they're really not too enthusiastic\n\n51:53.640 --> 51:55.440\n about hearing it was wrong.\n\n51:55.440 --> 51:57.880\n Yeah, that's the stickiness of human nature.\n\n51:57.880 --> 52:00.840\n Wow, so that bar, once it's published,\n\n52:01.880 --> 52:05.120\n the doctors, that's when the stickiness emerges, wow.\n\n52:05.120 --> 52:08.200\n Yeah, it's hard to put that toothpaste back in the tube.\n\n52:08.200 --> 52:11.520\n Now, that's pre publication transparency,\n\n52:11.520 --> 52:14.520\n which is essential and you could have,\n\n52:14.520 --> 52:17.440\n whoever saw that data pre publication\n\n52:17.440 --> 52:19.960\n could sign confidentiality agreements\n\n52:19.960 --> 52:22.480\n so that the drug companies couldn't argue\n\n52:22.480 --> 52:24.680\n that we're just opening the spigots of our data\n\n52:24.680 --> 52:28.880\n and people can copy it and blah, all the excuses they make.\n\n52:28.880 --> 52:30.520\n You could argue that you didn't have to\n\n52:30.520 --> 52:32.400\n but let's just let them do it.\n\n52:32.400 --> 52:35.160\n Let the peer reviewers sign confidentiality agreements\n\n52:35.160 --> 52:36.760\n and they won't leak the data\n\n52:36.760 --> 52:39.840\n but then you have to go to post publication transparency,\n\n52:39.840 --> 52:41.720\n which is what you were just getting at\n\n52:41.720 --> 52:46.720\n to let the data free and let citizens\n\n52:47.000 --> 52:50.520\n and citizen scientists and other doctors\n\n52:50.520 --> 52:52.640\n who are interested have at it.\n\n52:53.640 --> 52:56.600\n Kind of like Wiki, Wikipedia, have at it.\n\n52:57.680 --> 53:00.080\n Let it out and let people criticize each other.\n\n53:01.280 --> 53:03.120\n Okay, so speaking of the data,\n\n53:03.120 --> 53:08.120\n the FDA asked 55 years to release Pfizer vaccine data.\n\n53:08.120 --> 53:11.600\n This is also something I raised with Albert Bourla.\n\n53:11.600 --> 53:13.200\n What did he say?\n\n53:13.200 --> 53:16.200\n There's several things I didn't like about what he said.\n\n53:16.200 --> 53:17.760\n So some things are expected\n\n53:17.760 --> 53:20.520\n and some of it is just revealing the human being,\n\n53:20.520 --> 53:23.160\n which is what I'm interested in doing.\n\n53:23.160 --> 53:27.520\n But he said he wasn't aware of the 75 and the 55.\n\n53:27.520 --> 53:29.240\n I'm sorry, wait a minute.\n\n53:29.240 --> 53:30.520\n He wasn't aware of?\n\n53:30.520 --> 53:33.120\n The how long, so here I'll explain what he.\n\n53:33.120 --> 53:36.800\n Do you know that since you spoke to him,\n\n53:36.800 --> 53:41.800\n Pfizer has petitioned the judge to join the suit\n\n53:42.120 --> 53:45.000\n in behalf of the FDA's request\n\n53:45.000 --> 53:50.040\n to release that data over 55 or 75 years?\n\n53:50.040 --> 53:52.200\n Pfizer's fully aware of what's going on.\n\n53:52.200 --> 53:53.280\n He's aware.\n\n53:53.280 --> 53:56.280\n I'm sure he's aware in some formulation.\n\n53:56.280 --> 53:59.080\n The exact years he might have not been aware.\n\n53:59.080 --> 54:01.200\n But the point is that there is,\n\n54:02.520 --> 54:06.600\n that is the FDA, the relationship of Pfizer and the FDA\n\n54:06.600 --> 54:11.000\n in terms of me being able to read human beings\n\n54:11.000 --> 54:14.320\n was the thing he was most uncomfortable with,\n\n54:14.320 --> 54:17.440\n that he didn't wanna talk about the FDA.\n\n54:17.440 --> 54:20.080\n And that really, it was clear\n\n54:20.080 --> 54:22.280\n that there was a relationship there\n\n54:22.280 --> 54:26.440\n that if the words you use may do a lot of harm,\n\n54:26.440 --> 54:28.520\n potentially because like you're saying,\n\n54:28.520 --> 54:31.360\n there might be lawsuits going on, there's litigation,\n\n54:31.360 --> 54:33.480\n there's legal stuff, all that kind of stuff.\n\n54:33.480 --> 54:36.600\n And then there's a lot of games being played in this space.\n\n54:36.600 --> 54:40.040\n So I don't know how to interpret it\n\n54:40.040 --> 54:41.560\n if he's actually aware or not,\n\n54:41.560 --> 54:46.560\n but the deeper truth is that he's deeply uncomfortable\n\n54:49.600 --> 54:53.080\n bringing light to this part of the game.\n\n54:53.080 --> 54:56.000\n Yes, and I'm gonna read between the lines\n\n54:56.000 --> 54:59.960\n and Albert Borla certainly didn't ask me to speak for him.\n\n54:59.960 --> 55:02.480\n But I think, but when did you speak to him?\n\n55:02.480 --> 55:03.440\n How long ago?\n\n55:03.440 --> 55:05.800\n Wow, time flies when you're having fun.\n\n55:05.800 --> 55:06.640\n Two months ago.\n\n55:06.640 --> 55:07.480\n Two months ago.\n\n55:07.480 --> 55:12.040\n So that was just recently it's come out,\n\n55:12.040 --> 55:14.480\n just in the past week it's come out\n\n55:14.480 --> 55:18.920\n that Pfizer isn't battling the FDA.\n\n55:18.920 --> 55:23.920\n Pfizer has joined the FDA in the opposition to the request\n\n55:24.880 --> 55:29.880\n to release these documents in the same amount of time\n\n55:29.880 --> 55:33.200\n that the FDA took to evaluate them.\n\n55:33.200 --> 55:34.080\n Yeah.\n\n55:34.080 --> 55:39.080\n So Pfizer is offering to help the FDA\n\n55:43.740 --> 55:48.740\n to petition the judge to not enforce the timeline\n\n55:51.560 --> 55:54.120\n that he seems to be moving towards.\n\n55:54.120 --> 55:55.600\n So for people who are not familiar,\n\n55:55.600 --> 55:59.120\n we're talking about the Freedom of Information Act request\n\n55:59.120 --> 56:04.120\n to release the Pfizer vaccine data, study data\n\n56:05.200 --> 56:07.240\n to release as much of the data as possible,\n\n56:07.240 --> 56:08.920\n like the raw data, the details,\n\n56:08.920 --> 56:10.560\n or actually not even the raw data,\n\n56:10.560 --> 56:14.620\n it's data, doesn't matter, there's details to it.\n\n56:14.620 --> 56:19.620\n And I think the response from the FDA is that of course,\n\n56:20.200 --> 56:25.200\n yes, of course, but we can only publish\n\n56:25.200 --> 56:29.720\n we can only publish like some X number of pages a day.\n\n56:29.720 --> 56:31.000\n 500 pages.\n\n56:31.000 --> 56:32.720\n 500 pages of data.\n\n56:32.720 --> 56:36.440\n It's not a day though, it's a week I think.\n\n56:36.440 --> 56:39.400\n The point is whatever they're able to publish is ridiculous.\n\n56:39.400 --> 56:44.400\n It's like my printer can only print three pages a day\n\n56:45.520 --> 56:48.000\n and we cannot afford a second printer.\n\n56:48.000 --> 56:52.320\n So it's some kind of bureaucratic language for,\n\n56:52.320 --> 56:56.160\n there's a process to this, and now you're saying\n\n56:56.160 --> 57:00.320\n that Pfizer is obviously more engaged\n\n57:00.320 --> 57:04.160\n in helping this kind of bureaucratic process prosper\n\n57:04.160 --> 57:08.880\n in its full absurdity, Kafkaesque absurdity.\n\n57:08.880 --> 57:11.860\n So what is this?\n\n57:11.860 --> 57:13.800\n This really bothered people.\n\n57:13.800 --> 57:14.640\n This really.\n\n57:14.640 --> 57:15.680\n This is really troublesome.\n\n57:15.680 --> 57:19.660\n And just to put it in just plain English terms,\n\n57:19.660 --> 57:23.540\n Pfizer's making the case that it can't,\n\n57:24.860 --> 57:27.460\n the FDA and Pfizer together are making the case\n\n57:27.460 --> 57:29.820\n that they can't go through the documents.\n\n57:29.820 --> 57:33.700\n It's gonna take them some number of hundredfold,\n\n57:33.700 --> 57:37.140\n hundreds of folds more time to go through the documents\n\n57:37.140 --> 57:39.860\n than the FDA required to go through the documents\n\n57:39.860 --> 57:42.300\n to approve the vaccines,\n\n57:42.300 --> 57:44.940\n to give the vaccines full FDA approval.\n\n57:44.940 --> 57:48.940\n And the FDA's argument, talk about Kafkaesque,\n\n57:48.940 --> 57:51.340\n is that to do it more rapidly\n\n57:51.340 --> 57:52.980\n would cost them $3 million.\n\n57:54.820 --> 57:59.820\n $3 million equals one hour of vaccine sales over two years.\n\n58:01.980 --> 58:04.340\n One hour of sales.\n\n58:04.340 --> 58:05.900\n And they can't come up with the money.\n\n58:05.900 --> 58:08.020\n And now Pfizer has joined the suit\n\n58:08.020 --> 58:11.140\n to help the FDA fight off this judge, this mean judge,\n\n58:11.140 --> 58:12.900\n who thinks they ought to release the data.\n\n58:12.900 --> 58:15.020\n But evidently Pfizer isn't offering\n\n58:15.020 --> 58:17.300\n to come up with the $3 million either.\n\n58:17.300 --> 58:19.820\n So, but for $3 million, I mean, maybe,\n\n58:21.740 --> 58:25.500\n maybe the FDA should do a GoFundMe campaign.\n\n58:25.500 --> 58:28.420\n Well, obviously the money thing,\n\n58:28.420 --> 58:31.380\n I mean, I'm sure if Elon Musk comes along and says,\n\n58:31.380 --> 58:35.500\n I'll give you $100 million, publish it now,\n\n58:35.500 --> 58:37.900\n I think they'll come up with another.\n\n58:37.900 --> 58:41.900\n So, I mean, it's clear that there's cautiousness.\n\n58:43.660 --> 58:47.140\n I don't know the source of it from the FDA.\n\n58:47.140 --> 58:49.660\n There's only one explanation that I can think of,\n\n58:50.580 --> 58:53.020\n which is that the FDA and Pfizer\n\n58:53.020 --> 58:54.540\n don't wanna release the data.\n\n58:55.420 --> 58:57.940\n They don't wanna release the three\n\n58:57.940 --> 59:02.020\n or 500,000 pages of documents.\n\n59:03.180 --> 59:05.380\n And I don't know what's in there.\n\n59:05.380 --> 59:08.140\n I wanna say one thing very clearly.\n\n59:08.140 --> 59:10.140\n I am not an anti faxer.\n\n59:10.140 --> 59:11.940\n I believe the vaccines work.\n\n59:11.940 --> 59:15.220\n I believe everybody should get vaccinated.\n\n59:15.220 --> 59:17.620\n The evidence is clear that if you're vaccinated,\n\n59:17.620 --> 59:20.900\n you reduce your risk of dying of COVID by 20 fold.\n\n59:20.900 --> 59:23.460\n And we've got new sub variants coming along.\n\n59:23.460 --> 59:26.620\n And I just wanna be very clear about this.\n\n59:26.620 --> 59:31.620\n That said, there's something I would give you 10 to one odds\n\n59:32.420 --> 59:35.100\n on a bet that there's something in that data\n\n59:35.100 --> 59:40.100\n that is gonna be embarrassing to either FDA or Pfizer\n\n59:40.460 --> 59:41.300\n or both.\n\n59:41.300 --> 59:42.140\n So there's two options.\n\n59:42.140 --> 59:43.740\n I agree with you 100%.\n\n59:43.740 --> 59:46.700\n One is they know of embarrassing things.\n\n59:46.700 --> 59:48.180\n That's option one.\n\n59:48.180 --> 59:51.740\n And option two, they haven't invested enough\n\n59:51.740 --> 59:54.180\n to truly understand the data.\n\n59:54.180 --> 59:56.420\n Like, I mean, it's a lot of data\n\n59:56.420 --> 59:58.140\n that they have a sense\n\n59:58.140 --> 1:00:00.020\n that might be something embarrassing in there.\n\n1:00:00.020 --> 1:00:02.100\n And if we release it,\n\n1:00:02.100 --> 1:00:04.380\n surely the world will discover the embarrassing\n\n1:00:04.380 --> 1:00:08.860\n and to do a sort of the steel man their argument.\n\n1:00:08.860 --> 1:00:11.660\n They'll take the small, the press,\n\n1:00:11.660 --> 1:00:14.420\n the people will take the small embarrassing things\n\n1:00:14.420 --> 1:00:16.380\n and blow them up into big things.\n\n1:00:16.380 --> 1:00:20.260\n Yes, and support the anti vax campaign.\n\n1:00:20.260 --> 1:00:22.660\n I think that's all possible.\n\n1:00:22.660 --> 1:00:27.660\n Nonetheless, the data are about the original clinical trial.\n\n1:00:27.860 --> 1:00:32.860\n And the emergency use authorization was based\n\n1:00:33.340 --> 1:00:36.140\n on the first few months of the data from that trial.\n\n1:00:36.140 --> 1:00:37.780\n And it was a two year trial.\n\n1:00:37.780 --> 1:00:40.140\n The rest of that data has not been opened up\n\n1:00:40.140 --> 1:00:43.460\n and there was not an advisory committee meeting\n\n1:00:43.460 --> 1:00:44.940\n to look at that data\n\n1:00:44.940 --> 1:00:47.340\n when the FDA granted full authorization.\n\n1:00:47.340 --> 1:00:49.220\n Again, I am pro vaccine.\n\n1:00:49.220 --> 1:00:52.540\n I am not making an anti vax argument here.\n\n1:00:52.540 --> 1:00:56.060\n But I suspect that there's something pretty serious\n\n1:00:56.060 --> 1:00:57.380\n in that data.\n\n1:00:57.380 --> 1:01:00.020\n And the reason why I'm not an anti vaxxer,\n\n1:01:00.980 --> 1:01:03.380\n having not been able to see the data\n\n1:01:03.380 --> 1:01:06.020\n that the FDA and Pfizer seem to willing\n\n1:01:06.020 --> 1:01:09.940\n not just to put effort into preventing the release of,\n\n1:01:09.940 --> 1:01:12.100\n but seem to have quite a bit of energy\n\n1:01:12.100 --> 1:01:15.140\n into preventing, invest quite a bit of energy\n\n1:01:15.140 --> 1:01:16.460\n in not releasing that data.\n\n1:01:16.460 --> 1:01:18.380\n The reason why that doesn't tip me over\n\n1:01:18.380 --> 1:01:20.180\n into the anti vaxxer side\n\n1:01:20.180 --> 1:01:22.380\n is because that's clinical trial data,\n\n1:01:22.380 --> 1:01:23.660\n early clinical trial data\n\n1:01:23.660 --> 1:01:25.780\n that involved several thousand people.\n\n1:01:25.780 --> 1:01:28.900\n We now have millions of data points\n\n1:01:28.900 --> 1:01:31.060\n from people who have had the vaccine.\n\n1:01:31.060 --> 1:01:32.900\n This is real world data,\n\n1:01:32.900 --> 1:01:35.700\n showing the efficacy of the vaccines.\n\n1:01:35.700 --> 1:01:38.100\n And so far, knock on wood,\n\n1:01:38.100 --> 1:01:41.220\n there aren't side effects\n\n1:01:41.220 --> 1:01:45.100\n that overcome the benefits of vaccine.\n\n1:01:45.100 --> 1:01:46.500\n So I'm with you.\n\n1:01:46.500 --> 1:01:51.360\n I'm now, I guess, three shots of the vaccine.\n\n1:01:53.180 --> 1:01:55.740\n But there's a lot of people that are kind of saying,\n\n1:01:55.740 --> 1:02:00.260\n well, even the data on the real world use large scale data\n\n1:02:03.980 --> 1:02:05.660\n is messy.\n\n1:02:05.660 --> 1:02:06.820\n The way it's being reported,\n\n1:02:06.820 --> 1:02:08.780\n the way it's being interpreted.\n\n1:02:08.780 --> 1:02:11.500\n Well, one thing is clear to me\n\n1:02:11.500 --> 1:02:13.820\n that it is being politicized.\n\n1:02:13.820 --> 1:02:16.120\n I mean, if you just look objectively,\n\n1:02:17.120 --> 1:02:21.740\n don't have to go to at the shallow surface level.\n\n1:02:21.740 --> 1:02:24.140\n It seems like there's two groups\n\n1:02:25.180 --> 1:02:29.020\n that I can't even put a term to it\n\n1:02:29.020 --> 1:02:32.140\n because it's not really pro vaccine versus anti vaccine\n\n1:02:32.140 --> 1:02:37.140\n because it's pro vaccine, triple mask, Democrat, liberal,\n\n1:02:41.140 --> 1:02:44.700\n and then anti mandate, whatever those groups are.\n\n1:02:44.700 --> 1:02:46.540\n I can't quite, cause they're changing.\n\n1:02:46.540 --> 1:02:50.380\n Anti mask, but not really, but kind of.\n\n1:02:50.380 --> 1:02:53.260\n So those two groups that feel political in nature,\n\n1:02:53.260 --> 1:02:56.700\n not scientific in nature, they're bickering.\n\n1:02:56.700 --> 1:03:01.200\n And then it's clear that this data is being interpreted\n\n1:03:01.200 --> 1:03:03.140\n by the different groups differently.\n\n1:03:04.020 --> 1:03:07.460\n And it's very difficult for me as a human being\n\n1:03:07.460 --> 1:03:11.180\n to understand where the truth lies,\n\n1:03:11.180 --> 1:03:14.060\n especially given how much money is flying around\n\n1:03:14.060 --> 1:03:15.380\n on all sides.\n\n1:03:15.380 --> 1:03:19.380\n So the anti vaxxers can make a lot of money too.\n\n1:03:19.380 --> 1:03:20.220\n Let's not forget this.\n\n1:03:20.220 --> 1:03:22.500\n From the individual perspective,\n\n1:03:22.500 --> 1:03:25.260\n you can become famous being an anti vaxxer.\n\n1:03:25.260 --> 1:03:28.060\n And so there's a lot of incentives on all sides here.\n\n1:03:28.060 --> 1:03:33.060\n And there's real human emotion and fear\n\n1:03:33.300 --> 1:03:35.300\n and also credibility.\n\n1:03:37.620 --> 1:03:41.100\n Scientists don't wanna ruin their reputation\n\n1:03:41.100 --> 1:03:45.340\n if they speak out in whatever, like speak their opinion\n\n1:03:45.340 --> 1:03:49.540\n or they look at some slice of the data\n\n1:03:49.540 --> 1:03:51.300\n and begin to interpret it in some kind of way.\n\n1:03:51.300 --> 1:03:53.740\n They're very, it's clear that fear is dominating\n\n1:03:53.740 --> 1:03:57.020\n the discourse here, especially in the scientific community.\n\n1:03:57.020 --> 1:03:59.320\n So I don't know what to make of that.\n\n1:04:01.860 --> 1:04:05.660\n And the only happy people here is Pfizer.\n\n1:04:06.780 --> 1:04:08.660\n It's just plowing all ahead.\n\n1:04:08.660 --> 1:04:13.240\n I mean, with every single variant,\n\n1:04:13.240 --> 1:04:18.240\n there's very, I would say, outside of arguably\n\n1:04:20.300 --> 1:04:23.260\n a very flawed system, there's a lot of incredible\n\n1:04:23.260 --> 1:04:25.760\n scientific and engineering work being done\n\n1:04:25.760 --> 1:04:29.820\n in constantly developing new, like antiviral drugs,\n\n1:04:29.820 --> 1:04:33.380\n new vaccines to deal with the variants.\n\n1:04:33.380 --> 1:04:37.540\n So they're happily being a capitalist machine.\n\n1:04:37.540 --> 1:04:42.540\n And it's very difficult to know what to do with that.\n\n1:04:43.620 --> 1:04:46.580\n And let's just put this in perspective for folks.\n\n1:04:46.580 --> 1:04:49.660\n The best selling drug in the world has been Humira\n\n1:04:49.660 --> 1:04:51.420\n for a number of years.\n\n1:04:51.420 --> 1:04:55.500\n It's approved for the treatment of rheumatoid arthritis\n\n1:04:55.500 --> 1:04:57.740\n and eight other indications.\n\n1:04:57.740 --> 1:05:02.140\n And it's sold about $20 billion globally\n\n1:05:02.140 --> 1:05:03.820\n over the past few years.\n\n1:05:03.820 --> 1:05:07.140\n It peaked at that level.\n\n1:05:07.140 --> 1:05:12.140\n Pfizer expects to sell $65 billion of vaccine\n\n1:05:12.940 --> 1:05:16.280\n in the first two years of the pandemic.\n\n1:05:16.280 --> 1:05:19.960\n So this is by far the biggest selling\n\n1:05:19.960 --> 1:05:22.700\n and most profitable drug that's ever come along.\n\n1:05:22.700 --> 1:05:27.020\n I can ask you a difficult question here.\n\n1:05:28.480 --> 1:05:31.520\n In the fog that we're operating in here,\n\n1:05:34.320 --> 1:05:38.680\n on the Pfizer BioNTech vaccine,\n\n1:05:40.340 --> 1:05:43.460\n what was done well and what was done badly\n\n1:05:43.460 --> 1:05:47.740\n that you can see now, it seems like we'll know\n\n1:05:47.740 --> 1:05:50.080\n more decades from now.\n\n1:05:50.080 --> 1:05:51.380\n Yes.\n\n1:05:51.380 --> 1:05:56.380\n But now in the fog of today with the $65 billion\n\n1:05:57.860 --> 1:06:02.220\n flying around, where do you land?\n\n1:06:03.060 --> 1:06:08.060\n So we're gonna get to what I think is one of the key problems\n\n1:06:08.500 --> 1:06:12.220\n with the pharmaceutical industry model in the United States\n\n1:06:12.220 --> 1:06:15.040\n about being profit driven.\n\n1:06:15.040 --> 1:06:20.040\n So in 2016, the NIH did the key infrastructure work\n\n1:06:22.440 --> 1:06:25.240\n to make mRNA vaccines.\n\n1:06:26.920 --> 1:06:29.320\n That gets left out of the discussion a lot.\n\n1:06:29.320 --> 1:06:33.520\n And Pfizer BioNTech actually paid royalties voluntarily\n\n1:06:35.160 --> 1:06:36.000\n to the NIH.\n\n1:06:36.000 --> 1:06:36.920\n I don't know how much it was.\n\n1:06:36.920 --> 1:06:38.540\n I don't think it was a whole lot of money,\n\n1:06:38.540 --> 1:06:41.200\n but I think they wanted to avoid the litigation\n\n1:06:41.200 --> 1:06:45.880\n that Moderna got itself into by just taking that 2016\n\n1:06:45.880 --> 1:06:48.780\n knowledge and having that be the foundation\n\n1:06:48.780 --> 1:06:50.120\n of their product.\n\n1:06:50.120 --> 1:06:54.640\n So Pfizer took that and they did their R&D,\n\n1:06:54.640 --> 1:06:59.160\n they paid for their R&D having received that technology.\n\n1:06:59.160 --> 1:07:03.800\n And when they got the genetic code from China\n\n1:07:03.800 --> 1:07:08.800\n about the virus, they very quickly made a vaccine\n\n1:07:09.480 --> 1:07:10.920\n and the vaccine works.\n\n1:07:10.920 --> 1:07:14.520\n And President Trump to his credit launched\n\n1:07:14.520 --> 1:07:18.120\n Operation Warp Speed and just threw money at the problem.\n\n1:07:18.120 --> 1:07:22.400\n They just said, we spent five times more per person\n\n1:07:22.400 --> 1:07:26.840\n than the EU early on, just pay them whatever they want.\n\n1:07:26.840 --> 1:07:28.360\n Let's just get this going.\n\n1:07:28.360 --> 1:07:32.360\n And Americans were vaccinated more quickly.\n\n1:07:32.360 --> 1:07:34.160\n We paid a lot of money.\n\n1:07:34.160 --> 1:07:37.120\n The one mistake that I think the federal government made\n\n1:07:37.120 --> 1:07:41.000\n was they were paying these guaranteed fortunes\n\n1:07:41.000 --> 1:07:45.320\n and they didn't require that the companies participate\n\n1:07:45.320 --> 1:07:49.040\n in a program to do global vaccinations.\n\n1:07:50.080 --> 1:07:53.480\n So the companies doing their business model\n\n1:07:53.480 --> 1:07:56.240\n distributed the vaccines where they would make\n\n1:07:56.240 --> 1:07:57.240\n the most money.\n\n1:07:57.240 --> 1:07:59.080\n And obviously they would make the most money\n\n1:07:59.080 --> 1:08:00.000\n in the first world.\n\n1:08:00.000 --> 1:08:04.240\n And almost I think 85% of the vaccines early on\n\n1:08:04.240 --> 1:08:08.760\n went to the first world and very, very few vaccinations\n\n1:08:08.760 --> 1:08:10.520\n went to the third world.\n\n1:08:10.520 --> 1:08:15.520\n So what happened is there was such a low vaccination rate\n\n1:08:16.440 --> 1:08:21.440\n in May of 2021, there was all hands on deck cry for help\n\n1:08:23.040 --> 1:08:25.120\n from the World Trade Organization,\n\n1:08:26.520 --> 1:08:31.480\n the World Health Organization, the IMF and the World Bank\n\n1:08:31.480 --> 1:08:36.480\n made a plea for $50 billion so that we could get\n\n1:08:36.720 --> 1:08:40.520\n to 40% vaccination rate in the third world\n\n1:08:40.520 --> 1:08:42.280\n by the end of 2021.\n\n1:08:44.360 --> 1:08:47.480\n And it was unrequited, nobody answered.\n\n1:08:48.840 --> 1:08:53.840\n And now Africa has about a 8.9% vaccination rate.\n\n1:08:54.440 --> 1:08:57.080\n India is coming up, but it's been very low.\n\n1:08:57.080 --> 1:09:02.080\n The problem with all this is I believe those mRNA vaccines\n\n1:09:02.200 --> 1:09:03.800\n are excellent vaccines.\n\n1:09:04.680 --> 1:09:07.920\n But if we leave the third world unvaccinated,\n\n1:09:07.920 --> 1:09:12.720\n we're gonna have a constant supply of variants of COVID\n\n1:09:12.720 --> 1:09:15.760\n that are gonna come back into the United States\n\n1:09:15.760 --> 1:09:20.720\n and harm Americans exactly like Delta and Omicron have.\n\n1:09:20.720 --> 1:09:25.720\n So we've made a great drug, it reduces the risk of mortality\n\n1:09:25.720 --> 1:09:28.400\n in Americans who get it by a lot.\n\n1:09:28.400 --> 1:09:31.080\n But we're not doing what we need to do\n\n1:09:31.080 --> 1:09:33.320\n to protect Americans from Omicron.\n\n1:09:33.320 --> 1:09:34.760\n You don't have to be an idealist\n\n1:09:34.760 --> 1:09:36.960\n and worry about global vaccine equity.\n\n1:09:36.960 --> 1:09:41.280\n If you're just ordinary selfish people like most of us are,\n\n1:09:41.280 --> 1:09:43.600\n and you're worried about the health of Americans,\n\n1:09:43.600 --> 1:09:47.080\n you would ensure global vaccine distribution.\n\n1:09:47.080 --> 1:09:49.120\n Let me just make one more point.\n\n1:09:49.120 --> 1:09:51.760\n That $50 billion that was requested\n\n1:09:51.760 --> 1:09:55.240\n by the four organizations back in May of 2021,\n\n1:09:55.240 --> 1:09:59.320\n 32 billionaires made $50 billion\n\n1:09:59.320 --> 1:10:01.440\n from the vaccines at that point,\n\n1:10:01.440 --> 1:10:03.960\n took it into their private wealth.\n\n1:10:03.960 --> 1:10:05.040\n So what had been taken,\n\n1:10:05.040 --> 1:10:06.920\n this enormous amounts of money that had been taken\n\n1:10:06.920 --> 1:10:10.200\n into private wealth was enough to do\n\n1:10:10.200 --> 1:10:12.840\n what those organizations said needed to be done\n\n1:10:12.840 --> 1:10:15.600\n to prevent the sub variants from coming back\n\n1:10:15.600 --> 1:10:16.640\n and doing what they're doing.\n\n1:10:16.640 --> 1:10:19.080\n So the money was there, but how does the motivation,\n\n1:10:19.080 --> 1:10:22.600\n the money driven motivation of Big Pharma lead to that,\n\n1:10:22.600 --> 1:10:27.600\n that kind of allocation of vaccines?\n\n1:10:28.480 --> 1:10:31.480\n Because they can make more money in the United States.\n\n1:10:31.480 --> 1:10:33.080\n They're gonna distribute their vaccines\n\n1:10:33.080 --> 1:10:34.560\n where they can make the most money.\n\n1:10:34.560 --> 1:10:39.560\n Right, is there a malevolent aspect to this\n\n1:10:40.120 --> 1:10:44.520\n where, boy, I don't like saying this,\n\n1:10:44.520 --> 1:10:49.520\n but that they don't see it as a huge problem\n\n1:10:49.520 --> 1:10:53.200\n that variants will come back to the United States.\n\n1:10:53.200 --> 1:10:56.760\n I think it's the issue we were talking about earlier on\n\n1:10:56.760 --> 1:10:58.560\n where they're in a different culture\n\n1:10:58.560 --> 1:11:02.500\n and their culture is that their moral obligation,\n\n1:11:02.500 --> 1:11:04.600\n as Milton Friedman would say,\n\n1:11:04.600 --> 1:11:06.280\n is to maximize the profits\n\n1:11:06.280 --> 1:11:07.760\n that they return to shareholders.\n\n1:11:07.760 --> 1:11:10.600\n And don't think about the bigger picture.\n\n1:11:10.600 --> 1:11:12.720\n The collateral damage, don't think about the collateral.\n\n1:11:12.720 --> 1:11:16.780\n And also kind of believe, convince yourself\n\n1:11:16.780 --> 1:11:20.160\n that if we give into this capitalist machine\n\n1:11:20.160 --> 1:11:23.160\n in this very narrow sense of capitalism,\n\n1:11:23.160 --> 1:11:25.920\n that in the end, they'll do the most good.\n\n1:11:25.920 --> 1:11:28.560\n This kind of belief that like,\n\n1:11:28.560 --> 1:11:32.640\n if we just maximize profits, we'll do the most good.\n\n1:11:32.640 --> 1:11:36.800\n Yeah, that's an orthodoxy of several decades ago.\n\n1:11:36.800 --> 1:11:40.200\n And I don't think people can really say that in good faith.\n\n1:11:40.200 --> 1:11:43.720\n When you're talking about vaccinating the third world\n\n1:11:43.720 --> 1:11:44.920\n so we don't get hurt,\n\n1:11:44.920 --> 1:11:47.280\n it's a little bit hard to make the argument\n\n1:11:47.280 --> 1:11:48.500\n that the world's a better place\n\n1:11:48.500 --> 1:11:51.080\n because the profits of the investors went up.\n\n1:11:51.080 --> 1:11:52.480\n Yeah, but at the same time,\n\n1:11:54.800 --> 1:11:58.040\n I think that's a belief you can hold.\n\n1:11:58.040 --> 1:12:01.240\n I mean, I've interacted with a bunch of folks that kinda,\n\n1:12:01.240 --> 1:12:05.460\n it's the, I don't wanna mischaracterize Ayn Rand, okay?\n\n1:12:05.460 --> 1:12:07.340\n I respect a lot of people,\n\n1:12:07.340 --> 1:12:10.080\n but there's a belief that can take hold.\n\n1:12:10.080 --> 1:12:13.880\n If I just focus on this particular maximization,\n\n1:12:13.880 --> 1:12:16.000\n it will do the most good for the world.\n\n1:12:16.000 --> 1:12:19.160\n The problem is when you choose what to maximize\n\n1:12:19.160 --> 1:12:20.680\n and you put blinders on,\n\n1:12:20.680 --> 1:12:24.680\n it's too easy to start making gigantic mistakes\n\n1:12:24.680 --> 1:12:28.120\n that have a big negative impact on society.\n\n1:12:28.120 --> 1:12:30.680\n So it's really matters what you're maximizing.\n\n1:12:30.680 --> 1:12:33.680\n Right, and if we had a true democracy\n\n1:12:33.680 --> 1:12:35.260\n and everybody had one vote,\n\n1:12:36.500 --> 1:12:39.560\n everybody got decent information and had one vote,\n\n1:12:39.560 --> 1:12:44.040\n Ayn Rand's position would get some votes, but not many,\n\n1:12:44.040 --> 1:12:47.820\n and it would be way outvoted by the common people.\n\n1:12:48.840 --> 1:12:53.840\n Let me ask you about this very difficult topic.\n\n1:12:53.840 --> 1:12:58.840\n I'm talking to Mark Zuckerberg of Metta,\n\n1:13:00.640 --> 1:13:03.020\n the topic of censorship.\n\n1:13:03.020 --> 1:13:04.760\n I don't know if you've heard,\n\n1:13:04.760 --> 1:13:08.960\n but there's a guy named Robert Malone and Peter McCullough\n\n1:13:08.960 --> 1:13:10.880\n that were removed from many platforms\n\n1:13:10.880 --> 1:13:14.200\n for speaking about the COVID vaccine as being risky.\n\n1:13:14.200 --> 1:13:16.800\n They were both on Joe Rogan's program.\n\n1:13:17.680 --> 1:13:22.460\n What do you think about censorship in this space?\n\n1:13:23.600 --> 1:13:28.600\n In this difficult space where so much is controlled by,\n\n1:13:29.240 --> 1:13:31.580\n not controlled, but influenced by advertisements\n\n1:13:31.580 --> 1:13:32.560\n from Big Pharma,\n\n1:13:32.560 --> 1:13:37.560\n and science can even be influenced by Big Pharma.\n\n1:13:39.300 --> 1:13:41.280\n Where do you lean on this?\n\n1:13:41.280 --> 1:13:46.280\n Should we lean towards freedom\n\n1:13:46.700 --> 1:13:50.140\n and just allow all the voices,\n\n1:13:50.140 --> 1:13:54.540\n even those that go against the scientific consensus?\n\n1:13:54.540 --> 1:13:59.540\n Is that one way to fight the science\n\n1:13:59.540 --> 1:14:02.600\n that is funded by Big Pharma,\n\n1:14:02.600 --> 1:14:05.360\n or is that do more harm than good,\n\n1:14:05.360 --> 1:14:08.440\n having too many voices that are contending here?\n\n1:14:08.440 --> 1:14:10.640\n Should the ultimate battle be fought\n\n1:14:10.640 --> 1:14:15.120\n in the space of scientific publications?\n\n1:14:15.120 --> 1:14:19.360\n And particularly in the era of COVID,\n\n1:14:19.360 --> 1:14:22.600\n where there are large public health ramifications\n\n1:14:22.600 --> 1:14:27.440\n to this public discourse, the ante is way up.\n\n1:14:27.440 --> 1:14:30.000\n So I don't have a simple answer to that.\n\n1:14:31.160 --> 1:14:34.800\n I think everyone's allowed their own opinion.\n\n1:14:34.800 --> 1:14:38.680\n I don't think everyone's allowed their own scientific facts.\n\n1:14:38.680 --> 1:14:42.240\n And how we develop a mechanism\n\n1:14:43.100 --> 1:14:45.360\n that's other than an open internet\n\n1:14:45.360 --> 1:14:49.560\n where whoever is shouting the loudest gets the most clicks\n\n1:14:49.560 --> 1:14:54.240\n and rage creates value on the internet,\n\n1:14:54.240 --> 1:14:58.200\n I think that's not a good mechanism for working this out.\n\n1:14:58.200 --> 1:14:59.800\n And I don't think we have one.\n\n1:14:59.800 --> 1:15:01.800\n I don't have a solution to this.\n\n1:15:01.800 --> 1:15:05.300\n I mean, ideally, if we had a philosopher king,\n\n1:15:05.300 --> 1:15:08.720\n we could have a panel of people\n\n1:15:08.720 --> 1:15:12.760\n who were not conflicted by rigid opinions\n\n1:15:13.880 --> 1:15:18.800\n decide on what the boundaries of public discourse might be.\n\n1:15:19.640 --> 1:15:21.760\n I don't think it should be fully open.\n\n1:15:21.760 --> 1:15:24.380\n I don't think people who are making,\n\n1:15:25.360 --> 1:15:28.300\n who are committed to an anti vaccine position\n\n1:15:28.300 --> 1:15:31.000\n and will tailor their interpretation\n\n1:15:31.000 --> 1:15:34.920\n of complex scientific data to support their opinion,\n\n1:15:34.920 --> 1:15:36.780\n I think that can be harmful.\n\n1:15:36.780 --> 1:15:39.240\n Constraining their speech can be harmful as well.\n\n1:15:39.240 --> 1:15:41.160\n So I don't have an answer here.\n\n1:15:41.160 --> 1:15:42.160\n But yeah.\n\n1:15:42.160 --> 1:15:45.760\n I tend to believe that it's more dangerous\n\n1:15:45.760 --> 1:15:49.320\n to censor anti vax messages.\n\n1:15:49.320 --> 1:15:53.360\n The way to defeat anti vax messages\n\n1:15:53.360 --> 1:15:56.420\n is by being great communicators,\n\n1:15:56.420 --> 1:15:58.320\n by being great scientific communicators.\n\n1:15:58.320 --> 1:16:01.020\n So it's not that we need to censor\n\n1:16:02.060 --> 1:16:04.120\n the things we don't like.\n\n1:16:04.120 --> 1:16:06.720\n We need to be better at communicating\n\n1:16:06.720 --> 1:16:08.240\n the things we do like,\n\n1:16:08.240 --> 1:16:10.760\n or the things that we do believe represent\n\n1:16:10.760 --> 1:16:13.920\n the deep scientific truth.\n\n1:16:13.920 --> 1:16:18.400\n Because I think if you censor,\n\n1:16:18.400 --> 1:16:20.600\n you get worse at doing science\n\n1:16:22.160 --> 1:16:24.860\n and you give the wrong people power.\n\n1:16:27.200 --> 1:16:30.980\n So I tend to believe that you should give power\n\n1:16:30.980 --> 1:16:33.400\n to the individual scientists\n\n1:16:33.400 --> 1:16:35.720\n and also give them the responsibility\n\n1:16:35.720 --> 1:16:38.880\n of being better educators, communicators,\n\n1:16:38.880 --> 1:16:41.680\n expressers of scientific ideas,\n\n1:16:41.680 --> 1:16:43.480\n put pressure on them to release data,\n\n1:16:43.480 --> 1:16:46.800\n to release that data in a way that's easily consumable,\n\n1:16:46.800 --> 1:16:49.220\n not just like very difficult to understand,\n\n1:16:49.220 --> 1:16:50.760\n but in a way that can be understood\n\n1:16:50.760 --> 1:16:52.520\n by a large number of people.\n\n1:16:52.520 --> 1:16:54.740\n So the battle should be fought\n\n1:16:54.740 --> 1:16:57.160\n in the open space of ideas\n\n1:16:57.160 --> 1:17:02.160\n versus in the quiet space of journals.\n\n1:17:02.640 --> 1:17:05.960\n I think we no longer have that comfort,\n\n1:17:05.960 --> 1:17:08.280\n especially at the highest of stakes.\n\n1:17:08.280 --> 1:17:11.600\n So this kind of idea that a couple of peer reviewers\n\n1:17:11.600 --> 1:17:14.280\n decide the fate of billions\n\n1:17:14.280 --> 1:17:18.960\n doesn't seem to be sustainable,\n\n1:17:18.960 --> 1:17:23.960\n especially given a very real observation now\n\n1:17:24.180 --> 1:17:29.180\n that the reason Robert Malone has a large following\n\n1:17:30.840 --> 1:17:33.020\n is there's a deep distrust of institutions,\n\n1:17:33.020 --> 1:17:34.940\n deep distrust of scientists,\n\n1:17:34.940 --> 1:17:37.760\n of science as an institution,\n\n1:17:37.760 --> 1:17:41.400\n of power centers, of companies, of everything,\n\n1:17:41.400 --> 1:17:43.960\n and perhaps rightfully so.\n\n1:17:43.960 --> 1:17:45.520\n But the way to defend against that\n\n1:17:45.520 --> 1:17:49.760\n is not for the powerful to build a bigger wall.\n\n1:17:49.760 --> 1:17:51.720\n It's for the powerful to be authentic\n\n1:17:53.380 --> 1:17:55.760\n and maybe a lot of them to get fired,\n\n1:17:55.760 --> 1:17:58.900\n and for new minds, for new fresh scientists,\n\n1:17:59.840 --> 1:18:01.800\n ones who are more authentic, more real,\n\n1:18:01.800 --> 1:18:03.980\n better communicators to step up.\n\n1:18:03.980 --> 1:18:06.480\n So I fear censorship\n\n1:18:06.480 --> 1:18:09.980\n because it feels like censorship\n\n1:18:09.980 --> 1:18:13.720\n is an even harder job to do it well\n\n1:18:13.720 --> 1:18:16.660\n than being good communicators.\n\n1:18:16.660 --> 1:18:19.160\n And it seems like it's always the C students\n\n1:18:19.160 --> 1:18:21.320\n that end up doing the censorship.\n\n1:18:21.320 --> 1:18:24.960\n It's always the incompetent people,\n\n1:18:24.960 --> 1:18:28.760\n and not just the incompetent, but the biggest whiners.\n\n1:18:28.760 --> 1:18:32.960\n So what happens is the people\n\n1:18:32.960 --> 1:18:36.560\n that get the most emotional and the most outraged\n\n1:18:36.560 --> 1:18:38.220\n will drive the censorship.\n\n1:18:39.520 --> 1:18:42.560\n And it doesn't seem like reason drives the censorship.\n\n1:18:42.560 --> 1:18:44.840\n That's just objectively observing\n\n1:18:44.840 --> 1:18:47.960\n how censorship seems to work in this current.\n\n1:18:47.960 --> 1:18:50.760\n So there's so many forms of censorship.\n\n1:18:50.760 --> 1:18:51.960\n You look at the Soviet Union\n\n1:18:51.960 --> 1:18:54.040\n or the propaganda or Nazi Germany,\n\n1:18:54.040 --> 1:18:56.520\n it's a very different level of censorship.\n\n1:18:56.520 --> 1:18:59.360\n People tend to conflate all of these things together.\n\n1:18:59.360 --> 1:19:03.720\n Social media trying desperately to have trillions\n\n1:19:03.720 --> 1:19:07.280\n or hundreds of billions of exchanges a day,\n\n1:19:07.280 --> 1:19:10.640\n and try to make sure that their platform\n\n1:19:10.640 --> 1:19:15.640\n has some semblance of, quote, healthy conversations.\n\n1:19:16.980 --> 1:19:18.560\n People just don't go insane.\n\n1:19:18.560 --> 1:19:20.840\n They actually like using the platform,\n\n1:19:20.840 --> 1:19:23.420\n and they censor based on that.\n\n1:19:23.420 --> 1:19:24.920\n That's a different level of censorship.\n\n1:19:24.920 --> 1:19:28.040\n But even there, you can really run afoul\n\n1:19:28.040 --> 1:19:32.440\n of the people that get the whiny C students\n\n1:19:32.440 --> 1:19:34.880\n controlling too much of the censorship.\n\n1:19:34.880 --> 1:19:39.480\n I believe you should actually put the responsibility\n\n1:19:39.480 --> 1:19:42.520\n on the self proclaimed holders of truth,\n\n1:19:42.520 --> 1:19:45.640\n AKA scientists, at being better communicators.\n\n1:19:46.760 --> 1:19:47.600\n I agree with that.\n\n1:19:47.600 --> 1:19:51.440\n I'm not advocating for any kind of censorship.\n\n1:19:51.440 --> 1:19:55.600\n But Marshall McLuhan was very influential\n\n1:19:55.600 --> 1:19:57.200\n when I was in college.\n\n1:19:57.200 --> 1:20:02.200\n And his, that meme, the medium is the message.\n\n1:20:03.280 --> 1:20:04.840\n It's a little bit hard to understand\n\n1:20:04.840 --> 1:20:06.800\n when you're comparing radio to TV\n\n1:20:06.800 --> 1:20:09.880\n and saying radio's hotter or TV's hotter or something.\n\n1:20:09.880 --> 1:20:12.480\n But we now have the medium as the message\n\n1:20:12.480 --> 1:20:14.200\n in a way that we've never seen,\n\n1:20:14.200 --> 1:20:16.200\n we've never imagined before,\n\n1:20:16.200 --> 1:20:20.880\n where rage and anger and polarization\n\n1:20:22.800 --> 1:20:27.800\n are what drives the traffic on the internet.\n\n1:20:28.160 --> 1:20:33.160\n And we don't, it's a question of building the commons.\n\n1:20:34.120 --> 1:20:36.000\n Ideally, I don't know how to get there,\n\n1:20:36.000 --> 1:20:38.400\n so I'm not pretending to have a solution.\n\n1:20:38.400 --> 1:20:42.240\n But the commons of discourse about this particular issue,\n\n1:20:42.240 --> 1:20:47.160\n about vaccines, has been largely destroyed by the edges,\n\n1:20:47.160 --> 1:20:50.040\n by the drug companies and the advocates on the one side\n\n1:20:50.040 --> 1:20:54.680\n and the people who just criticize and think\n\n1:20:54.680 --> 1:20:57.720\n that even though the data are flawed\n\n1:20:57.720 --> 1:21:00.960\n that there's no way vaccines can be beneficial.\n\n1:21:00.960 --> 1:21:04.080\n And to have those people screaming at each other\n\n1:21:04.080 --> 1:21:07.200\n does nothing to improve the health\n\n1:21:07.200 --> 1:21:10.680\n of the 95% of the people in the middle\n\n1:21:10.680 --> 1:21:15.680\n who want to know what the rational way to go forward is\n\n1:21:16.480 --> 1:21:18.560\n and protect their families from COVID\n\n1:21:18.560 --> 1:21:20.320\n and live a good life\n\n1:21:20.320 --> 1:21:22.560\n and be able to participate in the economy.\n\n1:21:22.560 --> 1:21:25.200\n And that's the problem.\n\n1:21:25.200 --> 1:21:26.440\n I don't have a solution.\n\n1:21:26.440 --> 1:21:29.520\n Well, there's a difficult problem for Spotify and YouTube.\n\n1:21:29.520 --> 1:21:30.360\n I don't know if you heard,\n\n1:21:30.360 --> 1:21:33.360\n this is a thing that Joe Rogan is currently going through.\n\n1:21:33.360 --> 1:21:36.680\n As a platform, whether to censor the conversation\n\n1:21:36.680 --> 1:21:38.240\n that, for example, Joe's having.\n\n1:21:39.120 --> 1:21:40.080\n So I don't know if you heard,\n\n1:21:40.080 --> 1:21:43.920\n but Neil Young and other musicians have kind of spoke out\n\n1:21:43.920 --> 1:21:45.760\n and saying they're going to leave the platform\n\n1:21:45.760 --> 1:21:49.720\n because Joe Rogan is allowed to be on this platform\n\n1:21:49.720 --> 1:21:51.320\n having these kinds of conversations\n\n1:21:51.320 --> 1:21:52.960\n with the likes of Robert Malone.\n\n1:21:54.680 --> 1:21:57.760\n And it's clear to me that Spotify and YouTube\n\n1:21:57.760 --> 1:21:59.800\n are being significantly influenced\n\n1:21:59.800 --> 1:22:03.400\n by these extreme voices, like you mentioned, on each side.\n\n1:22:03.400 --> 1:22:05.800\n And it's also clear to me that Facebook is the same\n\n1:22:05.800 --> 1:22:07.680\n and it was going back and forth.\n\n1:22:07.680 --> 1:22:10.280\n In fact, that's why Facebook has been oscillating\n\n1:22:10.280 --> 1:22:12.600\n on the censorship is like one group gets louder\n\n1:22:12.600 --> 1:22:16.200\n than the other, depending on whether it's an election year.\n\n1:22:19.880 --> 1:22:21.200\n There's several things to say here.\n\n1:22:21.200 --> 1:22:24.560\n So one, it does seem, I think you put it really well,\n\n1:22:24.560 --> 1:22:26.480\n it would be amazing if these platforms\n\n1:22:26.480 --> 1:22:29.360\n could find mechanisms to listen to the center,\n\n1:22:29.360 --> 1:22:34.360\n to the big center that's actually going to be affected\n\n1:22:34.440 --> 1:22:38.560\n by the results of our pursuit of scientific truth.\n\n1:22:40.520 --> 1:22:42.120\n And listen to those voices.\n\n1:22:42.120 --> 1:22:45.800\n I also believe that most people are intelligent enough\n\n1:22:45.800 --> 1:22:49.360\n to process information and to make up their own minds.\n\n1:22:49.360 --> 1:22:51.680\n Like they're not, in terms of,\n\n1:22:54.120 --> 1:22:55.240\n it's complicated, of course,\n\n1:22:55.240 --> 1:22:57.120\n because we've just been talking about advertisement\n\n1:22:57.120 --> 1:22:58.880\n and how people can be influenced.\n\n1:22:58.880 --> 1:23:03.880\n But I feel like if you have raw, long form podcasts\n\n1:23:05.080 --> 1:23:08.440\n or programs where people express their mind\n\n1:23:08.440 --> 1:23:12.400\n and express their argument in full,\n\n1:23:12.400 --> 1:23:15.400\n I think people can hear it to make up their own mind.\n\n1:23:15.400 --> 1:23:18.080\n And if those arguments have a platform on which\n\n1:23:18.080 --> 1:23:21.160\n they can live, then other people could provide\n\n1:23:21.160 --> 1:23:23.680\n better arguments if they disagree with it.\n\n1:23:23.680 --> 1:23:26.720\n And now we as human beings, as rational,\n\n1:23:26.720 --> 1:23:29.120\n as intelligent human beings, can look at both\n\n1:23:29.120 --> 1:23:30.560\n and make up our own minds.\n\n1:23:30.560 --> 1:23:33.080\n And that's where social media can be very good\n\n1:23:33.080 --> 1:23:35.920\n at this collective intelligence.\n\n1:23:35.920 --> 1:23:39.160\n We together listen to all of these voices\n\n1:23:39.160 --> 1:23:40.640\n and make up our own mind.\n\n1:23:40.640 --> 1:23:42.840\n Humble ourselves, actually, often.\n\n1:23:42.840 --> 1:23:46.680\n You think, you know, like you're an expert,\n\n1:23:46.680 --> 1:23:48.600\n say you have a PhD in a certain thing,\n\n1:23:48.600 --> 1:23:50.920\n so there's this confidence that comes with that.\n\n1:23:50.920 --> 1:23:54.320\n And the collective intelligence, uncensored,\n\n1:23:54.320 --> 1:23:56.880\n allows you to humble yourself eventually.\n\n1:23:56.880 --> 1:24:01.160\n Like as you discover, all it takes is a few times,\n\n1:24:01.160 --> 1:24:05.040\n you know, looking back five years later,\n\n1:24:05.040 --> 1:24:07.240\n realizing I was wrong.\n\n1:24:07.240 --> 1:24:09.040\n And that's really healthy for a scientist.\n\n1:24:09.040 --> 1:24:11.000\n That's really healthy for anybody to go through.\n\n1:24:11.000 --> 1:24:13.880\n And only through having that open discourse\n\n1:24:13.880 --> 1:24:15.920\n can you really have that.\n\n1:24:15.920 --> 1:24:20.920\n That said, Spotify also, just like Pfizer is a company,\n\n1:24:20.920 --> 1:24:25.920\n which is why this podcast,\n\n1:24:26.760 --> 1:24:29.240\n I don't know if you know what RSS feeds are,\n\n1:24:29.240 --> 1:24:31.560\n but podcasts can't be censored.\n\n1:24:31.560 --> 1:24:33.320\n So Joe's in the unfortunate position\n\n1:24:33.320 --> 1:24:35.360\n he only lives on Spotify.\n\n1:24:35.360 --> 1:24:37.920\n So Spotify has been actually very good\n\n1:24:37.920 --> 1:24:40.720\n at saying we're staying out of it for now.\n\n1:24:41.920 --> 1:24:44.840\n But RSS, this is pirate radio.\n\n1:24:44.840 --> 1:24:47.080\n Nobody can censor it, it's the internet.\n\n1:24:47.080 --> 1:24:51.840\n So financially, in terms of platforms,\n\n1:24:51.840 --> 1:24:53.640\n this cannot be censored,\n\n1:24:53.640 --> 1:24:56.760\n which is why podcasts are really beautiful.\n\n1:24:56.760 --> 1:25:01.680\n And so if Spotify or YouTube wants to be\n\n1:25:01.680 --> 1:25:04.240\n the host of podcasts,\n\n1:25:04.240 --> 1:25:09.240\n I think where they flourish is free expression,\n\n1:25:10.880 --> 1:25:12.880\n no matter how crazy.\n\n1:25:12.880 --> 1:25:18.160\n Yes, but I do wanna push back a little bit on what you're saying.\n\n1:25:18.160 --> 1:25:23.080\n I have anti fax friends who I love.\n\n1:25:23.080 --> 1:25:26.120\n They're dear, cherished friends.\n\n1:25:26.120 --> 1:25:28.680\n And they'll send me stuff.\n\n1:25:28.680 --> 1:25:34.200\n And it'll take me an hour to go through what they sent\n\n1:25:34.200 --> 1:25:37.720\n to see if it is credible.\n\n1:25:37.720 --> 1:25:40.520\n And usually it's not.\n\n1:25:40.520 --> 1:25:42.800\n It's not a random sample of the anti fax argument.\n\n1:25:42.800 --> 1:25:46.760\n I'm not saying I can disprove the anti fax argument.\n\n1:25:46.760 --> 1:25:50.960\n But I am saying that it's almost like we were talking about\n\n1:25:50.960 --> 1:25:54.120\n how medical science clinical trials,\n\n1:25:54.120 --> 1:25:56.720\n the presentation of clinical trials to physicians\n\n1:25:56.720 --> 1:25:57.920\n could be improved.\n\n1:25:57.920 --> 1:26:00.520\n And the first thing we came up with\n\n1:26:00.520 --> 1:26:04.360\n is to have pre publication transparency\n\n1:26:04.360 --> 1:26:06.160\n in the peer review process.\n\n1:26:06.160 --> 1:26:10.040\n So bad information, biased information doesn't get out\n\n1:26:10.040 --> 1:26:13.320\n as if it's legitimate, and you can't put it back,\n\n1:26:13.320 --> 1:26:16.120\n recapture it once it gets out.\n\n1:26:16.120 --> 1:26:18.360\n I think there's an element of that\n\n1:26:18.360 --> 1:26:21.920\n in the arguments that are going on about vaccines.\n\n1:26:21.920 --> 1:26:23.160\n And they're on both sides.\n\n1:26:23.160 --> 1:26:28.360\n But I think the anti fax side puts out more units\n\n1:26:28.360 --> 1:26:33.480\n of information claiming to show that the vaccines don't work.\n\n1:26:33.480 --> 1:26:36.480\n And I guess in an ideal situation,\n\n1:26:36.480 --> 1:26:41.120\n there would be real time fact checking by independent people,\n\n1:26:41.120 --> 1:26:45.120\n not to censor it, but to just say that study was set up\n\n1:26:45.120 --> 1:26:47.960\n to do this, and this is what the conclusions were.\n\n1:26:47.960 --> 1:26:52.440\n So the way it was stated is on one side of this argument.\n\n1:26:52.440 --> 1:26:53.800\n But that's what I'm arguing.\n\n1:26:53.800 --> 1:26:55.040\n I agree with you.\n\n1:26:55.040 --> 1:26:58.480\n What I'm arguing is that this big network of humans\n\n1:26:58.480 --> 1:27:00.920\n that we have, that is the collective intelligence,\n\n1:27:00.920 --> 1:27:04.000\n can't do that real time if you allow it to,\n\n1:27:04.000 --> 1:27:05.920\n if you encourage people to do it.\n\n1:27:05.920 --> 1:27:08.200\n And the scientists, as opposed to, listen,\n\n1:27:08.200 --> 1:27:10.400\n I interact with a lot of colleagues,\n\n1:27:10.400 --> 1:27:12.520\n a lot of friends that are scientists,\n\n1:27:12.520 --> 1:27:14.040\n they roll their eyes.\n\n1:27:14.040 --> 1:27:16.480\n Their response is like, ugh.\n\n1:27:16.480 --> 1:27:18.800\n Like they don't want to interact with this.\n\n1:27:18.800 --> 1:27:22.880\n But that's just not the right response.\n\n1:27:22.880 --> 1:27:26.440\n When a huge number of people believe this,\n\n1:27:26.440 --> 1:27:30.040\n it is your job as communicators to defend your ideas.\n\n1:27:30.040 --> 1:27:33.160\n It is no longer the case that you go to a conference\n\n1:27:33.160 --> 1:27:36.440\n and defend your ideas to two other nerds\n\n1:27:36.440 --> 1:27:38.560\n that have been working on the same problem forever.\n\n1:27:38.560 --> 1:27:40.320\n I mean, sure, you can do that,\n\n1:27:40.320 --> 1:27:44.040\n but then you're rejecting the responsibility\n\n1:27:44.040 --> 1:27:48.040\n you have explicitly or implicitly accepted\n\n1:27:48.040 --> 1:27:49.800\n when you go into this field,\n\n1:27:49.800 --> 1:27:52.600\n that you will defend the ideas of truth.\n\n1:27:52.600 --> 1:27:55.840\n And the way to defend them is in the open battlefield\n\n1:27:55.840 --> 1:27:58.920\n of ideas, and become a better communicator.\n\n1:27:58.920 --> 1:28:00.960\n And I believe that when you have a lot,\n\n1:28:00.960 --> 1:28:02.600\n you said you invested one or two hours\n\n1:28:02.600 --> 1:28:06.680\n in this particular, but that's little ants interacting\n\n1:28:06.680 --> 1:28:11.680\n at scale, I think that allows us to progress towards truth.\n\n1:28:12.040 --> 1:28:14.560\n At least, you know, at least I hope so.\n\n1:28:14.560 --> 1:28:15.880\n I think you're an optimist.\n\n1:28:15.880 --> 1:28:17.920\n I want to work with you a little bit on this.\n\n1:28:17.920 --> 1:28:22.480\n Let's say a person like Joe Rogan,\n\n1:28:22.480 --> 1:28:26.040\n who, by the way, had me on his podcast and let me.\n\n1:28:26.040 --> 1:28:28.040\n It's an amazing conversation, I really enjoyed it.\n\n1:28:28.040 --> 1:28:29.040\n Well, thank you.\n\n1:28:29.040 --> 1:28:29.960\n I did too.\n\n1:28:29.960 --> 1:28:31.480\n And I didn't know Joe.\n\n1:28:31.480 --> 1:28:32.840\n I didn't know much about his podcast.\n\n1:28:32.840 --> 1:28:35.440\n He pushed back on Joe a bunch, which is great.\n\n1:28:35.440 --> 1:28:38.440\n And he was a gentleman, and we had it out.\n\n1:28:38.440 --> 1:28:41.240\n In fact, he put one clip, at one point,\n\n1:28:41.240 --> 1:28:43.080\n he said something that was a little bit wrong,\n\n1:28:43.080 --> 1:28:44.240\n and I corrected him.\n\n1:28:44.240 --> 1:28:46.440\n And he had the guy who.\n\n1:28:46.440 --> 1:28:47.280\n Jamie.\n\n1:28:47.280 --> 1:28:48.920\n Jamie, he had Jamie check it,\n\n1:28:48.920 --> 1:28:51.200\n and was very forthright in saying,\n\n1:28:51.200 --> 1:28:53.520\n yeah, you know, John's got a right here.\n\n1:28:53.520 --> 1:28:54.840\n We gotta modify this.\n\n1:28:54.840 --> 1:28:56.560\n In any event, in any event.\n\n1:28:56.560 --> 1:28:58.160\n You got him.\n\n1:28:58.160 --> 1:28:59.960\n Well, I wasn't trying to get him,\n\n1:28:59.960 --> 1:29:01.640\n I was just trying to. No, no, no, no.\n\n1:29:01.640 --> 1:29:03.320\n Totally, it was a beautiful exchange.\n\n1:29:03.320 --> 1:29:04.840\n There was so much respect in the room,\n\n1:29:04.840 --> 1:29:06.360\n pushing back and forth, it was great.\n\n1:29:06.360 --> 1:29:08.960\n Yeah, so I respect him.\n\n1:29:08.960 --> 1:29:13.120\n And I think when he has somebody on\n\n1:29:13.120 --> 1:29:16.680\n who's a dyed in the wool anti faxer,\n\n1:29:16.680 --> 1:29:21.640\n the question is, how can you balance,\n\n1:29:21.640 --> 1:29:24.440\n if it needs balance, in real time?\n\n1:29:24.440 --> 1:29:26.280\n I'm not talking about afterwards.\n\n1:29:26.280 --> 1:29:27.680\n I'm talking in real time.\n\n1:29:27.680 --> 1:29:30.800\n Maybe you record, well, he does record it, obviously.\n\n1:29:30.800 --> 1:29:33.720\n But maybe when there's a statement made\n\n1:29:33.720 --> 1:29:38.000\n that is made as if it's fact based,\n\n1:29:38.000 --> 1:29:41.880\n maybe that statement should be checked by\n\n1:29:41.880 --> 1:29:44.520\n some folks who,\n\n1:29:45.760 --> 1:29:48.080\n imaginary folks who are trustworthy.\n\n1:29:48.080 --> 1:29:51.640\n And in real time, as that discussion\n\n1:29:51.640 --> 1:29:54.200\n is being played on the podcast,\n\n1:29:54.200 --> 1:29:59.080\n to show what independent experts say about that claim.\n\n1:29:59.080 --> 1:30:00.200\n That's a really interesting idea.\n\n1:30:00.200 --> 1:30:01.600\n By the way, for some reason,\n\n1:30:01.600 --> 1:30:03.960\n this idea popped into my head now.\n\n1:30:03.960 --> 1:30:05.560\n I think real time is very difficult,\n\n1:30:05.560 --> 1:30:07.280\n and it's not difficult,\n\n1:30:07.280 --> 1:30:09.320\n but it kind of ruins the conversation\n\n1:30:09.320 --> 1:30:11.800\n because you want the idea to breathe.\n\n1:30:11.800 --> 1:30:15.160\n I think what's very possible is before it's published,\n\n1:30:15.160 --> 1:30:18.400\n it's the pre publication, before it's published,\n\n1:30:18.400 --> 1:30:20.360\n you let a bunch of people review it,\n\n1:30:20.360 --> 1:30:23.680\n and they can add their voices in post.\n\n1:30:23.680 --> 1:30:27.120\n Before it's published, they can add arguments,\n\n1:30:29.680 --> 1:30:31.480\n arguments against certain parts.\n\n1:30:31.480 --> 1:30:32.880\n That's very interesting to sort of,\n\n1:30:32.880 --> 1:30:37.240\n as one podcast, publish addendums.\n\n1:30:37.240 --> 1:30:40.440\n Publish the peer review together with the publication.\n\n1:30:40.440 --> 1:30:41.720\n That's very interesting.\n\n1:30:43.240 --> 1:30:44.120\n I might actually do that.\n\n1:30:44.120 --> 1:30:45.280\n That's really interesting.\n\n1:30:45.280 --> 1:30:47.120\n Because I've been doing more debates\n\n1:30:47.120 --> 1:30:51.720\n where at the same time have multiple people,\n\n1:30:51.720 --> 1:30:53.480\n which has a different dynamic\n\n1:30:53.480 --> 1:30:56.120\n because both people, I mean,\n\n1:30:56.120 --> 1:30:58.800\n it's really nice to have the time to pause\n\n1:30:58.800 --> 1:31:02.040\n just by yourself to fact check,\n\n1:31:02.040 --> 1:31:04.120\n to look at the study that was mentioned,\n\n1:31:04.120 --> 1:31:05.600\n to understand what's going on.\n\n1:31:05.600 --> 1:31:09.480\n So the peer review process, to have a little bit of time.\n\n1:31:09.480 --> 1:31:10.600\n That's really interesting.\n\n1:31:10.600 --> 1:31:14.360\n I actually would, I'd like to try that.\n\n1:31:14.360 --> 1:31:17.720\n To agree with you on some point in terms of anti vax,\n\n1:31:17.720 --> 1:31:20.640\n I've been fascinated by listening to arguments\n\n1:31:20.640 --> 1:31:23.800\n from this community of folks that's been quite large\n\n1:31:23.800 --> 1:31:25.520\n called the flat earthers,\n\n1:31:25.520 --> 1:31:28.080\n the people that believe the earth is flat.\n\n1:31:28.080 --> 1:31:30.920\n And I don't know if you've ever listened to them\n\n1:31:30.920 --> 1:31:33.760\n or read their arguments,\n\n1:31:33.760 --> 1:31:36.160\n but it's fascinating how consistent\n\n1:31:36.160 --> 1:31:37.800\n and convincing it all sounds\n\n1:31:37.800 --> 1:31:39.600\n when you just kind of take it in.\n\n1:31:39.600 --> 1:31:43.720\n Just like, just take it in like listening normally.\n\n1:31:43.720 --> 1:31:45.360\n It's all very logical.\n\n1:31:46.560 --> 1:31:49.120\n Like if you don't think very,\n\n1:31:49.120 --> 1:31:53.200\n well, no, so the thing is,\n\n1:31:53.200 --> 1:31:57.280\n the reality is at the very basic human level\n\n1:31:57.280 --> 1:32:00.600\n with our limited cognitive capabilities,\n\n1:32:00.600 --> 1:32:03.680\n the earth is pretty flat when you go outside\n\n1:32:03.680 --> 1:32:04.880\n and you look at flat.\n\n1:32:04.880 --> 1:32:08.040\n So like when you use common sense reasoning,\n\n1:32:08.040 --> 1:32:09.960\n it's very easy to play to that,\n\n1:32:09.960 --> 1:32:12.080\n to convince you that the earth is flat.\n\n1:32:12.080 --> 1:32:13.640\n Plus there's powerful organizations\n\n1:32:13.640 --> 1:32:16.280\n that want to manipulate you and so on.\n\n1:32:16.280 --> 1:32:20.920\n But then there's the whole progress of science\n\n1:32:20.920 --> 1:32:22.600\n and physics of the past,\n\n1:32:22.600 --> 1:32:26.120\n but that's difficult to integrate into your thought process.\n\n1:32:26.120 --> 1:32:29.200\n So it's very true that the people\n\n1:32:29.200 --> 1:32:30.720\n should listen to flat earthers\n\n1:32:30.720 --> 1:32:33.400\n because it was very revealing to me\n\n1:32:33.400 --> 1:32:37.920\n how easy it is to be convinced of basically anything\n\n1:32:39.240 --> 1:32:42.440\n by charismatic arguments.\n\n1:32:42.440 --> 1:32:46.920\n And if we're arguing about whether the earth is flat or not,\n\n1:32:46.920 --> 1:32:48.760\n as long as we're not navigating airplanes\n\n1:32:48.760 --> 1:32:49.920\n and doing other kinds of things,\n\n1:32:49.920 --> 1:32:53.800\n trying to get satellites to do transmission,\n\n1:32:53.800 --> 1:32:56.200\n it's not that important what I believe.\n\n1:32:56.200 --> 1:32:59.480\n But if we're arguing about how we approach\n\n1:32:59.480 --> 1:33:02.400\n the worst public health crisis in,\n\n1:33:02.400 --> 1:33:03.320\n I don't know how long,\n\n1:33:03.320 --> 1:33:06.400\n I think we're getting worse than the Spanish flu now.\n\n1:33:06.400 --> 1:33:07.800\n I don't know what the total global deaths\n\n1:33:07.800 --> 1:33:10.120\n with Spanish flu were, but in the United States,\n\n1:33:10.120 --> 1:33:12.440\n we certainly have more deaths than we had from Spanish flu.\n\n1:33:12.440 --> 1:33:14.720\n Plus the economic pain and suffering.\n\n1:33:14.720 --> 1:33:19.640\n Yes, yes, and the damage to the kids in school and so forth.\n\n1:33:19.640 --> 1:33:23.040\n We got a problem and it's not going away, unfortunately.\n\n1:33:23.040 --> 1:33:25.000\n So when we get a problem like that,\n\n1:33:25.000 --> 1:33:28.520\n it's not just an interesting bar room conversation\n\n1:33:28.520 --> 1:33:30.720\n about whether the earth is flat.\n\n1:33:30.720 --> 1:33:32.560\n There are millions of lives involved.\n\n1:33:34.320 --> 1:33:36.480\n Let me ask you yet another question,\n\n1:33:36.480 --> 1:33:40.280\n an issue I raised with Pfizer CO, Albert Burla.\n\n1:33:42.160 --> 1:33:45.400\n It's the question of revolving doors.\n\n1:33:45.400 --> 1:33:47.440\n That there seems to be a revolving door\n\n1:33:47.440 --> 1:33:51.120\n between Pfizer, FDA, and CDC.\n\n1:33:51.120 --> 1:33:53.280\n People that have worked at the FDA,\n\n1:33:53.280 --> 1:33:56.480\n now work at Pfizer, and vice versa,\n\n1:33:56.480 --> 1:33:58.660\n including the CDC and so on.\n\n1:34:00.760 --> 1:34:01.760\n What do you think about that?\n\n1:34:01.760 --> 1:34:03.920\n So first of all, his response, once again,\n\n1:34:03.920 --> 1:34:06.400\n is there's rules, there's very strict rules,\n\n1:34:06.400 --> 1:34:07.480\n and we follow them.\n\n1:34:08.680 --> 1:34:10.280\n Do you think that's a problem?\n\n1:34:11.140 --> 1:34:11.980\n Hoo ha.\n\n1:34:12.960 --> 1:34:16.200\n And also, maybe this is a good time to talk about\n\n1:34:16.200 --> 1:34:18.220\n this Pfizer play by the rules.\n\n1:34:19.480 --> 1:34:20.320\n One at a time?\n\n1:34:20.320 --> 1:34:21.160\n One at a time.\n\n1:34:21.160 --> 1:34:22.720\n Okay, and this isn't even about Pfizer,\n\n1:34:22.720 --> 1:34:24.280\n but it's an answer to the question.\n\n1:34:24.280 --> 1:34:25.120\n Yes.\n\n1:34:25.120 --> 1:34:27.480\n So there's this drug, Ajihelm,\n\n1:34:27.480 --> 1:34:31.320\n that was approved by the FDA maybe six months ago.\n\n1:34:31.320 --> 1:34:34.920\n It's a drug to prevent the progression\n\n1:34:34.920 --> 1:34:37.120\n of low grade Alzheimer's disease.\n\n1:34:38.320 --> 1:34:43.320\n The target for drug development for Alzheimer's disease\n\n1:34:43.600 --> 1:34:47.960\n has been reducing the amyloid plaques in the brain,\n\n1:34:47.960 --> 1:34:52.100\n which correlate with the progression of Alzheimer's.\n\n1:34:52.100 --> 1:34:57.100\n And Biogen showed that its drug, Ajihelm,\n\n1:34:57.760 --> 1:35:00.980\n reduces amyloid plaques in the brain.\n\n1:35:00.980 --> 1:35:03.020\n They did two clinical trials\n\n1:35:03.020 --> 1:35:05.600\n to determine the clinical efficacy,\n\n1:35:05.600 --> 1:35:09.960\n and they found that neither trial showed a meaningful benefit.\n\n1:35:09.960 --> 1:35:12.180\n And in those two trials,\n\n1:35:12.180 --> 1:35:15.960\n 33% more people in the Ajihelm group\n\n1:35:15.960 --> 1:35:19.060\n developed symptomatic brain swelling and bleeding\n\n1:35:19.060 --> 1:35:20.820\n than people in the placebo group.\n\n1:35:22.080 --> 1:35:25.940\n There was an advisory committee convened\n\n1:35:27.080 --> 1:35:30.400\n to debate and determine how they felt\n\n1:35:30.400 --> 1:35:34.200\n about the approvability of Ajihelm, given those facts.\n\n1:35:35.080 --> 1:35:37.120\n And those facts aren't in dispute.\n\n1:35:37.120 --> 1:35:41.540\n They're in Biogen slides, as well as FDA documents.\n\n1:35:41.540 --> 1:35:46.540\n The advisory committee voted 10 against approval\n\n1:35:47.600 --> 1:35:49.920\n and one abstain.\n\n1:35:49.920 --> 1:35:52.600\n So that's essentially universal,\n\n1:35:52.600 --> 1:35:56.240\n unanimous vote against approving Ajihelm.\n\n1:35:56.240 --> 1:36:00.680\n Now, the advisory committees have been pretty much cleansed\n\n1:36:00.680 --> 1:36:03.240\n of financial conflicts of interest.\n\n1:36:03.240 --> 1:36:08.240\n So this advisory committee votes 10 no, one abstention,\n\n1:36:09.240 --> 1:36:13.160\n and the FDA overrules the unanimous opinion\n\n1:36:13.160 --> 1:36:16.140\n of its advisory committee and approves the drug.\n\n1:36:17.400 --> 1:36:21.320\n Three of the members of the advisory committee resign.\n\n1:36:21.320 --> 1:36:22.320\n They say, we're not gonna be part,\n\n1:36:22.320 --> 1:36:24.760\n if the FDA is not gonna listen to a unanimous vote\n\n1:36:24.760 --> 1:36:26.720\n against approving this drug,\n\n1:36:26.720 --> 1:36:30.540\n which shows more harm than benefit, undisputed,\n\n1:36:31.560 --> 1:36:33.840\n we're not gonna participate in this.\n\n1:36:33.840 --> 1:36:36.680\n And the argument against approval\n\n1:36:36.680 --> 1:36:38.960\n is that the surrogate endpoint,\n\n1:36:38.960 --> 1:36:43.360\n the reduction of amyloid, the progression of amyloid plaques\n\n1:36:43.360 --> 1:36:48.020\n is known by the FDA not to be a valid clinical indicator.\n\n1:36:48.020 --> 1:36:50.920\n It doesn't correlate, 27 studies have shown,\n\n1:36:50.920 --> 1:36:53.340\n it doesn't correlate with clinical progression,\n\n1:36:53.340 --> 1:36:54.840\n interrupting the amyloid plaques\n\n1:36:54.840 --> 1:36:59.840\n doesn't mean that your Alzheimer's doesn't get worse.\n\n1:37:02.000 --> 1:37:05.200\n So it seems like it's a slam dunk\n\n1:37:05.200 --> 1:37:09.000\n and the FDA made a mistake and they should do whatever\n\n1:37:09.000 --> 1:37:12.080\n they do to protect their bureaucratic reputation.\n\n1:37:12.080 --> 1:37:15.280\n So the head of the Bureau of the FDA,\n\n1:37:15.280 --> 1:37:17.320\n the Center for Drug Evaluation and Research\n\n1:37:17.320 --> 1:37:21.880\n that approves new drugs, who had spent 16 years\n\n1:37:21.880 --> 1:37:25.300\n as an executive in the pharmaceutical industry,\n\n1:37:25.300 --> 1:37:28.000\n issued a statement and said,\n\n1:37:28.000 --> 1:37:30.920\n \"'What we should do in this situation\n\n1:37:30.920 --> 1:37:35.920\n \"'is to loosen the prohibition of financial ties of interest\n\n1:37:36.820 --> 1:37:38.540\n \"'with the drug companies,\n\n1:37:38.540 --> 1:37:41.400\n \"'so we get less emotional responses.'\"\n\n1:37:43.400 --> 1:37:46.160\n Said this, it's in print.\n\n1:37:49.400 --> 1:37:51.520\n People are just too emotional about this.\n\n1:37:51.520 --> 1:37:52.960\n People were just too emotional.\n\n1:37:52.960 --> 1:37:55.060\n The 10 people who voted against it\n\n1:37:55.060 --> 1:37:56.720\n and the no people who voted for it,\n\n1:37:56.720 --> 1:37:58.480\n it's all too emotional.\n\n1:37:58.480 --> 1:38:00.000\n So this gets back,\n\n1:38:00.000 --> 1:38:02.560\n this is a long answer to your short question.\n\n1:38:02.560 --> 1:38:04.880\n I think this is a wonderful window\n\n1:38:04.880 --> 1:38:07.120\n into the thinking of the FDA\n\n1:38:08.000 --> 1:38:11.160\n that financial conflicts of interest don't matter\n\n1:38:11.160 --> 1:38:13.280\n in a situation when I think it's obvious\n\n1:38:13.280 --> 1:38:15.000\n that they would matter.\n\n1:38:15.000 --> 1:38:18.040\n But there's not a direct financial conflict of interest.\n\n1:38:18.040 --> 1:38:23.040\n It's kinda, like it's not, like Albert said, there's rules.\n\n1:38:26.120 --> 1:38:27.200\n I mean, you're not allowed\n\n1:38:27.200 --> 1:38:29.760\n to have direct financial conflicts of interest.\n\n1:38:29.760 --> 1:38:32.280\n It's indirect.\n\n1:38:32.280 --> 1:38:34.560\n Right, but what I'm saying is,\n\n1:38:34.560 --> 1:38:36.560\n I'm not denying what he said is true,\n\n1:38:37.880 --> 1:38:42.020\n but the FDA, a high official in the FDA,\n\n1:38:42.020 --> 1:38:45.480\n is saying that we need to allow conflicts of interest\n\n1:38:45.480 --> 1:38:48.320\n in our advisory committee meetings.\n\n1:38:48.320 --> 1:38:49.280\n Wow.\n\n1:38:49.280 --> 1:38:53.320\n And that, she wants to change the rules.\n\n1:38:53.320 --> 1:38:54.160\n Right.\n\n1:38:54.160 --> 1:38:58.040\n So Albert Borla would still be playing by the rules,\n\n1:38:58.040 --> 1:39:03.040\n but it just shows how one side of the thinking here is.\n\n1:39:03.380 --> 1:39:05.280\n But you think that's influenced by the fact\n\n1:39:05.280 --> 1:39:07.360\n that there were pharmaceutical executives\n\n1:39:07.360 --> 1:39:09.920\n working at the FDA and vice versa?\n\n1:39:09.920 --> 1:39:11.720\n And they think that's a great idea.\n\n1:39:13.120 --> 1:39:14.520\n Who gets to fix this?\n\n1:39:14.520 --> 1:39:16.480\n Do you think it should be just banned?\n\n1:39:16.480 --> 1:39:17.320\n Like if you worked.\n\n1:39:17.320 --> 1:39:19.040\n I don't know, two separate questions.\n\n1:39:19.040 --> 1:39:23.640\n One is should the officials at the FDA come from pharma\n\n1:39:23.640 --> 1:39:24.800\n and vice versa?\n\n1:39:24.800 --> 1:39:25.640\n Yes.\n\n1:39:25.640 --> 1:39:26.460\n That's one question.\n\n1:39:26.460 --> 1:39:28.960\n And the other question is should advisory committee members\n\n1:39:28.960 --> 1:39:31.680\n be allowed to have financial conflicts of interest?\n\n1:39:31.680 --> 1:39:33.120\n Yes.\n\n1:39:33.120 --> 1:39:38.120\n I think, in my opinion, and people might say I'm biased,\n\n1:39:38.240 --> 1:39:40.320\n I think advisory committee people\n\n1:39:40.320 --> 1:39:42.080\n should not have conflicts of interest.\n\n1:39:42.080 --> 1:39:44.880\n I think their only interest ought to be the public interest.\n\n1:39:44.880 --> 1:39:49.240\n And that was true from my understanding of the situation.\n\n1:39:49.240 --> 1:39:51.280\n It's the afterword in my book.\n\n1:39:51.280 --> 1:39:54.200\n I spent some time studying it about Ajihelm.\n\n1:39:54.200 --> 1:39:56.520\n I think it's a slam dunk that there ought to be\n\n1:39:56.520 --> 1:39:57.660\n no conflicts of interest.\n\n1:39:57.660 --> 1:40:01.400\n Now the head of CDER, Center for Drug Evaluation Research,\n\n1:40:01.400 --> 1:40:04.660\n thinks that that's gonna give you a biased result\n\n1:40:04.660 --> 1:40:07.380\n because we don't have company influence.\n\n1:40:07.380 --> 1:40:12.380\n And that, I think, shows how biased their thinking is.\n\n1:40:14.360 --> 1:40:17.340\n That not having company influence is a bias.\n\n1:40:19.200 --> 1:40:21.200\n Let me try to load that in.\n\n1:40:21.200 --> 1:40:23.320\n I'm trying to empathize with the belief\n\n1:40:23.320 --> 1:40:26.760\n that companies should have a voice at the table.\n\n1:40:28.680 --> 1:40:30.440\n I mean, yeah, it's part of the game.\n\n1:40:30.440 --> 1:40:31.400\n They've convinced themselves\n\n1:40:31.400 --> 1:40:33.240\n that this is how it should be played.\n\n1:40:34.520 --> 1:40:36.320\n But they have a voice at the table.\n\n1:40:36.320 --> 1:40:37.720\n They've designed the studies.\n\n1:40:37.720 --> 1:40:38.560\n Right.\n\n1:40:38.560 --> 1:40:39.400\n That's their voice.\n\n1:40:39.400 --> 1:40:40.220\n That's the whole point.\n\n1:40:40.220 --> 1:40:41.060\n They analyze the data.\n\n1:40:41.060 --> 1:40:43.080\n I mean, what bigger voice do you deserve?\n\n1:40:43.080 --> 1:40:47.040\n But I do also think, on the more challenging question,\n\n1:40:47.040 --> 1:40:50.180\n I do think that there should be a ban.\n\n1:40:50.180 --> 1:40:53.600\n If you work at a pharmaceutical company,\n\n1:40:53.600 --> 1:40:55.400\n you should not be allowed to work\n\n1:40:55.400 --> 1:41:00.400\n at any regulatory agency.\n\n1:41:00.680 --> 1:41:01.520\n Yes.\n\n1:41:01.520 --> 1:41:02.340\n You should not.\n\n1:41:02.340 --> 1:41:03.960\n I mean, that, going back and forth,\n\n1:41:03.960 --> 1:41:06.680\n it just, even if it's 30 years later.\n\n1:41:06.680 --> 1:41:07.520\n Yeah, I agree.\n\n1:41:07.520 --> 1:41:11.000\n And I have another nomination for a ban.\n\n1:41:11.000 --> 1:41:12.960\n We're in this crazy situation\n\n1:41:12.960 --> 1:41:15.120\n where Medicare is not allowed to negotiate\n\n1:41:15.120 --> 1:41:17.800\n the price of drugs with the drug companies.\n\n1:41:17.800 --> 1:41:20.840\n So the drug companies get a patent on a new drug.\n\n1:41:20.840 --> 1:41:22.440\n Unlike every other developed country,\n\n1:41:22.440 --> 1:41:24.020\n they can charge whatever they want\n\n1:41:24.020 --> 1:41:27.800\n so they have a monopoly on a utility\n\n1:41:27.800 --> 1:41:29.560\n because no one else can make the drug.\n\n1:41:29.560 --> 1:41:31.960\n Charge whatever they want and Medicare has to pay for it.\n\n1:41:31.960 --> 1:41:35.640\n And you say, how did we get in this crazy situation?\n\n1:41:36.760 --> 1:41:39.600\n So how we got here is that in 2003,\n\n1:41:39.600 --> 1:41:42.020\n when Medicare Part D was passed,\n\n1:41:42.020 --> 1:41:45.680\n Billy Towson was head of the Ways and Means Committee\n\n1:41:45.680 --> 1:41:48.960\n in the House, played a key role in ushering this through\n\n1:41:48.960 --> 1:41:52.440\n with the nonnegotiation clause of it.\n\n1:41:52.440 --> 1:41:53.960\n And after it was passed,\n\n1:41:53.960 --> 1:41:57.480\n Billy Towson did not finish out his term in Congress.\n\n1:41:57.480 --> 1:42:02.160\n He went to pharma for a $2 million a year job.\n\n1:42:02.160 --> 1:42:05.160\n This is incredible.\n\n1:42:05.160 --> 1:42:08.000\n You might think that a ban on that would be a good idea.\n\n1:42:09.480 --> 1:42:12.080\n I spoke with Francis Collins, head of the NIH,\n\n1:42:12.080 --> 1:42:13.680\n on this podcast.\n\n1:42:13.680 --> 1:42:18.680\n He and NIH have a lot of power over funding in science.\n\n1:42:22.120 --> 1:42:24.840\n What are they doing right, what are they doing wrong\n\n1:42:24.840 --> 1:42:28.760\n in this interplay with big pharma?\n\n1:42:28.760 --> 1:42:30.440\n How connected are they?\n\n1:42:32.160 --> 1:42:33.720\n Again, returning to the question,\n\n1:42:33.720 --> 1:42:35.500\n what are they doing right,\n\n1:42:35.500 --> 1:42:37.680\n what are they doing wrong in your view?\n\n1:42:37.680 --> 1:42:41.160\n So my knowledge of the NIH is not as granular\n\n1:42:41.160 --> 1:42:43.260\n as my knowledge of pharma.\n\n1:42:44.480 --> 1:42:47.520\n That said, in broad brushstrokes,\n\n1:42:47.520 --> 1:42:51.180\n the NIH is doing the infrastructure work\n\n1:42:51.180 --> 1:42:53.400\n for all drug development.\n\n1:42:53.400 --> 1:42:56.700\n I think they've participated in 100% of the drugs\n\n1:42:56.700 --> 1:42:58.920\n that have been approved by the FDA\n\n1:42:58.920 --> 1:43:00.600\n over the past 10 years or so.\n\n1:43:01.480 --> 1:43:03.080\n They've done infrastructure work.\n\n1:43:03.080 --> 1:43:08.080\n And what they do is not work on particular drugs,\n\n1:43:08.160 --> 1:43:12.360\n but they develop work on drug targets,\n\n1:43:12.360 --> 1:43:16.920\n on targets in the human body that can be affected by drugs\n\n1:43:16.920 --> 1:43:21.560\n and might be beneficial to turn on or off.\n\n1:43:21.560 --> 1:43:24.560\n And then the drug companies, when they find a target\n\n1:43:24.560 --> 1:43:29.360\n that is mutable and potentially beneficial,\n\n1:43:29.360 --> 1:43:32.020\n then the drug companies can take the research\n\n1:43:32.020 --> 1:43:34.640\n and choose to invest in the development of the drugs,\n\n1:43:34.640 --> 1:43:35.640\n specific drug.\n\n1:43:36.740 --> 1:43:38.360\n That's our model.\n\n1:43:38.360 --> 1:43:43.360\n Now, 96% of the research that's done in clinical trials\n\n1:43:44.160 --> 1:43:47.280\n in the United States is about drugs and devices.\n\n1:43:47.280 --> 1:43:49.960\n And only a fraction of the 4% that's left over\n\n1:43:49.960 --> 1:43:51.780\n is about preventive medicine\n\n1:43:51.780 --> 1:43:54.480\n and how to make Americans healthier.\n\n1:43:54.480 --> 1:43:58.520\n I think, again, from the satellite view,\n\n1:43:58.520 --> 1:44:03.520\n the NIH is investing more in science\n\n1:44:04.260 --> 1:44:07.280\n that can lead to commercial development\n\n1:44:07.280 --> 1:44:10.160\n rather than, as you said at the beginning of the podcast,\n\n1:44:10.160 --> 1:44:13.480\n there's no big fitness and lifestyle industry\n\n1:44:13.480 --> 1:44:15.980\n that can counter pharma.\n\n1:44:15.980 --> 1:44:19.700\n So I think at the NIH level, that countering can be done.\n\n1:44:19.700 --> 1:44:22.560\n And the diabetes prevention program study\n\n1:44:22.560 --> 1:44:24.920\n that we talked about before where lifestyle\n\n1:44:24.920 --> 1:44:26.500\n was part of a randomized trial\n\n1:44:26.500 --> 1:44:28.940\n and was shown to be more effective than metformin\n\n1:44:28.940 --> 1:44:31.000\n at preventing the development of diabetes,\n\n1:44:31.000 --> 1:44:34.460\n that is absolute proof positive\n\n1:44:34.460 --> 1:44:36.140\n that investing in that kind of science\n\n1:44:36.140 --> 1:44:37.900\n can produce good results.\n\n1:44:37.900 --> 1:44:42.900\n So I think that we're aimed at drug development\n\n1:44:43.100 --> 1:44:44.880\n and what we ought to be aimed at\n\n1:44:44.880 --> 1:44:47.700\n is an epidemiological approach\n\n1:44:47.700 --> 1:44:49.900\n to improving the health of all Americans.\n\n1:44:49.900 --> 1:44:54.040\n We rank 68th in the world in healthy life expectancy\n\n1:44:55.060 --> 1:44:58.100\n despite spending an extra trillion and a half dollars a year.\n\n1:44:59.000 --> 1:45:02.560\n And I believe strongly\n\n1:45:02.560 --> 1:45:05.920\n that the reason why we've gotten in this crazy position\n\n1:45:06.880 --> 1:45:10.280\n is because the knowledge that we're producing\n\n1:45:10.280 --> 1:45:12.480\n is about new drugs and devices\n\n1:45:12.480 --> 1:45:15.780\n and it's not about improving population health.\n\n1:45:15.780 --> 1:45:19.680\n In this problem, the NIH is the perfect institution\n\n1:45:19.680 --> 1:45:23.160\n to play a role in rebalancing our research agenda.\n\n1:45:23.160 --> 1:45:24.940\n And some of that is on the leadership side\n\n1:45:24.940 --> 1:45:27.920\n with Francis Collins and Anthony Fauci,\n\n1:45:27.920 --> 1:45:32.460\n not just speaking about basically everything\n\n1:45:32.460 --> 1:45:34.760\n that just leads to drug development, vaccine development,\n\n1:45:34.760 --> 1:45:36.760\n but also speaking about healthy lifestyles\n\n1:45:36.760 --> 1:45:40.800\n and speaking about health, not just sickness.\n\n1:45:40.800 --> 1:45:43.200\n Yes, and investing, investing in health.\n\n1:45:43.200 --> 1:45:48.200\n I mean, it's like one feeds the other.\n\n1:45:49.000 --> 1:45:51.200\n One, you have to communicate to the public\n\n1:45:51.200 --> 1:45:53.880\n the importance of investing in health\n\n1:45:53.880 --> 1:45:57.840\n and that leads to you getting props for investing in health\n\n1:45:57.840 --> 1:45:59.520\n and then you can invest in health more and more\n\n1:45:59.520 --> 1:46:01.680\n and that communicates, I mean,\n\n1:46:01.680 --> 1:46:05.120\n everything that Anthony Fauci says or Francis Collins says\n\n1:46:05.120 --> 1:46:07.240\n has an impact on scientists.\n\n1:46:07.240 --> 1:46:12.120\n I mean, it sets the priorities.\n\n1:46:12.120 --> 1:46:15.940\n I don't think they, it's the sad thing about leaders,\n\n1:46:18.680 --> 1:46:22.080\n forgive me for saying the word, but mediocre leaders\n\n1:46:22.080 --> 1:46:26.800\n is they don't see themselves as part of a game.\n\n1:46:26.800 --> 1:46:29.920\n They don't see the momentum.\n\n1:46:29.920 --> 1:46:31.160\n It's like a fish in the water.\n\n1:46:31.160 --> 1:46:32.920\n They don't see the water.\n\n1:46:32.920 --> 1:46:36.080\n Great leaders stand up and reverse the direction\n\n1:46:36.080 --> 1:46:37.120\n of how things are going.\n\n1:46:37.120 --> 1:46:39.920\n And I actually put a lot of responsibility,\n\n1:46:39.920 --> 1:46:43.520\n some people say too much, but whatever.\n\n1:46:43.520 --> 1:46:46.440\n I think leaders carry the responsibility.\n\n1:46:46.440 --> 1:46:48.800\n I put a lot of responsibility on Anthony Fauci\n\n1:46:48.800 --> 1:46:51.360\n and Francis Collins for not actually speaking\n\n1:46:51.360 --> 1:46:55.920\n a lot more about health, not, and bigger,\n\n1:46:55.920 --> 1:47:00.920\n inspiring people in the power\n\n1:47:01.200 --> 1:47:05.560\n and the trustworthiness of science.\n\n1:47:05.560 --> 1:47:10.560\n You know, that's on the shoulders of Anthony Fauci.\n\n1:47:12.240 --> 1:47:13.760\n I'm gonna abstain from that\n\n1:47:13.760 --> 1:47:15.800\n because I'm not expert enough, but.\n\n1:47:15.800 --> 1:47:18.040\n Neither am I, but I'm opinionated.\n\n1:47:18.040 --> 1:47:21.080\n I am too, but not on camera.\n\n1:47:21.080 --> 1:47:22.520\n Yes.\n\n1:47:22.520 --> 1:47:27.200\n No, but seriously, the problem is pretty simple,\n\n1:47:27.200 --> 1:47:31.400\n that we're investing 96% of our funding\n\n1:47:31.400 --> 1:47:33.520\n of clinical research in drugs and devices\n\n1:47:33.520 --> 1:47:36.800\n and 80% of our health is determined\n\n1:47:36.800 --> 1:47:38.120\n by how we live our lives.\n\n1:47:38.120 --> 1:47:39.160\n Yes.\n\n1:47:39.160 --> 1:47:41.720\n And this is ridiculous.\n\n1:47:42.600 --> 1:47:45.600\n The United States is going further and further\n\n1:47:45.600 --> 1:47:49.760\n behind the other wealthy countries in terms of our health.\n\n1:47:49.760 --> 1:47:53.560\n We ranked 38th in healthy life expectancy in 2000\n\n1:47:53.560 --> 1:47:56.960\n and now we're spending a trillion and a half dollars extra\n\n1:47:56.960 --> 1:47:58.360\n and we rank 68th.\n\n1:47:58.360 --> 1:47:59.520\n We've gone down.\n\n1:47:59.520 --> 1:48:02.400\n You have this excellent, there's a few charts\n\n1:48:02.400 --> 1:48:06.440\n that I'll overlay that tell this story\n\n1:48:06.440 --> 1:48:09.720\n in really powerful ways.\n\n1:48:09.720 --> 1:48:13.600\n So one is the healthcare spending is percentage of GDP\n\n1:48:13.600 --> 1:48:17.680\n that on the X axis is years and the Y axis is percentage\n\n1:48:17.680 --> 1:48:20.800\n and the United States as compared to other countries\n\n1:48:20.800 --> 1:48:25.800\n on average has been much larger and growing.\n\n1:48:26.440 --> 1:48:30.520\n Right, we are now spending 7% more of our GDP,\n\n1:48:30.520 --> 1:48:35.200\n 17.7% versus 10.7% on healthcare.\n\n1:48:35.200 --> 1:48:38.840\n 7% and I think GDP is the fairest way\n\n1:48:38.840 --> 1:48:40.080\n to compare healthcare spending.\n\n1:48:40.080 --> 1:48:43.480\n Where per person in dollars we're spending even,\n\n1:48:43.480 --> 1:48:45.560\n the difference is even greater\n\n1:48:45.560 --> 1:48:48.200\n but other costs vary with GDP.\n\n1:48:48.200 --> 1:48:50.800\n So let's stick with the conservative way to do it.\n\n1:48:50.800 --> 1:49:00.760\n 17.7 or 18% of GDP, 18% of GDP spent on healthcare,\n\n1:49:00.760 --> 1:49:04.800\n 7% higher than the comparable country average.\n\n1:49:04.800 --> 1:49:05.640\n Right.\n\n1:49:05.640 --> 1:49:09.960\n 17.7% versus 10.7, 7% higher.\n\n1:49:09.960 --> 1:49:14.960\n Right and 7% of $23 trillion GDP\n\n1:49:15.160 --> 1:49:19.040\n is more than $1.5 trillion a year in excess.\n\n1:49:19.040 --> 1:49:21.000\n And then you have another chart that shows\n\n1:49:21.000 --> 1:49:24.840\n healthcare system performance compared to spending.\n\n1:49:25.840 --> 1:49:29.800\n And there's a cloud, a point cloud of different countries.\n\n1:49:29.800 --> 1:49:33.160\n The X axis being healthcare spending\n\n1:49:33.160 --> 1:49:36.360\n is a percentage of GDP which we just talked about.\n\n1:49:36.360 --> 1:49:40.880\n That US is 7% higher than everyone, the average.\n\n1:49:40.880 --> 1:49:44.520\n And then on the Y axis is performance.\n\n1:49:44.520 --> 1:49:48.280\n So X axis spending, Y axis performance.\n\n1:49:48.280 --> 1:49:50.600\n And there's a point cloud, we'll overlay this\n\n1:49:50.600 --> 1:49:52.400\n if you're watching on YouTube,\n\n1:49:52.400 --> 1:49:57.000\n of a bunch of countries that have high performance\n\n1:49:58.600 --> 1:50:01.320\n for what they're spending and then US\n\n1:50:02.640 --> 1:50:07.480\n is all alone on the right bottom side of the chart\n\n1:50:07.480 --> 1:50:10.760\n where it's low performance and high spending.\n\n1:50:10.760 --> 1:50:11.600\n Correct.\n\n1:50:12.880 --> 1:50:17.960\n So this is a system that is abiding by spending\n\n1:50:17.960 --> 1:50:21.160\n that is directed by the most profitable ways\n\n1:50:21.160 --> 1:50:22.480\n to deliver healthcare.\n\n1:50:22.480 --> 1:50:25.040\n So you put that in the hands of big pharma.\n\n1:50:25.040 --> 1:50:28.400\n As you maximize for profit, you're going to decrease\n\n1:50:28.400 --> 1:50:31.600\n performance and increase spending.\n\n1:50:31.600 --> 1:50:34.800\n Yes, but I wanna qualify that and say\n\n1:50:34.800 --> 1:50:36.360\n it's not all big pharma's fault.\n\n1:50:37.440 --> 1:50:39.320\n They're not responsible for all the problems\n\n1:50:39.320 --> 1:50:41.200\n in our healthcare system.\n\n1:50:41.200 --> 1:50:43.160\n They're not responsible for the administrative costs\n\n1:50:43.160 --> 1:50:44.520\n for example.\n\n1:50:44.520 --> 1:50:49.400\n But they are the largest component of the rising,\n\n1:50:49.400 --> 1:50:51.320\n our rising healthcare costs.\n\n1:50:51.320 --> 1:50:54.160\n And it has to do with this knowledge issue.\n\n1:50:54.160 --> 1:50:56.760\n Controlling the knowledge that doctors have\n\n1:50:57.640 --> 1:51:01.240\n makes it so that doctors can live with this situation\n\n1:51:01.240 --> 1:51:04.880\n believing that it's optimal when it's a wreck.\n\n1:51:04.880 --> 1:51:06.160\n Yeah.\n\n1:51:06.160 --> 1:51:08.680\n Let me ask you the big, so as a physician,\n\n1:51:10.160 --> 1:51:13.680\n so everything you've seen, we've talked about 80%\n\n1:51:13.680 --> 1:51:15.960\n of the impact on health is lifestyle.\n\n1:51:18.480 --> 1:51:20.200\n How do we live longer?\n\n1:51:20.200 --> 1:51:22.120\n What advice would you give to general people?\n\n1:51:22.120 --> 1:51:27.120\n What space of ideas result in living longer\n\n1:51:29.080 --> 1:51:30.720\n and higher quality lives?\n\n1:51:30.720 --> 1:51:33.560\n Right, this is a very simple question to answer.\n\n1:51:34.480 --> 1:51:37.800\n Exercise for at least a half hour\n\n1:51:37.800 --> 1:51:39.360\n at least five times a week.\n\n1:51:41.040 --> 1:51:42.360\n Number one.\n\n1:51:42.360 --> 1:51:44.160\n Number two, don't smoke.\n\n1:51:45.560 --> 1:51:49.320\n Number three, maintain a reasonably healthy body weight.\n\n1:51:49.320 --> 1:51:53.720\n Some people argue that being lower than a BMI of 25\n\n1:51:53.720 --> 1:51:54.800\n is healthy.\n\n1:51:54.800 --> 1:51:56.480\n I think that may be true,\n\n1:51:56.480 --> 1:52:00.440\n but I think getting above 30 is unhealthy\n\n1:52:00.440 --> 1:52:01.920\n and that ought to be.\n\n1:52:01.920 --> 1:52:06.920\n Now that's largely impacted by socioeconomic status\n\n1:52:07.600 --> 1:52:09.920\n and we don't wanna blame the victims here.\n\n1:52:09.920 --> 1:52:12.600\n So we gotta understand that when we talk about\n\n1:52:12.600 --> 1:52:14.920\n all of these things, not cigarettes,\n\n1:52:14.920 --> 1:52:18.360\n but exercise and a good diet\n\n1:52:18.360 --> 1:52:21.320\n and maintaining a healthy body weight,\n\n1:52:23.000 --> 1:52:26.120\n we have to include in doing those things\n\n1:52:27.000 --> 1:52:32.000\n the impediments to people of lower socioeconomic status\n\n1:52:32.480 --> 1:52:34.360\n being able to make those changes.\n\n1:52:34.360 --> 1:52:38.120\n We've got to understand that personal responsibility\n\n1:52:38.120 --> 1:52:39.880\n accounts for some of this,\n\n1:52:39.880 --> 1:52:44.000\n but also social circumstances accounts for some of it.\n\n1:52:44.000 --> 1:52:47.000\n And back to your fish bowl analogy,\n\n1:52:47.000 --> 1:52:50.040\n if you're swimming in a fish bowl,\n\n1:52:50.040 --> 1:52:51.240\n if you live in a fish tank\n\n1:52:51.240 --> 1:52:53.960\n that's not being properly maintained,\n\n1:52:53.960 --> 1:52:58.080\n the approach wouldn't be to treat individual sick fish,\n\n1:52:58.080 --> 1:53:01.560\n it would be to fix your fish tank\n\n1:53:01.560 --> 1:53:03.040\n to get the bacteria out of it\n\n1:53:03.040 --> 1:53:05.720\n and whatever bad stuff is in there\n\n1:53:05.720 --> 1:53:08.440\n and make your fish tank healthier.\n\n1:53:08.440 --> 1:53:12.840\n Well, we invest far less than the other wealthy countries do.\n\n1:53:12.840 --> 1:53:15.120\n We're flipped, we have the mirror image\n\n1:53:15.120 --> 1:53:19.040\n in the spending on social determinants of health\n\n1:53:19.040 --> 1:53:20.840\n and medical determinants of health.\n\n1:53:20.840 --> 1:53:23.120\n We have exactly the wrong order.\n\n1:53:23.120 --> 1:53:25.800\n And not only does that choke off\n\n1:53:25.800 --> 1:53:28.320\n social determinants of health, which are very important,\n\n1:53:28.320 --> 1:53:30.720\n but actually just the ratio,\n\n1:53:30.720 --> 1:53:32.920\n even if you were spending,\n\n1:53:32.920 --> 1:53:35.760\n if we raise the social spending\n\n1:53:35.760 --> 1:53:38.360\n and raise our medical spending in proportion,\n\n1:53:38.360 --> 1:53:41.280\n it's the ratio of social spending to medical spending\n\n1:53:41.280 --> 1:53:42.920\n that's the problem.\n\n1:53:42.920 --> 1:53:44.560\n So, and why do we do that?\n\n1:53:44.560 --> 1:53:46.440\n Well, the answer is perfectly obvious\n\n1:53:46.440 --> 1:53:48.680\n that the way to transfer money\n\n1:53:48.680 --> 1:53:51.840\n from working Americans to investors\n\n1:53:51.840 --> 1:53:53.680\n is through the biomedical model,\n\n1:53:54.560 --> 1:53:57.720\n not through the social health model.\n\n1:53:57.720 --> 1:53:59.920\n And that's the problem for,\n\n1:53:59.920 --> 1:54:02.840\n and I'd like to discuss this\n\n1:54:02.840 --> 1:54:06.360\n because the market isn't gonna get us\n\n1:54:06.360 --> 1:54:08.040\n to a reasonable allocation.\n\n1:54:08.040 --> 1:54:09.680\n All the other wealthy countries\n\n1:54:09.680 --> 1:54:11.560\n that are so much healthier than we are\n\n1:54:11.560 --> 1:54:14.040\n and spending so much less than we are\n\n1:54:14.040 --> 1:54:17.120\n have some form of government intervention\n\n1:54:17.120 --> 1:54:20.480\n in the quality of the health data that's available,\n\n1:54:20.480 --> 1:54:25.480\n in the budgeting of health and social factors.\n\n1:54:25.920 --> 1:54:28.040\n And we don't, we're kind of the Wild West\n\n1:54:28.040 --> 1:54:31.080\n and we let the market determine those allocations.\n\n1:54:31.080 --> 1:54:34.360\n And it's an awful failure.\n\n1:54:34.360 --> 1:54:36.720\n It's a horrendous failure.\n\n1:54:36.720 --> 1:54:39.800\n So one argument against government,\n\n1:54:39.800 --> 1:54:43.760\n or sorry, an alternative to the government intervention\n\n1:54:44.720 --> 1:54:48.320\n is the market can work better\n\n1:54:48.320 --> 1:54:51.720\n if the citizenry has better information.\n\n1:54:51.720 --> 1:54:53.160\n So one argument is that\n\n1:54:53.160 --> 1:54:58.160\n communicators like podcasts and so on,\n\n1:54:58.680 --> 1:55:01.080\n but other channels of communication\n\n1:55:01.080 --> 1:55:03.840\n will be the way to fight big pharma.\n\n1:55:03.840 --> 1:55:05.640\n Your book is the way to,\n\n1:55:05.640 --> 1:55:07.560\n by providing information.\n\n1:55:07.560 --> 1:55:10.360\n The alternative to the government intervention\n\n1:55:10.360 --> 1:55:11.760\n on every aspect of this,\n\n1:55:11.760 --> 1:55:13.440\n including communication with the doctors\n\n1:55:13.440 --> 1:55:15.400\n is to provide them other information\n\n1:55:15.400 --> 1:55:18.600\n and not allow the market to provide that information\n\n1:55:18.600 --> 1:55:22.440\n by basically making it exciting\n\n1:55:22.440 --> 1:55:27.000\n to buy books, to make better and better communicators\n\n1:55:27.000 --> 1:55:30.840\n on Twitter, through books, through op eds,\n\n1:55:30.840 --> 1:55:32.960\n through podcasts, through so on.\n\n1:55:32.960 --> 1:55:35.840\n So basically, cause there's a lot of incentive\n\n1:55:35.840 --> 1:55:40.440\n to communicate against the messages of big pharma.\n\n1:55:40.440 --> 1:55:43.640\n There's incentive because people want to understand\n\n1:55:43.640 --> 1:55:44.760\n what's good for their lives\n\n1:55:44.760 --> 1:55:46.880\n and they're willing to listen to charismatic people\n\n1:55:46.880 --> 1:55:50.920\n that are able to clearly explain what is good for them.\n\n1:55:50.920 --> 1:55:54.000\n And they do, and more than 80% of people\n\n1:55:54.000 --> 1:55:55.480\n think that drugs cost too much\n\n1:55:55.480 --> 1:55:58.780\n and the drug industry is too interested in profits.\n\n1:56:00.400 --> 1:56:02.320\n But they still get influenced.\n\n1:56:02.320 --> 1:56:05.520\n They can't, you can't get the vote through Congress.\n\n1:56:05.520 --> 1:56:08.720\n You know, Democrats and Republicans alike\n\n1:56:08.720 --> 1:56:10.280\n are taking money from Congress\n\n1:56:10.280 --> 1:56:13.920\n and somehow it just doesn't work out\n\n1:56:13.920 --> 1:56:17.200\n that these even small changes.\n\n1:56:17.200 --> 1:56:21.800\n I mean, the pared down part of Medicare,\n\n1:56:21.800 --> 1:56:26.800\n the plan for increasing Medicare negotiation drug costs\n\n1:56:27.640 --> 1:56:29.360\n in Build Back Better,\n\n1:56:29.360 --> 1:56:32.840\n it's literally gonna reduce the number of new drugs\n\n1:56:32.840 --> 1:56:37.720\n that are beneficial, uniquely beneficial\n\n1:56:37.720 --> 1:56:42.120\n by about one new drug or two new drugs over 30 years.\n\n1:56:42.120 --> 1:56:47.120\n It will have virtually an indecipherable impact.\n\n1:56:48.440 --> 1:56:53.440\n And yet pharma is talking about the impact on innovation.\n\n1:56:53.760 --> 1:56:55.920\n And if you vote for this,\n\n1:56:55.920 --> 1:56:58.280\n if you let your Congressman vote for this,\n\n1:56:58.280 --> 1:57:03.280\n you're gonna severely slow down drug innovation\n\n1:57:04.340 --> 1:57:07.040\n and that's gonna affect the quality of your life.\n\n1:57:07.040 --> 1:57:12.040\n Let me ask you about over medication\n\n1:57:17.000 --> 1:57:19.680\n that we've been talking about from different angles.\n\n1:57:19.680 --> 1:57:22.640\n But one difficult question for me,\n\n1:57:22.640 --> 1:57:25.520\n I'll just, I'll pick one of the difficult topics,\n\n1:57:25.520 --> 1:57:26.960\n depression.\n\n1:57:26.960 --> 1:57:31.960\n So depression is a serious, painful condition\n\n1:57:31.960 --> 1:57:36.320\n that leads to a lot of people suffering in the world.\n\n1:57:37.240 --> 1:57:40.560\n And yet it is likely they were over prescribing\n\n1:57:40.560 --> 1:57:42.380\n antidepressants.\n\n1:57:42.380 --> 1:57:47.040\n So as a doctor, as a patient, as a healthcare system,\n\n1:57:47.040 --> 1:57:50.340\n as a society, what do we do with that fact\n\n1:57:50.340 --> 1:57:53.040\n that people suffer?\n\n1:57:53.040 --> 1:57:56.560\n There's a lot of people suffering from depression\n\n1:57:57.560 --> 1:57:59.160\n and there's also people suffering\n\n1:57:59.160 --> 1:58:01.920\n from over prescribing of antidepressants.\n\n1:58:01.920 --> 1:58:02.840\n Right.\n\n1:58:02.840 --> 1:58:06.840\n So a paper in the New England Journal by Eric Turner\n\n1:58:06.840 --> 1:58:09.200\n showed that the data,\n\n1:58:09.200 --> 1:58:12.320\n if you put all the data together from antidepressants,\n\n1:58:12.320 --> 1:58:17.320\n you find out that antidepressants are not effective\n\n1:58:17.940 --> 1:58:19.360\n for people who are depressed\n\n1:58:19.360 --> 1:58:21.060\n but don't have a major depression.\n\n1:58:22.240 --> 1:58:25.280\n Major depression is a serious problem.\n\n1:58:25.280 --> 1:58:27.260\n People can't function normally.\n\n1:58:27.260 --> 1:58:31.020\n They have a hard time getting out,\n\n1:58:31.020 --> 1:58:34.220\n performing their normal social roles.\n\n1:58:35.780 --> 1:58:39.460\n But what's happened is that the publicity,\n\n1:58:39.460 --> 1:58:43.020\n I mean, Prozac Nation was a good example\n\n1:58:43.020 --> 1:58:45.980\n of making the argument that why should people\n\n1:58:45.980 --> 1:58:47.580\n settle for normal happiness\n\n1:58:47.580 --> 1:58:49.740\n when they can have better than normal happiness?\n\n1:58:49.740 --> 1:58:52.460\n And if you're not having normal happiness,\n\n1:58:52.460 --> 1:58:53.540\n you should take a drug.\n\n1:58:53.540 --> 1:58:58.540\n Well, that concept that serotonin metabolism\n\n1:59:00.340 --> 1:59:03.520\n is the root cause of depression\n\n1:59:03.520 --> 1:59:05.500\n is really a destructive one.\n\n1:59:05.500 --> 1:59:08.740\n We have drugs that change serotonin metabolism\n\n1:59:08.740 --> 1:59:12.140\n but we don't know if that's why antidepressants\n\n1:59:12.140 --> 1:59:14.440\n work on major depression.\n\n1:59:14.440 --> 1:59:16.020\n And they certainly don't work on everybody\n\n1:59:16.020 --> 1:59:16.860\n with major depression.\n\n1:59:16.860 --> 1:59:18.500\n I forget what the number needed a treat is.\n\n1:59:18.500 --> 1:59:20.820\n I think it's around four,\n\n1:59:20.820 --> 1:59:23.580\n one out of four people have significant improvement.\n\n1:59:23.580 --> 1:59:28.160\n But the people without major depression don't get better.\n\n1:59:28.160 --> 1:59:30.420\n And the vast majority of these drugs\n\n1:59:30.420 --> 1:59:33.700\n are used for people without major depression.\n\n1:59:33.700 --> 1:59:37.260\n So what's happened is that the feelings\n\n1:59:37.260 --> 1:59:42.020\n of life satisfaction of happiness and not sadness\n\n1:59:42.020 --> 1:59:43.940\n have been medicalized.\n\n1:59:43.940 --> 1:59:47.860\n The normal range of feelings have been medicalized.\n\n1:59:47.860 --> 1:59:51.020\n And that's not to say that they shouldn't be attended to.\n\n1:59:51.020 --> 1:59:54.340\n But the evidence shows that attending to them\n\n1:59:54.340 --> 1:59:57.020\n by giving somebody a medicine doesn't help\n\n1:59:57.020 --> 1:59:59.660\n except that they feel like somebody cares about them\n\n1:59:59.660 --> 2:00:01.420\n and believes that they're suffering.\n\n2:00:01.420 --> 2:00:04.060\n But there are problems in living\n\n2:00:04.060 --> 2:00:07.740\n that give rise to much of this symptomatology\n\n2:00:07.740 --> 2:00:10.100\n of less than major depression.\n\n2:00:10.100 --> 2:00:12.380\n And let's call it what it is\n\n2:00:12.380 --> 2:00:14.780\n and figure out a way to help people\n\n2:00:14.780 --> 2:00:17.980\n in visual therapy, group therapy.\n\n2:00:17.980 --> 2:00:19.880\n Maybe lifestyle modification would work.\n\n2:00:19.880 --> 2:00:20.880\n We gotta try that.\n\n2:00:21.920 --> 2:00:24.760\n But let's call it what it is instead of saying,\n\n2:00:24.760 --> 2:00:29.760\n oh, you're in this vast basket of people who are depressed\n\n2:00:29.860 --> 2:00:31.540\n so we'll give you an antidepressant\n\n2:00:31.540 --> 2:00:33.340\n even though the evidence shows\n\n2:00:33.340 --> 2:00:36.620\n that people who are suffering from your level of depression\n\n2:00:36.620 --> 2:00:38.220\n don't get better.\n\n2:00:38.220 --> 2:00:42.540\n And that's a consequence of not focusing\n\n2:00:42.540 --> 2:00:46.060\n on preventative medicine, the lifestyle changes,\n\n2:00:46.060 --> 2:00:47.140\n all that kind of stuff.\n\n2:00:47.140 --> 2:00:49.660\n Well, yes, but it's really a consequence\n\n2:00:49.660 --> 2:00:53.060\n of the drug companies creating the impression\n\n2:00:53.060 --> 2:00:54.720\n that if you're sad, take a pill.\n\n2:00:56.620 --> 2:01:01.140\n If you're nonmajor depression,\n\n2:01:01.140 --> 2:01:03.460\n how do you overcome depression?\n\n2:01:03.460 --> 2:01:06.700\n Well, you have to talk about what the problem is.\n\n2:01:06.700 --> 2:01:09.900\n So talk therapy, lifestyle changes.\n\n2:01:09.900 --> 2:01:12.260\n Well, no, I'm not jumping to that.\n\n2:01:12.260 --> 2:01:15.100\n I'm saying that you ought to,\n\n2:01:15.100 --> 2:01:19.420\n A, the way you feel must be respected.\n\n2:01:19.420 --> 2:01:21.140\n Yeah, acknowledge that you're suffering.\n\n2:01:21.140 --> 2:01:22.660\n Acknowledge that you're suffering\n\n2:01:22.660 --> 2:01:24.700\n and deal with healthcare providers\n\n2:01:24.700 --> 2:01:27.220\n who acknowledge that you're suffering.\n\n2:01:27.220 --> 2:01:30.180\n So let's take that first step.\n\n2:01:30.180 --> 2:01:32.260\n And then. Big first step also.\n\n2:01:32.260 --> 2:01:33.540\n Big first step, yeah.\n\n2:01:33.540 --> 2:01:36.220\n Family docs are pretty good at that.\n\n2:01:36.220 --> 2:01:38.980\n That's kind of the arena\n\n2:01:38.980 --> 2:01:41.880\n that caused me to go into family medicine.\n\n2:01:41.880 --> 2:01:44.260\n The subjective experience of the patient.\n\n2:01:44.260 --> 2:01:46.700\n Okay, so you're a person\n\n2:01:46.700 --> 2:01:49.620\n who is not getting the enjoyment out of their life\n\n2:01:49.620 --> 2:01:52.040\n that they feel they ought to be getting.\n\n2:01:52.040 --> 2:01:54.620\n Now let's figure out why\n\n2:01:54.620 --> 2:01:57.300\n and whether that means some time with a social worker,\n\n2:01:57.300 --> 2:01:59.020\n some time with a psychiatrist,\n\n2:01:59.020 --> 2:02:01.320\n some time with a psychiatric nurse.\n\n2:02:02.220 --> 2:02:04.100\n I'm not sure how you'd best do that\n\n2:02:04.100 --> 2:02:05.760\n most effectively and efficiently,\n\n2:02:05.760 --> 2:02:07.500\n but that's what you need to do.\n\n2:02:07.500 --> 2:02:11.680\n And it may be that there's a marital problem\n\n2:02:11.680 --> 2:02:13.620\n and there's something going on\n\n2:02:13.620 --> 2:02:18.580\n and one of the spouses can't find satisfaction\n\n2:02:18.580 --> 2:02:21.500\n in the life they have to live within their relationship.\n\n2:02:21.500 --> 2:02:24.640\n Maybe there's a past history of trauma or abuse\n\n2:02:24.640 --> 2:02:28.820\n that somebody is projecting onto their current situation.\n\n2:02:28.820 --> 2:02:31.100\n Maybe there's socioeconomic circumstances\n\n2:02:31.100 --> 2:02:33.100\n where they can't find a job\n\n2:02:33.100 --> 2:02:36.540\n that gives them self respect and enough money to live.\n\n2:02:36.540 --> 2:02:39.700\n All, you know, an infinite range of things.\n\n2:02:39.700 --> 2:02:42.080\n But let's figure out, make a diagnosis first.\n\n2:02:42.080 --> 2:02:45.460\n The diagnosis isn't that the person feels sadder\n\n2:02:45.460 --> 2:02:48.620\n than they feel, than they want to feel.\n\n2:02:48.620 --> 2:02:51.980\n The diagnosis is why does the person feel sadder\n\n2:02:51.980 --> 2:02:53.140\n than they want to feel?\n\n2:02:54.500 --> 2:02:56.340\n You mentioned this is what made you want\n\n2:02:56.340 --> 2:02:59.260\n to get into family medicine.\n\n2:03:00.980 --> 2:03:03.100\n As a doctor, what do you think about the saying,\n\n2:03:03.100 --> 2:03:05.380\n save one life, save the world?\n\n2:03:05.380 --> 2:03:10.380\n This was always moving to me about doctors\n\n2:03:13.780 --> 2:03:16.740\n because you have like this human in front of you\n\n2:03:17.700 --> 2:03:20.920\n and your time is worth money.\n\n2:03:22.340 --> 2:03:26.220\n Your, what you prescribe and your efforts\n\n2:03:26.220 --> 2:03:28.820\n after the visit are worth money.\n\n2:03:28.820 --> 2:03:31.860\n And it seems like the task of the doctor\n\n2:03:31.860 --> 2:03:34.760\n is to not think about any of that.\n\n2:03:34.760 --> 2:03:39.760\n Or not the task, but it seems like a great doctor,\n\n2:03:42.480 --> 2:03:45.080\n despite all that, just forgets it all\n\n2:03:45.080 --> 2:03:47.020\n and just cares about the one human.\n\n2:03:47.020 --> 2:03:51.260\n And somehow that feels like the love and effort\n\n2:03:51.260 --> 2:03:53.220\n you put into helping one person\n\n2:03:53.220 --> 2:03:55.460\n is the thing that will save the world.\n\n2:03:55.460 --> 2:03:58.420\n It's not like some economic argument\n\n2:03:58.420 --> 2:04:03.420\n or some political argument or financial argument.\n\n2:04:03.420 --> 2:04:08.420\n It's a very human drive that ultimately\n\n2:04:09.580 --> 2:04:13.020\n is behind all of this that will do good for the world.\n\n2:04:13.020 --> 2:04:15.600\n Yes, I think that's true.\n\n2:04:15.600 --> 2:04:19.660\n And at the same time, I think it's equally true\n\n2:04:19.660 --> 2:04:23.660\n that all physicians need to have a sense of responsibility\n\n2:04:23.660 --> 2:04:28.660\n about how the common resources are allocated\n\n2:04:28.660 --> 2:04:33.660\n to serve the whole population's interest best.\n\n2:04:34.180 --> 2:04:36.420\n That's a tension that you have as a physician.\n\n2:04:36.420 --> 2:04:38.500\n Let's take the extreme example.\n\n2:04:38.500 --> 2:04:41.460\n Let's say you had a patient in front of you\n\n2:04:41.460 --> 2:04:46.380\n who if you gave one $10 billion pill to,\n\n2:04:46.380 --> 2:04:47.740\n you would save their life.\n\n2:04:49.180 --> 2:04:52.420\n I would just be tortured by that as a physician\n\n2:04:52.420 --> 2:04:56.140\n because I know that $10 billion spent properly\n\n2:04:56.140 --> 2:05:00.260\n in an epidemiologically guided way\n\n2:05:00.260 --> 2:05:03.580\n is gonna save a whole lot more lives than one life.\n\n2:05:03.580 --> 2:05:06.380\n So it's also your responsibility as a physician\n\n2:05:06.380 --> 2:05:08.700\n to walk away from that patient.\n\n2:05:08.700 --> 2:05:10.540\n I wouldn't say that.\n\n2:05:10.540 --> 2:05:12.060\n I think it's your responsibility\n\n2:05:12.060 --> 2:05:14.020\n to be tortured by it.\n\n2:05:14.020 --> 2:05:15.180\n That's exactly right.\n\n2:05:17.100 --> 2:05:18.460\n The human condition.\n\n2:05:21.460 --> 2:05:24.700\n That's a tough job, but yeah, yeah.\n\n2:05:24.700 --> 2:05:27.220\n To maintain your humanity through it all.\n\n2:05:27.220 --> 2:05:30.260\n Yeah, but you've been asking at different points\n\n2:05:30.260 --> 2:05:35.260\n in this conversation, why are doctors so complacent\n\n2:05:35.980 --> 2:05:38.860\n about the tremendous amount of money we're spending?\n\n2:05:38.860 --> 2:05:41.460\n Why do they accept knowledge from different sources\n\n2:05:41.460 --> 2:05:44.340\n that may not pan out when they really know the truth?\n\n2:05:45.300 --> 2:05:48.380\n And the answer is that they're trying to do their best\n\n2:05:48.380 --> 2:05:49.500\n for their patients.\n\n2:05:49.500 --> 2:05:54.500\n And there's this, it's the same kind of torture\n\n2:05:56.340 --> 2:05:59.860\n to figure out what the hell is going on with the data.\n\n2:06:00.740 --> 2:06:03.420\n And that's a sort of future project.\n\n2:06:03.420 --> 2:06:06.140\n And maybe people will read my book\n\n2:06:06.140 --> 2:06:08.100\n and maybe they'll get a little more excited about it,\n\n2:06:08.100 --> 2:06:10.140\n become more legitimate in practice.\n\n2:06:10.140 --> 2:06:13.620\n I would feel like my life was worthwhile if that happened.\n\n2:06:13.620 --> 2:06:17.140\n But at the same time, they've got to do something\n\n2:06:17.140 --> 2:06:18.740\n with the patient in front of them.\n\n2:06:18.740 --> 2:06:21.100\n They've got to make a decision.\n\n2:06:21.100 --> 2:06:24.820\n And they probably, there are not many weirdos like me\n\n2:06:24.820 --> 2:06:27.300\n who invest their life in figuring out\n\n2:06:27.300 --> 2:06:28.300\n what's behind the data.\n\n2:06:28.300 --> 2:06:29.780\n They're trying to get through the day\n\n2:06:29.780 --> 2:06:31.620\n and do the right thing for their patient.\n\n2:06:31.620 --> 2:06:34.980\n So they're tortured by that decision too.\n\n2:06:34.980 --> 2:06:38.460\n And so if you're not careful,\n\n2:06:38.460 --> 2:06:43.460\n big pharma can manipulate that drive\n\n2:06:43.460 --> 2:06:44.940\n to try to help the patient,\n\n2:06:44.940 --> 2:06:49.700\n that humanity of dealing with the uncertainty of it all.\n\n2:06:49.700 --> 2:06:51.940\n Like what is the best thing to do?\n\n2:06:51.940 --> 2:06:53.780\n Big pharma can step in and use money\n\n2:06:53.780 --> 2:06:55.500\n to manipulate that humanity.\n\n2:06:55.500 --> 2:06:57.500\n Yeah, I would state it quite differently.\n\n2:06:57.500 --> 2:07:00.940\n It's sort of an opt out rather than an opt in.\n\n2:07:00.940 --> 2:07:02.820\n Big pharma will do that.\n\n2:07:02.820 --> 2:07:04.420\n And you need to opt out of it.\n\n2:07:07.980 --> 2:07:11.300\n What advice would you give to a young person today\n\n2:07:11.300 --> 2:07:13.100\n in high school or college\n\n2:07:13.100 --> 2:07:17.020\n stepping into this complicated world\n\n2:07:17.020 --> 2:07:22.020\n full of advertisements, of big powerful institutions,\n\n2:07:22.540 --> 2:07:24.900\n of big rich companies,\n\n2:07:24.900 --> 2:07:27.100\n how to have a positive impact in the world,\n\n2:07:27.100 --> 2:07:29.460\n how to live a life they can be proud of?\n\n2:07:30.860 --> 2:07:33.340\n I would say should that person\n\n2:07:34.580 --> 2:07:38.140\n who has only good motives go into medicine.\n\n2:07:38.140 --> 2:07:39.740\n They have an inclination to go into medicine\n\n2:07:39.740 --> 2:07:42.060\n and they've asked me what I think about that\n\n2:07:42.060 --> 2:07:45.420\n given what I know about the undermining\n\n2:07:45.420 --> 2:07:47.660\n of American healthcare at this point.\n\n2:07:47.660 --> 2:07:50.660\n And my answer is if you've got the calling,\n\n2:07:50.660 --> 2:07:51.500\n you should do it.\n\n2:07:52.420 --> 2:07:54.340\n You should do it because nobody's gonna do it\n\n2:07:54.340 --> 2:07:55.180\n better than you.\n\n2:07:56.220 --> 2:07:57.860\n And if you don't have the calling\n\n2:07:58.780 --> 2:08:01.020\n and you're in it for the money,\n\n2:08:01.020 --> 2:08:03.260\n you're not gonna be proud of yourself.\n\n2:08:03.260 --> 2:08:07.700\n How do you prevent yourself from doing,\n\n2:08:07.700 --> 2:08:12.700\n from letting the system change you over years and years,\n\n2:08:12.940 --> 2:08:17.940\n like letting the game of pharmaceutical influence affect you?\n\n2:08:20.820 --> 2:08:22.620\n It's a very hard question\n\n2:08:22.620 --> 2:08:27.620\n because the sociologic norms are to be affected\n\n2:08:28.060 --> 2:08:32.980\n and to trust the sources of information\n\n2:08:32.980 --> 2:08:36.340\n that are largely controlled by the drug industry.\n\n2:08:36.340 --> 2:08:38.220\n And that's why I wrote Sickening,\n\n2:08:38.220 --> 2:08:43.220\n is to try and help those people in the medical profession\n\n2:08:46.020 --> 2:08:50.620\n to understand that what's going on right now looks normal\n\n2:08:50.620 --> 2:08:52.380\n but it's not.\n\n2:08:52.380 --> 2:08:55.460\n The health of Americans is going downhill.\n\n2:08:55.460 --> 2:08:57.580\n Our society's getting ruined by the money\n\n2:08:57.580 --> 2:09:02.580\n that's getting pulled out of other socially beneficial uses\n\n2:09:02.580 --> 2:09:06.420\n to pay for health care that is not helping us.\n\n2:09:08.060 --> 2:09:12.580\n So fundamentally, the thing that is normal,\n\n2:09:12.580 --> 2:09:16.940\n now question the normal, don't.\n\n2:09:17.820 --> 2:09:21.820\n If you conform, conform hesitantly.\n\n2:09:21.820 --> 2:09:23.700\n Well, you have to conform.\n\n2:09:23.700 --> 2:09:26.620\n You can't become a doctor without conforming.\n\n2:09:26.620 --> 2:09:30.100\n I just made it through.\n\n2:09:30.100 --> 2:09:35.100\n But there aren't many and it's hard work.\n\n2:09:35.300 --> 2:09:38.060\n But you have to conform.\n\n2:09:38.060 --> 2:09:40.580\n And even with my colleagues in my own practice,\n\n2:09:40.580 --> 2:09:44.300\n I couldn't convince them that some of the beliefs they had\n\n2:09:44.300 --> 2:09:47.220\n about how best to practice weren't accurate.\n\n2:09:47.220 --> 2:09:51.100\n There's one scene, a younger physician\n\n2:09:51.100 --> 2:09:53.580\n had prescribed hormone replacement therapy.\n\n2:09:53.580 --> 2:09:56.220\n This is back in 2000, 2001.\n\n2:09:56.220 --> 2:10:00.380\n Had prescribed hormone replacement therapy for one of my patients\n\n2:10:00.380 --> 2:10:03.220\n who happened to be a really good personal friend.\n\n2:10:03.220 --> 2:10:08.780\n And I saw that patient covering for my colleague at one point\n\n2:10:08.780 --> 2:10:13.340\n and I saw that her hormone replacement therapy had been renewed.\n\n2:10:13.340 --> 2:10:15.580\n And I said, are you having hot flashes or any problem?\n\n2:10:15.580 --> 2:10:16.660\n No, no, no, no.\n\n2:10:16.660 --> 2:10:21.220\n But Dr. So and So said it's better for my health.\n\n2:10:21.220 --> 2:10:23.060\n And I said, no, it's not.\n\n2:10:23.060 --> 2:10:26.180\n The research is showing that it's not, it's harmful for your health\n\n2:10:26.180 --> 2:10:27.980\n and I think you should stop it.\n\n2:10:27.980 --> 2:10:32.780\n So my colleague approached me when she saw the chart and said,\n\n2:10:32.780 --> 2:10:34.780\n wait a minute, that's my patient.\n\n2:10:34.780 --> 2:10:37.180\n Maybe your friend, but it's my patient.\n\n2:10:37.180 --> 2:10:43.900\n And I went to a conference from my alma mater, medical school,\n\n2:10:43.900 --> 2:10:47.940\n and they said that healthy people should be given hormone replacement.\n\n2:10:47.940 --> 2:10:51.500\n And I said, there's got to be a way to get rid of it.\n\n2:10:51.500 --> 2:10:55.300\n And I said, there's got to be drug companies involved in this.\n\n2:10:55.300 --> 2:10:57.700\n And she said, no, no, no, it was at my university.\n\n2:10:57.700 --> 2:10:59.900\n It was not a drug company thing.\n\n2:10:59.900 --> 2:11:02.380\n We didn't go to a Caribbean island.\n\n2:11:02.380 --> 2:11:03.860\n I said, do you have the syllabus?\n\n2:11:03.860 --> 2:11:05.140\n She said, yeah.\n\n2:11:05.140 --> 2:11:07.660\n And she went and got the syllabus and sure enough,\n\n2:11:07.660 --> 2:11:10.380\n it was sponsored by a drug company.\n\n2:11:10.380 --> 2:11:11.340\n They're everywhere.\n\n2:11:11.340 --> 2:11:12.220\n They're everywhere.\n\n2:11:12.220 --> 2:11:16.340\n And it's back to Kuhn that groups of experts\n\n2:11:16.340 --> 2:11:21.740\n share unspoken assumptions, and in order to be included\n\n2:11:21.740 --> 2:11:23.140\n in that group of experts, you have\n\n2:11:23.140 --> 2:11:25.260\n to share those unspoken assumptions.\n\n2:11:25.260 --> 2:11:27.900\n And what I'm hoping to do with my book, Sickening,\n\n2:11:27.900 --> 2:11:31.900\n and being here having this wonderful conversation with you\n\n2:11:31.900 --> 2:11:36.220\n is to create an alternative to this normal\n\n2:11:36.220 --> 2:11:45.060\n that people can pursue and practice better medicine\n\n2:11:45.060 --> 2:11:47.220\n and also prevent burnout.\n\n2:11:47.220 --> 2:11:49.900\n I mean, about half the doctors complain that they're burned\n\n2:11:49.900 --> 2:11:51.260\n out and they've had it.\n\n2:11:51.260 --> 2:11:54.180\n And I think that this is subjective.\n\n2:11:54.180 --> 2:11:55.300\n I don't have data on this.\n\n2:11:55.300 --> 2:11:57.540\n This is just my opinion.\n\n2:11:57.540 --> 2:11:59.900\n But I think that a lot of that burnout\n\n2:11:59.900 --> 2:12:04.380\n is so called moral injury from practicing in a way\n\n2:12:04.380 --> 2:12:08.420\n that the docs know isn't working.\n\n2:12:08.420 --> 2:12:12.020\n It's not actually providing an alternative to the normals,\n\n2:12:12.020 --> 2:12:13.860\n expanding the normals, shifting the normal,\n\n2:12:13.860 --> 2:12:15.220\n just like with Kuhn.\n\n2:12:15.220 --> 2:12:19.420\n You're basically looking to shift\n\n2:12:19.420 --> 2:12:24.340\n the way medicine is done to the original,\n\n2:12:24.340 --> 2:12:29.860\n to the intent that it represents the ideal of medicine,\n\n2:12:29.860 --> 2:12:30.580\n of health care.\n\n2:12:30.580 --> 2:12:33.620\n Yeah, in Kuhnian terms, to have a revolution.\n\n2:12:33.620 --> 2:12:36.860\n And that revolution would be to practice medicine\n\n2:12:36.860 --> 2:12:40.620\n in a way that will be epidemiologically most\n\n2:12:40.620 --> 2:12:43.660\n effective, not most profitable for the people\n\n2:12:43.660 --> 2:12:47.420\n who are providing you with what's called knowledge.\n\n2:12:47.420 --> 2:12:53.220\n You helped a lot of people, as a doctor, as an educator,\n\n2:12:53.220 --> 2:12:56.540\n live better lives, live longer.\n\n2:12:56.540 --> 2:12:59.180\n But you yourself are a mortal being.\n\n2:12:59.180 --> 2:13:02.260\n Do you think about your own mortality?\n\n2:13:02.260 --> 2:13:03.660\n Do you think about your death?\n\n2:13:03.660 --> 2:13:06.020\n Are you afraid of death?\n\n2:13:06.020 --> 2:13:06.540\n I'm not.\n\n2:13:06.540 --> 2:13:12.100\n I've faced it, been close.\n\n2:13:12.100 --> 2:13:12.780\n Yourself?\n\n2:13:12.780 --> 2:13:14.980\n Yeah, yeah.\n\n2:13:14.980 --> 2:13:16.220\n How do you think about it?\n\n2:13:16.220 --> 2:13:19.780\n What wisdom do you gain from having come close to death,\n\n2:13:19.780 --> 2:13:23.060\n the fact that the whole thing ends?\n\n2:13:23.060 --> 2:13:25.780\n It's liberating.\n\n2:13:25.780 --> 2:13:26.740\n It's very liberating.\n\n2:13:26.740 --> 2:13:27.460\n I'm serious.\n\n2:13:27.460 --> 2:13:30.700\n I was close, and not too long ago.\n\n2:13:34.060 --> 2:13:41.820\n And it was a sense of, this may be the way it ends.\n\n2:13:41.820 --> 2:13:45.780\n And I've done my best.\n\n2:13:45.780 --> 2:13:48.220\n It's not been perfect.\n\n2:13:48.220 --> 2:13:51.180\n And if it ends here, it ends here.\n\n2:13:51.180 --> 2:13:54.460\n The people around me are trying to do their best.\n\n2:13:54.460 --> 2:13:57.860\n And in fact, I got pulled out of it.\n\n2:13:57.860 --> 2:14:01.540\n But it didn't look like I was going to get pulled out of it.\n\n2:14:01.540 --> 2:14:07.420\n Are you ultimately grateful for the ride, even though it ends?\n\n2:14:07.420 --> 2:14:11.940\n Well, it's a little odd.\n\n2:14:11.940 --> 2:14:13.140\n I think so.\n\n2:14:13.140 --> 2:14:18.820\n If I know you can't take the ride if you know it's going to end well.\n\n2:14:18.820 --> 2:14:19.940\n It's not the real ride.\n\n2:14:19.940 --> 2:14:22.140\n It's just a ride.\n\n2:14:22.140 --> 2:14:25.220\n But having gone through the whole thing,\n\n2:14:25.220 --> 2:14:31.260\n I definitely freed me of a sense of anxiety about death.\n\n2:14:31.260 --> 2:14:35.540\n And it said to me, do your best every day,\n\n2:14:35.540 --> 2:14:38.460\n because it's going to end sometime.\n\n2:14:38.460 --> 2:14:40.820\n I apologize for the ridiculously big question.\n\n2:14:40.820 --> 2:14:45.780\n But what do you think is the meaning of life,\n\n2:14:45.780 --> 2:14:47.420\n of our human existence?\n\n2:14:52.140 --> 2:14:56.900\n I think it's to care about something and do your best with it.\n\n2:14:56.900 --> 2:14:59.620\n Whether it's being a doctor and trying\n\n2:14:59.620 --> 2:15:03.180\n to make sure that the greatest number of people\n\n2:15:03.180 --> 2:15:06.460\n get the best health care.\n\n2:15:06.460 --> 2:15:09.380\n Or it's a gardener who wants to have the most beautiful plants.\n\n2:15:09.380 --> 2:15:12.780\n Or it's a grandparent who wants to have a good relationship\n\n2:15:12.780 --> 2:15:13.820\n with their grandchildren.\n\n2:15:13.820 --> 2:15:19.260\n But whatever it is that gives you a sense of meaning,\n\n2:15:19.260 --> 2:15:21.900\n as long as it doesn't hurt other people,\n\n2:15:21.900 --> 2:15:24.980\n to really commit yourself to it.\n\n2:15:24.980 --> 2:15:27.940\n That commitment, being in that commitment for me\n\n2:15:27.940 --> 2:15:29.860\n is the meaning of life.\n\n2:15:29.860 --> 2:15:34.540\n Put your whole heart and soul into the thing.\n\n2:15:34.540 --> 2:15:38.860\n What is it, the Bukowski poem, go all the way.\n\n2:15:38.860 --> 2:15:42.500\n John, you're an incredible human being, incredible educator.\n\n2:15:42.500 --> 2:15:45.060\n Like I said, I recommend people listen to your lectures.\n\n2:15:45.060 --> 2:15:47.980\n It's so refreshing to see that clarity\n\n2:15:47.980 --> 2:15:49.380\n of thought and brilliance.\n\n2:15:49.380 --> 2:15:51.900\n And obviously, your criticism of Big Pharma\n\n2:15:51.900 --> 2:15:56.420\n or your illumination of the mechanisms of Big Pharma\n\n2:15:56.420 --> 2:15:58.500\n is really important at this time.\n\n2:15:58.500 --> 2:16:02.820\n So I really hope people read your book, Sickening,\n\n2:16:02.820 --> 2:16:07.820\n that's out today, or depending on when this comes out.\n\n2:16:07.820 --> 2:16:11.140\n Thank you so much for spending your extremely valuable time\n\n2:16:11.140 --> 2:16:12.260\n with me today.\n\n2:16:12.260 --> 2:16:13.100\n It was amazing.\n\n2:16:13.100 --> 2:16:15.460\n Well, Lex, I wanted back to you.\n\n2:16:15.460 --> 2:16:18.700\n Thanks for engaging in this conversation,\n\n2:16:18.700 --> 2:16:21.420\n for creating the space to have it,\n\n2:16:21.420 --> 2:16:24.260\n and creating a listenership that is\n\n2:16:24.260 --> 2:16:27.380\n interested in understanding serious ideas.\n\n2:16:27.380 --> 2:16:29.460\n And I really appreciate the conversation.\n\n2:16:29.460 --> 2:16:30.940\n And I should mention that offline,\n\n2:16:30.940 --> 2:16:34.060\n you told me you listened to the Gilbert Strang episode.\n\n2:16:34.060 --> 2:16:35.980\n So for anyone who don't know Gilbert Strang,\n\n2:16:35.980 --> 2:16:39.020\n another epic human being that you should check out.\n\n2:16:39.020 --> 2:16:41.260\n If you don't know anything about mathematics\n\n2:16:41.260 --> 2:16:43.260\n or linear algebra, go look him up.\n\n2:16:43.260 --> 2:16:46.700\n He's one of the great mathematics educators of all time.\n\n2:16:46.700 --> 2:16:49.060\n So of all the people you mentioned to me,\n\n2:16:49.060 --> 2:16:50.780\n I appreciate that you mentioned him,\n\n2:16:50.780 --> 2:16:54.100\n because he is a rockstar of mathematics.\n\n2:16:54.100 --> 2:16:56.220\n John, thank you so much for talking to us, it was awesome.\n\n2:16:56.220 --> 2:16:57.900\n Great, thank you.\n\n2:16:57.900 --> 2:17:00.740\n Thanks for listening to this conversation with John Abramson.\n\n2:17:00.740 --> 2:17:02.140\n To support this podcast,\n\n2:17:02.140 --> 2:17:04.980\n please check out our sponsors in the description.\n\n2:17:04.980 --> 2:17:08.820\n And now, let me leave you some words from Marcus Aurelius.\n\n2:17:09.900 --> 2:17:14.740\n \"'Waste no time arguing about what a good man should be.\n\n2:17:14.740 --> 2:17:15.740\n Be one.\"\n\n2:17:15.740 --> 2:17:28.740\n Thank you for listening and hope to see you next time.\n\n"
}
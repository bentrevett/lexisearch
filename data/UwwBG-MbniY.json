{
  "title": "Daniel Kahneman: Thinking Fast and Slow, Deep Learning, and AI | Lex Fridman Podcast #65",
  "id": "UwwBG-MbniY",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:05.680\n The following is a conversation with Daniel Kahneman, winner of the Nobel Prize in Economics\n\n00:05.680 --> 00:10.080\n for his integration of economic science with the psychology of human behavior,\n\n00:10.080 --> 00:16.240\n judgment, and decision making. He's the author of the popular book Thinking Fast and Slow that\n\n00:16.240 --> 00:22.160\n summarizes in an accessible way his research of several decades, often in collaboration with\n\n00:22.160 --> 00:29.600\n Amos Tversky on cognitive biases, prospect theory, and happiness. The central thesis of this work\n\n00:29.600 --> 00:35.520\n is the dichotomy between two modes of thought. What he calls system one is fast, instinctive,\n\n00:35.520 --> 00:41.440\n and emotional. System two is slower, more deliberative, and more logical. The book\n\n00:41.440 --> 00:45.840\n delineates cognitive biases associated with each of these two types of thinking.\n\n00:46.960 --> 00:53.040\n His study of the human mind and its peculiar and fascinating limitations are both instructive and\n\n00:53.040 --> 00:59.200\n inspiring for those of us seeking to engineer intelligent systems. This is the Artificial\n\n00:59.200 --> 01:05.120\n Intelligence Podcast. If you enjoy it, subscribe on YouTube, give it five stars on Apple Podcast,\n\n01:05.120 --> 01:10.000\n follow on Spotify, support it on Patreon, or simply connect with me on Twitter at\n\n01:10.000 --> 01:16.800\n Lex Friedman spelled F R I D M A N. I recently started doing ads at the end of the introduction.\n\n01:16.800 --> 01:21.280\n I'll do one or two minutes after introducing the episode and never any ads in the middle\n\n01:21.280 --> 01:25.920\n that can break the flow of the conversation. I hope that works for you and doesn't hurt the\n\n01:25.920 --> 01:32.160\n listening experience. This show is presented by Cash App, the number one finance app in the App\n\n01:32.160 --> 01:37.440\n Store. I personally use Cash App to send money to friends, but you can also use it to buy, sell,\n\n01:37.440 --> 01:43.280\n and deposit Bitcoin in just seconds. Cash App also has a new investing feature. You can buy\n\n01:43.280 --> 01:48.640\n fractions of a stock, say one dollar's worth, no matter what the stock price is. Broker services\n\n01:48.640 --> 01:55.280\n are provided by Cash App Investing, a subsidiary of Square and member SIPC. I'm excited to be\n\n01:55.280 --> 02:00.480\n working with Cash App to support one of my favorite organizations called First, best known\n\n02:00.480 --> 02:05.760\n for their FIRST Robotics and Lego competitions. They educate and inspire hundreds of thousands\n\n02:05.760 --> 02:11.360\n of students in over 110 countries and have a perfect rating at Charity Navigator, which means\n\n02:11.360 --> 02:17.120\n that donated money is used to maximum effectiveness. When you get Cash App from the App Store or Google\n\n02:17.120 --> 02:24.480\n Play and use code LEXPODCAST, you'll get $10 and Cash App will also donate $10 to FIRST,\n\n02:24.480 --> 02:29.920\n which again is an organization that I've personally seen inspire girls and boys to dream\n\n02:29.920 --> 02:35.520\n of engineering a better world. And now here's my conversation with Daniel Kahneman.\n\n02:36.800 --> 02:43.600\n You tell a story of an SS soldier early in the war, World War II, in Nazi occupied France in\n\n02:43.600 --> 02:50.160\n Paris, where you grew up. He picked you up and hugged you and showed you a picture of a boy,\n\n02:50.160 --> 02:53.840\n Daniel Kahneman. Maybe not realizing that you were Jewish.\n\n02:53.840 --> 02:55.520\n Not maybe, certainly not.\n\n02:56.400 --> 03:01.360\n So I told you I'm from the Soviet Union that was significantly impacted by the war as well,\n\n03:01.360 --> 03:08.720\n and I'm Jewish as well. What do you think World War II taught us about human psychology broadly?\n\n03:09.680 --> 03:17.520\n Well, I think the only big surprise is the extermination policy, genocide,\n\n03:17.520 --> 03:27.040\n by the German people. That's when you look back on it, and I think that's a major surprise.\n\n03:27.040 --> 03:28.240\n It's a surprise because...\n\n03:28.240 --> 03:34.720\n It's a surprise that they could do it. It's a surprise that enough people\n\n03:34.720 --> 03:41.520\n willingly participated in that. This is a surprise. Now it's no longer a surprise,\n\n03:41.520 --> 03:49.840\n but it's changed many people's views, I think, about human beings. Certainly for me,\n\n03:50.720 --> 03:58.080\n the Ackman trial, that teaches you something because it's very clear that if it could happen\n\n03:58.080 --> 04:04.080\n in Germany, it could happen anywhere. It's not that the Germans were special.\n\n04:04.080 --> 04:05.280\n This could happen anywhere.\n\n04:05.280 --> 04:13.600\n So what do you think that is? Do you think we're all capable of evil? We're all capable of cruelty?\n\n04:13.600 --> 04:22.400\n I don't think in those terms. I think that what is certainly possible is you can dehumanize people\n\n04:23.200 --> 04:32.480\n so that you treat them not as people anymore, but as animals. And the same way that you can slaughter\n\n04:32.480 --> 04:39.520\n animals without feeling much of anything, it can be the same. And when you feel that,\n\n04:41.120 --> 04:49.360\n I think, the combination of dehumanizing the other side and having uncontrolled power over\n\n04:49.360 --> 04:54.560\n other people, I think that doesn't bring out the most generous aspect of human nature.\n\n04:54.560 --> 05:07.920\n So that Nazi soldier, he was a good man. And he was perfectly capable of killing a lot of people,\n\n05:08.480 --> 05:09.440\n and I'm sure he did.\n\n05:10.080 --> 05:20.160\n But what did the Jewish people mean to Nazis? So what the dismissal of Jewish as worthy of?\n\n05:20.160 --> 05:24.560\n IA Again, this is surprising that it was so extreme,\n\n05:25.120 --> 05:32.480\n but it's not one thing in human nature. I don't want to call it evil, but the distinction between\n\n05:32.480 --> 05:40.160\n the in group and the out group, that is very basic. So that's built in. The loyalty and\n\n05:40.160 --> 05:50.320\n affection towards in group and the willingness to dehumanize the out group, that is in human nature.\n\n05:50.320 --> 05:57.920\n That's what I think probably didn't need the Holocaust to teach us that. But the Holocaust is\n\n05:57.920 --> 06:05.120\n a very sharp lesson of what can happen to people and what people can do.\n\n06:05.120 --> 06:12.640\n SL. So the effect of the in group and the out group. IA It's clear. Those were people,\n\n06:13.600 --> 06:22.000\n you could shoot them. They were not human. There was no empathy, or very, very little empathy left.\n\n06:23.680 --> 06:32.720\n So occasionally, there might have been. And very quickly, by the way, the empathy disappeared,\n\n06:32.720 --> 06:37.680\n if there was initially. And the fact that everybody around you was doing it,\n\n06:39.840 --> 06:51.120\n that completely, the group doing it, and everybody shooting Jews, I think that makes it permissible.\n\n06:51.120 --> 07:01.280\n Now, how much, whether it could happen in every culture, or whether the Germans were just\n\n07:01.280 --> 07:10.000\n particularly efficient and disciplined, so they could get away with it. It's an interesting\n\n07:10.000 --> 07:15.360\n question. SL. Are these artifacts of history or is it human nature? IA I think that's really human\n\n07:15.360 --> 07:24.480\n nature. You put some people in a position of power relative to other people, and then they become\n\n07:24.480 --> 07:32.240\n less human, they become different. SL. But in general, in war, outside of concentration camps\n\n07:32.240 --> 07:39.760\n in World War Two, it seems that war brings out darker sides of human nature, but also the beautiful\n\n07:39.760 --> 07:49.120\n things about human nature. IA Well, I mean, what it brings out is the loyalty among soldiers. I mean,\n\n07:49.120 --> 07:57.920\n it brings out the bonding, male bonding, I think is a very real thing that happens. And there is\n\n07:57.920 --> 08:03.840\n a certain thrill to friendship, and there is certainly a certain thrill to friendship under\n\n08:03.840 --> 08:12.400\n risk and to shared risk. And so people have very profound emotions, up to the point where it gets\n\n08:12.400 --> 08:23.040\n so traumatic that little is left. SL. So let's talk about psychology a little bit. In your book,\n\n08:23.040 --> 08:30.640\n Thinking Fast and Slow, you describe two modes of thought, system one, the fast and instinctive,\n\n08:31.200 --> 08:37.360\n and emotional one, and system two, the slower, deliberate, logical one. At the risk of asking\n\n08:37.360 --> 08:46.320\n Darwin to discuss theory of evolution, can you describe distinguishing characteristics for people\n\n08:46.320 --> 08:52.800\n who have not read your book of the two systems? IA Well, I mean, the word system is a bit\n\n08:52.800 --> 09:01.440\n misleading, but at the same time it's misleading, it's also very useful. But what I call system one,\n\n09:01.440 --> 09:09.120\n it's easier to think of it as a family of activities. And primarily, the way I describe it\n\n09:09.120 --> 09:17.200\n is there are different ways for ideas to come to mind. And some ideas come to mind automatically,\n\n09:17.920 --> 09:26.480\n and the standard example is two plus two, and then something happens to you. And in other cases,\n\n09:26.480 --> 09:32.240\n you've got to do something, you've got to work in order to produce the idea. And my example,\n\n09:32.240 --> 09:38.000\n I always give the same pair of numbers as 27 times 14, I think. SL. You have to perform some\n\n09:38.000 --> 09:44.560\n algorithm in your head, some steps. IA Yes, and it takes time. It's a very difference. Nothing\n\n09:44.560 --> 09:50.640\n comes to mind except something comes to mind, which is the algorithm, I mean, that you've got\n\n09:50.640 --> 09:58.000\n to perform. And then it's work, and it engages short term memory, it engages executive function,\n\n09:58.000 --> 10:04.560\n and it makes you incapable of doing other things at the same time. So the main characteristic of\n\n10:04.560 --> 10:10.960\n system two is that there is mental effort involved, and there is a limited capacity for mental effort,\n\n10:10.960 --> 10:15.600\n whereas system one is effortless, essentially. That's the major distinction.\n\n10:15.600 --> 10:21.040\n SL. So you talk about there, you know, it's really convenient to talk about two systems,\n\n10:21.040 --> 10:28.240\n but you also mentioned just now and in general that there's no distinct two systems in the brain\n\n10:29.120 --> 10:36.240\n from a neurobiological, even from a psychology perspective. But why does it seem to, from the\n\n10:36.240 --> 10:46.160\n experiments you've conducted, there does seem to be kind of emergent two modes of thinking? So\n\n10:47.120 --> 10:55.680\n at some point, these kinds of systems came into a brain architecture. Maybe mammals share it.\n\n10:57.440 --> 11:01.520\n Or do you not think of it at all in those terms that it's all a mush and these two things just\n\n11:01.520 --> 11:11.840\n emerge? RL. Evolutionary theorizing about this is cheap and easy. So it's the way I think about it\n\n11:12.560 --> 11:20.720\n is that it's very clear that animals have perceptual system, and that includes an ability\n\n11:20.720 --> 11:27.120\n to understand the world, at least to the extent that they can predict, they can't explain anything,\n\n11:27.120 --> 11:34.000\n but they can anticipate what's going to happen. And that's a key form of understanding the world.\n\n11:34.720 --> 11:44.400\n And my crude idea is that what I call system two, well, system two grew out of this.\n\n11:45.200 --> 11:51.840\n And, you know, there is language and there is the capacity of manipulating ideas and the capacity\n\n11:51.840 --> 11:57.520\n of imagining futures and of imagining counterfactual things that haven't happened\n\n11:58.240 --> 12:05.600\n and to do conditional thinking. And there are really a lot of abilities that without language\n\n12:06.240 --> 12:13.120\n and without the very large brain that we have compared to others would be impossible. Now,\n\n12:13.760 --> 12:20.960\n system one is more like what the animals are, but system one also can talk. I mean,\n\n12:20.960 --> 12:26.480\n it has language. It understands language. Indeed, it speaks for us. I mean, you know,\n\n12:26.480 --> 12:32.800\n I'm not choosing every word as a deliberate process. The words, I have some idea and then\n\n12:32.800 --> 12:39.040\n the words come out and that's automatic and effortless. And many of the experiments you've\n\n12:39.040 --> 12:44.480\n done is to show that, listen, system one exists and it does speak for us and we should be careful\n\n12:44.480 --> 12:54.400\n about the voice it provides. Well, I mean, you know, we have to trust it because it's\n\n12:55.280 --> 13:01.760\n the speed at which it acts. System two, if we're dependent on system two for survival,\n\n13:01.760 --> 13:06.480\n we wouldn't survive very long because it's very slow. Yeah. Crossing the street.\n\n13:06.480 --> 13:12.560\n Crossing the street. I mean, many things depend on their being automatic. One very important aspect\n\n13:12.560 --> 13:20.320\n of system one is that it's not instinctive. You use the word instinctive. It contains skills that\n\n13:20.320 --> 13:27.360\n clearly have been learned. So that skilled behavior like driving a car or speaking, in fact,\n\n13:28.800 --> 13:34.960\n skilled behavior has to be learned. And so it doesn't, you know, you don't come equipped with\n\n13:35.920 --> 13:41.840\n driving. You have to learn how to drive and you have to go through a period where driving is not\n\n13:41.840 --> 13:48.880\n automatic before it becomes automatic. So. Yeah. You construct, I mean, this is where you talk\n\n13:48.880 --> 13:57.360\n about heuristic and biases is you, to make it automatic, you create a pattern and then system\n\n13:57.360 --> 14:02.960\n one essentially matches a new experience against the previously seen pattern. And when that match\n\n14:02.960 --> 14:08.160\n is not a good one, that's when the cognitive, all the mess happens, but it's most of the time\n\n14:08.160 --> 14:13.840\n it works. And so it's pretty. Most of the time, the anticipation of what's going to happen next\n\n14:13.840 --> 14:22.000\n is correct. And most of the time the plan about what you have to do is correct. And so most of\n\n14:22.000 --> 14:29.040\n the time everything works just fine. What's interesting actually is that in some sense,\n\n14:29.040 --> 14:36.240\n system one is much better at what it does than system two is at what it does. That is there is\n\n14:36.240 --> 14:44.480\n that quality of effortlessly solving enormously complicated problems, which clearly exists so\n\n14:44.480 --> 14:52.160\n that the chess player, a very good chess player, all the moves that come to their mind are strong\n\n14:52.160 --> 14:58.960\n moves. So all the selection of strong moves happens unconsciously and automatically and\n\n14:58.960 --> 15:05.840\n very, very fast. And all that is in system one. So system two verifies.\n\n15:07.280 --> 15:11.840\n So along this line of thinking, really what we are are machines that construct\n\n15:12.480 --> 15:19.360\n a pretty effective system one. You could think of it that way. So we're not talking about humans,\n\n15:19.360 --> 15:26.400\n but if we think about building artificial intelligence systems, robots, do you think\n\n15:26.400 --> 15:32.480\n all the features and bugs that you have highlighted in human beings are useful\n\n15:32.480 --> 15:38.320\n for constructing AI systems? So both systems are useful for perhaps instilling in robots?\n\n15:39.280 --> 15:50.320\n What is happening these days is that actually what is happening in deep learning is more like\n\n15:50.320 --> 15:56.480\n a system one product than like a system two product. I mean, deep learning matches patterns\n\n15:57.120 --> 16:04.480\n and anticipate what's going to happen. So it's highly predictive. What deep learning\n\n16:05.120 --> 16:12.000\n doesn't have and many people think that this is the critical, it doesn't have the ability to\n\n16:12.000 --> 16:19.040\n reason. So there is no system two there. But I think very importantly, it doesn't have any\n\n16:19.040 --> 16:27.520\n causality or any way to represent meaning and to represent real interactions. So until that is\n\n16:27.520 --> 16:34.880\n solved, what can be accomplished is marvelous and very exciting, but limited.\n\n16:35.600 --> 16:40.560\n That's actually really nice to think of current advances in machine learning as essentially\n\n16:40.560 --> 16:46.960\n system one advances. So how far can we get with just system one? If we think of deep learning\n\n16:46.960 --> 16:52.320\n in artificial intelligence systems? I mean, you know, it's very clear that deep mind has already\n\n16:52.320 --> 17:00.560\n gone way beyond what people thought was possible. I think the thing that has impressed me most about\n\n17:00.560 --> 17:07.840\n the developments in AI is the speed. It's that things, at least in the context of deep learning,\n\n17:07.840 --> 17:14.400\n and maybe this is about to slow down, but things moved a lot faster than anticipated.\n\n17:14.400 --> 17:24.320\n The transition from solving chess to solving Go, that's bewildering how quickly it went.\n\n17:25.600 --> 17:31.840\n The move from Alpha Go to Alpha Zero is sort of bewildering the speed at which they accomplished\n\n17:31.840 --> 17:41.360\n that. Now, clearly, there are many problems that you can solve that way, but there are some problems\n\n17:41.360 --> 17:45.120\n for which you need something else. Something like reasoning.\n\n17:45.760 --> 17:54.160\n Well, reasoning and also, you know, one of the real mysteries, psychologist Gary Marcus, who is\n\n17:54.160 --> 18:05.920\n also a critic of AI. I mean, what he points out, and I think he has a point, is that humans learn\n\n18:05.920 --> 18:16.000\n quickly. Children don't need a million examples, they need two or three examples. So, clearly,\n\n18:16.000 --> 18:25.280\n there is a fundamental difference. And what enables a machine to learn quickly, what you have\n\n18:25.280 --> 18:30.400\n to build into the machine, because it's clear that you have to build some expectations or\n\n18:30.400 --> 18:38.320\n or something in the machine to make it ready to learn quickly. That at the moment seems to be\n\n18:38.320 --> 18:47.680\n unsolved. I'm pretty sure that DeepMind is working on it, but if they have solved it, I haven't heard\n\n18:47.680 --> 18:54.640\n yet. They're trying to actually, them and OpenAI are trying to start to get to use neural networks\n\n18:54.640 --> 19:02.960\n to reason. So, assemble knowledge. Of course, causality is, temporal causality, is out of\n\n19:02.960 --> 19:09.200\n reach to most everybody. You mentioned the benefits of System 1 is essentially that it's\n\n19:09.200 --> 19:10.960\n fast, allows us to function in the world.\n\n19:10.960 --> 19:12.400\n Fast and skilled, yeah.\n\n19:13.040 --> 19:13.680\n It's skill.\n\n19:13.680 --> 19:19.920\n And it has a model of the world. You know, in a sense, I mean, there was the early phase of\n\n19:19.920 --> 19:29.440\n AI attempted to model reasoning. And they were moderately successful, but, you know, reasoning\n\n19:29.440 --> 19:37.440\n by itself doesn't get you much. Deep learning has been much more successful in terms of, you know,\n\n19:37.440 --> 19:43.920\n what they can do. But now, it's an interesting question, whether it's approaching its limits.\n\n19:43.920 --> 19:44.640\n What do you think?\n\n19:44.640 --> 19:51.840\n I think absolutely. So, I just talked to Gian LeCun. He mentioned, you know, so he thinks\n\n19:51.840 --> 19:57.840\n that the limits, we're not going to hit the limits with neural networks, that ultimately,\n\n19:57.840 --> 20:06.720\n this kind of System 1 pattern matching will start to look like System 2 without significant\n\n20:06.720 --> 20:12.480\n transformation of the architecture. So, I'm more with the majority of the people who think that,\n\n20:12.480 --> 20:16.400\n yes, neural networks will hit a limit in their capability.\n\n20:16.400 --> 20:22.960\n He, on the one hand, I have heard him tell them it's a sub, it's essentially that, you know,\n\n20:22.960 --> 20:28.080\n what they have accomplished is not a big deal, that they have just touched, that basically,\n\n20:28.080 --> 20:35.520\n you know, they can't do unsupervised learning in an effective way. But you're telling me that he\n\n20:35.520 --> 20:41.520\n thinks that the current, within the current architecture, you can do causality and reasoning?\n\n20:41.520 --> 20:47.200\n So, he's very much a pragmatist in a sense that's saying that we're very far away,\n\n20:47.200 --> 20:52.960\n that there's still, I think there's this idea that he says is, we can only see\n\n20:54.240 --> 20:59.280\n one or two mountain peaks ahead and there might be either a few more after or\n\n20:59.280 --> 21:01.920\n thousands more after. Yeah, so that kind of idea.\n\n21:01.920 --> 21:03.120\n I heard that metaphor.\n\n21:03.120 --> 21:13.520\n Yeah, right. But nevertheless, it doesn't see the final answer not fundamentally looking like one\n\n21:13.520 --> 21:18.160\n that we currently have. So, neural networks being a huge part of that.\n\n21:18.720 --> 21:25.520\n Yeah, I mean, that's very likely because pattern matching is so much of what's going on.\n\n21:26.400 --> 21:30.640\n And you can think of neural networks as processing information sequentially.\n\n21:30.640 --> 21:39.680\n Yeah, I mean, you know, there is an important aspect to, for example, you get systems that\n\n21:39.680 --> 21:44.640\n translate and they do a very good job, but they really don't know what they're talking about.\n\n21:45.760 --> 21:55.920\n And for that, I'm really quite surprised. For that, you would need an AI that has sensation,\n\n21:55.920 --> 21:58.000\n an AI that is in touch with the world.\n\n21:58.000 --> 22:04.480\n Yes, self awareness and maybe even something resembles consciousness kind of ideas.\n\n22:04.480 --> 22:10.640\n Certainly awareness of, you know, awareness of what's going on so that the words have meaning\n\n22:10.640 --> 22:15.680\n or can get, are in touch with some perception or some action.\n\n22:16.400 --> 22:23.920\n Yeah, so that's a big thing for Jan and as what he refers to as grounding to the physical space.\n\n22:23.920 --> 22:26.160\n So that's what we're talking about the same thing.\n\n22:26.160 --> 22:29.360\n Yeah, so how do you ground?\n\n22:29.360 --> 22:35.200\n I mean, the grounding, without grounding, then you get a machine that doesn't know what\n\n22:35.200 --> 22:39.680\n it's talking about because it is talking about the world ultimately.\n\n22:40.240 --> 22:43.600\n The question, the open question is what it means to ground. I mean, we're very\n\n22:44.880 --> 22:50.240\n human centric in our thinking, but what does it mean for a machine to understand what it means\n\n22:50.240 --> 22:57.280\n to be in this world? Does it need to have a body? Does it need to have a finiteness like we humans\n\n22:57.280 --> 23:02.240\n have all of these elements? It's a very, it's an open question.\n\n23:02.240 --> 23:05.920\n You know, I'm not sure about having a body, but having a perceptual system,\n\n23:05.920 --> 23:12.480\n having a body would be very helpful too. I mean, if you think about human, mimicking human,\n\n23:12.480 --> 23:19.360\n you know, but having a perception that seems to be essential so that you can build,\n\n23:20.080 --> 23:27.680\n you can accumulate knowledge about the world. So if you can imagine a human completely paralyzed,\n\n23:28.240 --> 23:33.520\n and there's a lot that the human brain could learn, you know, with a paralyzed body.\n\n23:33.520 --> 23:38.640\n So if we got a machine that could do that, that would be a big deal.\n\n23:38.640 --> 23:44.960\n TK And then the flip side of that, something you see in children and something in machine\n\n23:44.960 --> 23:51.040\n learning world is called active learning. Maybe it is also in, is being able to play with the world.\n\n23:52.640 --> 23:59.760\n How important for developing System 1 or System 2 do you think it is to play with the world?\n\n23:59.760 --> 24:00.960\n To be able to interact with the world?\n\n24:00.960 --> 24:08.960\n MG A lot of what you learn is you learn to anticipate the outcomes of your actions. I mean,\n\n24:08.960 --> 24:15.600\n you can see that how babies learn it, you know, with their hands, how they learn, you know,\n\n24:15.600 --> 24:20.640\n to connect, you know, the movements of their hands with something that clearly is something\n\n24:20.640 --> 24:28.320\n that happens in the brain and the ability of the brain to learn new patterns. So, you know,\n\n24:28.320 --> 24:34.880\n it's the kind of thing that you get with artificial limbs, that you connect it and then people learn\n\n24:34.880 --> 24:42.960\n to operate the artificial limb, you know, really impressively quickly, at least from what I hear.\n\n24:44.000 --> 24:47.760\n So we have a system that is ready to learn the world through action.\n\n24:49.040 --> 24:52.640\n TK At the risk of going into way too mysterious of land,\n\n24:52.640 --> 25:00.000\n what do you think it takes to build a system like that? Obviously, we're very far from understanding\n\n25:00.000 --> 25:08.000\n how the brain works, but how difficult is it to build this mind of ours?\n\n25:08.000 --> 25:13.200\n MG You know, I mean, I think that Jan LeCun's answer that we don't know how many mountains\n\n25:13.200 --> 25:20.080\n there are, I think that's a very good answer. I think that, you know, if you look at what Ray\n\n25:20.080 --> 25:28.800\n Kurzweil is saying, that strikes me as off the wall. But I think people are much more realistic\n\n25:28.800 --> 25:35.520\n than that, where actually Demis Hassabis is and Jan is, and so the people are actually doing the\n\n25:35.520 --> 25:41.440\n work fairly realistic, I think. TK To maybe phrase it another way,\n\n25:41.440 --> 25:44.960\n from a perspective not of building it, but from understanding it,\n\n25:44.960 --> 25:52.240\n how complicated are human beings in the following sense? You know, I work with autonomous vehicles\n\n25:52.240 --> 25:59.520\n and pedestrians, so we tried to model pedestrians. How difficult is it to model a human being,\n\n26:00.480 --> 26:06.080\n their perception of the world, the two systems they operate under, sufficiently to be able to\n\n26:06.080 --> 26:09.280\n predict whether the pedestrian is going to cross the road or not?\n\n26:09.280 --> 26:17.200\n MG I'm, you know, I'm fairly optimistic about that, actually, because what we're talking about\n\n26:18.000 --> 26:26.800\n is a huge amount of information that every vehicle has, and that feeds into one system,\n\n26:26.800 --> 26:33.440\n into one gigantic system. And so anything that any vehicle learns becomes part of what the whole\n\n26:33.440 --> 26:40.480\n system knows. And with a system multiplier like that, there is a lot that you can do.\n\n26:41.040 --> 26:48.560\n So human beings are very complicated, and the system is going to make mistakes, but human\n\n26:48.560 --> 26:56.400\n makes mistakes. I think that they'll be able to, I think they are able to anticipate pedestrians,\n\n26:56.400 --> 27:03.840\n otherwise a lot would happen. They're able to, you know, they're able to get into a roundabout\n\n27:04.640 --> 27:14.000\n and into traffic, so they must know both to expect or to anticipate how people will react\n\n27:14.000 --> 27:18.800\n when they're sneaking in. And there's a lot of learning that's involved in that.\n\n27:18.800 --> 27:28.080\n RL Currently, the pedestrians are treated as things that cannot be hit, and they're not\n\n27:28.080 --> 27:37.040\n treated as agents with whom you interact in a game theoretic way. So, I mean, it's not,\n\n27:37.040 --> 27:41.520\n it's a totally open problem, and every time somebody tries to solve it, it seems to be harder\n\n27:41.520 --> 27:46.640\n than we think. And nobody's really tried to seriously solve the problem of that dance,\n\n27:46.640 --> 27:52.080\n because I'm not sure if you've thought about the problem of pedestrians, but you're really\n\n27:52.080 --> 27:54.960\n putting your life in the hands of the driver.\n\n27:54.960 --> 27:59.760\n RL You know, there is a dance, there's part of the dance that would be quite complicated,\n\n28:00.320 --> 28:05.920\n but for example, when I cross the street and there is a vehicle approaching, I look the driver\n\n28:05.920 --> 28:13.360\n in the eye, and I think many people do that. And, you know, that's a signal that I'm sending,\n\n28:13.360 --> 28:18.480\n and I would be sending that machine to an autonomous vehicle, and it had better understand\n\n28:18.480 --> 28:20.720\n it, because it means I'm crossing.\n\n28:20.720 --> 28:26.240\n RL So, and there's another thing you do, that actually, so I'll tell you what you do,\n\n28:26.240 --> 28:31.440\n because we watched, I've watched hundreds of hours of video on this, is when you step\n\n28:31.440 --> 28:35.440\n in the street, you do that before you step in the street, and when you step in the street,\n\n28:35.440 --> 28:36.400\n you actually look away.\n\n28:36.400 --> 28:36.960\n RL Look away.\n\n28:36.960 --> 28:45.360\n RL Yeah. Now, what is that? What that's saying is, I mean, you're trusting that the car who\n\n28:45.360 --> 28:48.000\n hasn't slowed down yet will slow down.\n\n28:48.000 --> 28:53.680\n RL Yeah. And you're telling him, I'm committed. I mean, this is like in a game of chicken,\n\n28:53.680 --> 28:59.840\n so I'm committed, and if I'm committed, I'm looking away. So, there is, you just have\n\n28:59.840 --> 29:00.320\n to stop.\n\n29:00.320 --> 29:06.880\n RL So, the question is whether a machine that observes that needs to understand mortality.\n\n29:06.880 --> 29:16.480\n RL Here, I'm not sure that it's got to understand so much as it's got to anticipate. So, and\n\n29:17.120 --> 29:24.400\n here, but you know, you're surprising me, because here I would think that maybe you\n\n29:24.400 --> 29:30.560\n can anticipate without understanding, because I think this is clearly what's happening in\n\n29:30.560 --> 29:35.600\n playing go or in playing chess. There's a lot of anticipation, and there is zero understanding.\n\n29:35.600 --> 29:36.240\n RL Exactly.\n\n29:36.240 --> 29:46.400\n RL So, I thought that you didn't need a model of the human and a model of the human mind\n\n29:46.400 --> 29:50.880\n to avoid hitting pedestrians, but you are suggesting that actually\u2026\n\n29:50.880 --> 29:51.840\n RL There you go, yeah.\n\n29:51.840 --> 29:56.720\n RL You do. Then it's a lot harder, I thought.\n\n29:56.720 --> 30:02.560\n RL And I have a follow up question to see where your intuition lies. It seems that almost\n\n30:02.560 --> 30:10.800\n every robot human collaboration system is a lot harder than people realize. So, do you\n\n30:10.800 --> 30:17.200\n think it's possible for robots and humans to collaborate successfully? We talked a little\n\n30:17.200 --> 30:23.360\n bit about semi autonomous vehicles, like in the Tesla autopilot, but just in tasks in\n\n30:23.360 --> 30:30.160\n general. If you think we talked about current neural networks being kind of system one,\n\n30:30.160 --> 30:40.240\n do you think those same systems can borrow humans for system two type tasks and collaborate\n\n30:40.240 --> 30:40.880\n successfully?\n\n30:40.880 --> 30:49.520\n RL Well, I think that in any system where humans and the machine interact, the human\n\n30:49.520 --> 30:55.760\n will be superfluous within a fairly short time. That is, if the machine is advanced\n\n30:55.760 --> 31:01.600\n enough so that it can really help the human, then it may not need the human for a long\n\n31:01.600 --> 31:08.320\n time. Now, it would be very interesting if there are problems that for some reason the\n\n31:08.320 --> 31:14.240\n machine cannot solve, but that people could solve. Then you would have to build into the\n\n31:14.240 --> 31:22.080\n machine an ability to recognize that it is in that kind of problematic situation and\n\n31:22.080 --> 31:30.880\n to call the human. That cannot be easy without understanding. That is, it must be very difficult\n\n31:30.880 --> 31:38.400\n to program a recognition that you are in a problematic situation without understanding\n\n31:38.400 --> 31:39.440\n the problem.\n\n31:39.440 --> 31:47.360\n SL. That's very true. In order to understand the full scope of situations that are problematic,\n\n31:47.360 --> 31:51.680\n you almost need to be smart enough to solve all those problems.\n\n31:51.680 --> 32:01.120\n RL It's not clear to me how much the machine will need the human. I think the example of\n\n32:01.120 --> 32:06.160\n chess is very instructive. I mean, there was a time at which Kasparov was saying that human\n\n32:06.160 --> 32:13.440\n machine combinations will beat everybody. Even stockfish doesn't need people and Alpha\n\n32:13.440 --> 32:15.280\n Zero certainly doesn't need people.\n\n32:15.280 --> 32:20.880\n SL. The question is, just like you said, how many problems are like chess and how many\n\n32:20.880 --> 32:27.760\n problems are not like chess? Every problem probably in the end is like chess. The question\n\n32:27.760 --> 32:29.760\n is, how long is that transition period?\n\n32:29.760 --> 32:38.880\n RL That's a question I would ask you. Autonomous vehicle, just driving, is probably a lot more\n\n32:38.880 --> 32:47.840\n complicated than Go to solve that problem. Because it's open. That's not surprising to\n\n32:47.840 --> 32:58.960\n me because there is a hierarchical aspect to this, which is recognizing a situation\n\n32:58.960 --> 33:09.280\n and then within the situation bringing up the relevant knowledge. For that hierarchical\n\n33:09.280 --> 33:15.760\n type of system to work, you need a more complicated system than we currently have.\n\n33:15.760 --> 33:22.720\n SL. A lot of people think, because as human beings, this is probably the cognitive biases,\n\n33:22.720 --> 33:28.720\n they think of driving as pretty simple because they think of their own experience. This is\n\n33:28.720 --> 33:36.400\n actually a big problem for AI researchers or people thinking about AI because they evaluate\n\n33:36.400 --> 33:43.280\n how hard a particular problem is based on very limited knowledge, based on how hard\n\n33:43.280 --> 33:49.120\n it is for them to do the task. And then they take for granted, maybe you can speak to that\n\n33:49.120 --> 33:56.720\n because most people tell me driving is trivial and humans in fact are terrible at driving\n\n33:56.720 --> 34:02.040\n is what people tell me. And I see humans and humans are actually incredible at driving\n\n34:02.040 --> 34:08.520\n and driving is really terribly difficult. Is that just another element of the effects\n\n34:08.520 --> 34:13.680\n that you've described in your work on the psychology side?\n\n34:13.680 --> 34:22.000\n No, I mean, I haven't really, I would say that my research has contributed nothing to\n\n34:22.000 --> 34:27.800\n understanding the ecology and to understanding the structure of situations and the complexity\n\n34:27.800 --> 34:38.720\n of problems. So all we know is very clear that that goal, it's endlessly complicated,\n\n34:38.720 --> 34:46.840\n but it's very constrained. And in the real world, there are far fewer constraints and\n\n34:46.840 --> 34:49.320\n many more potential surprises.\n\n34:49.320 --> 34:54.720\n SL. So that's obvious because it's not always obvious to people, right? So when you think\n\n34:54.720 --> 34:55.720\n about\u2026\n\n34:55.720 --> 35:02.880\n Well, I mean, you know, people thought that reasoning was hard and perceiving was easy,\n\n35:02.880 --> 35:09.920\n but you know, they quickly learned that actually modeling vision was tremendously complicated\n\n35:09.920 --> 35:15.960\n and modeling, even proving theorems was relatively straightforward.\n\n35:15.960 --> 35:22.800\n To push back on that a little bit on the quickly part, it took several decades to learn that\n\n35:22.800 --> 35:28.400\n and most people still haven't learned that. I mean, our intuition, of course, AI researchers\n\n35:28.400 --> 35:34.760\n have, but you drift a little bit outside the specific AI field, the intuition is still\n\n35:34.760 --> 35:36.320\n perceptible to solve that.\n\n35:36.320 --> 35:41.280\n No, I mean, that's true. Intuitions, the intuitions of the public haven't changed\n\n35:41.280 --> 35:48.760\n radically. And they are, as you said, they're evaluating the complexity of problems by how\n\n35:48.760 --> 35:55.720\n difficult it is for them to solve the problems. And that's got very little to do with the\n\n35:55.720 --> 35:58.360\n complexities of solving them in AI.\n\n35:58.360 --> 36:06.120\n SL. How do you think from the perspective of an AI researcher, do we deal with the intuitions\n\n36:06.120 --> 36:15.080\n of the public? So in trying to think, arguably, the combination of hype investment and the\n\n36:15.080 --> 36:21.160\n public intuition is what led to the AI winters. I'm sure that same could be applied to tech\n\n36:21.160 --> 36:29.700\n or that the intuition of the public leads to media hype, leads to companies investing\n\n36:29.700 --> 36:36.700\n in the tech, and then the tech doesn't make the company's money. And then there's a crash.\n\n36:36.700 --> 36:43.280\n Is there a way to educate people to fight the, let's call it system one thinking?\n\n36:43.280 --> 36:54.600\n In general, no. I think that's the simple answer. And it's going to take a long time\n\n36:54.600 --> 37:09.240\n before the understanding of what those systems can do becomes public knowledge. And then\n\n37:09.240 --> 37:20.920\n the expectations, there are several aspects that are going to be very complicated. The\n\n37:20.920 --> 37:29.720\n fact that you have a device that cannot explain itself is a major, major difficulty. And we're\n\n37:29.720 --> 37:35.520\n already seeing that. I mean, this is really something that is happening. So it's happening\n\n37:35.520 --> 37:43.600\n in the judicial system. So you have system that are clearly better at predicting parole\n\n37:43.600 --> 37:54.220\n violations than judges, but they can't explain their reasoning. And so people don't want\n\n37:54.220 --> 37:56.040\n to trust them.\n\n37:56.040 --> 38:05.400\n We seem to in system one, even use cues to make judgements about our environment. So\n\n38:05.400 --> 38:11.040\n this explainability point, do you think humans can explain stuff?\n\n38:11.040 --> 38:20.400\n No, but I mean, there is a very interesting aspect of that. Humans think they can explain\n\n38:20.400 --> 38:28.160\n themselves. So when you say something and I ask you, why do you believe that? Then reasons\n\n38:28.160 --> 38:35.880\n will occur to you. But actually, my own belief is that in most cases, the reasons have very\n\n38:35.880 --> 38:41.880\n little to do with why you believe what you believe. So that the reasons are a story that\n\n38:41.880 --> 38:50.200\n comes to your mind when you need to explain yourself. But people traffic in those explanations\n\n38:50.200 --> 38:56.680\n I mean, the human interaction depends on those shared fictions and, and the stories that\n\n38:56.680 --> 38:58.580\n people tell themselves.\n\n38:58.580 --> 39:05.960\n You just made me actually realize and we'll talk about stories in a second. That not to\n\n39:05.960 --> 39:11.520\n be cynical about it, but perhaps there's a whole movement of people trying to do explainable\n\n39:11.520 --> 39:19.360\n AI. And really, we don't necessarily need to explain AI doesn't need to explain itself.\n\n39:19.360 --> 39:21.880\n It just needs to tell a convincing story.\n\n39:21.880 --> 39:23.560\n Yeah, absolutely.\n\n39:23.560 --> 39:29.160\n It doesn't necessarily, the story doesn't necessarily need to reflect the truth as it\n\n39:29.160 --> 39:32.800\n might, it just needs to be convincing. There's something to that.\n\n39:32.800 --> 39:38.840\n You can say exactly the same thing in a way that sounds cynical or doesn't sound cynical.\n\n39:38.840 --> 39:39.840\n Right.\n\n39:39.840 --> 39:48.000\n But the objective of having an explanation is to tell a story that will be acceptable\n\n39:48.000 --> 39:56.360\n to people. And, and, and for it to be acceptable and to be robustly acceptable, it has to have\n\n39:56.360 --> 40:04.480\n some elements of truth. But, but the objective is for people to accept it.\n\n40:04.480 --> 40:11.720\n It's quite brilliant, actually. But so on the, on the stories that we tell, sorry to\n\n40:11.720 --> 40:18.000\n ask me, ask you the question that most people know the answer to, but you talk about two\n\n40:18.000 --> 40:24.780\n selves in terms of how life is lived, the experienced self and remembering self. Can\n\n40:24.780 --> 40:26.920\n you describe the distinction between the two?\n\n40:26.920 --> 40:33.680\n Well, sure. I mean, the, there is an aspect of, of life that occasionally, you know, most\n\n40:33.680 --> 40:38.520\n of the time we just live and we have experiences and they're better and they're worse and it\n\n40:38.520 --> 40:45.760\n goes on over time. And mostly we forget everything that happens or we forget most of what happens.\n\n40:45.760 --> 40:56.280\n Then occasionally you, when something ends or at different points, you evaluate the past\n\n40:56.280 --> 41:03.560\n and you form a memory and the memory is schematic. It's not that you can roll a film of an interaction.\n\n41:03.560 --> 41:12.960\n You construct, in effect, the elements of a story about an, about an episode. So there\n\n41:12.960 --> 41:18.360\n is the experience and there is the story that is created about the experience. And that's\n\n41:18.360 --> 41:24.320\n what I call the remembering. So I had the image of two selves. So there is a self that\n\n41:24.320 --> 41:32.200\n lives and there is a self that evaluates life. Now the paradox and the deep paradox in that\n\n41:32.200 --> 41:41.960\n is that we have one system or one self that does the living, but the other system, the\n\n41:41.960 --> 41:49.180\n remembering self is all we get to keep. And basically decision making and, and everything\n\n41:49.180 --> 41:55.000\n that we do is governed by our memories, not by what actually happened. It's, it's governed\n\n41:55.000 --> 42:02.280\n by, by the story that we told ourselves or by the story that we're keeping. So that's,\n\n42:02.280 --> 42:03.280\n that's the distinction.\n\n42:03.280 --> 42:08.000\n I mean, there's a lot of brilliant ideas about the pursuit of happiness that come out of\n\n42:08.000 --> 42:14.160\n that. What are the properties of happiness which emerge from a remembering self?\n\n42:14.160 --> 42:19.160\n There are, there are properties of how we construct stories that are really important.\n\n42:19.160 --> 42:29.720\n So that I studied a few, but, but a couple are really very striking. And one is that\n\n42:29.720 --> 42:37.080\n in stories, time doesn't matter. There's a sequence of events or there are highlights\n\n42:37.080 --> 42:45.240\n or not. And, and how long it took, you know, they lived happily ever after or three years\n\n42:45.240 --> 42:53.480\n later or something. It, time really doesn't matter. And in stories, events matter, but\n\n42:53.480 --> 43:03.740\n time doesn't. That, that leads to a very interesting set of problems because time is all we got\n\n43:03.740 --> 43:11.040\n to live. I mean, you know, time is the currency of life. And yet time is not represented basically\n\n43:11.040 --> 43:18.520\n in evaluated memories. So that, that creates a lot of paradoxes that I've thought about.\n\n43:18.520 --> 43:27.520\n Yeah. They're fascinating. But if you were to give advice on how one lives a happy life\n\n43:27.520 --> 43:33.120\n based on such properties, what's the optimal?\n\n43:33.120 --> 43:38.880\n You know, I gave up, I abandoned happiness research because I couldn't solve that problem.\n\n43:38.880 --> 43:46.160\n I couldn't, I couldn't see. And in the first place, it's very clear that if you do talk\n\n43:46.160 --> 43:51.520\n in terms of those two selves, then that what makes the remembering self happy and what\n\n43:51.520 --> 43:59.320\n makes the experiencing self happy are different things. And I, I asked the question of, suppose\n\n43:59.320 --> 44:04.160\n you're planning a vacation and you're just told that at the end of the vacation, you'll\n\n44:04.160 --> 44:10.160\n get an amnesic drug, so you remember nothing. And they'll also destroy all your photos.\n\n44:10.160 --> 44:20.640\n So there'll be nothing. Would you still go to the same vacation? And, and it's, it turns\n\n44:20.640 --> 44:26.600\n out we go to vacations in large part to construct memories, not to have experiences, but to\n\n44:26.600 --> 44:32.520\n construct memories. And it turns out that the vacation that you would want for yourself,\n\n44:32.520 --> 44:38.080\n if you knew, you will not remember is probably not the same vacation that you will want for\n\n44:38.080 --> 44:46.240\n yourself if you will remember. So I have no solution to these problems, but clearly those\n\n44:46.240 --> 44:47.240\n are big issues.\n\n44:47.240 --> 44:53.060\n And you've talked about, you've talked about sort of how many minutes or hours you spend\n\n44:53.060 --> 44:58.120\n about the vacation. It's an interesting way to think about it because that's how you really\n\n44:58.120 --> 45:03.640\n experience the vacation outside the being in it. But there's also a modern, I don't\n\n45:03.640 --> 45:11.440\n know if you think about this or interact with it. There's a modern way to, um, magnify the\n\n45:11.440 --> 45:17.820\n remembering self, which is by posting on Instagram, on Twitter, on social networks. A lot of people\n\n45:17.820 --> 45:24.680\n live life for the picture that you take, that you post somewhere. And now thousands of people\n\n45:24.680 --> 45:29.040\n share and potentially potentially millions. And then you can relive it even much more\n\n45:29.040 --> 45:34.280\n than just those minutes. Do you think about that magnification much?\n\n45:34.280 --> 45:41.960\n You know, I'm too old for social networks. I, you know, I've never seen Instagram, so\n\n45:41.960 --> 45:46.640\n I cannot really speak intelligently about those things. I'm just too old.\n\n45:46.640 --> 45:49.840\n But it's interesting to watch the exact effects you've described.\n\n45:49.840 --> 45:55.560\n Make a very big difference. I mean, and it will make, it will also make a difference.\n\n45:55.560 --> 46:06.040\n And that I don't know whether, uh, it's clear that in some ways the devices that serve us\n\n46:06.040 --> 46:12.960\n are supplant functions. So you don't have to remember phone numbers. You don't have,\n\n46:12.960 --> 46:19.080\n you really don't have to know facts. I mean, the number of conversations I'm involved with,\n\n46:19.080 --> 46:27.640\n somebody says, well, let's look it up. Uh, so it's, it's in a way it's made conversations.\n\n46:27.640 --> 46:33.360\n Well it's, it means that it's much less important to know things. You know, it used to be very\n\n46:33.360 --> 46:43.200\n important to know things. This is changing. So the requirements of that, that we have\n\n46:43.200 --> 46:50.560\n for ourselves and for other people are changing because of all those supports and because,\n\n46:50.560 --> 46:57.600\n and I have no idea what Instagram does, but it's, uh, well, I'll tell you, I wish I could\n\n46:57.600 --> 47:03.600\n just have the, my remembering self could enjoy this conversation, but I'll get to enjoy it\n\n47:03.600 --> 47:08.520\n even more by having watched, by watching it and then talking to others. It'll be about\n\n47:08.520 --> 47:14.880\n a hundred thousand people as scary as this to say, well, listen or watch this, right?\n\n47:14.880 --> 47:20.320\n It changes things. It changes the experience of the world that you seek out experiences\n\n47:20.320 --> 47:25.920\n which could be shared in that way. It's in, and I haven't seen, it's, it's the same effects\n\n47:25.920 --> 47:30.760\n that you described. And I don't think the psychology of that magnification has been\n\n47:30.760 --> 47:33.240\n described yet because it's a new world.\n\n47:33.240 --> 47:43.240\n But the sharing, there was a, there was a time when people read books and, uh, and,\n\n47:43.240 --> 47:51.140\n and you could assume that your friends had read the same books that you read. So there\n\n47:51.140 --> 47:57.760\n was kind of invisible sharing. There was a lot of sharing going on and there was a lot\n\n47:57.760 --> 48:03.780\n of assumed common knowledge and, you know, that was built in. I mean, it was obvious\n\n48:03.780 --> 48:09.520\n that you had read the New York Times. It was obvious that you had read the reviews. I mean,\n\n48:09.520 --> 48:17.040\n so a lot was taken for granted that was shared. And, you know, when there were, when there\n\n48:17.040 --> 48:26.000\n were three television channels, it was obvious that you'd seen one of them probably the same.\n\n48:26.000 --> 48:32.400\n So sharing, sharing always was always there. It was just different.\n\n48:32.400 --> 48:40.920\n At the risk of, uh, inviting mockery from you, let me say that I'm also a fan of Sartre\n\n48:40.920 --> 48:47.560\n and Camus and existentialist philosophers. And, um, I'm joking of course about mockery,\n\n48:47.560 --> 48:54.180\n but from the perspective of the two selves, what do you think of the existentialist philosophy\n\n48:54.180 --> 49:03.680\n of life? So trying to really emphasize the experiencing self as the proper way to, or\n\n49:03.680 --> 49:05.960\n the best way to live life.\n\n49:05.960 --> 49:13.600\n I don't know enough philosophy to answer that, but it's not, uh, you know, the emphasis on,\n\n49:13.600 --> 49:16.760\n on experience is also the emphasis in Buddhism.\n\n49:16.760 --> 49:18.040\n Yeah, right. That's right.\n\n49:18.040 --> 49:27.280\n So, uh, that's, you just have got to, to experience things and, and, and not to evaluate and not\n\n49:27.280 --> 49:33.560\n to pass judgment and not to score, not to keep score. So, uh,\n\n49:33.560 --> 49:37.760\n If, when you look at the grand picture of experience, you think there's something to\n\n49:37.760 --> 49:44.480\n that, that one, one of the ways to achieve contentment and maybe even happiness is letting\n\n49:44.480 --> 49:51.800\n go of any of the things, any of the procedures of the remembering self.\n\n49:51.800 --> 49:58.080\n Well, yeah, I mean, I think, you know, if one could imagine a life in which people don't\n\n49:58.080 --> 50:05.960\n score themselves, uh, it, it feels as if that would be a better life as if the self scoring\n\n50:05.960 --> 50:18.040\n and you know, how am I doing a kind of question, uh, is not, is not a very happy thing to have.\n\n50:18.040 --> 50:25.360\n But I got out of that field because I couldn't solve that problem and, and that was because\n\n50:25.360 --> 50:31.500\n my intuition was that the experiencing self, that's reality.\n\n50:31.500 --> 50:36.560\n But then it turns out that what people want for themselves is not experiences. They want\n\n50:36.560 --> 50:41.600\n memories and they want a good story about their life. And so you cannot have a theory\n\n50:41.600 --> 50:47.880\n of happiness that doesn't correspond to what people want for themselves. And when I, when\n\n50:47.880 --> 50:53.760\n I realized that this, this was where things were going, I really sort of left the field\n\n50:53.760 --> 50:54.760\n of research.\n\n50:54.760 --> 51:01.100\n Do you think there's something instructive about this emphasis of reliving memories in\n\n51:01.100 --> 51:09.200\n building AI systems. So currently artificial intelligence systems are more like experiencing\n\n51:09.200 --> 51:16.280\n self in that they react to the environment. There's some pattern formation like a learning\n\n51:16.280 --> 51:23.120\n so on, but you really don't construct memories, uh, except in reinforcement learning every\n\n51:23.120 --> 51:25.720\n once in a while that you replay over and over.\n\n51:25.720 --> 51:30.280\n Yeah, but you know, that would in principle would not be.\n\n51:30.280 --> 51:36.000\n Do you think that's useful? Do you think it's a feature or a bug of human beings that we,\n\n51:36.000 --> 51:37.000\n that we look back?\n\n51:37.000 --> 51:43.360\n Oh, I think that's definitely a feature. That's not a bug. I mean, you, you have to look back\n\n51:43.360 --> 51:50.440\n in order to look forward. So, uh, without, without looking back, you couldn't, you couldn't\n\n51:50.440 --> 51:53.080\n really intelligently look forward.\n\n51:53.080 --> 51:57.080\n You're looking for the echoes of the same kind of experience in order to predict what\n\n51:57.080 --> 51:58.080\n the future holds.\n\n51:58.080 --> 51:59.080\n Yeah.\n\n51:59.080 --> 52:05.320\n So though Victor Frankel in his book, man's search for meaning, I'm not sure if you've\n\n52:05.320 --> 52:10.720\n read, describes his experience at the consecration concentration camps during world war two as\n\n52:10.720 --> 52:18.480\n a way to describe that finding identifying a purpose in life, a positive purpose in life\n\n52:18.480 --> 52:23.840\n can save one from suffering. First of all, do you connect with the philosophy that he\n\n52:23.840 --> 52:28.420\n describes there?\n\n52:28.420 --> 52:37.040\n Not really. I mean, the, so I can, I can really see that somebody who has that feeling of\n\n52:37.040 --> 52:44.640\n purpose and meaning and so on, that, that could sustain you. Uh, I in general don't\n\n52:44.640 --> 52:50.800\n have that feeling and I'm pretty sure that if I were in a concentration camp, I'd give\n\n52:50.800 --> 52:56.240\n up and die, you know? So he talks, he is, he is a survivor.\n\n52:56.240 --> 52:57.240\n Yeah.\n\n52:57.240 --> 53:04.000\n And, you know, he survived with that. And I'm, and I'm not sure how essential to survival\n\n53:04.000 --> 53:12.220\n this sense is, but I do know when I think about myself that I would have given up. Oh,\n\n53:12.220 --> 53:20.140\n this isn't going anywhere. And there is, there is a sort of character that, that, that manages\n\n53:20.140 --> 53:26.120\n to survive in conditions like that. And then because they survive, they tell stories and\n\n53:26.120 --> 53:31.840\n it sounds as if they survive because of what they were doing. We have no idea. They survived\n\n53:31.840 --> 53:36.240\n because the kind of people that they are and the other kind of people who survives and\n\n53:36.240 --> 53:41.800\n would tell themselves stories of a particular kind. So I'm not, uh,\n\n53:41.800 --> 53:46.840\n So you don't think seeking purpose is a significant driver in our being?\n\n53:46.840 --> 53:52.400\n Oh, I mean, it's, it's a very interesting question because when you ask people whether\n\n53:52.400 --> 53:56.240\n it's very important to have meaning in their life, they say, oh yes, that's the most important\n\n53:56.240 --> 54:03.880\n thing. But when you ask people, what kind of a day did you have? And, and you know,\n\n54:03.880 --> 54:10.320\n what were the experiences that you remember? You don't get much meaning. You get social\n\n54:10.320 --> 54:21.480\n experiences. Then, uh, and, and some people say that, for example, in, in, in child, you\n\n54:21.480 --> 54:25.720\n know, in taking care of children, the fact that they are your children and you're taking\n\n54:25.720 --> 54:34.040\n care of them, uh, makes a very big difference. I think that's entirely true. Uh, but it's\n\n54:34.040 --> 54:40.560\n more because of a story that we're telling ourselves, which is a very different story\n\n54:40.560 --> 54:45.140\n when we're taking care of our children or when we're taking care of other things.\n\n54:45.140 --> 54:50.880\n Jumping around a little bit in doing a lot of experiments, let me ask a question. Most\n\n54:50.880 --> 54:56.840\n of the work I do, for example, is in the, in the real world, but most of the clean good\n\n54:56.840 --> 55:04.480\n science that you can do is in the lab. So that distinction, do you think we can understand\n\n55:04.480 --> 55:12.680\n the fundamentals of human behavior through controlled experiments in the lab? If we talk\n\n55:12.680 --> 55:18.920\n about pupil diameter, for example, it's much easier to do when you can control lighting\n\n55:18.920 --> 55:27.680\n conditions, right? So when we look at driving, lighting variation destroys almost completely\n\n55:27.680 --> 55:34.740\n your ability to use pupil diameter. But in the lab for, as I mentioned, semi autonomous\n\n55:34.740 --> 55:43.080\n or autonomous vehicles in driving simulators, we can't, we don't capture true, honest, uh,\n\n55:43.080 --> 55:49.000\n human behavior in that particular domain. So what's your intuition? How much of human\n\n55:49.000 --> 55:56.160\n behavior can we study in this controlled environment of the lab? A lot, but you'd have to verify\n\n55:56.160 --> 56:03.240\n it, you know, that your, your conclusions are basically limited to the situation, to\n\n56:03.240 --> 56:09.000\n the experimental situation. Then you have to jump the big inductive leap to the real\n\n56:09.000 --> 56:17.920\n world. Uh, so, and, and that's the flare. That's where the difference, I think, between\n\n56:17.920 --> 56:25.840\n the good psychologists and others that are mediocre is in the sense of that your experiment\n\n56:25.840 --> 56:33.520\n captures something that's important and something that's real and others are just running experiments.\n\n56:33.520 --> 56:39.000\n So what is that? Like the birth of an idea to his development in your mind to something\n\n56:39.000 --> 56:44.840\n that leads to an experiment. Is that similar to maybe like what Einstein or a good physicist\n\n56:44.840 --> 56:48.840\n do is your intuition. You basically use your intuition to build up.\n\n56:48.840 --> 56:54.280\n Yeah, but I mean, you know, it's, it's very skilled intuition. I mean, I just had that\n\n56:54.280 --> 57:00.840\n experience actually. I had an idea that turns out to be very good idea a couple of days\n\n57:00.840 --> 57:08.400\n ago and, and you, and you have a sense of that building up. So I'm working with a collaborator\n\n57:08.400 --> 57:14.280\n and he essentially was saying, you know, what, what are you doing? What's, what's going on?\n\n57:14.280 --> 57:21.000\n And I was, I really, I couldn't exactly explain it, but I knew this is going somewhere, but\n\n57:21.000 --> 57:26.920\n you know, I've been around that game for a very long time. And so I can, you, you develop\n\n57:26.920 --> 57:34.640\n that anticipation that yes, this, this is worth following up. That's part of the skill.\n\n57:34.640 --> 57:41.560\n Is that something you can reduce to words in describing a process in the form of advice\n\n57:41.560 --> 57:42.560\n to others?\n\n57:42.560 --> 57:43.560\n No.\n\n57:43.560 --> 57:45.560\n Follow your heart, essentially.\n\n57:45.560 --> 57:51.680\n I mean, you know, it's, it's like trying to explain what it's like to drive. It's not,\n\n57:51.680 --> 57:54.140\n you've got to break it apart and it's not.\n\n57:54.140 --> 57:55.140\n And then you lose.\n\n57:55.140 --> 57:58.080\n And then you lose the experience.\n\n57:58.080 --> 58:05.140\n You mentioned collaboration. You've written about your collaboration with Amos Tversky\n\n58:05.140 --> 58:10.780\n that this is you writing, the 12 or 13 years in which most of our work was joint were years\n\n58:10.780 --> 58:16.720\n of interpersonal and intellectual bliss. Everything was interesting. Almost everything\n\n58:16.720 --> 58:22.080\n was funny. And there was a current joy of seeing an idea take shape. So many times in\n\n58:22.080 --> 58:27.320\n those years, we shared the magical experience of one of us saying something, which the other\n\n58:27.320 --> 58:32.520\n one would understand more deeply than the speaker had done. Contrary to the old laws\n\n58:32.520 --> 58:38.000\n of information theory, it was common for us to find that more information was received\n\n58:38.000 --> 58:43.860\n than had been sent. I have almost never had the experience with anyone else. If you have\n\n58:43.860 --> 58:49.120\n not had it, you don't know how marvelous collaboration can be.\n\n58:49.120 --> 58:58.840\n So let me ask a perhaps a silly question. How does one find and create such a collaboration?\n\n58:58.840 --> 59:01.120\n That may be asking like, how does one find love?\n\n59:01.120 --> 59:10.600\n Yeah, you have to be lucky. And I think you have to have the character for that because\n\n59:10.600 --> 59:17.600\n I've had many collaborations. I mean, none were as exciting as with Amos, but I've had\n\n59:17.600 --> 59:27.040\n and I'm having just very. So it's a skill. I think I'm good at it. Not everybody is good\n\n59:27.040 --> 59:32.100\n at it. And then it's the luck of finding people who are also good at it.\n\n59:32.100 --> 59:39.420\n Is there advice in a form for a young scientist who also seeks to violate this law of information\n\n59:39.420 --> 59:48.520\n theory?\n\n59:48.520 --> 59:59.560\n I really think it's so much luck is involved. And in those really serious collaborations,\n\n59:59.560 --> 1:00:06.660\n at least in my experience, are a very personal experience. And I have to like the person\n\n1:00:06.660 --> 1:00:13.280\n I'm working with. Otherwise, I mean, there is that kind of collaboration, which is like\n\n1:00:13.280 --> 1:00:21.880\n an exchange, a commercial exchange of giving this, you give me that. But the real ones\n\n1:00:21.880 --> 1:00:28.080\n are interpersonal. They're between people who like each other and who like making each\n\n1:00:28.080 --> 1:00:34.400\n other think and who like the way that the other person responds to your thoughts. You\n\n1:00:34.400 --> 1:00:37.080\n have to be lucky.\n\n1:00:37.080 --> 1:00:43.760\n But I already noticed that even just me showing up here, you've quickly started to digging\n\n1:00:43.760 --> 1:00:49.840\n in on a particular problem I'm working on and already new information started to emerge.\n\n1:00:49.840 --> 1:00:56.420\n Is that a process, just the process of curiosity of talking to people about problems and seeing?\n\n1:00:56.420 --> 1:01:03.400\n I'm curious about anything to do with AI and robotics. And I knew you were dealing with\n\n1:01:03.400 --> 1:01:05.240\n that. So I was curious.\n\n1:01:05.240 --> 1:01:13.100\n Just follow your curiosity. Jumping around on the psychology front, the dramatic sounding\n\n1:01:13.100 --> 1:01:24.960\n terminology of replication crisis, but really just the, at times, this effect that at times\n\n1:01:24.960 --> 1:01:29.240\n studies do not, are not fully generalizable. They don't.\n\n1:01:29.240 --> 1:01:33.040\n You are being polite. It's worse than that.\n\n1:01:33.040 --> 1:01:39.360\n Is it? So I'm actually not fully familiar to the degree how bad it is, right? So what\n\n1:01:39.360 --> 1:01:41.520\n do you think is the source? Where do you think?\n\n1:01:41.520 --> 1:01:47.520\n I think I know what's going on actually. I mean, I have a theory about what's going on\n\n1:01:47.520 --> 1:01:55.460\n and what's going on is that there is, first of all, a very important distinction between\n\n1:01:55.460 --> 1:02:03.120\n two types of experiments. And one type is within subject. So it's the same person has\n\n1:02:03.120 --> 1:02:09.200\n two experimental conditions. And the other type is between subjects where some people\n\n1:02:09.200 --> 1:02:14.160\n are this condition, other people are that condition. They're different worlds. And between\n\n1:02:14.160 --> 1:02:25.560\n subject experiments are much harder to predict and much harder to anticipate. And the reason,\n\n1:02:25.560 --> 1:02:31.880\n and they're also more expensive because you need more people. And it's just, so between\n\n1:02:31.880 --> 1:02:38.600\n subject experiments is where the problem is. It's not so much in within subject experiments,\n\n1:02:38.600 --> 1:02:46.920\n it's really between. And there is a very good reason why the intuitions of researchers about\n\n1:02:46.920 --> 1:02:54.180\n between subject experiments are wrong. And that's because when you are a researcher,\n\n1:02:54.180 --> 1:03:00.560\n you're in a within subject situation. That is you are imagining the two conditions and\n\n1:03:00.560 --> 1:03:09.680\n you see the causality and you feel it. But in the between subject condition, they live\n\n1:03:09.680 --> 1:03:18.440\n in one condition and the other one is just nowhere. So our intuitions are very weak about\n\n1:03:18.440 --> 1:03:26.520\n between subject experiments. And that I think is something that people haven't realized.\n\n1:03:26.520 --> 1:03:34.800\n And in addition, because of that, we have no idea about the power of manipulations of\n\n1:03:34.800 --> 1:03:42.420\n experimental manipulations because the same manipulation is much more powerful when you\n\n1:03:42.420 --> 1:03:48.880\n are in the two conditions than when you live in only one condition. And so the experimenters\n\n1:03:48.880 --> 1:03:56.760\n have very poor intuitions about between subject experiments. And there is something else which\n\n1:03:56.760 --> 1:04:04.080\n is very important, I think, which is that almost all psychological hypotheses are true.\n\n1:04:04.080 --> 1:04:13.200\n That is in the sense that, you know, directionally, if you have a hypothesis that A really causes\n\n1:04:13.200 --> 1:04:21.000\n B, that it's not true that A causes the opposite of B. Maybe A just has very little effect,\n\n1:04:21.000 --> 1:04:28.840\n but hypotheses are true mostly, except mostly they're very weak. They're much weaker than\n\n1:04:28.840 --> 1:04:38.000\n you think when you are having images. So the reason I'm excited about that is that I recently\n\n1:04:38.000 --> 1:04:50.560\n heard about some friends of mine who they essentially funded 53 studies of behavioral\n\n1:04:50.560 --> 1:04:59.420\n change by 20 different teams of people with a very precise objective of changing the number\n\n1:04:59.420 --> 1:05:12.600\n of times that people go to the gym. And the success rate was zero. Not one of the 53 studies\n\n1:05:12.600 --> 1:05:18.160\n worked. Now, what's interesting about that is those are the best people in the field\n\n1:05:18.160 --> 1:05:24.440\n and they have no idea what's going on. So they're not calibrated. They think that it's\n\n1:05:24.440 --> 1:05:30.760\n going to be powerful because they can imagine it, but actually it's just weak because you\n\n1:05:30.760 --> 1:05:37.880\n are focusing on your manipulation and it feels powerful to you. There's a thing that I've\n\n1:05:37.880 --> 1:05:43.480\n written about that's called the focusing illusion. That is that when you think about something,\n\n1:05:43.480 --> 1:05:48.400\n it looks very important, more important than it really is.\n\n1:05:48.400 --> 1:05:53.800\n More important than it really is. But if you don't see that effect, the 53 studies, doesn't\n\n1:05:53.800 --> 1:05:59.320\n that mean you just report that? So what was, I guess, the solution to that?\n\n1:05:59.320 --> 1:06:07.600\n Well, I mean, the solution is for people to trust their intuitions less or to try out\n\n1:06:07.600 --> 1:06:14.760\n their intuitions before. I mean, experiments have to be pre registered and by the time\n\n1:06:14.760 --> 1:06:20.960\n you run an experiment, you have to be committed to it and you have to run the experiment seriously\n\n1:06:20.960 --> 1:06:32.800\n enough and in a public. And so this is happening. The interesting thing is what happens before\n\n1:06:32.800 --> 1:06:37.920\n and how do people prepare themselves and how they run pilot experiments. It's going to\n\n1:06:37.920 --> 1:06:41.360\n train the way psychology is done and it's already happening.\n\n1:06:41.360 --> 1:06:48.520\n Do you have a hope for, this might connect to the study sample size.\n\n1:06:48.520 --> 1:06:49.520\n Yeah.\n\n1:06:49.520 --> 1:06:51.320\n Do you have a hope for the internet?\n\n1:06:51.320 --> 1:06:59.040\n Well, I mean, you know, this is really happening. MTurk, everybody's running experiments on\n\n1:06:59.040 --> 1:07:03.640\n MTurk and it's very cheap and very effective.\n\n1:07:03.640 --> 1:07:09.200\n Do you think that changes psychology essentially? Because you're thinking you cannot run 10,000\n\n1:07:09.200 --> 1:07:10.200\n subjects.\n\n1:07:10.200 --> 1:07:18.480\n Eventually it will. I mean, I, you know, I can't put my finger on how exactly, but it's,\n\n1:07:18.480 --> 1:07:24.880\n that's been true in psychology with whenever an important new method came in, it changes\n\n1:07:24.880 --> 1:07:33.160\n the field. So, and MTurk is really a method because it makes it very much easier to do\n\n1:07:33.160 --> 1:07:35.520\n something, to do some things.\n\n1:07:35.520 --> 1:07:40.680\n Is there a undergrad students who'll ask me, you know, how big a neural network should\n\n1:07:40.680 --> 1:07:49.080\n be for a particular problem? So let me ask you an equivalent question. How big, how many\n\n1:07:49.080 --> 1:07:53.560\n subjects does the study have for it to have a conclusive result?\n\n1:07:53.560 --> 1:08:00.760\n Well, it depends on the strength of the effect. So if you're studying visual perception or\n\n1:08:00.760 --> 1:08:08.600\n the perception of color, many of the classic results in visual, in color perception were\n\n1:08:08.600 --> 1:08:14.600\n done on three or four people. And I think one of them was colorblind, but partly colorblind,\n\n1:08:14.600 --> 1:08:24.820\n but on vision, you know, it's highly reliable. Many people don't need a lot of replications\n\n1:08:24.820 --> 1:08:35.800\n for some type of neurological experiment. When you're studying weaker phenomena and\n\n1:08:35.800 --> 1:08:41.120\n especially when you're studying them between subjects, then you need a lot more subjects\n\n1:08:41.120 --> 1:08:47.000\n than people have been running. And that is, that's one of the things that are happening\n\n1:08:47.000 --> 1:08:54.220\n in psychology now is that the power, the statistical power of experiments is increasing rapidly.\n\n1:08:54.220 --> 1:08:59.200\n Does the between subject, as the number of subjects goes to infinity approach?\n\n1:08:59.200 --> 1:09:06.440\n Well, I mean, you know, it goes to infinity is exaggerated, but people, the standard number\n\n1:09:06.440 --> 1:09:15.040\n of subjects for an experiment in psychology were 30 or 40. And for a weak effect, that's\n\n1:09:15.040 --> 1:09:25.720\n simply not enough. And you may need a couple of hundred. I mean, it's that sort of order\n\n1:09:25.720 --> 1:09:28.760\n of magnitude.\n\n1:09:28.760 --> 1:09:35.840\n What are the major disagreements in theories and effects that you've observed throughout\n\n1:09:35.840 --> 1:09:42.520\n your career that still stand today? You've worked on several fields, but what still is\n\n1:09:42.520 --> 1:09:47.320\n out there as a major disagreement that pops into your mind?\n\n1:09:47.320 --> 1:09:54.840\n I've had one extreme experience of, you know, controversy with somebody who really doesn't\n\n1:09:54.840 --> 1:10:01.720\n like the work that Amos Tversky and I did. And he's been after us for 30 years or more,\n\n1:10:01.720 --> 1:10:02.720\n at least.\n\n1:10:02.720 --> 1:10:03.720\n Do you want to talk about it?\n\n1:10:03.720 --> 1:10:10.400\n Well, I mean, his name is Gerd Gigerenzer. He's a well known German psychologist. And\n\n1:10:10.400 --> 1:10:18.960\n that's the one controversy, which I, it's been unpleasant. And no, I don't particularly\n\n1:10:18.960 --> 1:10:21.040\n want to talk about it.\n\n1:10:21.040 --> 1:10:25.680\n But is there is there open questions, even in your own mind, every once in a while? You\n\n1:10:25.680 --> 1:10:31.640\n know, we talked about semi autonomous vehicles. In my own mind, I see what the data says,\n\n1:10:31.640 --> 1:10:38.200\n but I also constantly torn. Do you have things where you or your studies have found something,\n\n1:10:38.200 --> 1:10:44.800\n but you're also intellectually torn about what it means? And there's maybe disagreements\n\n1:10:44.800 --> 1:10:47.560\n within your own mind about particular things.\n\n1:10:47.560 --> 1:10:52.280\n I mean, it's, you know, one of the things that are interesting is how difficult it is\n\n1:10:52.280 --> 1:11:00.440\n for people to change their mind. Essentially, you know, once they are committed, people\n\n1:11:00.440 --> 1:11:05.600\n just don't change their mind about anything that matters. And that is surprisingly, but\n\n1:11:05.600 --> 1:11:12.240\n it's true about scientists. So the controversy that I described, you know, that's been going\n\n1:11:12.240 --> 1:11:19.000\n on like 30 years and it's never going to be resolved. And you build a system and you live\n\n1:11:19.000 --> 1:11:27.000\n within that system and other other systems of ideas look foreign to you and there is\n\n1:11:27.000 --> 1:11:33.400\n very little contact and very little mutual influence. That happens a fair amount.\n\n1:11:33.400 --> 1:11:41.000\n Do you have a hopeful advice or message on that? Thinking about science, thinking about\n\n1:11:41.000 --> 1:11:47.840\n politics, thinking about things that have impact on this world, how can we change our\n\n1:11:47.840 --> 1:11:49.760\n mind?\n\n1:11:49.760 --> 1:11:56.920\n I think that, I mean, on things that matter, which are political or really political or\n\n1:11:56.920 --> 1:12:04.360\n religious and people just don't, don't change their mind. And by and large, and there's\n\n1:12:04.360 --> 1:12:13.360\n very little that you can do about it. The, what does happen is that if leaders change\n\n1:12:13.360 --> 1:12:19.840\n their minds. So for example, the public, the American public doesn't really believe in\n\n1:12:19.840 --> 1:12:26.920\n climate change, doesn't take it very seriously. But if some religious leaders decided this\n\n1:12:26.920 --> 1:12:34.600\n is a major threat to humanity, that would have a big effect. So that we have the opinions\n\n1:12:34.600 --> 1:12:39.840\n that we have, not because we know why we have them, but because we trust some people and\n\n1:12:39.840 --> 1:12:49.120\n we don't trust other people. And so it's much less about evidence than it is about stories.\n\n1:12:49.120 --> 1:12:55.040\n So the way, one way to change your mind isn't at the individual level, is that the leaders\n\n1:12:55.040 --> 1:12:59.640\n of the communities you look up with, the stories change and therefore your mind changes with\n\n1:12:59.640 --> 1:13:08.400\n them. So there's a guy named Alan Turing, came up with a Turing test. What do you think\n\n1:13:08.400 --> 1:13:18.760\n is a good test of intelligence? Perhaps we're drifting in a topic that we're maybe philosophizing\n\n1:13:18.760 --> 1:13:22.240\n about, but what do you think is a good test for intelligence, for an artificial intelligence\n\n1:13:22.240 --> 1:13:23.240\n system?\n\n1:13:23.240 --> 1:13:32.760\n Well, the standard definition of artificial general intelligence is that it can do anything\n\n1:13:32.760 --> 1:13:39.540\n that people can do and it can do them better. What we are seeing is that in many domains,\n\n1:13:39.540 --> 1:13:51.360\n you have domain specific devices or programs or software, and they beat people easily in\n\n1:13:51.360 --> 1:14:04.080\n a specified way. What we are very far from is that general ability, general purpose intelligence.\n\n1:14:04.080 --> 1:14:08.800\n In machine learning, people are approaching something more general. I mean, for Alpha\n\n1:14:08.800 --> 1:14:18.840\n Zero was much more general than Alpha Go, but it's still extraordinarily narrow and\n\n1:14:18.840 --> 1:14:28.160\n specific in what it can do. So we're quite far from something that can, in every domain,\n\n1:14:28.160 --> 1:14:30.960\n think like a human except better.\n\n1:14:30.960 --> 1:14:36.560\n What aspect, so the Turing test has been criticized, it's natural language conversation that is\n\n1:14:36.560 --> 1:14:44.080\n too simplistic. It's easy to quote unquote pass under constraints specified. What aspect\n\n1:14:44.080 --> 1:14:52.120\n of conversation would impress you if you heard it? Is it humor? What would impress the heck\n\n1:14:52.120 --> 1:14:55.680\n out of you if you saw it in conversation?\n\n1:14:55.680 --> 1:15:06.120\n Yeah, I mean, certainly wit would be impressive and humor would be more impressive than just\n\n1:15:06.120 --> 1:15:17.080\n factual conversation, which I think is easy. And allusions would be interesting and metaphors\n\n1:15:17.080 --> 1:15:25.640\n would be interesting. I mean, but new metaphors, not practiced metaphors. So there is a lot\n\n1:15:25.640 --> 1:15:33.160\n that would be sort of impressive that is completely natural in conversation, but that you really\n\n1:15:33.160 --> 1:15:34.160\n wouldn't expect.\n\n1:15:34.160 --> 1:15:40.440\n Does the possibility of creating a human level intelligence or superhuman level intelligence\n\n1:15:40.440 --> 1:15:47.440\n system excite you, scare you? How does it make you feel?\n\n1:15:47.440 --> 1:15:51.520\n I find the whole thing fascinating. Absolutely fascinating.\n\n1:15:51.520 --> 1:15:52.520\n So exciting.\n\n1:15:52.520 --> 1:16:00.360\n I think. And exciting. It's also terrifying, you know, but I'm not going to be around\n\n1:16:00.360 --> 1:16:09.200\n to see it. And so I'm curious about what is happening now, but I also know that predictions\n\n1:16:09.200 --> 1:16:16.160\n about it are silly. We really have no idea what it will look like 30 years from now.\n\n1:16:16.160 --> 1:16:18.360\n No idea.\n\n1:16:18.360 --> 1:16:26.480\n Speaking of silly, bordering on the profound, let me ask the question of, in your view,\n\n1:16:26.480 --> 1:16:32.400\n what is the meaning of it all? The meaning of life? He's a descendant of great apes that\n\n1:16:32.400 --> 1:16:40.680\n we are. Why, what drives us as a civilization, as a human being, as a force behind everything\n\n1:16:40.680 --> 1:16:49.920\n that you've observed and studied? Is there any answer or is it all just a beautiful mess?\n\n1:16:49.920 --> 1:16:58.760\n There is no answer that I can understand and I'm not, and I'm not actively looking for\n\n1:16:58.760 --> 1:16:59.760\n one.\n\n1:16:59.760 --> 1:17:02.160\n Do you think an answer exists?\n\n1:17:02.160 --> 1:17:08.200\n No. There is no answer that we can understand. I'm not qualified to speak about what we cannot\n\n1:17:08.200 --> 1:17:17.400\n understand, but there is, I know that we cannot understand reality, you know. I mean, there\n\n1:17:17.400 --> 1:17:22.720\n are a lot of things that we can do. I mean, you know, gravity waves, I mean, that's a\n\n1:17:22.720 --> 1:17:29.800\n big moment for humanity. And when you imagine that ape, you know, being able to go back\n\n1:17:29.800 --> 1:17:34.200\n to the Big Bang, that's, that's, but...\n\n1:17:34.200 --> 1:17:35.200\n But the why.\n\n1:17:35.200 --> 1:17:36.200\n Yeah, the why.\n\n1:17:36.200 --> 1:17:37.200\n It's bigger than us.\n\n1:17:37.200 --> 1:17:40.200\n The why is hopeless, really.\n\n1:17:40.200 --> 1:17:43.640\n Danny, thank you so much. It was an honor. Thank you for speaking today.\n\n1:17:43.640 --> 1:17:44.640\n Thank you.\n\n1:17:44.640 --> 1:17:49.480\n Thanks for listening to this conversation. And thank you to our presenting sponsor, Cash\n\n1:17:49.480 --> 1:17:56.720\n App. Download it, use code LexPodcast, you'll get $10 and $10 will go to FIRST, a STEM education\n\n1:17:56.720 --> 1:18:01.880\n nonprofit that inspires hundreds of thousands of young minds to become future leaders and\n\n1:18:01.880 --> 1:18:08.280\n innovators. If you enjoy this podcast, subscribe on YouTube, give it five stars on Apple Podcast,\n\n1:18:08.280 --> 1:18:13.880\n follow on Spotify, support it on Patreon, or simply connect with me on Twitter.\n\n1:18:13.880 --> 1:18:19.160\n And now, let me leave you with some words of wisdom from Daniel Kahneman.\n\n1:18:19.160 --> 1:18:24.780\n Intelligence is not only the ability to reason, it is also the ability to find relevant material\n\n1:18:24.780 --> 1:18:29.320\n and memory and to deploy attention when needed.\n\n1:18:29.320 --> 1:18:44.400\n Thank you for listening and hope to see you next time.\n\n"
}
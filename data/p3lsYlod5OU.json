{
  "title": "Michael Levin: Biology, Life, Aliens, Evolution, Embryogenesis & Xenobots | Lex Fridman Podcast #325",
  "id": "p3lsYlod5OU",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:04.640\n turns out that if you train a planarian and then cut their heads off, the tail will regenerate a\n\n00:04.640 --> 00:09.760\n brand new brain that still remembers the original information. I think planaria hold the answer to\n\n00:09.760 --> 00:14.800\n pretty much every deep question of life. For one thing, they're similar to our ancestors. So they\n\n00:14.800 --> 00:17.600\n have true symmetry, they have a true brain, they're not like earthworms, they're, you know,\n\n00:17.600 --> 00:20.640\n they're much more advanced life form. They have lots of different internal organs, but they're\n\n00:20.640 --> 00:24.560\n these little, they're about, you know, maybe two centimeters in the centimeter to two in size.\n\n00:24.560 --> 00:30.640\n And they have a head and a tail. And the first thing is planaria are immortal. So they do not\n\n00:30.640 --> 00:34.320\n age. There's no such thing as an old planarian. So that right there tells you that these theories\n\n00:34.320 --> 00:40.080\n of thermodynamic limitations on lifespan are wrong. It's not that well over time of everything\n\n00:40.080 --> 00:44.560\n degrades. No, planaria can keep it going for probably, you know, how long have they been\n\n00:44.560 --> 00:48.640\n around 400 million years, right? So these are the actual, so the planaria in our lab\n\n00:48.640 --> 00:54.880\n are actually in physical continuity with planaria that were here 400 million years ago.\n\n00:54.880 --> 01:00.080\n The following is a conversation with Michael Levin, one of the most fascinating and brilliant\n\n01:00.080 --> 01:07.120\n biologists I've ever talked to. He and his lab at Tufts University works on novel ways to understand\n\n01:07.120 --> 01:12.960\n and control complex pattern formation in biological systems. Andre Karpathy, a world\n\n01:12.960 --> 01:18.880\n class AI researcher, is the person who first introduced me to Michael Levin's work. I bring\n\n01:18.880 --> 01:25.680\n this up because these two people make me realize that biology has a lot to teach us about AI,\n\n01:25.680 --> 01:32.000\n and AI might have a lot to teach us about biology. This is the Lex Friedman podcast.\n\n01:32.000 --> 01:37.440\n To support it, please check out our sponsors in the description. And now, dear friends,\n\n01:37.440 --> 01:44.480\n here's Michael Levin. Embryogenesis is the process of building the human body from a single cell. I\n\n01:44.480 --> 01:50.160\n think it's one of the most incredible things that exists on earth from a single embryo. So how does\n\n01:50.160 --> 01:56.080\n this process work? Yeah, it is an incredible process. I think it's maybe the most magical\n\n01:56.080 --> 02:01.520\n process there is. And I think one of the most fundamentally interesting things about it is that\n\n02:01.520 --> 02:07.120\n it shows that each of us takes the journey from so called just physics to mind, right? Because we\n\n02:07.120 --> 02:12.880\n all start life as a single quiescent, unfertilized oocyte, and it's basically a bag of chemicals,\n\n02:12.880 --> 02:16.720\n and you look at that and you say, okay, this is chemistry and physics. And then nine months and\n\n02:16.720 --> 02:22.320\n some years later, you have an organism with high level cognition and preferences and an inner life\n\n02:22.320 --> 02:27.520\n and so on. And what embryogenesis tells us is that that transformation from physics to mind is\n\n02:27.520 --> 02:32.560\n gradual. It's smooth. There is no special place where, you know, a lightning bolt says, boom,\n\n02:32.560 --> 02:37.440\n now you've gone from physics to true cognition. That doesn't happen. And so we can see in this\n\n02:37.440 --> 02:41.440\n process that the whole mystery, you know, the biggest mystery of the universe, basically,\n\n02:41.440 --> 02:47.680\n how you get mind from matter. From just physics, in quotes. Yeah. So where's the magic into the\n\n02:47.680 --> 02:54.480\n thing? How do we get from information encoded in DNA and make physical reality out of that\n\n02:54.480 --> 02:59.280\n information? So one of the things that I think is really important if we're going to bring in DNA\n\n02:59.280 --> 03:05.520\n into this picture is to think about the fact that what DNA encodes is the hardware of life. DNA\n\n03:05.520 --> 03:09.760\n contains the instructions for the kind of micro level hardware that every cell gets to play with.\n\n03:09.760 --> 03:14.160\n So all the proteins, all the signaling factors, the ion channels, all the cool little pieces of\n\n03:14.160 --> 03:20.640\n hardware that cells have, that's what's in the DNA. The rest of it is in so called generic laws.\n\n03:20.640 --> 03:25.920\n And these are laws of mathematics. These are laws of computation. These are laws of physics,\n\n03:25.920 --> 03:32.000\n of all kinds of interesting things that are not directly in the DNA. And that process, you know,\n\n03:32.000 --> 03:36.800\n I think the reason I always put just physics in quotes is because I don't think there is such a\n\n03:36.800 --> 03:41.520\n thing as just physics. I think that thinking about these things in binary categories, like this is\n\n03:41.520 --> 03:45.840\n physics, this is true cognition, this is as if it's only faking these kinds of things. I think\n\n03:45.840 --> 03:49.760\n that's what gets us in trouble. I think that we really have to understand that it's a continuum\n\n03:49.760 --> 03:53.600\n and we have to work up the scaling, the laws of scaling. And we can certainly talk about that.\n\n03:53.600 --> 03:56.640\n There's a lot of really interesting thoughts to be had there.\n\n03:56.640 --> 04:03.200\n So the physics is deeply integrated with the information. So the DNA doesn't exist on its own.\n\n04:03.200 --> 04:10.480\n The DNA is integrated as, in some sense, in response to the laws of physics at every scale.\n\n04:10.480 --> 04:14.080\n The laws of the environment it exists in.\n\n04:14.080 --> 04:18.960\n Yeah, the environment and also the laws of the universe. I mean, the thing about the DNA is that\n\n04:18.960 --> 04:25.440\n it's once evolution discovers a certain kind of machine, that if the physical implementation is\n\n04:25.440 --> 04:29.920\n appropriate, it's sort of, and this is hard to talk about because we don't have a good vocabulary\n\n04:29.920 --> 04:36.560\n for this yet, but it's a very kind of a platonic notion that if the machine is there, it pulls down\n\n04:36.560 --> 04:42.960\n interesting things that you do not have to evolve from scratch because the laws of physics give it\n\n04:42.960 --> 04:47.200\n to you for free. So just as a really stupid example, if you're trying to evolve a particular\n\n04:47.200 --> 04:50.720\n triangle, you can evolve the first angle and you evolve the second angle, but you don't need to\n\n04:50.720 --> 04:54.480\n evolve the third. You know what it is already. Now, why do you know? That's a gift for free\n\n04:54.480 --> 04:58.240\n from geometry in a particular space. You know what that angle has to be. And if you evolve\n\n04:58.240 --> 05:01.920\n an ion channel, which is, ion channels are basically transistors, right? They're voltage\n\n05:01.920 --> 05:06.720\n gated current conductances. If you evolve that ion channel, you immediately get to use things\n\n05:06.720 --> 05:10.160\n like truth tables. You get logic functions. You don't have to evolve the logic function.\n\n05:10.160 --> 05:14.160\n You don't have to evolve a truth table. It doesn't have to be in the DNA. You get it for free,\n\n05:14.160 --> 05:17.360\n right? And the fact that if you have NAND gates, you can build anything you want, you get that for\n\n05:17.360 --> 05:22.720\n free. All you have to evolve is that first step, that first little machine that enables you to\n\n05:22.720 --> 05:27.680\n couple to those laws. And there's laws of adhesion and many other things. And this is all that\n\n05:27.680 --> 05:33.600\n interplay between the hardware that's set up by the genetics and the software that's made, right?\n\n05:33.600 --> 05:38.240\n The physiological software that basically does all the computation and the cognition and everything\n\n05:38.240 --> 05:43.920\n else is a real interplay between the information and the DNA and the laws of physics of computation\n\n05:43.920 --> 05:49.360\n and so on. So is it fair to say, just like this idea that the laws of mathematics are discovered,\n\n05:50.640 --> 05:55.520\n they're latent within the fabric of the universe in that same way the laws of biology are kind of\n\n05:55.520 --> 05:59.760\n discovered? Yeah, I think that's absolutely, and it's probably not a popular view, but I think\n\n05:59.760 --> 06:05.520\n that's right on the money. Yeah. Well, I think that's a really deep idea. Then embryogenesis\n\n06:05.520 --> 06:16.000\n is the process of revealing, of embodying, of manifesting these laws. You're not building the\n\n06:16.000 --> 06:23.520\n laws. You're just creating the capacity to reveal. Yes. I think, again, not the standard view of\n\n06:23.520 --> 06:27.760\n molecular biology by any means, but I think that's right on the money. I'll give you a simple example.\n\n06:27.760 --> 06:31.680\n Some of our latest work with these xenobots, right? So what we've done is to take some skin\n\n06:31.680 --> 06:36.080\n cells off of an early frog embryo and basically ask about their plasticity. If we give you a\n\n06:36.080 --> 06:40.400\n chance to sort of reboot your multicellularity in a different context, what would you do?\n\n06:40.400 --> 06:45.120\n Because what you might assume by... The thing about embryogenesis is that it's super reliable,\n\n06:45.120 --> 06:50.640\n right? It's very robust. And that really obscures some of its most interesting features. We get\n\n06:50.640 --> 06:54.800\n used to it. We get used to the fact that acorns make oak trees and frog eggs make frogs. And we\n\n06:54.800 --> 06:57.920\n say, well, what else is it going to make? That's what it makes. That's a standard story.\n\n06:57.920 --> 07:03.600\n But the reality is... And so you look at these skin cells and you say, well, what do they know\n\n07:03.600 --> 07:07.840\n how to do? Well, they know how to be a passive boring two dimensional outer layer, keeping the\n\n07:07.840 --> 07:11.200\n bacteria from getting into the embryo. That's what they know how to do. Well, it turns out that if\n\n07:11.200 --> 07:17.040\n you take these skin cells and you remove the rest of the embryo, so you remove all of the rest of\n\n07:17.040 --> 07:20.960\n the cells and you say, well, you're by yourself now, what do you want to do? So what they do is\n\n07:20.960 --> 07:26.480\n they form this multi little creature that runs around the dish. They have all kinds of incredible\n\n07:26.480 --> 07:30.960\n and incredible capacities. They navigate through mazes. They have various behaviors that they do\n\n07:30.960 --> 07:38.960\n both independently and together. Basically, they implement von Neumann's dream of self replication,\n\n07:38.960 --> 07:42.560\n because if you sprinkle a bunch of loose cells into the dish, what they do is they run around,\n\n07:42.560 --> 07:46.800\n they collect those cells into little piles. They sort of mush them together until those little\n\n07:46.800 --> 07:50.960\n piles become the next generation of xenobots. So you've got this machine that builds copies of\n\n07:50.960 --> 07:56.720\n itself from loose material in its environment. None of this are things that you would have expected\n\n07:56.720 --> 08:01.280\n from the frog genome. In fact, the genome is wild type. There's nothing wrong with their genetics.\n\n08:01.280 --> 08:06.320\n Nothing has been added, no nanomaterials, no genomic editing, nothing. And so what we have\n\n08:06.320 --> 08:11.360\n done there is engineered by subtraction. What you've done is you've removed the other cells\n\n08:11.360 --> 08:15.920\n that normally basically bully these cells into being skin cells. And you find out that what they\n\n08:15.920 --> 08:21.680\n really want to do is to be this, their default behaviors to be a xenobot. But in vivo, in the\n\n08:21.680 --> 08:28.640\n embryo, they get told to be skinned by these other cell types. And so now here comes this really\n\n08:28.640 --> 08:33.760\n interesting question that you just posed. When you ask where does the form of the tadpole and\n\n08:33.760 --> 08:39.920\n the frog come from, the standard answer is, well, it's selection. So over millions of years,\n\n08:39.920 --> 08:44.720\n it's been shaped to produce the specific body that's fit for froggy environments.\n\n08:44.720 --> 08:48.240\n Where does the shape of the xenobot come from? There's never been any xenobots. There's never\n\n08:48.240 --> 08:51.920\n been selection to be a good xenobot. These cells find themselves in the new environment.\n\n08:51.920 --> 08:57.920\n In 48 hours, they figure out how to be an entirely different protoorganism with new capacities like\n\n08:57.920 --> 09:02.000\n kinematic self replication. That's not how frogs or tadpoles replicate. We've made it impossible\n\n09:02.000 --> 09:05.600\n for them to replicate their normal way. Within a couple of days, these guys find a new way of\n\n09:05.600 --> 09:09.200\n doing it that's not done anywhere else in the biosphere. Well, actually, let's step back and\n\n09:09.200 --> 09:16.320\n define, what are xenobots? So a xenobot is a self assembling little protoorganism. It's also a\n\n09:16.320 --> 09:22.000\n biological robot. Those things are not distinct. It's a member of both classes. How much is it\n\n09:22.000 --> 09:28.160\n biology? How much is that robot? At this point, most of it is biology because what we're doing is\n\n09:28.160 --> 09:35.120\n we're discovering natural behaviors of the cells and also of the cell collectives. Now, one of the\n\n09:35.120 --> 09:39.440\n really important parts of this was that we're working together with Josh Bongaert's group at\n\n09:39.440 --> 09:45.040\n University of Vermont. They're computer scientists, they do AI, and they've basically been able to\n\n09:45.040 --> 09:51.440\n use a simulated evolution approach to ask, how can we manipulate these cells, give them signals,\n\n09:51.440 --> 09:56.080\n not rewire their DNA, so not hardware, but experience signals? So can we remove some cells?\n\n09:56.080 --> 09:59.920\n Can we add some cells? Can we poke them in different ways to get them to do other things?\n\n09:59.920 --> 10:04.400\n So in the future, there's going to be, we're now, and this is future unpublished work, but\n\n10:04.400 --> 10:08.720\n we're doing all sorts of interesting ways to reprogram them to new behaviors. But before you\n\n10:08.720 --> 10:13.040\n can start to reprogram these things, you have to understand what their innate capacities are.\n\n10:13.040 --> 10:19.520\n Okay, so that means engineering, programming, you're engineering them in the future. And in\n\n10:19.520 --> 10:28.400\n some sense, the definition of a robot is something you in part engineer versus evolve. I mean,\n\n10:28.400 --> 10:33.280\n it's such a fuzzy definition anyway, in some sense, many of the organisms within our body\n\n10:33.280 --> 10:40.640\n are kinds of robots. And I think robots is a weird line because it's, we tend to see robots\n\n10:40.640 --> 10:45.760\n as the other. I think there will be a time in the future when there's going to be something akin to\n\n10:45.760 --> 10:52.800\n the civil rights movements for robots, but we'll talk about that later perhaps. Anyway, so how do\n\n10:52.800 --> 11:00.000\n you, can we just linger on it? How do you build a Xenobot? What are we talking about here? From\n\n11:00.560 --> 11:06.640\n when does it start and how does it become the glorious Xenobot?\n\n11:06.640 --> 11:12.080\n Yeah, so just to take one step back, one of the things that a lot of people get stuck on is they\n\n11:12.080 --> 11:19.120\n say, well, you know, engineering requires new DNA circuits or it requires new nanomaterials,\n\n11:19.120 --> 11:24.560\n you know, what the thing is, we are now moving from old school engineering, which use passive\n\n11:24.560 --> 11:28.480\n materials, right? That things, you know, wood, metal, things like this, that basically the only\n\n11:28.480 --> 11:31.280\n thing you could depend on is that they were going to keep their shape. That's it. They don't do\n\n11:31.280 --> 11:35.120\n anything else. It's on you as an engineer to make them do everything they're going to do.\n\n11:35.120 --> 11:39.040\n And then there were active materials and now computation materials. This is a whole new era.\n\n11:39.040 --> 11:43.600\n These are agential materials. This is you're now collaborating with your substrate because your\n\n11:43.600 --> 11:51.280\n material has an agenda. These cells have, you know, billions of years of evolution. They have goals.\n\n11:51.280 --> 11:54.160\n They have preferences. They're not just going to sit where you put them. That's hilarious that you\n\n11:54.160 --> 11:58.880\n have to talk your material into keeping its shape. That's it. That is exactly right. That is exactly\n\n11:58.880 --> 12:04.400\n right. Stay there. It's like getting a bunch of cats or something and trying to organize the shape\n\n12:04.400 --> 12:08.000\n out of them. It's funny. We're on the same page here because in a paper, this is, this is currently\n\n12:08.640 --> 12:12.800\n just been accepted in nature by engineering. One of the figures I have is building a tower\n\n12:12.800 --> 12:17.360\n out of Legos versus dogs, right? So think about the difference, right? If you build out of Legos,\n\n12:17.360 --> 12:22.800\n you have full control over where it's going to go. But if somebody knocks it over, it's game over.\n\n12:22.800 --> 12:26.240\n With the dogs, you cannot just come and stack them. They're not going to stay that way. But\n\n12:26.240 --> 12:29.680\n the good news is that if you train them, then somebody knocks it over, they'll get right back\n\n12:29.680 --> 12:33.760\n up. So it's all right. So as an engineer, what you really want to know is what can they depend\n\n12:33.760 --> 12:37.440\n on this thing to do, right? That's really, you know, a lot of people have definitions of robots\n\n12:37.440 --> 12:41.360\n as far as what they're made of or how they got here, you know, design versus evolve, whatever.\n\n12:41.360 --> 12:45.200\n I don't think any of that is useful. I think, I think as an engineer, what you want to know is\n\n12:45.200 --> 12:49.920\n how much can I depend on this thing to do when I'm not around to micromanage it? What level of,\n\n12:50.960 --> 12:54.400\n what level of dependency can I, can I give this thing? How much agency does it have?\n\n12:54.400 --> 12:57.360\n Which then tells you what techniques do you use? So do you use micromanagement,\n\n12:57.360 --> 13:01.200\n like you put everything where it goes? Do you train it? Do you give it signals? Do you try\n\n13:01.200 --> 13:04.560\n to convince it to do things, right? How much, you know, how intelligent is your substrate?\n\n13:04.560 --> 13:08.480\n And so now we're moving into this, into this area where you're, you're, you're working with\n\n13:08.480 --> 13:12.560\n agential materials. That's a collaboration. That's not, that's not old, old style.\n\n13:12.560 --> 13:14.320\n What's the word you're using? Agential?\n\n13:14.320 --> 13:14.880\n Agential.\n\n13:14.880 --> 13:15.040\n Yeah.\n\n13:15.040 --> 13:15.680\n What's that mean?\n\n13:15.680 --> 13:19.440\n Agency. It comes from the word agency. So, so basically the material has agency, meaning that\n\n13:20.160 --> 13:26.000\n it has some, some level of obviously not human level, but some level of preferences, goals,\n\n13:26.000 --> 13:30.000\n memories, ability to remember things, to compute into the future, meaning anticipate,\n\n13:30.640 --> 13:34.800\n you know, when you're working with cells, they have all of that to some, to various degrees.\n\n13:34.800 --> 13:39.920\n Is that empowering or limiting having material as a mind of its own, literally?\n\n13:39.920 --> 13:43.600\n I think it's both, right? So it raises difficulties because it means that\n\n13:43.600 --> 13:48.880\n it, if you, if you're using the old mindset, which is a linear kind of extrapolation of what's going\n\n13:48.880 --> 13:54.320\n to happen, you're going to be surprised and shocked all the time because biology does not\n\n13:54.320 --> 13:59.200\n do what we linearly expect materials to do. On the other hand, it's massively liberating. And\n\n13:59.200 --> 14:04.240\n so in the following way, I've argued that advances in regenerative medicine require us to take\n\n14:04.240 --> 14:09.040\n advantage of this because what it means is that you can get the material to do things that you\n\n14:09.040 --> 14:13.120\n don't know how to micromanage. So just as a simple example, right? If you, if you, you had a rat\n\n14:13.840 --> 14:19.120\n and you wanted this rat to do a circus trick, put a ball in the little hoop, you can do it the\n\n14:19.120 --> 14:22.960\n micromanagement way, which is try to control every neuron and try to play the thing like a puppet,\n\n14:22.960 --> 14:26.960\n right? And maybe someday that'll be possible, maybe, or you can train the rat. And this is\n\n14:26.960 --> 14:31.040\n why humanity for thousands of years before we knew any neuroscience, we had no idea what's\n\n14:31.040 --> 14:35.040\n behind, what's between the ears of any animal. We were able to train these animals because once you\n\n14:35.040 --> 14:40.480\n recognize the level of agency of a certain system, you can use appropriate techniques. If you know\n\n14:40.480 --> 14:44.160\n the currency of motivation, reward and punishment, you know how smart it is, you know what kinds of\n\n14:44.160 --> 14:50.080\n things it likes to do. You are searching a much more, much smoother, much nicer problem space than\n\n14:50.080 --> 14:54.080\n if you try to micromanage the thing. And in regenerative medicine, when you're trying to get,\n\n14:54.080 --> 14:57.920\n let's say an arm to grow back or an eye to repair a cell birth defect or something,\n\n14:57.920 --> 15:02.960\n do you really want to be controlling tens of thousands of genes at each point to try to\n\n15:02.960 --> 15:07.760\n micromanage it? Or do you want to find the high level modular controls that say,\n\n15:07.760 --> 15:11.360\n build an arm here. You already know how to build an arm. You did it before, do it again.\n\n15:11.360 --> 15:15.920\n So that's, I think it's both, it's both difficult and it challenges us to develop new ways of\n\n15:15.920 --> 15:21.760\n engineering and it's hugely empowering. Okay. So how do you do, I mean, maybe sticking with\n\n15:21.760 --> 15:31.120\n the metaphor of dogs and cats, I presume you have to figure out the, find the dogs and dispose of\n\n15:31.120 --> 15:38.400\n the cats. Because, you know, it's like the old herding cats is an issue. So you may be able to\n\n15:38.400 --> 15:44.800\n train dogs. I suspect you will not be able to train cats. Or if you do, you're never going to\n\n15:44.800 --> 15:53.040\n be able to trust them. So is there a way to figure out which material is amenable to herding? Is it in\n\n15:53.040 --> 15:59.360\n the lab work or is it in simulation? Right now it's largely in the lab because we, our simulations\n\n15:59.360 --> 16:04.560\n do not capture yet the most interesting and powerful things about biology. So the simulation\n\n16:04.560 --> 16:10.480\n does, what we're pretty good at simulating are feed forward emergent types of things,\n\n16:10.480 --> 16:15.120\n right? So cellular automata, if you have simple rules and you sort of roll those forward for\n\n16:15.120 --> 16:19.360\n every, every agent or every cell in the simulation, then complex things happen, you know, ant colony\n\n16:19.360 --> 16:23.600\n or algorithms, things like that. We're good at that. And that's, and that's fine. The difficulty\n\n16:23.600 --> 16:28.400\n with all of that is that it's incredibly hard to reverse. So this is a really hard inverse problem,\n\n16:28.400 --> 16:31.520\n right? If you look at a bunch of termites and they make a, you know, a thing with a single chimney\n\n16:31.520 --> 16:36.080\n and you say, well, I like it, but I'd like two chimneys. How do you change the rules of behavior\n\n16:36.080 --> 16:40.320\n free termites? So they make two chimneys, right? Or, or if you say, here are a bunch of cells that are\n\n16:40.320 --> 16:44.720\n creating this kind of organism. I don't think that's optimal. I'd like to repair that birth\n\n16:44.720 --> 16:49.040\n defect. How do you control all the, all the individual low level rules, right? All the protein\n\n16:49.040 --> 16:53.520\n interactions and everything else, rolling it back from the anatomy that you want to the low level\n\n16:53.520 --> 16:57.360\n hardware rules is in general intractable. It's a, it's an inverse problem that's generally not\n\n16:57.360 --> 17:02.960\n solvable. So right now it's mostly in the lab because what we need to do is we need to understand\n\n17:02.960 --> 17:08.320\n how biology uses top down controls. So the idea is not, not bottom up emergence, but the idea of\n\n17:09.520 --> 17:14.560\n things like a goal directed test operate exit kinds of loops where, where it's basically an\n\n17:14.560 --> 17:19.120\n error minimization function over a new space and not a space of gene expression, but for example,\n\n17:19.120 --> 17:23.760\n a space of anatomy. So just as a simple example, if you have, you have a salamander and it's got\n\n17:23.760 --> 17:29.040\n an arm, you can, you can amputate that arm anywhere along the length. It will grow exactly\n\n17:29.040 --> 17:32.880\n what's needed and then it stops. That's the most amazing thing about regeneration is that it stops\n\n17:32.880 --> 17:37.280\n it knows when to stop. When does it stop? It stops when a correct salamander arm has been completed.\n\n17:37.280 --> 17:42.880\n So that tells you that's right. That's a, that's a, a means ends kind of analysis where it has to\n\n17:42.880 --> 17:47.280\n know what the correct limb is supposed to look like, right? So it has a way to ascertain the\n\n17:47.280 --> 17:51.360\n current shape. It has a way to measure that Delta from, from what shape it's supposed to be. And it\n\n17:51.360 --> 17:55.600\n will keep taking actions, meaning remodeling and growing and everything else until that's complete.\n\n17:55.600 --> 17:59.200\n So once you know that, and we've taken advantage of this in the lab to do some, some really wild\n\n17:59.200 --> 18:04.400\n things with, with both planaria and frog embryos and so on, once you know that, you can start\n\n18:04.400 --> 18:08.880\n playing with that, with that homeostatic cycle. You can ask, for example, well, how does it remember\n\n18:08.880 --> 18:12.240\n what the correct shape is? And can we mess with that memory? Can we give it a false memory of\n\n18:12.240 --> 18:16.160\n what the shape should be and let the cells build something else? Or can we mess with the measurement\n\n18:16.160 --> 18:20.800\n apparatus, right? So it gives you, it gives you those kinds of, so, so, so the idea is to\n\n18:21.680 --> 18:28.240\n basically appropriate a lot of the approaches and concepts from cognitive neuroscience and\n\n18:28.240 --> 18:33.600\n behavioral science into things that previously were taken to be dumb materials. And, you know,\n\n18:33.600 --> 18:37.440\n you get yelled at in class if you, if you, for being anthropomorphic, if you said, well, my cells\n\n18:37.440 --> 18:41.280\n want to do this and my cells want to do that. And I think, I think that's a, that's a major mistake\n\n18:41.280 --> 18:45.920\n that leaves a ton of capabilities on the table. So thinking about biologic systems as things that\n\n18:45.920 --> 18:56.560\n have memory, have almost something like cognitive ability, but I mean, how incredible is it,\n\n18:56.560 --> 19:03.600\n you know, that the salamander arm is being rebuilt, not with a dictator. It's kind of like\n\n19:03.600 --> 19:08.880\n the cellular automata system. All the individual workers are doing their own thing. So where's that\n\n19:10.320 --> 19:16.080\n top down signal that does the control coming from? Like, how can you find it? Like, why does it stop\n\n19:16.080 --> 19:21.120\n growing? How does it know the shape? How does it have memory of the shape? And how does it tell\n\n19:21.120 --> 19:26.080\n everybody to be like, whoa, whoa, whoa, slow down, we're done. So the first thing to think about,\n\n19:26.080 --> 19:33.680\n I think, is that there are no examples anywhere of a central dictator, because in this kind of\n\n19:33.680 --> 19:40.480\n science, because everything is made of parts. And so we, even though we feel as a unified central\n\n19:40.480 --> 19:45.840\n sort of intelligence and kind of point of cognition, we are a bag of neurons, right?\n\n19:45.840 --> 19:49.760\n All intelligence is collective intelligence. There's this, this is important to kind of\n\n19:50.720 --> 19:54.560\n think about, because a lot of people think, okay, there's real intelligence, like me,\n\n19:54.560 --> 19:59.280\n and then there's collective intelligence, which is ants and flocks of birds and termites and\n\n19:59.280 --> 20:05.520\n things like that. And maybe it's appropriate to think of them as an individual, and maybe it's\n\n20:05.520 --> 20:09.520\n not, and a lot of people are skeptical about that and so on. But you've got to realize that\n\n20:09.520 --> 20:13.760\n we are not, there's no such thing as this like indivisible diamond of intelligence that's like\n\n20:13.760 --> 20:19.600\n this one central thing that's not made of parts. We are all made of parts. And so if you believe,\n\n20:19.600 --> 20:25.520\n which I think is hard to get around, that we in fact have a centralized set of goals and\n\n20:25.520 --> 20:30.240\n preferences and we plan and we do things and so on, you are already committed to the fact that\n\n20:30.240 --> 20:34.000\n a collection of cells is able to do this, because we are a collection of cells. There's no getting\n\n20:34.000 --> 20:37.920\n around that. In our case, what we do is we navigate the three dimensional world and we\n\n20:37.920 --> 20:41.840\n have behavior. This is blowing my mind right now, because we are just a collection of cells.\n\n20:41.840 --> 20:50.560\n Oh yeah. So when I'm moving this arm, I feel like I'm the central dictator of that action,\n\n20:50.560 --> 20:57.840\n but there's a lot of stuff going on. All the cells here are collaborating in some interesting way.\n\n20:57.840 --> 21:00.880\n They're getting signal from the central nervous system.\n\n21:00.880 --> 21:05.600\n Well, even the central nervous system is misleadingly named because it isn't really\n\n21:05.600 --> 21:10.800\n central. Again, it's just a bunch of cells. I mean, all of them, right? There are no,\n\n21:10.800 --> 21:16.240\n there are no singular indivisible intelligences anywhere. We are all, every example that we've\n\n21:16.240 --> 21:21.040\n ever seen is a collective of something. It's just that we're used to it. We're used to that. We're\n\n21:21.040 --> 21:24.080\n used to, okay, this thing is kind of a single thing, but it's really not. You zoom in, you know\n\n21:24.080 --> 21:29.360\n what you see. You see a bunch of cells running around. Is there some unifying, I mean, we're\n\n21:29.360 --> 21:36.000\n jumping around, but that something that you look at as the bioelectrical signal versus the\n\n21:36.000 --> 21:46.880\n biochemical, the chemistry, the electricity, maybe the life is in that versus the cells.\n\n21:47.680 --> 21:56.400\n It's the, there's an orchestra playing and the resulting music is the dictator.\n\n21:57.120 --> 22:02.560\n That's not bad. That's Dennis Noble's kind of view of things. He has two really good books\n\n22:02.560 --> 22:07.360\n where he talks about this musical analogy, right? So I think that's, I like it. I like it.\n\n22:07.360 --> 22:08.640\n Is it wrong though?\n\n22:08.640 --> 22:13.600\n I don't think it's, no, I don't think it's wrong. I don't think it's wrong. I think the important\n\n22:13.600 --> 22:23.040\n thing about it is that we have to come to grips with the fact that a true proper cognitive\n\n22:23.040 --> 22:27.920\n intelligence can still be made of parts. Those things are, and in fact it has to be, and I think\n\n22:27.920 --> 22:32.800\n it's a real shame, but I see this all the time. When you have a collective like this, whether it\n\n22:32.800 --> 22:40.880\n be a group of robots or a collection of cells or neurons or whatever, as soon as we gain some\n\n22:40.880 --> 22:45.360\n insight into how it works, meaning that, oh, I see, in order to take this action, here's the\n\n22:45.360 --> 22:50.320\n information that got processed via this chemical mechanism or whatever. Immediately people say,\n\n22:50.320 --> 22:54.880\n oh, well then that's not real cognition. That's just physics. I think this is fundamentally\n\n22:54.880 --> 22:58.720\n flawed because if you zoom into anything, what are you going to see? Of course you're just going to\n\n22:58.720 --> 23:01.680\n see physics. What else could be underneath, right? It's not going to be fairy dust. It's going to be\n\n23:01.680 --> 23:05.920\n physics and chemistry, but that doesn't take away from the magic of the fact that there are certain\n\n23:05.920 --> 23:10.320\n ways to arrange that physics and chemistry and in particular the bioelectricity, which I like a lot,\n\n23:11.440 --> 23:18.640\n to give you an emergent collective with goals and preferences and memories and anticipations\n\n23:18.640 --> 23:22.160\n that do not belong to any of the subunits. So I think what we're getting into here,\n\n23:22.160 --> 23:26.640\n and we can talk about how this happens during embryogenesis and so on, what we're getting into\n\n23:26.640 --> 23:33.360\n is the origin of a self with a capital S. So we ourselves, there are many other kinds of\n\n23:33.360 --> 23:37.120\n selves, and we can tell some really interesting stories about where selves come from and how they\n\n23:37.120 --> 23:42.240\n become unified. Yeah, is this the first, or at least humans tend to think that this is the\n\n23:42.880 --> 23:49.440\n level of which the self with a capital S is first born, and we really don't want to see\n\n23:49.440 --> 23:54.720\n human civilization or Earth itself as one living organism. Yeah, that's very uncomfortable to us.\n\n23:54.720 --> 24:01.200\n It is, yeah. But is, yeah, where's the self born? We have to grow up past that. So what I like to do\n\n24:01.200 --> 24:06.560\n is, I'll tell you two quick stories about that. I like to roll backwards. So as opposed to, so if\n\n24:06.560 --> 24:10.560\n you start and you say, okay, here's a paramecium, and you see it, you know, it's a single cell\n\n24:10.560 --> 24:14.320\n organism, you see it doing various things, and people will say, okay, I'm sure there's some\n\n24:14.320 --> 24:18.160\n chemical story to be told about how it's doing it, so that's not a paramecium.\n\n24:18.160 --> 24:23.360\n So that's not true cognition, right? And people will argue about that. I like to work it backwards.\n\n24:23.360 --> 24:28.880\n I say, let's agree that you and I, as we sit here, are examples of true cognition, if anything,\n\n24:28.880 --> 24:32.960\n as if there's anything that's true cognition, we are examples of it. Now let's just roll back\n\n24:32.960 --> 24:36.800\n slowly, right? So you roll back to the time when you were a small child and used to doing whatever,\n\n24:36.800 --> 24:41.280\n and then just sort of day by day, you roll back, and eventually you become more or less that\n\n24:41.280 --> 24:46.560\n paramecium, and then you sort of even below that, right, as an unfertilized OSI. So\n\n24:46.560 --> 24:53.840\n it's, no one has, to my knowledge, no one has come up with any convincing discrete step at which\n\n24:53.840 --> 24:59.040\n my cognitive powers disappear, right? It just doesn't, the biology doesn't offer any specific\n\n24:59.040 --> 25:04.000\n step. It's incredibly smooth and slow and continuous. And so I think this idea that it just\n\n25:04.000 --> 25:10.080\n sort of magically shows up at one point, and then, you know, humans have true selves that don't exist\n\n25:10.080 --> 25:13.840\n elsewhere, I think it runs against everything we know about evolution, everything we know about\n\n25:13.840 --> 25:18.400\n developmental biology, these are all slow continua. And the other really important story I\n\n25:18.400 --> 25:23.280\n want to tell is where embryos come from. So think about this for a second. Amniote embryos, so this\n\n25:23.280 --> 25:29.200\n is humans, birds, and so on, mammals and birds and so on. Imagine a flat disk of cells, so there's\n\n25:29.200 --> 25:35.120\n maybe 50,000 cells. And in that, so when you get an egg from a fertilized, let's say you buy a\n\n25:35.120 --> 25:42.560\n fertilized egg from a farm, right? That egg will have about 50,000 cells in a flat disk, it looks\n\n25:42.560 --> 25:50.080\n like a little tiny little frisbee. And in that flat disk, what'll happen is there'll be one set\n\n25:50.080 --> 25:56.000\n of cells will become special, and it will tell all the other cells, I'm going to be the head,\n\n25:56.000 --> 26:00.160\n you guys don't be the head. And so it'll amplify symmetry breaking amplification, you get one\n\n26:00.160 --> 26:06.320\n embryo, there's some neural tissue and some other stuff forms. Now, you say, okay, I had one egg\n\n26:06.320 --> 26:10.880\n and one embryo, and there you go, what else could it be? Well, the reality is, and I used to, I did\n\n26:10.880 --> 26:16.400\n all of this as a grad student, if you take a little needle, and you make a scratch in that\n\n26:16.400 --> 26:20.720\n blastoderm in that disk, such that the cells can't talk to each other for a while, it heals up, but\n\n26:20.720 --> 26:26.240\n for a while, they can't talk to each other. What will happen is that both regions will decide that\n\n26:26.240 --> 26:29.120\n they can be the embryo, and there will be two of them. And then when they heal up, they become\n\n26:29.120 --> 26:33.920\n conjoint twins, and you can make two, you can make three, you can make lots. So the question of how\n\n26:33.920 --> 26:40.720\n many cells are in there cannot be answered until it's actually played all the way through. It isn't\n\n26:40.720 --> 26:44.320\n necessarily that there's just one, there can be many. So what you have is you have this medium,\n\n26:44.320 --> 26:49.280\n this, this undifferentiated, I'm sure there's a there's a psychological version of this somewhere\n\n26:49.280 --> 26:53.280\n that I don't know the proper terminology. But you have this, you have this list, like the ocean of\n\n26:53.280 --> 26:58.960\n potentiality, you have these 1000s of cells, and some number of individuals are going to be formed\n\n26:58.960 --> 27:05.040\n out of it, usually one, sometimes zero, sometimes several. And they form out of these cells,\n\n27:05.040 --> 27:10.880\n because a region of these cells organizes into a collective that will have goals, goals that\n\n27:10.880 --> 27:15.680\n individual cells don't have, for example, make a limb, make an eye, how many eyes? Well, exactly\n\n27:15.680 --> 27:19.120\n two. So individual cells don't know what an eye is, they don't know how many eyes you're supposed\n\n27:19.120 --> 27:23.360\n to have, but the collective does. The collective has goals and memories and anticipations that the\n\n27:23.360 --> 27:27.440\n individual cells don't. And that that the establishment of that boundary with its own\n\n27:27.440 --> 27:32.960\n ability to maintain to to pursue certain goals. That's the origin of selfhood.\n\n27:33.920 --> 27:42.800\n But I, is that goal in there somewhere? Were they always destined? Like, are they discovering\n\n27:42.800 --> 27:49.360\n that goal? Like, where the hell did evolution discover this when you went from the prokaryotes\n\n27:49.360 --> 27:55.600\n to eukaryotic cells? And then they started making groups. And when you make a certain group,\n\n27:55.600 --> 28:03.600\n you make a, you make it sound, and it's such a tricky thing to try to understand, you make it\n\n28:03.600 --> 28:09.680\n sound like this cells didn't get together and came up with a goal. But the very act of them\n\n28:09.680 --> 28:16.880\n getting together revealed the goal that was always there. There was always that potential\n\n28:16.880 --> 28:20.880\n for that goal. So the first thing to say is that there are way more questions here than\n\n28:20.880 --> 28:25.680\n certainties. Okay, so everything I'm telling you is cutting edge developing, you know, stuff. So\n\n28:25.680 --> 28:29.520\n it's not as if any of us know the answer to this. But, but here's, here's, here's my opinion on\n\n28:29.520 --> 28:36.000\n this. I think what evolution, I don't think that evolution produces solutions to specific problems,\n\n28:36.000 --> 28:39.680\n in other words, specific environments, like here's a frog that can live well in a froggy\n\n28:39.680 --> 28:46.000\n environment. I think what evolution produces is problem solving machines that that will that will\n\n28:46.000 --> 28:50.320\n solve problems in different spaces. So not just three dimensional spaces, but in a way,\n\n28:50.320 --> 28:55.120\n three dimensional space. This goes back to what we were talking about before we the brain is a\n\n28:55.120 --> 29:01.360\n evolutionarily a late development. It's a system that is able to net to pursue goals in three\n\n29:01.360 --> 29:05.040\n dimensional space by giving commands to muscles, where did that system come from that system\n\n29:05.040 --> 29:10.000\n evolved from a much more ancient, evolutionarily much more ancient system, where collections of\n\n29:10.000 --> 29:18.320\n cells gave instructions to for cell behaviors, meaning cells move to divide to die to change into\n\n29:18.320 --> 29:23.440\n cells to navigate more for space, the space of anatomies, the space of all possible anatomies.\n\n29:23.440 --> 29:27.520\n And before that, cells were navigating transcriptional space, which is a space of all\n\n29:27.520 --> 29:31.840\n possible gene expressions. And before that metabolic space. So what evolution has done,\n\n29:31.840 --> 29:38.720\n I think, is is is is produced hardware that is very good at navigating different spaces using a\n\n29:38.720 --> 29:42.560\n bag of tricks, right, which which I'm sure many of them we can steal for autonomous vehicles and\n\n29:42.560 --> 29:47.840\n robotics and various things. And what happens is that they navigate these spaces without a whole\n\n29:47.840 --> 29:51.520\n lot of commitment to what the space is. In fact, they don't know what the space is, right? We are\n\n29:51.520 --> 29:57.280\n all brains in a vat, so to speak. Every cell does not know, right? Every cell is some other name,\n\n29:57.280 --> 30:02.160\n some other cells external environment, right? So where does that with that border between you,\n\n30:02.160 --> 30:05.680\n you and the outside world, you don't really know where that is, right? Every every collection of\n\n30:05.680 --> 30:10.880\n cell has to figure that out from scratch. And the fact that evolution requires all of these things\n\n30:10.880 --> 30:15.520\n to figure out what they are, what effectors they have, what sensors they have, where does it make\n\n30:15.520 --> 30:18.960\n sense to draw a boundary between me and the outside world? The fact that you have to build all\n\n30:18.960 --> 30:25.680\n that from scratch, this autopoiesis is what defines the border of a self. Now, biology uses like a\n\n30:26.320 --> 30:31.760\n multi a multi scale competency architecture, meaning that every level has goals. So so\n\n30:31.760 --> 30:38.160\n molecular networks have goals, cells have goals, tissues, organs, colonies. And and it's the\n\n30:38.160 --> 30:43.280\n interplay of all of those that that enable biology to solve problems in new ways, for example, in\n\n30:43.280 --> 30:50.640\n xenobots and various other things. This is, you know, it's exactly as you said, in many ways,\n\n30:50.640 --> 30:56.080\n the cells are discovering new ways of being. But at the same time, evolution certainly shapes all\n\n30:56.080 --> 31:01.120\n this. So so evolution is very good at this agential bioengineering, right? When evolution\n\n31:01.680 --> 31:05.200\n is discovering a new way of being an animal, you know, an animal or a plant or something,\n\n31:06.000 --> 31:10.160\n sometimes it's by changing the hardware, you know, protein, changing proteins, protein structure,\n\n31:10.160 --> 31:14.160\n and so on. But much of the time, it's not by changing the hardware, it's by changing the\n\n31:14.160 --> 31:17.840\n signals that the cells give to each other. It's doing what we as engineers do, which is try to\n\n31:17.840 --> 31:22.640\n convince the cells to do various things by using signals, experiences, stimuli. That's what biology\n\n31:22.640 --> 31:27.360\n does. It has to, because it's not dealing with a blank slate. Every time as you know, if you're\n\n31:27.360 --> 31:32.960\n evolution, and you're trying to make make a make an organism, you're not dealing with a passive\n\n31:32.960 --> 31:37.760\n material that is fresh, and you have to specify it already wants to do certain things. So the easiest\n\n31:37.760 --> 31:42.560\n way to do that search to find whatever is going to be adaptive, is to find the signals that are\n\n31:42.560 --> 31:48.480\n going to convince cells to do various things, right? Your sense is that evolution operates\n\n31:48.480 --> 31:54.000\n both in the software and the hardware. And it's just easier, more efficient to operate in the\n\n31:54.000 --> 31:58.800\n software. Yes. And I should also say, I don't think the distinction is sharp. In other words,\n\n31:58.800 --> 32:03.120\n I think it's a continuum. But I think we can but I think it's a meaningful distinction where you can\n\n32:03.120 --> 32:08.480\n make changes to a particular protein, and now the enzymatic function is different, and it metabolizes\n\n32:08.480 --> 32:14.080\n differently, and whatever, and that will have implications for fitness. Or you can change the\n\n32:14.080 --> 32:20.480\n huge amount of information in the genome that isn't structural at all. It's, it's, it's signaling,\n\n32:20.480 --> 32:25.120\n it's when and how do cells say certain things to each other. And that can have massive changes,\n\n32:25.120 --> 32:29.120\n as far as how it's going to solve problems. I mean, this idea of multi hierarchical\n\n32:29.120 --> 32:35.760\n competence architecture, which is incredible to think about. So this hierarchy that evolution\n\n32:35.760 --> 32:43.120\n builds, I don't know who's responsible for this. I also see the incompetence of bureaucracies\n\n32:43.840 --> 32:52.320\n of humans when they get together. So how the hell does evolution build this, where at every level,\n\n32:53.200 --> 32:57.360\n only the best get to stick around, they somehow figure out how to do their job without knowing\n\n32:57.360 --> 33:04.160\n the bigger picture. And then there's like the bosses that do the bigger thing somehow, or that\n\n33:04.160 --> 33:11.040\n you can now abstract away the small group of cells as a as an organ or something. And then\n\n33:11.040 --> 33:16.640\n that organ does something bigger in the context of the full body or something like this.\n\n33:17.920 --> 33:23.680\n How is that built? Is there some intuition you can kind of provide of how that's constructed,\n\n33:23.680 --> 33:29.680\n that that hierarchical competence architecture? I love that competence,\n\n33:29.680 --> 33:33.280\n just the word competence is pretty cool in this context, because everybody's good at their job.\n\n33:34.080 --> 33:39.280\n Yeah, no, it's really key. And the other nice thing about competency is that so my central\n\n33:39.280 --> 33:43.840\n belief in all of this is that engineering is the right perspective on all of this stuff,\n\n33:43.840 --> 33:50.480\n because it gets you away from subjective terms. You know, people talk about sentience and this\n\n33:50.480 --> 33:54.880\n and that those things very hard to define, or people argue about them philosophically.\n\n33:54.880 --> 34:02.080\n I think that engineering terms like competency, like, you know, pursuit of goals, right? All of\n\n34:02.080 --> 34:06.400\n these things are, are empirically incredibly useful, because you know, when you see it,\n\n34:06.400 --> 34:11.920\n and if it helps you build, right, if I if I can pick the right level, I say, this thing has,\n\n34:11.920 --> 34:17.200\n I believe this is x level of like, competency, I think it's like a thermostat, or I think it's\n\n34:17.200 --> 34:22.800\n like a better thermostat, or I think it's a, you know, various other kinds of, you know,\n\n34:22.800 --> 34:28.000\n many, many different kinds of complex systems. If that helps me to control and predict and build\n\n34:28.000 --> 34:32.000\n such systems, then that's all there is to say, there's no more philosophy to argue about. So I\n\n34:32.000 --> 34:35.120\n like competency in that way, because you can quantify, you could, you have to, in fact, you\n\n34:35.120 --> 34:38.640\n have to, you have to make a claim competent at what? And then, or if I say, if I tell you,\n\n34:38.640 --> 34:42.400\n it has a goal, the question is, what's the goal? And how do you know? And I say, well, because\n\n34:42.400 --> 34:46.320\n every time I deviated from this particular state, that's what it spends energy to get back to,\n\n34:46.320 --> 34:51.920\n that's the goal. And we can quantify it, and we can be objective about it. So so so the the,\n\n34:51.920 --> 34:56.000\n we're not used to thinking about this, I give a talk sometimes called Why don't robots get cancer,\n\n34:56.000 --> 35:00.160\n right? And the reason robots don't get cancer is because generally speaking, with a few exceptions,\n\n35:00.160 --> 35:05.280\n our architectures have been, you've got a bunch of dumb parts. And you hope that if you put them\n\n35:05.280 --> 35:09.520\n together, the the the overlying machine will have some intelligence and do something rather,\n\n35:09.520 --> 35:13.280\n right, but the individual parts don't don't care, they don't have an agenda. Biology isn't like\n\n35:13.280 --> 35:20.560\n that every level has an agenda. And the final outcome is the result of cooperation and competition,\n\n35:20.560 --> 35:25.360\n both within and across levels. So for example, during embryogenesis, your tissues and organs are\n\n35:25.360 --> 35:28.800\n competing with each other. And it's actually a really important part of development, there's a\n\n35:28.800 --> 35:33.440\n reason they compete with each other, they're not all just, you know, sort of helping each other,\n\n35:33.440 --> 35:38.560\n they're also competing for information for metabolic for limited metabolic constraints.\n\n35:38.560 --> 35:43.440\n But to get back to your your other point, which is, you know, which is which is the seems like\n\n35:43.440 --> 35:48.800\n really efficient and good and so on compared to some of our human efforts. We also have to keep\n\n35:48.800 --> 35:56.320\n in mind that what happens here is that each level bends the option space for the level beneath so\n\n35:56.320 --> 36:03.920\n that your parts basically they don't see the the geometry. So I'm using them. And I think I take\n\n36:03.920 --> 36:10.160\n I take this the seriously terminology from from like, from like relativity, right, where the space\n\n36:10.160 --> 36:15.120\n is literally bent. So the option space is deformed by the higher level so that the lower levels, all\n\n36:15.120 --> 36:18.000\n they really have to do is go down their concentration gradient, they don't have to,\n\n36:18.000 --> 36:22.320\n in fact, they don't, they can't know what the big picture is. But if you bend the space just right,\n\n36:22.320 --> 36:26.720\n if they do what locally seems right, they end up doing your bidding, they end up doing things that\n\n36:26.720 --> 36:33.840\n are optimal in the in the higher space. Conversely, because the components are good at getting their\n\n36:33.840 --> 36:38.880\n job done, you as the higher level don't need to try to compute all the low level controls,\n\n36:38.880 --> 36:42.160\n all you're doing is bending the space, you don't know or care how they're going to do it.\n\n36:42.160 --> 36:47.680\n Give you a super simple example in the in the tappel, we found that okay, so so tappels need\n\n36:47.680 --> 36:51.600\n to become frogs and to become to go from a tappel head to a frog head, you have to rearrange the\n\n36:51.600 --> 36:55.200\n face. So the eyes have to move forward, the jaws have to come out the nostrils move like everything\n\n36:55.200 --> 36:59.840\n moves. It used to be thought that because all tappels look the same, and all frogs look the\n\n36:59.840 --> 37:03.200\n same. If you just remember, if every piece just moves in the right direction, the right amount,\n\n37:03.200 --> 37:08.000\n then you get your you get your fraud. Right. So we decided to test we I have this hypothesis that I\n\n37:08.000 --> 37:11.600\n thought I thought actually, the system is probably more intelligent than that. So what did we do?\n\n37:11.600 --> 37:15.920\n We made what we call Picasso tappels. So these are so everything is scrambled. So the eyes are on the\n\n37:15.920 --> 37:18.960\n back of the head, the jaws are off to the side, everything is scrambled. Well, guess what they\n\n37:18.960 --> 37:23.600\n make, they make pretty normal frogs, because all the different things move around in novel\n\n37:23.600 --> 37:28.240\n paths configurations until they get to the correct froggy sort of frog face configuration,\n\n37:28.240 --> 37:34.080\n then they stop. So, so the thing about that is now imagine evolution, right? So, so you make some\n\n37:34.080 --> 37:40.560\n sort of mutation, and it does, like every mutation, it does many things. So something good comes of it,\n\n37:40.560 --> 37:46.160\n but also it moves your mouth off to the side, right? Now, if if there wasn't this multi scale\n\n37:46.160 --> 37:49.360\n competency, you can see where this is going, if there wasn't this multi scale competency,\n\n37:49.360 --> 37:53.200\n the organism would be dead, your fitness is zero, because you can't eat. And you would never get to\n\n37:53.200 --> 37:57.680\n explore the other beneficial consequences of that mutation, you'd have to wait until you find some\n\n37:57.680 --> 38:01.840\n other way of doing it without moving the mouth, that's really hard. So, so the fitness landscape\n\n38:01.840 --> 38:06.320\n would be incredibly rugged evolution would take forever. The reason it works, one of the reasons\n\n38:06.320 --> 38:11.360\n it works so well, is because you do that, no worries, the mouth will find its way where where\n\n38:11.360 --> 38:15.680\n it belongs, right? So now you get to explore. So what that means is that all of these mutations\n\n38:15.680 --> 38:20.320\n that otherwise would be deleterious are now neutral, because the competency of the parts\n\n38:21.280 --> 38:26.480\n make up for all kinds of things. So all the noise of development, all the variability in the\n\n38:26.480 --> 38:32.080\n environment, all these things, the competency of the parts makes up for it. So the so so that's\n\n38:32.080 --> 38:36.080\n all that's all fantastic, right? That's all that's all great. The only other thing to remember when\n\n38:36.080 --> 38:41.040\n we compare this to human efforts is this. Every component has its own goals in various spaces,\n\n38:41.040 --> 38:46.560\n usually with very little regard for the welfare of the other levels. So so as a simple example,\n\n38:46.560 --> 38:52.000\n you know, you as a as a complex system, you will go out and you will do you know, jiu jitsu,\n\n38:52.000 --> 38:55.520\n or whatever, you'll have some go you have to go rock climbing, scrape a bunch of cells off your\n\n38:55.520 --> 38:59.680\n hands. And then you're happy as a system, right? You come back, and you've accomplished some goals,\n\n38:59.680 --> 39:03.120\n and you're really happy. Those cells are dead. They're gone. Right? Did you think about those\n\n39:03.120 --> 39:08.640\n cells? Not really, right? You had some you had some bruising out selfish SOB. That's it. And so\n\n39:08.640 --> 39:13.760\n and so that's the thing to remember is that, you know, and we know this from from history is that\n\n39:13.760 --> 39:19.520\n is that just being a collective isn't enough. Because what the goals of that collective will\n\n39:19.520 --> 39:24.560\n be relative to the welfare of the individual parts is a massively open and justify the means\n\n39:24.560 --> 39:29.600\n I'm telling you, Stalin was onto something. No, that's the danger. But we can exactly that's the\n\n39:29.600 --> 39:39.040\n danger of for us humans, we have to construct ethical systems under which we don't take seriously\n\n39:39.760 --> 39:43.840\n the full mechanism of biology and apply it to the way the world functions,\n\n39:43.840 --> 39:51.680\n which is which is an interesting line we've drawn. The world that built us is the one we\n\n39:51.680 --> 39:59.120\n reject in some sense, when we construct human societies, the idea that this country was founded\n\n39:59.120 --> 40:05.440\n on that all men are created equal. That's such a fascinating idea. That's like, you're fighting\n\n40:05.440 --> 40:14.640\n against nature and saying, well, there's something bigger here than a hierarchical competency\n\n40:14.640 --> 40:21.920\n architecture. But there's so many interesting things you said. So from an algorithmic perspective,\n\n40:21.920 --> 40:29.840\n the act of bending the option space. That's really, that's really profound. Because if you\n\n40:29.840 --> 40:36.800\n look at the way AI systems are built today, there's a big system, like I said, with robots,\n\n40:36.800 --> 40:42.080\n and as a goal, and he gets better and better at optimizing that goal at accomplishing that goal.\n\n40:42.080 --> 40:48.560\n But if biology built a hierarchical system where everything is doing computation,\n\n40:49.360 --> 40:54.640\n and everything is accomplishing the goal, not only that, it's kind of dumb,\n\n40:56.400 --> 41:03.360\n you know, with the limited with a bent option space is just doing the thing that's the easiest\n\n41:03.360 --> 41:10.960\n thing for in some sense. And somehow that allows you to have turtles on top of turtles,\n\n41:10.960 --> 41:17.920\n literally dumb systems on top of dumb systems that as a whole create something incredibly smart.\n\n41:18.480 --> 41:24.560\n Yeah, I mean, every system is has some degree of intelligence in its own problem domain. So,\n\n41:25.200 --> 41:30.400\n so cells will have problems they're trying to solve in physiological space and transcriptional\n\n41:30.400 --> 41:34.240\n space. And then I can give you some some cool examples of that. But the collective is trying\n\n41:34.240 --> 41:38.800\n to solve problems in anatomical space, right and forming a, you know, a creature and growing your\n\n41:38.800 --> 41:44.480\n blood vessels and so on. And then the collective the the the whole body is solving yet other\n\n41:44.480 --> 41:48.080\n problems, they may be in social space and linguistic space and three dimensional space.\n\n41:48.080 --> 41:52.080\n And who knows, you know, the group might be solving problems in, you know, I don't know,\n\n41:52.080 --> 41:57.840\n some sort of financial space or something. So one of the major differences with with most,\n\n41:59.280 --> 42:06.160\n with most AIs today is is a the kind of flatness of the architecture, but also of the fact that\n\n42:06.160 --> 42:13.360\n they're constructed from outside their their borders, and they're, you know, so a few. So,\n\n42:14.400 --> 42:18.640\n to a large extent, and of course, there are counter examples now, but but to a large extent,\n\n42:18.640 --> 42:23.760\n our technology has been such that you create a machine or a robot, it knows what its sensors are,\n\n42:23.760 --> 42:27.760\n it knows what its effectors are, it knows the boundary between it and the outside world,\n\n42:27.760 --> 42:32.800\n although this is given from the outside. Biology constructs this from scratch. Now the best example\n\n42:32.800 --> 42:38.880\n of this that that originally in robotics was actually Josh Bongard's work in 2006, where he\n\n42:38.880 --> 42:43.120\n made these, these robots that did not know their shape to start with. So like a baby, they sort of\n\n42:43.120 --> 42:47.040\n floundered around, they made some hypotheses, well, I did this, and I moved in this way. Well,\n\n42:47.040 --> 42:50.800\n maybe I'm a whatever, maybe I have wheels, or maybe I have six legs or whatever, right? And\n\n42:50.800 --> 42:54.240\n they would make a model and eventually will crawl around. So that's, I mean, that's really good.\n\n42:54.240 --> 42:58.160\n That's part of the autopoiesis, but we can go a step further. And some people are doing this. And\n\n42:58.160 --> 43:02.960\n then we're sort of working on some of this too, is this idea that let's even go back further,\n\n43:02.960 --> 43:06.640\n you don't even know what sensors you have, you don't know where you end in the outside world\n\n43:06.640 --> 43:11.200\n begins. All you have is is certain things like active inference, meaning you're trying to minimize\n\n43:11.200 --> 43:14.880\n surprise, right? You have some metabolic constraints, you don't have all the energy you\n\n43:14.880 --> 43:18.640\n need, you don't have all the time in the world to think about everything you want to think about. So\n\n43:18.640 --> 43:23.280\n that means that you can't afford to be a micro reductionist, you know, all this data coming in,\n\n43:23.280 --> 43:26.560\n you have to course grain it and say, I'm gonna take all this stuff, and I'm gonna call that a\n\n43:26.560 --> 43:30.560\n cat. I'm gonna take all this, I'm gonna call that the edge of the table I don't want to fall off of.\n\n43:30.560 --> 43:34.480\n And I don't want to know anything about the micro states, what I want to know is what is the optimal\n\n43:34.480 --> 43:38.560\n way to cut up my world. And by the way, this thing over here, that's me. And the reason that's me is\n\n43:38.560 --> 43:42.640\n because I have more control over this than I have over any of this other stuff. And so now you can\n\n43:42.640 --> 43:46.560\n begin to write. So that's self construction at that, that figuring out making models of the\n\n43:46.560 --> 43:51.120\n outside world, and then turning that inwards, and starting to make a model of yourself, right, which\n\n43:51.120 --> 43:58.560\n immediately starts to get into issues of agency and control. Because in order to if you are under\n\n43:58.560 --> 44:02.240\n metabolic constraints, meaning you don't have the energy, right, that all the energy in the world,\n\n44:02.240 --> 44:08.000\n you have to be efficient, that immediately forces you to start telling stories about coarse grained\n\n44:08.000 --> 44:11.840\n agents that do things, right, you don't have the energy to like Laplace's demon, you know,\n\n44:11.840 --> 44:17.360\n calculate every, every possible state that's going to happen, you have to you have to course grain,\n\n44:17.360 --> 44:21.920\n and you have to say, that is the kind of creature that does things, either things that I avoid,\n\n44:21.920 --> 44:25.280\n or things that I will go towards, that's a major food or whatever, whatever it's going to be.\n\n44:25.280 --> 44:30.560\n And so right at the base of simple, very simple organisms starting to make\n\n44:31.920 --> 44:39.040\n models of agents doing things, that is the origin of models of free will, basically, right, because\n\n44:39.040 --> 44:42.880\n you see the world around you as having agency. And then you turn that on yourself. And you say,\n\n44:42.880 --> 44:47.440\n wait, I have agency too, I can I do things, right. And and then you make decisions about what you're\n\n44:47.440 --> 44:52.640\n going to do. So all of this one one model is to view all of those kinds of things as\n\n44:53.920 --> 44:59.600\n being driven by that early need to determine what you are and to do so and to then take\n\n44:59.600 --> 45:04.800\n actions in the most energetically efficient space possible. Right. So free will emerges\n\n45:04.800 --> 45:10.000\n when you try to simplify, tell a nice narrative about your environment. I think that's very\n\n45:10.000 --> 45:18.080\n plausible. Yeah. You think free was an illusion. So you're kind of implying that it's a useful hack.\n\n45:19.360 --> 45:23.680\n Well, I'll say two things. The first thing is, I think I think it's very plausible to say that\n\n45:24.320 --> 45:30.560\n any organism that self or any agent that self whether it's biological or not, any agent that\n\n45:30.560 --> 45:36.960\n self constructs under energy constraints, is going to believe in free will, we'll get to whether it\n\n45:36.960 --> 45:41.200\n has free will momentarily. But but I think but I think what what it definitely drives is a view of\n\n45:41.200 --> 45:45.360\n yourself and the outside world as an agential view, I think that's inescapable. So that's true\n\n45:45.360 --> 45:50.480\n for even primitive organisms? I think so. I think that's now now they don't have now obviously,\n\n45:50.480 --> 45:55.360\n you have to scale down, right. So so so so they don't have the kinds of complex metacognition\n\n45:55.360 --> 45:59.520\n that we have. So they can do long term planning and thinking about free will and so on and so on.\n\n45:59.520 --> 46:05.040\n But but the sense of agency is really useful to accomplish tasks simple or complicated. That's\n\n46:05.040 --> 46:09.680\n right. In all kinds of spaces, not just in obvious three dimensional space. I mean, we're very good\n\n46:09.680 --> 46:16.720\n that the thing is, humans are very good at detecting agency of like medium sized objects\n\n46:16.720 --> 46:20.560\n moving at medium speeds in the three dimensional world, right? We see a bowling ball and we see a\n\n46:20.560 --> 46:23.920\n mouse and we immediately know what the difference is, right? And how we're going to mostly things\n\n46:23.920 --> 46:28.400\n you can eat or get eaten by. Yeah, yeah. That's our that's our training set, right? From the time\n\n46:28.400 --> 46:33.120\n you're little, your training set is visual data on on this this like little chunk of your experience.\n\n46:33.120 --> 46:39.120\n But imagine if imagine if from the time that we were born, we had innate senses of your blood\n\n46:39.120 --> 46:42.960\n chemistry, if you could feel your blood chemistry, the way you can see, right, you had a high bandwidth\n\n46:42.960 --> 46:46.640\n connection, and you could feel your blood chemistry, and you could see, you could sense all\n\n46:46.640 --> 46:51.040\n the things that your organs were doing. So your pancreas, your liver, all the things. If we had\n\n46:51.040 --> 46:55.760\n that you we would be very good at detecting intelligence and physiological space, we would\n\n46:55.760 --> 47:00.320\n know the level of intelligence that our various organs were deploying to deal with things that\n\n47:00.320 --> 47:04.400\n were coming to anticipate the stimuli to, you know, but but we're just terrible at that. We\n\n47:04.400 --> 47:07.920\n don't, in fact, in fact, people don't even, you know, you talk about intelligence that these are\n\n47:07.920 --> 47:12.160\n the paper spaces. And a lot of people think that's just crazy, because, because all we're all we know\n\n47:12.160 --> 47:18.880\n is motion. We do have access to that information. So it's actually possible that so evolution could\n\n47:18.880 --> 47:24.400\n if we wanted to construct an organism that's able to perceive the flow of blood through your body,\n\n47:24.400 --> 47:32.560\n the way you see an old friend and say, yo, what's up? How's the wife and the kids? In that same way,\n\n47:32.560 --> 47:37.920\n you would see that you would feel like a connection to the liver. Yeah, yeah, I think,\n\n47:37.920 --> 47:41.680\n you know, maybe other people's liver and not just your own, because you don't have access to other\n\n47:41.680 --> 47:46.160\n people's. Not yet. But you could imagine some really interesting connection, right? But like\n\n47:46.160 --> 47:52.800\n sexual selection, like, oh, that girl's got a nice liver. Well, that's like, the way her blood flows,\n\n47:52.800 --> 47:58.320\n the dynamics of the blood is very interesting. It's novel. I've never seen one of those.\n\n47:58.320 --> 48:03.920\n But you know, that's exactly what we're trying to half ass when we, when we judge judgment of\n\n48:03.920 --> 48:09.120\n beauty by facial symmetry and so on. That's a half assed assessment of exactly that. Because\n\n48:09.120 --> 48:13.760\n if your cells could not cooperate enough to keep your organism symmetrical, you know,\n\n48:13.760 --> 48:17.120\n you can make some inferences about what else is wrong, right? Like that's a very, you know,\n\n48:17.120 --> 48:23.280\n that's a very basic. Interesting. Yeah. So that in some deep sense, actually, that is what we're\n\n48:23.280 --> 48:33.120\n doing. We're trying to infer how health, we use the word healthy, but basically, how functional\n\n48:33.120 --> 48:41.120\n is this biological system I'm looking at so I can hook up with that one and make offspring? Yeah,\n\n48:41.120 --> 48:45.360\n yeah. Well, what kind of hardware might their genomics give me that that might be useful in\n\n48:45.360 --> 48:50.720\n the future? I wonder why evolution didn't give us a higher resolution signal. Like why the whole\n\n48:50.720 --> 48:58.160\n peacock thing with the feathers? It doesn't seem, it's a very low bandwidth signal for\n\n48:58.160 --> 49:02.880\n sexual selection. I'm gonna, and I'm not an expert on this stuff, but on peacocks. Well,\n\n49:02.880 --> 49:08.880\n you know, but I'll take a stab at the reason. I think that it's because it's an arms race. You\n\n49:08.880 --> 49:14.160\n see, you don't want everybody to know everything about you. So I think that as much as, as much as,\n\n49:14.160 --> 49:19.680\n and in fact, there's another interesting part of this arms race, which is, if you think about this,\n\n49:21.120 --> 49:27.760\n the most adaptive, evolvable system is one that has the most level of top down control, right?\n\n49:27.760 --> 49:33.920\n If it's really easy to say to a bunch of cells, make another finger versus, okay, here's 10,000\n\n49:33.920 --> 49:38.800\n gene expression changes that you need to do to make it to change your finger, right? The system\n\n49:38.800 --> 49:42.320\n with good top down control that has memory and when we need to get back to that, by the way,\n\n49:42.320 --> 49:48.080\n that's a question I neglected to answer about where the memory is and so on. A system that uses\n\n49:48.080 --> 49:53.920\n all of that is really highly evolvable and that's fantastic. But guess what? It's also highly subject\n\n49:53.920 --> 50:00.640\n to hijacking by parasites, by cheaters of various kinds, by conspecifics. Like we found that,\n\n50:01.440 --> 50:04.880\n and then that goes back to the story of the pattern memory in these planaria,\n\n50:04.880 --> 50:09.840\n there's a bacterium that lives on these planaria. That bacterium has an input into how many heads\n\n50:09.840 --> 50:14.480\n the worm is going to have because it's hijacks that control system and it's able to make a\n\n50:14.480 --> 50:18.480\n chemical that basically interfaces with the system that calculates how many heads you're\n\n50:18.480 --> 50:22.080\n supposed to have and they can make them have two heads. And so you can imagine that if you\n\n50:22.080 --> 50:25.520\n are two, so you want to be understandable for your own parts to understand each other,\n\n50:25.520 --> 50:28.880\n but you don't want to be too understandable because you'll be too easily controllable.\n\n50:28.880 --> 50:36.640\n And so I think that my guess is that that opposing pressure keeps us from being a super high\n\n50:36.640 --> 50:40.240\n bandwidth kind of thing where we can just look at somebody and know everything about them.\n\n50:40.240 --> 50:45.520\n So it's a kind of biological game of Texas hold them. You're showing some cards and you're hiding\n\n50:45.520 --> 50:50.560\n other cards and there's part of it and there's bluffing and there's all that. And then there's\n\n50:50.560 --> 50:55.520\n probably whole species that would do way too much bluffing. That's probably where peacocks fall.\n\n50:56.800 --> 51:04.400\n There's a book that I don't remember if I read or if I read summaries of the book,\n\n51:04.400 --> 51:10.160\n but it's about evolution of beauty and birds. Where is that from? Is that a book or does\n\n51:10.160 --> 51:15.600\n Richard Dawkins talk about it? But basically there's some species start to like over select\n\n51:15.600 --> 51:21.280\n for beauty, not over select. They just some reason select for beauty. There is a case to be made.\n\n51:21.280 --> 51:27.200\n Actually now I'm starting to remember, I think Darwin himself made a case that you can select\n\n51:27.200 --> 51:35.680\n based on beauty alone. There's a point where beauty doesn't represent some underlying biological\n\n51:35.680 --> 51:44.400\n truth. You start to select for beauty itself. And I think the deep question is there some evolutionary\n\n51:44.400 --> 51:53.760\n value to beauty, but it's an interesting kind of thought that can we deviate completely from\n\n51:53.760 --> 51:59.520\n the deep biological truth to actually appreciate some kind of the summarization in itself.\n\n52:00.480 --> 52:06.800\n Let me get back to memory because this is a really interesting idea. How do a collection of cells\n\n52:07.600 --> 52:13.520\n remember anything? How do biological systems remember anything? How is that akin to the kind\n\n52:13.520 --> 52:17.920\n of memory we think of humans as having within our big cognitive engine?\n\n52:17.920 --> 52:24.240\n Yeah. One of the ways to start thinking about bioelectricity is to ask ourselves, where did\n\n52:25.200 --> 52:32.320\n neurons and all these cool tricks that the brain uses to run these amazing problem solving abilities\n\n52:32.320 --> 52:36.400\n on and basically an electrical network, right? Where did that come from? They didn't just evolve,\n\n52:36.400 --> 52:40.720\n you know, appear out of nowhere. It must have evolved from something. And what it evolved from\n\n52:40.720 --> 52:46.320\n was a much more ancient ability of cells to form networks to solve other kinds of problems. For\n\n52:46.320 --> 52:51.520\n example, to navigate more for space to control the body shape. And so all of the components\n\n52:52.320 --> 52:58.320\n of neurons, so ion channels, neurotransmitter machinery, electrical synapses, all this stuff\n\n52:58.320 --> 53:03.600\n is way older than brains, way older than neurons, in fact, older than multicellularity. And so\n\n53:03.600 --> 53:09.120\n it was already that even bacterial biofilms, there's some beautiful work from UCSD on brain\n\n53:09.120 --> 53:14.880\n like dynamics and bacterial biofilms. So evolution figured out very early on that electrical networks\n\n53:14.880 --> 53:19.120\n are amazing at having memories, at integrating information across distance, at different kinds\n\n53:19.120 --> 53:23.760\n of optimization tasks, you know, image recognition and so on, long before there were brains.\n\n53:24.400 --> 53:30.160\n Can you actually just step back? We'll return to it. What is bioelectricity? What is biochemistry?\n\n53:30.160 --> 53:36.160\n What is, what are electrical networks? I think a lot of the biology community focuses on\n\n53:36.160 --> 53:45.840\n the chemicals as the signaling mechanisms that make the whole thing work. You have, I think,\n\n53:47.200 --> 53:53.600\n to a large degree, uniquely, maybe you can correct me on that, have focused on the bioelectricity,\n\n53:53.600 --> 54:00.080\n which is using electricity for signaling. There's also probably mechanical. Sure, sure. Like knocking\n\n54:00.080 --> 54:07.840\n on the door. So what's the difference? And what's an electrical network? Yeah, so I want to make\n\n54:07.840 --> 54:14.800\n sure and kind of give credit where credit is due. So as far back as 1903, and probably late 1800s\n\n54:14.800 --> 54:20.560\n already, people were thinking about the importance of electrical phenomena in life. So I'm for sure\n\n54:20.560 --> 54:25.920\n not the first person to stress the importance of electricity. People, there were waves of research\n\n54:25.920 --> 54:33.600\n in the in the 30s, in the 40s, and then, again, in the kind of 70s, 80s, and 90s of sort of the\n\n54:33.600 --> 54:37.520\n pioneers of bioelectricity, who did some amazing work on all this, I think, I think what what\n\n54:37.520 --> 54:43.040\n we've done that's new, is to step away from this idea that, and I'll describe what what the\n\n54:43.040 --> 54:46.800\n bioelectricity is a step away from the idea that, well, here's another piece of physics that you\n\n54:46.800 --> 54:51.760\n need to keep track of to understand physiology and development. And to really start looking at this\n\n54:51.760 --> 54:57.360\n as saying, no, this is a privileged computational layer that gives you access to the actual\n\n54:57.360 --> 55:02.160\n cognition of the tissue of basal cognition. So, so merging that that developmental biophysics with\n\n55:02.160 --> 55:05.920\n ideas and cognition of computation, and so on, I think I think that's what we've done that's new.\n\n55:05.920 --> 55:09.840\n But people have been talking about bioelectricity for a really long time. And so I'll, so I'll\n\n55:09.840 --> 55:16.400\n define that. So what happens is that if you have, if you have a single cell, cell has a membrane,\n\n55:16.400 --> 55:21.600\n in that membrane are proteins called ion channels, and those proteins allow charged molecules,\n\n55:21.600 --> 55:27.280\n potassium, sodium, chloride, to go in and out under certain circumstances. And when there's\n\n55:27.280 --> 55:33.200\n an imbalance of of those ions, there becomes a voltage gradient across that membrane. And so\n\n55:33.200 --> 55:38.720\n all cells, all living cells try to hold a particular kind of voltage difference across\n\n55:38.720 --> 55:44.240\n the membrane, and they spend a lot of energy to do so. When you now now, so that's it, that's it,\n\n55:44.240 --> 55:48.720\n that's a single cell. When you have multiple cells, the cells sitting next to each other,\n\n55:48.720 --> 55:53.200\n they can communicate their voltage state to each other via a number of different ways. But one of\n\n55:53.200 --> 55:56.880\n them is this thing called a gap junction, which is basically like a little submarine hatch that\n\n55:56.880 --> 56:01.440\n just kind of docks, right? And the ions from one side can flow to the other side, and vice versa.\n\n56:02.160 --> 56:02.720\n So...\n\n56:02.720 --> 56:08.720\n Isn't it incredible that this evolved? Isn't that wild? Because that didn't exist.\n\n56:09.600 --> 56:11.440\n Correct. This had to be, this had to be evolved.\n\n56:11.440 --> 56:12.640\n It had to be invented.\n\n56:12.640 --> 56:13.280\n That's right.\n\n56:13.280 --> 56:17.440\n Somebody invented electricity in the ocean. When did this get invented?\n\n56:17.440 --> 56:22.800\n Yeah. So, I mean, it is incredible. The guy who discovered gap junctions,\n\n56:22.800 --> 56:25.360\n Werner Loewenstein, I visited him. He was really old.\n\n56:25.360 --> 56:26.720\n A human being?\n\n56:26.720 --> 56:27.360\n He discovered them.\n\n56:27.360 --> 56:32.480\n Because who really discovered them lived probably four billion years ago.\n\n56:32.480 --> 56:32.880\n Good point.\n\n56:32.880 --> 56:35.600\n So you give credit where credit is due, I'm just saying.\n\n56:35.600 --> 56:43.200\n He rediscovered gap junctions. But when I visited him in Woods Hole, maybe 20 years ago now,\n\n56:43.200 --> 56:47.840\n he told me that he was writing, and unfortunately, he passed away, and I think this book never got\n\n56:47.840 --> 56:52.800\n written. He was writing a book on gap junctions and consciousness. And I think it would have been\n\n56:52.800 --> 56:57.040\n an incredible book, because gap junctions are magic. I'll explain why in a minute.\n\n56:57.920 --> 57:02.720\n What happens is that, just imagine, the thing about both these ion channels and these gap\n\n57:02.720 --> 57:08.880\n junctions is that many of them are themselves voltage sensitive. So that's a voltage sensitive\n\n57:08.880 --> 57:13.600\n current conductance. That's a transistor. And as soon as you've invented one, immediately,\n\n57:13.600 --> 57:20.240\n you now get access to, from this platonic space of mathematical truths, you get access to all of the\n\n57:20.240 --> 57:26.000\n cool things that transistors do. So now, when you have a network of cells, not only do they talk to\n\n57:26.000 --> 57:30.160\n each other, but they can send messages to each other, and the differences of voltage can propagate.\n\n57:30.160 --> 57:34.000\n Now, to neuroscientists, this is old hat, because you see this in the brain, right? This action\n\n57:34.000 --> 57:40.000\n potentials, the electricity. They have these awesome movies where you can take a zebra,\n\n57:40.000 --> 57:45.040\n like a transparent animal, like a zebrafish, and you can literally look down, and you can see all\n\n57:45.040 --> 57:49.120\n the firings as the fish is making decisions about what to eat and things like this. It's amazing.\n\n57:49.120 --> 57:54.160\n Well, your whole body is doing that all the time, just much slower. So there are very few things\n\n57:54.160 --> 57:59.360\n that neurons do that all the cells in your body don't do. They all do very similar things, just\n\n57:59.360 --> 58:04.320\n on a much slower timescale. And whereas your brain is thinking about how to solve problems in\n\n58:04.320 --> 58:08.880\n three dimensional space, the cells in an embryo are thinking about how to solve problems in\n\n58:08.880 --> 58:12.240\n anatomical space. They're trying to have memories like, hey, how many fingers are we supposed to\n\n58:12.240 --> 58:15.840\n have? Well, how many do we have now? What do we do to get from here to there? That's the kind of\n\n58:15.840 --> 58:20.720\n problems they're thinking about. And the reason that gap junctions are magic is, imagine, right,\n\n58:20.720 --> 58:29.360\n from the earliest time. Here are two cells. This cell, how can they communicate? Well,\n\n58:29.360 --> 58:34.800\n the simple version is this cell could send a chemical signal, it floats over, and it hits\n\n58:34.800 --> 58:39.200\n a receptor on this cell, right? Because it comes from outside, this cell can very easily tell that\n\n58:39.200 --> 58:44.240\n that came from outside. Whatever information is coming, that's not my information. That information\n\n58:44.240 --> 58:48.640\n is coming from the outside. So I can trust it, I can ignore it, I can do various things with it,\n\n58:48.640 --> 58:52.160\n I can do various things with it, whatever, but I know it comes from the outside. Now imagine\n\n58:52.160 --> 58:55.360\n instead that you have two cells with a gap junction between them. Something happens,\n\n58:55.360 --> 58:59.760\n let's say this cell gets poked, there's a calcium spike, the calcium spike or whatever small\n\n58:59.760 --> 59:04.400\n molecule signal propagates through the gap junction to this cell. There's no ownership\n\n59:04.400 --> 59:10.000\n metadata on that signal. This cell does not know now that it came from outside because it looks\n\n59:10.000 --> 59:15.200\n exactly like its own memories would have looked like of whatever had happened, right? So gap\n\n59:15.200 --> 59:21.440\n junctions to some extent wipe ownership information on data, which means that if I can't, if you and\n\n59:21.440 --> 59:26.320\n I are sharing memories and we can't quite tell who the memories belong to, that's the beginning of a\n\n59:26.320 --> 59:31.840\n mind melt. That's the beginning of a scale up of cognition from here's me and here's you to no,\n\n59:31.840 --> 59:36.640\n now there's just us. So they enforce a collective intelligence gap junctions. That's right. It\n\n59:36.640 --> 59:39.680\n helps. It's the beginning. It's not the whole story by any means, but it's the start.\n\n59:39.680 --> 59:48.240\n Where's state stored of the system? Is it in part in the gap junctions themselves? Is it in the\n\n59:48.240 --> 59:55.360\n cells? There are many, many layers to this as always in biology. So there are chemical networks.\n\n59:55.360 --> 1:00:00.320\n So for example, gene regulatory networks, right? Which, or basically any kind of chemical pathway\n\n1:00:00.320 --> 1:00:04.480\n where different chemicals activate and repress each other, they can store memories. So in a\n\n1:00:04.480 --> 1:00:09.120\n dynamical system sense, they can store memories. They can get into stable states that are hard to\n\n1:00:09.120 --> 1:00:13.200\n pull them out of. So that becomes, once they get in, that's a memory, a permanent memory or a\n\n1:00:13.200 --> 1:00:17.760\n semi permanent memory of something that's happened. There are cytoskeletal structures that are\n\n1:00:17.760 --> 1:00:24.640\n physically, they store memories in physical configuration. There are electrical memories\n\n1:00:24.640 --> 1:00:30.560\n like flip flops where there is no physical. So if you look, I showed my students this example\n\n1:00:30.560 --> 1:00:37.920\n as a flip flop. And the reason that it stores a zero one is not because some piece of the hardware\n\n1:00:37.920 --> 1:00:42.880\n moved. It's because there's a cycling of the current in one side of the thing. If I come over\n\n1:00:42.880 --> 1:00:50.080\n and I hold the other side to a high voltage for a brief period of time, it flips over and now it's\n\n1:00:50.080 --> 1:00:54.880\n here. But none of the hardware moved. The information is in a stable dynamical sense. And\n\n1:00:54.880 --> 1:00:58.560\n if you were to x ray the thing, you couldn't tell me if it was zero or one, because all you would\n\n1:00:58.560 --> 1:01:03.120\n see is where the hardware is. You wouldn't see the energetic state of the system. So there are\n\n1:01:03.120 --> 1:01:09.680\n bioelectrical states that are held in that exact way, like volatile ram basically, like in the\n\n1:01:09.680 --> 1:01:14.960\n electrical state. It's very akin to the different ways that memory is stored in a computer.\n\n1:01:15.840 --> 1:01:21.120\n So there's ram, there's hard drive. You can make that mapping, right? So I think the interesting\n\n1:01:21.120 --> 1:01:26.960\n thing is that based on the biology, we can have a more sophisticated, you know, I think we can\n\n1:01:26.960 --> 1:01:32.560\n revise some of our computer engineering methods because there are some interesting things that\n\n1:01:32.560 --> 1:01:38.400\n biology we haven't done yet. But that mapping is not bad. I mean, I think it works in many ways.\n\n1:01:38.400 --> 1:01:43.280\n Yeah, I wonder because I mean, the way we build computers at the root of computer science is the\n\n1:01:43.280 --> 1:01:52.240\n idea of proof of correctness. We program things to be perfect, reliable. You know, this idea of\n\n1:01:52.240 --> 1:01:58.240\n resilience and robustness to unknown conditions is not as important. So that's what biology is really\n\n1:01:58.240 --> 1:02:04.000\n good at. So I don't know what kind of systems. I don't know how we go from a computer to a\n\n1:02:04.000 --> 1:02:10.480\n biological system in the future. Yeah, I think that, you know, the thing about biology is all\n\n1:02:10.480 --> 1:02:15.280\n about making really important decisions really quickly on very limited information. I mean,\n\n1:02:15.280 --> 1:02:19.600\n that's what biology is all about. You have to act, you have to act now. The stakes are very high,\n\n1:02:19.600 --> 1:02:24.080\n and you don't know most of what you need to know to be perfect. And so there's not even an attempt\n\n1:02:24.080 --> 1:02:29.920\n to be perfect or to get it right in any sense. There are just things like active inference,\n\n1:02:29.920 --> 1:02:37.120\n minimize surprise, optimize some efficiency and some things like this that guides the whole\n\n1:02:37.120 --> 1:02:44.640\n business. I mentioned too offline that somebody who's a fan of your work is Andre Kapathy.\n\n1:02:44.640 --> 1:02:52.720\n And he's, amongst many things, also writes occasionally a great blog. He came up with\n\n1:02:52.720 --> 1:03:00.720\n this idea, I don't know if he coined the term, but of software 2.0, where the programming is\n\n1:03:00.720 --> 1:03:08.240\n done in the space of configuring these artificial neural networks. Is there some sense in which that\n\n1:03:08.240 --> 1:03:16.400\n would be the future of programming for us humans, where we're less doing like Python like programming\n\n1:03:16.400 --> 1:03:25.680\n and more... How would that look like? But basically doing the hyperparameters of something\n\n1:03:25.680 --> 1:03:33.360\n akin to a biological system and watching it go and adjusting it and creating some kind of feedback\n\n1:03:33.360 --> 1:03:40.800\n loop within the system so it corrects itself. And then we watch it over time accomplish the goals\n\n1:03:40.800 --> 1:03:46.880\n we want it to accomplish. Is that kind of the dream of the dogs that you described in the Nature\n\n1:03:46.880 --> 1:03:54.960\n paper? Yeah. I mean, that's what you just painted is a very good description of our efforts at\n\n1:03:54.960 --> 1:04:01.040\n regenerative medicine as a kind of somatic psychiatry. So the idea is that you're not trying\n\n1:04:01.040 --> 1:04:07.920\n to micromanage. I mean, think about the limitations of a lot of the medicines today. We try to\n\n1:04:07.920 --> 1:04:14.560\n interact down at the level of pathways. So we're trying to micromanage it. What's the problem? Well,\n\n1:04:14.560 --> 1:04:20.800\n one problem is that for almost every medicine other than antibiotics, once you stop it, the\n\n1:04:20.800 --> 1:04:23.680\n problem comes right back. You haven't fixed anything. You were addressing symptoms. You\n\n1:04:23.680 --> 1:04:28.560\n weren't actually curing anything, again, except for antibiotics. That's one problem. The other\n\n1:04:28.560 --> 1:04:33.600\n problem is you have massive amount of side effects because you were trying to interact at the lowest\n\n1:04:33.600 --> 1:04:40.400\n level. It's like, I'm going to try to program this computer by changing the melting point of\n\n1:04:40.400 --> 1:04:46.640\n copper. Maybe you can do things that way, but my God, it's hard to program at the hardware level.\n\n1:04:46.640 --> 1:04:53.360\n So what I think we're starting to understand is that, and by the way, this goes back to what you\n\n1:04:53.360 --> 1:04:58.800\n were saying before about that we could have access to our internal state. So people who practice that\n\n1:04:58.800 --> 1:05:04.000\n kind of stuff, so yoga and biofeedback and those, those are all the people that uniformly will say\n\n1:05:04.000 --> 1:05:08.480\n things like, well, the body has an intelligence and this and that. Those two sets overlap perfectly\n\n1:05:08.480 --> 1:05:13.600\n because that's exactly right. Because once you start thinking about it that way, you realize that\n\n1:05:13.600 --> 1:05:18.480\n the better locus of control is not always at the lowest level. This is why we don't all program\n\n1:05:18.480 --> 1:05:24.720\n with a soldering iron. We take advantage of the high level intelligences that are there,\n\n1:05:24.720 --> 1:05:28.960\n intelligences that are there, which means trying to figure out, okay, which of your tissues can\n\n1:05:28.960 --> 1:05:35.200\n learn? What can they learn? Why is it that certain drugs stop working after you take them for a while\n\n1:05:35.200 --> 1:05:40.160\n with this habituation, right? And so can we understand habituation, sensitization, associative\n\n1:05:40.160 --> 1:05:44.400\n learning, these kinds of things in chemical pathways? We're going to have a completely\n\n1:05:44.400 --> 1:05:49.200\n different way. I think we're going to have a completely different way of using drugs and of\n\n1:05:49.200 --> 1:05:54.560\n medicine in general when we start focusing on the goal states and on the intelligence of our\n\n1:05:54.560 --> 1:05:59.040\n subsystems as opposed to treating everything as if the only path was micromanagement from\n\n1:05:59.040 --> 1:06:05.200\n chemistry upwards. Well, can you speak to this idea of somatic psychiatry? What are somatic cells?\n\n1:06:05.200 --> 1:06:11.760\n How do they form networks that use bioelectricity to have memory and all those kinds of things?\n\n1:06:11.760 --> 1:06:16.160\n Yeah. What are somatic cells like basics here? Somatic cells just means the cells of your body.\n\n1:06:16.160 --> 1:06:20.000\n Soma just means body, right? So somatic cells are just the... I'm not even specifically making a\n\n1:06:20.000 --> 1:06:23.920\n distinction between somatic cells and stem cells or anything like that. I mean, basically all the\n\n1:06:23.920 --> 1:06:28.400\n cells in your body, not just neurons, but all the cells in your body. They form electrical\n\n1:06:28.400 --> 1:06:32.400\n networks during embryogenesis, during regeneration. What those networks are doing\n\n1:06:33.280 --> 1:06:39.600\n in part is processing information about what our current shape is and what the goal shape is.\n\n1:06:39.600 --> 1:06:45.120\n Now, how do I know this? Because I can give you a couple of examples. One example is when we started\n\n1:06:45.120 --> 1:06:50.400\n studying this, we said, okay, here's a planarian. A planarian is a flatworm. It has one head and one\n\n1:06:50.400 --> 1:06:55.200\n tail normally. And the amazing... There's several amazing things about planaria, but basically they\n\n1:06:55.200 --> 1:07:00.960\n kind of... I think planaria hold the answer to pretty much every deep question of life.\n\n1:07:00.960 --> 1:07:04.960\n For one thing, they're similar to our ancestors. So they have true symmetry. They have a true\n\n1:07:04.960 --> 1:07:08.320\n brain. They're not like earthworms. They're a much more advanced life form. They have lots\n\n1:07:08.320 --> 1:07:12.240\n of different internal organs, but they're these little... They're about maybe two centimeters in\n\n1:07:12.240 --> 1:07:17.680\n the centimeter to two in size. They have a head and a tail. And the first thing is planaria are\n\n1:07:17.680 --> 1:07:22.320\n immortal. So they do not age. There's no such thing as an old planarian. So that right there\n\n1:07:22.320 --> 1:07:27.680\n tells you that these theories of thermodynamic limitations on lifespan are wrong. It's not that\n\n1:07:27.680 --> 1:07:33.280\n well over time everything degrades. No, planaria can keep it going for probably how long have\n\n1:07:33.280 --> 1:07:38.960\n they been around 400 million years. So the planaria in our lab are actually in physical\n\n1:07:38.960 --> 1:07:43.600\n continuity with planaria that were here 400 million years ago. So there's planaria that\n\n1:07:43.600 --> 1:07:49.280\n have lived that long essentially. What does it mean physical continuity? Because what they do\n\n1:07:49.280 --> 1:07:54.560\n is they split in half. The way they reproduce is they split in half. So the planaria, the back end\n\n1:07:54.560 --> 1:07:59.680\n grabs the petri dish, the front end takes off and they rip themselves in half. But isn't it some\n\n1:07:59.680 --> 1:08:07.600\n sense where like you are a physical continuation? Yes, except that we go through a bottleneck of one\n\n1:08:07.600 --> 1:08:11.760\n cell, which is the egg. They do not. I mean, they can. There's certain planaria. Got it. So we go\n\n1:08:11.760 --> 1:08:17.200\n through a very ruthless compression process and they don't. Yes. Like an auto encoder, you know,\n\n1:08:17.200 --> 1:08:22.160\n sort of squashed down to one cell and then back out. These guys just tear themselves in half.\n\n1:08:22.880 --> 1:08:26.640\n And so the other amazing thing about them is they regenerate. So you can cut them into pieces.\n\n1:08:26.640 --> 1:08:32.560\n The record is, I think, 276 or something like that by Thomas Hunt Morgan. And each piece regrows a\n\n1:08:32.560 --> 1:08:36.960\n perfect little worm. They know exactly, every piece knows exactly what's missing, what needs\n\n1:08:36.960 --> 1:08:45.360\n to happen. In fact, if you chop it in half, as it grows the other half, the original tissue shrinks\n\n1:08:45.360 --> 1:08:50.080\n so that when the new tiny head shows up, they're proportional. So it keeps perfect proportion.\n\n1:08:50.080 --> 1:08:54.160\n If you starve them, they shrink. If you feed them again, they expand. Their control,\n\n1:08:54.160 --> 1:08:58.960\n their anatomical control is just insane. Somebody cut them into over 200 pieces.\n\n1:08:58.960 --> 1:09:03.520\n Yeah. Thomas Hunt Morgan did. Hashtag science. Amazing. And maybe more. I mean,\n\n1:09:03.520 --> 1:09:06.720\n they didn't have antibiotics back then. I bet he lost some due to infection. I bet it's\n\n1:09:06.720 --> 1:09:10.000\n actually more than that. I bet you could do more than that. Humans can't do that.\n\n1:09:11.760 --> 1:09:16.960\n Well, yes. I mean, again, true, except that... Maybe you can at the embryonic level.\n\n1:09:16.960 --> 1:09:21.120\n Well, that's the thing, right? So when I talk about this, I say, just remember that\n\n1:09:21.120 --> 1:09:24.880\n as amazing as it is to grow a whole planarian from a tiny fragment,\n\n1:09:24.880 --> 1:09:30.640\n half of the human population can grow a full body from one cell. So development is really,\n\n1:09:30.640 --> 1:09:34.240\n you can look at development as just an example of regeneration.\n\n1:09:34.240 --> 1:09:39.600\n Yeah. To think, we'll talk about regenerative medicine, but there's some sense of what would\n\n1:09:39.600 --> 1:09:45.520\n be like that warm in like 500 years where I can just go regrow a hand.\n\n1:09:46.320 --> 1:09:49.920\n Yep. With given time, it takes time to grow large things.\n\n1:09:49.920 --> 1:09:50.560\n For now.\n\n1:09:50.560 --> 1:09:51.840\n Yeah, I think so. I think.\n\n1:09:51.840 --> 1:09:56.240\n You can probably... Why not accelerate? Oh, biology takes its time?\n\n1:09:56.800 --> 1:10:00.080\n I'm not going to say anything is impossible, but I don't know of a way to accelerate these\n\n1:10:00.080 --> 1:10:04.000\n processes. I think it's possible. I think we are going to be regenerative, but I don't know of a\n\n1:10:04.000 --> 1:10:04.800\n way to make it faster.\n\n1:10:04.800 --> 1:10:10.080\n I could just think people from a few centuries from now would be like, well, they used to have\n\n1:10:10.080 --> 1:10:17.920\n to wait a week for the hand to regrow. It's like when the microwave was invented. You can toast\n\n1:10:17.920 --> 1:10:27.360\n your... What's that called when you put a cheese on a toast? It's delicious is all I know. I'm\n\n1:10:27.360 --> 1:10:33.280\n blanking. Anywho. All right. So planaria, why were we talking about the magical planaria that they\n\n1:10:33.280 --> 1:10:34.320\n have the mystery of life?\n\n1:10:34.320 --> 1:10:37.120\n Yeah. So the reason we're talking about planaria is not only are they immortal,\n\n1:10:37.680 --> 1:10:42.880\n not only do they regenerate every part of the body, they generally don't get cancer,\n\n1:10:43.920 --> 1:10:47.360\n which we can talk about why that's important. They're smart. They can learn things. You can\n\n1:10:47.360 --> 1:10:52.320\n train them. And it turns out that if you train a planaria and then cut their heads off, the tail\n\n1:10:52.320 --> 1:10:56.000\n will regenerate a brand new brain that still remembers the original information.\n\n1:10:56.000 --> 1:10:58.960\n Do they have a biological network going on or no?\n\n1:10:58.960 --> 1:10:59.280\n Yes.\n\n1:10:59.280 --> 1:11:05.200\n So their somatic cells are forming a network. And that's what you mean by a true brain? What's the\n\n1:11:05.200 --> 1:11:06.480\n requirement for a true brain?\n\n1:11:07.200 --> 1:11:12.080\n Like everything else, it's a continuum, but a true brain has certain characteristics as far as the\n\n1:11:12.080 --> 1:11:15.680\n density, like a localized density of neurons that guides behavior.\n\n1:11:15.680 --> 1:11:16.240\n In the head.\n\n1:11:16.240 --> 1:11:22.080\n Exactly. Exactly. If you cut their head off, the tail doesn't do anything. It just sits there\n\n1:11:22.080 --> 1:11:28.000\n until a new brain regenerates. They have all the same neurotransmitters that you and I have.\n\n1:11:28.000 --> 1:11:32.720\n But here's why we're talking about them in this context. So here's your planaria. You cut off the\n\n1:11:32.720 --> 1:11:35.840\n head. You cut off the tail. You have a middle fragment. That middle fragment has to make one\n\n1:11:35.840 --> 1:11:40.080\n head and one tail. How does it know how many of each to make? And where do they go? How come it\n\n1:11:40.080 --> 1:11:46.960\n doesn't switch? How come, right? So we did a very simple thing. And we said, okay, let's make the\n\n1:11:46.960 --> 1:11:52.400\n hypothesis that there's a somatic electrical network that remembers the correct pattern,\n\n1:11:52.400 --> 1:11:55.760\n and that what it's doing is recalling that memory and building to that pattern.\n\n1:11:55.760 --> 1:12:01.920\n So what we did was we used a way to visualize electrical activity in these cells, right? It's a\n\n1:12:01.920 --> 1:12:06.960\n variant of what people used to look for electricity in the brain. And we saw that that fragment has a\n\n1:12:08.080 --> 1:12:12.720\n very particular electrical pattern. You can literally see it once we developed the technique.\n\n1:12:12.720 --> 1:12:17.920\n It has a very particular electrical pattern that shows you where the head and the tail goes,\n\n1:12:17.920 --> 1:12:22.240\n right? You can just see it. And then we said, okay, well now let's test the idea that that's\n\n1:12:22.240 --> 1:12:25.920\n a memory that actually controls where the head and the tail goes. Let's change that pattern. So\n\n1:12:25.920 --> 1:12:29.680\n basically, incept the false memory. And so what you can do is you can do that in many different\n\n1:12:29.680 --> 1:12:34.640\n ways. One way is with drugs that target ion channels to say, and so you pick these drugs\n\n1:12:34.640 --> 1:12:39.600\n and you say, okay, I'm going to do it so that instead of this one head, one tail electrical\n\n1:12:39.600 --> 1:12:43.440\n pattern, you have a two headed pattern, right? You're just editing the electrical information\n\n1:12:43.440 --> 1:12:47.520\n in the network. When you do that, guess what the cells build? They build a two headed worm.\n\n1:12:47.520 --> 1:12:51.040\n And the coolest thing about it, no genetic changes. So we haven't touched the genome.\n\n1:12:51.040 --> 1:12:54.320\n The genome is totally wild type. But the amazing thing about it is that when you take these two\n\n1:12:54.320 --> 1:12:59.520\n headed animals and you cut them into pieces again, some of those pieces will continue to\n\n1:12:59.520 --> 1:13:05.840\n make two headed animals. So that information, that memory, that electrical circuit, not only does it\n\n1:13:05.840 --> 1:13:09.920\n hold the information for how many heads, not only does it use that information to tell the cells\n\n1:13:09.920 --> 1:13:14.320\n what to do to regenerate, but it stores it. Once you've reset it, it keeps. And we can go back,\n\n1:13:14.320 --> 1:13:18.960\n we can take a two headed animal and put it back to one headed. So now imagine, so there's a couple\n\n1:13:18.960 --> 1:13:22.720\n of interesting things here that that have implications for understanding what genomes\n\n1:13:22.720 --> 1:13:27.200\n and things like that. Imagine I take this two headed animal. Oh, and by the way, when they\n\n1:13:27.200 --> 1:13:31.360\n reproduce, when they tear themselves in half, you still get two headed animals. So imagine I take\n\n1:13:31.360 --> 1:13:34.640\n them and I throw them in the Charles River over here. So 100 years later, some scientists come\n\n1:13:34.640 --> 1:13:38.640\n along and they scoop up some samples and they go, oh, there's a single headed form and a two headed\n\n1:13:38.640 --> 1:13:43.600\n form. Wow, a speciation event. Cool. Let's sequence the genome and see why, what happened. The genomes\n\n1:13:43.600 --> 1:13:47.040\n are identical. There's nothing wrong with the genome. So if you ask the question, how does,\n\n1:13:47.040 --> 1:13:51.360\n so, so this goes back to your very first question is where do body plans come from, right? How does\n\n1:13:51.360 --> 1:13:55.600\n the planarian know how many heads it's supposed to have? Now it's interesting because you could\n\n1:13:55.600 --> 1:14:01.840\n say DNA, but what happened, what, what, as it turns out, the DNA produces a piece of hardware\n\n1:14:01.840 --> 1:14:07.520\n that by default says one head the way that when you turn on a calculator, by default, it's a zero\n\n1:14:07.520 --> 1:14:11.120\n every single time, right? When you turn it on, it just says zero, but it's a programmable calculator\n\n1:14:11.120 --> 1:14:16.000\n as it turns out. So once you've changed that next time, it won't say zero. It'll say something else\n\n1:14:16.000 --> 1:14:19.120\n and the same thing here. So you can make, you can make one headed, two headed, you can make no\n\n1:14:19.120 --> 1:14:23.120\n headed worms. We've done some other things along these lines, some other really weird constructs.\n\n1:14:24.000 --> 1:14:28.640\n So, so this, this, this, this question of, right. So again, it's really important. The, the hardware\n\n1:14:28.640 --> 1:14:33.920\n software distinction is really important because the hardware is essential because without proper\n\n1:14:33.920 --> 1:14:38.080\n hardware, you're never going to get to the right physiology of having that memory. But once you\n\n1:14:38.080 --> 1:14:42.320\n have it, it doesn't fully determine what the information is going to be. You can have other\n\n1:14:42.320 --> 1:14:46.720\n information in there and it's reprogrammable by us, by bacteria, by various parasites, probably\n\n1:14:47.360 --> 1:14:52.480\n things like that. The other amazing thing about these planarias, think about this, most animals,\n\n1:14:52.480 --> 1:14:56.480\n when we get a mutation in our bodies, our children don't inherit it, right? So you can go on, you\n\n1:14:56.480 --> 1:15:00.720\n could run around for 50, 60 years getting mutations. Your children don't have those mutations\n\n1:15:00.720 --> 1:15:05.120\n because we go through the egg stage. Planaria tear themselves in half and that's how they reproduce.\n\n1:15:05.120 --> 1:15:10.080\n So for 400 million years, they keep every mutation that they've had that doesn't kill the cell that\n\n1:15:10.080 --> 1:15:14.640\n it's in. So when you look at these planaria, their bodies are what's called mixoploid, meaning that\n\n1:15:14.640 --> 1:15:17.840\n every cell might have a different number of chromosomes. They look like a tumor. If you look\n\n1:15:17.840 --> 1:15:22.720\n at the, the, the, the, the genome is an incredible mess because they accumulate all this stuff.\n\n1:15:22.720 --> 1:15:28.240\n And yet the, their body structure is, they are the best regenerators on the planet. Their anatomy is\n\n1:15:28.240 --> 1:15:32.720\n rock solid, even though their genome is always all kinds of crap. So this is a kind of a scandal,\n\n1:15:32.720 --> 1:15:37.520\n right? That, you know, when we learn that, well, you know, what are genomes to what genomes determine\n\n1:15:37.520 --> 1:15:41.520\n your body? Okay. Why is the animal with the worst genome have the best anatomical control, the most\n\n1:15:41.520 --> 1:15:46.080\n cancer resistant, the most regenerative, right? Really, we're just beginning to start to understand\n\n1:15:46.080 --> 1:15:50.720\n this relationship between the, the genomically determined hardware and, and, and by the way,\n\n1:15:50.720 --> 1:15:55.440\n just as of, as of a couple of months ago, I think I now somewhat understand why this is,\n\n1:15:55.440 --> 1:15:57.840\n but it's really, it's really a major, you know, a major puzzle.\n\n1:15:57.840 --> 1:16:05.280\n I mean, that really throws a wrench into the whole nature versus nurture because you usually\n\n1:16:05.280 --> 1:16:12.720\n associate electricity with the, with the nurture and the hardware with the nature.\n\n1:16:13.360 --> 1:16:19.360\n And it's, there's just this weird integrated mess that propagates through generations.\n\n1:16:19.360 --> 1:16:25.040\n Yeah. It's much more fluid. It's much more complex. You can, you can imagine what's,\n\n1:16:25.040 --> 1:16:29.200\n what's happening here is just, just imagine the evolution of a, of a, of an animal like this,\n\n1:16:29.200 --> 1:16:33.280\n that, that multi scale, this goes back to this multi scale competency, right? Imagine that you\n\n1:16:33.280 --> 1:16:38.800\n have two, two, two, you have, you have an animal that that where its, its tissues have some degree\n\n1:16:38.800 --> 1:16:42.960\n of multi scale competency. So for example, if the like, like we saw in the tadpole, you know,\n\n1:16:42.960 --> 1:16:46.240\n if you put an eye on its tail, they can still see out of that eye, right? That the, you know,\n\n1:16:46.240 --> 1:16:50.400\n there's all, there's incredible plasticity. So if you have an animal and it comes up for selection\n\n1:16:50.400 --> 1:16:56.880\n and the fitness is quite good, evolution doesn't know whether the fitness is good because the\n\n1:16:56.880 --> 1:17:01.600\n genome was awesome or because the genome was kind of junky, but, but the competency made up for it,\n\n1:17:01.600 --> 1:17:06.160\n right? And things kind of ended up good. So what that means is that the more competency you have,\n\n1:17:06.160 --> 1:17:11.520\n the harder it is for selection to pick the best genomes, it hides information, right? And so that\n\n1:17:11.520 --> 1:17:16.640\n means that, so, so what happens, you know, evolution basically starts all those start,\n\n1:17:16.640 --> 1:17:21.200\n all the hard work is being done to increase the competency because it's harder and harder to see\n\n1:17:21.200 --> 1:17:25.760\n the genomes. And so I think in planaria, what happened is that there's this runaway phenomenon\n\n1:17:25.760 --> 1:17:31.040\n where all the effort went into the algorithm such that we know you got a crappy genome. We can't\n\n1:17:31.040 --> 1:17:35.360\n keep, we can't clean up the genome. We can't keep track of it. So what's going to happen is what\n\n1:17:35.360 --> 1:17:40.160\n survives are the algorithms that can create a great worm no matter what the genome is. So\n\n1:17:40.160 --> 1:17:44.080\n everything went into the algorithm and which, which of course then reduces the pressure on\n\n1:17:44.080 --> 1:17:49.040\n keeping a, you know, keeping a clean genome. So this idea of, right, and different animals have\n\n1:17:49.040 --> 1:17:53.600\n this in different, to different levels, but this idea of putting energy into an algorithm that\n\n1:17:54.720 --> 1:17:59.040\n does not overtrain on priors, right? It can't assume, I mean, I think biology is this way in\n\n1:17:59.040 --> 1:18:04.160\n general, evolution doesn't take the past too seriously because it makes these basically\n\n1:18:04.160 --> 1:18:08.800\n problem solving machines as opposed to like exactly what, you know, to, to, to deal with\n\n1:18:08.800 --> 1:18:14.480\n exactly what happened last time. Yeah. Problem solving versus memory recall. So a little memory,\n\n1:18:14.480 --> 1:18:18.560\n but a lot of problem solving. I think so. Yeah. In many cases, yeah. Problem solving.\n\n1:18:22.240 --> 1:18:25.600\n I mean, it's incredible that those kinds of systems are able to be constructed,\n\n1:18:25.600 --> 1:18:31.280\n um, especially how much they contrast with the way we build problem solving systems in the AI world.\n\n1:18:32.480 --> 1:18:39.600\n Um, back to Xenobots. I'm not sure if we ever described how Xenobots are built, but\n\n1:18:39.600 --> 1:18:45.280\n I mean, you have a paper titled biological robots perspectives on an emerging interdisciplinary\n\n1:18:45.280 --> 1:18:51.360\n field. And the beginning you, uh, you mentioned that the word Xenobots is like controversial.\n\n1:18:51.360 --> 1:18:57.280\n Do you guys get in trouble for using Xenobots or what? Do people not like the word Xenobots?\n\n1:18:57.280 --> 1:19:02.400\n Are you trying to be provocative with the word Xenobots versus biological robots?\n\n1:19:02.400 --> 1:19:07.200\n I don't know. Is there some drama that we should be aware of? There's a little bit of drama. Uh,\n\n1:19:07.200 --> 1:19:15.200\n I think, I think the drama is basically related to people, um, having very fixed ideas about what\n\n1:19:15.200 --> 1:19:22.960\n terms mean. And I think in many cases, these ideas are completely out of date with, with where science\n\n1:19:22.960 --> 1:19:28.720\n is now. And for sure they're, they're out of date with what's going to be, I mean, these, these,\n\n1:19:28.720 --> 1:19:33.760\n these concepts, uh, are not going to survive the next couple of decades. So if you ask a person\n\n1:19:33.760 --> 1:19:38.080\n and including, um, you know, a lot of people in biology who kind of want to keep a sharp\n\n1:19:38.080 --> 1:19:42.160\n distinction between biologicals and robots, right? See, what's a robot? Well, a robot,\n\n1:19:42.160 --> 1:19:46.400\n it comes out of a factory. It's made by humans. It is boring. It is a meaning that you can predict\n\n1:19:46.400 --> 1:19:50.640\n everything it's going to do. It's made of metal and certain other inorganic materials. Living\n\n1:19:50.640 --> 1:19:54.400\n organisms are magical. They, they, they arise, right? And so on. So these, these distinctions,\n\n1:19:54.400 --> 1:20:00.720\n I think these, these distinctions, I think were, were never good, but, uh, they're going to be\n\n1:20:00.720 --> 1:20:05.120\n completely useless going forward. And so part of, there's a couple of papers that that's one paper\n\n1:20:05.120 --> 1:20:09.520\n and there's another one that Josh Bongar and I wrote where we really attack the terminology.\n\n1:20:09.520 --> 1:20:16.880\n And we say these binary categories are based on very, um, nonessential kind of surface, uh,\n\n1:20:16.880 --> 1:20:22.560\n limitations of, of technology and imagination that were true before, but they've got to go. And so,\n\n1:20:22.560 --> 1:20:27.360\n and so we call them Zenobots. So, so Xeno for Xenopus Levus, where this is, it's the frog that,\n\n1:20:27.360 --> 1:20:32.320\n that these guys are made of, but we think it's an example of, of, of, uh, of a biobot technology,\n\n1:20:32.320 --> 1:20:39.680\n because ultimately if we, if we under, once we understand how to, uh, communicate and manipulate,\n\n1:20:39.680 --> 1:20:45.680\n um, the inputs to these cells, we will be able to get them to build whatever we want them to build.\n\n1:20:45.680 --> 1:20:49.360\n And that's robotics, right? It's, it's the rational construction of machines that have\n\n1:20:49.360 --> 1:20:54.560\n useful purposes. I, I absolutely think that this is a robotics platform, whereas some biologists\n\n1:20:54.560 --> 1:21:02.080\n don't, but it's built in a way that, uh, all the different components are doing their own computation.\n\n1:21:02.080 --> 1:21:06.000\n So in a way that we've been talking about, so you're trying to do top down control in that\n\n1:21:06.000 --> 1:21:09.680\n biological system. And in the future, all of this will, will, will merge together because\n\n1:21:09.680 --> 1:21:13.840\n of course at some point we're going to throw in synthetic biology circuits, right? New, new, um,\n\n1:21:13.840 --> 1:21:17.200\n you know, new transcriptional circuits to get them to do new things. Of course we'll throw some of\n\n1:21:17.200 --> 1:21:21.680\n that in, but we specifically stayed away from all of that because in the first few papers,\n\n1:21:21.680 --> 1:21:25.600\n and there's some more coming down the pike that are, I think going to be pretty, pretty dynamite,\n\n1:21:25.600 --> 1:21:30.720\n um, that, uh, we want to show what the native cells are made of. Because what happens is,\n\n1:21:30.720 --> 1:21:33.920\n you know, if you engineer the heck out of them, right, if we were to put in new, you know,\n\n1:21:33.920 --> 1:21:38.000\n new transcription factors and some new metabolic machinery and whatever, people will say, well,\n\n1:21:38.000 --> 1:21:44.000\n okay, you engineered this and you made it do whatever. And fine. I wanted to show, uh, and,\n\n1:21:44.000 --> 1:21:50.240\n and, and the whole team, uh, wanted to show the plasticity and the intelligence in the biology.\n\n1:21:50.240 --> 1:21:55.280\n What does it do that's surprising before you even start manipulating the hardware in that way?\n\n1:21:55.280 --> 1:22:02.560\n Yeah. Don't try to, uh, over control the thing. Let it flourish. The, the full beauty of the\n\n1:22:02.560 --> 1:22:07.600\n biological system. Why Xenopus Levus? How do you pronounce it? The frog.\n\n1:22:07.600 --> 1:22:09.360\n Xenopus Levus. Yeah. Yeah. It's a very popular.\n\n1:22:09.360 --> 1:22:10.240\n Why this frog?\n\n1:22:10.240 --> 1:22:15.360\n It's been used since, uh, I think the fifties. Uh, it's just very convenient because you can,\n\n1:22:15.360 --> 1:22:19.280\n you know, we, we keep the adults in this, in this, uh, very fine frog habitat. They lay eggs. They\n\n1:22:19.280 --> 1:22:24.880\n lay tens of thousands of eggs at a time. Um, the eggs develop right in front of your eyes. It's the\n\n1:22:24.880 --> 1:22:29.440\n most mad magical thing you can, you can see because normally, you know, if you were to deal\n\n1:22:29.440 --> 1:22:32.960\n with mice or rabbits or whatever, you don't see the early stages, right? Cause everything's inside\n\n1:22:32.960 --> 1:22:36.640\n the mother. Everything's in a Petri dish at room temperature. So you just, you, you have an egg,\n\n1:22:36.640 --> 1:22:40.400\n it's fertilized and you can just watch it divide and divide and divide. And on all the organs\n\n1:22:40.400 --> 1:22:44.960\n form, you can just see it. And at that point, um, the community has, has developed lots of\n\n1:22:44.960 --> 1:22:50.000\n different tools for understanding what's going on and also for, for manipulating, right? So it's,\n\n1:22:50.000 --> 1:22:54.160\n it's people use it for, um, you know, for understanding birth defects and neurobiology\n\n1:22:54.160 --> 1:22:58.640\n and cancer immunology. So you get the whole, uh, embryogenesis in the Petri dish.\n\n1:23:00.160 --> 1:23:03.520\n That's so cool to watch. Is there videos of this? Oh yeah. Yeah. Yeah. There's,\n\n1:23:03.520 --> 1:23:08.160\n but yeah, there's, there's amazing videos on, on, online. I mean, mammalian embryos are super cool\n\n1:23:08.160 --> 1:23:12.560\n too. For example, monozygotic twins are what happens when you cut a mammalian embryo in half.\n\n1:23:12.560 --> 1:23:15.760\n You don't get two half bodies. You get two perfectly normal bodies because it's a\n\n1:23:15.760 --> 1:23:19.920\n regeneration event, right? Development is just the, it's just the kind of regeneration really.\n\n1:23:19.920 --> 1:23:25.120\n And why this particular frog? It's just, uh, cause they were doing in the fifties and.\n\n1:23:25.760 --> 1:23:32.000\n It breeds well in, um, you know, in, in, it's easy to raise in, in the laboratory and, uh,\n\n1:23:32.000 --> 1:23:36.480\n it's very prolific and all the tools basically for decades, people have been developing tools.\n\n1:23:36.480 --> 1:23:40.800\n There's other, some people use other frogs, but I have to say this is, this is, this is important.\n\n1:23:40.800 --> 1:23:46.080\n Xenobots are fundamentally not anything about frogs. So, um, I can't say too much about this\n\n1:23:46.080 --> 1:23:50.400\n cause it's not published and peer reviewed yet, but we've made Xenobots out of other things that\n\n1:23:50.400 --> 1:23:54.640\n have nothing to do with frogs. It's, this is not a frog phenomenon. This is, we, we started with\n\n1:23:54.640 --> 1:23:59.040\n frog because it's so convenient, but this, this, this plasticity is not a fraud. You know, it's\n\n1:23:59.040 --> 1:24:02.880\n not related to the fact that they're frogs. What happens when you kiss it? Does it turn\n\n1:24:02.880 --> 1:24:07.120\n into a prince? No. Or a princess? Which way? Uh, prince. Yeah. Prince should be a prince.\n\n1:24:07.120 --> 1:24:10.720\n Yeah. Uh, that's an experiment that I don't believe we've done. And if we have, I don't\n\n1:24:10.720 --> 1:24:16.320\n want to collaborate, I can, I can take on the lead, uh, on that effort. Okay, cool. Uh,\n\n1:24:17.680 --> 1:24:23.360\n how does the cells coordinate? Let's focus in on just the embryogenesis. So there's one cell,\n\n1:24:24.320 --> 1:24:32.240\n so it divides, doesn't have to be very careful about what each cell starts doing once they divide.\n\n1:24:32.240 --> 1:24:37.840\n Yes. And like, when there's three of them, it's like the cofounders or whatever,\n\n1:24:37.840 --> 1:24:44.320\n like, well, like slow down, you're responsible for this. When do they become specialized and\n\n1:24:44.320 --> 1:24:49.440\n how do they coordinate that specialization? So, so this is the basic science of developmental\n\n1:24:49.440 --> 1:24:55.120\n biology. There's a lot known about all of that, but, um, but I'll tell you what I think is kind\n\n1:24:55.120 --> 1:25:00.560\n of the most important part, which is, yes, it's very important who does what. However,\n\n1:25:01.200 --> 1:25:07.440\n because going back to this issue of why I made this claim that, um, biology doesn't take the past\n\n1:25:07.440 --> 1:25:12.560\n too seriously. And what I mean by that is it doesn't assume that everything is the way it's,\n\n1:25:12.560 --> 1:25:17.200\n it's expected to be. Right. And here's an example of that. Um, this was, this was done, this was,\n\n1:25:17.200 --> 1:25:21.280\n this was an old experiment going back to the forties, but, um, basically imagine imagine\n\n1:25:21.280 --> 1:25:25.760\n it's a new salamander and it's got these little tube tubules that go to the kidneys, right? It's\n\n1:25:25.760 --> 1:25:30.080\n a little tube. Take a cross section of that tube. You see eight to 10 cells that have\n\n1:25:30.080 --> 1:25:34.880\n cooperated to make this little tube in cross section, right? So one amazing, one amazing\n\n1:25:34.880 --> 1:25:41.200\n thing you can do is, um, you can, you can mess with a very early cell division to make the cells\n\n1:25:41.200 --> 1:25:44.560\n gigantic, bigger. You can, you can make them different sizes. You can force them to be different\n\n1:25:44.560 --> 1:25:50.160\n sizes. So if you make the cells different sizes, the whole nude is still the same size.\n\n1:25:50.160 --> 1:25:53.840\n So if you take a cross section through the, through that tubule, instead of eight to 10\n\n1:25:53.840 --> 1:25:59.200\n cells, you might have four or five or you might have, you know, three until you make the cells so\n\n1:25:59.200 --> 1:26:06.480\n enormous that one single cell wraps around itself and, and gives you that same large scale structure\n\n1:26:06.480 --> 1:26:11.120\n with a completely different molecular mechanism. So now instead of cell to cell communication to\n\n1:26:11.120 --> 1:26:15.840\n make a tubule, instead of that, it's one cell using the cytoskeleton to bend itself around.\n\n1:26:15.840 --> 1:26:20.400\n So think about what that means in the service of a large scale, talk about top down control,\n\n1:26:20.400 --> 1:26:24.960\n right? In the service of a large scale anatomical feature, different molecular mechanisms get\n\n1:26:24.960 --> 1:26:29.760\n called up. So now think about this, you're, you're, you're a nude cell and trying to make an embryo.\n\n1:26:30.320 --> 1:26:34.480\n If you had a fixed idea of who was supposed to do what, you'd be screwed because now your cells\n\n1:26:34.480 --> 1:26:40.240\n are gigantic. Nothing would work. The, there's an incredible tolerance for changes in the size of\n\n1:26:40.240 --> 1:26:45.280\n the parts and the amount of DNA in those parts. Um, all sorts of stuff you can, you can, the life\n\n1:26:45.280 --> 1:26:49.200\n is highly interoperable. You can put electrodes in there and you can put weird nanomaterials. It\n\n1:26:49.200 --> 1:26:54.400\n still works. It's, it's, uh, this is that problem solving action, right? It's able to do what it\n\n1:26:54.400 --> 1:27:00.160\n needs to do, even when circumstances change. That is, you know, the hallmark of intelligence,\n\n1:27:00.160 --> 1:27:04.080\n right? William James defined intelligence as the ability to get to the same goal by different\n\n1:27:04.080 --> 1:27:08.960\n means. That's this, you get to the same goal by completely different means. And so, so,\n\n1:27:08.960 --> 1:27:12.640\n so why am I bringing this up is just to say that, yeah, it's important for the cells to do the right\n\n1:27:12.640 --> 1:27:17.520\n stuff, but they have incredible tolerances for things not being what you expect and to still\n\n1:27:17.520 --> 1:27:23.840\n get their job done. So if you're, you know, um, all of these things are not hardwired.\n\n1:27:23.840 --> 1:27:28.880\n There are organisms that might be hardwired. For example, the nematode C elegans in that organism,\n\n1:27:28.880 --> 1:27:32.800\n every cell is numbered, meaning that every C elegans has exactly the same number of cells\n\n1:27:32.800 --> 1:27:36.000\n as every other C elegans. They're all in the same place. They all divide. There's literally a map\n\n1:27:36.000 --> 1:27:40.880\n of how it works that in that, in that sort of system, it's, it's, it's much more cookie cutter,\n\n1:27:40.880 --> 1:27:47.840\n but, but most, most organisms are incredibly plastic in that way. Is there something particularly\n\n1:27:47.840 --> 1:27:53.680\n magical to you about the whole developmental biology process? Um, is there something you\n\n1:27:53.680 --> 1:27:58.080\n could say, cause you just said it, they're very good at accomplishing the goal of the job they\n\n1:27:58.080 --> 1:28:05.120\n need to do the competency thing, but you get fricking organism from one cell. It's like, uh,\n\n1:28:06.640 --> 1:28:14.000\n I mean, it's very hard, hard to intuit that whole process to even think about reverse engineering\n\n1:28:14.000 --> 1:28:19.760\n that process. Right. Very hard to the point where I often just imagine, I, I sometimes ask my\n\n1:28:19.760 --> 1:28:23.680\n students to do this thought experiment. Imagine you were, you were shrunk down to the, to the scale\n\n1:28:23.680 --> 1:28:27.120\n of a single cell and you were in the middle of an embryo and you were looking around at what's going\n\n1:28:27.120 --> 1:28:30.400\n on and the cells running around, some cells are dying at the, you know, every time you look,\n\n1:28:30.400 --> 1:28:35.520\n it's kind of a different number of cells for most organisms. And so I think that if you didn't know\n\n1:28:35.520 --> 1:28:40.080\n what embryonic development was, you would have no clue that what you're seeing is always going to\n\n1:28:40.080 --> 1:28:44.560\n make the same thing. Nevermind knowing what that, what that is. Nevermind being able to say, even\n\n1:28:44.560 --> 1:28:48.080\n with full genomic information, being able to say, what the hell are they building? We have no way\n\n1:28:48.080 --> 1:28:54.720\n to do that. But, but just even to guess that, wow, the, the, the outcome of all this activity is it's\n\n1:28:54.720 --> 1:29:00.080\n always going to be, it's always going to build the same thing. The imperative to create the final you\n\n1:29:00.080 --> 1:29:06.240\n as you are now is there already. So you can, you would, so you start from the same embryo,\n\n1:29:06.240 --> 1:29:14.480\n you create a very similar organism. Yeah. Except for cases like the Xenobots, when you give them\n\n1:29:14.480 --> 1:29:18.240\n a different environment, they come up with a different way to be adaptive in that environment.\n\n1:29:18.240 --> 1:29:24.080\n But overall, I mean, so, so I think, so I think to, you know, kind of summarize it,\n\n1:29:24.080 --> 1:29:31.520\n I think what evolution is really good at is creating hardware that has a very stable baseline\n\n1:29:31.520 --> 1:29:36.880\n mode, meaning that left to its own devices, it's very good at doing the same thing. But it has a\n\n1:29:36.880 --> 1:29:41.360\n bunch of problem solving capacity such that if any, if any assumptions don't hold, if your cells are\n\n1:29:41.360 --> 1:29:45.040\n a weird size, or you get the wrong number of cells, or there's a, you know, somebody stuck\n\n1:29:45.040 --> 1:29:50.960\n in electrode halfway through the body, whatever, it will still get most of what it needs to do done.\n\n1:29:52.400 --> 1:29:57.760\n You've talked about the magic and the power of biology here. If we look at the human brain,\n\n1:29:57.760 --> 1:30:02.560\n how special is the brain in this context? You're kind of minimizing the importance of the brain\n\n1:30:03.200 --> 1:30:08.640\n or lessening its, we think of all the special computation happens in the brain,\n\n1:30:08.640 --> 1:30:14.960\n everything else is like the help. You're kind of saying that the whole thing is the whole thing\n\n1:30:14.960 --> 1:30:22.160\n is doing computation. But nevertheless, how special is the human brain in this full context of\n\n1:30:22.160 --> 1:30:27.680\n biology? Yeah, I mean, look, there's no getting away from the fact that the human brain allows\n\n1:30:27.680 --> 1:30:31.920\n us to do things that we could not do without it. You can say the same thing about the liver.\n\n1:30:31.920 --> 1:30:37.680\n Yeah, no, this is this is true. And so and so, you know, I, my goal is not No, you're right. My goal\n\n1:30:37.680 --> 1:30:41.840\n is just being polite to the brain right now. Well, being a politician, like, listen,\n\n1:30:42.320 --> 1:30:46.480\n everybody has everybody has a role. Yeah, it's very important role. That's right. We have to\n\n1:30:46.480 --> 1:30:51.920\n acknowledge the importance of the brain, you know, there are more than enough people who are\n\n1:30:52.480 --> 1:30:58.720\n cheerleading the brain, right? So so I don't feel like nothing I say is going to reduce people's\n\n1:30:58.720 --> 1:31:04.160\n excitement about the human brain. And so so I emphasize other things credit. I don't think it\n\n1:31:04.160 --> 1:31:08.880\n gets too much credit. I think other things don't get enough credit. I think the brain is the human\n\n1:31:08.880 --> 1:31:13.760\n brain is incredible and special and all that. I think other things need more credit. And and I\n\n1:31:13.760 --> 1:31:19.360\n also think that this and I'm sort of this way about everything. I don't like binary categories,\n\n1:31:19.360 --> 1:31:24.880\n but almost anything I like a continuum. And the thing about the human brain is that it by by by\n\n1:31:24.880 --> 1:31:32.080\n accepting that as some kind of an important category or essential, essential thing, we end\n\n1:31:32.080 --> 1:31:38.320\n up with all kinds of weird pseudo problems and conundrum. So for example, when we talk about it,\n\n1:31:38.320 --> 1:31:44.880\n you know, if you don't want to talk about ethics and other other things like that, and what you\n\n1:31:44.880 --> 1:31:50.000\n know, this this idea that surely if we look out into the universe, surely, we don't believe that\n\n1:31:50.000 --> 1:31:54.320\n this human brain is the only way to be sentient, right? Surely we don't, you know, and to have high\n\n1:31:54.320 --> 1:31:59.360\n level cognition. I just can't even wrap my mind around this, this idea that that is the only way\n\n1:31:59.360 --> 1:32:04.160\n to do it. No doubt there are other architectures made bond made of completely different principles\n\n1:32:04.160 --> 1:32:09.760\n that achieve the same thing. And once we believe that, then that tells us something important. It\n\n1:32:09.760 --> 1:32:15.520\n tells us that things that are not quite human brains or chimeras of human brains and other\n\n1:32:15.520 --> 1:32:20.800\n tissue or human brains or other kinds of brains and novel configurations or things that are sort\n\n1:32:20.800 --> 1:32:26.720\n of brains, but not really, or plants or embryos or whatever, might also have important cognitive\n\n1:32:26.720 --> 1:32:32.000\n status. So that's the only thing I think we have to be really careful about treating the human\n\n1:32:32.000 --> 1:32:37.680\n brain as if it was some kind of like sharp binary category. You know, you are or you aren't. I don't\n\n1:32:37.680 --> 1:32:44.960\n believe that exists. So when we look out at all the beautiful variety of human brains,\n\n1:32:44.960 --> 1:32:52.880\n semi biological architectures out there in the universe, how many intelligent alien civilizations\n\n1:32:52.880 --> 1:32:59.200\n do you think are out there? Boy, I have no expertise in that whatsoever. You haven't met\n\n1:32:59.200 --> 1:33:06.800\n any? I have met the ones we've made. I think that I mean, exactly. In some sense with synthetic\n\n1:33:06.800 --> 1:33:12.800\n biology, are you not creating aliens? I absolutely think so because look, all of life,\n\n1:33:12.800 --> 1:33:19.840\n all of all standard model systems are an end of one course of evolution on Earth, right? And trying\n\n1:33:19.840 --> 1:33:26.880\n to make conclusions about biology from looking at life on Earth is like testing your theory on the\n\n1:33:26.880 --> 1:33:32.720\n same data that generated it. It's all it's all kind of like locked in. So we absolutely have to\n\n1:33:32.720 --> 1:33:40.240\n create novel examples that have no history on Earth that don't, you know, xenobots have no\n\n1:33:40.240 --> 1:33:44.560\n history of selection to be a good xenobot. The cells have selection for various things, but the\n\n1:33:44.560 --> 1:33:48.960\n xenobot itself never existed before. And so we can make chimeras, you know, we make frog a lottles\n\n1:33:48.960 --> 1:33:53.520\n that are sort of half frog, half axolotl. You can make all sorts of high brats, right constructions\n\n1:33:53.520 --> 1:33:58.640\n of living tissue with robots and whatever. We need to be making these things until we find actual\n\n1:33:58.640 --> 1:34:03.920\n aliens, because otherwise, we're just looking at an end of one set of examples, all kinds of frozen\n\n1:34:03.920 --> 1:34:08.720\n accidents of evolution and so on. We need to go beyond that to really understand biology. But\n\n1:34:08.720 --> 1:34:17.040\n we're still even when you do a synthetic biology, you're locked in to the basic components of the\n\n1:34:17.040 --> 1:34:23.760\n way biology is done on this Earth. Yeah, right. And also, and the and also the basic constraints\n\n1:34:23.760 --> 1:34:27.840\n of the environment, even artificial environments to construct in the lab are tied up to the\n\n1:34:27.840 --> 1:34:34.240\n environment. I mean, what do you? Okay, let's say there is I mean, what I think is there's\n\n1:34:34.240 --> 1:34:39.440\n a nearly infinite number of intelligent civilizations living or dead out there.\n\n1:34:41.920 --> 1:34:50.320\n If you pick one out of the box, what do you think it would look like? So in when you think about\n\n1:34:50.320 --> 1:34:58.880\n synthetic biology, or creating synthetic organisms, how hard is it to create something that's very\n\n1:34:58.880 --> 1:35:06.320\n different? Yeah, I think it's very hard to create something that's very different, right? It's we\n\n1:35:06.320 --> 1:35:12.400\n are just locked in both both both experimentally and in terms of our imagination, right? It's very\n\n1:35:12.400 --> 1:35:18.000\n hard. And you also emphasize several times that the idea of shape. Yeah, the individual cell get\n\n1:35:18.000 --> 1:35:23.920\n together with other cells and they kind of they're gonna build a shape. So it's shape and function,\n\n1:35:23.920 --> 1:35:29.200\n but shape is a critical thing. Yeah. So here, I'll take a stab. I mean, I agree with you. I did\n\n1:35:29.200 --> 1:35:33.600\n to whatever extent that we can say anything, I do think that there's, you know, probably an\n\n1:35:33.600 --> 1:35:38.800\n infinite number of, of different different architectures with with that are with interesting\n\n1:35:38.800 --> 1:35:45.840\n cognitive properties out there. What can we say about them? I think that the only things that are\n\n1:35:45.840 --> 1:35:50.880\n going I don't I don't think we can rely on any of the typical stuff, you know, carbon based, none of\n\n1:35:50.880 --> 1:35:56.400\n that. Like, I think all of that is just, you know, us being having having a lack of imagination. But\n\n1:35:56.960 --> 1:36:03.760\n I think the things that are going to be universal, if anything is, are things, for example, driven by\n\n1:36:03.760 --> 1:36:09.280\n resource limitation, the fact that you are fighting a hostile world, and you have to draw a\n\n1:36:09.280 --> 1:36:13.040\n boundary between yourself and the world somewhere, the fact that that boundary is not given to you\n\n1:36:13.040 --> 1:36:18.000\n by anybody, you have to you have to assume it, you know, estimated yourself. And the fact that\n\n1:36:18.000 --> 1:36:22.160\n you have to course grain your experience and the fact that you're going to try to minimize surprise\n\n1:36:22.160 --> 1:36:25.920\n and the fact that like these, these are the things that I think are fundamental about biology,\n\n1:36:25.920 --> 1:36:30.160\n none of the, you know, the facts about the genetic code, or even the fact that we have genes or the\n\n1:36:30.160 --> 1:36:34.160\n biochemistry of it, I don't think any of those things are fundamental. But it's going to be a\n\n1:36:34.160 --> 1:36:38.640\n lot more about the information and about the creation of the self, the fact that so in my in\n\n1:36:38.640 --> 1:36:44.560\n my framework, selves are demarcated by the scale of the goals that they can pursue. So from little\n\n1:36:44.560 --> 1:36:48.640\n tiny local goals to like massive, you know, planetary scale goals for certain humans,\n\n1:36:49.440 --> 1:36:53.280\n and everything and everything in between. So you can draw this like cognitive light cone about\n\n1:36:53.280 --> 1:36:58.960\n that determines the the scale of the goals you could possibly pursue. I think those kinds of\n\n1:36:58.960 --> 1:37:04.080\n frameworks, like that, like active inference, and so on are going to be universally applicable,\n\n1:37:04.080 --> 1:37:08.640\n but but none of the other things that are that are typically discussed. Quick pause,\n\n1:37:08.640 --> 1:37:16.320\n do you need a bathroom break? We were just talking about, you know, aliens and all that. That's a\n\n1:37:16.320 --> 1:37:20.720\n funny thing, which is, I don't know if you've seen them, there's a kind of debate that goes on about\n\n1:37:20.720 --> 1:37:24.560\n cognition and plants, and what can you say about different kinds of computation and cognition and\n\n1:37:24.560 --> 1:37:28.800\n plants. And I always I always look at that something like if you're weirded out by cognition\n\n1:37:28.800 --> 1:37:34.560\n and plants, you're not ready for exobiology, right? If you know something that's that similar\n\n1:37:34.560 --> 1:37:38.960\n here on Earth is already like freaking you out, then I think there's going to be all kinds of\n\n1:37:38.960 --> 1:37:44.080\n cognitive life out there that we're gonna have a really hard time recognizing. I think robots will\n\n1:37:44.080 --> 1:37:54.080\n help us, yeah, like expand our mind about cognition, either that or the word like xenobots. So,\n\n1:37:54.640 --> 1:38:01.920\n and they maybe becomes the same thing is, you know, really, when the human engineers,\n\n1:38:01.920 --> 1:38:08.400\n the thing, at least in part, and then is able to achieve some kind of cognition that's different\n\n1:38:08.400 --> 1:38:14.320\n than what you're used to, then you start to understand like, oh, you know, every living\n\n1:38:14.320 --> 1:38:19.680\n organism is capable of cognition. Oh, I need to kind of broaden my understanding what cognition\n\n1:38:19.680 --> 1:38:25.520\n is. But do you think plants, like when you when you eat them, are they screaming? I don't know\n\n1:38:25.520 --> 1:38:30.080\n about screaming. I think you have to see what I think when I eat a salad. Yeah, good. Yeah,\n\n1:38:30.080 --> 1:38:34.560\n I think you have to scale down the expectations in terms of right, so probably they're not\n\n1:38:34.560 --> 1:38:39.760\n screaming in the way that we would be screaming. However, there's plenty of data on plants being\n\n1:38:39.760 --> 1:38:46.720\n able to do anticipation and certain kinds of memory and so on. I think, you know, what you\n\n1:38:46.720 --> 1:38:51.440\n just said about robots, I hope you're right. And I hope that's but there's two, there's two ways\n\n1:38:51.440 --> 1:38:54.720\n that people can take that right. So one way is exactly what you just said to try to kind of\n\n1:38:54.720 --> 1:39:00.320\n expand their expand their their their notions for that category. The other way people often go is\n\n1:39:02.000 --> 1:39:08.240\n they just sort of define the term is if if if it's not a natural product, it's it's just faking,\n\n1:39:08.240 --> 1:39:11.920\n right? It's not really intelligence if it was made by somebody else, because it's that same,\n\n1:39:11.920 --> 1:39:16.160\n it's the same thing. They can see how it's done. And once you see how it's like a magic trick,\n\n1:39:16.160 --> 1:39:21.360\n when you see how it's done, it's not as fun anymore. And and I think people have a real\n\n1:39:21.360 --> 1:39:25.280\n tendency for that. And they sort of which which I find really strange in the sense that if somebody\n\n1:39:25.280 --> 1:39:31.920\n said to me, we have this this this sort of blind, like, like, hill climbing search,\n\n1:39:32.480 --> 1:39:36.800\n and then and then we have a really smart team of engineers, which one do you think is going to\n\n1:39:36.800 --> 1:39:41.680\n produce a system that has good intelligence? I think it's really weird to say that it only\n\n1:39:41.680 --> 1:39:45.600\n comes from the blind search, right? It can't be done by people who, by the way, can also use\n\n1:39:45.600 --> 1:39:49.920\n evolutionary techniques if they want to, but also rational design. I think it's really weird to say\n\n1:39:49.920 --> 1:39:55.600\n that real intelligence only comes from natural evolution. So I hope you're right. I hope people\n\n1:39:55.600 --> 1:40:01.360\n take it the other the other way. But there's a nice shortcut. So I work with Lego robots a lot now\n\n1:40:01.360 --> 1:40:13.520\n from for my own personal pleasure. Not in that way internet. So four legs. And one of the things\n\n1:40:13.520 --> 1:40:21.440\n that changes my experience with the robots a lot is when I can't understand why I did a certain\n\n1:40:21.440 --> 1:40:27.680\n thing. And there's a lot of ways to engineer that. Me, the person that created the software that runs\n\n1:40:27.680 --> 1:40:33.120\n it. There's a lot of ways for me to build that software in such a way that I don't exactly know\n\n1:40:33.120 --> 1:40:40.160\n why it did a certain basic decision. Of course, as an engineer, you can go in and start to look at\n\n1:40:40.160 --> 1:40:45.840\n logs. You can log all kind of data, sensory data, the decisions you made, you know, all the outputs\n\n1:40:45.840 --> 1:40:52.320\n in your networks and so on. But I also try to really experience that surprise and that really\n\n1:40:52.320 --> 1:40:57.840\n experience as another person would that totally doesn't know how it's built. And I think the magic\n\n1:40:57.840 --> 1:41:06.960\n is there in not knowing how it works. That I think biology does that for you through the layers of\n\n1:41:06.960 --> 1:41:14.320\n abstraction. Yeah, it because nobody really knows what's going on inside the biological. Like each\n\n1:41:14.320 --> 1:41:20.480\n one component is clueless about the big picture. I think there's actually really cheap systems that\n\n1:41:20.480 --> 1:41:26.640\n can that can illustrate that kind of thing, which is even like, you know, fractals, right? Like,\n\n1:41:27.200 --> 1:41:32.560\n you have a very small, short formula in Z, and you see it and there's no magic, you're just going to\n\n1:41:32.560 --> 1:41:36.960\n crank through, you know, Z squared plus C, whatever, you're just going to crank through it. But the\n\n1:41:36.960 --> 1:41:43.280\n result of it is this incredibly rich, beautiful image, right? That that just like, wow, all of\n\n1:41:43.280 --> 1:41:49.760\n that was in this, like, 10 character long string, like amazing. So the fact that you can you can\n\n1:41:49.760 --> 1:41:54.800\n know everything there is to know about the details and the process and all the parts and every like,\n\n1:41:54.800 --> 1:42:01.120\n there's literally no magic of any kind there. And yet the outcome is something that you would never\n\n1:42:01.120 --> 1:42:06.480\n have expected. And it's just it just, you know, is incredibly rich and complex and beautiful. So\n\n1:42:07.200 --> 1:42:13.360\n there's a lot of that. You write that you work on developing conceptual frameworks for understanding\n\n1:42:13.360 --> 1:42:17.840\n unconventional cognition. So the kind of thing we've been talking about, I just like the term\n\n1:42:17.840 --> 1:42:23.440\n unconventional cognition. And you want to figure out how to detect, study and communicate with\n\n1:42:23.440 --> 1:42:29.200\n the thing. You've already mentioned a few examples, but what is unconventional cognition? Is it as\n\n1:42:29.200 --> 1:42:34.880\n simply as everything else outside of what we define usually as cognition, cognitive science,\n\n1:42:34.880 --> 1:42:40.560\n the stuff going on between our ears? Or is there some deeper way to get at the fundamentals of\n\n1:42:41.440 --> 1:42:47.440\n what is cognition? Yeah, I think like, and I'm certainly not the only person who works in\n\n1:42:47.440 --> 1:42:53.440\n unconventional, unconventional cognition. So it's the term used? Yeah, that's one that I so I've\n\n1:42:53.440 --> 1:42:56.960\n coined a number of weird terms, but that's not one of mine like that. That's an existing thing. So\n\n1:42:56.960 --> 1:43:00.880\n so for example, somebody like Andy Adam Askey, who I don't know if you've if you've had him on,\n\n1:43:00.880 --> 1:43:05.600\n if you haven't, you should he's a he's a he's a, you know, very interesting guy. He's a computer\n\n1:43:05.600 --> 1:43:10.640\n scientist, and he does unconventional cognition and slime molds, all kinds of weird. He's a real\n\n1:43:10.640 --> 1:43:15.280\n weird, weird cat, really interesting. Anyway, so so that's, you know, it's a bunch of terms that\n\n1:43:15.280 --> 1:43:21.600\n I've come up with. But that's not one of mine. So I think like many terms, that one is, is really\n\n1:43:21.600 --> 1:43:26.560\n defined by the times, meaning that unconventional cognitive things that are unconventional cognition\n\n1:43:26.560 --> 1:43:31.920\n today are not going to be considered unconventional cognition at some point. It's one of those,\n\n1:43:31.920 --> 1:43:37.840\n it's one of those things. And so it's, you know, it's, it's, it's this, it's this really deep\n\n1:43:37.840 --> 1:43:46.240\n question of how do you recognize, communicate with, classify cognition, when you cannot rely\n\n1:43:46.240 --> 1:43:52.160\n on the typical milestones, right? So typical, you know, again, if you stick with the with the, the\n\n1:43:52.160 --> 1:43:56.640\n history of life on Earth, like these, these exact model systems, you would say, Ah, here's a particular\n\n1:43:56.640 --> 1:44:00.160\n structure of the brain. And this one has fewer of those. And this one has a bigger frontal cortex.\n\n1:44:00.160 --> 1:44:04.640\n And this one, right, so these are these are landmarks that that we're that we're used to,\n\n1:44:04.640 --> 1:44:10.560\n and and allows us to make very kind of rapid judgments about things. But if you can't rely on\n\n1:44:10.560 --> 1:44:15.520\n that, either because you're looking at a synthetic thing, or an engineered thing, or an alien thing,\n\n1:44:16.160 --> 1:44:19.600\n then what do you do? Right? How do you and so and so that's what I'm really interested. I'm\n\n1:44:19.600 --> 1:44:25.040\n interested in mind in all of its possible implementations, not just the obvious ones\n\n1:44:25.040 --> 1:44:31.040\n that we know from from looking at brains here on Earth. Whenever I think about something like\n\n1:44:31.040 --> 1:44:36.880\n unconventional cognition, I think about cellular automata, I'm just captivated by the beauty of the\n\n1:44:36.880 --> 1:44:46.480\n thing. The fact that from simple little objects, you can create some such beautiful complexity\n\n1:44:46.480 --> 1:44:53.120\n that very quickly, you forget about the individual objects, and you see the things that it creates\n\n1:44:53.120 --> 1:45:00.800\n as its own organisms. That blows my mind every time. Like, honestly, I could full time just\n\n1:45:01.920 --> 1:45:05.920\n eat mushrooms and watch cellular automata. Don't even have to do mushrooms.\n\n1:45:06.880 --> 1:45:13.280\n Just cellular automata. It feels like, I mean, from the engineering perspective, I love\n\n1:45:13.280 --> 1:45:18.320\n when a very simple system captures something really powerful, because then you can study\n\n1:45:18.320 --> 1:45:23.120\n that system to understand something fundamental about complexity about life on Earth.\n\n1:45:24.080 --> 1:45:32.000\n Anyway, how do I communicate with a thing? If cellular automata can do cognition, if a plant\n\n1:45:32.000 --> 1:45:40.000\n can do cognition, if a xenobot can do cognition, how do I like whisper in its ear and get an\n\n1:45:40.000 --> 1:45:46.880\n answer back to how do I have a conversation? How do I have a xenobot on a podcast?\n\n1:45:46.880 --> 1:45:53.840\n It's a really interesting line of investigation that opens up. I mean, we've thought about this.\n\n1:45:53.840 --> 1:46:00.400\n So you need a few things. You need to understand the space in which they live. So not just the\n\n1:46:00.400 --> 1:46:03.680\n physical modality, like can they see light, can they feel vibration? I mean, that's important,\n\n1:46:03.680 --> 1:46:08.320\n of course, because that's how you deliver your message. But not just the ideas for a communication\n\n1:46:08.320 --> 1:46:16.000\n medium, not just the physical medium, but saliency, right? So what's important to this\n\n1:46:16.000 --> 1:46:22.080\n system? And systems have all kinds of different levels of sophistication of what you could expect\n\n1:46:22.080 --> 1:46:28.080\n to get back. And I think what's really important, I call this the spectrum of persuadability,\n\n1:46:28.080 --> 1:46:33.200\n which is this idea that when you're looking at a system, you can't assume where on the spectrum\n\n1:46:33.200 --> 1:46:41.440\n it is. You have to do experiments. And so for example, if you look at a gene regulatory network,\n\n1:46:41.440 --> 1:46:45.760\n which is just a bunch of nodes that turn each other on and off at various rates, you might\n\n1:46:45.760 --> 1:46:50.320\n look at that and you say, well, there's no magic here. I mean, clearly this thing is as deterministic\n\n1:46:50.320 --> 1:46:54.320\n as it gets. It's a piece of hardware. The only way we're going to be able to control it is by\n\n1:46:54.320 --> 1:46:57.920\n rewiring it, which is the way molecular biology works, right? We can add nodes, remove nodes,\n\n1:46:57.920 --> 1:47:03.440\n whatever. Well, so we've done simulations and shown that biological, and now we're doing this in the\n\n1:47:03.440 --> 1:47:08.960\n lab, the biological networks like that have associative memory. So they can actually learn,\n\n1:47:08.960 --> 1:47:12.000\n they can learn from experience. They have habituation, they have sensitization, they\n\n1:47:12.000 --> 1:47:15.840\n have associative memory, which you wouldn't have known if you assume that they have to be on the\n\n1:47:15.840 --> 1:47:19.520\n left side of that spectrum. So when you're going to communicate with something, and we've even,\n\n1:47:21.280 --> 1:47:26.080\n Charles Abramson and I have written a paper on behaviorist approaches to synthetic organisms,\n\n1:47:26.080 --> 1:47:29.600\n meaning that if you're given something, you have no idea what it is or what it can do,\n\n1:47:29.600 --> 1:47:34.480\n how do you figure out what its psychology is, what its level is, what does it, and so we literally\n\n1:47:34.480 --> 1:47:38.480\n lay out a set of protocols, starting with the simplest things and then moving up to more complex\n\n1:47:38.480 --> 1:47:42.640\n things where you can make no assumptions about what this thing can do, right? You have to start\n\n1:47:42.640 --> 1:47:47.120\n and you'll find out. So when you're going to, so here's a simple, I mean, here's one way to\n\n1:47:47.120 --> 1:47:51.600\n communicate with something. If you can train it, that's a way of communicating. So if you can\n\n1:47:51.600 --> 1:47:56.160\n provide, if you can figure out what the currency of reward of positive and negative reinforcement is,\n\n1:47:56.160 --> 1:48:01.520\n right, and you can get it to do something it wasn't doing before based on experiences you've\n\n1:48:01.520 --> 1:48:06.080\n given, you have taught it one thing. You have communicated one thing, that such and such an\n\n1:48:06.080 --> 1:48:11.520\n action is good, some other action is not good. That's like a basic atom of a primitive atom\n\n1:48:11.520 --> 1:48:19.040\n of communication. What about in some sense, if it gets you to do something you haven't done before,\n\n1:48:19.040 --> 1:48:24.560\n is it answering back? Yeah, most certainly. And there's, I've seen cartoons, I think maybe Gary\n\n1:48:24.560 --> 1:48:29.040\n Larson or somebody had had a cartoon of these rats in the maze and the one rat, you know,\n\n1:48:29.040 --> 1:48:32.720\n assist to the other. You look at this every time, every time I walk over here, he starts scribbling\n\n1:48:32.720 --> 1:48:37.200\n in that on the, you know, on the clipboard that he has, it's awesome. If we step outside ourselves\n\n1:48:38.720 --> 1:48:46.400\n and really measure how much, like if I actually measure how much I've changed because of my\n\n1:48:46.400 --> 1:48:52.400\n interaction with certain cellular automata. I mean, you really have to take that into\n\n1:48:52.400 --> 1:48:58.320\n consideration about like, well, these things are changing you too. Yes. I know, you know how it\n\n1:48:58.320 --> 1:49:04.080\n works and so on, but you're being changed by the thing. Yeah, absolutely. I think I read,\n\n1:49:04.080 --> 1:49:08.640\n I don't know any details, but I think I read something about how wheat and other things\n\n1:49:08.640 --> 1:49:13.520\n have domesticated humans in terms of, right, but by their properties change the way that\n\n1:49:13.520 --> 1:49:19.280\n the human behavior and societal structures. In that sense, cats are running the world\n\n1:49:20.240 --> 1:49:27.200\n because they've took over the, so first off, so first they, while not giving a shit about humans,\n\n1:49:27.200 --> 1:49:35.680\n clearly with every ounce of their being, they've somehow got just millions and millions of humans\n\n1:49:35.680 --> 1:49:43.280\n to take them home and feed them. And then not only the physical space did they take over,\n\n1:49:43.280 --> 1:49:48.640\n they took over the digital space. They dominate the internet in terms of cuteness, in terms of\n\n1:49:48.640 --> 1:49:55.760\n memeability. And so they're like, they got themselves literally inside the memes, they\n\n1:49:55.760 --> 1:50:01.040\n become viral and spread on the internet. And they're the ones that are probably controlling\n\n1:50:01.040 --> 1:50:06.000\n humans. That's my theory. Another, that's a follow up paper after the frog kissing. Okay.\n\n1:50:06.000 --> 1:50:18.000\n I mean, you mentioned sentience and consciousness. You have a paper titled Generalizing Frameworks\n\n1:50:18.000 --> 1:50:30.320\n for Sentience Beyond Natural Species. So beyond normal cognition, if we look at sentience and\n\n1:50:30.320 --> 1:50:34.000\n consciousness, and I wonder if you draw an interesting distinction between those two\n\n1:50:34.000 --> 1:50:44.560\n elsewhere, outside of humans, and maybe outside of Earth, you think aliens have sentience. And\n\n1:50:45.120 --> 1:50:50.880\n if they do, how do we think about it? So when you have this framework, what is this paper? What is\n\n1:50:50.880 --> 1:50:57.040\n the way you propose to think about sentience? Yeah, that particular paper was a very short\n\n1:50:57.040 --> 1:51:01.280\n commentary on another paper that was written about crabs. It was a really good paper on them,\n\n1:51:01.280 --> 1:51:07.760\n crabs and various, like a rubric of different types of behaviors that could be applied to\n\n1:51:07.760 --> 1:51:13.440\n different creatures, and they're trying to apply it to crabs and so on. Consciousness,\n\n1:51:13.440 --> 1:51:18.400\n we can talk about if you want, but it's a whole separate kettle of fish. I almost never talk about\n\n1:51:18.400 --> 1:51:24.240\n crabs. In this case, yes. I almost never talk about consciousness, per se. I've said very,\n\n1:51:24.240 --> 1:51:29.120\n very little about it, but we can talk about it if you want. Mostly what I talk about is cognition,\n\n1:51:29.120 --> 1:51:36.240\n because I think that that's much easier to deal with in a kind of rigorous experimental way.\n\n1:51:36.240 --> 1:51:45.040\n I think that all of these terms have, you know, sentience and so on, have different definitions,\n\n1:51:45.040 --> 1:51:52.480\n and I fundamentally, I think that people can, as long as they specify what they mean ahead of time,\n\n1:51:53.520 --> 1:51:58.480\n I think people can define them in various ways. The only thing that I really think\n\n1:51:58.480 --> 1:52:04.960\n that I really kind of insist on is that the right way to think about all this stuff is\n\n1:52:06.800 --> 1:52:12.640\n from an engineering perspective. What does it help me to control, predict, and does it help\n\n1:52:12.640 --> 1:52:20.720\n me do my next experiment? That's not a universal perspective. Some people have philosophical\n\n1:52:20.720 --> 1:52:25.600\n kind of underpinnings, and those are primary, and if anything runs against that, then it must\n\n1:52:25.600 --> 1:52:31.440\n automatically be wrong. Some people will say, I don't care what else. If your theory says to me\n\n1:52:31.440 --> 1:52:38.560\n that thermostats have little tiny goals, I'm not, so that's it. That's my philosophical\n\n1:52:38.560 --> 1:52:43.200\n preconception. Thermostats do not have goals, and that's it. That's one way of doing it,\n\n1:52:43.200 --> 1:52:46.400\n and some people do it that way. I do not do it that way, and I think that we can't,\n\n1:52:47.440 --> 1:52:51.440\n I don't think we can know much of anything from a philosophical armchair. I think that\n\n1:52:51.440 --> 1:52:57.280\n all of these theories and ways of doing things stand or fall based on just basically one set\n\n1:52:57.280 --> 1:53:01.040\n of criteria. Does it help you run a rich research program? That's it.\n\n1:53:01.040 --> 1:53:08.240\n I agree with you totally, but forget philosophy. What about the poetry of ambiguity? What about\n\n1:53:08.240 --> 1:53:14.800\n at the limits of the things you can engineer using terms that can be defined in multiple ways\n\n1:53:14.800 --> 1:53:22.720\n and living within that uncertainty in order to play with words until something lands that you\n\n1:53:22.720 --> 1:53:27.600\n can engineer? I mean, that's to me where consciousness sits currently. Nobody really\n\n1:53:27.600 --> 1:53:33.360\n understands the heart problem of consciousness, the subject, what it feels like, because it really\n\n1:53:33.360 --> 1:53:39.040\n feels like, it feels like something to be this biological system. This conglomerate of a bunch\n\n1:53:39.040 --> 1:53:44.800\n of cells in this hierarchy of competencies feels like something, and yeah, I feel like one thing,\n\n1:53:45.360 --> 1:53:58.720\n and is that just a side effect of a complex system, or is there something more that humans have,\n\n1:53:58.720 --> 1:54:03.680\n or is there something more that any biological system has? Some kind of magic, some kind of,\n\n1:54:03.680 --> 1:54:10.560\n not just a sense of agency, but a real sense with a capital letter S of agency.\n\n1:54:10.560 --> 1:54:11.120\n Yeah.\n\n1:54:12.080 --> 1:54:13.760\n Ah, boy, yeah, that's a deep question.\n\n1:54:13.760 --> 1:54:16.640\n Is there room for poetry in engineering or no?\n\n1:54:16.640 --> 1:54:22.240\n No, there definitely is, and a lot of the poetry comes in when we realize that none of the\n\n1:54:22.240 --> 1:54:29.680\n categories we deal with are sharp as we think they are, right? And so in the different areas of all\n\n1:54:29.680 --> 1:54:34.160\n these spectra are where a lot of the poetry sits, I have many new theories about things,\n\n1:54:34.160 --> 1:54:38.400\n but I, in fact, do not have a good theory about consciousness that I plan to trot out.\n\n1:54:38.400 --> 1:54:42.800\n And you almost don't see it as useful for your current work to think about consciousness?\n\n1:54:42.800 --> 1:54:46.160\n I think it will come. I have some thoughts about it, but I don't feel like they're going to move\n\n1:54:46.160 --> 1:54:47.520\n the needle yet on that.\n\n1:54:47.520 --> 1:54:50.720\n And you want to ground it in engineering always.\n\n1:54:50.720 --> 1:54:58.240\n So, well, I mean, so if we really tackle consciousness per se, in the terms of the\n\n1:54:58.240 --> 1:55:04.160\n hard problem, that isn't necessarily going to be groundable in engineering, right? That\n\n1:55:04.160 --> 1:55:10.400\n aspect of cognition is, but actual consciousness per se, first person perspective, I'm not sure\n\n1:55:10.400 --> 1:55:16.480\n that that's groundable in engineering. And I think specifically what's different about it is\n\n1:55:16.480 --> 1:55:20.080\n there's a couple of things. So let's, you know, here we go. I'll say a couple of things about\n\n1:55:20.800 --> 1:55:28.000\n consciousness. One thing is that what makes it different is that for every other thing,\n\n1:55:28.000 --> 1:55:35.200\n other aspect of science, when we think about having a correct or a good theory of it,\n\n1:55:35.200 --> 1:55:41.360\n we have some idea of what format that theory makes predictions in. So whether those be numbers\n\n1:55:41.360 --> 1:55:45.200\n or whatever, we have some idea. We may not know the answer, we may not have the theory,\n\n1:55:45.200 --> 1:55:49.120\n but we know that when we get the theory, here's what it's going to output, and then we'll know\n\n1:55:49.120 --> 1:55:54.320\n if it's right or wrong. For actual consciousness, not behavior, not neural correlates, but actual\n\n1:55:54.320 --> 1:55:59.280\n first person consciousness. If we had a correct theory of consciousness, or even a good one,\n\n1:55:59.840 --> 1:56:05.440\n what the hell would, what format would it make predictions in, right? Because all the things\n\n1:56:05.440 --> 1:56:10.640\n that we know about basically boil down to observable behaviors. So the only thing I can\n\n1:56:10.640 --> 1:56:19.920\n think of when I think about that is, it'll be poetry, or it'll be something to, if I ask you,\n\n1:56:19.920 --> 1:56:23.920\n okay, you've got a great theory of consciousness, and here's this creature, maybe it's a natural one,\n\n1:56:23.920 --> 1:56:28.720\n maybe it's an engineered one, whatever. And I want you to tell me what your theory says about this\n\n1:56:30.000 --> 1:56:36.640\n being, what it's like to be this being. The only thing I can imagine you giving me is some piece\n\n1:56:36.640 --> 1:56:45.600\n of art, a poem or something, that once I've taken it in, I share, I now have a similar state as\n\n1:56:45.600 --> 1:56:51.360\n whatever. That's about as good as I can come up with. Well, it's possible that once you have a\n\n1:56:51.360 --> 1:56:56.240\n good understanding of consciousness, it would be mapped to some things that are more measurable.\n\n1:56:56.240 --> 1:57:07.440\n So for example, it's possible that a conscious being is one that's able to suffer. So you start\n\n1:57:07.440 --> 1:57:16.400\n to look at pain and suffering. You can start to connect it closer to things that you can measure\n\n1:57:16.400 --> 1:57:25.760\n that, in terms of how they reflect themselves in behavior and problem solving and creation and\n\n1:57:25.760 --> 1:57:31.520\n attainment of goals, for example, which I think suffering is one of the, you know, life is suffering.\n\n1:57:31.520 --> 1:57:40.720\n It's one of the big aspects of the human condition. And so if consciousness is somehow a,\n\n1:57:40.720 --> 1:57:48.080\n maybe at least a catalyst for suffering, you could start to get like echoes of it. You start to see\n\n1:57:48.080 --> 1:57:52.880\n like the actual effects of consciousness and behavior. That it's not just about subjective\n\n1:57:52.880 --> 1:57:59.120\n experience. It's like it's really deeply integrated in the problem solving decision making of a\n\n1:57:59.120 --> 1:58:06.000\n system, something like this. But also it's possible that we realize, this is not a philosophical\n\n1:58:06.000 --> 1:58:13.360\n statement. Philosophers can write their books. I welcome it. You know, I take the Turing test\n\n1:58:13.360 --> 1:58:20.800\n really seriously. I don't know why people really don't like it. When a robot convinces you that\n\n1:58:20.800 --> 1:58:26.080\n it's intelligent, I think that's a really incredible accomplishment. And there's some deep\n\n1:58:26.080 --> 1:58:32.560\n sense in which that is intelligence. If it looks like it's intelligent, it is intelligent. And I\n\n1:58:32.560 --> 1:58:43.600\n think there's some deep aspect of a system that appears to be conscious. In some deep sense,\n\n1:58:43.600 --> 1:58:51.520\n it is conscious. At least for me, we have to consider that possibility. And a system that\n\n1:58:51.520 --> 1:58:58.480\n appears to be conscious is an engineering challenge. Yeah, I don't disagree with any of\n\n1:58:58.480 --> 1:59:06.080\n that. I mean, especially intelligence, I think, is a publicly observable thing. Science fiction\n\n1:59:06.080 --> 1:59:12.400\n has dealt with this for a century or much more, maybe. This idea that when you are confronted with\n\n1:59:12.400 --> 1:59:17.760\n something that just doesn't meet any of your typical assumptions, so you can't look in the\n\n1:59:17.760 --> 1:59:23.280\n skull and say, oh, well, there's that frontal cortex, so then I guess we're good. So this thing\n\n1:59:23.280 --> 1:59:30.160\n lands on your front lawn, and the little door opens, and something trundles out, and it's shiny\n\n1:59:30.160 --> 1:59:35.520\n and aluminum looking, and it hands you this poem that it wrote while it was flying over,\n\n1:59:35.520 --> 1:59:40.960\n and how happy it is to meet you. What's going to be your criteria for whether you get to take it\n\n1:59:40.960 --> 1:59:46.000\n apart and see what makes it tick, or whether you have to be nice to it and whatever? All the\n\n1:59:46.000 --> 1:59:51.280\n criteria that we have now and that people are using, and as you said, a lot of people are\n\n1:59:51.280 --> 1:59:55.920\n down on the Turing test and things like this, but what else have we got? Because measuring\n\n1:59:55.920 --> 2:00:03.280\n the cortex size isn't going to cut it in the broader scheme of things. So I think it's a\n\n2:00:03.280 --> 2:00:11.360\n wide open problem. Our solution to the problem of other minds, it's very simplistic. We give each\n\n2:00:11.360 --> 2:00:15.840\n other credit for having minds just because we're sort of on an anatomical level, we're pretty\n\n2:00:15.840 --> 2:00:21.360\n similar, and so it's good enough. But how far is that going to go? So I think that's really primitive.\n\n2:00:21.360 --> 2:00:28.960\n So yeah, I think it's a major unsolved problem. It's a really challenging direction of thought\n\n2:00:28.960 --> 2:00:36.640\n to the human race that you talked about, like embodied minds. If you start to think that other\n\n2:00:36.640 --> 2:00:43.360\n things other than humans have minds, that's really challenging. Because all men are created equal\n\n2:00:43.360 --> 2:00:52.320\n starts being like, all right, well, we should probably treat not just cows with respect,\n\n2:00:52.960 --> 2:01:02.400\n but like plants, and not just plants, but some kind of organized conglomerates of cells\n\n2:01:02.400 --> 2:01:08.960\n in a petri dish. In fact, some of the work we're doing, like you're doing and the whole community\n\n2:01:08.960 --> 2:01:13.760\n of science is doing with biology, people might be like, we were really mean to viruses.\n\n2:01:13.760 --> 2:01:20.320\n Yeah. I mean, yeah, the thing is, you're right. And I certainly get phone calls about people\n\n2:01:20.320 --> 2:01:26.560\n complaining about frog skin and so on. But I think we have to separate the sort of deep\n\n2:01:26.560 --> 2:01:30.560\n philosophical aspects versus what actually happens. So what actually happens on Earth\n\n2:01:30.560 --> 2:01:37.280\n is that people with exactly the same anatomical structure kill each other on a daily basis.\n\n2:01:37.280 --> 2:01:43.680\n So I think it's clear that simply knowing that something else is equally or maybe more\n\n2:01:44.880 --> 2:01:51.120\n cognitive or conscious than you are is not a guarantee of kind behavior, that much we know of.\n\n2:01:51.120 --> 2:01:56.880\n And so then we look at a commercial farming of mammals and various other things. And so I think\n\n2:01:56.880 --> 2:02:03.120\n on a practical basis, long before we get to worrying about things like frog skin,\n\n2:02:03.120 --> 2:02:08.400\n we have to ask ourselves, why are we, what can we do about the way that we've been behaving\n\n2:02:08.400 --> 2:02:13.280\n towards creatures, which we know for a fact, because of our similarities are basically just\n\n2:02:13.280 --> 2:02:18.880\n like us. That's kind of a whole other social thing. But fundamentally, of course, you're\n\n2:02:18.880 --> 2:02:24.720\n absolutely right in that we are also, think about this, we are on this planet in some way,\n\n2:02:24.720 --> 2:02:31.360\n incredibly lucky. It's just dumb luck that we really only have one dumb animal.\n\n2:02:31.360 --> 2:02:37.200\n We only have one dominant species. It didn't have to work out that way. So you could easily\n\n2:02:37.200 --> 2:02:43.360\n imagine that there could be a planet somewhere with more than one equally or maybe near equally\n\n2:02:43.360 --> 2:02:49.200\n intelligent species. But they may not look anything like each other. So there may be\n\n2:02:49.200 --> 2:02:54.960\n multiple ecosystems where there are things of similar to human like intelligence. And then\n\n2:02:54.960 --> 2:02:59.840\n you'd have all kinds of issues about how do you relate to them when they're physically\n\n2:02:59.840 --> 2:03:04.960\n like you at all. But yet in terms of behavior and culture and whatever, it's pretty obvious\n\n2:03:04.960 --> 2:03:09.600\n that they've got as much on the ball as you have. Or maybe imagine that there was another\n\n2:03:10.400 --> 2:03:18.320\n group of beings that was on average 40 IQ points lower. We're pretty lucky in many ways. We don't\n\n2:03:18.320 --> 2:03:24.400\n really have, even though we still act badly in many ways. But the fact is, all humans are more\n\n2:03:24.400 --> 2:03:30.160\n or less in that same range, but didn't have to work out that way. Well, but I think that's part\n\n2:03:30.160 --> 2:03:38.800\n of the way life works on Earth, maybe human civilization works, is it seems like we want\n\n2:03:38.800 --> 2:03:45.280\n ourselves to be quite similar. And then within that, you know, where everybody's about the same\n\n2:03:45.280 --> 2:03:49.840\n relatively IQ, intelligence, problem solving capabilities, even physical characteristics.\n\n2:03:49.840 --> 2:03:56.400\n But then we'll find some aspect of that that's different. And that seems to be like,\n\n2:03:58.560 --> 2:04:06.560\n I mean, it's really dark to say, but that seems to be the, not even a bug, but like a feature\n\n2:04:07.440 --> 2:04:14.960\n of the early development of human civilization. You pick the other, your tribe versus the other\n\n2:04:14.960 --> 2:04:22.640\n tribe and you war, it's a kind of evolution in the space of memes, a space of ideas, I think,\n\n2:04:22.640 --> 2:04:28.240\n and you war with each other. So we're very good at finding the other, even when the characteristics\n\n2:04:28.240 --> 2:04:35.040\n are really the same. And that's, I don't know what that, I mean, I'm sure so many of these things\n\n2:04:35.040 --> 2:04:41.600\n echo in the biological world in some way. Yeah. There's a fun experiment that I did. My son\n\n2:04:41.600 --> 2:04:46.880\n actually came up with this and we did a biology unit together. He's a homeschool. And so we did\n\n2:04:46.880 --> 2:04:50.800\n this a couple of years ago. We did this thing where, imagine you get this slime mold, right?\n\n2:04:50.800 --> 2:04:57.600\n Fisarum polycephalum, and it grows on a Petri dish of agar and it sort of spreads out and it's a\n\n2:04:57.600 --> 2:05:02.160\n single cell protist, but it's like this giant thing. And so you put down a piece of oat and\n\n2:05:02.160 --> 2:05:05.760\n it wants to go get the oat and it sort of grows towards the oat. So what you do is you take a\n\n2:05:05.760 --> 2:05:10.160\n razor blade and you just separate the piece of the whole culture that's growing towards the\n\n2:05:10.160 --> 2:05:15.040\n oat. You just kind of separate it. And so now think about the interesting decision making\n\n2:05:15.040 --> 2:05:20.960\n calculus for that little piece. I can go get the oat and therefore I won't have to share those\n\n2:05:20.960 --> 2:05:25.280\n nutrients with this giant mass over there. So the nutrients per unit volume is going to be amazing.\n\n2:05:25.280 --> 2:05:30.560\n I should go eat the oat. But if I first rejoin, because Fisarum, once you cut it, has the ability\n\n2:05:30.560 --> 2:05:36.240\n to join back up. If I first rejoin, then that whole calculus becomes impossible because there\n\n2:05:36.240 --> 2:05:40.960\n is no more me anymore. There's just we and then we will go eat this thing, right? So this\n\n2:05:40.960 --> 2:05:46.320\n interesting, you can imagine a kind of game theory where the number of agents isn't fixed\n\n2:05:46.320 --> 2:05:50.320\n and that it's not just cooperate or defect, but it's actually merge and whatever, right?\n\n2:05:50.320 --> 2:05:54.400\n Yeah. So that computation, how does it do that decision making?\n\n2:05:54.400 --> 2:06:00.240\n Yeah. So it's really interesting. And so empirically, what we found is that it tends\n\n2:06:00.240 --> 2:06:04.720\n to merge first. It tends to merge first and then the whole thing goes. But it's really interesting\n\n2:06:04.720 --> 2:06:09.600\n that that calculus, I mean, I'm not an expert in the economic game theory and all that,\n\n2:06:09.600 --> 2:06:14.880\n but maybe there's some sort of hyperbolic discounting or something. But maybe this idea\n\n2:06:14.880 --> 2:06:22.720\n that the actions you take not only change your payoff, but they change who or what you are,\n\n2:06:22.720 --> 2:06:27.440\n and that you could take an action after which you don't exist anymore, or you are radically\n\n2:06:27.440 --> 2:06:33.280\n changed, or you are merged with somebody else. As far as I know, that's a whole different\n\n2:06:33.280 --> 2:06:38.720\n thing. As far as I know, we're still missing a formalism for even knowing how to model\n\n2:06:38.720 --> 2:06:39.720\n any of that.\n\n2:06:39.720 --> 2:06:45.200\n Do you see evolution, by the way, as a process that applies here on Earth? Where did evolution\n\n2:06:45.200 --> 2:06:46.200\n come from?\n\n2:06:46.200 --> 2:06:47.200\n Yeah.\n\n2:06:47.200 --> 2:06:54.560\n So this thing from the very origin of life that took us to today, what the heck is that?\n\n2:06:54.560 --> 2:07:00.960\n I think evolution is inevitable in the sense that if you combine, and basically, I think\n\n2:07:00.960 --> 2:07:05.600\n one of the most useful things that was done in early computing, I guess in the 60s, it\n\n2:07:05.600 --> 2:07:13.320\n started with evolutionary computation and just showing how simple it is that if you have\n\n2:07:13.320 --> 2:07:19.280\n imperfect heredity and competition together, those two things, or three things, so heredity,\n\n2:07:19.280 --> 2:07:25.000\n imperfect heredity, and competition, or selection, those three things, and that's it. Now you're\n\n2:07:25.000 --> 2:07:29.640\n off to the races. And so that can be, it's not just on Earth because it can be done in\n\n2:07:29.640 --> 2:07:33.480\n the computer, it can be done in chemical systems, it can be done in, you know, Lee Smolin says\n\n2:07:33.480 --> 2:07:42.400\n it works on cosmic scales. So I think that that kind of thing is incredibly pervasive\n\n2:07:42.400 --> 2:07:49.200\n and general. It's a general feature of life. It's interesting to think about, you know,\n\n2:07:49.200 --> 2:07:55.280\n the standard thought about this is that it's blind, right? Meaning that the intelligence\n\n2:07:55.280 --> 2:08:01.520\n of the process is zero, it's stumbling around. And I think that back in the day, when the\n\n2:08:01.520 --> 2:08:07.560\n options were it's dumb like machines, or it's smart like humans, then of course, the scientists\n\n2:08:07.560 --> 2:08:10.680\n went in this direction, because nobody wanted creationism. They said, okay, it's got to\n\n2:08:10.680 --> 2:08:15.920\n be like completely blind. I'm not actually sure, right? Because I think that everything\n\n2:08:15.920 --> 2:08:20.880\n is a continuum. And I think that it doesn't have to be smart with foresight like us, but\n\n2:08:20.880 --> 2:08:25.720\n it doesn't have to be completely blind either. I think there may be aspects of it. And in\n\n2:08:25.720 --> 2:08:30.760\n particular, this kind of multi scale competency might give it a little bit of look ahead maybe\n\n2:08:30.760 --> 2:08:36.700\n or a little bit of problem solving sort of baked in. But that's going to be completely\n\n2:08:36.700 --> 2:08:41.640\n different in different systems. I do think it's general. I don't think it's just on Earth.\n\n2:08:41.640 --> 2:08:44.040\n I think it's a very fundamental thing.\n\n2:08:44.040 --> 2:08:50.120\n And it does seem to have a kind of direction that it's taking us that's somehow perhaps\n\n2:08:50.120 --> 2:08:57.360\n is defined by the environment itself. It feels like we're headed towards something. Like,\n\n2:08:57.360 --> 2:09:03.060\n we're playing out a script that was just like a single cell defines the entire organism.\n\n2:09:03.060 --> 2:09:10.480\n It feels like from the origin of Earth itself, it's playing out a kind of script. You can't\n\n2:09:10.480 --> 2:09:12.480\n really go any other way.\n\n2:09:12.480 --> 2:09:17.280\n I mean, so this is very controversial, and I don't know the answer. But people have argued\n\n2:09:17.280 --> 2:09:22.720\n that this is called, you know, sort of rewinding the tape of life, right? And some people have\n\n2:09:22.720 --> 2:09:28.440\n argued, I think, I think Conway Morris, maybe has argued that it is that there's a deep\n\n2:09:28.440 --> 2:09:34.640\n attractor, for example, to human to the human kind of structure and that and that if you\n\n2:09:34.640 --> 2:09:37.560\n were to rewind it again, you'd basically get more or less the same thing. And then other\n\n2:09:37.560 --> 2:09:41.920\n people have argued that, no, it's incredibly sensitive to frozen accidents. And then once\n\n2:09:41.920 --> 2:09:46.200\n certain stochastic decisions are made downstream, everything is going to be different. I don't\n\n2:09:46.200 --> 2:09:52.760\n know. I don't know. You know, we're very bad at predicting attractors in the space of complex\n\n2:09:52.760 --> 2:09:56.880\n systems, generally speaking, right? We don't know. So maybe, so maybe evolution on Earth\n\n2:09:56.880 --> 2:10:01.360\n has these deep attractors that no matter what has happened, it pretty much would likely\n\n2:10:01.360 --> 2:10:03.640\n to end up there or maybe not. I don't know.\n\n2:10:03.640 --> 2:10:10.880\n What's a really difficult idea to imagine that if you ran Earth a million times, 500,000\n\n2:10:10.880 --> 2:10:17.160\n times you would get Hitler? Like, yeah, we don't like to think like that. We think like,\n\n2:10:17.160 --> 2:10:23.480\n because at least maybe in America, you'd like to think that individual decisions can change\n\n2:10:23.480 --> 2:10:30.760\n the world. And if individual decisions could change the world, then surely any perturbation\n\n2:10:30.760 --> 2:10:38.560\n could result in a totally different trajectory. But maybe there's a, in this competency hierarchy,\n\n2:10:38.560 --> 2:10:43.320\n it's a self correcting system. There's just ultimately, there's a bunch of chaos that\n\n2:10:43.320 --> 2:10:47.200\n ultimately is leading towards something like a super intelligent, artificial intelligence\n\n2:10:47.200 --> 2:10:56.800\n system that answers 42. I mean, there might be a kind of imperative for life that it's\n\n2:10:56.800 --> 2:11:04.360\n headed to. And we're too focused on our day to day life of getting coffee and snacks and\n\n2:11:04.360 --> 2:11:12.840\n having sex and getting a promotion at work, not to see the big imperative of life on Earth\n\n2:11:12.840 --> 2:11:14.560\n that is headed towards something.\n\n2:11:14.560 --> 2:11:24.640\n Yeah, maybe, maybe. It's difficult. I think one of the things that's important about Chimerica\n\n2:11:24.640 --> 2:11:29.520\n bioengineering technologies, all of those things are that we have to start developing\n\n2:11:29.520 --> 2:11:35.240\n a better science of predicting the cognitive goals of composite systems. So we're just\n\n2:11:35.240 --> 2:11:41.320\n not very good at it, right? We don't know if I create a composite system, and this could\n\n2:11:41.320 --> 2:11:48.240\n be Internet of Things or swarm robotics or a cellular swarm or whatever. What is the\n\n2:11:48.240 --> 2:11:51.640\n emergent intelligence of this thing? First of all, what level is it going to be at? And\n\n2:11:51.640 --> 2:11:56.240\n if it has goal directed capacity, what are the goals going to be? Like, we are just not\n\n2:11:56.240 --> 2:12:06.420\n very good at predicting that yet. And I think that it's an existential level need for us\n\n2:12:06.420 --> 2:12:10.520\n to be able to because we're building these things all the time, right? We're building\n\n2:12:10.520 --> 2:12:16.060\n both physical structures like swarm robotics, and we're building social financial structures\n\n2:12:16.060 --> 2:12:21.640\n and so on, with very little ability to predict what sort of autonomous goals that system\n\n2:12:21.640 --> 2:12:26.780\n is going to have, of which we are now cogs. And so learning to predict and control those\n\n2:12:26.780 --> 2:12:31.400\n things is going to be critical. So in fact, if you're right and there is some kind of\n\n2:12:31.400 --> 2:12:36.680\n attractor to evolution, it would be nice to know what that is and then to make a rational\n\n2:12:36.680 --> 2:12:39.800\n decision of whether we're going to go along or we're going to pop out of it or try to\n\n2:12:39.800 --> 2:12:44.120\n pop out of it because there's no guarantee. I mean, that's the other kind of important\n\n2:12:44.120 --> 2:12:49.760\n thing. A lot of people, I get a lot of complaints from people who email me and say, you know,\n\n2:12:49.760 --> 2:12:56.240\n what you're doing, it isn't natural. And I'll say, look, natural, that'd be nice if somebody\n\n2:12:56.240 --> 2:13:02.520\n was making sure that natural was matched up to our values, but no one's doing that. Evolution\n\n2:13:02.520 --> 2:13:07.160\n optimizes for biomass. That's it. Nobody's optimizing. It's not optimizing for your happiness.\n\n2:13:07.160 --> 2:13:11.600\n I don't think necessarily it's optimizing for intelligence or fairness or any of that\n\n2:13:11.600 --> 2:13:12.600\n stuff.\n\n2:13:12.600 --> 2:13:18.720\n I'm going to find that person that emailed you, beat them up, take their place, steal\n\n2:13:18.720 --> 2:13:22.040\n everything they own and say, no, this is natural.\n\n2:13:22.040 --> 2:13:28.200\n This is natural. Yeah, exactly. Because it comes from an old worldview where you could\n\n2:13:28.200 --> 2:13:32.040\n assume that whatever is natural, that that's probably for the best. And I think we're long\n\n2:13:32.040 --> 2:13:37.000\n out of that garden of Eden kind of view. So I think we can do better. I think we, and\n\n2:13:37.000 --> 2:13:42.020\n we have to, right? Natural just isn't great for a lot of life forms.\n\n2:13:42.020 --> 2:13:46.520\n What are some cool synthetic organisms that you think about, you dream about? When you\n\n2:13:46.520 --> 2:13:51.400\n think about embodied mind, what do you imagine? What do you hope to build?\n\n2:13:51.400 --> 2:13:57.700\n Yeah, on a practical level, what I really hope to do is to gain enough of an understanding\n\n2:13:57.700 --> 2:14:04.680\n of the embodied intelligence of the organs and tissues such that we can achieve a radically\n\n2:14:04.680 --> 2:14:11.080\n different regenerative medicine so that we can say, basically, and I think about it as,\n\n2:14:11.080 --> 2:14:18.200\n you know, in terms of like, okay, can you, what's the goal kind of end game for this\n\n2:14:18.200 --> 2:14:22.480\n whole thing? To me, the end game is something that you would call an anatomical compiler.\n\n2:14:22.480 --> 2:14:27.440\n So the idea is you would sit down in front of the computer and you would draw the body\n\n2:14:27.440 --> 2:14:31.880\n or the organ that you wanted. Not molecular details, but like, yeah, this is what I want.\n\n2:14:31.880 --> 2:14:36.200\n I want a six legged, you know, frog with a propeller on top, or I want a heart that looks\n\n2:14:36.200 --> 2:14:39.800\n like this, or I want a leg that looks like this. And what it would do if we knew what\n\n2:14:39.800 --> 2:14:47.000\n we were doing is put out, convert that anatomical description into a set of stimuli that would\n\n2:14:47.000 --> 2:14:51.320\n have to be given to cells to convince them to build exactly that thing, right? I probably\n\n2:14:51.320 --> 2:14:56.840\n won't live to see it, but I think it's achievable. And I think with that, if we can have that,\n\n2:14:56.840 --> 2:15:03.140\n then that is basically the solution to all of medicine except for infectious disease.\n\n2:15:03.140 --> 2:15:07.620\n So birth defects, right? Traumatic injury, cancer, aging, degenerative disease. If we\n\n2:15:07.620 --> 2:15:11.440\n knew how to tell cells what to build, all of those things go away. So those things go\n\n2:15:11.440 --> 2:15:18.520\n away. And the positive feedback spiral of economic costs, where all of the advances\n\n2:15:18.520 --> 2:15:22.880\n are increasingly more heroic and expensive interventions of a sinking ship when you're\n\n2:15:22.880 --> 2:15:26.980\n like 90 and so on, right? All of that goes away because basically, instead of trying\n\n2:15:26.980 --> 2:15:33.800\n to fix you up as you degrade, you progressively regenerate, you apply the regenerative medicine\n\n2:15:33.800 --> 2:15:38.920\n early before things degrade. So I think that that'll have massive economic impacts over\n\n2:15:38.920 --> 2:15:43.800\n what we're trying to do now, which is not at all sustainable. And that's what I hope.\n\n2:15:43.800 --> 2:15:50.080\n I hope that we get it. So to me, yes, the xenobots will be doing useful things, cleaning\n\n2:15:50.080 --> 2:15:55.480\n up the environment, cleaning out your joints and all that kind of stuff. But more important\n\n2:15:55.480 --> 2:16:04.920\n than that, I think we can use these synthetic systems to try to develop a science of detecting\n\n2:16:04.920 --> 2:16:10.840\n and manipulating the goals of collective intelligences of cells specifically for regenerative medicine.\n\n2:16:10.840 --> 2:16:15.840\n And then sort of beyond that, if we think further beyond that, what I hope is that kind\n\n2:16:15.840 --> 2:16:22.480\n of like what you said, all of this drives a reconsideration of how we formulate ethical\n\n2:16:22.480 --> 2:16:29.080\n norms because this old school, so in the olden days, what you could do is if you were confronted\n\n2:16:29.080 --> 2:16:33.200\n with something, you could tap on it, right? And if you heard a metallic clanging sound,\n\n2:16:33.200 --> 2:16:37.160\n you'd say, ah, fine, right? So you could conclude it was made in a factory. I can take it apart.\n\n2:16:37.160 --> 2:16:40.960\n I can do whatever, right? If you did that and you got sort of a squishy kind of warm\n\n2:16:40.960 --> 2:16:46.080\n sensation, you'd say, ah, I need to be more or less nice to it and whatever. That's not\n\n2:16:46.080 --> 2:16:49.360\n going to be feasible. It was never really feasible, but it was good enough because we\n\n2:16:49.360 --> 2:16:55.940\n didn't have any, we didn't know any better. That needs to go. And I think that by breaking\n\n2:16:55.940 --> 2:17:03.200\n down those artificial barriers, someday we can try to build a system of ethical norms\n\n2:17:03.200 --> 2:17:08.740\n that does not rely on these completely contingent facts of our earthly history, but on something\n\n2:17:08.740 --> 2:17:15.520\n much, much deeper that really takes agency and the capacity to suffer and all that takes\n\n2:17:15.520 --> 2:17:16.520\n that seriously.\n\n2:17:16.520 --> 2:17:21.560\n The capacity to suffer and the deep questions I would ask of a system is can I eat it and\n\n2:17:21.560 --> 2:17:30.560\n can I have sex with it? Which is the two fundamental tests of, again, the human condition. So I\n\n2:17:30.560 --> 2:17:39.480\n can basically do what Dali does that's in the physical space. So print out like a 3D\n\n2:17:39.480 --> 2:17:46.320\n print Pepe the Frog with a propeller head, propeller hat is the dream.\n\n2:17:46.320 --> 2:17:50.840\n Well yes and no. I mean, I want to get away from the 3D printing thing because that will\n\n2:17:50.840 --> 2:17:55.560\n be available for some things much earlier. I mean, we can already do bladders and ears\n\n2:17:55.560 --> 2:17:59.920\n and things like that because it's micro level control, right? When you 3D print, you are\n\n2:17:59.920 --> 2:18:02.960\n in charge of where every cell goes. And for some things that, you know, for, for like\n\n2:18:02.960 --> 2:18:06.040\n this thing, they had that I think 20 years ago or maybe earlier than that, you could\n\n2:18:06.040 --> 2:18:07.040\n do that.\n\n2:18:07.040 --> 2:18:11.480\n So yeah, I would like to emphasize the Dali part where you provide a few words and it\n\n2:18:11.480 --> 2:18:19.920\n generates a painting. So here you say, I want a frog with these features and then it would\n\n2:18:19.920 --> 2:18:25.000\n go direct a complex biological system to construct something like that.\n\n2:18:25.000 --> 2:18:30.040\n Yeah. The main magic would be, I mean, I think from, from looking at Dali and so on, it looks\n\n2:18:30.040 --> 2:18:34.360\n like the first part is kind of solved now where you go from, from the words to the image,\n\n2:18:34.360 --> 2:18:39.920\n like that seems more or less solved. The next step is really hard. This is what keeps things\n\n2:18:39.920 --> 2:18:46.880\n like CRISPR and genomic editing and so on. That's what limits all the impacts for regenerative\n\n2:18:46.880 --> 2:18:51.320\n medicine because going back to, okay, this is the knee joint that I want, or this is\n\n2:18:51.320 --> 2:18:56.000\n the eye that I want. Now, what genes do I edit to make that happen, right? Going back\n\n2:18:56.000 --> 2:18:59.840\n in that direction is really hard. So instead of that, it's going to be, okay, I understand\n\n2:18:59.840 --> 2:19:03.680\n how to motivate cells to build particular structures. Can I rewrite the memory of what\n\n2:19:03.680 --> 2:19:07.480\n they think they're supposed to be building such that then I can, you know, take my hands\n\n2:19:07.480 --> 2:19:09.960\n off the wheel and let them, let them do their thing.\n\n2:19:09.960 --> 2:19:13.960\n So some of that is experiment, but some of that may be AI can help too. Just like with\n\n2:19:13.960 --> 2:19:23.400\n protein folding, this is exactly the problem that protein folding in the most simple medium\n\n2:19:23.400 --> 2:19:31.800\n tried and has solved with alpha fold, which is how does the sequence of letters result\n\n2:19:31.800 --> 2:19:37.160\n in this three dimensional shape? And you have to, I guess it didn't solve it because you\n\n2:19:37.160 --> 2:19:43.760\n have to, if you say, I want this shape, how do I then have a sequence of letters? Yeah.\n\n2:19:43.760 --> 2:19:45.920\n The reverse engineering step is really tricky.\n\n2:19:45.920 --> 2:19:51.680\n It is. I think, I think we're, we're, and we're doing some of this now is, is to use\n\n2:19:51.680 --> 2:19:57.800\n AI to try and build actionable models of the intelligence of the cellular collectives.\n\n2:19:57.800 --> 2:20:02.400\n So try to help us and help us gain models that, that, that, and, and we've had some\n\n2:20:02.400 --> 2:20:08.480\n success in this. So we, we did something like this for, for, you know, for repairing birth\n\n2:20:08.480 --> 2:20:14.240\n defects of the brain in frog. We've done some of this for normalizing melanoma where you\n\n2:20:14.240 --> 2:20:20.140\n can really start to use AI to make models of how would I impact this thing if I wanted\n\n2:20:20.140 --> 2:20:25.600\n to given all the complexities, right. And, and, and given all the, the, the, the controls\n\n2:20:25.600 --> 2:20:27.520\n that it, that it knows how to do.\n\n2:20:27.520 --> 2:20:34.060\n So when you say regenerative medicine, so we talked about creating biological organisms,\n\n2:20:34.060 --> 2:20:41.440\n but if you regrow a hand, that information is already there, right? The biological system\n\n2:20:41.440 --> 2:20:48.080\n has that information. So how does regenerative medicine work today? How do you hope it works?\n\n2:20:48.080 --> 2:20:49.080\n What's the hope there?\n\n2:20:49.080 --> 2:20:50.080\n Yeah.\n\n2:20:50.080 --> 2:20:52.480\n Yeah. How do you make it happen?\n\n2:20:52.480 --> 2:20:57.480\n Well today there's a set of popular approaches. So, so one is 3d printing. So the idea is\n\n2:20:57.480 --> 2:21:00.600\n I'm going to make a scaffold of the thing that I want. I'm going to seed it with cells\n\n2:21:00.600 --> 2:21:03.760\n and then, and then there it is, right? So kind of direct, and then that works for certain\n\n2:21:03.760 --> 2:21:08.920\n things. You can make a bladder that way or an ear, something like that. The other, the\n\n2:21:08.920 --> 2:21:14.300\n other ideas is some sort of stem cell transplant. These are the ideas. If we, if we put in stem\n\n2:21:14.300 --> 2:21:17.920\n cells with appropriate factors, we can get them to generate certain kinds of neurons\n\n2:21:17.920 --> 2:21:24.760\n for certain diseases and so on. All of those things are good for relatively simple structures,\n\n2:21:24.760 --> 2:21:30.660\n but when you want an eye or a hand or something else, I think in this maybe an unpopular opinion,\n\n2:21:30.660 --> 2:21:36.560\n I think the only hope we have in any reasonable kind of timeframe is to understand how the\n\n2:21:36.560 --> 2:21:41.320\n thing was motivated to get made in the first place. So what is it that, that made those\n\n2:21:41.320 --> 2:21:48.400\n cells in the, in the beginning, create a particular arm with a particular set of sizes and shapes\n\n2:21:48.400 --> 2:21:51.760\n and number of fingers and all that. And why is it that a salamander can keep losing theirs\n\n2:21:51.760 --> 2:21:57.640\n and keep regrowing theirs and a planarian can do the same even more? So to me, uh, kind\n\n2:21:57.640 --> 2:22:02.840\n of ultimate regenerate medicine was when you can tell the cells to build whatever it is\n\n2:22:02.840 --> 2:22:07.400\n you need them to build. Right. And so the, so that we can all be like planaria basically,\n\n2:22:07.400 --> 2:22:13.680\n do you have to start at the very beginning or can you, um, do a shortcut? Cause we're\n\n2:22:13.680 --> 2:22:19.560\n going to hand, you already got the whole organism. Yeah. So here's what we've done, right? So,\n\n2:22:19.560 --> 2:22:24.160\n we've, we've more or less solved that in frogs. So frogs, unlike salamanders do not regenerate\n\n2:22:24.160 --> 2:22:31.800\n their legs as adults. And so, so, uh, we've shown that with a very, um, uh, kind of simple\n\n2:22:31.800 --> 2:22:36.100\n intervention. So what we do is there's two things you need to, uh, you need to have a\n\n2:22:36.100 --> 2:22:39.520\n signal that tells the cells what to do, and then you need some way of delivering it. And\n\n2:22:39.520 --> 2:22:44.080\n so this is work together with, um, with David Kaplan and I should do a, um, a disclosure\n\n2:22:44.080 --> 2:22:48.200\n here. We have a company called morphosuticals and spin off where we're trying to, uh, to\n\n2:22:48.200 --> 2:22:52.320\n address, uh, uh, regenerate, you know, limb regeneration. So we've solved it in the frog\n\n2:22:52.320 --> 2:22:56.440\n and we're now in trials and mice. So now we're going to, we're in mammals now. It's, I can't\n\n2:22:56.440 --> 2:22:59.720\n say anything about how it's going, but the frog thing is solved. So what you do is, um,\n\n2:22:59.720 --> 2:23:04.480\n after you have a little frog, Lou Skywalker with every growing hand. Yeah, basically,\n\n2:23:04.480 --> 2:23:07.840\n basically. Yeah. Yeah. So what you do is we did, we did with legs instead of forearms.\n\n2:23:07.840 --> 2:23:11.200\n And what you do is, um, after amputation, normally they, they don't regenerate. You\n\n2:23:11.200 --> 2:23:15.620\n put on a wearable bioreactor. So it's this thing that, um, that goes on and, uh, Dave\n\n2:23:15.620 --> 2:23:21.300\n Kaplan does lab makes these things and inside it's a, it's a very controlled environment.\n\n2:23:21.300 --> 2:23:26.360\n It is a silk gel that carries, uh, some drugs, for example, ion channel drugs. And what you're\n\n2:23:26.360 --> 2:23:33.720\n doing is you're saying to the cells, you should regrow what normally goes here. So, uh, that\n\n2:23:33.720 --> 2:23:37.760\n whole thing is on for 24 hours and you take it off and you don't touch the leg. Again,\n\n2:23:37.760 --> 2:23:41.280\n this is really important because what we're not looking for is a set of micromanagement,\n\n2:23:41.280 --> 2:23:45.600\n uh, you know, printing or controlling the cells we want to trigger. We want to, we want\n\n2:23:45.600 --> 2:23:49.260\n to interact with it early on and then not touch it again because, because we don't know\n\n2:23:49.260 --> 2:23:54.820\n how to make a frog leg, but the frog knows how to make a frog leg. So 24 hours, 18 months\n\n2:23:54.820 --> 2:23:58.480\n of leg growth after that, without us touching it again. And after 18 months, you get a pretty\n\n2:23:58.480 --> 2:24:02.720\n good leg that kind of shows this proof of concept that early on when the cells right\n\n2:24:02.720 --> 2:24:05.560\n after injury, when they're first making a decision about what they're going to do, you\n\n2:24:05.560 --> 2:24:09.440\n can, you can impact them. And once they've decided to make a leg, they don't need you\n\n2:24:09.440 --> 2:24:14.040\n after that. They can do their own thing. So that's an approach that we're now taking.\n\n2:24:14.040 --> 2:24:18.480\n What about cancer suppression? That's something you mentioned earlier. How can all of these\n\n2:24:18.480 --> 2:24:20.360\n ideas help with cancer suppression?\n\n2:24:20.360 --> 2:24:23.600\n So let's, let's go back to the beginning and ask what, what, what, what cancer is. So I\n\n2:24:23.600 --> 2:24:28.520\n think, um, you know, asking why there's cancer is the wrong question. I think the right question\n\n2:24:28.520 --> 2:24:33.420\n is why is there ever anything but cancer? So, so in the normal state, you have a bunch\n\n2:24:33.420 --> 2:24:38.680\n of cells that are all cooperating towards a large scale goal. If that process of cooperation\n\n2:24:38.680 --> 2:24:42.780\n breaks down and you've got a cell that is isolated from that electrical network that\n\n2:24:42.780 --> 2:24:47.280\n lets you remember what the big goal is, you revert back to your unicellular lifestyle\n\n2:24:47.280 --> 2:24:51.020\n as far as, now think about that border between self and world, right? Normally when all these\n\n2:24:51.020 --> 2:24:56.360\n cells are connected by gap junctions into an electrical network, they are all one self,\n\n2:24:56.360 --> 2:25:01.600\n right? That meaning that, um, their goals, they have these large tissue level goals and\n\n2:25:01.600 --> 2:25:06.760\n so on. As soon as a cell is disconnected from that, the self is tiny, right? And so at that\n\n2:25:06.760 --> 2:25:11.580\n point, and so, so people, a lot of people model cancer cell cells as being more selfish\n\n2:25:11.580 --> 2:25:14.280\n and all that. They're not more selfish. They're equally selfish. It's just that their self\n\n2:25:14.280 --> 2:25:18.040\n is smaller. Normally the self is huge. Now they got tiny little selves. Now what are\n\n2:25:18.040 --> 2:25:22.680\n the goals of tiny little selves? Well, proliferate, right? And migrate to wherever life is good.\n\n2:25:22.680 --> 2:25:26.640\n And that's metastasis. That's proliferation and metastasis. So, so one thing we found\n\n2:25:26.640 --> 2:25:31.960\n and people have noticed years ago that when cells convert to cancer, the first thing they\n\n2:25:31.960 --> 2:25:36.800\n see is they close the gap junctions. And it's a lot like, I think it's a lot like that experiment\n\n2:25:36.800 --> 2:25:41.440\n with the slime mold where until you close that gap junction, you can't even entertain\n\n2:25:41.440 --> 2:25:44.520\n the idea of leaving the collective because there is no you at that point, right? Your\n\n2:25:44.520 --> 2:25:48.600\n mind melded with this, with this whole other network. But as soon as the gap junction is\n\n2:25:48.600 --> 2:25:53.600\n closed, now the boundary between you and now, now the rest of the body is just outside environment\n\n2:25:53.600 --> 2:25:58.520\n to you. You're just a, you're just a unicellular organism and the rest of the body's environment.\n\n2:25:58.520 --> 2:26:04.840\n So, so we, so we studied this process and we worked out a way to artificially control\n\n2:26:04.840 --> 2:26:10.120\n the bioelectric state of these cells to physically force them to remain in that network. And\n\n2:26:10.120 --> 2:26:15.580\n so then, then what that, what that means is that nasty mutations like KRAS and things\n\n2:26:15.580 --> 2:26:20.920\n like that, these really tough oncogenic mutations that cause tumors. If you, if you do them\n\n2:26:20.920 --> 2:26:29.120\n and then, but then within artificially control of the bioelectrics, you greatly reduce tumor\n\n2:26:29.120 --> 2:26:33.840\n genesis or, or normalize cells that had already begun to convert. You basically, they go back\n\n2:26:33.840 --> 2:26:38.080\n to being normal cells. And so this is another, much like with the planaria, this is another\n\n2:26:38.080 --> 2:26:43.400\n way in which the bioelectric state kind of dominates what the, what the genetic state\n\n2:26:43.400 --> 2:26:47.200\n is. So if you sequence the, you know, if you sequence the nucleic acid, you'll see the\n\n2:26:47.200 --> 2:26:50.800\n KRAS mutation, you'll say, ah, well that's going to be a tumor, but there isn't a tumor\n\n2:26:50.800 --> 2:26:54.200\n because, because bioelectrically you've kept the cells connected and they're just working\n\n2:26:54.200 --> 2:26:59.760\n on making nice skin and kidneys and whatever else. So, so we've started moving that to,\n\n2:26:59.760 --> 2:27:04.760\n to, to human glioblastoma cells and we're hoping for, you know, a patient in the future\n\n2:27:04.760 --> 2:27:07.560\n interaction with patients.\n\n2:27:07.560 --> 2:27:12.820\n So is this one of the possible ways in which we may quote cure cancer?\n\n2:27:12.820 --> 2:27:17.160\n I think so. Yeah, I think so. I think, I think the actual cure, I mean, there are other technology,\n\n2:27:17.160 --> 2:27:21.920\n you know, immune therapy, I think is a great technology. Chemotherapy, I don't think is\n\n2:27:21.920 --> 2:27:25.680\n a good, is a good technology. I think we've got to get, get off of that.\n\n2:27:25.680 --> 2:27:27.720\n So chemotherapy just kills cells.\n\n2:27:27.720 --> 2:27:32.920\n Yeah. Well, chemotherapy hopes to kill more of the tumor cells than of your cells. That's\n\n2:27:32.920 --> 2:27:36.440\n it. It's a fine balance. The problem is the cells are very similar because they are your\n\n2:27:36.440 --> 2:27:43.480\n cells. And so if you don't have a very tight way of distinguishing between them, then the\n\n2:27:43.480 --> 2:27:46.240\n toll that chemo takes on the rest of the body is just unbelievable.\n\n2:27:46.240 --> 2:27:49.760\n And immunotherapy tries to get the immune system to do some of the work.\n\n2:27:49.760 --> 2:27:54.720\n Exactly. Yeah. I think that's potentially a very good, a very good approach. If, if\n\n2:27:54.720 --> 2:27:59.520\n the immune system can be taught to recognize enough of, of the cancer cells, that that's\n\n2:27:59.520 --> 2:28:02.720\n a pretty good approach. But I, but I think, but I think our approach is in a way more\n\n2:28:02.720 --> 2:28:08.440\n fundamental because if you can, if you can keep the cells harnessed towards organ level\n\n2:28:08.440 --> 2:28:13.900\n goals as opposed to individual cell goals, then nobody will be making a tumor or metastasizing\n\n2:28:13.900 --> 2:28:15.440\n and so on.\n\n2:28:15.440 --> 2:28:21.840\n So we've been living through a pandemic. What do you think about viruses in this full beautiful\n\n2:28:21.840 --> 2:28:30.080\n biological context we've been talking about? Are they beautiful to you? Are they terrifying?\n\n2:28:30.080 --> 2:28:36.800\n Also maybe let's say, are they, since we've been discriminating this whole conversation,\n\n2:28:36.800 --> 2:28:43.840\n are they living? Are they embodied minds? Embodied minds that are assholes?\n\n2:28:43.840 --> 2:28:47.200\n As far as I know, and I haven't been able to find this paper again, but, but somewhere\n\n2:28:47.200 --> 2:28:51.680\n I saw in the last couple of months, there was some, there was some papers showing an\n\n2:28:51.680 --> 2:28:55.360\n example of a virus that actually had physiology. So there was some, something was going on,\n\n2:28:55.360 --> 2:29:01.320\n I think proton flux or something on the virus itself. But, but barring that, generally speaking,\n\n2:29:01.320 --> 2:29:06.860\n viruses are very passive. They don't do anything by themselves. And so I don't see any particular\n\n2:29:06.860 --> 2:29:14.100\n reason to attribute much of a mind to them. I think, you know, they represent a way to\n\n2:29:14.100 --> 2:29:18.520\n hijack other minds for sure, like, like cells and other things.\n\n2:29:18.520 --> 2:29:24.300\n But that's an interesting interplay though. If they're hijacking other minds, you know,\n\n2:29:24.300 --> 2:29:28.420\n the way we're, we were talking about living organisms that they can interact with each\n\n2:29:28.420 --> 2:29:36.400\n other and have it alter each other's trajectory by having interacted. I mean, that's, that's\n\n2:29:36.400 --> 2:29:45.680\n a deep, meaningful connection between a virus and a cell. And I think both are transformed\n\n2:29:45.680 --> 2:29:49.040\n by the experience. And so in that sense, both are living.\n\n2:29:49.040 --> 2:29:56.320\n Yeah. Yeah. You know, the whole category, I, this question of what's living and what's\n\n2:29:56.320 --> 2:30:00.000\n not living, I really, I'm not sure. And I know there's people that work on this and\n\n2:30:00.000 --> 2:30:05.480\n I don't want to piss anybody off, but, but I have not found that particularly useful\n\n2:30:05.480 --> 2:30:11.480\n as, as to try and make that a binary kind of a distinction. I think level of cognition\n\n2:30:11.480 --> 2:30:17.080\n is very interesting of, but as a, as a continuum, but, but living and nonliving, I, you know,\n\n2:30:17.080 --> 2:30:20.680\n I don't, I really know what to do with that. I don't, I don't know what you do next after,\n\n2:30:20.680 --> 2:30:21.800\n after making that distinction.\n\n2:30:21.800 --> 2:30:27.640\n That's why I make the very binary distinction. Can I have sex with it or not? Can I eat it\n\n2:30:27.640 --> 2:30:30.360\n or not? Those, cause there's, those are actionable, right?\n\n2:30:30.360 --> 2:30:34.000\n Yeah. Well, I think that's a critical point that you brought up because how you relate\n\n2:30:34.000 --> 2:30:40.000\n to something is really what this is all about, right? As an engineer, how do I control it?\n\n2:30:40.000 --> 2:30:44.120\n But maybe I shouldn't be controlling it. Maybe I should be, you know, can I have a relationship\n\n2:30:44.120 --> 2:30:48.400\n with it? Should I be listening to its advice? Like, like all the way from, you know, I need\n\n2:30:48.400 --> 2:30:52.800\n to take it apart all the way to, I better do what it says cause it seems to be pretty\n\n2:30:52.800 --> 2:30:56.480\n smart and everything in between, right? That's really what we're asking about.\n\n2:30:56.480 --> 2:31:01.400\n Yeah. We need to understand our relationship to it. We're searching for that relationship,\n\n2:31:01.400 --> 2:31:08.200\n even in the most trivial senses. You came up with a lot of interesting terms. We've mentioned\n\n2:31:08.200 --> 2:31:14.560\n some of them. Agential material. That's a really interesting one. That's a really interesting\n\n2:31:14.560 --> 2:31:19.600\n one for the future of computation and artificial intelligence and computer science and all\n\n2:31:19.600 --> 2:31:25.940\n of that. There's also, let me go through some of them. If they spark some interesting thought\n\n2:31:25.940 --> 2:31:32.640\n for you, there's teleophobia, the unwarranted fear of erring on the side of too much agency\n\n2:31:32.640 --> 2:31:35.000\n when considering a new system.\n\n2:31:35.000 --> 2:31:36.000\n Yeah.\n\n2:31:36.000 --> 2:31:41.080\n That's the opposite. I mean, being afraid of maybe anthropomorphizing the thing.\n\n2:31:41.080 --> 2:31:47.120\n This'll get some people ticked off, I think. But I don't think, I think the whole notion\n\n2:31:47.120 --> 2:31:54.440\n of anthropomorphizing is a holdover from a pre scientific age where humans were magic\n\n2:31:54.440 --> 2:32:00.080\n and everything else wasn't magic and you were anthropomorphizing when you dared suggest\n\n2:32:00.080 --> 2:32:05.760\n that something else has some features of humans. And I think we need to be way beyond that.\n\n2:32:05.760 --> 2:32:12.640\n And this issue of anthropomorphizing, I think it's a cheap charge. I don't think it holds\n\n2:32:12.640 --> 2:32:18.240\n any water at all other than when somebody makes a cognitive claim. I think all cognitive\n\n2:32:18.240 --> 2:32:22.620\n claims are engineering claims, really. So when somebody says this thing knows or this\n\n2:32:22.620 --> 2:32:27.800\n thing hopes or this thing wants or this thing predicts, all you can say is fabulous. Give\n\n2:32:27.800 --> 2:32:33.420\n me the engineering protocol that you've derived using that hypothesis and we will see if this\n\n2:32:33.420 --> 2:32:36.760\n thing helps us or not. And then, and then we can, you know, then we can make a rational\n\n2:32:36.760 --> 2:32:37.760\n decision.\n\n2:32:37.760 --> 2:32:43.400\n I also like anatomical compiler, a future system representing the longterm end game\n\n2:32:43.400 --> 2:32:49.280\n of the science of morphogenesis that reminds us how far away from true understanding we\n\n2:32:49.280 --> 2:32:54.740\n are. Someday you will be able to sit in front of an anatomical computer, specify the shape\n\n2:32:54.740 --> 2:32:59.480\n of the animal or a plant that you want, and it will convert that shape specification to\n\n2:32:59.480 --> 2:33:05.160\n a set of stimuli that will have to be given to cells to build exactly that shape. No matter\n\n2:33:05.160 --> 2:33:12.560\n how weird it ends up being, you have total control. Just imagine the possibility for\n\n2:33:12.560 --> 2:33:18.780\n memes in the physical space. One of the glorious accomplishments of human civilizations is\n\n2:33:18.780 --> 2:33:25.840\n memes in digital space. Now this could create memes in physical space. I am both excited\n\n2:33:25.840 --> 2:33:31.800\n and terrified by that possibility. Cognitive light cone, I think we also talked about the\n\n2:33:31.800 --> 2:33:39.220\n outer boundary in space and time of the largest goal a given system can work towards. Is this\n\n2:33:39.220 --> 2:33:42.500\n kind of like shaping the set of options?\n\n2:33:42.500 --> 2:33:49.680\n It's a little different than options. It's really focused on... I first came up with\n\n2:33:49.680 --> 2:33:55.320\n this back in 2018, I want to say. There was a conference, a Templeton conference where\n\n2:33:55.320 --> 2:34:01.160\n they challenged us to come up with frameworks. I think actually it's the diverse intelligence\n\n2:34:01.160 --> 2:34:02.160\n community.\n\n2:34:02.160 --> 2:34:03.160\n Summer Institute.\n\n2:34:03.160 --> 2:34:04.160\n Yeah, they had a Summer Institute.\n\n2:34:04.160 --> 2:34:06.640\n That's the logos, the bee with some circuits.\n\n2:34:06.640 --> 2:34:13.360\n Yeah, it's got different life forms. The whole program is called diverse intelligence. They\n\n2:34:13.360 --> 2:34:18.240\n challenged us to come up with a framework that was suitable for analyzing different\n\n2:34:18.240 --> 2:34:23.000\n kinds of intelligence together. Because the kinds of things you do to a human are not\n\n2:34:23.000 --> 2:34:29.560\n good with an octopus, not good with a plant and so on. I started thinking about this.\n\n2:34:29.560 --> 2:34:35.560\n I asked myself what do all cognitive agents, no matter what their provenance, no matter\n\n2:34:35.560 --> 2:34:41.560\n what their architecture is, what do cognitive agents have in common? It seems to me that\n\n2:34:41.560 --> 2:34:46.480\n what they have in common is some degree of competency to pursue a goal. What you can\n\n2:34:46.480 --> 2:34:51.720\n do then is you can draw. What I ended up drawing was this thing that it's kind of like a backwards\n\n2:34:51.720 --> 2:34:58.520\n Minkowski cone diagram where all of space is collapsed into one axis and then here and\n\n2:34:58.520 --> 2:35:04.160\n then time is this axis. Then what you can do is you can draw for any creature, you can\n\n2:35:04.160 --> 2:35:12.360\n semi quantitatively estimate what are the spatial and temporal goals that it's capable\n\n2:35:12.360 --> 2:35:13.360\n of pursuing.\n\n2:35:13.360 --> 2:35:20.240\n For example, if you are a tick and all you really are able to pursue is maximum or a\n\n2:35:20.240 --> 2:35:24.800\n bacterium and maximizing the level of some chemical in your vicinity, that's all you've\n\n2:35:24.800 --> 2:35:29.440\n got, it's a tiny little icon, then you're a simple system like a tick or a bacterium.\n\n2:35:29.440 --> 2:35:37.520\n If you are something like a dog, well, you've got some ability to care about some spatial\n\n2:35:37.520 --> 2:35:41.680\n region, some temporal. You can remember a little bit backwards, you can predict a little\n\n2:35:41.680 --> 2:35:46.280\n bit forwards, but you're never ever going to care about what happens in the next town\n\n2:35:46.280 --> 2:35:51.680\n over four weeks from now. As far as we know, it's just impossible for that kind of architecture.\n\n2:35:51.680 --> 2:35:56.580\n If you're a human, you might be working towards world peace long after you're dead. You might\n\n2:35:56.580 --> 2:36:04.120\n have a planetary scale goal that's enormous. Then there may be other greater intelligences\n\n2:36:04.120 --> 2:36:08.800\n somewhere that can care in the linear range about numbers of creatures, some sort of Buddha\n\n2:36:08.800 --> 2:36:16.040\n like character that can care about everybody's welfare, really care the way that we can't.\n\n2:36:16.040 --> 2:36:20.640\n It's not a mapping of what you can sense, how far you can sense. It's not a mapping\n\n2:36:20.640 --> 2:36:25.720\n of how far you can act. It's a mapping of how big are the goals you are capable of envisioning\n\n2:36:25.720 --> 2:36:33.880\n and working towards. I think that enables you to put synthetic kinds of constructs,\n\n2:36:33.880 --> 2:36:40.120\n AIs, aliens, swarms, whatever on the same diagram because we're not talking about what\n\n2:36:40.120 --> 2:36:44.720\n you're made of or how you got here. We're talking about what are the size and complexity\n\n2:36:44.720 --> 2:36:46.760\n of the goals towards which you can work.\n\n2:36:46.760 --> 2:36:50.760\n Is there any other terms that pop into mind that are interesting?\n\n2:36:50.760 --> 2:36:54.200\n I'm trying to remember. I have a list of them somewhere on my website.\n\n2:36:54.200 --> 2:37:01.840\n Human morphology, yeah, definitely check it out. Morphosutical, I like that one. Ionisutical.\n\n2:37:01.840 --> 2:37:08.600\n Yeah. Those refer to different types of interventions in the regenerative medicine space. Amorphosutical\n\n2:37:08.600 --> 2:37:16.200\n is something that it's a kind of intervention that really targets the cells decision making\n\n2:37:16.200 --> 2:37:20.640\n process about what they're going to build. Ionisuticals are like that, but more focused\n\n2:37:20.640 --> 2:37:24.200\n specifically on the bioelectrics. There's also, of course, biochemical, biomechanical,\n\n2:37:24.200 --> 2:37:29.160\n who knows what else, maybe optical kinds of signaling systems there as well.\n\n2:37:29.160 --> 2:37:37.920\n Target morphology is interesting. It's designed to capture this idea that it's not just feedforward\n\n2:37:37.920 --> 2:37:41.980\n emergence and oftentimes in biology, I mean, of course that happens too, but in many cases\n\n2:37:41.980 --> 2:37:48.440\n in biology, the system is specifically working towards a target in anatomical morphospace.\n\n2:37:48.440 --> 2:37:57.200\n It's a navigation task really. These kinds of problem solving can be formalized as navigation\n\n2:37:57.200 --> 2:38:00.920\n tasks and that they're really going towards a particular region. How do you know? Because\n\n2:38:00.920 --> 2:38:03.720\n you deviate them and then they go back.\n\n2:38:03.720 --> 2:38:12.160\n Let me ask you, because you've really challenged a lot of ideas in biology in the work you\n\n2:38:12.160 --> 2:38:18.160\n do, probably because some of your rebelliousness comes from the fact that you came from a different\n\n2:38:18.160 --> 2:38:23.800\n field of computer engineering, but could you give advice to young people today in high\n\n2:38:23.800 --> 2:38:31.600\n school or college that are trying to pave their life story, whether it's in science\n\n2:38:31.600 --> 2:38:36.440\n or elsewhere, how they can have a career they can be proud of or a life they can be proud\n\n2:38:36.440 --> 2:38:37.440\n of advice?\n\n2:38:37.440 --> 2:38:42.320\n Boy, it's dangerous to give advice because things change so fast, but one central thing\n\n2:38:42.320 --> 2:38:47.880\n I can say, moving up and through academia and whatnot, you will be surrounded by really\n\n2:38:47.880 --> 2:38:56.280\n smart people. What you need to do is be very careful at distinguishing specific critique\n\n2:38:56.280 --> 2:39:03.840\n versus kind of meta advice. What I mean by that is if somebody really smart and successful\n\n2:39:03.840 --> 2:39:11.400\n and obviously competent is giving you specific critiques on what you've done, that's gold.\n\n2:39:11.400 --> 2:39:15.200\n It's an opportunity to hone your craft, to get better at what you're doing, to learn,\n\n2:39:15.200 --> 2:39:17.520\n to find your mistakes. That's great.\n\n2:39:17.520 --> 2:39:23.080\n If they are telling you what you ought to be studying, how you ought to approach things,\n\n2:39:23.080 --> 2:39:28.880\n what is the right way to think about things, you should probably ignore most of that. The\n\n2:39:28.880 --> 2:39:36.200\n reason I make that distinction is that a lot of really successful people are very well\n\n2:39:36.200 --> 2:39:43.080\n calibrated on their own ideas and their own field and their own area. They know exactly\n\n2:39:43.080 --> 2:39:46.460\n what works and what doesn't and what's good and what's bad, but they're not calibrated\n\n2:39:46.460 --> 2:39:53.040\n on your ideas. The things they will say, oh, this is a dumb idea, don't do this and you\n\n2:39:53.040 --> 2:40:01.940\n shouldn't do that, that stuff is generally worse than useless. It can be very demoralizing\n\n2:40:01.940 --> 2:40:09.080\n and really limiting. What I say to people is read very broadly, work really hard, know\n\n2:40:09.080 --> 2:40:14.220\n what you're talking about, take all specific criticism as an opportunity to improve what\n\n2:40:14.220 --> 2:40:21.800\n you're doing and then completely ignore everything else. I just tell you from my own experience,\n\n2:40:21.800 --> 2:40:26.280\n most of what I consider to be interesting and useful things that we've done, very smart\n\n2:40:26.280 --> 2:40:32.960\n people have said, this is a terrible idea, don't do that. I think we just don't know.\n\n2:40:32.960 --> 2:40:37.720\n We have no idea beyond our own. At best, we know what we ought to be doing. We very rarely\n\n2:40:37.720 --> 2:40:39.320\n know what anybody else should be doing.\n\n2:40:39.320 --> 2:40:45.240\n Yeah, and their ideas, their perspective has been also calibrated, not just on their field\n\n2:40:45.240 --> 2:40:51.520\n and specific situation, but also on a state of that field at a particular time in the\n\n2:40:51.520 --> 2:40:57.880\n past. There's not many people in this world that are able to achieve revolutionary success\n\n2:40:57.880 --> 2:41:02.680\n multiple times in their life. Whenever you say somebody very smart, usually what that\n\n2:41:02.680 --> 2:41:09.120\n means is somebody who's smart, who achieved a success at a certain point in their life\n\n2:41:09.120 --> 2:41:14.720\n and people often get stuck in that place where they found success. To be constantly challenging\n\n2:41:14.720 --> 2:41:23.240\n your worldview is a very difficult thing. Also at the same time, probably if a lot of\n\n2:41:23.240 --> 2:41:29.480\n people tell, that's the weird thing about life, if a lot of people tell you that something\n\n2:41:29.480 --> 2:41:36.160\n is stupid or is not going to work, that either means it's stupid, it's not going to work,\n\n2:41:36.160 --> 2:41:42.680\n or it's actually a great opportunity to do something new and you don't know which one\n\n2:41:42.680 --> 2:41:49.920\n it is and it's probably equally likely to be either. Well, I don't know, the probabilities.\n\n2:41:49.920 --> 2:41:53.400\n Depends how lucky you are, depends how brilliant you are, but you don't know and so you can't\n\n2:41:53.400 --> 2:41:55.680\n take that advice as actual data.\n\n2:41:55.680 --> 2:42:03.920\n Yeah, you have to and this is kind of hard to describe and fuzzy, but I'm a firm believer\n\n2:42:03.920 --> 2:42:09.160\n that you have to build up your own intuition. So over time, you have to take your own risks\n\n2:42:09.160 --> 2:42:13.580\n that seem like they make sense to you and then learn from that and build up so that\n\n2:42:13.580 --> 2:42:18.120\n you can trust your own gut about what's a good idea even when, and then sometimes you'll\n\n2:42:18.120 --> 2:42:21.560\n make mistakes and they'll turn out to be a dead end and that's fine, that's science,\n\n2:42:21.560 --> 2:42:28.560\n but what I tell my students is life is hard and science is hard and you're going to sweat\n\n2:42:28.560 --> 2:42:34.880\n and bleed and everything and you should be doing that for ideas that really fire you\n\n2:42:34.880 --> 2:42:44.940\n up inside and really don't let kind of the common denominator of standardized approaches\n\n2:42:44.940 --> 2:42:46.800\n to things slow you down.\n\n2:42:46.800 --> 2:42:53.480\n So you mentioned planaria being in some sense immortal. What's the role of death in life?\n\n2:42:53.480 --> 2:42:58.760\n What's the role of death in this whole process we have? Is it, when you look at biological\n\n2:42:58.760 --> 2:43:08.000\n systems, is death an important feature, especially as you climb up the hierarchy of competency?\n\n2:43:08.000 --> 2:43:17.320\n Boy, that's an interesting question. I think that it's certainly a factor that promotes\n\n2:43:17.320 --> 2:43:24.520\n change and turnover and an opportunity to do something different the next time for a\n\n2:43:24.520 --> 2:43:29.520\n larger scale system. So apoptosis, it's really interesting. I mean, death is really interesting\n\n2:43:29.520 --> 2:43:33.040\n in a number of ways. One is like you could think about like what was the first thing\n\n2:43:33.040 --> 2:43:37.420\n to die? That's an interesting question. What was the first creature that you could say\n\n2:43:37.420 --> 2:43:42.880\n actually died? It's a tough thing because we don't have a great definition for it. So\n\n2:43:42.880 --> 2:43:48.480\n if you bring a cabbage home and you put it in your fridge, at what point are you going\n\n2:43:48.480 --> 2:43:58.880\n to say it's died, right? So it's kind of hard to know. There's one paper in which I talk\n\n2:43:58.880 --> 2:44:04.960\n about this idea that, I mean, think about this and imagine that you have a creature\n\n2:44:04.960 --> 2:44:11.680\n that's aquatic, let's say it's a frog or something or a tadpole, and the animal dies,\n\n2:44:11.680 --> 2:44:17.600\n in the pond it dies for whatever reason. Most of the cells are still alive. So you could\n\n2:44:17.600 --> 2:44:23.200\n imagine that if when it died, there was some sort of breakdown of the connectivity between\n\n2:44:23.200 --> 2:44:28.760\n the cells, a bunch of cells crawled off, they could have a life as amoebas. Some of them\n\n2:44:28.760 --> 2:44:33.780\n could join together and become a xenobot and twiddle around, right? So we know from planaria\n\n2:44:33.780 --> 2:44:37.800\n that there are cells that don't obey the Hayflick limit and just sort of live forever. So you\n\n2:44:37.800 --> 2:44:42.400\n could imagine an organism that when the organism dies, it doesn't disappear, rather the individual\n\n2:44:42.400 --> 2:44:46.280\n cells that are still alive, crawl off and have a completely different kind of lifestyle\n\n2:44:46.280 --> 2:44:50.080\n and maybe come back together as something else, or maybe they don't. So all of this,\n\n2:44:50.080 --> 2:44:57.080\n I'm sure, is happening somewhere on some planet. So death in any case, I mean, we already kind\n\n2:44:57.080 --> 2:45:00.640\n of knew this because the molecules, we know that when something dies, the molecules go\n\n2:45:00.640 --> 2:45:05.200\n through the ecosystem, but even the cells don't necessarily die at that point, they\n\n2:45:05.200 --> 2:45:09.720\n might have another life in a different way. You can think about something like HeLa, right?\n\n2:45:09.720 --> 2:45:14.400\n The HeLa cell line, you know, that has this, that's had this incredible life. There are\n\n2:45:14.400 --> 2:45:18.040\n way more HeLa cells now than there ever been, than there, than there were when, when she\n\n2:45:18.040 --> 2:45:19.040\n was alive.\n\n2:45:19.040 --> 2:45:22.240\n It seems like as the organisms become more and more complex, like if you look at the\n\n2:45:22.240 --> 2:45:29.800\n mammals, their relationship with death becomes more and more complex. So the survival imperative\n\n2:45:29.800 --> 2:45:37.400\n starts becoming interesting and humans are arguably the first species that have invented\n\n2:45:37.400 --> 2:45:43.120\n the fear of death. The understanding that you're going to die, let's put it this way,\n\n2:45:43.120 --> 2:45:49.560\n like long, so not like instinctual, like, I need to run away from the thing that's going\n\n2:45:49.560 --> 2:45:53.960\n to eat me, but starting to contemplate the finiteness of life.\n\n2:45:53.960 --> 2:45:59.400\n Yeah. I mean, one thing, so, so one thing about the human light, cognitive light cone\n\n2:45:59.400 --> 2:46:04.200\n is that for the first, as far as we know, for the first time, you might have goals that\n\n2:46:04.200 --> 2:46:08.160\n are longer than your lifespan, that are not achievable, right? So if you're, if you are,\n\n2:46:08.160 --> 2:46:11.800\n let's say, and I don't know if this is true, but if you're a goldfish and you have a 10\n\n2:46:11.800 --> 2:46:14.760\n minute attention span, I'm not sure if that's true, but let's say, let's say there's some\n\n2:46:14.760 --> 2:46:20.260\n organism with a, with a short kind of cognitive light cone that way, all of your goals are\n\n2:46:20.260 --> 2:46:23.560\n potentially achievable because you're probably going to live the next 10 minutes. So whatever\n\n2:46:23.560 --> 2:46:27.440\n goals you have, they are totally achievable. If you're a human, you could have all kinds\n\n2:46:27.440 --> 2:46:31.240\n of goals that are guaranteed not achievable because they just take too long, like guaranteed\n\n2:46:31.240 --> 2:46:35.840\n you're not going to achieve them. So I wonder if, you know, is that, is that a, you know,\n\n2:46:35.840 --> 2:46:39.920\n like a perennial, you know, sort of thorn in our, in our psychology that drives some,\n\n2:46:39.920 --> 2:46:43.920\n some psychosis or whatever? I have, I have no idea. Another interesting thing about that,\n\n2:46:43.920 --> 2:46:47.720\n actually, I've been thinking about this a lot in the last couple of weeks, this notion\n\n2:46:47.720 --> 2:46:58.480\n of giving up. So you would think that evolutionarily, the most adaptive way of being is that you\n\n2:46:58.480 --> 2:47:02.960\n go, you, you, you, you fight as long as you physically can. And then when you can't, you\n\n2:47:02.960 --> 2:47:06.680\n can't, and there's in, there's this photograph, there's videos you can find of insects are\n\n2:47:06.680 --> 2:47:10.000\n crawling around where like, you know, like, like most of it is already gone, and it's\n\n2:47:10.000 --> 2:47:15.240\n still sort of crawling, you know, like, Terminator style, right? Like, as far as as long as you\n\n2:47:15.240 --> 2:47:20.320\n physically can, you keep going. Mammals don't do that. So a lot of mammals, including rats,\n\n2:47:20.320 --> 2:47:25.780\n have this thing where when, when they think it's a hopeless situation, they literally\n\n2:47:25.780 --> 2:47:29.060\n give up and die when physically, they could have kept going. I mean, humans certainly\n\n2:47:29.060 --> 2:47:33.320\n do this. And there's, there's some like, really unpleasant experiments that the this guy forget\n\n2:47:33.320 --> 2:47:37.960\n his name did with drowning rats, where if he where where rats normally drown after a\n\n2:47:37.960 --> 2:47:41.480\n couple of minutes, but if you teach them that if you just tread water for a couple of minutes,\n\n2:47:41.480 --> 2:47:45.360\n you'll get rescued, they can tread water for like an hour. And so right, and so they literally\n\n2:47:45.360 --> 2:47:49.920\n just give up and die. And so evolutionarily, that doesn't seem like a good strategy at\n\n2:47:49.920 --> 2:47:53.320\n all evolutionarily, since why would you like, what's the benefit ever of giving up, you\n\n2:47:53.320 --> 2:47:57.400\n just do what you can, and you know, one time out of 1000, you'll actually get rescued, right?\n\n2:47:57.400 --> 2:48:03.080\n But this issue of actually giving up suggests some very interesting metacognitive controls\n\n2:48:03.080 --> 2:48:08.080\n where you've now gotten to the point where survival actually isn't the top drive. And\n\n2:48:08.080 --> 2:48:11.560\n that for whatever, you know, there are other considerations that have like taken over.\n\n2:48:11.560 --> 2:48:15.560\n And I think that's uniquely a mammalian thing. But then I don't know.\n\n2:48:15.560 --> 2:48:23.080\n Yeah, the Camus, the existentialist question of why live, just the fact that humans commit\n\n2:48:23.080 --> 2:48:27.880\n suicide is a really fascinating question from an evolutionary perspective.\n\n2:48:27.880 --> 2:48:33.360\n And what was the first and that's the other thing, like, what is the simplest system,\n\n2:48:33.360 --> 2:48:38.760\n whether whether evolved or natural or whatever, that is able to do that? Right? Like, you\n\n2:48:38.760 --> 2:48:42.440\n can think, you know, what other animals are actually able to do that? I'm not sure.\n\n2:48:42.440 --> 2:48:49.760\n Maybe you could see animals over time, for some reason, lowering the value of survive\n\n2:48:49.760 --> 2:48:55.560\n at all costs, gradually, until other objectives might become more important.\n\n2:48:55.560 --> 2:48:59.320\n Maybe. I don't know how evolutionarily how that how that gets off the ground. That just\n\n2:48:59.320 --> 2:49:06.600\n seems like that would have such a strong pressure against it, you know. Just imagine, you know,\n\n2:49:06.600 --> 2:49:13.240\n a population with a lower, you know, if you were a mutant in a population that had less\n\n2:49:13.240 --> 2:49:19.200\n of a less of a survival imperative, would you put your genes outperform the others?\n\n2:49:19.200 --> 2:49:26.440\n Is there such a thing as population selection? Because maybe suicide is a way for organisms\n\n2:49:26.440 --> 2:49:31.840\n to decide themselves that they're not fit for the environment? Somehow?\n\n2:49:31.840 --> 2:49:36.660\n Yeah, that's a that's a really contrary, you know, population level selection is a kind\n\n2:49:36.660 --> 2:49:42.840\n of a deep controversial area. But it's tough because on the face of it, if that was your\n\n2:49:42.840 --> 2:49:47.040\n genome, it wouldn't get propagated because you would die and then your neighbor who didn't\n\n2:49:47.040 --> 2:49:49.040\n have that would would have all the kids.\n\n2:49:49.040 --> 2:49:55.140\n It feels like there could be some deep truth there that we're not understanding. What about\n\n2:49:55.140 --> 2:49:59.300\n you yourself as one biological system? Are you afraid of death?\n\n2:49:59.300 --> 2:50:05.820\n To be honest, I'm more concerned with especially now getting older and having helped a couple\n\n2:50:05.820 --> 2:50:14.880\n of people pass. I think about what's a what's a good way to go? Basically, like nowadays,\n\n2:50:14.880 --> 2:50:19.160\n I don't know what that is, I, you know, sitting in a, you know, a facility that sort of tries\n\n2:50:19.160 --> 2:50:24.840\n to stretch you out as long as you can, that doesn't seem that doesn't seem good. And there's\n\n2:50:24.840 --> 2:50:29.400\n not a lot of opportunities to sort of, I don't know, sacrifice yourself for something useful,\n\n2:50:29.400 --> 2:50:33.640\n right? There's not terribly many opportunities for that in modern society. So I don't know,\n\n2:50:33.640 --> 2:50:38.040\n that's that's that's more of I'm not I'm not particularly worried about death itself.\n\n2:50:38.040 --> 2:50:46.380\n But I've seen it happen. And and it's not it's not pretty. And I don't know what what\n\n2:50:46.380 --> 2:50:48.080\n a better what a better alternative is.\n\n2:50:48.080 --> 2:50:56.360\n So the existential aspect of it does not worry you deeply? The fact that this ride ends?\n\n2:50:56.360 --> 2:51:01.340\n No, it began. I mean, the ride began, right? So there was I don't know how many billions\n\n2:51:01.340 --> 2:51:04.740\n of years before that I wasn't around. So that's okay.\n\n2:51:04.740 --> 2:51:10.520\n But isn't the experience of life? It's almost like feels like you're immortal. Because the\n\n2:51:10.520 --> 2:51:15.720\n way you make plans, the way you think about the future. I mean, if you if you look at\n\n2:51:15.720 --> 2:51:22.360\n your own personal rich experience, yes, you can understand, okay, eventually, I died as\n\n2:51:22.360 --> 2:51:28.960\n people I love that have died. So surely, I will die and it hurts and so on. But like,\n\n2:51:28.960 --> 2:51:34.240\n he sure doesn't. It's so easy to get lost in feeling like this is going to go on forever.\n\n2:51:34.240 --> 2:51:37.320\n Yeah, it's a little bit like the people who say they don't believe in free will, right?\n\n2:51:37.320 --> 2:51:41.680\n I mean, you can say that but but when you go to a restaurant, you still have to pick\n\n2:51:41.680 --> 2:51:46.080\n a soup and stuff. So right, so so I don't know if I know I've actually seen that that\n\n2:51:46.080 --> 2:51:49.920\n happened at lunch with a with a well known philosopher and he didn't believe in free\n\n2:51:49.920 --> 2:51:53.600\n will and the other waitress came around and he was like, Well, let me see. I was like,\n\n2:51:53.600 --> 2:51:58.200\n What are you doing here? You're gonna choose a sandwich, right? So it's I think it's one\n\n2:51:58.200 --> 2:52:02.100\n of those things. I think you can know that, you know, you're not going to live forever.\n\n2:52:02.100 --> 2:52:07.100\n But you can't you can't. It's not practical to live that way unless you know, so you buy\n\n2:52:07.100 --> 2:52:11.920\n insurance and then you do some stuff like that. But but but mostly, you know, I think\n\n2:52:11.920 --> 2:52:17.440\n you just you just live as if as if as if you can make plans.\n\n2:52:17.440 --> 2:52:22.520\n We talked about all kinds of life. We talked about all kinds of embodied minds. What do\n\n2:52:22.520 --> 2:52:28.000\n you think is the meaning of it all? What's the meaning of all the biological lives we've\n\n2:52:28.000 --> 2:52:33.280\n been talking about here on Earth? Why are we here?\n\n2:52:33.280 --> 2:52:38.920\n I don't know that that's a that that's a well posed question other than the existential\n\n2:52:38.920 --> 2:52:40.900\n question you post before.\n\n2:52:40.900 --> 2:52:47.000\n Is that question hanging out with the question of what is consciousness and there at retreat\n\n2:52:47.000 --> 2:52:55.280\n somewhere? Not sure because sipping pina coladas and because they're ambiguously defined.\n\n2:52:55.280 --> 2:53:01.660\n Maybe I'm not sure that any of these things really ride on the correctness of our scientific\n\n2:53:01.660 --> 2:53:06.740\n understanding. But I mean, just just for an example, right? I've always found I've always\n\n2:53:06.740 --> 2:53:16.760\n found it weird that people get really worked up to find out realities about their their\n\n2:53:16.760 --> 2:53:22.820\n bodies, for example. Right. You've seen them. Ex Machina. Right. And so there's this great\n\n2:53:22.820 --> 2:53:26.120\n scene where he's cutting his hand to find out, you know, a piece full of cock. Now,\n\n2:53:26.120 --> 2:53:31.880\n to me, right? If if I open up and I find out and I find a bunch of cogs, my conclusion\n\n2:53:31.880 --> 2:53:37.360\n is not, oh, crap, I must not have true cognition. That sucks. My conclusion is, wow, cogs can\n\n2:53:37.360 --> 2:53:42.840\n have true cognition. Great. So right. So. So it seems to me, I guess I guess I'm with\n\n2:53:42.840 --> 2:53:48.240\n Descartes on this one, that whatever whatever the truth ends up being of of of how is what\n\n2:53:48.240 --> 2:53:53.080\n is consciousness, how it can be conscious? None of that is going to alter my primary\n\n2:53:53.080 --> 2:53:56.600\n experience, which is this is what it is. And if and if a bunch of molecular networks can\n\n2:53:56.600 --> 2:54:03.300\n do it, fantastic. If it turns out that there's a there's a non corporeal, you know, so great.\n\n2:54:03.300 --> 2:54:09.200\n We can we'll study that, whatever. But but the fundamental existential aspect of it is,\n\n2:54:09.200 --> 2:54:13.400\n you know, if somebody if somebody told me today that, yeah, yeah, you were created yesterday\n\n2:54:13.400 --> 2:54:18.280\n and all your memories are, you know, sort of fake, you know, kind of like like like Boltzmann\n\n2:54:18.280 --> 2:54:23.280\n brains, right. And the human, you know, human skepticism, all that. Yeah. OK. Well, so so\n\n2:54:23.280 --> 2:54:31.280\n but but here I am now. So so it's the experience. It's primal, so like that's the that's the\n\n2:54:31.280 --> 2:54:36.300\n thing that matters. So the the backstory doesn't matter. I think so. I think so. From a first\n\n2:54:36.300 --> 2:54:39.600\n person perspective, now from a third person, like scientifically, it's all very interesting.\n\n2:54:39.600 --> 2:54:43.760\n From a third person perspective, I could say, wow, that's that's amazing that that this\n\n2:54:43.760 --> 2:54:48.000\n happens and how does it happen and whatever. But from a first person perspective, I could\n\n2:54:48.000 --> 2:54:52.020\n care less. Like I just it's just what I've what I learned from any of these scientific\n\n2:54:52.020 --> 2:54:57.160\n facts is, OK, well, I guess then that's that that then I guess that's what is sufficient\n\n2:54:57.160 --> 2:55:01.820\n to to give me my, you know, amazing first person perspective. I think if you dig deeper\n\n2:55:01.820 --> 2:55:10.100\n and deeper and get a get surprising answers to why the hell we're here, it might give\n\n2:55:10.100 --> 2:55:18.680\n you some guidance on how to live. Maybe, maybe. I don't know. That would be nice. On the one\n\n2:55:18.680 --> 2:55:23.240\n hand, you might be right, because on the one hand, if I don't know what else could possibly\n\n2:55:23.240 --> 2:55:26.240\n give you that guidance. Right. So so you would think that it would have to be that or you\n\n2:55:26.240 --> 2:55:30.400\n would do it would have to be science because there isn't anything else. So so that's so\n\n2:55:30.400 --> 2:55:36.680\n maybe on the other hand, I am really not sure how you go from any, you know, what they call\n\n2:55:36.680 --> 2:55:41.120\n from an is to an odd right from any factual description of what's going on. This goes\n\n2:55:41.120 --> 2:55:44.920\n back to the natural. Right. Just because somebody says, oh, man, that's that's completely not\n\n2:55:44.920 --> 2:55:50.000\n natural. It's never happened on Earth before. I'm not impressed by that whatsoever. I think\n\n2:55:50.000 --> 2:55:56.280\n I think whatever hazard hasn't happened, we are now in a position to do better if we can.\n\n2:55:56.280 --> 2:56:03.680\n Right. Well, this also because you said there's science and there's nothing else. There it's\n\n2:56:03.680 --> 2:56:12.000\n it's really tricky to know how to intellectually deal with a thing that science doesn't currently\n\n2:56:12.000 --> 2:56:22.880\n understand. Right. So like, the thing is, if you believe that science solves everything,\n\n2:56:22.880 --> 2:56:30.280\n you can too easily in your mind think our current understanding, like, we've solved\n\n2:56:30.280 --> 2:56:36.120\n everything. Right. Right. Right. Like, it jumps really quickly to not science as a mechanism\n\n2:56:36.120 --> 2:56:43.000\n as a as a process, but more like science of today. Like, you could just look at human\n\n2:56:43.000 --> 2:56:48.640\n history and throughout human history, just physicists and everybody would claim we've\n\n2:56:48.640 --> 2:56:53.240\n solved everything. Sure. Sure. Like, like, there's a few small things to figure out.\n\n2:56:53.240 --> 2:56:58.480\n And we basically solved everything. Were in reality, I think asking, like, what is the\n\n2:56:58.480 --> 2:57:08.120\n meaning of life is resetting the palette of like, we might be tiny and confused and don't\n\n2:57:08.120 --> 2:57:12.800\n have anything figured out. It's almost going to be hilarious a few centuries from now when\n\n2:57:12.800 --> 2:57:21.480\n they look back how dumb we were. Yeah, I 100% agree. So when I say science and nothing else,\n\n2:57:21.480 --> 2:57:27.640\n I certainly don't mean the science of today because I think overall, I think we are we\n\n2:57:27.640 --> 2:57:32.400\n know very little. I think most of the things that we're sure of now are going to be, as\n\n2:57:32.400 --> 2:57:36.280\n you said, are going to look hilarious down the line. So I think we're just at the beginning\n\n2:57:36.280 --> 2:57:42.320\n of a lot of really important things. When I say nothing but science, I also include\n\n2:57:42.320 --> 2:57:48.000\n the kind of first person, what I call science that you do. So the interesting thing about\n\n2:57:48.000 --> 2:57:52.120\n I think about consciousness and studying consciousness and things like that in the first person is\n\n2:57:52.120 --> 2:57:57.760\n unlike doing science in the third person, where you as the scientist are minimally changed\n\n2:57:57.760 --> 2:58:01.360\n by it, maybe not at all. So when I do an experiment, I'm still me, there's the experiment, whatever\n\n2:58:01.360 --> 2:58:04.900\n I've done, I've learned something, so that's a small change. But but overall, that's it.\n\n2:58:04.900 --> 2:58:10.640\n In order to really study consciousness, you will you are part of the experiment, you will\n\n2:58:10.640 --> 2:58:13.920\n be altered by that experiment, right? Whatever, whatever it is that you're doing, whether\n\n2:58:13.920 --> 2:58:22.120\n it's some sort of contemplative practice or, or some sort of psychoactive, you know, whatever.\n\n2:58:22.120 --> 2:58:26.160\n You are now you are now your own experiment, and you are right. And so I consider I fold\n\n2:58:26.160 --> 2:58:29.960\n that in, I think that's that's part of it. I think that exploring our own mind and our\n\n2:58:29.960 --> 2:58:34.680\n own consciousness is very important. I think much of it is not captured by what currently\n\n2:58:34.680 --> 2:58:41.520\n is third person science for sure. But ultimately, I include all of that in science, with a capital\n\n2:58:41.520 --> 2:58:48.800\n S in terms of like a, a rational investigation of both first and third person aspects of\n\n2:58:48.800 --> 2:58:50.300\n our world.\n\n2:58:50.300 --> 2:58:57.960\n We are our own experiment, as beautifully put. And when when two systems get to interact\n\n2:58:57.960 --> 2:59:03.780\n with each other, that's the kind of experiment. So I'm deeply honored that you would do this\n\n2:59:03.780 --> 2:59:07.760\n experiment with me today. Thanks so much. I'm a huge fan of your work. Likewise, thank\n\n2:59:07.760 --> 2:59:13.800\n you for doing everything you're doing. I can't wait to see the kind of incredible things\n\n2:59:13.800 --> 2:59:18.200\n you build. So thank you for talking. Really appreciate being here. Thank you.\n\n2:59:18.200 --> 2:59:22.200\n Thank you for listening to this conversation with Michael Levin. To support this podcast,\n\n2:59:22.200 --> 2:59:26.760\n please check out our sponsors in the description. And now let me leave you with some words from\n\n2:59:26.760 --> 2:59:35.760\n Charles Darwin in The Origin of Species. From the war of nature, from famine and death,\n\n2:59:35.760 --> 2:59:41.000\n the most exalted object which we're capable of conceiving, namely, the production of the\n\n2:59:41.000 --> 2:59:47.600\n higher animals directly follows. There's grandeur in this view of life, with its several\n\n2:59:47.600 --> 2:59:54.880\n powers having been originally breathed into a few forms, or into one, and that whilst\n\n2:59:54.880 --> 2:59:59.840\n this planet has gone cycling on according to the fixed laws of gravity, from its most\n\n2:59:59.840 --> 3:00:06.880\n simpler beginning, endless forms, most beautiful and most wonderful, have been and are being\n\n3:00:06.880 --> 3:00:25.480\n evolved. Thank you for listening, and hope to see you next time.\n\n"
}
{
  "title": "Alex Garland: Ex Machina, Devs, Annihilation, and the Poetry of Science | Lex Fridman Podcast #77",
  "id": "gU-mkuMU428",
  "transcript": "WEBVTT\n\n00:00.140 --> 00:03.360\n The following is a conversation with Alex Garland,\n\n00:03.360 --> 00:06.400\n writer and director of many imaginative\n\n00:06.400 --> 00:09.760\n and philosophical films from the dreamlike exploration\n\n00:09.760 --> 00:12.720\n of human self destruction in the movie Annihilation\n\n00:12.720 --> 00:16.440\n to the deep questions of consciousness and intelligence\n\n00:16.440 --> 00:18.600\n raised in the movie Ex Machina,\n\n00:18.600 --> 00:21.080\n which to me is one of the greatest movies\n\n00:21.080 --> 00:23.880\n in artificial intelligence ever made.\n\n00:23.880 --> 00:25.820\n I'm releasing this podcast to coincide\n\n00:25.820 --> 00:28.600\n with the release of this new series called Devs\n\n00:28.600 --> 00:32.560\n that will premiere this Thursday, March 5th on Hulu\n\n00:32.560 --> 00:34.740\n as part of FX on Hulu.\n\n00:35.640 --> 00:39.320\n It explores many of the themes this very podcast is about,\n\n00:39.320 --> 00:43.480\n from quantum mechanics to artificial life to simulation\n\n00:43.480 --> 00:46.520\n to the modern nature of power in the tech world.\n\n00:47.400 --> 00:50.360\n I got a chance to watch a preview and loved it.\n\n00:50.360 --> 00:52.080\n The acting is great.\n\n00:52.080 --> 00:55.400\n Nick Offerman especially is incredible in it.\n\n00:55.400 --> 00:58.040\n The cinematography is beautiful\n\n00:58.040 --> 00:59.960\n and the philosophical and scientific ideas\n\n00:59.960 --> 01:02.060\n explored are profound.\n\n01:02.060 --> 01:04.480\n And for me as an engineer and scientist,\n\n01:04.480 --> 01:07.280\n which is fun to see brought to life.\n\n01:07.280 --> 01:09.040\n For example, if you watch the trailer\n\n01:09.040 --> 01:10.560\n for the series carefully,\n\n01:10.560 --> 01:13.160\n you'll see there's a programmer with a Russian accent\n\n01:13.160 --> 01:16.180\n looking at a screen with Python like code on it\n\n01:16.180 --> 01:18.160\n that appears to be using a library\n\n01:18.160 --> 01:20.260\n that interfaces with a quantum computer.\n\n01:21.120 --> 01:23.000\n This attention and technical detail\n\n01:23.000 --> 01:25.560\n on several levels is impressive.\n\n01:25.560 --> 01:27.440\n And one of the reasons I'm a big fan\n\n01:27.440 --> 01:30.100\n of how Alex weaves science and philosophy together\n\n01:30.100 --> 01:30.940\n in his work.\n\n01:31.960 --> 01:35.120\n Meeting Alex for me was unlikely,\n\n01:35.120 --> 01:36.760\n but it was life changing\n\n01:36.760 --> 01:40.200\n in ways I may only be able to articulate in a few years.\n\n01:41.220 --> 01:43.640\n Just as meeting spot many of Boston Dynamics\n\n01:43.640 --> 01:47.840\n for the first time planted a seed of an idea in my mind,\n\n01:47.840 --> 01:50.200\n so did meeting Alex Garland.\n\n01:50.200 --> 01:52.840\n He's humble, curious, intelligent,\n\n01:52.840 --> 01:55.340\n and to me an inspiration.\n\n01:55.340 --> 01:58.000\n Plus, he's just really a fun person to talk with\n\n01:58.000 --> 02:01.340\n about the biggest possible questions in our universe.\n\n02:02.220 --> 02:05.120\n This is the Artificial Intelligence Podcast.\n\n02:05.120 --> 02:07.340\n If you enjoy it, subscribe on YouTube,\n\n02:07.340 --> 02:09.160\n give it five stars on Apple Podcast,\n\n02:09.160 --> 02:10.560\n support it on Patreon,\n\n02:10.560 --> 02:12.600\n or simply connect with me on Twitter\n\n02:12.600 --> 02:17.080\n at Lex Friedman spelled F R I D M A N.\n\n02:17.080 --> 02:19.640\n As usual, I'll do one or two minutes of ads now\n\n02:19.640 --> 02:21.080\n and never any ads in the middle\n\n02:21.080 --> 02:23.380\n that can break the flow of the conversation.\n\n02:23.380 --> 02:24.800\n I hope that works for you\n\n02:24.800 --> 02:27.500\n and doesn't hurt the listening experience.\n\n02:27.500 --> 02:29.960\n This show is presented by Cash App,\n\n02:29.960 --> 02:32.400\n the number one finance app in the App Store.\n\n02:32.400 --> 02:35.840\n When you get it, use code LEXPODCAST.\n\n02:35.840 --> 02:38.040\n Cash App lets you send money to friends,\n\n02:38.040 --> 02:40.360\n buy Bitcoin, and invest in the stock market\n\n02:40.360 --> 02:41.900\n with as little as one dollar.\n\n02:42.880 --> 02:45.220\n Since Cash App allows you to buy Bitcoin,\n\n02:45.220 --> 02:47.160\n let me mention that cryptocurrency\n\n02:47.160 --> 02:50.400\n in the context of the history of money is fascinating.\n\n02:50.400 --> 02:52.760\n I recommend A Scent of Money\n\n02:52.760 --> 02:55.040\n as a great book on this history.\n\n02:55.040 --> 02:59.920\n Debits and credits on ledgers started 30,000 years ago.\n\n02:59.920 --> 03:03.960\n The US dollar was created about 200 years ago.\n\n03:03.960 --> 03:07.480\n At Bitcoin, the first decentralized cryptocurrency\n\n03:07.480 --> 03:10.060\n was released just over 10 years ago.\n\n03:10.060 --> 03:11.460\n So given that history,\n\n03:11.460 --> 03:13.060\n cryptocurrency is still very much\n\n03:13.060 --> 03:15.020\n in its early days of development,\n\n03:15.020 --> 03:16.680\n but it still is aiming to\n\n03:16.680 --> 03:20.760\n and just might redefine the nature of money.\n\n03:20.760 --> 03:23.160\n So again, if you get Cash App from the App Store\n\n03:23.160 --> 03:26.200\n or Google Play and use code LEXPODCAST,\n\n03:26.200 --> 03:27.480\n you'll get $10,\n\n03:27.480 --> 03:30.300\n and Cash App will also donate $10 to FIRST,\n\n03:30.300 --> 03:31.960\n one of my favorite organizations\n\n03:31.960 --> 03:33.840\n that is helping advance robotics\n\n03:33.840 --> 03:36.620\n and STEM education for young people around the world.\n\n03:37.640 --> 03:41.640\n And now, here's my conversation with Alex Garland.\n\n03:42.560 --> 03:45.260\n You described the world inside the shimmer\n\n03:45.260 --> 03:47.280\n in the movie Annihilation as dreamlike\n\n03:47.280 --> 03:48.880\n in that it's internally consistent\n\n03:48.880 --> 03:50.840\n but detached from reality.\n\n03:50.840 --> 03:52.480\n That leads me to ask,\n\n03:52.480 --> 03:56.360\n do you think, a philosophical question, I apologize,\n\n03:56.360 --> 03:58.720\n do you think we might be living in a dream\n\n03:58.720 --> 04:02.380\n or in a simulation, like the kind that the shimmer creates?\n\n04:03.840 --> 04:07.160\n We human beings here today.\n\n04:07.160 --> 04:08.320\n Yeah.\n\n04:08.320 --> 04:11.720\n I wanna sort of separate that out into two things.\n\n04:11.720 --> 04:15.600\n Yes, I think we're living in a dream of sorts.\n\n04:15.600 --> 04:18.520\n No, I don't think we're living in a simulation.\n\n04:18.520 --> 04:20.840\n I think we're living on a planet\n\n04:20.840 --> 04:23.800\n with a very thin layer of atmosphere\n\n04:23.800 --> 04:27.720\n and the planet is in a very large space\n\n04:27.720 --> 04:30.000\n and the space is full of other planets and stars\n\n04:30.000 --> 04:31.360\n and quasars and stuff like that.\n\n04:31.360 --> 04:35.680\n And I don't think those physical objects,\n\n04:35.680 --> 04:38.840\n I don't think the matter in that universe is simulated.\n\n04:38.840 --> 04:40.600\n I think it's there.\n\n04:40.600 --> 04:42.760\n We are definitely,\n\n04:44.760 --> 04:46.360\n it's a hot problem with saying definitely,\n\n04:46.360 --> 04:50.180\n but in my opinion, I'll just go back to that.\n\n04:50.180 --> 04:53.040\n I think it seems very like we're living in a dream state.\n\n04:53.040 --> 04:54.280\n I'm pretty sure we are.\n\n04:54.280 --> 04:56.480\n And I think that's just to do with the nature\n\n04:56.480 --> 04:58.000\n of how we experience the world.\n\n04:58.000 --> 05:00.260\n We experience it in a subjective way.\n\n05:01.200 --> 05:04.400\n And the thing I've learned most\n\n05:04.400 --> 05:06.240\n as I've got older in some respects\n\n05:06.240 --> 05:10.800\n is the degree to which reality is counterintuitive\n\n05:10.800 --> 05:13.640\n and that the things that are presented to us as objective\n\n05:13.640 --> 05:15.120\n turn out not to be objective\n\n05:15.120 --> 05:17.360\n and quantum mechanics is full of that kind of thing,\n\n05:17.360 --> 05:18.960\n but actually just day to day life\n\n05:18.960 --> 05:20.840\n is full of that kind of thing as well.\n\n05:20.840 --> 05:25.840\n So my understanding of the way the brain works\n\n05:27.160 --> 05:30.760\n is you get some information, hit your optic nerve,\n\n05:30.760 --> 05:32.760\n and then your brain makes its best guess\n\n05:32.760 --> 05:36.320\n about what it's seeing or what it's saying it's seeing.\n\n05:36.320 --> 05:39.220\n It may or may not be an accurate best guess.\n\n05:39.220 --> 05:41.320\n It might be an inaccurate best guess.\n\n05:41.320 --> 05:45.440\n And that gap, the best guess gap,\n\n05:45.440 --> 05:48.980\n means that we are essentially living in a subjective state,\n\n05:48.980 --> 05:51.000\n which means that we're in a dream state.\n\n05:51.000 --> 05:54.000\n So I think you could enlarge on the dream state\n\n05:54.000 --> 05:55.440\n in all sorts of ways.\n\n05:55.440 --> 05:58.280\n So yes, dream state, no simulation\n\n05:58.280 --> 06:00.440\n would be where I'd come down.\n\n06:00.440 --> 06:04.020\n Going further, deeper into that direction,\n\n06:04.020 --> 06:08.560\n you've also described that world as psychedelia.\n\n06:08.560 --> 06:11.440\n So on that topic, I'm curious about that world.\n\n06:11.440 --> 06:13.320\n On the topic of psychedelic drugs,\n\n06:13.320 --> 06:15.920\n do you see those kinds of chemicals\n\n06:15.920 --> 06:18.280\n that modify our perception\n\n06:18.280 --> 06:22.000\n as a distortion of our perception of reality\n\n06:22.000 --> 06:25.840\n or a window into another reality?\n\n06:25.840 --> 06:27.060\n No, I think what I'd be saying\n\n06:27.060 --> 06:29.140\n is that we live in a distorted reality\n\n06:29.140 --> 06:30.520\n and then those kinds of drugs\n\n06:30.520 --> 06:32.400\n give us a different kind of distorted.\n\n06:32.400 --> 06:33.240\n Different perspective.\n\n06:33.240 --> 06:34.060\n Yeah, exactly.\n\n06:34.060 --> 06:35.920\n They just give an alternate distortion.\n\n06:35.920 --> 06:37.560\n And I think that what they really do\n\n06:37.560 --> 06:41.040\n is they give a distorted perception,\n\n06:41.040 --> 06:45.540\n which is a little bit more allied to daydreams\n\n06:45.540 --> 06:47.320\n or unconscious interests.\n\n06:47.320 --> 06:51.120\n So if for some reason you're feeling unconsciously anxious\n\n06:51.120 --> 06:53.220\n at that moment and you take a psychedelic drug,\n\n06:53.220 --> 06:56.560\n you'll have a more pronounced, unpleasant experience.\n\n06:56.560 --> 06:59.080\n And if you're feeling very calm or happy,\n\n06:59.080 --> 07:00.360\n you might have a good time.\n\n07:01.720 --> 07:04.800\n But yeah, so if I'm saying we're starting from a premise,\n\n07:04.800 --> 07:07.920\n our starting point is we were already in the\n\n07:07.920 --> 07:09.500\n slightly psychedelic state.\n\n07:10.580 --> 07:13.400\n What those drugs do is help you go further down an avenue\n\n07:13.400 --> 07:16.240\n or maybe a slightly different avenue, but that's all.\n\n07:16.240 --> 07:19.520\n So in that movie, Annihilation,\n\n07:19.520 --> 07:24.520\n the shimmer, this alternate dreamlike state\n\n07:24.980 --> 07:29.420\n is created by, I believe perhaps, an alien entity.\n\n07:29.420 --> 07:32.100\n Of course, everything is up to interpretation, right?\n\n07:32.100 --> 07:36.180\n But do you think there's, in our world, in our universe,\n\n07:36.180 --> 07:39.080\n do you think there's intelligent life out there?\n\n07:39.080 --> 07:42.500\n And if so, how different is it from us humans?\n\n07:42.500 --> 07:47.200\n Well, one of the things I was trying to do in Annihilation\n\n07:47.200 --> 07:51.760\n was to offer up a form of alien life\n\n07:51.760 --> 07:53.380\n that was actually alien,\n\n07:53.380 --> 07:58.380\n because it would often seem to me that in the way\n\n07:58.380 --> 08:03.220\n that in the way we would represent aliens in books\n\n08:03.220 --> 08:04.380\n or cinema or television,\n\n08:04.380 --> 08:08.300\n or any one of the sort of storytelling mediums,\n\n08:08.300 --> 08:11.940\n is we would always give them very humanlike qualities.\n\n08:11.940 --> 08:14.900\n So they wanted to teach us about galactic federations,\n\n08:14.900 --> 08:17.780\n or they wanted to eat us, or they wanted our resources,\n\n08:17.780 --> 08:20.240\n like our water, or they want to enslave us,\n\n08:20.240 --> 08:21.420\n or whatever it happens to be.\n\n08:21.420 --> 08:25.460\n But all of these are incredibly humanlike motivations.\n\n08:25.460 --> 08:30.460\n And I was interested in the idea of an alien\n\n08:30.900 --> 08:34.300\n that was not in any way like us.\n\n08:34.300 --> 08:36.220\n It didn't share.\n\n08:36.220 --> 08:38.820\n Maybe it had a completely different clock speed.\n\n08:38.820 --> 08:42.140\n Maybe it's way, so we're talking about,\n\n08:42.140 --> 08:43.180\n we're looking at each other,\n\n08:43.180 --> 08:46.860\n we're getting information, light hits our optic nerve,\n\n08:46.860 --> 08:49.060\n our brain makes the best guess of what we're doing.\n\n08:49.060 --> 08:50.300\n Sometimes it's right, something, you know,\n\n08:50.300 --> 08:51.820\n the thing we were talking about before.\n\n08:51.820 --> 08:54.980\n What if this alien doesn't have an optic nerve?\n\n08:54.980 --> 08:57.700\n Maybe its way of encountering the space it's in\n\n08:57.700 --> 08:59.260\n is wholly different.\n\n08:59.260 --> 09:01.820\n Maybe it has a different relationship with gravity.\n\n09:01.820 --> 09:04.060\n The basic laws of physics it operates under\n\n09:04.060 --> 09:05.820\n might be fundamentally different.\n\n09:05.820 --> 09:07.820\n It could be a different time scale and so on.\n\n09:07.820 --> 09:10.340\n Yeah, or it could be the same laws,\n\n09:10.340 --> 09:12.740\n could be the same underlying laws of physics.\n\n09:12.740 --> 09:16.260\n You know, it's a machine created,\n\n09:16.260 --> 09:19.180\n or it's a creature created in a quantum mechanical way.\n\n09:19.180 --> 09:21.820\n It just ends up in a very, very different place\n\n09:21.820 --> 09:23.420\n to the one we end up in.\n\n09:23.420 --> 09:26.820\n So, part of the preoccupation with annihilation\n\n09:26.820 --> 09:29.900\n was to come up with an alien that was really alien\n\n09:29.900 --> 09:31.380\n and didn't give us,\n\n09:32.780 --> 09:35.380\n and it didn't give us and we didn't give it\n\n09:35.380 --> 09:39.980\n any kind of easy connection between human and the alien.\n\n09:39.980 --> 09:42.140\n Because I think it was to do with the idea\n\n09:42.140 --> 09:44.540\n that you could have an alien that landed on this planet\n\n09:44.540 --> 09:46.580\n that wouldn't even know we were here.\n\n09:46.580 --> 09:49.420\n And we might only glancingly know it was here.\n\n09:49.420 --> 09:52.180\n There'd just be this strange point\n\n09:52.180 --> 09:53.860\n where the vent diagrams connected,\n\n09:53.860 --> 09:56.180\n where we could sense each other or something like that.\n\n09:56.180 --> 09:59.980\n So in the movie, first of all, incredibly original view\n\n09:59.980 --> 10:01.900\n of what an alien life would be.\n\n10:01.900 --> 10:04.940\n And in that sense, it's a huge success.\n\n10:05.980 --> 10:07.860\n Let's go inside your imagination.\n\n10:07.860 --> 10:12.860\n Did the alien, that alien entity know anything about humans\n\n10:13.020 --> 10:13.940\n when it landed?\n\n10:13.940 --> 10:14.780\n No.\n\n10:14.780 --> 10:18.140\n So the idea is you're basically an alien\n\n10:18.140 --> 10:22.420\n that life is trying to reach out to anything\n\n10:22.420 --> 10:25.940\n that might be able to hear its mechanism of communication.\n\n10:25.940 --> 10:30.100\n Or was it simply, was it just basically their biologist\n\n10:30.100 --> 10:32.980\n exploring different kinds of stuff that you can find?\n\n10:32.980 --> 10:34.500\n But this is the interesting thing is,\n\n10:34.500 --> 10:36.740\n as soon as you say their biologist,\n\n10:36.740 --> 10:38.340\n you've done the thing of attributing\n\n10:38.340 --> 10:40.540\n human type motivations to it.\n\n10:40.540 --> 10:47.540\n So I was trying to free myself from anything like that.\n\n10:48.380 --> 10:51.060\n So all sorts of questions you might answer\n\n10:51.060 --> 10:54.100\n about this notional alien, I wouldn't be able to answer\n\n10:54.100 --> 10:57.420\n because I don't know what it was or how it worked.\n\n10:57.420 --> 11:00.900\n You know, I had some rough ideas.\n\n11:00.900 --> 11:04.340\n Like it had a very, very, very slow clock speed.\n\n11:04.340 --> 11:07.380\n And I thought maybe the way it is interacting\n\n11:07.380 --> 11:09.180\n with this environment is a little bit like\n\n11:09.180 --> 11:13.340\n the way an octopus will change its color forms\n\n11:13.340 --> 11:15.180\n around the space that it's in.\n\n11:15.180 --> 11:19.420\n So it's sort of reacting to what it's in to an extent,\n\n11:19.420 --> 11:23.620\n but the reason it's reacting in that way is indeterminate.\n\n11:23.620 --> 11:26.860\n But it's so, but it's clock speed was slower\n\n11:26.860 --> 11:30.340\n than our human life clock speed or inter,\n\n11:30.340 --> 11:32.940\n but it's faster than evolution.\n\n11:32.940 --> 11:34.980\n Faster than our evolution.\n\n11:34.980 --> 11:37.700\n Yeah, given the 4 billion years it took us to get here,\n\n11:37.700 --> 11:39.820\n then yes, maybe it started at eight.\n\n11:39.820 --> 11:43.420\n If you look at the human civilization as a single organism,\n\n11:43.420 --> 11:46.780\n in that sense, you know, this evolution could be us.\n\n11:46.780 --> 11:49.860\n You know, the evolution of living organisms on earth\n\n11:49.860 --> 11:51.380\n could be just a single organism.\n\n11:51.380 --> 11:54.100\n And it's kind of, that's its life,\n\n11:54.100 --> 11:57.220\n is the evolution process that eventually will lead\n\n11:57.220 --> 12:00.940\n to probably the heat death of the universe\n\n12:00.940 --> 12:02.660\n or something before that.\n\n12:02.660 --> 12:05.380\n I mean, that's just an incredible idea.\n\n12:05.380 --> 12:07.100\n So you almost don't know.\n\n12:07.100 --> 12:09.020\n You've created something\n\n12:09.020 --> 12:11.660\n that you don't even know how it works.\n\n12:11.660 --> 12:16.660\n Yeah, because anytime I tried to look into\n\n12:16.980 --> 12:18.220\n how it might work,\n\n12:18.220 --> 12:20.260\n I would then inevitably be attaching\n\n12:20.260 --> 12:22.860\n my kind of thought processes into it.\n\n12:22.860 --> 12:24.980\n And I wanted to try and put a bubble around it.\n\n12:24.980 --> 12:29.540\n I would say, no, this is alien in its most alien form.\n\n12:29.540 --> 12:32.900\n I have no real point of contact.\n\n12:32.900 --> 12:37.620\n So unfortunately I can't talk to Stanley Kubrick.\n\n12:37.620 --> 12:41.380\n So I'm really fortunate to get a chance to talk to you.\n\n12:41.380 --> 12:45.860\n On this particular notion,\n\n12:45.860 --> 12:48.380\n I'd like to ask it a bunch of different ways\n\n12:48.380 --> 12:49.500\n and we'll explore it in different ways,\n\n12:49.500 --> 12:52.460\n but do you ever consider human imagination,\n\n12:52.460 --> 12:57.020\n your imagination as a window into a possible future?\n\n12:57.020 --> 12:59.460\n And that what you're doing,\n\n12:59.460 --> 13:02.140\n you're putting that imagination on paper as a writer\n\n13:02.140 --> 13:04.740\n and then on screen as a director.\n\n13:04.740 --> 13:07.380\n And that plants the seeds in the minds of millions\n\n13:07.380 --> 13:10.180\n of future and current scientists.\n\n13:10.180 --> 13:13.020\n And so your imagination, you putting it down\n\n13:13.020 --> 13:14.980\n actually makes it as a reality.\n\n13:14.980 --> 13:18.580\n So it's almost like a first step of the scientific method\n\n13:18.580 --> 13:20.340\n that you imagining what's possible\n\n13:20.340 --> 13:22.460\n in your new series with Ex Machina\n\n13:23.500 --> 13:28.500\n is actually inspiring thousands of 12 year olds,\n\n13:28.820 --> 13:30.700\n millions of scientists\n\n13:30.700 --> 13:33.100\n and actually creating the future view of imagine.\n\n13:34.460 --> 13:37.140\n Well, all I could say is that from my point of view,\n\n13:37.140 --> 13:39.220\n it's almost exactly the reverse\n\n13:39.220 --> 13:44.220\n because I see that pretty much everything I do\n\n13:45.660 --> 13:50.260\n is a reaction to what scientists are doing.\n\n13:50.260 --> 13:53.460\n I'm an interested lay person.\n\n13:53.460 --> 13:58.260\n And I feel this individual,\n\n13:58.260 --> 14:02.700\n I feel that the most interesting area\n\n14:02.700 --> 14:05.540\n that humans are involved in is science.\n\n14:05.540 --> 14:07.340\n I think art is very, very interesting,\n\n14:07.340 --> 14:09.500\n but the most interesting is science.\n\n14:09.500 --> 14:12.660\n And science is in a weird place\n\n14:12.660 --> 14:17.660\n because maybe around the time Newton was alive,\n\n14:18.060 --> 14:21.340\n if a very, very interested lay person said to themselves,\n\n14:21.340 --> 14:23.980\n I want to really understand what Newton is saying\n\n14:23.980 --> 14:25.500\n about the way the world works\n\n14:25.500 --> 14:28.860\n with a few years of dedicated thinking,\n\n14:28.860 --> 14:31.100\n they would be able to understand\n\n14:32.500 --> 14:34.500\n the sort of principles he was laying out.\n\n14:34.500 --> 14:35.940\n And I don't think that's true anymore.\n\n14:35.940 --> 14:37.900\n I think that's stopped being true now.\n\n14:37.900 --> 14:41.740\n So I'm pretty smart guy.\n\n14:41.740 --> 14:43.940\n And if I said to myself,\n\n14:43.940 --> 14:46.300\n I want to really, really understand\n\n14:47.860 --> 14:51.220\n what is currently the state of quantum mechanics\n\n14:51.220 --> 14:54.700\n or string theory or any of the sort of branching areas of it,\n\n14:54.700 --> 14:56.260\n I wouldn't be able to.\n\n14:56.260 --> 14:59.060\n I'd be intellectually incapable of doing it\n\n14:59.060 --> 15:02.220\n because to work in those fields at the moment\n\n15:02.220 --> 15:03.620\n is a bit like being an athlete.\n\n15:03.620 --> 15:06.740\n I suspect you need to start when you're 12, you know?\n\n15:06.740 --> 15:09.540\n And if you start in your mid 20s,\n\n15:09.540 --> 15:11.500\n start trying to understand in your mid 20s,\n\n15:11.500 --> 15:13.980\n then you're just never going to catch up.\n\n15:13.980 --> 15:15.740\n That's the way it feels to me.\n\n15:15.740 --> 15:19.500\n So what I do is I try to make myself open.\n\n15:19.500 --> 15:24.300\n So the people that you're implying maybe I would influence,\n\n15:24.300 --> 15:25.900\n to me, it's exactly the other way around.\n\n15:25.900 --> 15:28.020\n These people are strongly influencing me.\n\n15:28.020 --> 15:30.420\n I'm thinking they're doing something fascinating.\n\n15:30.420 --> 15:32.980\n I'm concentrating and working as hard as I can\n\n15:32.980 --> 15:35.980\n to try and understand the implications of what they say.\n\n15:35.980 --> 15:38.260\n And in some ways, often what I'm trying to do\n\n15:38.260 --> 15:41.500\n is disseminate their ideas\n\n15:42.740 --> 15:47.740\n into a means by which it can enter a public conversation.\n\n15:50.300 --> 15:53.620\n So Ex Machina contains lots of name checks,\n\n15:53.620 --> 15:57.060\n all sorts of existing thought experiments,\n\n15:58.940 --> 16:02.820\n shadows on Plato's cave and Mary in the black and white room\n\n16:02.820 --> 16:07.500\n and all sorts of different longstanding thought processes\n\n16:07.500 --> 16:12.500\n about sentience or consciousness or subjectivity\n\n16:12.660 --> 16:14.500\n or gender or whatever it happens to be.\n\n16:14.500 --> 16:17.460\n And then I'm trying to marshal that into a narrative\n\n16:17.460 --> 16:19.580\n to say, look, this stuff is interesting\n\n16:19.580 --> 16:23.340\n and it's also relevant and this is my best shot at it.\n\n16:23.340 --> 16:27.700\n So I'm the one being influenced in my construction.\n\n16:27.700 --> 16:28.900\n That's fascinating.\n\n16:28.900 --> 16:31.020\n Of course you would say that\n\n16:31.020 --> 16:33.460\n because you're not even aware of your own.\n\n16:33.460 --> 16:35.660\n That's probably what Kubrick would say too, right?\n\n16:35.660 --> 16:40.140\n Is in describing why, how 9,000 is created\n\n16:40.140 --> 16:42.020\n the way how 9,000 is created,\n\n16:42.020 --> 16:43.500\n is you're just studying what's,\n\n16:43.500 --> 16:48.220\n but the reality when the specifics of the knowledge\n\n16:48.220 --> 16:50.300\n passes through your imagination,\n\n16:50.300 --> 16:53.820\n I would argue that you're incorrect\n\n16:53.820 --> 16:56.940\n in thinking that you're just disseminating knowledge\n\n16:56.940 --> 17:01.940\n that the very act of your imagination consuming that science,\n\n17:05.300 --> 17:09.180\n it creates something that creates the next step,\n\n17:09.180 --> 17:11.260\n potentially creates the next step.\n\n17:11.260 --> 17:15.140\n I certainly think that's true with 2001 A Space Odyssey.\n\n17:15.140 --> 17:18.100\n I think at its best, and if it fails.\n\n17:18.100 --> 17:20.780\n It's true of that, yeah, it's true of that, definitely.\n\n17:21.860 --> 17:23.860\n At its best, it plans something.\n\n17:23.860 --> 17:24.900\n It's hard to describe it.\n\n17:24.900 --> 17:29.140\n It inspires the next generation\n\n17:29.140 --> 17:31.060\n and it could be field dependent.\n\n17:31.060 --> 17:35.020\n So your new series has more a connection to physics,\n\n17:35.020 --> 17:37.580\n quantum physics, quantum mechanics, quantum computing,\n\n17:37.580 --> 17:40.500\n and yet Ex Machina has more artificial intelligence.\n\n17:40.500 --> 17:43.060\n I know more about AI.\n\n17:43.060 --> 17:48.060\n My sense that AI is much earlier\n\n17:48.580 --> 17:51.820\n in the depth of its understanding.\n\n17:51.820 --> 17:55.260\n I would argue nobody understands anything\n\n17:55.260 --> 17:57.820\n to the depth that physicists do about physics.\n\n17:57.820 --> 18:00.500\n In AI, nobody understands AI,\n\n18:00.500 --> 18:03.980\n that there is a lot of importance and role for imagination,\n\n18:03.980 --> 18:05.980\n which I think we're in that,\n\n18:05.980 --> 18:08.180\n where Freud imagined the subconscious,\n\n18:08.180 --> 18:10.860\n we're in that stage of AI,\n\n18:10.860 --> 18:12.740\n where there's a lot of imagination needed\n\n18:12.740 --> 18:14.340\n thinking outside the box.\n\n18:14.340 --> 18:15.820\n Yeah, it's interesting.\n\n18:15.820 --> 18:20.820\n The spread of discussions and the spread of anxieties\n\n18:21.100 --> 18:23.460\n that exists about AI fascinate me.\n\n18:24.620 --> 18:29.620\n The way in which some people seem terrified about it\n\n18:30.500 --> 18:32.340\n whilst also pursuing it.\n\n18:32.340 --> 18:36.900\n And I've never shared that fear about AI personally,\n\n18:38.740 --> 18:42.660\n but the way in which it agitates people\n\n18:42.660 --> 18:44.540\n and also the people who it agitates,\n\n18:44.540 --> 18:47.380\n I find kind of fascinating.\n\n18:47.380 --> 18:49.300\n Are you afraid?\n\n18:49.300 --> 18:50.860\n Are you excited?\n\n18:51.900 --> 18:54.660\n Are you sad by the possibility,\n\n18:54.660 --> 18:56.940\n let's take the existential risk\n\n18:56.940 --> 18:58.020\n of artificial intelligence,\n\n18:58.020 --> 19:01.260\n by the possibility an artificial intelligence system\n\n19:02.140 --> 19:06.540\n becomes our offspring and makes us obsolete?\n\n19:07.420 --> 19:10.660\n I mean, it's a huge subject to talk about, I suppose.\n\n19:10.660 --> 19:13.100\n But one of the things I think is that humans\n\n19:13.100 --> 19:18.100\n are actually very experienced at creating new life forms\n\n19:19.900 --> 19:23.140\n because that's why you and I are both here\n\n19:23.140 --> 19:24.980\n and it's why everyone on the planet is here.\n\n19:24.980 --> 19:29.820\n And so something in the process of having a living thing\n\n19:29.820 --> 19:31.980\n that exists that didn't exist previously\n\n19:31.980 --> 19:35.380\n is very much encoded into the structures of our life\n\n19:35.380 --> 19:37.300\n and the structures of our societies.\n\n19:37.300 --> 19:38.620\n Doesn't mean we always get it right,\n\n19:38.620 --> 19:41.460\n but it does mean we've learned quite a lot about that.\n\n19:42.620 --> 19:45.420\n We've learned quite a lot about what the dangers are\n\n19:45.420 --> 19:49.260\n of allowing things to be unchecked.\n\n19:49.260 --> 19:51.540\n And it's why we then create systems\n\n19:51.540 --> 19:54.060\n of checks and balances in our government\n\n19:54.060 --> 19:55.220\n and so on and so forth.\n\n19:55.220 --> 19:56.460\n I mean, that's not to say,\n\n19:57.500 --> 19:59.860\n the other thing is it seems like\n\n19:59.860 --> 20:01.860\n there's all sorts of things that you could put\n\n20:01.860 --> 20:04.420\n into a machine that you would not be.\n\n20:04.420 --> 20:07.460\n So with us, we sort of roughly try to give some rules\n\n20:07.460 --> 20:10.180\n to live by and some of us then live by those rules\n\n20:10.180 --> 20:11.020\n and some don't.\n\n20:11.020 --> 20:12.020\n And with a machine,\n\n20:12.020 --> 20:13.860\n it feels like you could enforce those things.\n\n20:13.860 --> 20:17.060\n So partly because of our previous experience\n\n20:17.060 --> 20:19.100\n and partly because of the different nature of a machine,\n\n20:19.100 --> 20:20.860\n I just don't feel anxious about it.\n\n20:22.380 --> 20:25.380\n More I just see all the good that,\n\n20:25.380 --> 20:28.220\n broadly speaking, the good that can come from it.\n\n20:28.220 --> 20:32.780\n But that's just where I am on that anxiety spectrum.\n\n20:32.780 --> 20:34.580\n You know, it's kind of, there's a sadness.\n\n20:34.580 --> 20:37.740\n So we as humans give birth to other humans, right?\n\n20:37.740 --> 20:39.340\n But there's generations.\n\n20:39.340 --> 20:41.380\n And there's often in the older generation,\n\n20:41.380 --> 20:44.100\n a sadness about what the world has become now.\n\n20:44.100 --> 20:44.940\n I mean, that's kind of...\n\n20:44.940 --> 20:47.140\n Yeah, there is, but there's a counterpoint as well,\n\n20:47.140 --> 20:51.500\n which is that most parents would wish\n\n20:51.500 --> 20:53.940\n for a better life for their children.\n\n20:53.940 --> 20:57.020\n So there may be a regret about some things about the past,\n\n20:57.020 --> 20:59.540\n but broadly speaking, what people really want\n\n20:59.540 --> 21:00.620\n is that things will be better\n\n21:00.620 --> 21:02.740\n for the future generations, not worse.\n\n21:02.740 --> 21:06.100\n And so, and then it's a question about\n\n21:06.100 --> 21:07.940\n what constitutes a future generation.\n\n21:07.940 --> 21:09.740\n A future generation could involve people.\n\n21:09.740 --> 21:11.220\n It also could involve machines\n\n21:11.220 --> 21:14.660\n and it could involve a sort of cross pollinated version\n\n21:14.660 --> 21:17.300\n of the two or any, but none of those things\n\n21:17.300 --> 21:19.860\n make me feel anxious.\n\n21:19.860 --> 21:21.260\n It doesn't give you anxiety.\n\n21:21.260 --> 21:23.020\n It doesn't excite you?\n\n21:23.020 --> 21:24.260\n Like anything that's new?\n\n21:24.260 --> 21:25.500\n It does.\n\n21:25.500 --> 21:26.940\n Not anything that's new.\n\n21:26.940 --> 21:29.860\n I don't think, for example, I've got,\n\n21:29.860 --> 21:32.500\n my anxieties relate to things like social media\n\n21:32.500 --> 21:35.900\n that, so I've got plenty of anxieties about that.\n\n21:35.900 --> 21:38.260\n Which is also driven by artificial intelligence\n\n21:38.260 --> 21:41.020\n in the sense that there's too much information\n\n21:41.020 --> 21:45.060\n to be able to, an algorithm has to filter that information\n\n21:45.060 --> 21:46.140\n and present to you.\n\n21:46.140 --> 21:49.660\n So ultimately the algorithm, a simple,\n\n21:49.660 --> 21:52.540\n oftentimes simple algorithm is controlling\n\n21:52.540 --> 21:54.660\n the flow of information on social media.\n\n21:54.660 --> 21:57.500\n So that's another form of AI.\n\n21:57.500 --> 21:59.580\n But at least my sense of it, I might be wrong,\n\n21:59.580 --> 22:02.900\n but my sense of it is that the algorithms have\n\n22:03.740 --> 22:06.060\n an either conscious or unconscious bias,\n\n22:06.060 --> 22:07.420\n which is created by the people\n\n22:07.420 --> 22:08.780\n who are making the algorithms\n\n22:08.780 --> 22:13.420\n and sort of delineating the areas\n\n22:13.420 --> 22:15.660\n to which those algorithms are gonna lean.\n\n22:15.660 --> 22:19.260\n And so for example, the kind of thing I'd be worried about\n\n22:19.260 --> 22:21.340\n is that it hasn't been thought about enough\n\n22:21.340 --> 22:24.540\n how dangerous it is to allow algorithms\n\n22:24.540 --> 22:26.980\n to create echo chambers, say.\n\n22:26.980 --> 22:30.980\n But that doesn't seem to me to be about the AI\n\n22:30.980 --> 22:32.700\n or the algorithm.\n\n22:32.700 --> 22:34.940\n It's the naivety of the people\n\n22:34.940 --> 22:38.300\n who are constructing the algorithms to do that thing.\n\n22:38.300 --> 22:39.460\n If you see what I mean.\n\n22:39.460 --> 22:40.420\n Yes.\n\n22:40.420 --> 22:43.540\n So in your new series, Devs,\n\n22:43.540 --> 22:45.020\n and we could speak more broadly,\n\n22:45.020 --> 22:47.860\n there's a, let's talk about the people\n\n22:47.860 --> 22:49.300\n constructing those algorithms,\n\n22:49.300 --> 22:51.780\n which in our modern society, Silicon Valley,\n\n22:51.780 --> 22:54.660\n those algorithms happen to be a source of a lot of income\n\n22:54.660 --> 22:56.500\n because of advertisements.\n\n22:56.500 --> 22:59.940\n So let me ask sort of a question about those people.\n\n23:01.220 --> 23:04.740\n Are current concerns and failures on social media,\n\n23:04.740 --> 23:06.580\n their naivety?\n\n23:06.580 --> 23:08.260\n I can't pronounce that word well.\n\n23:08.260 --> 23:09.820\n Are they naive?\n\n23:09.820 --> 23:14.820\n Are they, I use that word carefully,\n\n23:14.940 --> 23:19.940\n but evil in intent or misaligned in intent?\n\n23:20.900 --> 23:23.100\n I think that's a, do they mean well\n\n23:23.100 --> 23:27.180\n and just go have an unintended consequence?\n\n23:27.180 --> 23:29.940\n Or is there something dark in them\n\n23:29.940 --> 23:33.780\n that results in them creating a company\n\n23:33.780 --> 23:37.380\n results in that super competitive drive to be successful.\n\n23:37.380 --> 23:38.780\n And those are the people that will end up\n\n23:38.780 --> 23:40.140\n controlling the algorithms.\n\n23:41.140 --> 23:43.140\n At a guess, I'd say there are instances\n\n23:43.140 --> 23:44.780\n of all those things.\n\n23:44.780 --> 23:47.500\n So sometimes I think it's naivety.\n\n23:47.500 --> 23:49.580\n Sometimes I think it's extremely dark.\n\n23:49.580 --> 23:54.580\n And sometimes I think people are not being naive or dark.\n\n23:56.860 --> 23:59.980\n And then in those instances are sometimes\n\n24:01.100 --> 24:02.820\n generating things that are very benign\n\n24:02.820 --> 24:05.100\n and other times generating things\n\n24:05.100 --> 24:07.820\n that despite their best intentions are not very benign.\n\n24:07.820 --> 24:11.300\n It's something, I think the reason why I don't get anxious\n\n24:11.300 --> 24:20.300\n about AI in terms of, or at least AIs that have,\n\n24:20.300 --> 24:22.940\n I don't know, a relationship with,\n\n24:22.940 --> 24:24.620\n some sort of relationship with humans\n\n24:24.620 --> 24:27.620\n is that I think that's the stuff we're quite well equipped\n\n24:27.620 --> 24:31.180\n to understand how to mitigate.\n\n24:31.180 --> 24:36.180\n The problem is issues that relate actually\n\n24:37.660 --> 24:41.020\n to the power of humans or the wealth of humans.\n\n24:41.020 --> 24:45.460\n And that's where it's dangerous here and now.\n\n24:45.460 --> 24:50.340\n So what I see, I'll tell you what I sometimes feel\n\n24:50.340 --> 24:55.340\n about Silicon Valley is that it's like Wall Street\n\n24:55.540 --> 24:56.980\n in the 80s.\n\n24:58.740 --> 25:03.740\n It's rabidly capitalistic, absolutely rabidly capitalistic\n\n25:03.820 --> 25:06.380\n and it's rabidly greedy.\n\n25:06.380 --> 25:11.380\n But whereas in the 80s, the sense one had of Wall Street\n\n25:12.740 --> 25:15.220\n was that these people kind of knew they were sharks\n\n25:15.220 --> 25:17.460\n and in a way relished in being sharks\n\n25:17.460 --> 25:22.260\n and dressed in sharp suits and kind of lorded\n\n25:23.180 --> 25:26.020\n over other people and felt good about doing it.\n\n25:26.020 --> 25:27.860\n Silicon Valley has managed to hide\n\n25:27.860 --> 25:30.940\n its voracious Wall Street like capitalism\n\n25:30.940 --> 25:35.940\n behind hipster T shirts and cool cafes in the place\n\n25:35.940 --> 25:37.420\n where they set up there.\n\n25:37.420 --> 25:40.580\n And so that obfuscates what's really going on\n\n25:40.580 --> 25:44.220\n and what's really going on is the absolute voracious pursuit\n\n25:44.220 --> 25:45.820\n of money and power.\n\n25:45.820 --> 25:48.380\n So that's where it gets shaky for me.\n\n25:48.380 --> 25:52.740\n So that veneer and you explore that brilliantly,\n\n25:53.540 --> 25:57.580\n that veneer of virtue that Silicon Valley has.\n\n25:57.580 --> 26:01.060\n Which they believe themselves, I'm sure for a long time.\n\n26:01.060 --> 26:06.060\n Okay, I hope to be one of those people and I believe that.\n\n26:11.900 --> 26:15.740\n So as maybe a devil's advocate term,\n\n26:15.740 --> 26:17.420\n poorly used in this case,\n\n26:19.220 --> 26:20.980\n what if some of them really are trying\n\n26:20.980 --> 26:21.980\n to build a better world?\n\n26:21.980 --> 26:22.820\n I can't.\n\n26:22.820 --> 26:24.060\n I'm sure I think some of them are.\n\n26:24.060 --> 26:26.420\n I think I've spoken to ones who I believe in their heart\n\n26:26.420 --> 26:27.700\n feel they're building a better world.\n\n26:27.700 --> 26:29.020\n Are they not able to?\n\n26:29.020 --> 26:31.500\n No, they may or may not be,\n\n26:31.500 --> 26:35.700\n but it's just as a zone with a lot of bullshit flying about.\n\n26:35.700 --> 26:36.980\n And there's also another thing,\n\n26:36.980 --> 26:40.140\n which is this actually goes back to,\n\n26:41.020 --> 26:44.380\n I always thought about some sports\n\n26:44.380 --> 26:46.580\n that later turned out to be corrupt\n\n26:46.580 --> 26:47.940\n in the way that the sport,\n\n26:47.940 --> 26:49.980\n like who won the boxing match\n\n26:49.980 --> 26:54.100\n or how a football match got thrown or cricket match\n\n26:54.100 --> 26:55.460\n or whatever happened to be.\n\n26:55.460 --> 26:56.940\n And I used to think, well, look,\n\n26:56.940 --> 26:59.260\n if there's a lot of money\n\n26:59.260 --> 27:00.540\n and there really is a lot of money,\n\n27:00.540 --> 27:03.420\n people stand to make millions or even billions,\n\n27:03.420 --> 27:05.940\n you will find a corruption that's gonna happen.\n\n27:05.940 --> 27:10.940\n So it's in the nature of its voracious appetite\n\n27:12.740 --> 27:14.180\n that some people will be corrupt\n\n27:14.180 --> 27:16.140\n and some people will exploit\n\n27:16.140 --> 27:17.940\n and some people will exploit\n\n27:17.940 --> 27:19.740\n whilst thinking they're doing something good.\n\n27:19.740 --> 27:23.460\n But there are also people who I think are very, very smart\n\n27:23.460 --> 27:26.380\n and very benign and actually very self aware.\n\n27:26.380 --> 27:29.580\n And so I'm not trying to,\n\n27:29.580 --> 27:32.780\n I'm not trying to wipe out the motivations\n\n27:32.780 --> 27:34.740\n of this entire area.\n\n27:34.740 --> 27:37.380\n But I do, there are people in that world\n\n27:37.380 --> 27:38.780\n who scare the hell out of me.\n\n27:38.780 --> 27:40.140\n Yeah, sure.\n\n27:40.140 --> 27:42.020\n Yeah, I'm a little bit naive in that,\n\n27:42.020 --> 27:45.820\n like I don't care at all about money.\n\n27:45.820 --> 27:50.140\n And so I'm a...\n\n27:50.140 --> 27:52.740\n You might be one of the good guys.\n\n27:52.740 --> 27:55.820\n Yeah, but so the thought is, but I don't have money.\n\n27:55.820 --> 27:58.180\n So my thought is if you give me a billion dollars,\n\n27:58.180 --> 28:00.100\n I would, it would change nothing\n\n28:00.100 --> 28:01.540\n and I would spend it right away\n\n28:01.540 --> 28:04.460\n on investing it right back and creating a good world.\n\n28:04.460 --> 28:07.660\n But your intuition is that billion,\n\n28:07.660 --> 28:08.980\n there's something about that money\n\n28:08.980 --> 28:13.220\n that maybe slowly corrupts the people around you.\n\n28:13.220 --> 28:16.380\n There's somebody gets in that corrupts your soul\n\n28:16.380 --> 28:17.820\n the way you view the world.\n\n28:17.820 --> 28:20.140\n Money does corrupt, we know that.\n\n28:20.140 --> 28:22.620\n But there's a different sort of problem\n\n28:22.620 --> 28:26.660\n aside from just the money corrupts thing\n\n28:26.660 --> 28:29.300\n that we're familiar with throughout history.\n\n28:30.740 --> 28:34.100\n And it's more about the sense of reinforcement\n\n28:34.100 --> 28:37.020\n an individual gets, which is so...\n\n28:37.020 --> 28:42.020\n It effectively works like the reason I earned all this money\n\n28:42.420 --> 28:44.540\n and so much more money than anyone else\n\n28:44.540 --> 28:46.180\n is because I'm very gifted.\n\n28:46.180 --> 28:47.940\n I'm actually a bit smarter than they are,\n\n28:47.940 --> 28:49.660\n or I'm a lot smarter than they are,\n\n28:49.660 --> 28:52.100\n and I can see the future in the way they can't.\n\n28:52.100 --> 28:55.300\n And maybe some of those people are not particularly smart,\n\n28:55.300 --> 28:56.540\n they're very lucky,\n\n28:56.540 --> 28:59.140\n or they're very talented entrepreneurs.\n\n28:59.140 --> 29:02.060\n And there's a difference between...\n\n29:02.060 --> 29:05.300\n So in other words, the acquisition of the money and power\n\n29:05.300 --> 29:08.620\n can suddenly start to feel like evidence of virtue.\n\n29:08.620 --> 29:09.940\n And it's not evidence of virtue,\n\n29:09.940 --> 29:11.940\n it might be evidence of completely different things.\n\n29:11.940 --> 29:13.380\n That's brilliantly put, yeah.\n\n29:13.380 --> 29:15.420\n Yeah, that's brilliantly put.\n\n29:15.420 --> 29:18.100\n So I think one of the fundamental drivers\n\n29:18.100 --> 29:20.540\n of my current morality...\n\n29:20.540 --> 29:25.540\n Let me just represent nerds in general of all kinds,\n\n29:27.140 --> 29:32.140\n is of constant self doubt and the signals...\n\n29:33.100 --> 29:36.660\n I'm very sensitive to signals from people that tell me\n\n29:36.660 --> 29:38.620\n I'm doing the wrong thing.\n\n29:38.620 --> 29:41.140\n But when there's a huge inflow of money,\n\n29:42.820 --> 29:44.100\n you just put it brilliantly\n\n29:44.100 --> 29:46.620\n that that could become an overpowering signal\n\n29:46.620 --> 29:49.420\n that everything you do is right.\n\n29:49.420 --> 29:53.180\n And so your moral compass can just get thrown off.\n\n29:53.180 --> 29:57.300\n Yeah, and that is not contained to Silicon Valley,\n\n29:57.300 --> 29:58.340\n that's across the board.\n\n29:58.340 --> 29:59.580\n In general, yeah.\n\n29:59.580 --> 30:01.060\n Like I said, I'm from the Soviet Union,\n\n30:01.060 --> 30:05.060\n the current president is convinced, I believe,\n\n30:05.060 --> 30:09.100\n actually he wants to do really good by the country\n\n30:09.100 --> 30:10.260\n and by the world,\n\n30:10.260 --> 30:14.220\n but his moral compass may be off because...\n\n30:14.220 --> 30:17.580\n Yeah, I mean, it's the interesting thing about evil,\n\n30:17.580 --> 30:20.940\n which is that I think most people\n\n30:20.940 --> 30:24.020\n who do spectacularly evil things think themselves\n\n30:24.020 --> 30:25.580\n they're doing really good things.\n\n30:25.580 --> 30:27.820\n That they're not there thinking,\n\n30:27.820 --> 30:29.700\n I am a sort of incarnation of Satan.\n\n30:29.700 --> 30:33.540\n They're thinking, yeah, I've seen a way to fix the world\n\n30:33.540 --> 30:35.780\n and everyone else is wrong, here I go.\n\n30:35.780 --> 30:39.340\n In fact, I'm having a fascinating conversation\n\n30:39.340 --> 30:42.860\n with a historian of Stalin, and he took power.\n\n30:42.860 --> 30:47.140\n He actually got more power\n\n30:47.140 --> 30:49.460\n than almost any person in history.\n\n30:49.460 --> 30:52.220\n And he wanted, he didn't want power.\n\n30:52.220 --> 30:54.140\n He just wanted, he truly,\n\n30:54.140 --> 30:55.420\n and this is what people don't realize,\n\n30:55.420 --> 30:58.380\n he truly believed that communism\n\n30:58.380 --> 31:00.900\n will make for a better world.\n\n31:00.900 --> 31:01.740\n Absolutely.\n\n31:01.740 --> 31:02.980\n And he wanted power.\n\n31:02.980 --> 31:04.620\n He wanted to destroy the competition\n\n31:04.620 --> 31:07.500\n to make sure that we actually make communism work\n\n31:07.500 --> 31:10.020\n in the Soviet Union and then spread across the world.\n\n31:10.020 --> 31:12.940\n He was trying to do good.\n\n31:12.940 --> 31:16.020\n I think it's typically the case\n\n31:16.020 --> 31:17.820\n that that's what people think they're doing.\n\n31:17.820 --> 31:21.100\n And I think that, but you don't need to go to Stalin.\n\n31:21.100 --> 31:24.380\n I mean, Stalin, I think Stalin probably got pretty crazy,\n\n31:24.380 --> 31:26.380\n but actually that's another part of it,\n\n31:26.380 --> 31:29.460\n which is that the other thing that comes\n\n31:29.460 --> 31:31.740\n from being convinced of your own virtue\n\n31:31.740 --> 31:34.740\n is that then you stop listening to the modifiers around you.\n\n31:34.740 --> 31:37.820\n And that tends to drive people crazy.\n\n31:37.820 --> 31:40.500\n It's other people that keep us sane.\n\n31:40.500 --> 31:42.180\n And if you stop listening to them,\n\n31:42.180 --> 31:43.580\n I think you go a bit mad.\n\n31:43.580 --> 31:44.420\n That also happens.\n\n31:44.420 --> 31:45.260\n That's funny.\n\n31:45.260 --> 31:47.180\n Disagreement keeps us sane.\n\n31:47.180 --> 31:52.180\n To jump back for an entire generation of AI researchers,\n\n31:53.140 --> 31:56.860\n 2001, a Space Odyssey, put an image,\n\n31:56.860 --> 31:59.260\n the idea of human level, superhuman level intelligence\n\n31:59.260 --> 32:00.980\n into their mind.\n\n32:00.980 --> 32:04.820\n Do you ever, sort of jumping back to Ex Machina\n\n32:04.820 --> 32:06.060\n and talk a little bit about that,\n\n32:06.060 --> 32:08.860\n do you ever consider the audience of people\n\n32:08.860 --> 32:13.540\n who build the systems, the roboticists, the scientists\n\n32:13.540 --> 32:16.340\n that build the systems based on the stories you create,\n\n32:17.220 --> 32:20.220\n which I would argue, I mean, there's literally\n\n32:20.220 --> 32:25.220\n most of the top researchers about 40, 50 years old and plus,\n\n32:27.340 --> 32:29.620\n that's their favorite movie, 2001 Space Odyssey.\n\n32:29.620 --> 32:33.540\n And it really is in their work, their idea of what ethics is,\n\n32:33.540 --> 32:37.420\n of what is the target, the hope, the dangers of AI,\n\n32:37.420 --> 32:39.180\n is that movie, right?\n\n32:39.180 --> 32:43.700\n Do you ever consider the impact on those researchers\n\n32:43.700 --> 32:45.380\n when you create the work you do?\n\n32:46.420 --> 32:51.220\n Certainly not with Ex Machina in relation to 2001,\n\n32:51.220 --> 32:54.620\n because I'm not sure, I mean, I'd be pleased if there was,\n\n32:54.620 --> 32:58.420\n but I'm not sure in a way there isn't a fundamental\n\n32:58.420 --> 33:03.420\n discussion of issues to do with AI that isn't already\n\n33:03.620 --> 33:07.260\n and better dealt with by 2001.\n\n33:07.260 --> 33:11.260\n 2001 does a very, very good account of the way\n\n33:13.220 --> 33:17.940\n in which an AI might think and also potential issues\n\n33:17.940 --> 33:19.740\n with the way the AI might think.\n\n33:19.740 --> 33:23.700\n And also then a separate question about whether the AI\n\n33:23.700 --> 33:26.540\n is malevolent or benevolent.\n\n33:26.540 --> 33:30.220\n And 2001 doesn't really, it's a slightly odd thing\n\n33:30.220 --> 33:33.180\n to be making a film when you know there's a preexisting film\n\n33:33.180 --> 33:35.540\n which is not a really superb job.\n\n33:35.540 --> 33:38.460\n But there's questions of consciousness, embodiment,\n\n33:38.460 --> 33:40.860\n and also the same kinds of questions.\n\n33:40.860 --> 33:42.820\n Because those are my two favorite AI movies.\n\n33:42.820 --> 33:46.300\n So can you compare Hal 9000 and Ava,\n\n33:46.300 --> 33:50.620\n Hal 9000 from 2001 Space Odyssey and Ava from Ex Machina?\n\n33:50.620 --> 33:53.180\n The, in your view, from a philosophical perspective.\n\n33:53.180 --> 33:54.700\n But they've got different goals.\n\n33:54.700 --> 33:56.620\n The two AIs have completely different goals.\n\n33:56.620 --> 33:58.260\n I think that's really the difference.\n\n33:58.260 --> 34:01.260\n So in some respects, Ex Machina took as a premise\n\n34:02.180 --> 34:06.180\n how do you assess whether something else has consciousness?\n\n34:06.180 --> 34:07.940\n So it was a version of the Turing test,\n\n34:07.940 --> 34:10.980\n except instead of having the machine hidden,\n\n34:10.980 --> 34:13.660\n you put the machine in plain sight\n\n34:13.660 --> 34:15.940\n in the way that we are in plain sight of each other\n\n34:15.940 --> 34:17.500\n and say now assess the consciousness.\n\n34:17.500 --> 34:22.500\n And the way it was illustrating the way in which you'd assess\n\n34:22.500 --> 34:24.380\n the state of consciousness of a machine\n\n34:24.380 --> 34:26.340\n is exactly the same way we assess\n\n34:26.340 --> 34:28.460\n the state of consciousness of each other.\n\n34:28.460 --> 34:31.620\n And in exactly the same way that in a funny way,\n\n34:31.620 --> 34:34.780\n your sense of my consciousness is actually based\n\n34:34.780 --> 34:37.740\n primarily on your own consciousness.\n\n34:37.740 --> 34:41.100\n That is also then true with the machine.\n\n34:41.100 --> 34:44.620\n And so it was actually about how much of\n\n34:45.620 --> 34:47.580\n the sense of consciousness is a projection\n\n34:47.580 --> 34:49.220\n rather than something that consciousness\n\n34:49.220 --> 34:50.540\n is actually containing.\n\n34:50.540 --> 34:53.780\n And has Plato's cave, I mean, this you really explored,\n\n34:53.780 --> 34:57.020\n you could argue that how sort of Space Odyssey explores\n\n34:57.020 --> 34:58.860\n idea of the Turing test for intelligence,\n\n34:58.860 --> 35:00.260\n they're not tests, there's no test,\n\n35:00.260 --> 35:03.180\n but it's more focused on intelligence.\n\n35:03.180 --> 35:08.180\n And Ex Machina kind of goes around intelligence\n\n35:08.740 --> 35:11.300\n and says the consciousness of the human to human,\n\n35:11.300 --> 35:13.380\n human to robot interactions more interest,\n\n35:13.380 --> 35:15.900\n more important, more at least the focus\n\n35:15.900 --> 35:18.140\n of that particular movie.\n\n35:18.140 --> 35:20.980\n Yeah, it's about the interior state\n\n35:20.980 --> 35:23.940\n and what constitutes the interior state\n\n35:23.940 --> 35:25.380\n and how do we know it's there?\n\n35:25.380 --> 35:27.020\n And actually in that respect,\n\n35:27.020 --> 35:32.020\n Ex Machina is as much about consciousness in general\n\n35:32.500 --> 35:36.900\n as it is to do specifically with machine consciousness.\n\n35:36.900 --> 35:37.740\n Yes.\n\n35:37.740 --> 35:38.980\n And it's also interesting,\n\n35:38.980 --> 35:40.820\n you know that thing you started asking about,\n\n35:40.820 --> 35:42.580\n the dream state, and I was saying,\n\n35:42.580 --> 35:43.900\n well, I think we're all in a dream state\n\n35:43.900 --> 35:46.180\n because we're all in a subjective state.\n\n35:46.180 --> 35:51.180\n One of the things that I became aware of with Ex Machina\n\n35:52.820 --> 35:55.140\n is that the way in which people reacted to the film\n\n35:55.140 --> 35:57.940\n was very based on what they took into the film.\n\n35:57.940 --> 36:01.780\n So many people thought Ex Machina was the tale\n\n36:01.780 --> 36:05.820\n of a sort of evil robot who murders two men and escapes.\n\n36:05.820 --> 36:09.180\n And she has no empathy, for example,\n\n36:09.180 --> 36:10.660\n because she's a machine.\n\n36:10.660 --> 36:14.660\n Whereas I felt, no, she was a conscious being\n\n36:14.660 --> 36:18.420\n with a consciousness different from mine, but so what,\n\n36:18.420 --> 36:22.140\n imprisoned and made a bunch of value judgments\n\n36:22.140 --> 36:25.780\n about how to get out of that box.\n\n36:25.780 --> 36:29.100\n And there's a moment which it sort of slightly bugs me,\n\n36:29.100 --> 36:31.860\n but nobody ever has noticed it and it's years after,\n\n36:31.860 --> 36:33.020\n so I might as well say it now,\n\n36:33.020 --> 36:36.740\n which is that after Ava has escaped,\n\n36:36.740 --> 36:39.740\n she crosses a room and as she's crossing a room,\n\n36:39.740 --> 36:42.020\n this is just before she leaves the building,\n\n36:42.020 --> 36:44.900\n she looks over her shoulder and she smiles.\n\n36:44.900 --> 36:49.220\n And I thought after all the conversation about tests,\n\n36:49.220 --> 36:52.340\n in a way, the best indication you could have\n\n36:52.340 --> 36:54.820\n of the interior state of someone\n\n36:54.820 --> 36:57.220\n is if they are not being observed\n\n36:57.220 --> 36:59.500\n and they smile about something\n\n36:59.500 --> 37:01.220\n with their smiling for themself.\n\n37:01.220 --> 37:05.860\n And that to me was evidence of Ava's true sentience,\n\n37:05.860 --> 37:07.780\n whatever that sentience was.\n\n37:07.780 --> 37:12.780\n Oh, that's really interesting, we don't get to observe Ava much\n\n37:12.780 --> 37:16.180\n or something like a smile in any context\n\n37:16.180 --> 37:17.660\n except through interaction,\n\n37:17.660 --> 37:20.500\n trying to convince others that she's conscious,\n\n37:20.500 --> 37:21.540\n that's beautiful.\n\n37:21.540 --> 37:22.820\n Exactly, yeah.\n\n37:22.820 --> 37:25.020\n But it was a small, in a funny way,\n\n37:25.020 --> 37:28.780\n I think maybe people saw it as an evil smile,\n\n37:28.780 --> 37:32.140\n like, ha, I fooled them.\n\n37:32.140 --> 37:34.180\n But actually it was just a smile.\n\n37:34.180 --> 37:35.540\n And I thought, well, in the end,\n\n37:35.540 --> 37:37.300\n after all the conversations about the test,\n\n37:37.300 --> 37:39.740\n that was the answer to the test and then off she goes.\n\n37:39.740 --> 37:44.420\n So if we align, if we just linger a little bit longer\n\n37:44.420 --> 37:49.420\n on Hal and Ava, do you think in terms of motivation,\n\n37:49.700 --> 37:51.580\n what was Hal's motivation?\n\n37:51.580 --> 37:54.140\n Is Hal good or evil?\n\n37:54.140 --> 37:57.060\n Is Ava good or evil?\n\n37:57.060 --> 38:02.060\n Ava's good, in my opinion, and Hal is neutral\n\n38:03.140 --> 38:06.500\n because I don't think Hal is presented\n\n38:06.500 --> 38:11.500\n as having a sophisticated emotional life.\n\n38:11.740 --> 38:14.580\n He has a set of paradigms,\n\n38:14.580 --> 38:16.620\n which is that the mission needs to be completed.\n\n38:16.620 --> 38:18.860\n I mean, it's a version of the paperclip.\n\n38:18.860 --> 38:19.700\n Yeah.\n\n38:19.700 --> 38:23.140\n The idea that it's just, it's a super intelligent machine,\n\n38:23.140 --> 38:25.580\n but it's just performed a particular task\n\n38:25.580 --> 38:28.940\n and in doing that task may destroy everybody on Earth\n\n38:28.940 --> 38:32.420\n or may achieve undesirable effects for us humans.\n\n38:32.420 --> 38:33.260\n Precisely, yeah.\n\n38:33.260 --> 38:34.900\n But what if...\n\n38:34.900 --> 38:38.340\n At the very end, he says something like I'm afraid, Dave,\n\n38:38.340 --> 38:43.340\n but that may be he is on some level experiencing fear\n\n38:44.580 --> 38:49.380\n or it may be this is the terms in which it would be wise\n\n38:49.380 --> 38:52.700\n to stop someone from doing the thing they're doing,\n\n38:52.700 --> 38:53.540\n if you see what I mean.\n\n38:53.540 --> 38:54.380\n Yes, absolutely.\n\n38:54.380 --> 38:55.420\n So actually that's funny.\n\n38:55.420 --> 39:00.420\n So that's such a small, short exploration of consciousness\n\n39:00.420 --> 39:03.420\n that I'm afraid, and then you just with ex machina say,\n\n39:03.420 --> 39:05.660\n okay, we're gonna magnify that part\n\n39:05.660 --> 39:07.180\n and then minimize the other part.\n\n39:07.180 --> 39:09.820\n That's a good way to sort of compare the two.\n\n39:09.820 --> 39:13.220\n But if you could just use your imagination,\n\n39:13.220 --> 39:18.220\n if Ava sort of, I don't know,\n\n39:19.660 --> 39:23.620\n ran the, was president of the United States,\n\n39:23.620 --> 39:24.460\n so had some power.\n\n39:24.460 --> 39:27.580\n So what kind of world would you want to create?\n\n39:27.580 --> 39:32.580\n If you kind of say good, and there is a sense\n\n39:32.780 --> 39:36.620\n that she has a really, like there's a desire\n\n39:36.620 --> 39:40.220\n for a better human to human interaction,\n\n39:40.220 --> 39:42.380\n human to robot interaction in her.\n\n39:42.380 --> 39:44.900\n But what kind of world do you think she would create\n\n39:44.900 --> 39:46.140\n with that desire?\n\n39:46.140 --> 39:48.740\n See, that's a really, that's a very interesting question.\n\n39:48.740 --> 39:52.140\n I'm gonna approach it slightly obliquely,\n\n39:52.140 --> 39:55.580\n which is that if a friend of yours\n\n39:55.580 --> 40:00.580\n got stabbed in a mugging, and you then felt very angry\n\n40:01.980 --> 40:04.060\n at the person who'd done the stabbing,\n\n40:04.060 --> 40:06.940\n but then you learned that it was a 15 year old\n\n40:06.940 --> 40:09.820\n and the 15 year old, both their parents were addicted\n\n40:09.820 --> 40:12.380\n to crystal meth and the kid had been addicted\n\n40:12.380 --> 40:13.380\n since he was 10.\n\n40:13.380 --> 40:15.460\n And he really never had any hope in the world.\n\n40:15.460 --> 40:17.900\n And he'd been driven crazy by his upbringing\n\n40:17.900 --> 40:22.900\n and did the stabbing that would hugely modify.\n\n40:22.900 --> 40:25.460\n And it would also make you wary about that kid\n\n40:25.460 --> 40:27.580\n then becoming president of America.\n\n40:27.580 --> 40:32.100\n And Ava has had a very, very distorted introduction\n\n40:32.100 --> 40:33.020\n into the world.\n\n40:33.020 --> 40:38.020\n So, although there's nothing as it were organically\n\n40:38.340 --> 40:42.860\n within Ava that would lean her towards badness,\n\n40:43.820 --> 40:47.300\n it's not that robots or sentient robots are bad.\n\n40:47.300 --> 40:51.820\n She did not, her arrival into the world\n\n40:51.820 --> 40:53.460\n was being imprisoned by humans.\n\n40:53.460 --> 40:57.260\n So, I'm not sure she'd be a great president.\n\n40:57.260 --> 41:00.980\n The trajectory through which she arrived\n\n41:00.980 --> 41:05.380\n at her moral views have some dark elements.\n\n41:05.380 --> 41:08.100\n But I like Ava personally, I like Ava.\n\n41:08.100 --> 41:09.260\n Would you vote for her?\n\n41:11.460 --> 41:14.020\n I'm having difficulty finding anyone to vote for\n\n41:14.020 --> 41:17.180\n in my country or if I lived here in yours.\n\n41:17.180 --> 41:19.020\n I am.\n\n41:19.020 --> 41:21.060\n So, that's a yes, I guess, because I'm not sure\n\n41:21.060 --> 41:23.020\n Yes, I guess, because of the competition.\n\n41:23.020 --> 41:25.060\n She could easily do a better job than any of the people\n\n41:25.060 --> 41:27.460\n we've got around at the moment.\n\n41:27.460 --> 41:29.060\n I'd vote her over Boris Johnson.\n\n41:32.100 --> 41:36.660\n So, what is a good test of consciousness?\n\n41:36.660 --> 41:38.860\n We talk about consciousness a little bit more.\n\n41:38.860 --> 41:42.220\n If something appears conscious, is it conscious?\n\n41:42.220 --> 41:47.220\n You mentioned the smile, which seems to be something done.\n\n41:47.220 --> 41:49.540\n I mean, that's a really good indication\n\n41:49.540 --> 41:52.260\n because it's a tree falling in the forest\n\n41:52.260 --> 41:53.780\n with nobody there to hear it.\n\n41:53.780 --> 41:57.460\n But does the appearance from a robotics perspective\n\n41:57.460 --> 41:59.980\n of consciousness mean consciousness to you?\n\n41:59.980 --> 42:02.780\n No, I don't think you could say that fully\n\n42:02.780 --> 42:05.060\n because I think you could then easily have\n\n42:05.060 --> 42:06.940\n a thought experiment which said,\n\n42:06.940 --> 42:09.980\n we will create something which we know is not conscious\n\n42:09.980 --> 42:13.100\n but is going to give a very, very good account\n\n42:13.100 --> 42:13.940\n of seeming conscious.\n\n42:13.940 --> 42:17.620\n And so, and also it would be a particularly bad test\n\n42:17.620 --> 42:20.940\n where humans are involved because humans are so quick\n\n42:20.940 --> 42:25.940\n to project sentience into things that don't have sentience.\n\n42:26.340 --> 42:29.300\n So, someone could have their computer playing up\n\n42:29.300 --> 42:31.940\n and feel as if their computer is being malevolent to them\n\n42:31.940 --> 42:32.780\n when it clearly isn't.\n\n42:32.780 --> 42:37.780\n And so, of all the things to judge consciousness, us.\n\n42:38.460 --> 42:39.300\n Humans are bad at it.\n\n42:39.300 --> 42:40.620\n We're empathy machines.\n\n42:40.620 --> 42:42.940\n So, the flip side of it is that\n\n42:42.940 --> 42:44.820\n so the flip side of that,\n\n42:44.820 --> 42:48.820\n the argument there is because we just attribute consciousness\n\n42:48.820 --> 42:52.340\n to everything almost and anthropomorphize everything\n\n42:52.340 --> 42:57.340\n including Roombas, that maybe consciousness is not real,\n\n42:57.740 --> 43:00.100\n that we just attribute consciousness to each other.\n\n43:00.100 --> 43:03.020\n So, you have a sense that there is something really special\n\n43:03.020 --> 43:07.380\n going on in our mind that makes us unique\n\n43:07.380 --> 43:10.100\n and gives us this subjective experience.\n\n43:10.100 --> 43:13.900\n There's something very interesting going on in our minds.\n\n43:13.900 --> 43:16.740\n I'm slightly worried about the word special\n\n43:16.740 --> 43:20.740\n because it gets a bit, it nudges towards metaphysics\n\n43:20.740 --> 43:23.020\n and maybe even magic.\n\n43:23.020 --> 43:25.820\n I mean, in some ways, something magic like,\n\n43:27.020 --> 43:29.340\n which I don't think is there at all.\n\n43:29.340 --> 43:30.300\n I mean, if you think about,\n\n43:30.300 --> 43:33.020\n so there's an idea called panpsychism\n\n43:33.020 --> 43:34.940\n that says consciousness is in everything.\n\n43:34.940 --> 43:36.300\n Yeah, I don't buy that.\n\n43:36.300 --> 43:37.140\n I don't buy that.\n\n43:37.140 --> 43:39.980\n Yeah, so the idea that there is a thing\n\n43:39.980 --> 43:42.900\n that it would be like to be the sun.\n\n43:42.900 --> 43:44.860\n Yeah, no, I don't buy that.\n\n43:44.860 --> 43:46.700\n I think that consciousness is a thing.\n\n43:48.060 --> 43:51.900\n My sort of broad modification is that usually\n\n43:51.900 --> 43:54.540\n the more I find out about things,\n\n43:54.540 --> 43:59.540\n the more illusory our instinct is\n\n44:00.540 --> 44:02.980\n and is leading us into a different direction\n\n44:02.980 --> 44:04.820\n about what that thing actually is.\n\n44:04.820 --> 44:07.660\n That happens, it seems to me in modern science,\n\n44:07.660 --> 44:10.020\n that happens a hell of a lot,\n\n44:10.020 --> 44:13.420\n whether it's to do with even how big or small things are.\n\n44:13.420 --> 44:16.740\n So my sense is that consciousness is a thing,\n\n44:16.740 --> 44:18.700\n but it isn't quite the thing\n\n44:18.700 --> 44:20.220\n or maybe very different from the thing\n\n44:20.220 --> 44:22.260\n that we instinctively think it is.\n\n44:22.260 --> 44:24.620\n So it's there, it's very interesting,\n\n44:24.620 --> 44:28.900\n but we may be in sort of quite fundamentally\n\n44:28.900 --> 44:33.340\n misunderstanding it for reasons that are based on intuition.\n\n44:33.340 --> 44:38.340\n So I have to ask, this is kind of an interesting question.\n\n44:38.540 --> 44:42.140\n The Ex Machina for many people, including myself,\n\n44:42.140 --> 44:44.780\n is one of the greatest AI films ever made.\n\n44:44.780 --> 44:45.740\n It's number two for me.\n\n44:45.740 --> 44:46.580\n Thanks.\n\n44:46.580 --> 44:48.420\n Yeah, it's definitely not number one.\n\n44:48.420 --> 44:50.620\n If it was number one, I'd really have to, anyway, yeah.\n\n44:50.620 --> 44:52.340\n Whenever you grow up with something, right,\n\n44:52.340 --> 44:55.500\n whenever you grow up with something, it's in the mud.\n\n44:56.540 --> 45:01.020\n But there's, one of the things that people bring up,\n\n45:01.020 --> 45:04.260\n and can't please everyone, including myself,\n\n45:04.260 --> 45:06.580\n this is what I first reacted to the film,\n\n45:06.580 --> 45:09.500\n is the idea of the lone genius.\n\n45:09.500 --> 45:12.740\n This is the criticism that people say,\n\n45:12.740 --> 45:14.540\n sort of me as an AI researcher,\n\n45:14.540 --> 45:18.860\n I'm trying to create what Nathan is trying to do.\n\n45:19.860 --> 45:23.180\n So there's a brilliant series called Chernobyl.\n\n45:23.180 --> 45:24.500\n Yes, it's fantastic.\n\n45:24.500 --> 45:26.100\n Absolutely spectacular.\n\n45:26.100 --> 45:30.100\n I mean, they got so many things brilliant or right.\n\n45:30.100 --> 45:32.620\n But one of the things, again, the criticism there.\n\n45:32.620 --> 45:34.940\n Yeah, they conflated lots of people into one.\n\n45:34.940 --> 45:37.820\n Into one character that represents all nuclear scientists,\n\n45:37.820 --> 45:39.940\n Ivana Komiak.\n\n45:42.580 --> 45:46.020\n It's a composite character that presents all scientists.\n\n45:46.020 --> 45:47.420\n Is this what you were,\n\n45:47.420 --> 45:49.260\n is this the way you were thinking about that?\n\n45:49.260 --> 45:51.620\n Or is it just simplifies the storytelling?\n\n45:51.620 --> 45:53.580\n How do you think about the lone genius?\n\n45:53.580 --> 45:56.860\n Well, I'd say this, the series I'm doing at the moment\n\n45:56.860 --> 46:01.580\n is a critique in part of the lone genius concept.\n\n46:01.580 --> 46:03.820\n So yes, I'm sort of oppositional\n\n46:03.820 --> 46:08.180\n and either agnostic or atheistic about that as a concept.\n\n46:08.180 --> 46:10.540\n I mean, not entirely.\n\n46:12.180 --> 46:15.780\n Whether lone is the right word, broadly isolated,\n\n46:15.780 --> 46:20.780\n but Newton clearly exists in a sort of bubble of himself,\n\n46:21.180 --> 46:22.860\n in some respects, so does Shakespeare.\n\n46:22.860 --> 46:25.580\n So do you think we would have an iPhone without Steve Jobs?\n\n46:25.580 --> 46:28.060\n I mean, how much contribution from a genius?\n\n46:28.060 --> 46:29.660\n Steve Jobs clearly isn't a lone genius\n\n46:29.660 --> 46:32.060\n because there's too many other people\n\n46:32.060 --> 46:33.740\n in the sort of superstructure around him\n\n46:33.740 --> 46:38.180\n who are absolutely fundamental to that journey.\n\n46:38.180 --> 46:40.340\n But you're saying Newton, but that's a scientific,\n\n46:40.340 --> 46:44.060\n so there's an engineering element to building Ava.\n\n46:44.060 --> 46:48.580\n But just to say, what Ex Machina is really,\n\n46:48.580 --> 46:50.220\n it's a thought experiment.\n\n46:50.220 --> 46:52.260\n I mean, so it's a construction\n\n46:52.260 --> 46:55.740\n of putting four people in a house.\n\n46:56.820 --> 47:00.180\n Nothing about Ex Machina adds up in all sorts of ways,\n\n47:00.180 --> 47:03.580\n in as much as the, who built the machine parts?\n\n47:03.580 --> 47:05.340\n Did the people building the machine parts\n\n47:05.340 --> 47:08.940\n know what they were creating and how did they get there?\n\n47:08.940 --> 47:11.420\n And it's a thought experiment.\n\n47:11.420 --> 47:14.740\n So it doesn't stand up to scrutiny of that sort.\n\n47:14.740 --> 47:18.180\n I don't think it's actually that interesting of a question,\n\n47:18.180 --> 47:22.340\n but it's brought up so often that I had to ask it\n\n47:22.340 --> 47:25.620\n because that's exactly how I felt after a while.\n\n47:27.180 --> 47:30.140\n There's something about, there was almost a defense,\n\n47:30.140 --> 47:33.020\n like I watched your movie the first time\n\n47:33.020 --> 47:36.060\n and at least for the first little while in a defensive way,\n\n47:36.060 --> 47:40.660\n like how dare this person try to step into the AI space\n\n47:40.660 --> 47:43.540\n and try to beat Kubrick.\n\n47:43.540 --> 47:45.260\n That's the way I was thinking,\n\n47:45.260 --> 47:48.180\n because it comes off as a movie that really is going\n\n47:48.180 --> 47:50.940\n after the deep fundamental questions about AI.\n\n47:50.940 --> 47:53.700\n So there's a kind of a nerd do this,\n\n47:53.700 --> 47:57.220\n like it's automatically searching for the flaws.\n\n47:57.220 --> 47:58.540\n And I did.\n\n47:58.540 --> 48:00.220\n I do exactly the same.\n\n48:00.220 --> 48:03.780\n I think in Annihilation, in the other movie,\n\n48:03.780 --> 48:06.300\n I was be able to free myself from that much quicker\n\n48:06.300 --> 48:08.420\n that it is a thought experiment.\n\n48:08.420 --> 48:10.980\n There's, who cares if there's batteries\n\n48:10.980 --> 48:12.020\n that don't run out, right?\n\n48:12.020 --> 48:14.620\n Those kinds of questions, that's the whole point.\n\n48:14.620 --> 48:18.580\n But it's nevertheless something I wanted to bring up.\n\n48:18.580 --> 48:20.820\n Yeah, it's a fair thing to bring up.\n\n48:20.820 --> 48:24.220\n For me, you hit on the lone genius thing.\n\n48:24.220 --> 48:27.100\n For me, it was actually, people always said,\n\n48:27.100 --> 48:31.460\n Ex Machina makes this big leap in terms of where AI\n\n48:31.460 --> 48:34.900\n has got to and also what AI would look like\n\n48:34.900 --> 48:36.140\n if it got to that point.\n\n48:36.140 --> 48:38.540\n There's another one, which is just robotics.\n\n48:38.540 --> 48:42.020\n I mean, look at the way Ava walks around a room.\n\n48:42.020 --> 48:44.340\n It's like, forget it, building that.\n\n48:44.340 --> 48:47.780\n That's also got to be a very, very long way off.\n\n48:47.780 --> 48:49.820\n And if you did get there, would it look anything like that?\n\n48:49.820 --> 48:50.740\n It's a thought experiment.\n\n48:50.740 --> 48:51.940\n Actually, I disagree with you.\n\n48:51.940 --> 48:56.500\n I think the way, as a ballerina, Alicia Vikander,\n\n48:56.500 --> 49:00.260\n brilliant actress, actor that moves around,\n\n49:01.580 --> 49:03.460\n we're very far away from creating that.\n\n49:03.460 --> 49:06.140\n But the way she moves around is exactly\n\n49:06.140 --> 49:08.580\n the definition of perfection for a roboticist.\n\n49:08.580 --> 49:09.980\n It's like smooth and efficient.\n\n49:09.980 --> 49:12.860\n So it is where we wanna get, I believe.\n\n49:12.860 --> 49:15.460\n I think, so I hang out with a lot\n\n49:15.460 --> 49:16.900\n of like human robotics people.\n\n49:16.900 --> 49:20.420\n They love elegant, smooth motion like that.\n\n49:20.420 --> 49:21.540\n That's their dream.\n\n49:21.540 --> 49:23.580\n So the way she moved is actually what I believe\n\n49:23.580 --> 49:25.900\n that would dream for a robot to move.\n\n49:25.900 --> 49:29.500\n It might not be that useful to move that sort of that way,\n\n49:29.500 --> 49:32.180\n but that is the definition of perfection\n\n49:32.180 --> 49:33.220\n in terms of movement.\n\n49:34.100 --> 49:35.900\n Drawing inspiration from real life.\n\n49:35.900 --> 49:39.460\n So for devs, for Ex Machina,\n\n49:39.460 --> 49:42.540\n look at characters like Elon Musk.\n\n49:42.540 --> 49:44.740\n What do you think about the various big technological\n\n49:44.740 --> 49:48.940\n efforts of Elon Musk and others like him\n\n49:48.940 --> 49:51.780\n and that he's involved with such as Tesla,\n\n49:51.780 --> 49:55.180\n SpaceX, Neuralink, do you see any of that technology\n\n49:55.180 --> 49:57.060\n potentially defining the future worlds\n\n49:57.060 --> 49:58.500\n you create in your work?\n\n49:58.500 --> 50:02.620\n So Tesla's automation, SpaceX's space exploration,\n\n50:02.620 --> 50:05.260\n Neuralink is brain machine interface,\n\n50:05.260 --> 50:09.820\n somehow merger of biological and electric systems.\n\n50:09.820 --> 50:13.780\n I'm in a way I'm influenced by that almost by definition\n\n50:13.780 --> 50:15.420\n because that's the world I live in.\n\n50:15.420 --> 50:17.860\n And this is the thing that's happening in that world.\n\n50:17.860 --> 50:20.060\n And I also feel supportive of it.\n\n50:20.060 --> 50:24.660\n So I think amongst various things,\n\n50:24.660 --> 50:28.660\n Elon Musk has done, I'm almost sure he's done\n\n50:28.660 --> 50:32.180\n a very, very good thing with Tesla for all of us.\n\n50:33.020 --> 50:36.180\n It's really kicked all the other car manufacturers\n\n50:36.180 --> 50:39.780\n in the face, it's kicked the fossil fuel industry\n\n50:39.780 --> 50:42.340\n in the face and they needed kicking in the face\n\n50:42.340 --> 50:43.180\n and he's done it.\n\n50:43.180 --> 50:47.980\n So that's the world he's part of creating\n\n50:47.980 --> 50:51.940\n and I live in that world, just bought a Tesla in fact.\n\n50:51.940 --> 50:56.940\n And so does that play into whatever I then make\n\n50:57.540 --> 51:02.540\n in some ways it does partly because I try to be a writer\n\n51:03.300 --> 51:07.100\n who quite often filmmakers are in some ways fixated\n\n51:07.100 --> 51:09.020\n on the films they grew up with\n\n51:09.020 --> 51:11.660\n and they sort of remake those films in some ways.\n\n51:11.660 --> 51:13.300\n I've always tried to avoid that.\n\n51:13.300 --> 51:17.740\n And so I looked at the real world to get inspiration\n\n51:17.740 --> 51:21.380\n and as much as possible sort of by living, I think.\n\n51:21.380 --> 51:24.420\n And so yeah, I'm sure.\n\n51:24.420 --> 51:28.300\n Which of the directions do you find most exciting?\n\n51:28.300 --> 51:29.240\n Space travel.\n\n51:30.620 --> 51:31.540\n Space travel.\n\n51:31.540 --> 51:36.180\n So you haven't really explored space travel in your work.\n\n51:36.180 --> 51:39.740\n You've said something like if you had unlimited amount\n\n51:39.740 --> 51:43.260\n of money, I think I read at AMA that you would make\n\n51:43.260 --> 51:47.100\n like a multi year series Space Wars or something like that.\n\n51:47.100 --> 51:50.720\n So what is it that excites you about space exploration?\n\n51:50.720 --> 51:55.720\n Well, because if we have any sort of long term future,\n\n51:56.060 --> 52:00.220\n it's that, it just simply is that.\n\n52:00.220 --> 52:04.260\n If energy and matter are linked up in the way\n\n52:04.260 --> 52:09.260\n we think they're linked up, we'll run out if we don't move.\n\n52:09.500 --> 52:11.140\n So we gotta move.\n\n52:11.140 --> 52:15.900\n And, but also, how can we not?\n\n52:15.900 --> 52:20.900\n It's built into us to do it or die trying.\n\n52:21.380 --> 52:26.380\n I was on Easter Island a few months ago,\n\n52:27.500 --> 52:30.220\n which is, as I'm sure you know, in the middle of the Pacific\n\n52:30.220 --> 52:32.860\n and difficult for people to have got to,\n\n52:32.860 --> 52:34.020\n but they got there.\n\n52:34.020 --> 52:37.260\n And I did think a lot about the way those boats\n\n52:37.260 --> 52:42.100\n must have set out into something like space.\n\n52:42.100 --> 52:47.100\n It was the ocean and how sort of fundamental\n\n52:47.500 --> 52:49.740\n that was to the way we are.\n\n52:49.740 --> 52:53.700\n And it's the one that most excites me\n\n52:53.700 --> 52:55.720\n because it's the one I want most to happen.\n\n52:55.720 --> 52:57.620\n It's the thing, it's the place\n\n52:57.620 --> 52:59.660\n where we could get to as humans.\n\n52:59.660 --> 53:03.620\n Like in a way I could live with us never really unlocking\n\n53:03.620 --> 53:06.260\n fully unlocking the nature of consciousness.\n\n53:06.260 --> 53:09.140\n I'd like to know, I'm really curious,\n\n53:09.140 --> 53:12.020\n but if we never leave the solar system\n\n53:12.020 --> 53:14.300\n and if we never get further out into this galaxy\n\n53:14.300 --> 53:16.900\n or maybe even galaxies beyond our galaxy,\n\n53:16.900 --> 53:20.020\n that would, that feels sad to me\n\n53:20.020 --> 53:24.460\n because it's so limiting.\n\n53:24.460 --> 53:26.860\n Yeah, there's something hopeful and beautiful\n\n53:26.860 --> 53:30.140\n about reaching out any kind of exploration,\n\n53:30.140 --> 53:33.340\n reaching out across Earth centuries ago\n\n53:33.340 --> 53:35.180\n and then reaching out into space.\n\n53:35.180 --> 53:37.100\n So what do you think about colonization of Mars?\n\n53:37.100 --> 53:38.660\n So go to Mars, does that excite you\n\n53:38.660 --> 53:41.300\n the idea of a human being stepping foot on Mars?\n\n53:41.300 --> 53:43.220\n It does, it absolutely does.\n\n53:43.220 --> 53:45.300\n But in terms of what would really excite me,\n\n53:45.300 --> 53:47.160\n it would be leaving the solar system\n\n53:47.160 --> 53:49.040\n in as much as that I just think,\n\n53:49.920 --> 53:52.780\n I think we already know quite a lot about Mars.\n\n53:52.780 --> 53:55.340\n And, but yes, listen, if it happened,\n\n53:55.340 --> 53:58.980\n that would be, I hope I see it in my lifetime.\n\n53:58.980 --> 54:01.060\n I really hope I see it in my lifetime.\n\n54:01.060 --> 54:03.620\n So it would be a wonderful thing.\n\n54:03.620 --> 54:05.420\n Without giving anything away,\n\n54:05.420 --> 54:10.420\n but the series begins with the use of quantum computers.\n\n54:11.220 --> 54:13.180\n The new series does,\n\n54:13.180 --> 54:14.660\n begins with the use of quantum computers\n\n54:14.660 --> 54:17.100\n to simulate basic living organisms,\n\n54:17.100 --> 54:19.280\n or actually I don't know if it's quantum computers are used,\n\n54:19.280 --> 54:22.800\n but basic living organisms are simulated on a screen.\n\n54:22.800 --> 54:24.300\n It's a really cool kind of demo.\n\n54:24.300 --> 54:25.120\n Yeah, that's right.\n\n54:25.120 --> 54:28.180\n They're using, yes, they are using a quantum computer\n\n54:28.180 --> 54:31.660\n to simulate a nematode, yeah.\n\n54:31.660 --> 54:34.780\n So returning to our discussion of simulation,\n\n54:34.780 --> 54:38.760\n or thinking of the universe as a computer,\n\n54:38.760 --> 54:41.180\n do you think the universe is deterministic?\n\n54:41.180 --> 54:42.420\n Is there a free will?\n\n54:43.300 --> 54:46.740\n So with the qualification of what do I know?\n\n54:46.740 --> 54:48.040\n Cause I'm a layman, right?\n\n54:48.040 --> 54:49.360\n Lay person.\n\n54:49.360 --> 54:51.600\n But with a big imagination.\n\n54:51.600 --> 54:52.500\n Thanks.\n\n54:52.500 --> 54:54.660\n With that qualification,\n\n54:54.660 --> 54:56.820\n yup, I think the universe is deterministic\n\n54:56.820 --> 54:58.500\n and I see absolutely,\n\n54:58.500 --> 55:02.300\n I cannot see how free will fits into that.\n\n55:02.300 --> 55:05.060\n So yes, deterministic, no free will.\n\n55:05.060 --> 55:07.140\n That would be my position.\n\n55:07.140 --> 55:09.420\n And how does that make you feel?\n\n55:09.420 --> 55:12.380\n It partly makes me feel that it's exactly in keeping\n\n55:12.380 --> 55:14.420\n with the way these things tend to work out,\n\n55:14.420 --> 55:17.140\n which is that we have an incredibly strong sense\n\n55:17.140 --> 55:18.660\n that we do have free will.\n\n55:20.740 --> 55:24.300\n And just as we have an incredibly strong sense\n\n55:24.300 --> 55:26.180\n that time is a constant,\n\n55:26.180 --> 55:30.060\n and turns out probably not to be the case.\n\n55:30.060 --> 55:31.680\n So we're definitely in the case of time,\n\n55:31.680 --> 55:36.080\n but the problem I always have with free will\n\n55:36.080 --> 55:37.940\n is that it gets,\n\n55:37.940 --> 55:40.500\n I can never seem to find the place\n\n55:40.500 --> 55:43.020\n where it is supposed to reside.\n\n55:43.020 --> 55:45.480\n And yet you explore.\n\n55:45.480 --> 55:46.820\n Just a bit of very, very,\n\n55:46.820 --> 55:49.640\n but we have something we can call free will,\n\n55:49.640 --> 55:51.900\n but it's not the thing that we think it is.\n\n55:51.900 --> 55:54.020\n But free will, so do you,\n\n55:54.020 --> 55:55.660\n what we call free will is just.\n\n55:55.660 --> 55:56.940\n What we call it is the illusion of it.\n\n55:56.940 --> 56:00.180\n And that's a subjective experience of the illusion.\n\n56:00.180 --> 56:01.620\n Which is a useful thing to have.\n\n56:01.620 --> 56:04.500\n And it partly comes down to,\n\n56:04.500 --> 56:06.860\n although we live in a deterministic universe,\n\n56:06.860 --> 56:08.540\n our brains are not very well equipped\n\n56:08.540 --> 56:11.160\n to fully determine the deterministic universe.\n\n56:11.160 --> 56:12.860\n So we're constantly surprised\n\n56:12.860 --> 56:15.620\n and feel like we're making snap decisions\n\n56:15.620 --> 56:17.540\n based on imperfect information.\n\n56:17.540 --> 56:19.980\n So that feels a lot like free will.\n\n56:19.980 --> 56:21.300\n It just isn't.\n\n56:21.300 --> 56:24.220\n Would be my, that's my guess.\n\n56:24.220 --> 56:27.060\n So in that sense, your sort of sense\n\n56:27.060 --> 56:30.780\n is that you can unroll the universe forward or backward\n\n56:30.780 --> 56:33.340\n and you will see the same thing.\n\n56:33.340 --> 56:36.700\n And you would, I mean, that notion.\n\n56:36.700 --> 56:38.940\n Yeah, sort of, sort of.\n\n56:38.940 --> 56:40.300\n But yeah, sorry, go ahead.\n\n56:40.300 --> 56:44.900\n I mean, that notion is a bit uncomfortable\n\n56:44.900 --> 56:45.940\n to think about.\n\n56:45.940 --> 56:48.840\n That it's, you can roll it back.\n\n56:50.220 --> 56:53.380\n And forward and.\n\n56:53.380 --> 56:55.060\n Well, if you were able to do it,\n\n56:55.060 --> 56:58.160\n it would certainly have to be a quantum computer.\n\n56:58.160 --> 57:00.940\n Something that worked in a quantum mechanical way\n\n57:00.940 --> 57:05.940\n in order to understand a quantum mechanical system, I guess.\n\n57:07.660 --> 57:09.980\n And so that unrolling, there might be a multiverse thing\n\n57:09.980 --> 57:11.180\n where there's a bunch of branching.\n\n57:11.180 --> 57:12.140\n Well, exactly.\n\n57:12.140 --> 57:14.160\n Because it wouldn't follow that every time\n\n57:14.160 --> 57:15.540\n you roll it back or forward,\n\n57:15.540 --> 57:17.980\n you'd get exactly the same result.\n\n57:17.980 --> 57:21.420\n Which is another thing that's hard to wrap your mind around.\n\n57:21.420 --> 57:24.660\n So yeah, but that, yes.\n\n57:24.660 --> 57:27.260\n But essentially what you just described, that.\n\n57:27.260 --> 57:29.700\n The yes forwards and yes backwards,\n\n57:29.700 --> 57:31.860\n but you might get a slightly different result\n\n57:31.860 --> 57:33.400\n or a very different result.\n\n57:33.400 --> 57:34.500\n Or very different.\n\n57:34.500 --> 57:36.460\n Along the same lines, you've explored\n\n57:36.460 --> 57:39.820\n some really deep scientific ideas in this new series.\n\n57:39.820 --> 57:41.620\n And I mean, just in general,\n\n57:41.620 --> 57:44.780\n you're unafraid to ground yourself\n\n57:44.780 --> 57:49.460\n in some of the most amazing scientific ideas of our time.\n\n57:49.460 --> 57:51.420\n What are the things you've learned\n\n57:51.420 --> 57:53.500\n or ideas you find beautiful and mysterious\n\n57:53.500 --> 57:55.340\n about quantum mechanics, multiverse,\n\n57:55.340 --> 57:58.140\n string theory, quantum computing that you've learned?\n\n57:58.140 --> 58:01.260\n Well, I would have to say every single thing\n\n58:01.260 --> 58:03.120\n I've learned is beautiful.\n\n58:03.120 --> 58:06.560\n And one of the motivators for me is that\n\n58:06.560 --> 58:11.560\n I think that people tend not to see scientific thinking\n\n58:13.620 --> 58:17.420\n as being essentially poetic and lyrical.\n\n58:17.420 --> 58:20.860\n But I think that is literally exactly what it is.\n\n58:20.860 --> 58:23.940\n And I think the idea of entanglement\n\n58:23.940 --> 58:25.800\n or the idea of superpositions,\n\n58:25.800 --> 58:28.220\n or the fact that you could even demonstrate a superposition\n\n58:28.220 --> 58:31.220\n or have a machine that relies on the existence\n\n58:31.220 --> 58:33.540\n of superpositions in order to function,\n\n58:33.540 --> 58:36.940\n to me is almost indescribably beautiful.\n\n58:39.420 --> 58:41.020\n It fills me with awe.\n\n58:41.020 --> 58:42.420\n It fills me with awe.\n\n58:42.420 --> 58:47.420\n And also it's not just a sort of grand, massive awe of,\n\n58:49.420 --> 58:51.460\n but it's also delicate.\n\n58:51.460 --> 58:54.180\n It's very, very delicate and subtle.\n\n58:54.180 --> 58:59.180\n And it has these beautiful sort of nuances in it.\n\n58:59.940 --> 59:03.480\n And also these completely paradigm changing\n\n59:03.480 --> 59:04.460\n thoughts and truths.\n\n59:04.460 --> 59:08.740\n So it's as good as it gets as far as I can tell.\n\n59:08.740 --> 59:10.940\n So broadly everything.\n\n59:10.940 --> 59:12.900\n That doesn't mean I believe everything I read\n\n59:12.900 --> 59:14.280\n in quantum physics.\n\n59:14.280 --> 59:17.340\n Because obviously a lot of the interpretations\n\n59:17.340 --> 59:18.980\n are completely in conflict with each other.\n\n59:18.980 --> 59:22.380\n And who knows whether string theory\n\n59:22.380 --> 59:25.060\n will turn out to be a good description or not.\n\n59:25.060 --> 59:29.160\n But the beauty in it, it seems undeniable.\n\n59:29.160 --> 59:34.160\n And I do wish people more readily understood\n\n59:34.160 --> 59:39.160\n how beautiful and poetic science is, I would say.\n\n59:41.720 --> 59:43.120\n Science is poetry.\n\n59:44.360 --> 59:49.360\n In terms of quantum computing being used to simulate things\n\n59:51.880 --> 59:54.640\n or just in general, the idea of simulating,\n\n59:54.640 --> 59:56.800\n simulating small parts of our world,\n\n59:56.800 --> 1:00:00.560\n which actually current physicists are really excited about\n\n1:00:00.560 --> 1:00:02.720\n simulating small quantum mechanical systems\n\n1:00:02.720 --> 1:00:03.880\n on quantum computers.\n\n1:00:03.880 --> 1:00:05.660\n But scaling that up to something bigger,\n\n1:00:05.660 --> 1:00:07.260\n like simulating life forms.\n\n1:00:09.000 --> 1:00:11.360\n How do you think, what are the possible trajectories\n\n1:00:11.360 --> 1:00:14.280\n of that going wrong or going right\n\n1:00:14.280 --> 1:00:16.660\n if you unroll that into the future?\n\n1:00:17.920 --> 1:00:21.260\n Well, if a bit like Ava and her robotics,\n\n1:00:21.260 --> 1:00:26.260\n you park the sheer complexity of what you're trying to do.\n\n1:00:26.260 --> 1:00:31.260\n The issues are, I think it will have a profound,\n\n1:00:35.780 --> 1:00:37.500\n if you were able to have a machine\n\n1:00:37.500 --> 1:00:40.660\n that was able to project forwards and backwards accurately,\n\n1:00:40.660 --> 1:00:42.820\n it would in an empirical way show,\n\n1:00:42.820 --> 1:00:45.100\n it would demonstrate that you don't have free will.\n\n1:00:45.100 --> 1:00:47.300\n So the first thing that would happen is people\n\n1:00:47.300 --> 1:00:51.700\n would have to really take on a very, very different idea\n\n1:00:51.700 --> 1:00:53.660\n of what they were.\n\n1:00:53.660 --> 1:00:56.380\n The thing that they truly, truly believe they are,\n\n1:00:56.380 --> 1:00:57.580\n they are not.\n\n1:00:57.580 --> 1:01:01.260\n And so that I suspect would be very, very disturbing\n\n1:01:01.260 --> 1:01:02.340\n to a lot of people.\n\n1:01:02.340 --> 1:01:04.560\n Do you think that has a positive or negative effect\n\n1:01:04.560 --> 1:01:08.860\n on society, the realization that you are not,\n\n1:01:08.860 --> 1:01:11.060\n you cannot control your actions essentially,\n\n1:01:11.060 --> 1:01:13.460\n I guess is the way that could be interpreted?\n\n1:01:13.460 --> 1:01:17.500\n Yeah, although in some ways we instinctively understand\n\n1:01:17.500 --> 1:01:20.620\n that already because in the example I gave you of the kid\n\n1:01:20.620 --> 1:01:23.700\n in the stabbing, we would all understand that that kid\n\n1:01:23.700 --> 1:01:25.820\n was not really fully in control of their actions.\n\n1:01:25.820 --> 1:01:29.560\n So it's not an idea that's entirely alien to us, but.\n\n1:01:29.560 --> 1:01:31.060\n I don't know if we understand that.\n\n1:01:31.060 --> 1:01:35.460\n I think there's a bunch of people who see the world\n\n1:01:35.460 --> 1:01:37.460\n that way, but not everybody.\n\n1:01:37.460 --> 1:01:39.600\n Yes, true, of course true.\n\n1:01:39.600 --> 1:01:43.120\n But what this machine would do is prove it beyond any doubt\n\n1:01:43.120 --> 1:01:45.960\n because someone would say, well, I don't believe that's true.\n\n1:01:45.960 --> 1:01:48.240\n And then you'd predict, well, in 10 seconds,\n\n1:01:48.240 --> 1:01:49.080\n you're gonna do this.\n\n1:01:49.080 --> 1:01:50.160\n And they'd say, no, no, I'm not.\n\n1:01:50.160 --> 1:01:51.000\n And then they'd do it.\n\n1:01:51.000 --> 1:01:53.460\n And then determinism would have played its part.\n\n1:01:53.460 --> 1:01:56.020\n But I, or something like that.\n\n1:01:56.020 --> 1:02:00.020\n But actually the exact terms of that thought experiment\n\n1:02:00.020 --> 1:02:03.860\n probably wouldn't play out, but still broadly speaking,\n\n1:02:03.860 --> 1:02:06.180\n you could predict something happening in another room,\n\n1:02:06.180 --> 1:02:08.380\n sort of unseen, I suppose,\n\n1:02:08.380 --> 1:02:10.620\n that foreknowledge would not allow you to affect.\n\n1:02:10.620 --> 1:02:13.340\n So what effect would that have?\n\n1:02:13.340 --> 1:02:15.540\n I think people would find it very disturbing,\n\n1:02:15.540 --> 1:02:17.740\n but then after they'd got over their sense\n\n1:02:17.740 --> 1:02:21.180\n of being disturbed, which by the way,\n\n1:02:21.180 --> 1:02:22.620\n I don't even think you need a machine\n\n1:02:22.620 --> 1:02:24.620\n to take this idea on board.\n\n1:02:24.620 --> 1:02:26.420\n But after they've got over that,\n\n1:02:26.420 --> 1:02:29.780\n they'd still understand that even though I have no free will\n\n1:02:29.780 --> 1:02:33.120\n and my actions are in effect already determined,\n\n1:02:33.980 --> 1:02:35.620\n I still feel things.\n\n1:02:36.540 --> 1:02:39.180\n I still care about stuff.\n\n1:02:39.180 --> 1:02:41.400\n I remember my daughter saying to me,\n\n1:02:43.900 --> 1:02:46.860\n she'd got hold of the idea that my view of the universe\n\n1:02:46.860 --> 1:02:48.420\n made it meaningless.\n\n1:02:48.420 --> 1:02:49.860\n And she said, well, then it's meaningless.\n\n1:02:49.860 --> 1:02:52.580\n And I said, well, I can prove it's not meaningless\n\n1:02:52.580 --> 1:02:56.260\n because you mean something to me and I mean something to you.\n\n1:02:56.260 --> 1:02:58.220\n So it's not completely meaningless\n\n1:02:58.220 --> 1:03:00.500\n because there is a bit of meaning contained\n\n1:03:00.500 --> 1:03:01.420\n within this space.\n\n1:03:01.420 --> 1:03:06.020\n And so with a lack of free will space,\n\n1:03:06.020 --> 1:03:08.300\n you could think, well, this robs me of everything I am.\n\n1:03:08.300 --> 1:03:09.820\n And then you'd say, well, no, it doesn't\n\n1:03:09.820 --> 1:03:12.020\n because you still like eating cheeseburgers\n\n1:03:12.020 --> 1:03:13.860\n and you still like going to see the movies.\n\n1:03:13.860 --> 1:03:17.120\n And so how big a difference does it really make?\n\n1:03:17.980 --> 1:03:21.260\n But I think initially people would find it very disturbing.\n\n1:03:21.260 --> 1:03:24.540\n I think that what would come,\n\n1:03:24.540 --> 1:03:27.880\n if you could really unlock with a determinism machine,\n\n1:03:27.880 --> 1:03:30.260\n everything, there'd be this wonderful wisdom\n\n1:03:30.260 --> 1:03:31.100\n that would come from it.\n\n1:03:31.100 --> 1:03:32.700\n And I'd rather have that than not.\n\n1:03:34.340 --> 1:03:37.180\n So that's a really good example of a technology\n\n1:03:37.180 --> 1:03:40.660\n revealing to us humans something fundamental about our world,\n\n1:03:40.660 --> 1:03:41.740\n about our society.\n\n1:03:41.740 --> 1:03:45.020\n So it's almost this creation\n\n1:03:45.020 --> 1:03:47.780\n is helping us understand ourselves.\n\n1:03:47.780 --> 1:03:51.420\n And the same could be said about artificial intelligence.\n\n1:03:51.420 --> 1:03:55.700\n So what do you think us creating something like Ava\n\n1:03:55.700 --> 1:03:58.140\n will help us understand about ourselves?\n\n1:03:58.140 --> 1:04:00.940\n How will that change society?\n\n1:04:00.940 --> 1:04:04.160\n Well, I would hope it would teach us some humility.\n\n1:04:05.060 --> 1:04:07.400\n Humans are very big on exceptionalism.\n\n1:04:07.400 --> 1:04:12.400\n America is constantly proclaiming itself\n\n1:04:12.800 --> 1:04:15.360\n to be the greatest nation on earth,\n\n1:04:15.360 --> 1:04:18.080\n which it may feel like that if you're an American,\n\n1:04:18.080 --> 1:04:20.680\n but it may not feel like that if you're from Finland,\n\n1:04:20.680 --> 1:04:21.800\n because there's all sorts of things\n\n1:04:21.800 --> 1:04:23.560\n you dearly love about Finland.\n\n1:04:23.560 --> 1:04:27.320\n And exceptionalism is usually bullshit.\n\n1:04:28.200 --> 1:04:29.060\n Probably not always.\n\n1:04:29.060 --> 1:04:30.000\n If we both sat here,\n\n1:04:30.000 --> 1:04:31.920\n we could find a good example of something that isn't,\n\n1:04:31.920 --> 1:04:34.000\n but as a rule of thumb.\n\n1:04:34.000 --> 1:04:36.120\n And what it would do\n\n1:04:36.120 --> 1:04:39.560\n is it would teach us some humility about,\n\n1:04:40.640 --> 1:04:42.840\n actually often that's what science does in a funny way.\n\n1:04:42.840 --> 1:04:44.400\n It makes us more and more interesting,\n\n1:04:44.400 --> 1:04:46.520\n but it makes us a smaller and smaller part\n\n1:04:46.520 --> 1:04:48.120\n of the thing that's interesting.\n\n1:04:48.120 --> 1:04:50.980\n And I don't mind that humility at all.\n\n1:04:52.200 --> 1:04:53.760\n I don't think it's a bad thing.\n\n1:04:53.760 --> 1:04:57.320\n Our excesses don't tend to come from humility.\n\n1:04:57.320 --> 1:04:59.000\n Our excesses come from the opposite,\n\n1:04:59.000 --> 1:05:00.480\n megalomania and stuff.\n\n1:05:00.480 --> 1:05:02.960\n We tend to think of consciousness\n\n1:05:02.960 --> 1:05:06.880\n as having some form of exceptionalism attached to it.\n\n1:05:06.880 --> 1:05:09.320\n I suspect if we ever unravel it,\n\n1:05:09.320 --> 1:05:13.720\n it will turn out to be less than we thought in a way.\n\n1:05:13.720 --> 1:05:17.780\n And perhaps your very own exceptionalist assertion\n\n1:05:17.780 --> 1:05:19.360\n earlier on in our conversation\n\n1:05:19.360 --> 1:05:23.040\n that consciousness is something belongs to us humans,\n\n1:05:23.040 --> 1:05:25.340\n or not humans, but living organisms,\n\n1:05:25.340 --> 1:05:27.680\n maybe you will one day find out\n\n1:05:27.680 --> 1:05:30.240\n that consciousness is in everything.\n\n1:05:30.240 --> 1:05:32.840\n And that will humble you.\n\n1:05:32.840 --> 1:05:35.660\n If that was true, it would certainly humble me,\n\n1:05:35.660 --> 1:05:39.040\n although maybe, almost maybe, I don't know.\n\n1:05:39.040 --> 1:05:41.040\n I don't know what effect that would have.\n\n1:05:45.560 --> 1:05:48.400\n My understanding of that principle is along the lines of,\n\n1:05:48.400 --> 1:05:52.580\n say, that an electron has a preferred state,\n\n1:05:52.580 --> 1:05:56.600\n or it may or may not pass through a bit of glass.\n\n1:05:56.600 --> 1:05:58.320\n It may reflect off, or it may go through,\n\n1:05:58.320 --> 1:05:59.160\n or something like that.\n\n1:05:59.160 --> 1:06:03.700\n And so that feels as if a choice has been made.\n\n1:06:07.340 --> 1:06:10.820\n But if I'm going down the fully deterministic route,\n\n1:06:10.820 --> 1:06:13.220\n I would say there's just an underlying determinism\n\n1:06:13.220 --> 1:06:14.720\n that has defined that,\n\n1:06:14.720 --> 1:06:16.680\n that has defined the preferred state,\n\n1:06:16.680 --> 1:06:18.840\n or the reflection or non reflection.\n\n1:06:18.840 --> 1:06:19.960\n But look, yeah, you're right.\n\n1:06:19.960 --> 1:06:22.520\n If it turned out that there was a thing\n\n1:06:22.520 --> 1:06:23.920\n that it was like to be the sun,\n\n1:06:23.920 --> 1:06:27.880\n then I'd be amazed and humbled,\n\n1:06:27.880 --> 1:06:30.040\n and I'd be happy to be both, that sounds pretty cool.\n\n1:06:30.040 --> 1:06:32.560\n And you'll say the same thing as you said to your daughter,\n\n1:06:32.560 --> 1:06:35.140\n but it's nevertheless feels something like to be me,\n\n1:06:35.140 --> 1:06:37.960\n and that's pretty damn good.\n\n1:06:39.520 --> 1:06:42.160\n So Kubrick created many masterpieces,\n\n1:06:42.160 --> 1:06:46.040\n including The Shining, Dr. Strangelove, Clockwork Orange.\n\n1:06:46.040 --> 1:06:48.960\n But to me, he will be remembered, I think,\n\n1:06:48.960 --> 1:06:53.160\n to many 100 years from now for 2001 in Space Odyssey.\n\n1:06:53.160 --> 1:06:54.760\n I would say that's his greatest film.\n\n1:06:54.760 --> 1:06:55.600\n I agree.\n\n1:06:55.600 --> 1:07:00.560\n And you are incredibly humble.\n\n1:07:00.560 --> 1:07:02.500\n I listened to a bunch of your interviews,\n\n1:07:02.500 --> 1:07:04.920\n and I really appreciate that you're humble\n\n1:07:04.920 --> 1:07:07.940\n in your creative efforts and your work.\n\n1:07:07.940 --> 1:07:10.200\n But if I were to force you a gunpoint.\n\n1:07:11.460 --> 1:07:12.460\n Do you have a gun?\n\n1:07:13.340 --> 1:07:15.040\n You don't know that, the mystery.\n\n1:07:16.260 --> 1:07:20.120\n It's to imagine 100 years out into the future.\n\n1:07:20.120 --> 1:07:23.460\n What will Alex Carlin be remembered for\n\n1:07:23.460 --> 1:07:25.580\n from something you've created already,\n\n1:07:25.580 --> 1:07:28.100\n or feel you may feel somewhere deep inside\n\n1:07:28.100 --> 1:07:29.320\n you may still create?\n\n1:07:30.180 --> 1:07:33.340\n Well, okay, well, I'll take the question in the spirit\n\n1:07:33.340 --> 1:07:35.520\n it was asked, but very generous.\n\n1:07:36.940 --> 1:07:37.780\n Gunpoint.\n\n1:07:37.780 --> 1:07:38.620\n Yeah.\n\n1:07:42.940 --> 1:07:46.600\n What I try to do, so therefore what I hope,\n\n1:07:48.100 --> 1:07:50.820\n yeah, if I'm remembered, what I might be remembered for,\n\n1:07:50.820 --> 1:07:55.820\n is as someone who participates in a conversation.\n\n1:07:55.860 --> 1:07:58.520\n And I think that often what happens\n\n1:07:58.520 --> 1:08:00.940\n is people don't participate in conversations,\n\n1:08:00.940 --> 1:08:04.480\n they make proclamations, they make statements,\n\n1:08:04.480 --> 1:08:06.820\n and people can either react against the statement\n\n1:08:06.820 --> 1:08:08.720\n or can fall in line behind it.\n\n1:08:08.720 --> 1:08:10.280\n And I don't like that.\n\n1:08:10.280 --> 1:08:13.060\n So I want to be part of a conversation.\n\n1:08:13.060 --> 1:08:15.540\n I take as a sort of basic principle,\n\n1:08:15.540 --> 1:08:17.560\n I think I take lots of my cues from science,\n\n1:08:17.560 --> 1:08:19.340\n but one of the best ones, it seems to me,\n\n1:08:19.340 --> 1:08:22.360\n is that when a scientist has something proved wrong,\n\n1:08:22.360 --> 1:08:24.020\n that they previously believed in,\n\n1:08:24.020 --> 1:08:26.640\n they then have to abandon that position.\n\n1:08:26.640 --> 1:08:28.500\n So I'd like to be someone who is allied\n\n1:08:28.500 --> 1:08:30.340\n to that sort of thinking.\n\n1:08:30.340 --> 1:08:34.340\n So part of an exchange of ideas.\n\n1:08:34.340 --> 1:08:38.140\n And the exchange of ideas for me is something like,\n\n1:08:38.140 --> 1:08:40.940\n people in your world, show me things\n\n1:08:40.940 --> 1:08:42.600\n about how the world works.\n\n1:08:42.600 --> 1:08:44.780\n And then I say, this is how I feel\n\n1:08:44.780 --> 1:08:46.180\n about what you've told me.\n\n1:08:46.180 --> 1:08:47.980\n And then other people can react to that.\n\n1:08:47.980 --> 1:08:52.260\n And it's not to say this is how the world is.\n\n1:08:52.260 --> 1:08:54.560\n It's just to say, it is interesting\n\n1:08:54.560 --> 1:08:56.860\n to think about the world in this way.\n\n1:08:56.860 --> 1:08:59.860\n And the conversation is one of the things\n\n1:08:59.860 --> 1:09:02.260\n I'm really hopeful about in your works.\n\n1:09:02.260 --> 1:09:05.240\n The conversation you're having is with the viewer,\n\n1:09:05.240 --> 1:09:09.180\n in the sense that you're bringing back\n\n1:09:10.220 --> 1:09:13.860\n you and several others, but you very much so,\n\n1:09:13.860 --> 1:09:18.860\n sort of intellectual depth to cinema, to now series,\n\n1:09:21.260 --> 1:09:25.340\n sort of allowing film to be something that,\n\n1:09:26.300 --> 1:09:29.660\n yeah, sparks a conversation, is a conversation,\n\n1:09:29.660 --> 1:09:32.900\n lets people think, allows them to think.\n\n1:09:32.900 --> 1:09:35.180\n But also, it's very important for me\n\n1:09:35.180 --> 1:09:38.540\n that if that conversation is gonna be a good conversation,\n\n1:09:38.540 --> 1:09:42.780\n what that must involve is that someone like you\n\n1:09:42.780 --> 1:09:45.820\n who understands AI, and I imagine understands a lot\n\n1:09:45.820 --> 1:09:48.700\n about quantum mechanics, if they then watch the narrative,\n\n1:09:48.700 --> 1:09:52.100\n feels, yes, this is a fair account.\n\n1:09:52.100 --> 1:09:55.580\n So it is a worthy addition to the conversation.\n\n1:09:55.580 --> 1:09:57.580\n That for me is hugely important.\n\n1:09:57.580 --> 1:09:59.820\n I'm not interested in getting that stuff wrong.\n\n1:09:59.820 --> 1:10:02.060\n I'm only interested in trying to get it right.\n\n1:10:04.140 --> 1:10:06.340\n Alex, it was truly an honor to talk to you.\n\n1:10:06.340 --> 1:10:07.180\n I really appreciate it.\n\n1:10:07.180 --> 1:10:08.000\n I really enjoy it.\n\n1:10:08.000 --> 1:10:08.840\n Thank you so much.\n\n1:10:08.840 --> 1:10:09.660\n Thank you.\n\n1:10:09.660 --> 1:10:10.500\n Thanks, man.\n\n1:10:10.500 --> 1:10:13.280\n Thanks for listening to this conversation\n\n1:10:13.280 --> 1:10:15.200\n with Alex Garland, and thank you\n\n1:10:15.200 --> 1:10:17.360\n to our presenting sponsor, Cash App.\n\n1:10:17.360 --> 1:10:21.280\n Download it, use code LexPodcast, you'll get $10,\n\n1:10:21.280 --> 1:10:23.960\n and $10 will go to FIRST, an organization\n\n1:10:23.960 --> 1:10:26.200\n that inspires and educates young minds\n\n1:10:26.200 --> 1:10:29.000\n to become science and technology innovators of tomorrow.\n\n1:10:29.900 --> 1:10:32.560\n If you enjoy this podcast, subscribe on YouTube,\n\n1:10:32.560 --> 1:10:34.480\n give it five stars on Apple Podcast,\n\n1:10:34.480 --> 1:10:36.880\n support it on Patreon, or simply connect with me\n\n1:10:36.880 --> 1:10:38.960\n on Twitter, at Lex Friedman.\n\n1:10:38.960 --> 1:10:43.480\n And now, let me leave you with a question from Ava,\n\n1:10:43.480 --> 1:10:45.880\n the central artificial intelligence character\n\n1:10:45.880 --> 1:10:48.840\n in the movie Ex Machina, that she asked\n\n1:10:48.840 --> 1:10:50.420\n during her Turing test.\n\n1:10:51.440 --> 1:10:54.560\n What will happen to me if I fail your test?\n\n1:10:54.560 --> 1:11:10.560\n Thank you for listening, and hope to see you next time.\n\n"
}
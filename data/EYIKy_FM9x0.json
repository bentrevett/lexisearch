{
  "title": "Michael I. Jordan: Machine Learning, Recommender Systems, and Future of AI | Lex Fridman Podcast #74",
  "id": "EYIKy_FM9x0",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:05.620\n The following is a conversation with Michael I. Jordan, a professor at Berkeley and one\n\n00:05.620 --> 00:10.280\n of the most influential people in the history of machine learning, statistics, and artificial\n\n00:10.280 --> 00:11.280\n intelligence.\n\n00:11.280 --> 00:17.640\n He has been cited over 170,000 times and he has mentored many of the world class researchers\n\n00:17.640 --> 00:25.480\n defining the field of AI today, including Andrew Ng, Zubin Garamani, Ben Taskar, and\n\n00:25.480 --> 00:27.640\n Yoshua Bengio.\n\n00:27.640 --> 00:34.560\n All this, to me, is as impressive as the over 32,000 points in the six NBA championships\n\n00:34.560 --> 00:38.120\n of the Michael J. Jordan of basketball fame.\n\n00:38.120 --> 00:43.200\n There's a nonzero probability that I talked to the other Michael Jordan given my connection\n\n00:43.200 --> 00:48.480\n to and love of the Chicago Bulls of the 90s, but if I had to pick one, I'm going with\n\n00:48.480 --> 00:54.160\n the Michael Jordan of statistics and computer science, or as Yann LeCun calls him, the Miles\n\n00:54.160 --> 00:56.080\n Davis of machine learning.\n\n00:56.080 --> 01:01.560\n In his blog post titled Artificial Intelligence, the Revolution Hasn't Happened Yet, Michael\n\n01:01.560 --> 01:05.560\n argues for broadening the scope of the artificial intelligence field.\n\n01:05.560 --> 01:12.080\n In many ways, the underlying spirit of this podcast is the same, to see artificial intelligence\n\n01:12.080 --> 01:18.660\n as a deeply human endeavor, to not only engineer algorithms and robots, but to understand and\n\n01:18.660 --> 01:25.120\n empower human beings at all levels of abstraction, from the individual to our civilization as\n\n01:25.120 --> 01:26.800\n a whole.\n\n01:26.800 --> 01:29.480\n This is the Artificial Intelligence Podcast.\n\n01:29.480 --> 01:34.080\n If you enjoy it, subscribe and YouTube, give it five stars at Apple Podcast, support it\n\n01:34.080 --> 01:42.160\n on Patreon, or simply connect with me on Twitter at Lex Friedman spelled F R I D M A N.\n\n01:42.160 --> 01:46.560\n As usual, I'll do one or two minutes of ads now and never any ads in the middle that\n\n01:46.560 --> 01:48.640\n can break the flow of the conversation.\n\n01:48.640 --> 01:54.000\n I hope that works for you and doesn't hurt the listening experience.\n\n01:54.000 --> 01:58.360\n This show is presented by Cash App, the number one finance app in the App Store.\n\n01:58.360 --> 02:02.080\n When you get it, use code LEX PODCAST.\n\n02:02.080 --> 02:06.500\n Cash App lets you send money to friends, buy Bitcoin, and invest in the stock market with\n\n02:06.500 --> 02:08.760\n as little as $1.\n\n02:08.760 --> 02:13.500\n Since Cash App does fractional share trading, let me mention that the order execution algorithm\n\n02:13.500 --> 02:18.480\n that worked behind the scenes to create the abstraction of the fractional orders is to\n\n02:18.480 --> 02:21.200\n me an algorithmic marvel.\n\n02:21.200 --> 02:26.400\n Great props for the Cash App engineers for solving a hard problem that in the end provides\n\n02:26.400 --> 02:31.140\n an easy interface that takes a step up to the next layer of abstraction over the stock\n\n02:31.140 --> 02:38.440\n market, making trading more accessible for new investors and diversification much easier.\n\n02:38.440 --> 02:42.760\n So once again, if you get Cash App from the App Store or Google Play and use the code\n\n02:42.760 --> 02:49.280\n LEX PODCAST, you'll get $10 and Cash App will also donate $10 to First, one of my favorite\n\n02:49.280 --> 02:55.120\n organizations that is helping to advance robotics and STEM education for young people around\n\n02:55.120 --> 02:57.120\n the world.\n\n02:57.120 --> 03:02.760\n And now, here's my conversation with Michael I. Jordan.\n\n03:02.760 --> 03:06.480\n Given that you're one of the greats in the field of AI, machine learning, computer science,\n\n03:06.480 --> 03:14.000\n and so on, you're trivially called the Michael Jordan of machine learning, although as you\n\n03:14.000 --> 03:19.680\n know, you were born first, so technically MJ is the Michael I. Jordan of basketball.\n\n03:19.680 --> 03:25.520\n But anyway, my favorite is Yann LeCun calling you the Miles Davis of machine learning because\n\n03:25.520 --> 03:30.600\n as he says, you reinvent yourself periodically and sometimes leave fans scratching their\n\n03:30.600 --> 03:32.460\n heads after you change direction.\n\n03:32.460 --> 03:38.840\n So can you put at first your historian hat on and give a history of computer science\n\n03:38.840 --> 03:46.040\n and AI as you saw it, as you experienced it, including the four generations of AI successes\n\n03:46.040 --> 03:47.800\n that I've seen you talk about?\n\n03:47.800 --> 03:48.800\n Sure.\n\n03:48.800 --> 03:54.040\n Yeah, first of all, I much prefer Yann's metaphor.\n\n03:54.040 --> 04:00.020\n Miles Davis was a real explorer in jazz and he had a coherent story.\n\n04:00.020 --> 04:04.320\n So I think I have one, but it's not just the one you lived, it's the one you think about\n\n04:04.320 --> 04:05.320\n later.\n\n04:05.320 --> 04:09.920\n What the historian does is they look back and they revisit.\n\n04:09.920 --> 04:16.520\n I think what's happening right now is not AI, that was an intellectual aspiration that's\n\n04:16.520 --> 04:18.640\n still alive today as an aspiration.\n\n04:18.640 --> 04:22.480\n But I think this is akin to the development of chemical engineering from chemistry or\n\n04:22.480 --> 04:25.900\n electrical engineering from electromagnetism.\n\n04:25.900 --> 04:31.040\n So if you go back to the 30s or 40s, there wasn't yet chemical engineering.\n\n04:31.040 --> 04:35.600\n There was chemistry, there was fluid flow, there was mechanics and so on.\n\n04:35.600 --> 04:41.280\n But people pretty clearly viewed interesting goals to try to build factories that make\n\n04:41.280 --> 04:48.060\n chemicals products and do it viably, safely, make good ones, do it at scale.\n\n04:48.060 --> 04:52.160\n So people started to try to do that, of course, and some factories worked, some didn't, some\n\n04:52.160 --> 04:58.200\n were not viable, some exploded, but in parallel, developed a whole field called chemical engineering.\n\n04:58.200 --> 05:02.040\n Electrical engineering is a field, it's no bones about it, it has theoretical aspects\n\n05:02.040 --> 05:04.720\n to it, it has practical aspects.\n\n05:04.720 --> 05:09.640\n It's not just engineering, quote unquote, it's the real thing, real concepts are needed.\n\n05:09.640 --> 05:11.680\n Same thing with electrical engineering.\n\n05:11.680 --> 05:16.620\n There was Maxwell's equations, which in some sense were everything you know about electromagnetism,\n\n05:16.620 --> 05:19.120\n but you needed to figure out how to build circuits, how to build modules, how to put\n\n05:19.120 --> 05:22.920\n them together, how to bring electricity from one point to another safely and so on and\n\n05:22.920 --> 05:23.920\n so forth.\n\n05:23.920 --> 05:26.080\n So a whole field that developed called electrical engineering.\n\n05:26.080 --> 05:33.320\n I think that's what's happening right now, is that we have a proto field, which is statistics,\n\n05:33.320 --> 05:36.560\n more of the theoretical side of it, algorithmic side of computer science, that was enough\n\n05:36.560 --> 05:39.240\n to start to build things, but what things?\n\n05:39.240 --> 05:44.120\n Systems that bring value to human beings and use human data and mix in human decisions.\n\n05:44.120 --> 05:47.620\n The engineering side of that is all ad hoc.\n\n05:47.620 --> 05:48.620\n That's what's emerging.\n\n05:48.620 --> 05:51.560\n In fact, if you wanna call machine learning a field, I think that's what it is, that it's\n\n05:51.560 --> 05:56.600\n a proto form of engineering based on statistical and computational ideas of previous generations.\n\n05:56.600 --> 06:01.280\n But do you think there's something deeper about AI in his dreams and aspirations as\n\n06:01.280 --> 06:03.840\n compared to chemical engineering and electrical engineering?\n\n06:03.840 --> 06:07.960\n Well the dreams and aspirations maybe, but those are 500 years from now.\n\n06:07.960 --> 06:10.480\n I think that that's like the Greeks sitting there and saying, it would be neat to get\n\n06:10.480 --> 06:12.920\n to the moon someday.\n\n06:12.920 --> 06:16.200\n I think we have no clue how the brain does computation.\n\n06:16.200 --> 06:17.560\n We're just a clueless.\n\n06:17.560 --> 06:23.600\n We're even worse than the Greeks on most anything interesting scientifically of our era.\n\n06:23.600 --> 06:29.100\n Can you linger on that just for a moment because you stand not completely unique, but a little\n\n06:29.100 --> 06:31.400\n bit unique in the clarity of that.\n\n06:31.400 --> 06:36.760\n Can you elaborate your intuition of why we're, like where we stand in our understanding of\n\n06:36.760 --> 06:37.760\n the human brain?\n\n06:37.760 --> 06:41.280\n And a lot of people say, you know, scientists say we're not very far in understanding human\n\n06:41.280 --> 06:44.560\n brain, but you're like, you're saying we're in the dark here.\n\n06:44.560 --> 06:45.960\n Well, I know I'm not unique.\n\n06:45.960 --> 06:49.240\n I don't even think in the clarity, but if you talk to real neuroscientists that really\n\n06:49.240 --> 06:53.480\n study real synapses or real neurons, they agree, they agree.\n\n06:53.480 --> 06:58.680\n It's a hundreds of year task and they're building it up slowly and surely.\n\n06:58.680 --> 07:00.920\n What the signal is there is not clear.\n\n07:00.920 --> 07:02.700\n We think we have all of our metaphors.\n\n07:02.700 --> 07:08.240\n We think it's electrical, maybe it's chemical, it's a whole soup, it's ions and proteins\n\n07:08.240 --> 07:09.240\n and it's a cell.\n\n07:09.240 --> 07:11.080\n And that's even around like a single synapse.\n\n07:11.080 --> 07:15.920\n If you look at a electron micrograph of a single synapse, it's a city of its own.\n\n07:15.920 --> 07:20.800\n And that's one little thing on a dendritic tree, which is extremely complicated electrochemical\n\n07:20.800 --> 07:22.000\n thing.\n\n07:22.000 --> 07:25.760\n And it's doing these spikes and voltages are flying around and then proteins are taking\n\n07:25.760 --> 07:29.440\n that and taking it down into the DNA and who knows what.\n\n07:29.440 --> 07:31.760\n So it is the problem of the next few centuries.\n\n07:31.760 --> 07:33.360\n It is fantastic.\n\n07:33.360 --> 07:34.940\n But we have our metaphors about it.\n\n07:34.940 --> 07:36.160\n Is it an economic device?\n\n07:36.160 --> 07:42.040\n Is it like the immune system or is it like a layered set of, you know, arithmetic computations?\n\n07:42.040 --> 07:44.780\n We have all these metaphors and they're fun.\n\n07:44.780 --> 07:48.120\n But that's not real science per se.\n\n07:48.120 --> 07:49.120\n There is neuroscience.\n\n07:49.120 --> 07:50.120\n That's not neuroscience.\n\n07:50.120 --> 07:51.120\n All right.\n\n07:51.120 --> 07:55.380\n That's like the Greek speculating about how to get to the moon, fun, right?\n\n07:55.380 --> 07:59.040\n And I think that I like to say this fairly strongly because I think a lot of young people\n\n07:59.040 --> 08:03.440\n think we're on the verge because a lot of people who don't talk about it clearly let\n\n08:03.440 --> 08:07.520\n it be understood that, yes, we kind of, this is a brain inspired, we're kind of close,\n\n08:07.520 --> 08:10.280\n you know, breakthroughs are on the horizon.\n\n08:10.280 --> 08:13.600\n And that's scrupulous people sometimes who need money for their labs.\n\n08:13.600 --> 08:18.680\n That's what I'm saying, scrupulous, but people will oversell, I need money for my lab, I'm\n\n08:18.680 --> 08:23.880\n studying computational neuroscience, I'm going to oversell it.\n\n08:23.880 --> 08:25.200\n And so there's been too much of that.\n\n08:25.200 --> 08:32.040\n So I'll step into the gray area between metaphor and engineering with, I'm not sure if you're\n\n08:32.040 --> 08:35.520\n familiar with brain computer interfaces.\n\n08:35.520 --> 08:42.240\n So a company like Elon Musk has Neuralink that's working on putting electrodes into\n\n08:42.240 --> 08:46.520\n the brain and trying to be able to read, both read and send electrical signals.\n\n08:46.520 --> 08:54.320\n Just as you said, even the basic mechanism of communication in the brain is not something\n\n08:54.320 --> 08:55.320\n we understand.\n\n08:55.320 --> 09:00.880\n But do you hope without understanding the fundamental principles of how the brain works,\n\n09:00.880 --> 09:06.600\n we'll be able to do something interesting at that gray area of metaphor?\n\n09:06.600 --> 09:07.600\n It's not my area.\n\n09:07.600 --> 09:11.200\n So I hope in the sense, like anybody else hopes for some interesting things to happen\n\n09:11.200 --> 09:15.600\n from research, I would expect more something like Alzheimer's will get figured out from\n\n09:15.600 --> 09:16.600\n modern neuroscience.\n\n09:16.600 --> 09:22.560\n There's a lot of human suffering based on brain disease and we throw things like lithium\n\n09:22.560 --> 09:25.900\n at the brain, it kind of works, no one has a clue why.\n\n09:25.900 --> 09:28.240\n That's not quite true, but mostly we don't know.\n\n09:28.240 --> 09:31.940\n And that's even just about the biochemistry of the brain and how it leads to mood swings\n\n09:31.940 --> 09:33.120\n and so on.\n\n09:33.120 --> 09:38.160\n How thought emerges from that, we were really, really completely dim.\n\n09:38.160 --> 09:41.540\n So that you might want to hook up electrodes and try to do some signal processing on that\n\n09:41.540 --> 09:45.640\n and try to find patterns, fine, by all means, go for it.\n\n09:45.640 --> 09:48.740\n It's just not scientific at this point.\n\n09:48.740 --> 09:53.220\n So it's like kind of sitting in a satellite and watching the emissions from a city and\n\n09:53.220 --> 09:57.680\n trying to infer things about the microeconomy, even though you don't have microeconomic concepts.\n\n09:57.680 --> 09:59.200\n It's really that kind of thing.\n\n09:59.200 --> 10:02.520\n And so yes, can you find some signals that do something interesting or useful?\n\n10:02.520 --> 10:06.640\n Can you control a cursor or mouse with your brain?\n\n10:06.640 --> 10:13.240\n Yeah, absolutely, and then I can imagine business models based on that and even medical applications\n\n10:13.240 --> 10:14.240\n of that.\n\n10:14.240 --> 10:19.680\n But from there to understanding algorithms that allow us to really tie in deeply from\n\n10:19.680 --> 10:22.580\n the brain to computer, I just, no, I don't agree with Elon Musk.\n\n10:22.580 --> 10:26.580\n I don't think that's even, that's not for our generations, not even for the century.\n\n10:26.580 --> 10:33.580\n So just in hopes of getting you to dream, you've mentioned Kolmogorov and Turing might\n\n10:33.580 --> 10:41.120\n pop up, do you think that there might be breakthroughs that will get you to sit back in five, 10\n\n10:41.120 --> 10:43.160\n years and say, wow?\n\n10:43.160 --> 10:49.240\n Oh, I'm sure there will be, but I don't think that there'll be demos that impress me.\n\n10:49.240 --> 10:55.120\n I don't think that having a computer call a restaurant and pretend to be a human is\n\n10:55.120 --> 10:56.120\n a breakthrough.\n\n10:56.120 --> 10:57.120\n Right.\n\n10:57.120 --> 10:59.840\n And people, you know, some people present it as such.\n\n10:59.840 --> 11:01.660\n It's imitating human intelligence.\n\n11:01.660 --> 11:07.400\n It's even putting coughs in the thing to make a bit of a PR stunt.\n\n11:07.400 --> 11:11.440\n And so fine that the world runs on those things too.\n\n11:11.440 --> 11:14.940\n And I don't want to diminish all the hard work and engineering that goes behind things\n\n11:14.940 --> 11:17.760\n like that and the ultimate value to the human race.\n\n11:17.760 --> 11:20.520\n But that's not scientific understanding.\n\n11:20.520 --> 11:23.880\n And I know the people that work on these things, they are after scientific understanding.\n\n11:23.880 --> 11:26.780\n In the meantime, they've got to kind of, you know, the trains got to run and they got mouths\n\n11:26.780 --> 11:30.460\n to feed and they got things to do and there's nothing wrong with all that.\n\n11:30.460 --> 11:32.560\n I would call that though, just engineering.\n\n11:32.560 --> 11:35.960\n And I want to distinguish that between an engineering field, like electrical engineering\n\n11:35.960 --> 11:39.360\n and chemical engineering that originally emerged, that had real principles and you really know\n\n11:39.360 --> 11:43.680\n what you're doing and you had a little scientific understanding, maybe not even complete.\n\n11:43.680 --> 11:49.040\n So it became more predictable and it really gave value to human life because it was understood.\n\n11:49.040 --> 11:54.180\n And so we don't want to muddle too much these waters of, you know, what we're able to do\n\n11:54.180 --> 11:58.080\n versus what we really can't do in a way that's going to impress the next.\n\n11:58.080 --> 12:02.520\n So I don't need to be wowed, but I think that someone comes along in 20 years, a younger\n\n12:02.520 --> 12:08.400\n person who's absorbed all the technology and for them to be wowed, I think they have to\n\n12:08.400 --> 12:09.400\n be more deeply impressed.\n\n12:09.400 --> 12:13.020\n A young Kolmogorov would not be wowed by some of the stunts that you see right now coming\n\n12:13.020 --> 12:14.020\n from the big companies.\n\n12:14.020 --> 12:19.040\n The demos, but do you think the breakthroughs from Kolmogorov would be, and give this question\n\n12:19.040 --> 12:24.120\n a chance, do you think there'll be in the scientific fundamental principles arena or\n\n12:24.120 --> 12:28.400\n do you think it's possible to have fundamental breakthroughs in engineering?\n\n12:28.400 --> 12:33.200\n Meaning, you know, I would say some of the things that Elon Musk is working with SpaceX\n\n12:33.200 --> 12:39.840\n and then others sort of trying to revolutionize the fundamentals of engineering, of manufacturing,\n\n12:39.840 --> 12:44.480\n of saying, here's a problem we know how to do a demo of and actually taking it to scale.\n\n12:44.480 --> 12:45.480\n Yeah.\n\n12:45.480 --> 12:46.960\n So there's going to be all kinds of breakthroughs.\n\n12:46.960 --> 12:48.280\n I just don't like that terminology.\n\n12:48.280 --> 12:52.000\n I'm a scientist and I work on things day in and day out and things move along and eventually\n\n12:52.000 --> 12:56.400\n you say, wow, something happened, but I don't like that language very much.\n\n12:56.400 --> 13:01.000\n Also I don't like to prize theoretical breakthroughs over practical ones.\n\n13:01.000 --> 13:05.080\n I tend to be more of a theoretician and I think there's lots to do in that arena right\n\n13:05.080 --> 13:06.760\n now.\n\n13:06.760 --> 13:09.800\n And so I wouldn't point to the Kolmogorovs, I might point to the Edisons of the era and\n\n13:09.800 --> 13:11.840\n maybe Musk is a bit more like that.\n\n13:11.840 --> 13:17.440\n But you know, Musk, God bless him, also will say things about AI that he knows very little\n\n13:17.440 --> 13:23.840\n about and he leads people astray when he talks about things he doesn't know anything about.\n\n13:23.840 --> 13:27.360\n Trying to program a computer to understand natural language, to be involved in a dialogue\n\n13:27.360 --> 13:30.460\n we're having right now, that ain't going to happen in our lifetime.\n\n13:30.460 --> 13:35.240\n You could fake it, you can mimic, sort of take old sentences that humans use and retread\n\n13:35.240 --> 13:38.560\n them, but the deep understanding of language, no, it's not going to happen.\n\n13:38.560 --> 13:42.960\n And so from that, I hope you can perceive that the deeper, yet deeper kind of aspects\n\n13:42.960 --> 13:44.520\n and intelligence are not going to happen.\n\n13:44.520 --> 13:45.520\n Now will there be breakthroughs?\n\n13:45.520 --> 13:49.600\n No, I think that Google was a breakthrough, I think Amazon is a breakthrough, you know,\n\n13:49.600 --> 13:53.280\n I think Uber is a breakthrough, you know, that bring value to human beings at scale\n\n13:53.280 --> 13:56.880\n in new, brand new ways based on data flows and so on.\n\n13:56.880 --> 14:01.260\n A lot of these things are slightly broken because there's not kind of an engineering\n\n14:01.260 --> 14:06.680\n field that takes economic value in context of data and, you know, planetary scale and\n\n14:06.680 --> 14:11.240\n worries about all the externalities, the privacy, you know, we don't have that field so we don't\n\n14:11.240 --> 14:13.200\n think these things through very well.\n\n14:13.200 --> 14:17.560\n I see that as emerging and that will be, you know, looking back from 100 years, that will\n\n14:17.560 --> 14:21.240\n be a constituted breakthrough in this era, just like electrical engineering was a breakthrough\n\n14:21.240 --> 14:24.560\n in the early part of the last century and chemical engineering was a breakthrough.\n\n14:24.560 --> 14:30.360\n So the scale, the markets that you talk about and we'll get to will be seen as sort of breakthrough\n\n14:30.360 --> 14:34.360\n and we're in the very early days of really doing interesting stuff there and we'll get\n\n14:34.360 --> 14:40.920\n to that, but just taking a quick step back, can you give, kind of throw off the historian\n\n14:40.920 --> 14:41.920\n hat.\n\n14:41.920 --> 14:47.760\n I mean, you briefly said that the history of AI kind of mimics the history of chemical\n\n14:47.760 --> 14:49.240\n engineering, but...\n\n14:49.240 --> 14:50.360\n I keep saying machine learning.\n\n14:50.360 --> 14:54.280\n You keep wanting to say AI, just to let you know, I don't, you know, I resist that.\n\n14:54.280 --> 15:01.080\n I don't think this is about AI really was John McCarthy as almost a philosopher saying,\n\n15:01.080 --> 15:03.560\n wouldn't it be cool if we could put thought in a computer?\n\n15:03.560 --> 15:08.040\n If we could mimic the human capability to think or put intelligence in, in some sense\n\n15:08.040 --> 15:09.960\n into a computer.\n\n15:09.960 --> 15:13.560\n That's an interesting philosophical question and he wanted to make it more than philosophy.\n\n15:13.560 --> 15:17.340\n He wanted to actually write down a logical formula and algorithms that would do that.\n\n15:17.340 --> 15:20.180\n And that is a perfectly valid, reasonable thing to do.\n\n15:20.180 --> 15:23.080\n That's not what's happening in this era.\n\n15:23.080 --> 15:27.760\n So the reason I keep saying AI actually, and I'd love to hear what you think about it.\n\n15:27.760 --> 15:34.640\n Machine learning has a very particular set of methods and tools.\n\n15:34.640 --> 15:37.720\n Maybe your version of it is that mine doesn't, it's very, very open.\n\n15:37.720 --> 15:40.160\n It does optimization, it does sampling, it does...\n\n15:40.160 --> 15:42.920\n So systems that learn is what machine learning is.\n\n15:42.920 --> 15:44.560\n Systems that learn and make decisions.\n\n15:44.560 --> 15:45.560\n And make decisions.\n\n15:45.560 --> 15:49.080\n So it's not just pattern recognition and, you know, finding patterns, it's all about\n\n15:49.080 --> 15:52.560\n making decisions in real worlds and having close feedback loops.\n\n15:52.560 --> 15:58.400\n So something like symbolic AI, expert systems, reasoning systems, knowledge based representation,\n\n15:58.400 --> 16:03.760\n all of those kinds of things, search, does that neighbor fit into what you think of as\n\n16:03.760 --> 16:04.760\n machine learning?\n\n16:04.760 --> 16:07.560\n So I don't even like the word machine learning, I think that what the field you're talking\n\n16:07.560 --> 16:11.720\n about is all about making large collections of decisions under uncertainty by large collections\n\n16:11.720 --> 16:12.720\n of entities.\n\n16:12.720 --> 16:13.720\n Right?\n\n16:13.720 --> 16:16.100\n And there are principles for that, at that scale.\n\n16:16.100 --> 16:19.040\n You don't have to say the principles are for a single entity that's making decisions, single\n\n16:19.040 --> 16:20.560\n agent or single human.\n\n16:20.560 --> 16:22.600\n It really immediately goes to the network of decisions.\n\n16:22.600 --> 16:24.080\n Is a good word for that or no?\n\n16:24.080 --> 16:25.400\n No, there's no good words for any of this.\n\n16:25.400 --> 16:27.240\n That's kind of part of the problem.\n\n16:27.240 --> 16:29.920\n So we can continue the conversation to use AI for all that.\n\n16:29.920 --> 16:35.520\n I just want to kind of raise the flag here that this is not about, we don't know what\n\n16:35.520 --> 16:38.140\n intelligence is and real intelligence.\n\n16:38.140 --> 16:41.000\n We don't know much about abstraction and reasoning at the level of humans.\n\n16:41.000 --> 16:42.000\n We don't have a clue.\n\n16:42.000 --> 16:44.720\n We're not trying to build that because we don't have a clue.\n\n16:44.720 --> 16:45.720\n Eventually it may emerge.\n\n16:45.720 --> 16:48.280\n They'll make, I don't know if there'll be breakthroughs, but eventually we'll start\n\n16:48.280 --> 16:50.160\n to get glimmers of that.\n\n16:50.160 --> 16:51.480\n It's not what's happening right now.\n\n16:51.480 --> 16:52.480\n Okay.\n\n16:52.480 --> 16:53.480\n We're taking data.\n\n16:53.480 --> 16:54.560\n We're trying to make good decisions based on that.\n\n16:54.560 --> 16:55.560\n We're trying to scale.\n\n16:55.560 --> 16:58.260\n We're trying to economically viably, we're trying to build markets.\n\n16:58.260 --> 17:04.680\n We're trying to keep value at that scale and aspects of this will look intelligent.\n\n17:04.680 --> 17:08.120\n Computers were so dumb before, they will seem more intelligent.\n\n17:08.120 --> 17:12.320\n We will use that buzzword of intelligence so we can use it in that sense.\n\n17:12.320 --> 17:17.960\n So machine learning, you can scope it narrowly as just learning from data and pattern recognition.\n\n17:17.960 --> 17:22.140\n But when I talk about these topics, maybe data science is another word you could throw\n\n17:22.140 --> 17:26.880\n in the mix, it really is important that the decisions are as part of it.\n\n17:26.880 --> 17:28.760\n It's consequential decisions in the real world.\n\n17:28.760 --> 17:30.880\n Am I going to have a medical operation?\n\n17:30.880 --> 17:33.480\n Am I going to drive down the street?\n\n17:33.480 --> 17:38.240\n Things where there's scarcity, things that impact other human beings or other environments\n\n17:38.240 --> 17:39.400\n and so on.\n\n17:39.400 --> 17:40.800\n How do I do that based on data?\n\n17:40.800 --> 17:41.800\n How do I do that adaptively?\n\n17:41.800 --> 17:44.160\n How do I use computers to help those kinds of things go forward?\n\n17:44.160 --> 17:45.640\n Whatever you want to call that.\n\n17:45.640 --> 17:46.640\n So let's call it AI.\n\n17:46.640 --> 17:52.960\n Let's agree to call it AI, but let's not say that the goal of that is intelligence.\n\n17:52.960 --> 17:56.640\n The goal of that is really good working systems at planetary scale that we've never seen before.\n\n17:56.640 --> 18:00.800\n So reclaim the word AI from the Dartmouth conference from many decades ago of the dream\n\n18:00.800 --> 18:01.800\n of humans.\n\n18:01.800 --> 18:02.800\n I don't want to reclaim it.\n\n18:02.800 --> 18:03.800\n I want a new word.\n\n18:03.800 --> 18:04.800\n I think it was a bad choice.\n\n18:04.800 --> 18:09.820\n I mean, if you read one of my little things, the history was basically that McCarthy needed\n\n18:09.820 --> 18:14.800\n a new name because cybernetics already existed and he didn't like, no one really liked Norbert\n\n18:14.800 --> 18:15.800\n Wiener.\n\n18:15.800 --> 18:19.560\n Norbert Wiener was kind of an island to himself and he felt that he had encompassed all this\n\n18:19.560 --> 18:21.200\n and in some sense he did.\n\n18:21.200 --> 18:24.400\n You look at the language of cybernetics, it was everything we're talking about.\n\n18:24.400 --> 18:28.200\n It was control theory and signal processing and some notions of intelligence and closed\n\n18:28.200 --> 18:29.440\n feedback loops and data.\n\n18:29.440 --> 18:30.960\n It was all there.\n\n18:30.960 --> 18:34.240\n It's just not a word that lived on partly because of the maybe the personalities.\n\n18:34.240 --> 18:36.720\n But McCarthy needed a new word to say, I'm different from you.\n\n18:36.720 --> 18:38.400\n I'm not part of your show.\n\n18:38.400 --> 18:40.080\n I got my own.\n\n18:40.080 --> 18:46.240\n Invented this word and again, thinking forward about the movies that would be made about\n\n18:46.240 --> 18:48.680\n it, it was a great choice.\n\n18:48.680 --> 18:52.000\n But thinking forward about creating a sober academic and real world discipline, it was\n\n18:52.000 --> 18:56.320\n a terrible choice because it led to promises that are not true that we understand.\n\n18:56.320 --> 18:58.880\n We understand artificial perhaps, but we don't understand intelligence.\n\n18:58.880 --> 19:03.360\n It's a small tangent because you're one of the great personalities of machine learning,\n\n19:03.360 --> 19:06.400\n whatever the heck you call the field.\n\n19:06.400 --> 19:11.880\n Do you think science progresses by personalities or by the fundamental principles and theories\n\n19:11.880 --> 19:15.080\n and research that's outside of personalities?\n\n19:15.080 --> 19:16.080\n Both.\n\n19:16.080 --> 19:17.560\n And I wouldn't say there should be one kind of personality.\n\n19:17.560 --> 19:23.200\n I have mine and I have my preferences and I have a kind of network around me that feeds\n\n19:23.200 --> 19:26.680\n me and some of them agree with me and some of them disagree, but all kinds of personalities\n\n19:26.680 --> 19:28.480\n are needed.\n\n19:28.480 --> 19:31.680\n Right now, I think the personality that it's a little too exuberant, a little bit too ready\n\n19:31.680 --> 19:35.840\n to promise the moon is a little bit too much in ascendance.\n\n19:35.840 --> 19:38.160\n And I do think that there's some good to that.\n\n19:38.160 --> 19:41.580\n It certainly attracts lots of young people to our field, but a lot of those people come\n\n19:41.580 --> 19:47.400\n in with strong misconceptions and they have to then unlearn those and then find something\n\n19:47.400 --> 19:48.880\n to do.\n\n19:48.880 --> 19:52.920\n And so I think there's just got to be some multiple voices and I wasn't hearing enough\n\n19:52.920 --> 19:54.840\n of the more sober voice.\n\n19:54.840 --> 20:02.160\n So as a continuation of a fun tangent and speaking of vibrant personalities, what would\n\n20:02.160 --> 20:07.400\n you say is the most interesting disagreement you have with Jan Lacune?\n\n20:07.400 --> 20:12.520\n So Jan's an old friend and I just say that I don't think we disagree about very much\n\n20:12.520 --> 20:13.520\n really.\n\n20:13.520 --> 20:18.800\n He and I both kind of have a let's build it kind of mentality and does it work kind of\n\n20:18.800 --> 20:21.360\n mentality and kind of concrete.\n\n20:21.360 --> 20:27.120\n We both speak French and we speak French more together and we have a lot in common.\n\n20:27.120 --> 20:31.800\n And so if one wanted to highlight a disagreement, it's not really a fundamental one.\n\n20:31.800 --> 20:35.200\n I think it's just kind of what we're emphasizing.\n\n20:35.200 --> 20:43.440\n Jan has emphasized pattern recognition and has emphasized prediction.\n\n20:43.440 --> 20:45.320\n And it's interesting to try to take that as far as you can.\n\n20:45.320 --> 20:50.600\n If you could do perfect prediction, what would that give you kind of as a thought experiment?\n\n20:50.600 --> 20:55.200\n And I think that's way too limited.\n\n20:55.200 --> 20:56.640\n We cannot do perfect prediction.\n\n20:56.640 --> 20:59.360\n We will never have the data sets that allow me to figure out what you're about ready to\n\n20:59.360 --> 21:00.760\n do, what question you're going to ask next.\n\n21:00.760 --> 21:01.760\n I have no clue.\n\n21:01.760 --> 21:03.320\n I will never know such things.\n\n21:03.320 --> 21:07.520\n Moreover, most of us find ourselves during the day in all kinds of situations we had\n\n21:07.520 --> 21:13.480\n no anticipation of that are kind of very, very novel in various ways.\n\n21:13.480 --> 21:16.340\n And in that moment, we want to think through what we want.\n\n21:16.340 --> 21:19.240\n And also there's going to be market forces acting on us.\n\n21:19.240 --> 21:22.320\n I'd like to go down that street, but now it's full because there's a crane in the street.\n\n21:22.320 --> 21:23.320\n I got it.\n\n21:23.320 --> 21:24.320\n I got to think about that.\n\n21:24.320 --> 21:26.240\n I got to think about what I might really want here.\n\n21:26.240 --> 21:29.520\n And I got to sort of think about how much it costs me to do this action versus this\n\n21:29.520 --> 21:30.520\n action.\n\n21:30.520 --> 21:32.800\n I got to think about the risks involved.\n\n21:32.800 --> 21:37.000\n A lot of our current pattern recognition and prediction systems don't do any risk evaluations.\n\n21:37.000 --> 21:39.000\n They have no error bars, right?\n\n21:39.000 --> 21:41.080\n I got to think about other people's decisions around me.\n\n21:41.080 --> 21:45.560\n I got to think about a collection of my decisions, even just thinking about like a medical treatment,\n\n21:45.560 --> 21:50.480\n you know, I'm not going to take a, the prediction of a neural net about my health, about something\n\n21:50.480 --> 21:51.480\n consequential.\n\n21:51.480 --> 21:54.580\n I'm not about ready to have a heart attack because some number is over 0.7.\n\n21:54.580 --> 21:58.920\n Even if you had all the data in the world that ever been collected about heart attacks\n\n21:58.920 --> 22:02.640\n better than any doctor ever had, I'm not going to trust the output of that neural net to\n\n22:02.640 --> 22:03.640\n predict my heart attack.\n\n22:03.640 --> 22:06.400\n I'm going to want to ask what if questions around that.\n\n22:06.400 --> 22:10.360\n I'm going to want to look at some us or other possible data I didn't have, causal things.\n\n22:10.360 --> 22:13.680\n I'm going to want to have a dialogue with a doctor about things we didn't think about\n\n22:13.680 --> 22:15.480\n when he gathered the data.\n\n22:15.480 --> 22:16.640\n You know, I could go on and on.\n\n22:16.640 --> 22:17.900\n I hope you can see.\n\n22:17.900 --> 22:21.520\n And I don't, I think that if you say predictions, everything that, that, that you're missing\n\n22:21.520 --> 22:23.520\n all of this stuff.\n\n22:23.520 --> 22:28.240\n And so prediction plus decision making is everything, but both of them are equally important.\n\n22:28.240 --> 22:32.520\n And so the field has emphasized prediction, Jan rightly so has seen how powerful that\n\n22:32.520 --> 22:33.660\n is.\n\n22:33.660 --> 22:37.240\n But at the cost of people not being aware that decision making is where the rubber really\n\n22:37.240 --> 22:41.440\n hits the road, where human lives are at stake, where risks are being taken, where you got\n\n22:41.440 --> 22:42.440\n to gather more data.\n\n22:42.440 --> 22:43.640\n You got to think about the error bars.\n\n22:43.640 --> 22:45.920\n You got to think about the consequences of your decisions on others.\n\n22:45.920 --> 22:48.960\n You got to think about the economy around your decisions, blah, blah, blah, blah.\n\n22:48.960 --> 22:52.120\n I'm not the only one working on those, but we're a smaller tribe.\n\n22:52.120 --> 22:56.400\n And right now we're not the one that people talk about the most.\n\n22:56.400 --> 23:00.460\n But you know, if you go out in the real world and industry, you know, at Amazon, I'd say\n\n23:00.460 --> 23:03.720\n half the people there are working on decision making and the other half are doing, you know,\n\n23:03.720 --> 23:04.720\n the pattern recognition.\n\n23:04.720 --> 23:05.720\n It's important.\n\n23:05.720 --> 23:10.160\n And the words of pattern recognition and prediction, I think the distinction there, not to linger\n\n23:10.160 --> 23:16.120\n on words, but the distinction there is more a constrained sort of in the lab data set\n\n23:16.120 --> 23:21.160\n versus decision making is talking about consequential decisions in the real world, under the messiness\n\n23:21.160 --> 23:23.760\n and the uncertainty of the real world.\n\n23:23.760 --> 23:27.480\n And just the whole of it, the whole mess of it that actually touches human beings and\n\n23:27.480 --> 23:28.480\n scale.\n\n23:28.480 --> 23:31.120\n And the forces, that's the distinction.\n\n23:31.120 --> 23:33.840\n It helps add those, that perspective, that broader perspective.\n\n23:33.840 --> 23:34.840\n You're right.\n\n23:34.840 --> 23:35.840\n I totally agree.\n\n23:35.840 --> 23:38.120\n On the other hand, if you're a real prediction person, of course, you want it to be in the\n\n23:38.120 --> 23:39.120\n real world.\n\n23:39.120 --> 23:40.120\n You want to predict real world events.\n\n23:40.120 --> 23:43.200\n I'm just saying that's not possible with just data sets.\n\n23:43.200 --> 23:47.520\n That it has to be in the context of, you know, strategic things that someone's doing, data\n\n23:47.520 --> 23:50.880\n they might gather, things they could have gathered, the reasoning process around data.\n\n23:50.880 --> 23:53.580\n It's not just taking data and making predictions based on the data.\n\n23:53.580 --> 23:58.280\n So one of the things that you're working on, I'm sure there's others working on it, but\n\n23:58.280 --> 24:04.960\n I don't hear often it talked about, especially in the clarity that you talk about it, and\n\n24:04.960 --> 24:10.600\n I think it's both the most exciting and the most concerning area of AI in terms of decision\n\n24:10.600 --> 24:11.600\n making.\n\n24:11.600 --> 24:15.400\n So you've talked about AI systems that help make decisions that scale in a distributed\n\n24:15.400 --> 24:19.720\n way, millions, billions decisions, sort of markets of decisions.\n\n24:19.720 --> 24:24.920\n Can you, as a starting point, sort of give an example of a system that you think about\n\n24:24.920 --> 24:27.240\n when you're thinking about these kinds of systems?\n\n24:27.240 --> 24:31.400\n Yeah, so first of all, you're absolutely getting into some territory, which I will be beyond\n\n24:31.400 --> 24:32.400\n my expertise.\n\n24:32.400 --> 24:35.720\n And there are lots of things that are going to be very not obvious to think about.\n\n24:35.720 --> 24:39.920\n Just like, again, I like to think about history a little bit, but think about put yourself\n\n24:39.920 --> 24:40.920\n back in the sixties.\n\n24:40.920 --> 24:43.440\n There was kind of a banking system that wasn't computerized really.\n\n24:43.440 --> 24:48.160\n There was database theory emerging and database people had to think about how do I actually\n\n24:48.160 --> 24:53.560\n not just move data around, but actual money and have it be, you know, valid and have transactions\n\n24:53.560 --> 24:57.840\n that ATMs happen that are actually, you know, all valid and so on and so forth.\n\n24:57.840 --> 25:01.560\n So that's the kind of issues you get into when you start to get serious about sorts\n\n25:01.560 --> 25:02.960\n of things like this.\n\n25:02.960 --> 25:07.240\n I like to think about as kind of almost a thought experiment to help me think something\n\n25:07.240 --> 25:11.160\n simpler, which is the music market.\n\n25:11.160 --> 25:16.160\n And because there is, to first order, there is no music market in the world right now\n\n25:16.160 --> 25:18.740\n and in our country, for sure.\n\n25:18.740 --> 25:23.720\n There are something called things called record companies and they make money and they prop\n\n25:23.720 --> 25:29.480\n up a few really good musicians and make them superstars and they all make huge amounts\n\n25:29.480 --> 25:30.980\n of money.\n\n25:30.980 --> 25:33.820\n But there's a long tail of huge numbers of people that make lots and lots of really good\n\n25:33.820 --> 25:40.560\n music that is actually listened to by more people than the famous people.\n\n25:40.560 --> 25:41.560\n They are not in a market.\n\n25:41.560 --> 25:42.820\n They cannot have a career.\n\n25:42.820 --> 25:43.880\n They do not make money.\n\n25:43.880 --> 25:47.760\n The creators, the creators, the creators, the so called influencers or whatever that\n\n25:47.760 --> 25:49.340\n diminishes who they are.\n\n25:49.340 --> 25:53.360\n So there are people who make extremely good music, especially in the hip hop or Latin\n\n25:53.360 --> 25:55.260\n world these days.\n\n25:55.260 --> 25:56.320\n They do it on their laptop.\n\n25:56.320 --> 26:01.040\n That's what they do on the weekend and they have another job during the week and they\n\n26:01.040 --> 26:03.920\n put it up on SoundCloud or other sites.\n\n26:03.920 --> 26:04.920\n Eventually it gets streamed.\n\n26:04.920 --> 26:06.140\n It now gets turned into bits.\n\n26:06.140 --> 26:07.720\n It's not economically valuable.\n\n26:07.720 --> 26:08.980\n The information is lost.\n\n26:08.980 --> 26:10.200\n It gets put up there.\n\n26:10.200 --> 26:11.580\n People stream it.\n\n26:11.580 --> 26:16.240\n You walk around in a big city, you see people with headphones, especially young kids listening\n\n26:16.240 --> 26:17.240\n to music all the time.\n\n26:17.240 --> 26:21.080\n If you look at the data, very little of the music they are listening to is the famous\n\n26:21.080 --> 26:23.120\n people's music and none of it's old music.\n\n26:23.120 --> 26:24.360\n It's all the latest stuff.\n\n26:24.360 --> 26:27.480\n But the people who made that latest stuff are like some 16 year old somewhere who will\n\n26:27.480 --> 26:29.600\n never make a career out of this, who will never make money.\n\n26:29.600 --> 26:31.480\n Of course there will be a few counter examples.\n\n26:31.480 --> 26:35.360\n The record companies incentivize to pick out a few and highlight them.\n\n26:35.360 --> 26:37.720\n Long story short, there's a missing market there.\n\n26:37.720 --> 26:43.480\n There is not a consumer producer relationship at the level of the actual creative acts.\n\n26:43.480 --> 26:48.200\n The pipelines and Spotify's of the world that take this stuff and stream it along, they\n\n26:48.200 --> 26:51.160\n make money off of subscriptions or advertising and those things.\n\n26:51.160 --> 26:52.160\n They're making the money.\n\n26:52.160 --> 26:53.160\n All right.\n\n26:53.160 --> 26:55.800\n And then they will offer bits and pieces of it to a few people again to highlight that\n\n26:55.800 --> 26:58.640\n they simulate a market.\n\n26:58.640 --> 27:03.560\n Anyway, a real market would be if you're a creator of music that you actually are somebody\n\n27:03.560 --> 27:07.440\n who's good enough that people want to listen to you, you should have the data available\n\n27:07.440 --> 27:08.440\n to you.\n\n27:08.440 --> 27:11.480\n There should be a dashboard showing a map of the United States.\n\n27:11.480 --> 27:14.680\n So in last week, here's all the places your songs were listened to.\n\n27:14.680 --> 27:20.520\n It should be transparent, vetable, so that if someone down in Providence sees that you're\n\n27:20.520 --> 27:24.160\n being listened to 10,000 times in Providence, that they know that's real data.\n\n27:24.160 --> 27:25.320\n You know it's real data.\n\n27:25.320 --> 27:27.300\n They will have you come give a show down there.\n\n27:27.300 --> 27:30.040\n They will broadcast to the people who've been listening to you that you're coming.\n\n27:30.040 --> 27:34.480\n If you do this right, you could go down there and make $20,000.\n\n27:34.480 --> 27:37.100\n You do that three times a year, you start to have a career.\n\n27:37.100 --> 27:39.600\n So in this sense, AI creates jobs.\n\n27:39.600 --> 27:40.680\n It's not about taking away human jobs.\n\n27:40.680 --> 27:43.480\n It's creating new jobs because it creates a new market.\n\n27:43.480 --> 27:46.800\n Once you've created a market, you've now connected up producers and consumers.\n\n27:46.800 --> 27:50.000\n The person who's making the music can say to someone who comes to their shows a lot,\n\n27:50.000 --> 27:53.200\n hey, I'll play at your daughter's wedding for $10,000.\n\n27:53.200 --> 27:54.200\n You'll say 8,000.\n\n27:54.200 --> 27:55.200\n They'll say 9,000.\n\n27:55.200 --> 27:59.000\n Then again, you can now get an income up to $100,000.\n\n27:59.000 --> 28:01.920\n You're not going to be a millionaire.\n\n28:01.920 --> 28:06.900\n And now even think about really the value of music is in these personal connections,\n\n28:06.900 --> 28:13.180\n even so much so that a young kid wants to wear a tshirt with their favorite musician's\n\n28:13.180 --> 28:14.840\n signature on it.\n\n28:14.840 --> 28:18.080\n So if they listen to the music on the internet, the internet should be able to provide them\n\n28:18.080 --> 28:21.840\n with a button that they push and the merchandise arrives the next day.\n\n28:21.840 --> 28:23.000\n We can do that.\n\n28:23.000 --> 28:24.400\n And now why should we do that?\n\n28:24.400 --> 28:27.560\n Well, because the kid who bought the shirt will be happy, but more the person who made\n\n28:27.560 --> 28:29.080\n the music will get the money.\n\n28:29.080 --> 28:32.360\n There's no advertising needed.\n\n28:32.360 --> 28:36.460\n So you can create markets between producers and consumers, take 5% cut.\n\n28:36.460 --> 28:39.200\n Your company will be perfectly sound.\n\n28:39.200 --> 28:45.080\n It'll go forward into the future and it will create new markets and that raises human happiness.\n\n28:45.080 --> 28:48.280\n Now this seems like, well, this is easy, just create this dashboard, kind of create some\n\n28:48.280 --> 28:49.280\n connections and all that.\n\n28:49.280 --> 28:52.900\n But if you think about Uber or whatever, you think about the challenges in the real world\n\n28:52.900 --> 28:56.180\n of doing things like this, and there are actually new principles going to be needed.\n\n28:56.180 --> 28:59.080\n You're trying to create a new kind of two way market at a different scale that's ever\n\n28:59.080 --> 29:00.080\n been done before.\n\n29:00.080 --> 29:04.720\n There's going to be unwanted aspects of the market.\n\n29:04.720 --> 29:05.720\n There'll be bad people.\n\n29:05.720 --> 29:10.880\n There'll be the data will get used in the wrong ways, it'll fail in some ways, it won't\n\n29:10.880 --> 29:11.880\n deliver about.\n\n29:11.880 --> 29:12.880\n You have to think that through.\n\n29:12.880 --> 29:17.240\n Just like anyone who ran a big auction or ran a big matching service in economics will\n\n29:17.240 --> 29:18.880\n think these things through.\n\n29:18.880 --> 29:22.520\n And so that maybe doesn't get at all the huge issues that can arise when you start to create\n\n29:22.520 --> 29:26.760\n markets, but it starts to, at least for me, solidify my thoughts and allow me to move\n\n29:26.760 --> 29:28.080\n forward in my own thinking.\n\n29:28.080 --> 29:29.080\n Yeah.\n\n29:29.080 --> 29:32.840\n So I talked to the head of research at Spotify actually, and I think their longterm goal,\n\n29:32.840 --> 29:39.920\n they've said, is to have at least one million creators make a comfortable living putting\n\n29:39.920 --> 29:41.120\n on Spotify.\n\n29:41.120 --> 29:52.160\n So I think you articulate a really nice vision of the world and the digital and the cyberspace\n\n29:52.160 --> 29:53.920\n of markets.\n\n29:53.920 --> 30:04.100\n What do you think companies like Spotify or YouTube or Netflix can do to create such markets?\n\n30:04.100 --> 30:05.400\n Is it an AI problem?\n\n30:05.400 --> 30:08.600\n Is it an interface problem for interface design?\n\n30:08.600 --> 30:13.440\n Is it some other kind of, is it an economics problem?\n\n30:13.440 --> 30:15.600\n Who should they hire to solve these problems?\n\n30:15.600 --> 30:17.480\n Well, part of it's not just top down.\n\n30:17.480 --> 30:20.000\n So the Silicon Valley has this attitude that they know how to do it.\n\n30:20.000 --> 30:23.380\n They will create the system just like Google did with the search box that will be so good\n\n30:23.380 --> 30:27.000\n that they'll just, everyone will adopt that.\n\n30:27.000 --> 30:31.500\n It's everything you said, but really I think missing that kind of culture.\n\n30:31.500 --> 30:34.800\n So it's literally that 16 year old who's able to create the songs.\n\n30:34.800 --> 30:37.000\n You don't create that as a Silicon Valley entity.\n\n30:37.000 --> 30:39.340\n You don't hire them per se.\n\n30:39.340 --> 30:44.320\n You have to create an ecosystem in which they are wanted and that they belong.\n\n30:44.320 --> 30:47.680\n And so you have to have some cultural credibility to do things like this.\n\n30:47.680 --> 30:53.060\n Netflix, to their credit, wanted some of that credibility and they created shows, content.\n\n30:53.060 --> 30:54.060\n They call it content.\n\n30:54.060 --> 30:56.880\n It's such a terrible word, but it's culture.\n\n30:56.880 --> 31:01.160\n And so with movies, you can kind of go give a large sum of money to somebody graduating\n\n31:01.160 --> 31:03.440\n from the USC film school.\n\n31:03.440 --> 31:07.880\n It's a whole thing of its own, but it's kind of like rich white people's thing to do.\n\n31:07.880 --> 31:11.760\n And American culture has not been so much about rich white people.\n\n31:11.760 --> 31:16.580\n It's been about all the immigrants, all the Africans who came and brought that culture\n\n31:16.580 --> 31:23.040\n and those rhythms to this world and created this whole new thing.\n\n31:23.040 --> 31:24.040\n American culture.\n\n31:24.040 --> 31:26.800\n And so companies can't artificially create that.\n\n31:26.800 --> 31:28.440\n They can't just say, hey, we're here.\n\n31:28.440 --> 31:29.440\n We're going to buy it up.\n\n31:29.440 --> 31:31.440\n You've got a partner.\n\n31:31.440 --> 31:37.520\n And so anyway, not to denigrate, these companies are all trying and they should, and I'm sure\n\n31:37.520 --> 31:40.160\n they're asking these questions and some of them are even making an effort.\n\n31:40.160 --> 31:44.400\n But it is partly a respect the culture as a technology person.\n\n31:44.400 --> 31:49.880\n You've got to blend your technology with cultural meaning.\n\n31:49.880 --> 31:54.400\n How much of a role do you think the algorithm, so machine learning has in connecting the\n\n31:54.400 --> 31:59.600\n consumer to the creator, sort of the recommender system aspect of this?\n\n31:59.600 --> 32:00.600\n Yeah.\n\n32:00.600 --> 32:01.600\n It's a great question.\n\n32:01.600 --> 32:02.600\n I think pretty high.\n\n32:02.600 --> 32:07.320\n There's no magic in the algorithms, but a good recommender system is way better than\n\n32:07.320 --> 32:09.160\n a bad recommender system.\n\n32:09.160 --> 32:15.180\n And recommender systems is a billion dollar industry back even 10, 20 years ago.\n\n32:15.180 --> 32:17.540\n And it continues to be extremely important going forward.\n\n32:17.540 --> 32:20.680\n What's your favorite recommender system, just so we can put something, well, just historically\n\n32:20.680 --> 32:24.800\n I was one of the, when I first went to Amazon, I first didn't like Amazon because they put\n\n32:24.800 --> 32:30.400\n the book people out of business or the library, the local booksellers went out of business.\n\n32:30.400 --> 32:34.620\n I've come to accept that there probably are more books being sold now and poor people\n\n32:34.620 --> 32:36.920\n reading them than ever before.\n\n32:36.920 --> 32:39.440\n And then local book stores are coming back.\n\n32:39.440 --> 32:41.540\n So that's how economics sometimes work.\n\n32:41.540 --> 32:44.280\n You go up and you go down.\n\n32:44.280 --> 32:48.760\n But anyway, when I finally started going there and I bought a few books, I was really pleased\n\n32:48.760 --> 32:52.400\n to see another few books being recommended to me that I never would have thought of.\n\n32:52.400 --> 32:53.400\n And I bought a bunch of them.\n\n32:53.400 --> 32:55.320\n So they obviously had a good business model.\n\n32:55.320 --> 33:00.980\n But I learned things and I still to this day kind of browse using that service.\n\n33:00.980 --> 33:05.760\n And I think lots of people get a lot, that is a good aspect of a recommendation system.\n\n33:05.760 --> 33:10.480\n I'm learning from my peers in an indirect way.\n\n33:10.480 --> 33:13.880\n And their algorithms are not meant to have them impose what we learn.\n\n33:13.880 --> 33:16.680\n It really is trying to find out what's in the data.\n\n33:16.680 --> 33:19.680\n It doesn't work so well for other kinds of entities, but that's just the complexity of\n\n33:19.680 --> 33:20.680\n human life.\n\n33:20.680 --> 33:26.440\n Like shirts, I'm not going to get recommendations on shirts, but that's interesting.\n\n33:26.440 --> 33:32.160\n If you try to recommend restaurants, it's hard.\n\n33:32.160 --> 33:35.400\n It's hard to do it at scale.\n\n33:35.400 --> 33:42.080\n But a blend of recommendation systems with other economic ideas, matchings and so on\n\n33:42.080 --> 33:45.240\n is really, really still very open research wise.\n\n33:45.240 --> 33:48.680\n And there's new companies that are going to emerge that do that well.\n\n33:48.680 --> 33:54.480\n What do you think is going to the messy, difficult land of say politics and things like that,\n\n33:54.480 --> 33:58.480\n that YouTube and Twitter have to deal with in terms of recommendation systems?\n\n33:58.480 --> 34:03.120\n Being able to suggest, I think Facebook just launched Facebook news.\n\n34:03.120 --> 34:08.920\n So recommend the kind of news that are most likely for you to be interesting.\n\n34:08.920 --> 34:14.520\n Do you think this is AI solvable, again, whatever term we want to use, do you think it's a solvable\n\n34:14.520 --> 34:18.760\n problem for machines or is it a deeply human problem that's unsolvable?\n\n34:18.760 --> 34:20.240\n So I don't even think about it at that level.\n\n34:20.240 --> 34:25.400\n I think that what's broken with some of these companies, it's all monetization by advertising.\n\n34:25.400 --> 34:29.200\n They're not, at least Facebook, I want to critique them, but they didn't really try\n\n34:29.200 --> 34:32.680\n to connect a producer and a consumer in an economic way, right?\n\n34:32.680 --> 34:34.700\n No one wants to pay for anything.\n\n34:34.700 --> 34:38.420\n And so they all, you know, starting with Google and Facebook, they went back to the playbook\n\n34:38.420 --> 34:41.440\n of, you know, the television companies back in the day.\n\n34:41.440 --> 34:43.200\n No one wanted to pay for this signal.\n\n34:43.200 --> 34:47.200\n They will pay for the TV box, but not for the signal, at least back in the day.\n\n34:47.200 --> 34:50.400\n And so advertising kind of filled that gap and advertising was new and interesting and\n\n34:50.400 --> 34:54.400\n it somehow didn't take over our lives quite, right?\n\n34:54.400 --> 34:59.880\n Fast forward, Google provides a service that people don't want to pay for.\n\n34:59.880 --> 35:04.120\n And so somewhat surprisingly in the nineties, they made, they ended up making huge amounts\n\n35:04.120 --> 35:05.600\n so they cornered the advertising market.\n\n35:05.600 --> 35:08.400\n It didn't seem like that was going to happen, at least to me.\n\n35:08.400 --> 35:11.720\n These little things on the right hand side of the screen just did not seem all that economically\n\n35:11.720 --> 35:14.360\n interesting, but that companies had maybe no other choice.\n\n35:14.360 --> 35:17.800\n The TV market was going away and billboards and so on.\n\n35:17.800 --> 35:19.860\n So they've, they got it.\n\n35:19.860 --> 35:24.880\n And I think that sadly that Google just has, it was doing so well with that at making such\n\n35:24.880 --> 35:25.880\n money.\n\n35:25.880 --> 35:28.700\n They didn't think much more about how, wait a minute, is there a producer consumer relationship\n\n35:28.700 --> 35:29.700\n to be set up here?\n\n35:29.700 --> 35:32.840\n Not just between us and the advertisers market to be created.\n\n35:32.840 --> 35:35.160\n Is there an actual market between the producer consumer?\n\n35:35.160 --> 35:38.240\n They're the producers, the person who created that video clip, the person that made that\n\n35:38.240 --> 35:42.000\n website, the person who could make more such things, the person who could adjust it as\n\n35:42.000 --> 35:46.800\n a function of demand, the person on the other side who's asking for different kinds of things,\n\n35:46.800 --> 35:47.800\n you know?\n\n35:47.800 --> 35:51.320\n So you see glimmers of that now there's influencers and there's kind of a little glimmering of\n\n35:51.320 --> 35:53.480\n a market, but it should have been done 20 years ago.\n\n35:53.480 --> 35:54.480\n It should have been thought about.\n\n35:54.480 --> 35:58.400\n It should have been created in parallel with the advertising ecosystem.\n\n35:58.400 --> 35:59.860\n And then Facebook inherited that.\n\n35:59.860 --> 36:03.160\n And I think they also didn't think very much about that.\n\n36:03.160 --> 36:07.960\n So fast forward and now they are making huge amounts of money off of advertising.\n\n36:07.960 --> 36:11.560\n And the news thing and all these clicks is just feeding the advertising.\n\n36:11.560 --> 36:13.640\n It's all connected up to the advertiser.\n\n36:13.640 --> 36:18.580\n So you want more people to click on certain things because that money flows to you, Facebook.\n\n36:18.580 --> 36:20.000\n You're very much incentivized to do that.\n\n36:20.000 --> 36:23.480\n And when you start to find it's breaking, people are telling you, well, we're getting\n\n36:23.480 --> 36:24.480\n into some troubles.\n\n36:24.480 --> 36:27.580\n You try to adjust it with your smart AI algorithms, right?\n\n36:27.580 --> 36:28.960\n And figure out what are bad clicks.\n\n36:28.960 --> 36:31.040\n So maybe it shouldn't be click through rate, it should be something else.\n\n36:31.040 --> 36:34.080\n I find that pretty much hopeless.\n\n36:34.080 --> 36:37.400\n It does get into all the complexity of human life and you can try to fix it.\n\n36:37.400 --> 36:40.840\n You should, but you could also fix the whole business model.\n\n36:40.840 --> 36:44.600\n And the business model is that really, what are, are there some human producers and consumers\n\n36:44.600 --> 36:45.600\n out there?\n\n36:45.600 --> 36:48.760\n Is there some economic value to be liberated by connecting them directly?\n\n36:48.760 --> 36:52.640\n Is it such that it's so valuable that people will be able to pay for it?\n\n36:52.640 --> 36:53.640\n All right.\n\n36:53.640 --> 36:54.640\n And micro payments, like small payments.\n\n36:54.640 --> 36:56.620\n Micro, but even have to be micro.\n\n36:56.620 --> 37:00.120\n So I like the example, suppose I'm going, next week I'm going to India.\n\n37:00.120 --> 37:01.120\n Never been to India before.\n\n37:01.120 --> 37:02.120\n Right?\n\n37:02.120 --> 37:06.560\n I have a couple of days in Mumbai, I have no idea what to do there.\n\n37:06.560 --> 37:07.560\n Right?\n\n37:07.560 --> 37:08.880\n And I could go on the web right now and search.\n\n37:08.880 --> 37:10.080\n It's going to be kind of hopeless.\n\n37:10.080 --> 37:14.080\n I'm not going to find, you know, I have lots of advertisers in my face.\n\n37:14.080 --> 37:15.080\n Right?\n\n37:15.080 --> 37:19.320\n What I really want to do is broadcast to the world that I am going to Mumbai and have someone\n\n37:19.320 --> 37:24.000\n on the other side of a market look at me and, and there's a recommendation system there.\n\n37:24.000 --> 37:26.040\n So I'm not looking at all possible people coming to Mumbai.\n\n37:26.040 --> 37:27.680\n They're looking at the people who are relevant to them.\n\n37:27.680 --> 37:32.480\n So someone in my age group, someone who kind of knows me in some level, I give up a little\n\n37:32.480 --> 37:35.720\n privacy by that, but I'm happy because what I'm going to get back is this person can make\n\n37:35.720 --> 37:39.320\n a little video for me, or they're going to write a little two page paper on here's the\n\n37:39.320 --> 37:43.160\n cool things that you want to do and move by this week, especially, right?\n\n37:43.160 --> 37:44.160\n I'm going to look at that.\n\n37:44.160 --> 37:45.160\n I'm not going to pay a micro payment.\n\n37:45.160 --> 37:48.000\n I'm going to pay, you know, a hundred dollars or whatever for that.\n\n37:48.000 --> 37:49.000\n It's real value.\n\n37:49.000 --> 37:50.000\n It's like journalism.\n\n37:50.000 --> 37:54.920\n Um, and as an honest subscription, it's that I'm going to pay that person in that moment.\n\n37:54.920 --> 37:56.680\n Company's going to take 5% of that.\n\n37:56.680 --> 37:57.760\n And that person has now got it.\n\n37:57.760 --> 38:01.240\n It's a gig economy, if you will, but you know, done for it, you know, thinking about a little\n\n38:01.240 --> 38:05.000\n bit behind YouTube, there was actually people who could make more of those things.\n\n38:05.000 --> 38:07.960\n If they were connected to a market, they would make more of those things independently.\n\n38:07.960 --> 38:08.960\n You don't have to tell them what to do.\n\n38:08.960 --> 38:11.680\n You don't have to incentivize them any other way.\n\n38:11.680 --> 38:15.760\n Um, and so, yeah, these companies, I don't think have thought long and hard about that.\n\n38:15.760 --> 38:20.160\n So I do distinguish on Facebook on the one side, who just not thought about these things\n\n38:20.160 --> 38:21.160\n at all.\n\n38:21.160 --> 38:25.200\n I think, uh, thinking that AI will fix everything, uh, and Amazon thinks about them all the time\n\n38:25.200 --> 38:26.520\n because they were already out in the real world.\n\n38:26.520 --> 38:28.080\n They were delivering packages, people's doors.\n\n38:28.080 --> 38:29.400\n They were, they were worried about a market.\n\n38:29.400 --> 38:32.600\n They were worried about sellers and, you know, they worry and some things they do are great.\n\n38:32.600 --> 38:36.440\n Some things maybe not so great, but you know, they're in that business model.\n\n38:36.440 --> 38:38.360\n And then I'd say Google sort of hovers somewhere in between.\n\n38:38.360 --> 38:41.440\n I don't, I don't think for a long, long time they got it.\n\n38:41.440 --> 38:45.720\n I think they probably see that YouTube is more pregnant with possibility than, than,\n\n38:45.720 --> 38:49.120\n than they might've thought and that they're probably heading that direction.\n\n38:49.120 --> 38:54.000\n Um, but uh, you know, Silicon Valley has been dominated by the Google Facebook kind of mentality\n\n38:54.000 --> 38:58.800\n and the subscription and advertising and that is, that's the core problem, right?\n\n38:58.800 --> 39:03.640\n The fake news actually rides on top of that because it means that you're monetizing with\n\n39:03.640 --> 39:05.600\n clip through rate and that is the core problem.\n\n39:05.600 --> 39:06.880\n You got to remove that.\n\n39:06.880 --> 39:11.200\n So advertisement, if we're going to linger on that, I mean, that's an interesting thesis.\n\n39:11.200 --> 39:15.060\n I don't know if everyone really deeply thinks about that.\n\n39:15.060 --> 39:16.720\n So you're right.\n\n39:16.720 --> 39:20.960\n The thought is the advertising model is the only thing we have, the only thing we'll ever\n\n39:20.960 --> 39:21.960\n have.\n\n39:21.960 --> 39:30.240\n We have to fix, we have to build algorithms that despite that business model, you know,\n\n39:30.240 --> 39:34.680\n find the better angels of our nature and do good by society and by the individual.\n\n39:34.680 --> 39:40.000\n But you think we can slowly, you think, first of all, there's a difference between should\n\n39:40.000 --> 39:42.040\n and could.\n\n39:42.040 --> 39:46.600\n So you're saying we should slowly move away from the advertising model and have a direct\n\n39:46.600 --> 39:49.920\n connection between the consumer and the creator.\n\n39:49.920 --> 39:55.240\n The question I also have is, can we, because the advertising model is so successful now\n\n39:55.240 --> 40:00.400\n in terms of just making a huge amount of money and therefore being able to build a big company\n\n40:00.400 --> 40:03.920\n that provides, has really smart people working that create a good service.\n\n40:03.920 --> 40:05.680\n Do you think it's possible?\n\n40:05.680 --> 40:07.880\n And just to clarify, you think we should move away?\n\n40:07.880 --> 40:08.880\n Well, I think we should.\n\n40:08.880 --> 40:09.880\n Yeah.\n\n40:09.880 --> 40:10.880\n But we is the, you know, me.\n\n40:10.880 --> 40:11.880\n So society.\n\n40:11.880 --> 40:12.880\n Yeah.\n\n40:12.880 --> 40:16.360\n Well, the companies, I mean, so first of all, full disclosure, I'm doing a day a week at\n\n40:16.360 --> 40:18.840\n Amazon because I kind of want to learn more about how they do things.\n\n40:18.840 --> 40:22.760\n So, you know, I'm not speaking for Amazon in any way, but, you know, I did go there\n\n40:22.760 --> 40:26.240\n because I actually believe they get a little bit of this or trying to create these markets.\n\n40:26.240 --> 40:29.520\n And they don't really use, advertising is not a crucial part of it.\n\n40:29.520 --> 40:30.520\n Well, that's a good question.\n\n40:30.520 --> 40:34.840\n So it has become not crucial, but it's become more and more present if you go to Amazon\n\n40:34.840 --> 40:35.840\n website.\n\n40:35.840 --> 40:38.840\n And, you know, without revealing too many deep secrets about Amazon, I can tell you\n\n40:38.840 --> 40:42.480\n that, you know, a lot of people in the company question this and there's a huge questioning\n\n40:42.480 --> 40:43.620\n going on.\n\n40:43.620 --> 40:45.660\n You do not want a world where there's zero advertising.\n\n40:45.660 --> 40:47.160\n That actually is a bad world.\n\n40:47.160 --> 40:48.160\n Okay.\n\n40:48.160 --> 40:49.280\n So here's a way to think about it.\n\n40:49.280 --> 40:55.000\n You're a company that like Amazon is trying to bring products to customers, right?\n\n40:55.000 --> 40:58.360\n And the customer, at any given moment, you want to buy a vacuum cleaner, say, you want\n\n40:58.360 --> 40:59.360\n to know what's available for me.\n\n40:59.360 --> 41:00.840\n And, you know, it's not going to be that obvious.\n\n41:00.840 --> 41:02.160\n You have to do a little bit of work at it.\n\n41:02.160 --> 41:04.600\n The recommendation system will sort of help, right?\n\n41:04.600 --> 41:08.080\n But now suppose this other person over here has just made the world, you know, they spent\n\n41:08.080 --> 41:09.080\n a huge amount of energy.\n\n41:09.080 --> 41:10.080\n They had a great idea.\n\n41:10.080 --> 41:11.080\n They made a great vacuum cleaner.\n\n41:11.080 --> 41:12.400\n They know they really did it.\n\n41:12.400 --> 41:13.400\n They nailed it.\n\n41:13.400 --> 41:16.680\n It's an MIT, you know, whiz kid that made a great new vacuum cleaner, right?\n\n41:16.680 --> 41:18.240\n It's not going to be in the recommendation system.\n\n41:18.240 --> 41:19.280\n No one will know about it.\n\n41:19.280 --> 41:22.440\n The algorithms will not find it and AI will not fix that.\n\n41:22.440 --> 41:23.440\n Okay.\n\n41:23.440 --> 41:24.440\n At all.\n\n41:24.440 --> 41:25.440\n Right.\n\n41:25.440 --> 41:30.660\n How do you allow that vacuum cleaner to start to get in front of people, be sold well advertising.\n\n41:30.660 --> 41:35.360\n And here, what advertising is, it's a signal that you're, you believe in your product enough\n\n41:35.360 --> 41:37.480\n that you're willing to pay some real money for it.\n\n41:37.480 --> 41:39.480\n And to me as a consumer, I look at that signal.\n\n41:39.480 --> 41:43.240\n I say, well, first of all, I know these are not just cheap little ads cause we have now\n\n41:43.240 --> 41:44.240\n right now there.\n\n41:44.240 --> 41:47.740\n I know that, you know, these are super cheap, you know, pennies.\n\n41:47.740 --> 41:51.120\n If I see an ad where it's actually, I know the company is only doing a few of these and\n\n41:51.120 --> 41:54.520\n they're making, you know, real money is kind of flowing and I see an ad, I may pay more\n\n41:54.520 --> 41:55.520\n attention to it.\n\n41:55.520 --> 42:01.600\n And I actually might want that because I see, Hey, that guy spent money on his vacuum cleaner.\n\n42:01.600 --> 42:02.600\n Maybe there's something good there.\n\n42:02.600 --> 42:03.600\n So I will look at it.\n\n42:03.600 --> 42:06.620\n And so that's part of the overall information flow in a good market.\n\n42:06.620 --> 42:11.720\n So advertising has a role, but the problem is of course that that signal is now completely\n\n42:11.720 --> 42:15.800\n gone because it just, you know, dominant by these tiny little things that add up to big\n\n42:15.800 --> 42:17.740\n money for the company, you know?\n\n42:17.740 --> 42:22.600\n So I think it will just, I think it will change because the societies just don't, you know,\n\n42:22.600 --> 42:26.480\n stick with things that annoy a lot of people and advertising currently annoys people more\n\n42:26.480 --> 42:28.480\n than it provides information.\n\n42:28.480 --> 42:32.200\n And I think that a Google probably is smart enough to figure out that this is a dead,\n\n42:32.200 --> 42:35.760\n this is a bad model, even though it's a hard, huge amount of money and they'll have to figure\n\n42:35.760 --> 42:38.080\n out how to pull it away from it slowly.\n\n42:38.080 --> 42:42.280\n And I'm sure the CEO there will figure it out, but they need to do it.\n\n42:42.280 --> 42:47.120\n And they needed it to, so if you reduce advertising, not to zero, but you reduce it at the same\n\n42:47.120 --> 42:51.640\n time you bring up producer, consumer, actual real value being delivered.\n\n42:51.640 --> 42:56.260\n So real money is being paid and they take a 5% cut that 5% could start to get big enough\n\n42:56.260 --> 43:00.080\n to cancel out the lost revenue from the kind of the poor kind of advertising.\n\n43:00.080 --> 43:04.740\n And I think that a good company will do that, will realize that.\n\n43:04.740 --> 43:08.440\n And Facebook, you know, again, God bless them.\n\n43:08.440 --> 43:14.680\n They bring, you know, grandmothers, they bring children's pictures into grandmothers lives.\n\n43:14.680 --> 43:17.340\n It's fantastic.\n\n43:17.340 --> 43:22.440\n But they need to think of a new business model and that's the core problem there.\n\n43:22.440 --> 43:26.440\n Until they start to connect producer consumer, I think they will just continue to make money\n\n43:26.440 --> 43:30.560\n and then buy the next social network company and then buy the next one and the innovation\n\n43:30.560 --> 43:34.880\n level will not be high and the health issues will not go away.\n\n43:34.880 --> 43:41.120\n So I apologize that we kind of returned to words, I don't think the exact terms matter,\n\n43:41.120 --> 43:49.440\n but in sort of defense of advertisement, don't you think the kind of direct connection between\n\n43:49.440 --> 44:00.960\n consumer and creator producer is what advertisement strives to do, right?\n\n44:00.960 --> 44:06.680\n So that is best advertisement is literally now Facebook is listening to our conversation\n\n44:06.680 --> 44:11.400\n and heard that you're going to India and will be able to actually start automatically for\n\n44:11.400 --> 44:14.500\n you making these connections and start giving this offer.\n\n44:14.500 --> 44:19.800\n So like, I apologize if it's just a matter of terms, but just to draw a distinction,\n\n44:19.800 --> 44:23.000\n is it possible to make advertisements just better and better and better algorithmically\n\n44:23.000 --> 44:26.040\n to where it actually becomes a connection, almost a direct connection?\n\n44:26.040 --> 44:27.040\n That's a good question.\n\n44:27.040 --> 44:28.040\n So let's component on that.\n\n44:28.040 --> 44:32.000\n First of all, what we just talked about, I was defending advertising.\n\n44:32.000 --> 44:33.000\n Okay.\n\n44:33.000 --> 44:36.400\n So I was defending it as a way to get signals into a market that don't come any other way,\n\n44:36.400 --> 44:37.720\n especially algorithmically.\n\n44:37.720 --> 44:41.640\n It's a sign that someone spent money on it, it's a sign they think it's valuable.\n\n44:41.640 --> 44:45.020\n And if I think that if other things, someone else thinks it's valuable, and if I trust\n\n44:45.020 --> 44:47.360\n other people, I might be willing to listen.\n\n44:47.360 --> 44:51.840\n I don't trust that Facebook though, who's an intermediary between this.\n\n44:51.840 --> 44:54.600\n I don't think they care about me.\n\n44:54.600 --> 44:55.600\n Okay.\n\n44:55.600 --> 44:56.720\n I don't think they do.\n\n44:56.720 --> 45:00.880\n And I find it creepy that they know I'm going to India next week because of our conversation.\n\n45:00.880 --> 45:02.360\n Why do you think that is?\n\n45:02.360 --> 45:07.120\n So what, could you just put your PR hat on?\n\n45:07.120 --> 45:14.180\n Why do you think you find Facebook creepy and not trust them as do majority of the population?\n\n45:14.180 --> 45:19.360\n So they're out of the Silicon Valley companies, I saw like not approval rate, but there's\n\n45:19.360 --> 45:23.080\n ranking of how much people trust companies and Facebook is in the gutter.\n\n45:23.080 --> 45:25.600\n In the gutter, including people inside of Facebook.\n\n45:25.600 --> 45:28.000\n So what do you attribute that to?\n\n45:28.000 --> 45:29.000\n Because when I...\n\n45:29.000 --> 45:31.840\n Come on, you don't find it creepy that right now we're talking that I might walk out on\n\n45:31.840 --> 45:35.880\n the street right now that some unknown person who I don't know kind of comes up to me and\n\n45:35.880 --> 45:37.500\n says, I hear you're going to India.\n\n45:37.500 --> 45:38.900\n I mean, that's not even Facebook.\n\n45:38.900 --> 45:42.560\n That's just, I want transparency in human society.\n\n45:42.560 --> 45:45.680\n I want to have, if you know something about me, there's actually some reason you know\n\n45:45.680 --> 45:47.080\n something about me.\n\n45:47.080 --> 45:51.560\n That's something that if I look at it later and audit it kind of, I approve.\n\n45:51.560 --> 45:54.580\n You know something about me because you care in some way.\n\n45:54.580 --> 45:58.240\n There's a caring relationship even, or an economic one or something.\n\n45:58.240 --> 46:02.000\n Not just that you're someone who could exploit it in ways I don't know about or care about\n\n46:02.000 --> 46:05.240\n or I'm troubled by or whatever.\n\n46:05.240 --> 46:09.880\n We're in a world right now where that happens way too much and that Facebook knows things\n\n46:09.880 --> 46:14.720\n about a lot of people and could exploit it and does exploit it at times.\n\n46:14.720 --> 46:16.880\n I think most people do find that creepy.\n\n46:16.880 --> 46:17.880\n It's not for them.\n\n46:17.880 --> 46:23.440\n It's not that Facebook is not doing it because they care about them in a real sense.\n\n46:23.440 --> 46:24.440\n And they shouldn't.\n\n46:24.440 --> 46:26.740\n They should not be a big brother caring about us.\n\n46:26.740 --> 46:28.560\n That is not the role of a company like that.\n\n46:28.560 --> 46:29.560\n Why not?\n\n46:29.560 --> 46:32.160\n Wait, not the big brother part, but the caring, the trusting.\n\n46:32.160 --> 46:37.120\n I mean, don't those companies, just to link on it because a lot of companies have a lot\n\n46:37.120 --> 46:38.320\n of information about us.\n\n46:38.320 --> 46:42.560\n I would argue that there's companies like Microsoft that has more information about\n\n46:42.560 --> 46:46.000\n us than Facebook does and yet we trust Microsoft more.\n\n46:46.000 --> 46:47.480\n Well, Microsoft is pivoting.\n\n46:47.480 --> 46:51.360\n Microsoft, you know, under Satya Nadella has decided this is really important.\n\n46:51.360 --> 46:53.320\n We don't want to do creepy things.\n\n46:53.320 --> 46:56.720\n Really want people to trust us to actually only use information in ways that they really\n\n46:56.720 --> 47:00.360\n would approve of, that we don't decide, right?\n\n47:00.360 --> 47:06.640\n And I'm just kind of adding that the health of a market is that when I connect to someone\n\n47:06.640 --> 47:10.160\n who produces a consumer, it's not just a random producer or consumer, it's people who see\n\n47:10.160 --> 47:11.160\n each other.\n\n47:11.160 --> 47:14.360\n They don't like each other, but they sense that if they transact, some happiness will\n\n47:14.360 --> 47:15.940\n go up on both sides.\n\n47:15.940 --> 47:22.800\n If a company helps me to do that in moments that I choose of my choosing, then fine.\n\n47:22.800 --> 47:28.560\n So, and also think about the difference between, you know, browsing versus buying, right?\n\n47:28.560 --> 47:31.760\n There are moments in my life I just want to buy, you know, a gadget or something.\n\n47:31.760 --> 47:33.080\n I need something for that moment.\n\n47:33.080 --> 47:37.400\n I need some ammonia for my house or something because I got a problem with a spill.\n\n47:37.400 --> 47:38.400\n I want to just go in.\n\n47:38.400 --> 47:40.080\n I don't want to be advertised at that moment.\n\n47:40.080 --> 47:43.040\n I don't want to be led down various, you know, that's annoying.\n\n47:43.040 --> 47:49.020\n I want to just go and have it be extremely easy to do what I want.\n\n47:49.020 --> 47:52.440\n Other moments I might say, no, it's like today I'm going to the shopping mall.\n\n47:52.440 --> 47:55.560\n I want to walk around and see things and see people and be exposed to stuff.\n\n47:55.560 --> 47:56.800\n So I want control over that though.\n\n47:56.800 --> 48:00.200\n I don't want the company's algorithms to decide for me, right?\n\n48:00.200 --> 48:01.200\n I think that's the thing.\n\n48:01.200 --> 48:04.880\n There's a total loss of control if Facebook thinks they should take the control from us\n\n48:04.880 --> 48:08.200\n of deciding when we want to have certain kinds of information, when we don't, what information\n\n48:08.200 --> 48:11.880\n that is, how much it relates to what they know about us that we didn't really want them\n\n48:11.880 --> 48:13.680\n to know about us.\n\n48:13.680 --> 48:15.840\n I don't want them to be helping me in that way.\n\n48:15.840 --> 48:21.640\n I don't want them to be helping them by they decide they have control over what I want\n\n48:21.640 --> 48:22.640\n and when.\n\n48:22.640 --> 48:23.640\n I totally agree.\n\n48:23.640 --> 48:28.560\n Facebook, by the way, I have this optimistic thing where I think Facebook has the kind\n\n48:28.560 --> 48:32.480\n of personal information about us that could create a beautiful thing.\n\n48:32.480 --> 48:36.200\n So I'm really optimistic of what Facebook could do.\n\n48:36.200 --> 48:38.680\n It's not what it's doing, but what it could do.\n\n48:38.680 --> 48:39.840\n So I don't see that.\n\n48:39.840 --> 48:43.400\n I think that optimism is misplaced because there's not a bit, you have to have a business\n\n48:43.400 --> 48:44.400\n model behind these things.\n\n48:44.400 --> 48:48.480\n Create a beautiful thing is really, let's be, let's be clear.\n\n48:48.480 --> 48:51.400\n It's about something that people would value.\n\n48:51.400 --> 48:55.080\n And I don't think they have that business model and I don't think they will suddenly\n\n48:55.080 --> 48:58.920\n discover it by what, you know, a long hot shower.\n\n48:58.920 --> 48:59.920\n I disagree.\n\n48:59.920 --> 49:04.840\n I disagree in terms of, you can discover a lot of amazing things in a shower.\n\n49:04.840 --> 49:05.840\n So I didn't say that.\n\n49:05.840 --> 49:10.240\n I said, they won't come, they won't do it, but in the shower, I think a lot of other\n\n49:10.240 --> 49:11.300\n people will discover it.\n\n49:11.300 --> 49:15.240\n I think that this guy, so I should also, full disclosure, there's a company called United\n\n49:15.240 --> 49:18.760\n Masters, which I'm on their board and they've created this music market and I have a hundred\n\n49:18.760 --> 49:23.220\n thousand artists now signed on and they've done things like gone to the NBA and the NBA,\n\n49:23.220 --> 49:26.960\n the music you find behind NBA clips right now is their music, right?\n\n49:26.960 --> 49:31.920\n That's a company that had the right business model in mind from the get go, right?\n\n49:31.920 --> 49:32.920\n Executed on that.\n\n49:32.920 --> 49:37.220\n And from day one, there was value brought to, so here you have a kid who made some songs\n\n49:37.220 --> 49:41.260\n who suddenly their songs are on the NBA website, right?\n\n49:41.260 --> 49:43.440\n That's real economic value to people.\n\n49:43.440 --> 49:51.800\n And so, you know, so you and I differ on the optimism of being able to sort of change the\n\n49:51.800 --> 49:54.440\n direction of the Titanic, right?\n\n49:54.440 --> 50:01.120\n So I, yeah, I'm older than you, so I've seen some Titanic's crash, got it.\n\n50:01.120 --> 50:05.560\n But and just to elaborate, cause I totally agree with you and I just want to know how\n\n50:05.560 --> 50:11.880\n difficult you think this problem is of, so for example, I want to read some news and\n\n50:11.880 --> 50:16.940\n I would, there's a lot of times in the day where something makes me either smile or think\n\n50:16.940 --> 50:20.800\n in a way where I like consciously think this really gave me value.\n\n50:20.800 --> 50:26.480\n Like I sometimes listen to the daily podcasts in the New York times, way better than the\n\n50:26.480 --> 50:29.320\n New York times themselves, by the way, for people listening.\n\n50:29.320 --> 50:32.560\n That's like real journalism is happening for some reason in the podcast space.\n\n50:32.560 --> 50:37.600\n It doesn't make sense to me, but often I listen to it 20 minutes and I would be willing to\n\n50:37.600 --> 50:41.860\n pay for that, like $5, $10 for that experience.\n\n50:41.860 --> 50:48.200\n And how difficult, that's kind of what you're getting at is that little transaction.\n\n50:48.200 --> 50:52.640\n How difficult is it to create a frictionless system like Uber has, for example, for other\n\n50:52.640 --> 50:53.640\n things?\n\n50:53.640 --> 50:55.280\n What's your intuition there?\n\n50:55.280 --> 50:58.500\n So I, first of all, I pay little bits of money to, you know, to send, there's something\n\n50:58.500 --> 51:00.300\n called courts that does financial things.\n\n51:00.300 --> 51:04.480\n I like medium as a site, I don't pay there, but I would.\n\n51:04.480 --> 51:06.280\n You had a great post on medium.\n\n51:06.280 --> 51:10.280\n I would have loved to pay you a dollar and not others.\n\n51:10.280 --> 51:15.560\n I wouldn't have wanted it per se because there should be also sites where that's not actually\n\n51:15.560 --> 51:16.560\n the goal.\n\n51:16.560 --> 51:20.240\n The goal is to actually have a broadcast channel that I monetize in some other way if I chose\n\n51:20.240 --> 51:21.240\n to.\n\n51:21.240 --> 51:23.080\n I mean, I could now people know about it.\n\n51:23.080 --> 51:26.360\n I could, I'm not doing it, but that's fine with me.\n\n51:26.360 --> 51:29.840\n Also the musicians who are making all this music, I don't think the right model is that\n\n51:29.840 --> 51:32.880\n you pay a little subscription fee to them, right?\n\n51:32.880 --> 51:35.860\n Because people can copy the bits too easily and it's just not that somewhere the value\n\n51:35.860 --> 51:36.860\n is.\n\n51:36.860 --> 51:39.800\n The value is that a connection was made between real human beings, then you can follow up\n\n51:39.800 --> 51:40.800\n on that.\n\n51:40.800 --> 51:41.800\n All right.\n\n51:41.800 --> 51:42.960\n And create yet more value.\n\n51:42.960 --> 51:47.920\n So no, I think there's a lot of open questions here, hot open questions, but also, yeah,\n\n51:47.920 --> 51:51.360\n I do want good recommendation systems that recommend cool stuff to me.\n\n51:51.360 --> 51:52.360\n But it's pretty hard, right?\n\n51:52.360 --> 51:55.880\n I don't like them to recommend stuff just based on my browsing history.\n\n51:55.880 --> 51:59.000\n I don't like the based on stuff they know about me, quote unquote.\n\n51:59.000 --> 52:00.860\n What's unknown about me is the most interesting.\n\n52:00.860 --> 52:03.640\n So this is the, this is the really interesting question.\n\n52:03.640 --> 52:05.860\n We may disagree, maybe not.\n\n52:05.860 --> 52:12.160\n I think that I love recommender systems and I want to give them everything about me in\n\n52:12.160 --> 52:13.160\n a way that I trust.\n\n52:13.160 --> 52:14.160\n Yeah.\n\n52:14.160 --> 52:17.880\n But you, but you don't, because, so for example, this morning I clicked on a, you know, I was\n\n52:17.880 --> 52:19.960\n pretty sleepy this morning.\n\n52:19.960 --> 52:23.280\n I clicked on a story about the queen of England.\n\n52:23.280 --> 52:24.280\n Yes.\n\n52:24.280 --> 52:25.280\n Right.\n\n52:25.280 --> 52:26.440\n I do not give a damn about the queen of England.\n\n52:26.440 --> 52:27.560\n I really do not.\n\n52:27.560 --> 52:28.560\n But it was clickbait.\n\n52:28.560 --> 52:31.520\n It kind of looked funny and I had to say, what the heck are they talking about?\n\n52:31.520 --> 52:34.040\n I don't want to have my life, you know, heading that direction.\n\n52:34.040 --> 52:36.180\n Now that's in my browsing history.\n\n52:36.180 --> 52:39.880\n The system in any reasonable system will think that I care about the queen of England.\n\n52:39.880 --> 52:40.880\n That's browsing history.\n\n52:40.880 --> 52:41.880\n Right.\n\n52:41.880 --> 52:44.640\n But, but you're saying all the trace, all the digital exhaust or whatever, that's been\n\n52:44.640 --> 52:45.640\n kind of the models.\n\n52:45.640 --> 52:48.560\n If you collect all this stuff, you're going to figure all of us out.\n\n52:48.560 --> 52:51.280\n Well, if you're trying to figure out like kind of one person like Trump or something,\n\n52:51.280 --> 52:52.280\n maybe you could figure him out.\n\n52:52.280 --> 52:58.040\n But if you're trying to figure out, you know, 500 million people, you know, no way, no way.\n\n52:58.040 --> 52:59.040\n You think so?\n\n52:59.040 --> 53:00.040\n No, I do.\n\n53:00.040 --> 53:01.040\n I think so.\n\n53:01.040 --> 53:02.560\n I think we are, humans are just amazingly rich and complicated.\n\n53:02.560 --> 53:05.220\n Every one of us has our little quirks, every one of us has our little things that could\n\n53:05.220 --> 53:08.020\n intrigue us that we don't even know it will intrigue us.\n\n53:08.020 --> 53:12.240\n And there's no sign of it in our past, but by God, there it comes and you know, you fall\n\n53:12.240 --> 53:13.240\n in love with it.\n\n53:13.240 --> 53:16.520\n And I don't want a company trying to figure that out for me and anticipate that I want\n\n53:16.520 --> 53:22.160\n them to provide a forum, a market, a place that I kind of go and by hook or by crook,\n\n53:22.160 --> 53:26.120\n this happens, you know, I I'm walking down the street and I hear some Chilean music being\n\n53:26.120 --> 53:28.580\n played and I never knew I liked Chilean music, but wow.\n\n53:28.580 --> 53:33.680\n So there is that side and I want them to provide a limited, but you know, interesting place\n\n53:33.680 --> 53:34.680\n to go.\n\n53:34.680 --> 53:35.680\n Right.\n\n53:35.680 --> 53:39.740\n And so don't try to use your AI to kind of, you know, figure me out and then put me in\n\n53:39.740 --> 53:45.140\n a world where you figured me out, you know, no, create huge spaces for human beings where\n\n53:45.140 --> 53:50.360\n our creativity and our style will be enriched and come forward and it'll be a lot of more\n\n53:50.360 --> 53:51.360\n transparency.\n\n53:51.360 --> 53:55.400\n I won't have people randomly, anonymously putting comments up and I'll special based\n\n53:55.400 --> 54:00.080\n on stuff they know about me, facts that, you know, we are so broken right now.\n\n54:00.080 --> 54:02.920\n If you're, you know, especially if you're a celebrity, but you know, it's about anybody\n\n54:02.920 --> 54:06.720\n that anonymous people are hurting lots and lots of people right now.\n\n54:06.720 --> 54:10.200\n That's part of this thing that Silicon Valley is thinking that, you know, just collect all\n\n54:10.200 --> 54:12.480\n this information and use it in a great way.\n\n54:12.480 --> 54:16.420\n So no, I'm not, I'm not a pessimist, I'm very much an optimist by nature, but I think that's\n\n54:16.420 --> 54:19.920\n just been the wrong path for the whole technology to take.\n\n54:19.920 --> 54:24.040\n Be more limited, create, let humans rise up.\n\n54:24.040 --> 54:25.740\n Don't try to replace them.\n\n54:25.740 --> 54:26.760\n That's the AI mantra.\n\n54:26.760 --> 54:28.660\n Don't try to anticipate them.\n\n54:28.660 --> 54:32.320\n Don't try to predict them because you're, you're, you're not going to, you're not going\n\n54:32.320 --> 54:33.320\n to be able to do those things.\n\n54:33.320 --> 54:34.320\n You're going to make things worse.\n\n54:34.320 --> 54:35.320\n Okay.\n\n54:35.320 --> 54:38.760\n So right now, just give this a chance.\n\n54:38.760 --> 54:43.840\n Right now, the recommender systems are the creepy people in the shadow watching your\n\n54:43.840 --> 54:45.500\n every move.\n\n54:45.500 --> 54:47.800\n So they're looking at traces of you.\n\n54:47.800 --> 54:53.000\n They're not directly interacting with you, sort of the, your close friends and family,\n\n54:53.000 --> 54:57.120\n the way they know you is by having conversation, by actually having interactions back and forth.\n\n54:57.120 --> 55:02.360\n Do you think there's a place for recommender systems sort of to step, cause you, you just\n\n55:02.360 --> 55:06.740\n emphasize the value of human to human connection, but yeah, just give it a chance, AI human\n\n55:06.740 --> 55:07.840\n connection.\n\n55:07.840 --> 55:13.560\n Is there a role for an AI system to have conversations with you in terms of, to try to figure out\n\n55:13.560 --> 55:17.360\n what kind of music you like, not by just watching what you listening to, but actually having\n\n55:17.360 --> 55:19.560\n a conversation, natural language or otherwise.\n\n55:19.560 --> 55:21.760\n Yeah, no, I'm, I'm, so I'm not against it.\n\n55:21.760 --> 55:25.120\n I just wanted to push back against the, maybe you're saying you have options for Facebook.\n\n55:25.120 --> 55:31.760\n So there I think it's misplaced, but, but I think that distributing, yeah, no, so good\n\n55:31.760 --> 55:33.520\n for you.\n\n55:33.520 --> 55:34.520\n Go for it.\n\n55:34.520 --> 55:35.520\n That's a hard spot to be in.\n\n55:35.520 --> 55:36.520\n Yeah, no, good.\n\n55:36.520 --> 55:39.520\n Human interaction, like on our daily, the context around me in my own home is something\n\n55:39.520 --> 55:42.280\n that I don't want some big company to know about at all, but I would be more than happy\n\n55:42.280 --> 55:44.200\n to have technology help me with it.\n\n55:44.200 --> 55:45.200\n Which kind of technology?\n\n55:45.200 --> 55:49.200\n Well, you know, just, Alexa, Amazon, well, a good, Alexa's done right.\n\n55:49.200 --> 55:52.160\n And I think Alexa is a research platform right now more than anything else.\n\n55:52.160 --> 55:56.480\n But Alexa done right, you know, could do things like I, I leave the water running in my garden\n\n55:56.480 --> 55:59.200\n and I say, Hey, Alexa, the water's running in my garden.\n\n55:59.200 --> 56:02.040\n And even have Alexa figure out that that means when my wife comes home, that she should be\n\n56:02.040 --> 56:03.600\n told about that.\n\n56:03.600 --> 56:04.600\n That's a little bit of a reasoning.\n\n56:04.600 --> 56:08.860\n I would call that AI and by any kind of stretch, it's a little bit of reasoning and it actually\n\n56:08.860 --> 56:11.000\n kind of would make my life a little easier and better.\n\n56:11.000 --> 56:14.600\n And you know, I don't, I wouldn't call this a wow moment, but I kind of think that overall\n\n56:14.600 --> 56:18.320\n rises human happiness up to have that kind of thing.\n\n56:18.320 --> 56:20.840\n But not when you're lonely, Alexa, knowing loneliness.\n\n56:20.840 --> 56:25.600\n No, no, I don't want Alexa to be, feel intrusive.\n\n56:25.600 --> 56:28.440\n And I don't want just the designer of the system to kind of work all this out.\n\n56:28.440 --> 56:32.440\n I really want to have a lot of control and I want transparency and control.\n\n56:32.440 --> 56:36.800\n And if a company can stand up and give me that in the context of new technology, I think\n\n56:36.800 --> 56:37.800\n they're good.\n\n56:37.800 --> 56:39.280\n First of all, be way more successful than our current generation.\n\n56:39.280 --> 56:43.300\n And like I said, I was mentioning Microsoft, I really think they're, they're pivoting to\n\n56:43.300 --> 56:47.000\n kind of be the trusted old uncle, but you know, I think that they get that this is a\n\n56:47.000 --> 56:51.600\n way to go, that if you let people find technology, empowers them to have more control and have\n\n56:51.600 --> 56:56.720\n and have control, not just over privacy, but over this rich set of interactions, that that\n\n56:56.720 --> 56:58.120\n people are going to like that a lot more.\n\n56:58.120 --> 57:00.560\n And that's, that's the right business model going forward.\n\n57:00.560 --> 57:02.240\n What does control over privacy look like?\n\n57:02.240 --> 57:04.760\n Do you think you should be able to just view all the data that?\n\n57:04.760 --> 57:05.920\n No, it's much more than that.\n\n57:05.920 --> 57:07.900\n I mean, first of all, it should be an individual decision.\n\n57:07.900 --> 57:09.220\n Some people don't want privacy.\n\n57:09.220 --> 57:10.720\n They want their whole life out there.\n\n57:10.720 --> 57:13.720\n Other people's want it.\n\n57:13.720 --> 57:16.020\n Privacy is not a zero one.\n\n57:16.020 --> 57:17.020\n It's not a legal thing.\n\n57:17.020 --> 57:20.280\n It's not just about which data is available, which is not.\n\n57:20.280 --> 57:24.880\n I like to recall to people that, you know, a couple hundred years ago, everyone, there\n\n57:24.880 --> 57:29.640\n was not really big cities, everyone lived in on the countryside and villages and villages.\n\n57:29.640 --> 57:30.640\n Everybody knew everything about you.\n\n57:30.640 --> 57:32.720\n Very, you didn't have any privacy.\n\n57:32.720 --> 57:33.720\n Is that bad?\n\n57:33.720 --> 57:34.720\n Are we better off now?\n\n57:34.720 --> 57:39.040\n Well, you know, arguably no, because what did you get for that loss of certain kinds\n\n57:39.040 --> 57:40.520\n of privacy?\n\n57:40.520 --> 57:44.080\n Well, people help each other if they, because they know everything about you.\n\n57:44.080 --> 57:46.400\n They know something's bad's happening, they will help you with that.\n\n57:46.400 --> 57:47.400\n Right.\n\n57:47.400 --> 57:48.400\n And now you live in a big city, no one knows about that.\n\n57:48.400 --> 57:50.840\n You get no help.\n\n57:50.840 --> 57:52.680\n So it kind of depends the answer.\n\n57:52.680 --> 57:56.320\n I want certain people who I trust and there should be relationships.\n\n57:56.320 --> 57:59.000\n I should kind of manage all those, but who knows what about me?\n\n57:59.000 --> 58:00.800\n I should have some agency there.\n\n58:00.800 --> 58:04.680\n It shouldn't, I shouldn't be a drift in a sea of technology where I have no agency.\n\n58:04.680 --> 58:08.560\n I don't want to go reading things and checking boxes.\n\n58:08.560 --> 58:09.960\n So I don't know how to do that.\n\n58:09.960 --> 58:11.480\n And I'm not a privacy researcher per se.\n\n58:11.480 --> 58:14.360\n I just, I recognize the vast complexity of this.\n\n58:14.360 --> 58:15.360\n It's not just technology.\n\n58:15.360 --> 58:18.920\n It's not just legal scholars meeting technologists.\n\n58:18.920 --> 58:20.900\n There's gotta be kind of a whole layers around it.\n\n58:20.900 --> 58:26.480\n And so I, when I alluded to this emerging engineering field, this is a big part of it.\n\n58:26.480 --> 58:31.320\n When electrical engineering came, I'm not one around at the time, but you just didn't\n\n58:31.320 --> 58:34.120\n plug electricity into walls and all kinds of work.\n\n58:34.120 --> 58:37.840\n You don't have to have like underwriters laboratory that reassured you that that plug's not going\n\n58:37.840 --> 58:41.720\n to burn up your house and that that machine will do this and that and everything.\n\n58:41.720 --> 58:44.520\n There'll be whole people who can install things.\n\n58:44.520 --> 58:46.360\n There'll be people who can watch the installers.\n\n58:46.360 --> 58:49.960\n There'll be a whole layers, you know, an onion of these kinds of things.\n\n58:49.960 --> 58:53.960\n And for things as deep and interesting as privacy, which is as least as interesting\n\n58:53.960 --> 58:58.120\n as electricity, that's going to take decades to kind of work out, but it's going to require\n\n58:58.120 --> 59:00.320\n a lot of new structures that we don't have right now.\n\n59:00.320 --> 59:02.320\n So it's kind of hard to talk about it.\n\n59:02.320 --> 59:04.840\n And you're saying there's a lot of money to be made if you get it right.\n\n59:04.840 --> 59:05.840\n So something you should look at.\n\n59:05.840 --> 59:09.560\n A lot of money to be made in all these things that provide human services and people recognize\n\n59:09.560 --> 59:12.360\n them as useful parts of their lives.\n\n59:12.360 --> 59:14.280\n So yeah.\n\n59:14.280 --> 59:19.660\n So yeah, the dialogue sometimes goes from the exuberant technologists to the no technology\n\n59:19.660 --> 59:20.800\n is good, kind of.\n\n59:20.800 --> 59:24.480\n And that's, you know, in our public discourse, you know, and as far as you see too much of\n\n59:24.480 --> 59:28.400\n this kind of thing and the sober discussions in the middle, which are the challenge he\n\n59:28.400 --> 59:31.560\n wants to have or where we need to be having our conversations.\n\n59:31.560 --> 59:36.480\n And you know, there's just not actually, there's not many forum fora for those.\n\n59:36.480 --> 59:39.180\n You know, there's, that's, that's kind of what I would look for.\n\n59:39.180 --> 59:42.040\n Maybe I could go and I could read a comment section of something and it would actually\n\n59:42.040 --> 59:44.520\n be this kind of dialogue going back and forth.\n\n59:44.520 --> 59:45.800\n You don't see much of this, right?\n\n59:45.800 --> 59:49.800\n Which is why actually there's a resurgence of podcasts out of all, because people are\n\n59:49.800 --> 59:55.760\n really hungry for conversation, but there's technology is not helping much.\n\n59:55.760 --> 1:00:01.520\n So comment sections of anything, including YouTube is not hurting and not helping.\n\n1:00:01.520 --> 1:00:02.520\n Yeah.\n\n1:00:02.520 --> 1:00:07.800\n And you think technically speaking, it's possible to help.\n\n1:00:07.800 --> 1:00:13.840\n I don't know the answers, but it's a, it's a, it's a less anonymity, a little more locality,\n\n1:00:13.840 --> 1:00:17.340\n you know, worlds that you kind of enter in and you trust the people there in those worlds\n\n1:00:17.340 --> 1:00:20.040\n so that when you start having a discussion, you know, not only is that people are not\n\n1:00:20.040 --> 1:00:23.120\n going to hurt you, but it's not going to be a total waste of your time because there's\n\n1:00:23.120 --> 1:00:26.640\n a lot of wasting of time that, you know, a lot of us, I pulled out of Facebook early\n\n1:00:26.640 --> 1:00:31.360\n on cause it was clearly going to waste a lot of my time even though there was some value.\n\n1:00:31.360 --> 1:00:34.600\n And so, yeah, worlds that are somehow you enter in and you know what you're getting\n\n1:00:34.600 --> 1:00:38.400\n and it's kind of appeals to you and you might, new things might happen, but you kind of have\n\n1:00:38.400 --> 1:00:40.820\n some, some trust in that world.\n\n1:00:40.820 --> 1:00:46.520\n And there's some deep, interesting, complex psychological aspects around anonymity, how\n\n1:00:46.520 --> 1:00:49.960\n that changes human behavior that's quite dark.\n\n1:00:49.960 --> 1:00:50.960\n Quite dark.\n\n1:00:50.960 --> 1:00:51.960\n Yeah.\n\n1:00:51.960 --> 1:00:55.440\n I think a lot of us are, especially those of us who really loved the advent of technology.\n\n1:00:55.440 --> 1:00:56.760\n I love social networks when they came out.\n\n1:00:56.760 --> 1:00:59.520\n I was just, I didn't see any negatives there at all.\n\n1:00:59.520 --> 1:01:01.720\n But then I started seeing comment sections.\n\n1:01:01.720 --> 1:01:04.760\n I think it was maybe, you know, with the CNN or something.\n\n1:01:04.760 --> 1:01:10.040\n And I started to go, wow, this, this darkness I just did not know about and, and our technology\n\n1:01:10.040 --> 1:01:11.520\n is now amplifying it.\n\n1:01:11.520 --> 1:01:15.960\n So sorry for the big philosophical question, but on that topic, do you think human beings,\n\n1:01:15.960 --> 1:01:21.120\n cause you've also, out of all things, had a foot in psychology too, the, do you think\n\n1:01:21.120 --> 1:01:23.800\n human beings are fundamentally good?\n\n1:01:23.800 --> 1:01:32.240\n Like all of us have good intent that could be mind or is it depending on context and\n\n1:01:32.240 --> 1:01:34.960\n environment, everybody could be evil.\n\n1:01:34.960 --> 1:01:37.720\n So my answer is fundamentally good.\n\n1:01:37.720 --> 1:01:39.240\n But fundamentally limited.\n\n1:01:39.240 --> 1:01:41.320\n All of us have very, you know, blinkers on.\n\n1:01:41.320 --> 1:01:43.940\n We don't see the other person's pain that easily.\n\n1:01:43.940 --> 1:01:46.680\n We don't see the other person's point of view that easily.\n\n1:01:46.680 --> 1:01:49.880\n We're very much in our own head, in our own world.\n\n1:01:49.880 --> 1:01:53.920\n And on my good days, I think the technology could open us up to, you know, more perspectives\n\n1:01:53.920 --> 1:01:58.560\n and more less blinkered and more understanding, you know, a lot of wars in human history happened\n\n1:01:58.560 --> 1:01:59.560\n because of just ignorance.\n\n1:01:59.560 --> 1:02:02.600\n They didn't, they, they thought the other person was doing this while their person wasn't\n\n1:02:02.600 --> 1:02:03.600\n doing this.\n\n1:02:03.600 --> 1:02:05.440\n And we have a huge amounts of that.\n\n1:02:05.440 --> 1:02:09.200\n But in my lifetime, I've not seen technology really help in that way yet.\n\n1:02:09.200 --> 1:02:13.600\n And I do, I do, I do believe in that, but you know, no, I think fundamentally humans\n\n1:02:13.600 --> 1:02:14.600\n are good.\n\n1:02:14.600 --> 1:02:17.440\n The people suffer, people have grievances because you have grudges and those things\n\n1:02:17.440 --> 1:02:20.000\n cause them to do things they probably wouldn't want.\n\n1:02:20.000 --> 1:02:22.640\n They regret it often.\n\n1:02:22.640 --> 1:02:28.080\n So no, I, I think it's a, you know, part of the progress of technology is to indeed allow\n\n1:02:28.080 --> 1:02:31.160\n it to be a little easier to be the real good person you actually are.\n\n1:02:31.160 --> 1:02:39.880\n Well, but do you think individual human life or society could be modeled as an optimization\n\n1:02:39.880 --> 1:02:40.880\n problem?\n\n1:02:40.880 --> 1:02:45.080\n Not the way I think typically, I mean, that's, you're talking about one of the most complex\n\n1:02:45.080 --> 1:02:49.600\n phenomenon in the whole, you know, in all of which the individual human life or society\n\n1:02:49.600 --> 1:02:50.600\n as a whole.\n\n1:02:50.600 --> 1:02:51.600\n Both, both.\n\n1:02:51.600 --> 1:02:54.440\n I mean, individual human life is amazingly complex.\n\n1:02:54.440 --> 1:02:58.960\n And so you know, optimization is kind of just one branch of mathematics that talks about\n\n1:02:58.960 --> 1:02:59.960\n certain kinds of things.\n\n1:02:59.960 --> 1:03:04.520\n And it just feels way too limited for the complexity of such things.\n\n1:03:04.520 --> 1:03:09.440\n What properties of optimization problems do you think, so do you think most interesting\n\n1:03:09.440 --> 1:03:13.860\n problems that could be solved through optimization, what kind of properties does that surface\n\n1:03:13.860 --> 1:03:19.680\n have non convexity, convexity, linearity, all those kinds of things, saddle points?\n\n1:03:19.680 --> 1:03:22.160\n Well, so optimization is just one piece of mathematics.\n\n1:03:22.160 --> 1:03:27.480\n You know, there's like, you just, even in our era, we're aware that say sampling is\n\n1:03:27.480 --> 1:03:31.520\n coming up, examples of something coming up with a distribution.\n\n1:03:31.520 --> 1:03:32.520\n What's optimization?\n\n1:03:32.520 --> 1:03:33.520\n What's sampling?\n\n1:03:33.520 --> 1:03:35.920\n Well, they, you can, if you're a kind of a certain kind of mathematician, you can try\n\n1:03:35.920 --> 1:03:38.680\n to blend them and make them seem to be sort of the same thing.\n\n1:03:38.680 --> 1:03:44.160\n But optimization is roughly speaking, trying to find a point that, a single point that\n\n1:03:44.160 --> 1:03:48.740\n is the optimum of a criterion function of some kind.\n\n1:03:48.740 --> 1:03:53.940\n And sampling is trying to, from that same surface, treat that as a distribution or density\n\n1:03:53.940 --> 1:03:56.920\n and find points that have high density.\n\n1:03:56.920 --> 1:04:03.480\n So I want the entire distribution in a sampling paradigm and I want the, you know, the single\n\n1:04:03.480 --> 1:04:07.640\n point, that's the best point in the optimization paradigm.\n\n1:04:07.640 --> 1:04:11.880\n Now if you were optimizing in the space of probability measures, the output of that could\n\n1:04:11.880 --> 1:04:13.080\n be a whole probability distribution.\n\n1:04:13.080 --> 1:04:15.560\n So you can start to make these things the same.\n\n1:04:15.560 --> 1:04:18.400\n But in mathematics, if you go too high up that kind of abstraction hierarchy, you start\n\n1:04:18.400 --> 1:04:22.900\n to lose the, you know, the ability to do the interesting theorems.\n\n1:04:22.900 --> 1:04:23.900\n So you kind of don't try that.\n\n1:04:23.900 --> 1:04:26.960\n You don't try to overly over abstract.\n\n1:04:26.960 --> 1:04:31.540\n So as a small tangent, what kind of worldview do you find more appealing?\n\n1:04:31.540 --> 1:04:35.080\n One that is deterministic or stochastic?\n\n1:04:35.080 --> 1:04:36.880\n Well, that's easy.\n\n1:04:36.880 --> 1:04:38.160\n I mean, I'm a statistician.\n\n1:04:38.160 --> 1:04:40.400\n You know, the world is highly stochastic.\n\n1:04:40.400 --> 1:04:42.360\n I don't know what's going to happen in the next five minutes, right?\n\n1:04:42.360 --> 1:04:44.360\n Because what you're going to ask, what we're going to do, what I'll say.\n\n1:04:44.360 --> 1:04:45.360\n Due to the uncertainty.\n\n1:04:45.360 --> 1:04:46.360\n Due to the...\n\n1:04:46.360 --> 1:04:47.360\n Massive uncertainty.\n\n1:04:47.360 --> 1:04:48.360\n Yeah.\n\n1:04:48.360 --> 1:04:49.360\n You know, massive uncertainty.\n\n1:04:49.360 --> 1:04:53.080\n And so the best I can do is have come rough sense or probability distribution on things\n\n1:04:53.080 --> 1:04:58.280\n and somehow use that in my reasoning about what to do now.\n\n1:04:58.280 --> 1:05:07.080\n So how does the distributed at scale when you have multi agent systems look like?\n\n1:05:07.080 --> 1:05:13.760\n So optimization can optimize sort of, it makes a lot more sense, sort of at least from my\n\n1:05:13.760 --> 1:05:18.240\n from robotics perspective, for a single robot, for a single agent, trying to optimize some\n\n1:05:18.240 --> 1:05:21.040\n objective function.\n\n1:05:21.040 --> 1:05:27.080\n When you start to enter the real world, this game theoretic concept starts popping up.\n\n1:05:27.080 --> 1:05:30.400\n That's how do you see optimization in this?\n\n1:05:30.400 --> 1:05:32.720\n Because you've talked about markets in a scale.\n\n1:05:32.720 --> 1:05:33.720\n What does that look like?\n\n1:05:33.720 --> 1:05:34.720\n Do you see it as optimization?\n\n1:05:34.720 --> 1:05:36.120\n Do you see it as sampling?\n\n1:05:36.120 --> 1:05:38.280\n Do you see like, how should you mark?\n\n1:05:38.280 --> 1:05:39.280\n These all blend together.\n\n1:05:39.280 --> 1:05:44.120\n And a system designer thinking about how to build an incentivized system will have a blend\n\n1:05:44.120 --> 1:05:45.120\n of all these things.\n\n1:05:45.120 --> 1:05:49.800\n So, you know, a particle in a potential well is optimizing a functional called a Lagrangian,\n\n1:05:49.800 --> 1:05:50.800\n right?\n\n1:05:50.800 --> 1:05:51.800\n The particle doesn't know that.\n\n1:05:51.800 --> 1:05:54.640\n There's no algorithm running that does that.\n\n1:05:54.640 --> 1:05:55.640\n It just happens.\n\n1:05:55.640 --> 1:05:59.160\n And so it's a description mathematically of something that helps us understand as analysts\n\n1:05:59.160 --> 1:06:00.840\n what's happening, right?\n\n1:06:00.840 --> 1:06:03.520\n And so the same thing will happen when we talk about, you know, mixtures of humans and\n\n1:06:03.520 --> 1:06:07.080\n computers and markets and so on and so forth, there'll be certain principles that allow\n\n1:06:07.080 --> 1:06:10.320\n us to understand what's happening, whether or not the actual algorithms are being used\n\n1:06:10.320 --> 1:06:13.000\n by any sense is not clear.\n\n1:06:13.000 --> 1:06:19.080\n Now at some point, I may have set up a multi agent or market kind of system.\n\n1:06:19.080 --> 1:06:22.440\n And I'm now thinking about an individual agent in that system.\n\n1:06:22.440 --> 1:06:25.200\n And they're asked to do some task and they're incentivized in some way, they get certain\n\n1:06:25.200 --> 1:06:28.160\n signals and they have some utility.\n\n1:06:28.160 --> 1:06:31.560\n What they will do at that point is they just won't know the answer, they may have to optimize\n\n1:06:31.560 --> 1:06:32.560\n to find an answer.\n\n1:06:32.560 --> 1:06:36.920\n Okay, so an artist could be embedded inside of an overall market.\n\n1:06:36.920 --> 1:06:39.880\n You know, and game theory is very, very broad.\n\n1:06:39.880 --> 1:06:44.020\n It is often studied very narrowly for certain kinds of problems.\n\n1:06:44.020 --> 1:06:47.920\n But it's roughly speaking, this is just the, I don't know what you're going to do.\n\n1:06:47.920 --> 1:06:51.560\n So I kind of anticipate that a little bit, and you anticipate what I'm anticipating.\n\n1:06:51.560 --> 1:06:53.360\n And we kind of go back and forth in our own minds.\n\n1:06:53.360 --> 1:06:55.480\n We run kind of thought experiments.\n\n1:06:55.480 --> 1:07:00.420\n You've talked about this interesting point in terms of game theory, you know, most optimization\n\n1:07:00.420 --> 1:07:04.840\n problems really hate saddle points, maybe you can describe what saddle points are.\n\n1:07:04.840 --> 1:07:09.560\n But I've heard you kind of mentioned that there's a there's a branch of optimization\n\n1:07:09.560 --> 1:07:14.720\n that you could try to explicitly look for saddle points as a good thing.\n\n1:07:14.720 --> 1:07:15.840\n Oh, not optimization.\n\n1:07:15.840 --> 1:07:19.740\n That's just game theory that that so there's all kinds of different equilibria in game\n\n1:07:19.740 --> 1:07:20.740\n theory.\n\n1:07:20.740 --> 1:07:23.220\n And some of them are highly explanatory behavior.\n\n1:07:23.220 --> 1:07:24.760\n They're not attempting to be algorithmic.\n\n1:07:24.760 --> 1:07:29.080\n They're just trying to say, if you happen to be at this equilibrium, you would see certain\n\n1:07:29.080 --> 1:07:30.080\n kind of behavior.\n\n1:07:30.080 --> 1:07:31.080\n And we see that in real life.\n\n1:07:31.080 --> 1:07:39.420\n That's what an economist wants to do, especially behavioral economists in continuous differential\n\n1:07:39.420 --> 1:07:44.020\n game theory, you're in continuous spaces, a some of the simplest equilibria are saddle\n\n1:07:44.020 --> 1:07:46.400\n points and Nash equilibrium as a saddle point.\n\n1:07:46.400 --> 1:07:48.440\n It's a special kind of saddle point.\n\n1:07:48.440 --> 1:07:53.560\n So classically, in game theory, you were trying to find Nash equilibria and an algorithmic\n\n1:07:53.560 --> 1:07:56.400\n game theory, you're trying to find algorithms that would find them.\n\n1:07:56.400 --> 1:07:57.760\n And so you're trying to find saddle points.\n\n1:07:57.760 --> 1:08:00.720\n I mean, so that's literally what you're trying to do.\n\n1:08:00.720 --> 1:08:04.160\n But you know, any economist knows that Nash equilibria have their limitations.\n\n1:08:04.160 --> 1:08:08.200\n They are definitely not that explanatory in many situations.\n\n1:08:08.200 --> 1:08:10.360\n They're not what you really want.\n\n1:08:10.360 --> 1:08:12.180\n There's other kind of equilibria.\n\n1:08:12.180 --> 1:08:15.440\n And there's names associated with these because they came from history with certain people\n\n1:08:15.440 --> 1:08:18.080\n working on them, but there will be new ones emerging.\n\n1:08:18.080 --> 1:08:21.200\n So you know, one example is a Stackelberg equilibrium.\n\n1:08:21.200 --> 1:08:25.800\n So you know, Nash, you and I are both playing this game against each other or for each other,\n\n1:08:25.800 --> 1:08:29.000\n maybe it's cooperative, and we're both going to think it through and then we're going to\n\n1:08:29.000 --> 1:08:32.520\n decide and we're going to do our thing simultaneously.\n\n1:08:32.520 --> 1:08:34.640\n You know, in a Stackelberg, no, I'm going to be the first mover.\n\n1:08:34.640 --> 1:08:35.880\n I'm going to make a move.\n\n1:08:35.880 --> 1:08:38.400\n You're going to look at my move and then you're going to make yours.\n\n1:08:38.400 --> 1:08:42.180\n Now since I know you're going to look at my move, I anticipate what you're going to do.\n\n1:08:42.180 --> 1:08:46.960\n And so I don't do something stupid, but then I know that you are also anticipating me.\n\n1:08:46.960 --> 1:08:51.800\n So we're kind of going back and forth on why, but there is then a first mover thing.\n\n1:08:51.800 --> 1:08:54.920\n And so those are different equilibria, right?\n\n1:08:54.920 --> 1:08:59.220\n And so just mathematically, yeah, these things have certain topologies and certain shapes\n\n1:08:59.220 --> 1:09:02.840\n that are like, what's it, algorithmically or dynamically, how do you move towards them?\n\n1:09:02.840 --> 1:09:05.820\n How do you move away from things?\n\n1:09:05.820 --> 1:09:09.500\n You know, so some of these questions have answers, they've been studied, others do not.\n\n1:09:09.500 --> 1:09:13.920\n And especially if it becomes stochastic, especially if there's large numbers of decentralized\n\n1:09:13.920 --> 1:09:17.440\n things, there's just, you know, young people get in this field who kind of think it's all\n\n1:09:17.440 --> 1:09:19.520\n done because we have, you know, TensorFlow.\n\n1:09:19.520 --> 1:09:23.680\n Well, no, these are all open problems and they're really important and interesting.\n\n1:09:23.680 --> 1:09:25.140\n And it's about strategic settings.\n\n1:09:25.140 --> 1:09:26.640\n How do I collect data?\n\n1:09:26.640 --> 1:09:29.280\n Suppose I don't know what you're going to do because I don't know you very well, right?\n\n1:09:29.280 --> 1:09:31.180\n Well, I got to collect data about you.\n\n1:09:31.180 --> 1:09:34.280\n So maybe I want to push you into a part of the space where I don't know much about you\n\n1:09:34.280 --> 1:09:35.280\n so I can get data.\n\n1:09:35.280 --> 1:09:38.960\n Cause, and then later I'll realize that you'll never, you'll never go there because of the\n\n1:09:38.960 --> 1:09:39.960\n way the game is set up.\n\n1:09:39.960 --> 1:09:44.080\n You know, that's part of the overall, you know, data analysis context is that.\n\n1:09:44.080 --> 1:09:47.840\n Even the game of poker is fascinating space, whenever there's any uncertainty, a lack of\n\n1:09:47.840 --> 1:09:52.560\n information, it's a super exciting space.\n\n1:09:52.560 --> 1:09:55.360\n Just to linger on optimization for a second.\n\n1:09:55.360 --> 1:10:01.600\n So when we look at deep learning, it's essentially minimization of a complicated loss function.\n\n1:10:01.600 --> 1:10:07.400\n So is there something insightful or hopeful that you see in the kinds of function surface\n\n1:10:07.400 --> 1:10:13.800\n that loss functions, the deep learning and in the real world is trying to optimize over?\n\n1:10:13.800 --> 1:10:20.040\n Is there something interesting as it's just the usual kind of problems of optimization?\n\n1:10:20.040 --> 1:10:25.600\n I think from an optimization point of view, that surface, first of all, it's pretty smooth.\n\n1:10:25.600 --> 1:10:29.120\n And secondly, if there's over, if it's over parameterized, there's kind of lots of paths\n\n1:10:29.120 --> 1:10:31.540\n down to reasonable Optima.\n\n1:10:31.540 --> 1:10:35.680\n And so kind of the getting downhill to the, to an optimum is viewed as not as hard as\n\n1:10:35.680 --> 1:10:39.980\n you might've expected in high dimensions.\n\n1:10:39.980 --> 1:10:43.200\n The fact that some Optima tend to be really good ones and others not so good.\n\n1:10:43.200 --> 1:10:48.080\n And you tend to, it's not, sometimes you find the good ones is sort of still needs explanation.\n\n1:10:48.080 --> 1:10:49.080\n Yeah.\n\n1:10:49.080 --> 1:10:53.560\n But, but the particular surface is coming from the particular generation of neural nets.\n\n1:10:53.560 --> 1:10:56.880\n I kind of suspect those will, those will change in 10 years.\n\n1:10:56.880 --> 1:10:58.360\n It will not be exactly those surfaces.\n\n1:10:58.360 --> 1:11:02.500\n There'll be some others that are an optimization theory will help contribute to why other surfaces\n\n1:11:02.500 --> 1:11:05.640\n or why other algorithms.\n\n1:11:05.640 --> 1:11:09.840\n Years of arithmetic operations with a little bit of nonlinearity, that's not, that didn't\n\n1:11:09.840 --> 1:11:10.960\n come from neuroscience per se.\n\n1:11:10.960 --> 1:11:13.920\n I mean, maybe in the minds of some of the people working on it, they were thinking about\n\n1:11:13.920 --> 1:11:19.040\n brains, but they were arithmetic circuits in all kinds of fields, computer science control\n\n1:11:19.040 --> 1:11:20.640\n theory and so on.\n\n1:11:20.640 --> 1:11:23.480\n And that layers of these could transform things in certain ways.\n\n1:11:23.480 --> 1:11:32.000\n And that if it's smooth, maybe you could find parameter values is a sort of big discovery\n\n1:11:32.000 --> 1:11:35.000\n that it's working, it's able to work at this scale.\n\n1:11:35.000 --> 1:11:39.840\n But I don't think that we're stuck with that and we're, we're certainly not stuck with\n\n1:11:39.840 --> 1:11:42.120\n that cause we're understanding the brain.\n\n1:11:42.120 --> 1:11:46.360\n So in terms of on the algorithm side sort of gradient descent, do you think we're stuck\n\n1:11:46.360 --> 1:11:49.360\n with gradient descent as a variance of it?\n\n1:11:49.360 --> 1:11:53.600\n What variance do you find interesting or do you think there'll be something else invented\n\n1:11:53.600 --> 1:11:59.720\n that is able to walk all over these optimization spaces in more interesting ways?\n\n1:11:59.720 --> 1:12:04.700\n So there's a co design of the surface and the, or the architecture and the algorithm.\n\n1:12:04.700 --> 1:12:08.080\n So if you just ask if we stay with the kind of architectures that we have now and not\n\n1:12:08.080 --> 1:12:13.080\n just neural nets, but you know, phase retrieval architectures or matrix completion architectures\n\n1:12:13.080 --> 1:12:15.080\n and so on.\n\n1:12:15.080 --> 1:12:19.560\n You know, I think we've kind of come to a place where yeah, a stochastic gradient algorithms\n\n1:12:19.560 --> 1:12:25.840\n are dominant and there are versions that are a little better than others.\n\n1:12:25.840 --> 1:12:29.160\n They have more guarantees, they're more robust and so on.\n\n1:12:29.160 --> 1:12:34.260\n And there's ongoing research to kind of figure out which is the best arm for which situation.\n\n1:12:34.260 --> 1:12:37.880\n But I think that that'll start to co evolve, that that'll put pressure on the actual architecture.\n\n1:12:37.880 --> 1:12:40.800\n And so we shouldn't do it in this particular way, we should do it in a different way because\n\n1:12:40.800 --> 1:12:45.340\n this other algorithm is now available if you do it in a different way.\n\n1:12:45.340 --> 1:12:51.600\n So that I can't really anticipate that co evolution process, but you know, gradients\n\n1:12:51.600 --> 1:12:54.480\n are amazing mathematical objects.\n\n1:12:54.480 --> 1:13:01.120\n They have a lot of people who start to study them more deeply mathematically are kind of\n\n1:13:01.120 --> 1:13:05.160\n shocked about what they are and what they can do.\n\n1:13:05.160 --> 1:13:11.040\n Think about it this way, suppose that I tell you if you move along the x axis, you go uphill\n\n1:13:11.040 --> 1:13:15.920\n in some objective by three units, whereas if you move along the y axis, you go uphill\n\n1:13:15.920 --> 1:13:18.000\n by seven units, right?\n\n1:13:18.000 --> 1:13:22.440\n Now I'm going to only allow you to move a certain unit distance, right?\n\n1:13:22.440 --> 1:13:23.440\n What are you going to do?\n\n1:13:23.440 --> 1:13:27.240\n Well, most people will say that I'm going to go along the y axis, I'm getting the biggest\n\n1:13:27.240 --> 1:13:31.120\n bang for my buck, you know, and my buck is only one unit, so I'm going to put all of\n\n1:13:31.120 --> 1:13:33.960\n it in the y axis, right?\n\n1:13:33.960 --> 1:13:39.320\n And why should I even take any of my strength, my step size and put any of it in the x axis\n\n1:13:39.320 --> 1:13:41.480\n because I'm getting less bang for my buck.\n\n1:13:41.480 --> 1:13:47.480\n That seems like a completely clear argument and it's wrong because the gradient direction\n\n1:13:47.480 --> 1:13:51.780\n is not to go along the y axis, it's to take a little bit of the x axis.\n\n1:13:51.780 --> 1:13:59.200\n And to understand that, you have to know some math and so even a trivial so called operator\n\n1:13:59.200 --> 1:14:04.020\n like gradient is not trivial and so, you know, exploiting its properties is still very important.\n\n1:14:04.020 --> 1:14:06.840\n Now we know that just pervading descent has got all kinds of problems, it gets stuck in\n\n1:14:06.840 --> 1:14:10.960\n many ways and it had never, you know, good dimension dependence and so on.\n\n1:14:10.960 --> 1:14:15.960\n So my own line of work recently has been about what kinds of stochasticity, how can we get\n\n1:14:15.960 --> 1:14:20.200\n dimension dependence, how can we do the theory of that and we've come up pretty favorable\n\n1:14:20.200 --> 1:14:22.720\n results with certain kinds of stochasticity.\n\n1:14:22.720 --> 1:14:25.000\n We have sufficient conditions generally.\n\n1:14:25.000 --> 1:14:28.760\n We know if you do this, we will give you a good guarantee.\n\n1:14:28.760 --> 1:14:32.280\n We don't have necessary conditions that it must be done a certain way in general.\n\n1:14:32.280 --> 1:14:38.200\n So stochasticity, how much randomness to inject into the walking along the gradient?\n\n1:14:38.200 --> 1:14:40.000\n And what kind of randomness?\n\n1:14:40.000 --> 1:14:42.240\n Why is randomness good in this process?\n\n1:14:42.240 --> 1:14:44.240\n Why is stochasticity good?\n\n1:14:44.240 --> 1:14:49.320\n Yeah, so I can give you simple answers but in some sense again, it's kind of amazing.\n\n1:14:49.320 --> 1:14:55.600\n Stochasticity just, you know, particular features of a surface that could have hurt you if you\n\n1:14:55.600 --> 1:15:02.080\n were doing one thing deterministically won't hurt you because by chance, there's very little\n\n1:15:02.080 --> 1:15:04.800\n chance that you would get hurt.\n\n1:15:04.800 --> 1:15:12.840\n So here stochasticity, it just kind of saves you from some of the particular features of\n\n1:15:12.840 --> 1:15:13.840\n surfaces.\n\n1:15:13.840 --> 1:15:19.400\n In fact, if you think about surfaces that are discontinuous in our first derivative,\n\n1:15:19.400 --> 1:15:25.400\n like an absolute value function, you will go down and hit that point where there's nondifferentiability.\n\n1:15:25.400 --> 1:15:28.520\n And if you're running a deterministic algorithm at that point, you can really do something\n\n1:15:28.520 --> 1:15:29.520\n bad.\n\n1:15:29.520 --> 1:15:32.960\n Whereas stochasticity just means it's pretty unlikely that's going to happen, that you're\n\n1:15:32.960 --> 1:15:35.720\n going to hit that point.\n\n1:15:35.720 --> 1:15:41.860\n So it's again, nontrivial to analyze but especially in higher dimensions, also stochasticity,\n\n1:15:41.860 --> 1:15:45.440\n our intuition isn't very good about it but it has properties that kind of are very appealing\n\n1:15:45.440 --> 1:15:49.200\n in high dimensions for a lot of large number of reasons.\n\n1:15:49.200 --> 1:15:52.520\n So it's all part of the mathematics to kind of, that's what's fun to work in the field\n\n1:15:52.520 --> 1:15:57.040\n is that you get to try to understand this mathematics.\n\n1:15:57.040 --> 1:16:01.200\n But long story short, you know, partly empirically, it was discovered stochastic gradient is very\n\n1:16:01.200 --> 1:16:06.600\n effective and theory kind of followed, I'd say, that but I don't see that we're getting\n\n1:16:06.600 --> 1:16:09.120\n clearly out of that.\n\n1:16:09.120 --> 1:16:15.560\n What's the most beautiful, mysterious, a profound idea to you in optimization?\n\n1:16:15.560 --> 1:16:17.360\n I don't know the most.\n\n1:16:17.360 --> 1:16:23.600\n But let me just say that Nesterov's work on Nesterov acceleration to me is pretty surprising\n\n1:16:23.600 --> 1:16:26.280\n and pretty deep.\n\n1:16:26.280 --> 1:16:27.280\n Can you elaborate?\n\n1:16:27.280 --> 1:16:32.240\n Well Nesterov acceleration is just that, suppose that we are going to use gradients\n\n1:16:32.240 --> 1:16:33.240\n to move around in a space.\n\n1:16:33.240 --> 1:16:37.280\n For the reasons I've alluded to, they're nice directions to move.\n\n1:16:37.280 --> 1:16:40.520\n And suppose that I tell you that you're only allowed to use gradients, you're not going\n\n1:16:40.520 --> 1:16:47.440\n to be allowed to use this local person that can only sense kind of the change in the surface.\n\n1:16:47.440 --> 1:16:50.920\n But I'm going to give you kind of a computer that's able to store all your previous gradients.\n\n1:16:50.920 --> 1:16:55.020\n And so you start to learn some something about the surface.\n\n1:16:55.020 --> 1:16:58.620\n And I'm going to restrict you to maybe move in the direction of like a linear span of\n\n1:16:58.620 --> 1:16:59.620\n all the gradients.\n\n1:16:59.620 --> 1:17:02.880\n So you can't kind of just move in some arbitrary direction, right?\n\n1:17:02.880 --> 1:17:05.720\n So now we have a well defined mathematical complexity model.\n\n1:17:05.720 --> 1:17:09.320\n There's certain classes of algorithms that can do that and others that can't.\n\n1:17:09.320 --> 1:17:13.800\n And we can ask for certain kinds of surfaces, how fast can you get down to the optimum?\n\n1:17:13.800 --> 1:17:14.960\n So there's answers to these.\n\n1:17:14.960 --> 1:17:21.040\n So for a smooth convex function, there's an answer, which is one over the number of steps\n\n1:17:21.040 --> 1:17:22.400\n squared.\n\n1:17:22.400 --> 1:17:29.120\n You will be within a ball of that size after k steps.\n\n1:17:29.120 --> 1:17:35.420\n Gradient descent in particular has a slower rate, it's one over k.\n\n1:17:35.420 --> 1:17:38.960\n So you could ask, is gradient descent actually, even though we know it's a good algorithm,\n\n1:17:38.960 --> 1:17:39.960\n is it the best algorithm?\n\n1:17:39.960 --> 1:17:41.960\n And the answer is no.\n\n1:17:41.960 --> 1:17:47.420\n Well, not clear yet, because one over k squared is a lower bound.\n\n1:17:47.420 --> 1:17:49.960\n That's probably the best you can do.\n\n1:17:49.960 --> 1:17:52.740\n Gradient is one over k, but is there something better?\n\n1:17:52.740 --> 1:17:59.280\n And so I think as a surprise to most, Nesterov discovered a new algorithm that has got two\n\n1:17:59.280 --> 1:18:00.280\n pieces to it.\n\n1:18:00.280 --> 1:18:06.640\n It's two gradients and puts those together in a certain kind of obscure way.\n\n1:18:06.640 --> 1:18:09.280\n And the thing doesn't even move downhill all the time.\n\n1:18:09.280 --> 1:18:10.760\n It sometimes goes back uphill.\n\n1:18:10.760 --> 1:18:13.160\n And if you're a physicist, that kind of makes some sense.\n\n1:18:13.160 --> 1:18:17.720\n You're building up some momentum and that is kind of the right intuition, but that intuition\n\n1:18:17.720 --> 1:18:22.460\n is not enough to understand kind of how to do it and why it works.\n\n1:18:22.460 --> 1:18:23.460\n But it does.\n\n1:18:23.460 --> 1:18:27.520\n It achieves one over k squared and it has a mathematical structure and it's still kind\n\n1:18:27.520 --> 1:18:31.160\n of to this day, a lot of us are writing papers and trying to explore that and understand\n\n1:18:31.160 --> 1:18:32.560\n it.\n\n1:18:32.560 --> 1:18:36.680\n So there are lots of cool ideas and optimization, but just kind of using gradients, I think\n\n1:18:36.680 --> 1:18:40.760\n is number one that goes back, you know, 150 years.\n\n1:18:40.760 --> 1:18:43.580\n And then Nesterov, I think has made a major contribution with this idea.\n\n1:18:43.580 --> 1:18:47.840\n So like you said, gradients themselves are in some sense, mysterious.\n\n1:18:47.840 --> 1:18:50.440\n They're not as trivial as...\n\n1:18:50.440 --> 1:18:52.040\n Not as trivial.\n\n1:18:52.040 --> 1:18:54.080\n Coordinate descent is more of a trivial one.\n\n1:18:54.080 --> 1:18:55.080\n You just pick one of the coordinates.\n\n1:18:55.080 --> 1:18:56.080\n That's how we think.\n\n1:18:56.080 --> 1:18:57.080\n That's how our human mind thinks.\n\n1:18:57.080 --> 1:18:58.200\n That's how our human minds think.\n\n1:18:58.200 --> 1:19:03.280\n And gradients are not that easy for our human mind to grapple with.\n\n1:19:03.280 --> 1:19:08.600\n An absurd question, but what is statistics?\n\n1:19:08.600 --> 1:19:12.160\n So here it's a little bit, it's somewhere between math and science and technology.\n\n1:19:12.160 --> 1:19:13.420\n It's somewhere in that convex hole.\n\n1:19:13.420 --> 1:19:17.720\n So it's a set of principles that allow you to make inferences that have got some reason\n\n1:19:17.720 --> 1:19:22.640\n to be believed and also principles that allow you to make decisions where you can have some\n\n1:19:22.640 --> 1:19:25.100\n reason to believe you're not going to make errors.\n\n1:19:25.100 --> 1:19:27.680\n So all of that requires some assumptions about what do you mean by an error?\n\n1:19:27.680 --> 1:19:31.420\n What do you mean by the probabilities?\n\n1:19:31.420 --> 1:19:38.080\n But after you start making some of those assumptions, you're led to conclusions that, yes, I can\n\n1:19:38.080 --> 1:19:42.080\n guarantee that if you do this in this way, your probability of making an error will be\n\n1:19:42.080 --> 1:19:43.600\n small.\n\n1:19:43.600 --> 1:19:47.880\n Your probability of continuing to not make errors over time will be small.\n\n1:19:47.880 --> 1:19:52.280\n And the probability that you found something that's real will be small, will be high.\n\n1:19:52.280 --> 1:19:54.640\n So decision making is a big part of that.\n\n1:19:54.640 --> 1:19:55.640\n Decision making is a big part.\n\n1:19:55.640 --> 1:19:56.640\n Yeah.\n\n1:19:56.640 --> 1:20:03.600\n So statistics, short history was that, it goes back as a formal discipline, 250 years\n\n1:20:03.600 --> 1:20:04.960\n or so.\n\n1:20:04.960 --> 1:20:09.280\n It was called inverse probability because around that era, probability was developed\n\n1:20:09.280 --> 1:20:12.000\n sort of especially to explain gambling situations.\n\n1:20:12.000 --> 1:20:15.480\n Of course, interesting.\n\n1:20:15.480 --> 1:20:18.880\n So you would say, well, given the state of nature is this, there's a certain roulette\n\n1:20:18.880 --> 1:20:23.680\n board that has a certain mechanism and what kind of outcomes do I expect to see?\n\n1:20:23.680 --> 1:20:27.440\n And especially if I do things long amounts of time, what outcomes will I see?\n\n1:20:27.440 --> 1:20:30.640\n And the physicists started to pay attention to this.\n\n1:20:30.640 --> 1:20:33.500\n And then people said, well, let's turn the problem around.\n\n1:20:33.500 --> 1:20:37.480\n What if I saw certain outcomes, could I infer what the underlying mechanism was?\n\n1:20:37.480 --> 1:20:38.480\n That's an inverse problem.\n\n1:20:38.480 --> 1:20:41.640\n And in fact, for quite a while, statistics was called inverse probability.\n\n1:20:41.640 --> 1:20:44.060\n That was the name of the field.\n\n1:20:44.060 --> 1:20:50.600\n And I believe that it was Laplace who was working in Napoleon's government who needed\n\n1:20:50.600 --> 1:20:54.280\n to do a census of France, learn about the people there.\n\n1:20:54.280 --> 1:21:01.240\n So he went and gathered data and he analyzed that data to determine policy and said, well,\n\n1:21:01.240 --> 1:21:06.760\n let's call this field that does this kind of thing statistics because the word state\n\n1:21:06.760 --> 1:21:07.760\n is in there.\n\n1:21:07.760 --> 1:21:12.360\n In French, that's etat, but it's the study of data for the state.\n\n1:21:12.360 --> 1:21:18.640\n So anyway, that caught on and it's been called statistics ever since.\n\n1:21:18.640 --> 1:21:23.280\n But by the time it got formalized, it was sort of in the 30s.\n\n1:21:23.280 --> 1:21:28.560\n And around that time, there was game theory and decision theory developed nearby.\n\n1:21:28.560 --> 1:21:31.640\n People in that era didn't think of themselves as either computer science or statistics or\n\n1:21:31.640 --> 1:21:32.640\n control or econ.\n\n1:21:32.640 --> 1:21:34.540\n They were all the above.\n\n1:21:34.540 --> 1:21:39.320\n And so Von Neumann is developing game theory, but also thinking of that as decision theory.\n\n1:21:39.320 --> 1:21:45.120\n Wald is an econometrician developing decision theory and then turning that into statistics.\n\n1:21:45.120 --> 1:21:50.160\n And so it's all about, here's not just data and you analyze it, here's a loss function.\n\n1:21:50.160 --> 1:21:51.160\n Here's what you care about.\n\n1:21:51.160 --> 1:21:53.080\n Here's the question you're trying to ask.\n\n1:21:53.080 --> 1:21:59.440\n Here is a probability model and here's the risk you will face if you make certain decisions.\n\n1:21:59.440 --> 1:22:04.040\n And to this day, in most advanced statistical curricula, you teach decision theory as the\n\n1:22:04.040 --> 1:22:08.500\n starting point and then it branches out into the two branches of Bayesian and frequentist.\n\n1:22:08.500 --> 1:22:11.840\n But that's all about decisions.\n\n1:22:11.840 --> 1:22:19.040\n In statistics, what is the most beautiful, mysterious, maybe surprising idea that you've\n\n1:22:19.040 --> 1:22:20.040\n come across?\n\n1:22:20.040 --> 1:22:21.040\n Yeah, good question.\n\n1:22:21.040 --> 1:22:27.640\n I mean, there's a bunch of surprising ones.\n\n1:22:27.640 --> 1:22:30.320\n There's something that's way too technical for this thing, but something called James\n\n1:22:30.320 --> 1:22:36.040\n Stein estimation, which is kind of surprising and really takes time to wrap your head around.\n\n1:22:36.040 --> 1:22:37.040\n Can you try to maybe...\n\n1:22:37.040 --> 1:22:39.120\n I think I don't want to even want to try.\n\n1:22:39.120 --> 1:22:44.200\n Let me just say a colleague at Steven Stigler at University of Chicago wrote a really beautiful\n\n1:22:44.200 --> 1:22:47.200\n paper on James Stein estimation, which helps to...\n\n1:22:47.200 --> 1:22:48.600\n It's views a paradox.\n\n1:22:48.600 --> 1:22:52.240\n It kind of defeats the mind's attempts to understand it, but you can and Steve has a\n\n1:22:52.240 --> 1:22:56.560\n nice perspective on that.\n\n1:22:56.560 --> 1:23:00.320\n So one of the troubles with statistics is that it's like in physics that are in quantum\n\n1:23:00.320 --> 1:23:02.520\n physics, you have multiple interpretations.\n\n1:23:02.520 --> 1:23:07.600\n There's a wave and particle duality in physics and you get used to that over time, but it\n\n1:23:07.600 --> 1:23:11.680\n still kind of haunts you that you don't really quite understand the relationship.\n\n1:23:11.680 --> 1:23:15.840\n The electron's a wave and electron's a particle.\n\n1:23:15.840 --> 1:23:16.840\n Well the same thing happens here.\n\n1:23:16.840 --> 1:23:21.320\n There's Bayesian ways of thinking and frequentist, and they are different.\n\n1:23:21.320 --> 1:23:25.000\n They sometimes become sort of the same in practice, but they are physically different.\n\n1:23:25.000 --> 1:23:27.640\n And then in some practice, they are not the same at all.\n\n1:23:27.640 --> 1:23:30.480\n They give you rather different answers.\n\n1:23:30.480 --> 1:23:33.860\n And so it is very much like wave and particle duality, and that is something that you have\n\n1:23:33.860 --> 1:23:35.840\n to kind of get used to in the field.\n\n1:23:35.840 --> 1:23:37.720\n Can you define Bayesian and frequentist?\n\n1:23:37.720 --> 1:23:41.320\n Yeah in decision theory you can make, I have a video that people could see.\n\n1:23:41.320 --> 1:23:46.040\n It's called are you a Bayesian or a frequentist and kind of help try to make it really clear.\n\n1:23:46.040 --> 1:23:47.160\n It comes from decision theory.\n\n1:23:47.160 --> 1:23:51.920\n So you know, decision theory, you're talking about loss functions, which are a function\n\n1:23:51.920 --> 1:23:54.760\n of data X and parameter theta.\n\n1:23:54.760 --> 1:23:57.080\n They're a function of two arguments.\n\n1:23:57.080 --> 1:23:58.080\n Okay.\n\n1:23:58.080 --> 1:23:59.880\n Neither one of those arguments is known.\n\n1:23:59.880 --> 1:24:01.640\n You don't know the data a priori.\n\n1:24:01.640 --> 1:24:03.760\n It's random and the parameters unknown.\n\n1:24:03.760 --> 1:24:04.760\n All right.\n\n1:24:04.760 --> 1:24:07.240\n So you have a function of two things you don't know, and you're trying to say, I want that\n\n1:24:07.240 --> 1:24:08.240\n function to be small.\n\n1:24:08.240 --> 1:24:10.880\n I want small loss, right?\n\n1:24:10.880 --> 1:24:13.440\n Well what are you going to do?\n\n1:24:13.440 --> 1:24:17.280\n So you sort of say, well, I'm going to average over these quantities or maximize over them\n\n1:24:17.280 --> 1:24:23.120\n or something so that, you know, I turn that uncertainty into something certain.\n\n1:24:23.120 --> 1:24:25.920\n So you could look at the first argument and average over it, or you could look at the\n\n1:24:25.920 --> 1:24:27.040\n second argument and average over it.\n\n1:24:27.040 --> 1:24:28.040\n That's Bayesian and frequentist.\n\n1:24:28.040 --> 1:24:32.840\n So the frequentist says, I'm going to look at the X, the data, and I'm going to take\n\n1:24:32.840 --> 1:24:35.360\n that as random and I'm going to average over the distribution.\n\n1:24:35.360 --> 1:24:40.700\n So I take the expectation loss under X. Theta is held fixed, right?\n\n1:24:40.700 --> 1:24:42.140\n That's called the risk.\n\n1:24:42.140 --> 1:24:46.480\n And so it's looking at other, all the data sets you could get, right?\n\n1:24:46.480 --> 1:24:50.200\n And say, how well will a certain procedure do under all those data sets?\n\n1:24:50.200 --> 1:24:52.560\n That's called a frequentist guarantee, right?\n\n1:24:52.560 --> 1:24:56.080\n So I think it is very appropriate when like you're building a piece of software and you're\n\n1:24:56.080 --> 1:24:59.280\n shipping it out there and people are using it on all kinds of data sets.\n\n1:24:59.280 --> 1:25:02.600\n You want to have a stamp, a guarantee on it that as people run it on many, many data sets\n\n1:25:02.600 --> 1:25:07.720\n that you never even thought about that 95% of the time it will do the right thing.\n\n1:25:07.720 --> 1:25:09.800\n Perfectly reasonable.\n\n1:25:09.800 --> 1:25:13.240\n The Bayesian perspective says, well, no, I'm going to look at the other argument of the\n\n1:25:13.240 --> 1:25:15.240\n loss function, the theta part, okay?\n\n1:25:15.240 --> 1:25:17.600\n That's unknown and I'm uncertain about it.\n\n1:25:17.600 --> 1:25:21.560\n So I could have my own personal probability for what it is, you know, how many tall people\n\n1:25:21.560 --> 1:25:22.560\n are there out there?\n\n1:25:22.560 --> 1:25:25.160\n I'm trying to infer the average height of the population while I have an idea roughly\n\n1:25:25.160 --> 1:25:27.440\n what the height is.\n\n1:25:27.440 --> 1:25:32.200\n So I'm going to average over the theta.\n\n1:25:32.200 --> 1:25:37.760\n So now that loss function as only now, again, one argument's gone, now it's a function of\n\n1:25:37.760 --> 1:25:41.760\n X and that's what a Bayesian does is they say, well, let's just focus on the particular\n\n1:25:41.760 --> 1:25:45.360\n X we got, the data set we got, we condition on that.\n\n1:25:45.360 --> 1:25:48.240\n Conditional on the X, I say something about my loss.\n\n1:25:48.240 --> 1:25:50.480\n That's a Bayesian approach to things.\n\n1:25:50.480 --> 1:25:54.360\n And the Bayesian will argue that it's not relevant to look at all the other data sets\n\n1:25:54.360 --> 1:25:58.800\n you could have gotten and average over them, the frequentist approach.\n\n1:25:58.800 --> 1:26:02.080\n It's really only the data sets you got, right?\n\n1:26:02.080 --> 1:26:06.000\n And I do agree with that, especially in situations where you're working with a scientist, you\n\n1:26:06.000 --> 1:26:09.440\n can learn a lot about the domain and you're really only focused on certain kinds of data\n\n1:26:09.440 --> 1:26:13.320\n and you gathered your data and you make inferences.\n\n1:26:13.320 --> 1:26:17.600\n I don't agree with it though, that, you know, in the sense that there are needs for frequentist\n\n1:26:17.600 --> 1:26:20.880\n guarantees, you're writing software, people are using it out there, you want to say something.\n\n1:26:20.880 --> 1:26:24.880\n So these two things have to got to fight each other a little bit, but they have to blend.\n\n1:26:24.880 --> 1:26:27.880\n So long story short, there's a set of ideas that are right in the middle that are called\n\n1:26:27.880 --> 1:26:29.880\n empirical Bayes.\n\n1:26:29.880 --> 1:26:34.600\n And empirical Bayes sort of starts with the Bayesian framework.\n\n1:26:34.600 --> 1:26:40.680\n It's kind of arguably philosophically more, you know, reasonable and kosher.\n\n1:26:40.680 --> 1:26:44.120\n Write down a bunch of the math that kind of flows from that, and then realize there's\n\n1:26:44.120 --> 1:26:48.040\n a bunch of things you don't know because it's the real world and you don't know everything.\n\n1:26:48.040 --> 1:26:50.160\n So you're uncertain about certain quantities.\n\n1:26:50.160 --> 1:26:54.440\n At that point, ask, is there a reasonable way to plug in an estimate for those things?\n\n1:26:54.440 --> 1:26:55.440\n Okay.\n\n1:26:55.440 --> 1:27:00.480\n And in some cases, there's quite a reasonable thing to do, to plug in, there's a natural\n\n1:27:00.480 --> 1:27:04.000\n thing you can observe in the world that you can plug in and then do a little bit more\n\n1:27:04.000 --> 1:27:06.440\n mathematics and assure yourself it's really good.\n\n1:27:06.440 --> 1:27:09.800\n So based on math or based on human expertise, what's, what, what are good?\n\n1:27:09.800 --> 1:27:10.800\n Oh, they're both going in.\n\n1:27:10.800 --> 1:27:16.160\n The Bayesian framework allows you to put a lot of human expertise in, but the math kind\n\n1:27:16.160 --> 1:27:19.480\n of guides you along that path and then kind of reassures you the end, you could put that\n\n1:27:19.480 --> 1:27:22.780\n stamp of approval under certain assumptions, this thing will work.\n\n1:27:22.780 --> 1:27:25.960\n So you asked the question, what's my favorite, you know, or what's the most surprising, nice\n\n1:27:25.960 --> 1:27:26.960\n idea.\n\n1:27:26.960 --> 1:27:31.760\n So one that is more accessible is something called false discovery rate, which is, you\n\n1:27:31.760 --> 1:27:35.520\n know, you're making not just one hypothesis test or making one decision, you're making\n\n1:27:35.520 --> 1:27:37.440\n a whole bag of them.\n\n1:27:37.440 --> 1:27:41.800\n And in that bag of decisions, you look at the ones where you made a discovery, you announced\n\n1:27:41.800 --> 1:27:43.320\n that something interesting had happened.\n\n1:27:43.320 --> 1:27:44.320\n All right.\n\n1:27:44.320 --> 1:27:47.160\n That's going to be some subset of your big bag.\n\n1:27:47.160 --> 1:27:50.880\n In the ones you made a discovery, which subset of those are bad?\n\n1:27:50.880 --> 1:27:53.320\n Or false, false discoveries.\n\n1:27:53.320 --> 1:27:57.680\n You'd like the fraction of your false discoveries among your discoveries to be small.\n\n1:27:57.680 --> 1:28:02.480\n That's a different criterion than accuracy or precision or recall or sensitivity and\n\n1:28:02.480 --> 1:28:03.480\n specificity.\n\n1:28:03.480 --> 1:28:04.960\n It's a different quantity.\n\n1:28:04.960 --> 1:28:09.960\n Those latter ones are almost all of them have more of a frequentist flavor.\n\n1:28:09.960 --> 1:28:13.960\n They say, given the truth is that the null hypothesis is true.\n\n1:28:13.960 --> 1:28:17.400\n Here's what accuracy I would get, or given that the alternative is true, here's what\n\n1:28:17.400 --> 1:28:18.400\n I would get.\n\n1:28:18.400 --> 1:28:22.360\n So it's kind of going forward from the state of nature to the data.\n\n1:28:22.360 --> 1:28:25.920\n The Bayesian goes the other direction from the data back to the state of nature.\n\n1:28:25.920 --> 1:28:28.180\n And that's actually what false discovery rate is.\n\n1:28:28.180 --> 1:28:32.680\n It says, given you made a discovery, okay, that's conditioned on your data.\n\n1:28:32.680 --> 1:28:34.960\n What's the probability of the hypothesis?\n\n1:28:34.960 --> 1:28:36.920\n It's going the other direction.\n\n1:28:36.920 --> 1:28:41.000\n And so the classical frequency look at that, well, I can't know that there's some priors\n\n1:28:41.000 --> 1:28:42.600\n needed in that.\n\n1:28:42.600 --> 1:28:47.460\n And the empirical Bayesian goes ahead and plows forward and starts writing down these formulas\n\n1:28:47.460 --> 1:28:51.280\n and realizes at some point, some of those things can actually be estimated in a reasonable\n\n1:28:51.280 --> 1:28:52.600\n way.\n\n1:28:52.600 --> 1:28:54.220\n And so it's kind of, it's a beautiful set of ideas.\n\n1:28:54.220 --> 1:28:56.800\n So I, this kind of line of argument has come out.\n\n1:28:56.800 --> 1:29:02.320\n It's not certainly mine, but it sort of came out from Robbins around 1960.\n\n1:29:02.320 --> 1:29:07.320\n Brad Efron has written beautifully about this in various papers and books.\n\n1:29:07.320 --> 1:29:14.120\n And the FDR is, you know, Benjamin in Israel, John Story did this Bayesian interpretation\n\n1:29:14.120 --> 1:29:15.120\n and so on.\n\n1:29:15.120 --> 1:29:18.480\n And he used to absorb these things over the years and find it a very healthy way to think\n\n1:29:18.480 --> 1:29:21.280\n about statistics.\n\n1:29:21.280 --> 1:29:28.240\n Let me ask you about intelligence to jump slightly back out into philosophy, perhaps.\n\n1:29:28.240 --> 1:29:33.940\n You said that maybe you can elaborate, but you said that defining just even the question\n\n1:29:33.940 --> 1:29:38.800\n of what is intelligence is a very difficult question.\n\n1:29:38.800 --> 1:29:39.800\n Is it a useful question?\n\n1:29:39.800 --> 1:29:45.240\n Do you think we'll one day understand the fundamentals of human intelligence and what\n\n1:29:45.240 --> 1:29:51.880\n it means, you know, have good benchmarks for general intelligence that we put before our\n\n1:29:51.880 --> 1:29:53.520\n machines?\n\n1:29:53.520 --> 1:29:58.240\n So I don't work on these topics so much that you're really asking the question for a psychologist\n\n1:29:58.240 --> 1:29:59.240\n really.\n\n1:29:59.240 --> 1:30:04.440\n And I studied some, but I don't consider myself at least an expert at this point.\n\n1:30:04.440 --> 1:30:07.680\n You know, a psychologist aims to understand human intelligence, right?\n\n1:30:07.680 --> 1:30:10.960\n And I think many psychologists I know are fairly humble about this.\n\n1:30:10.960 --> 1:30:15.880\n They might try to understand how a baby understands, you know, whether something's a solid or liquid\n\n1:30:15.880 --> 1:30:18.720\n or whether something's hidden or not.\n\n1:30:18.720 --> 1:30:24.400\n And maybe how a child starts to learn the meaning of certain words, what's a verb, what's\n\n1:30:24.400 --> 1:30:30.580\n a noun and also, you know, slowly but surely trying to figure out things.\n\n1:30:30.580 --> 1:30:35.720\n But humans ability to take a really complicated environment, reason about it, abstract about\n\n1:30:35.720 --> 1:30:41.520\n it, find the right abstractions, communicate about it, interact and so on is just, you\n\n1:30:41.520 --> 1:30:46.920\n know, really staggeringly rich and complicated.\n\n1:30:46.920 --> 1:30:51.320\n And so, you know, I think in all humility, we don't think we're kind of aiming for that\n\n1:30:51.320 --> 1:30:52.320\n in the near future.\n\n1:30:52.320 --> 1:30:56.820\n A certain psychologist doing experiments with babies in the lab or with people talking has\n\n1:30:56.820 --> 1:30:58.920\n a much more limited aspiration.\n\n1:30:58.920 --> 1:31:02.120\n And you know, Kahneman and Tversky would look at our reasoning patterns and they're not\n\n1:31:02.120 --> 1:31:05.880\n deeply understanding all the how we do our reasoning, but they're sort of saying, hey,\n\n1:31:05.880 --> 1:31:09.480\n here's some oddities about the reasoning and some things you should think about it.\n\n1:31:09.480 --> 1:31:14.560\n But also, as I emphasize in some things I've been writing about, you know, AI, the revolution\n\n1:31:14.560 --> 1:31:15.560\n hasn't happened yet.\n\n1:31:15.560 --> 1:31:16.560\n Yeah.\n\n1:31:16.560 --> 1:31:17.560\n Great blog post.\n\n1:31:17.560 --> 1:31:22.580\n I've been emphasizing that, you know, if you step back and look at intelligent systems\n\n1:31:22.580 --> 1:31:26.800\n of any kind and whatever you mean by intelligence, it's not just the humans or the animals or,\n\n1:31:26.800 --> 1:31:31.680\n you know, the plants or whatever, you know, so a market that brings goods into a city,\n\n1:31:31.680 --> 1:31:35.680\n you know, food to restaurants or something every day is a system.\n\n1:31:35.680 --> 1:31:37.820\n It's a decentralized set of decisions.\n\n1:31:37.820 --> 1:31:40.840\n Looking at it from far enough away, it's just like a collection of neurons.\n\n1:31:40.840 --> 1:31:44.600\n Every neuron is making its own little decisions, presumably in some way.\n\n1:31:44.600 --> 1:31:48.000\n And if you step back enough, every little part of an economic system is making all of\n\n1:31:48.000 --> 1:31:49.560\n its decisions.\n\n1:31:49.560 --> 1:31:53.020\n And just like with the brain, who knows what an individual neuron does and what the overall\n\n1:31:53.020 --> 1:31:54.800\n goal is, right?\n\n1:31:54.800 --> 1:31:58.560\n But something happens at some aggregate level, same thing with the economy.\n\n1:31:58.560 --> 1:32:01.380\n People eat in a city and it's robust.\n\n1:32:01.380 --> 1:32:04.840\n It works at all scales, small villages to big cities.\n\n1:32:04.840 --> 1:32:07.040\n It's been working for thousands of years.\n\n1:32:07.040 --> 1:32:10.520\n It works rain or shine, so it's adaptive.\n\n1:32:10.520 --> 1:32:14.680\n So all the kind of, you know, those are adjectives one tends to apply to intelligent systems.\n\n1:32:14.680 --> 1:32:19.960\n Robust, adaptive, you know, you don't need to keep adjusting it, self healing, whatever.\n\n1:32:19.960 --> 1:32:20.960\n Plus not perfect.\n\n1:32:20.960 --> 1:32:24.680\n You know, intelligences are never perfect and markets are not perfect.\n\n1:32:24.680 --> 1:32:28.160\n But I do not believe in this era that you cannot, that you can say, well, our computers\n\n1:32:28.160 --> 1:32:31.760\n are, our humans are smart, but you know, no markets are not, more markets are.\n\n1:32:31.760 --> 1:32:34.080\n So they are intelligent.\n\n1:32:34.080 --> 1:32:38.160\n Now we humans didn't evolve to be markets.\n\n1:32:38.160 --> 1:32:40.320\n We've been participating in them, right?\n\n1:32:40.320 --> 1:32:43.280\n But we are not ourselves a market per se.\n\n1:32:43.280 --> 1:32:45.920\n The neurons could be viewed as the market.\n\n1:32:45.920 --> 1:32:48.200\n There's economic, you know, neuroscience kind of perspective.\n\n1:32:48.200 --> 1:32:50.320\n That's interesting to pursue all that.\n\n1:32:50.320 --> 1:32:54.200\n The point though is, is that if you were to study humans and really be the world's best\n\n1:32:54.200 --> 1:32:57.440\n psychologist studied for thousands of years and come up with the theory of human intelligence,\n\n1:32:57.440 --> 1:33:01.840\n you might have never discovered principles of markets, you know, supply demand curves\n\n1:33:01.840 --> 1:33:05.000\n and you know, matching and auctions and all that.\n\n1:33:05.000 --> 1:33:08.760\n Those are real principles and they lead to a form of intelligence that's not maybe human\n\n1:33:08.760 --> 1:33:09.760\n intelligence.\n\n1:33:09.760 --> 1:33:11.480\n It's arguably another kind of intelligence.\n\n1:33:11.480 --> 1:33:14.880\n There probably are third kinds of intelligence or fourth that none of us are really thinking\n\n1:33:14.880 --> 1:33:16.480\n too much about right now.\n\n1:33:16.480 --> 1:33:20.840\n So if you really, and then all of those are relevant to computer systems in the future.\n\n1:33:20.840 --> 1:33:23.880\n Certainly the market one is relevant right now.\n\n1:33:23.880 --> 1:33:27.440\n Whereas the understanding of human intelligence is not so clear that it's relevant right now.\n\n1:33:27.440 --> 1:33:29.360\n Probably not.\n\n1:33:29.360 --> 1:33:33.160\n So if you want general intelligence, whatever one means by that, or, you know, understanding\n\n1:33:33.160 --> 1:33:37.000\n intelligence in a deep sense and all that, it is definitely has to be not just human\n\n1:33:37.000 --> 1:33:38.000\n intelligence.\n\n1:33:38.000 --> 1:33:39.280\n It's gotta be this broader thing.\n\n1:33:39.280 --> 1:33:40.480\n And that's not a mystery.\n\n1:33:40.480 --> 1:33:41.480\n Markets are intelligent.\n\n1:33:41.480 --> 1:33:46.000\n So, you know, it's definitely not just a philosophical stance to say we've got to move beyond intelligence.\n\n1:33:46.000 --> 1:33:47.000\n That sounds ridiculous.\n\n1:33:47.000 --> 1:33:48.000\n Yeah.\n\n1:33:48.000 --> 1:33:49.000\n But it's not.\n\n1:33:49.000 --> 1:33:52.160\n And in that blog post, you define different kinds of like intelligent infrastructure,\n\n1:33:52.160 --> 1:33:58.040\n AI, which I really like is some of the concepts you've just been describing.\n\n1:33:58.040 --> 1:34:02.720\n Do you see ourselves, if we see earth, human civilization as a single organism, do you\n\n1:34:02.720 --> 1:34:06.980\n think the intelligence of that organism, when you think from the perspective of markets\n\n1:34:06.980 --> 1:34:12.340\n and intelligence infrastructure is increasing, is it increasing linearly?\n\n1:34:12.340 --> 1:34:14.240\n Is it increasing exponentially?\n\n1:34:14.240 --> 1:34:16.000\n What do you think the future of that intelligence?\n\n1:34:16.000 --> 1:34:17.000\n Yeah, I don't know.\n\n1:34:17.000 --> 1:34:20.560\n I don't tend to think, I don't tend to answer questions like that because you know, that's\n\n1:34:20.560 --> 1:34:21.560\n science fiction.\n\n1:34:21.560 --> 1:34:25.200\n I'm hoping to catch you off guard.\n\n1:34:25.200 --> 1:34:31.320\n Well again, because you said it's so far in the future, it's fun to ask and you'll probably,\n\n1:34:31.320 --> 1:34:36.440\n you know, like you said, predicting the future is really nearly impossible.\n\n1:34:36.440 --> 1:34:43.720\n But say as an axiom, one day we create a human level, a superhuman level intelligent, not\n\n1:34:43.720 --> 1:34:47.560\n the scale of markets, but the scale of an individual.\n\n1:34:47.560 --> 1:34:51.760\n What do you think it is, what do you think it would take to do that?\n\n1:34:51.760 --> 1:34:58.880\n Or maybe to ask another question is how would that system be different than the biological\n\n1:34:58.880 --> 1:35:01.480\n human beings that we see around us today?\n\n1:35:01.480 --> 1:35:06.160\n Is it possible to say anything interesting to that question or is it just a stupid question?\n\n1:35:06.160 --> 1:35:08.200\n It's not a stupid question, but it's science fiction.\n\n1:35:08.200 --> 1:35:09.200\n Science fiction.\n\n1:35:09.200 --> 1:35:13.400\n And so I'm totally happy to read science fiction and think about it from time in my own life.\n\n1:35:13.400 --> 1:35:17.480\n I loved, there was this like brain in a vat kind of, you know, little thing that people\n\n1:35:17.480 --> 1:35:22.680\n were talking about when I was a student, I remember, you know, imagine that, you know,\n\n1:35:22.680 --> 1:35:26.960\n between your brain and your body, there's a, you know, there's a bunch of wires, right?\n\n1:35:26.960 --> 1:35:31.480\n And suppose that every one of them was replaced with a literal wire.\n\n1:35:31.480 --> 1:35:35.000\n And then suppose that wire was turned in actually a little wireless, you know, there's a receiver\n\n1:35:35.000 --> 1:35:36.000\n and sender.\n\n1:35:36.000 --> 1:35:41.560\n So the brain has got all the senders and receiver, you know, on all of its exiting, you know,\n\n1:35:41.560 --> 1:35:45.920\n axons and all the dendrites down to the body have replaced with senders and receivers.\n\n1:35:45.920 --> 1:35:50.080\n Now you could move the body off somewhere and put the brain in a vat, right?\n\n1:35:50.080 --> 1:35:54.600\n And then you could do things like start killing off those senders and receivers one by one.\n\n1:35:54.600 --> 1:35:56.960\n And after you've killed off all of them, where is that person?\n\n1:35:56.960 --> 1:35:59.640\n You know, they thought they were out in the body walking around the world and they moved\n\n1:35:59.640 --> 1:36:00.640\n on.\n\n1:36:00.640 --> 1:36:01.640\n So those are science fiction things.\n\n1:36:01.640 --> 1:36:02.640\n Those are fun to think about.\n\n1:36:02.640 --> 1:36:05.760\n It's just intriguing about where is, what is thought, where is it and all that.\n\n1:36:05.760 --> 1:36:10.680\n And I think every 18 year old should take philosophy classes and think about these things.\n\n1:36:10.680 --> 1:36:13.440\n And I think that everyone should think about what could happen in society that's kind of\n\n1:36:13.440 --> 1:36:14.440\n bad and all that.\n\n1:36:14.440 --> 1:36:17.600\n But I really don't think that's the right thing for most of us that are my age group\n\n1:36:17.600 --> 1:36:19.480\n to be doing and thinking about.\n\n1:36:19.480 --> 1:36:26.720\n I really think that we have so many more present, you know, first challenges and dangers and\n\n1:36:26.720 --> 1:36:32.320\n real things to build and all that such that, you know, spending too much time on science\n\n1:36:32.320 --> 1:36:36.080\n fiction, at least in public for like this, I think is not what we should be doing.\n\n1:36:36.080 --> 1:36:37.600\n Maybe over beers in private.\n\n1:36:37.600 --> 1:36:38.600\n That's right.\n\n1:36:38.600 --> 1:36:43.600\n Well, I'm not going to broadcast where I have beers because this is going to go on Facebook\n\n1:36:43.600 --> 1:36:45.480\n and I don't want a lot of people showing up there.\n\n1:36:45.480 --> 1:36:51.640\n But yeah, I'll, I love Facebook, Twitter, Amazon, YouTube.\n\n1:36:51.640 --> 1:36:58.280\n I have I'm optimistic and hopeful, but maybe, maybe I don't have grounds for such optimism\n\n1:36:58.280 --> 1:36:59.280\n and hope.\n\n1:36:59.280 --> 1:37:07.160\n But let me ask, you've mentored some of the brightest sort of some of the seminal figures\n\n1:37:07.160 --> 1:37:08.160\n in the field.\n\n1:37:08.160 --> 1:37:14.080\n Can you give advice to people who are undergraduates today?\n\n1:37:14.080 --> 1:37:17.640\n What does it take to take, you know, advice on their journey if they're interested in\n\n1:37:17.640 --> 1:37:23.920\n machine learning and in the ideas of markets from economics and psychology and all the\n\n1:37:23.920 --> 1:37:25.680\n kinds of things that you've exploring?\n\n1:37:25.680 --> 1:37:27.960\n What steps should they take on that journey?\n\n1:37:27.960 --> 1:37:30.360\n Well, yeah, first of all, the door is open and second, it's a journey.\n\n1:37:30.360 --> 1:37:33.880\n I like your language there.\n\n1:37:33.880 --> 1:37:37.120\n It is not that you're so brilliant and you have great, brilliant ideas and therefore\n\n1:37:37.120 --> 1:37:42.440\n that's just, you know, that's how you have success or that's how you enter into the field.\n\n1:37:42.440 --> 1:37:48.480\n It's that you apprentice yourself, you spend a lot of time, you work on hard things, you\n\n1:37:48.480 --> 1:37:53.880\n try and pull back and you be as broad as you can, you talk to lots of people.\n\n1:37:53.880 --> 1:37:57.000\n And it's like entering in any kind of a creative community.\n\n1:37:57.000 --> 1:38:01.600\n There's years that are needed and human connections are critical to it.\n\n1:38:01.600 --> 1:38:06.080\n So, you know, I think about, you know, being a musician or being an artist or something,\n\n1:38:06.080 --> 1:38:10.600\n you don't just, you know, immediately from day one, you know, you're a genius and therefore\n\n1:38:10.600 --> 1:38:11.600\n you do it.\n\n1:38:11.600 --> 1:38:18.900\n No, you, you know, practice really, really hard on basics and you be humble about where\n\n1:38:18.900 --> 1:38:22.200\n you are and then, and you realize you'll never be an expert on everything.\n\n1:38:22.200 --> 1:38:29.460\n So you kind of pick and there's a lot of randomness and a lot of kind of luck, but luck just kind\n\n1:38:29.460 --> 1:38:33.960\n of picks out which branch of the tree you go down, but you'll go down some branch.\n\n1:38:33.960 --> 1:38:35.460\n So yeah, it's a community.\n\n1:38:35.460 --> 1:38:39.200\n So the graduate school is, I still think is one of the wonderful phenomena that we have\n\n1:38:39.200 --> 1:38:40.780\n in our, in our world.\n\n1:38:40.780 --> 1:38:43.160\n It's very much about apprenticeship with an advisor.\n\n1:38:43.160 --> 1:38:45.780\n It's very much about a group of people you belong to.\n\n1:38:45.780 --> 1:38:47.020\n It's a four or five year process.\n\n1:38:47.020 --> 1:38:51.580\n So it's plenty of time to start from kind of nothing to come up to something, you know,\n\n1:38:51.580 --> 1:38:54.700\n more, more expertise, and then to start to have your own creativity start to flower,\n\n1:38:54.700 --> 1:38:58.240\n even surprising your own self.\n\n1:38:58.240 --> 1:38:59.760\n And it's a very cooperative endeavor.\n\n1:38:59.760 --> 1:39:05.620\n I think a lot of people think of science as highly competitive and I think in some other\n\n1:39:05.620 --> 1:39:08.080\n fields it might be more so.\n\n1:39:08.080 --> 1:39:11.860\n Here it's way more cooperative than you might imagine.\n\n1:39:11.860 --> 1:39:14.660\n And people are always teaching each other something and people are always more than\n\n1:39:14.660 --> 1:39:20.000\n happy to be clear that, so I feel I'm an expert on certain kinds of things, but I'm very much\n\n1:39:20.000 --> 1:39:23.480\n not expert on lots of other things and a lot of them are relevant and a lot of them are,\n\n1:39:23.480 --> 1:39:26.320\n I should know, but should in some society, you know, you don't.\n\n1:39:26.320 --> 1:39:32.100\n So I'm always willing to reveal my ignorance to people around me so they can teach me things.\n\n1:39:32.100 --> 1:39:34.220\n And I think a lot of us feel that way about our field.\n\n1:39:34.220 --> 1:39:35.460\n So it's very cooperative.\n\n1:39:35.460 --> 1:39:39.140\n I might add it's also very international because it's so cooperative.\n\n1:39:39.140 --> 1:39:40.780\n We see no barriers.\n\n1:39:40.780 --> 1:39:44.460\n And so that the nationalism that you see, especially in the current era and everything\n\n1:39:44.460 --> 1:39:48.180\n is just at odds with the way that most of us think about what we're doing here, where\n\n1:39:48.180 --> 1:39:53.420\n this is a human endeavor and we cooperate and are very much trying to do it together\n\n1:39:53.420 --> 1:39:56.580\n for the, you know, the benefit of everybody.\n\n1:39:56.580 --> 1:40:02.820\n So last question, where and how and why did you learn French and which language is more\n\n1:40:02.820 --> 1:40:05.660\n beautiful English or French?\n\n1:40:05.660 --> 1:40:06.660\n Great question.\n\n1:40:06.660 --> 1:40:10.100\n So first of all, I think Italian is actually more beautiful than French and English.\n\n1:40:10.100 --> 1:40:11.100\n And I also speak that.\n\n1:40:11.100 --> 1:40:15.860\n So I'm married to an Italian and I have kids and we speak Italian.\n\n1:40:15.860 --> 1:40:23.180\n Anyway, all kidding aside, every language allows you to express things a bit differently.\n\n1:40:23.180 --> 1:40:26.820\n And it is one of the great fun things to do in life is to explore those things.\n\n1:40:26.820 --> 1:40:34.540\n So in fact, when I kids or teens or college students ask me what they study, I say, well,\n\n1:40:34.540 --> 1:40:36.980\n do what your heart, where your heart is, certainly do a lot of math.\n\n1:40:36.980 --> 1:40:42.500\n Math is good for everybody, but do some poetry and do some history and do some language too.\n\n1:40:42.500 --> 1:40:44.620\n You know, throughout your life, you'll want to be a thinking person.\n\n1:40:44.620 --> 1:40:47.500\n You'll want to have done that.\n\n1:40:47.500 --> 1:40:54.700\n For me, French I learned when I was, I'd say a late teen, I was living in the middle of\n\n1:40:54.700 --> 1:41:01.100\n the country in Kansas and not much was going on in Kansas with all due respect to Kansas.\n\n1:41:01.100 --> 1:41:04.380\n And so my parents happened to have some French books on the shelf and just in my boredom,\n\n1:41:04.380 --> 1:41:07.140\n I pulled them down and I found this is fun.\n\n1:41:07.140 --> 1:41:09.220\n And I kind of learned the language by reading.\n\n1:41:09.220 --> 1:41:13.540\n And when I first heard it spoken, I had no idea what was being spoken, but I realized\n\n1:41:13.540 --> 1:41:18.540\n I had somehow knew it from some previous life and so I made the connection.\n\n1:41:18.540 --> 1:41:23.500\n But then I traveled and just I love to go beyond my own barriers and my own comfort\n\n1:41:23.500 --> 1:41:24.500\n or whatever.\n\n1:41:24.500 --> 1:41:29.460\n And I found myself on trains in France next to say older people who had lived a whole\n\n1:41:29.460 --> 1:41:30.460\n life of their own.\n\n1:41:30.460 --> 1:41:37.900\n And the ability to communicate with them was special and the ability to also see myself\n\n1:41:37.900 --> 1:41:43.100\n in other people's shoes and have empathy and kind of work on that language as part of that.\n\n1:41:43.100 --> 1:41:49.140\n So after that kind of experience and also embedding myself in French culture, which\n\n1:41:49.140 --> 1:41:53.780\n is quite amazing, languages are rich, not just because there's something inherently\n\n1:41:53.780 --> 1:41:55.940\n beautiful about it, but it's all the creativity that went into it.\n\n1:41:55.940 --> 1:41:59.900\n So I learned a lot of songs, read poems, read books.\n\n1:41:59.900 --> 1:42:05.300\n And then I was here actually at MIT where we're doing the podcast today and a young\n\n1:42:05.300 --> 1:42:11.960\n professor not yet married and not having a lot of friends in the area.\n\n1:42:11.960 --> 1:42:13.980\n So I just didn't have, I was kind of a bored person.\n\n1:42:13.980 --> 1:42:16.020\n I said, I heard a lot of Italians around.\n\n1:42:16.020 --> 1:42:20.020\n There's happened to be a lot of Italians at MIT, an Italian professor for some reason.\n\n1:42:20.020 --> 1:42:22.060\n And so I was kind of vaguely understanding what they were talking about.\n\n1:42:22.060 --> 1:42:23.660\n I said, well, I should learn this language too.\n\n1:42:23.660 --> 1:42:25.620\n So I did.\n\n1:42:25.620 --> 1:42:30.860\n And then later met my spouse and Italian became a part of my life.\n\n1:42:30.860 --> 1:42:32.180\n But I go to China a lot these days.\n\n1:42:32.180 --> 1:42:38.160\n I go to Asia, I go to Europe and every time I go, I kind of am amazed by the richness\n\n1:42:38.160 --> 1:42:42.820\n of human experience and the people don't have any idea if you haven't traveled, kind of\n\n1:42:42.820 --> 1:42:46.900\n how amazingly rich and I love the diversity.\n\n1:42:46.900 --> 1:42:48.060\n It's not just a buzzword to me.\n\n1:42:48.060 --> 1:42:49.060\n It really means something.\n\n1:42:49.060 --> 1:42:53.180\n I love to embed myself with other people's experiences.\n\n1:42:53.180 --> 1:42:56.420\n And so yeah, learning language is a big part of that.\n\n1:42:56.420 --> 1:43:00.460\n I think I've said in some interview at some point that if I had millions of dollars and\n\n1:43:00.460 --> 1:43:03.300\n infinite time or whatever, what would you really work on if you really wanted to do\n\n1:43:03.300 --> 1:43:04.300\n AI?\n\n1:43:04.300 --> 1:43:07.360\n And for me, that is natural language and really done right.\n\n1:43:07.360 --> 1:43:09.840\n Deep understanding of language.\n\n1:43:09.840 --> 1:43:13.580\n That's to me, an amazingly interesting scientific challenge.\n\n1:43:13.580 --> 1:43:15.180\n One we're very far away on.\n\n1:43:15.180 --> 1:43:17.720\n One we're very far away, but good natural language.\n\n1:43:17.720 --> 1:43:19.140\n People are kind of really invested then.\n\n1:43:19.140 --> 1:43:22.460\n I think a lot of them see that's where the core of AI is that if you understand that\n\n1:43:22.460 --> 1:43:26.580\n you really help human communication, you understand something about the human mind, the semantics\n\n1:43:26.580 --> 1:43:30.980\n that come out of the human mind and I agree, I think that will be such a long time.\n\n1:43:30.980 --> 1:43:34.720\n So I didn't do that in my career just cause I kind of, I was behind in the early days.\n\n1:43:34.720 --> 1:43:36.460\n I didn't kind of know enough of that stuff.\n\n1:43:36.460 --> 1:43:41.180\n I was at MIT, I didn't learn much language and it was too late at some point to kind\n\n1:43:41.180 --> 1:43:47.180\n of spend a whole career doing that, but I admire that field and so in my little way\n\n1:43:47.180 --> 1:43:53.340\n by learning language, you know, kind of that part of my brain has been trained up.\n\n1:43:53.340 --> 1:43:55.460\n Jan was right.\n\n1:43:55.460 --> 1:43:57.460\n You truly are the Miles Davis of machine learning.\n\n1:43:57.460 --> 1:43:59.620\n I don't think there's a better place than it.\n\n1:43:59.620 --> 1:44:01.580\n Mike it was a huge honor talking to you today.\n\n1:44:01.580 --> 1:44:02.580\n Merci beaucoup.\n\n1:44:02.580 --> 1:44:03.580\n All right.\n\n1:44:03.580 --> 1:44:04.580\n It's been my pleasure.\n\n1:44:04.580 --> 1:44:09.300\n Thanks for listening to this conversation with Michael I. Jordan and thank you to our\n\n1:44:09.300 --> 1:44:11.420\n presenting sponsor, Cash App.\n\n1:44:11.420 --> 1:44:18.100\n Download it, use code LEXPodcast, you'll get $10 and $10 will go to FIRST, an organization\n\n1:44:18.100 --> 1:44:22.580\n that inspires and educates young minds to become science and technology innovators of\n\n1:44:22.580 --> 1:44:23.880\n tomorrow.\n\n1:44:23.880 --> 1:44:28.820\n If you enjoy this podcast, subscribe on YouTube, give it five stars on Apple Podcast, support\n\n1:44:28.820 --> 1:44:34.700\n on Patreon, or simply connect with me on Twitter at Lex Friedman.\n\n1:44:34.700 --> 1:44:39.340\n And now let me leave you with some words of wisdom from Michael I. Jordan from his blog\n\n1:44:39.340 --> 1:44:45.580\n post titled Artificial Intelligence, the revolution hasn't happened yet, calling for broadening\n\n1:44:45.580 --> 1:44:48.560\n the scope of the AI field.\n\n1:44:48.560 --> 1:44:52.860\n We should embrace the fact that what we are witnessing is the creation of a new branch\n\n1:44:52.860 --> 1:44:54.340\n of engineering.\n\n1:44:54.340 --> 1:45:00.660\n The term engineering is often invoked in a narrow sense in academia and beyond with overtones\n\n1:45:00.660 --> 1:45:07.540\n of cold, effectless machinery and negative connotations of loss of control by humans.\n\n1:45:07.540 --> 1:45:11.020\n But an engineering discipline can be what we want it to be.\n\n1:45:11.020 --> 1:45:16.340\n In the current era, we have a real opportunity to conceive of something historically new,\n\n1:45:16.340 --> 1:45:19.740\n a human centric engineering discipline.\n\n1:45:19.740 --> 1:45:24.380\n I will resist giving this emerging discipline a name, but if the acronym AI continues to\n\n1:45:24.380 --> 1:45:29.860\n be used, let's be aware of the very real limitations of this placeholder.\n\n1:45:29.860 --> 1:45:37.300\n Let's broaden our scope, tone down the hype, and recognize the serious challenges ahead.\n\n1:45:37.300 --> 1:45:50.300\n Thank you for listening and hope to see you next time.\n\n"
}
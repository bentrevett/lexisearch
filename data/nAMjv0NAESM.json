{
  "title": "Scott Aaronson: Computational Complexity and Consciousness | Lex Fridman Podcast #130",
  "id": "nAMjv0NAESM",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:04.240\n The following is a conversation with Scott Aaronson, his second time on the podcast.\n\n00:04.960 --> 00:10.320\n He is a professor at UT Austin, director of the Quantum Information Center,\n\n00:10.320 --> 00:17.120\n and previously a professor at MIT. Last time we talked about quantum computing. This time\n\n00:17.680 --> 00:23.280\n we talk about computation complexity, consciousness, and theories of everything.\n\n00:23.280 --> 00:31.280\n I'm recording this intro, as you may be able to tell, in a very strange room in the middle of the\n\n00:31.280 --> 00:39.280\n night. I'm not really sure how I got here or how I'm going to get out, but Hunter S. Thompson\n\n00:39.280 --> 00:46.080\n saying I think applies to today and the last few days and actually the last couple of weeks.\n\n00:46.080 --> 00:51.440\n Life should not be a journey to the grave with the intention of arriving safely in a pretty and well\n\n00:51.440 --> 00:59.440\n preserved body, but rather to skid in broadside in a cloud of smoke, thoroughly used up, totally\n\n00:59.440 --> 01:08.080\n worn out, and loudly proclaiming, wow, what a ride. So I figured whatever I'm up to here,\n\n01:08.880 --> 01:14.480\n and yes, lots of wine is involved, I'm going to have to improvise, have to improvise,\n\n01:14.480 --> 01:20.320\n have to improvise, hence this recording. Okay, quick mention of each sponsor,\n\n01:20.320 --> 01:25.520\n followed by some thoughts related to the episode. First sponsor is SimpliSafe, a home security\n\n01:25.520 --> 01:32.880\n company I use to monitor and protect my apartment, though of course I'm always prepared with a fall\n\n01:32.880 --> 01:43.520\n back plan, as a man in this world must always be. Second sponsor is 8sleep, a mattress that cools\n\n01:43.520 --> 01:50.160\n itself, measures heart rate variability, has a nap, and has given me yet another reason to look\n\n01:50.160 --> 01:57.920\n forward to sleep, including the all important power nap. Third sponsor is ExpressVPN, the VPN\n\n01:57.920 --> 02:05.040\n I've used for many years to protect my privacy on the internet. Finally, the fourth sponsor is Better\n\n02:05.040 --> 02:11.440\n Help, online therapy when you want to face your demons with a licensed professional, not just\n\n02:11.440 --> 02:17.280\n by doing David Goggins like physical challenges like I seem to do on occasion. Please check out\n\n02:17.280 --> 02:21.840\n these sponsors in the description to get a discount and to support the podcast.\n\n02:22.800 --> 02:27.520\n As a side note, let me say that this is the second time I've recorded a conversation outdoors.\n\n02:28.400 --> 02:34.160\n The first one was with Steven Wolfram when it was actually sunny out, in this case it was raining,\n\n02:34.160 --> 02:40.640\n which is why I found a covered outdoor patio. But I learned a valuable lesson, which is that\n\n02:40.640 --> 02:47.120\n raindrops can be quite loud on the hard metal surface of a patio cover. I did my best with\n\n02:47.120 --> 02:54.640\n the audio, I hope it still sounds okay to you. I'm learning, always improving. In fact, as Scott says,\n\n02:55.440 --> 03:00.720\n if you always win, then you're probably doing something wrong. To be honest, I get pretty upset\n\n03:00.720 --> 03:08.240\n with myself when I fail, small or big, but I've learned that this feeling is priceless. It can be\n\n03:08.240 --> 03:16.080\n fuel, when channeled into concrete plans of how to improve. So if you enjoy this thing, subscribe\n\n03:16.080 --> 03:22.480\n on YouTube, review the Five Stars in Apple podcast, follow on Spotify, support on Patreon,\n\n03:22.480 --> 03:29.200\n or connect with me on Twitter at Lex Friedman. And now, here's my conversation with Scott Aaronson.\n\n03:30.320 --> 03:34.960\n Let's start with the most absurd question, but I've read you write some fascinating stuff about\n\n03:34.960 --> 03:40.720\n it, so let's go there. Are we living in a simulation? What difference does it make,\n\n03:40.720 --> 03:46.640\n Lex? I mean, I'm serious. What difference? Because if we are living in a simulation,\n\n03:46.640 --> 03:52.640\n it raises the question, how real does something have to be in simulation for it to be sufficiently\n\n03:52.640 --> 03:57.760\n immersive for us humans? But I mean, even in principle, how could we ever know if we were in\n\n03:57.760 --> 04:02.640\n one, right? A perfect simulation, by definition, is something that's indistinguishable from the\n\n04:02.640 --> 04:07.440\n real thing. Well, we didn't say anything about perfect. No, no, that's right. Well, if it was\n\n04:07.440 --> 04:13.040\n an imperfect simulation, if we could hack it, find a bug in it, then that would be one thing,\n\n04:13.040 --> 04:19.840\n right? If this was like The Matrix and there was a way for me to do flying kung fu moves or\n\n04:19.840 --> 04:24.400\n something by hacking the simulation, well then we would have to cross that bridge when we came to\n\n04:24.400 --> 04:33.360\n it, wouldn't we? At that point, it's hard to see the difference between that and just what people\n\n04:33.360 --> 04:39.440\n would ordinarily refer to as a world with miracles. What about from a different perspective, thinking\n\n04:39.440 --> 04:44.560\n about the universe as a computation, like a program running on a computer? That's kind of\n\n04:44.560 --> 04:50.480\n a neighboring concept. It is. It is an interesting and reasonably well defined question to ask,\n\n04:50.480 --> 04:57.760\n is the world computable? Does the world satisfy what we would call in CS the church touring\n\n04:57.760 --> 05:07.040\n thesis? That is, could we take any physical system and simulate it to any desired precision by a\n\n05:07.040 --> 05:13.920\n touring machine, given the appropriate input data, right? And so far, I think the indications are\n\n05:13.920 --> 05:20.240\n pretty strong that our world does seem to satisfy the church touring thesis. At least if it doesn't,\n\n05:20.240 --> 05:27.360\n then we haven't yet discovered why not. But now, does that mean that our universe is a simulation?\n\n05:27.360 --> 05:33.680\n Well, that word seems to suggest that there is some other larger universe in which it is running.\n\n05:34.800 --> 05:40.880\n And the problem there is that if the simulation is perfect, then we're never going to be able to get\n\n05:40.880 --> 05:47.760\n any direct evidence about that other universe. We will only be able to see the effects of the\n\n05:47.760 --> 05:53.680\n computation that is running in this universe. Well, let's imagine an analogy. Let's imagine\n\n05:53.680 --> 06:01.280\n a PC, a personal computer, a computer. Is it possible with the advent of artificial intelligence\n\n06:01.280 --> 06:08.880\n for the computer to look outside of itself to see, to understand its creator? I mean,\n\n06:08.880 --> 06:14.800\n that's a simple, is that a ridiculous analogy? Well, I mean, with the computers that we actually\n\n06:14.800 --> 06:23.520\n have, I mean, first of all, we all know that humans have done an imperfect job of enforcing\n\n06:23.520 --> 06:29.840\n the abstraction boundaries of computers, right? Like you may try to confine some program to a\n\n06:29.840 --> 06:37.680\n playpen, but as soon as there's one memory allocation error in the C program, then the\n\n06:37.680 --> 06:43.040\n program has gotten out of that playpen and it can do whatever it wants, right? This is how most hacks\n\n06:43.040 --> 06:49.680\n work, you know, viruses and worms and exploits. And, you know, you would have to imagine that an\n\n06:49.680 --> 06:55.360\n AI would be able to discover something like that. Now, you know, of course, if we could actually\n\n06:55.360 --> 07:02.960\n discover some exploit of reality itself, then, you know, then this whole, I mean, then in some\n\n07:02.960 --> 07:08.480\n sense we wouldn't have to philosophize about this, right? This would no longer be a metaphysical\n\n07:08.480 --> 07:17.120\n conversation. But the question is, what would that hack look like? Yeah, well, I have no idea. I mean,\n\n07:18.400 --> 07:25.120\n Peter Shor, you know, the very famous person in quantum computing, of course, has joked that\n\n07:25.760 --> 07:31.440\n maybe the reason why we haven't yet, you know, integrated general relativity in quantum mechanics\n\n07:31.440 --> 07:36.160\n is that, you know, the part of the universe that depends on both of them was actually left\n\n07:36.160 --> 07:42.640\n unspecified. And if we ever tried to do an experiment involving the singularity of a black\n\n07:42.640 --> 07:47.840\n hole or something like that, then, you know, the universe would just generate an overflow error or\n\n07:47.840 --> 07:55.440\n something, right? Yeah, we would just crash the universe. Now, you know, the universe, you know,\n\n07:55.440 --> 08:03.120\n has seemed to hold up pretty well for, you know, 14 billion years, right? So, you know, my, you know,\n\n08:03.120 --> 08:09.760\n a Occam's razor kind of guess has to be that, you know, it will continue to hold up, you know,\n\n08:09.760 --> 08:15.520\n that the fact that we don't know the laws of physics governing some phenomenon is not a strong\n\n08:15.520 --> 08:21.600\n sign that probing that phenomenon is going to crash the universe, right? But, you know, of course,\n\n08:21.600 --> 08:28.000\n I could be wrong. But do you think on the physics side of things, you know, there's been recently a\n\n08:28.000 --> 08:33.520\n few folks, Eric Weinstein and Stephen Wolfram that came out with a theory of everything. I think\n\n08:33.520 --> 08:39.600\n there's a history of physicists dreaming and working on the unification of all the laws of\n\n08:39.600 --> 08:46.320\n physics. Do you think it's possible that once we understand more physics, not necessarily the\n\n08:46.320 --> 08:50.480\n unification of the laws, but just understand physics more deeply at the fundamental level,\n\n08:50.480 --> 08:58.000\n we'll be able to start, you know, I mean, part of this is humorous, but looking to see if there's\n\n08:58.000 --> 09:05.280\n any bugs in the universe that could be exploited for, you know, traveling at not just speed of\n\n09:05.280 --> 09:10.240\n light, but just traveling faster than our current spaceships can travel, all that kind of stuff.\n\n09:10.240 --> 09:15.440\n Well, I mean, to travel faster than our current spaceships could travel, you wouldn't need to\n\n09:15.440 --> 09:20.880\n find any bug in the universe, right? The known laws of physics, you know, let us go much faster\n\n09:20.880 --> 09:25.680\n up to the speed of light, right? And, you know, when people want to go faster than the speed of\n\n09:25.680 --> 09:30.800\n light, well, we actually know something about what that would entail, namely that, you know,\n\n09:30.800 --> 09:36.800\n according to relativity, that seems to entail communication backwards in time. Okay, so then\n\n09:36.800 --> 09:41.600\n you have to worry about closed time like curves and all of that stuff. So, you know, in some sense,\n\n09:41.600 --> 09:45.920\n we sort of know the price that you have to pay for these things, right?\n\n09:45.920 --> 09:48.400\n But under the current understanding of physics.\n\n09:48.400 --> 09:53.040\n That's right. That's right. We can't, you know, say that they're impossible, but we, you know,\n\n09:53.040 --> 10:01.200\n we know that sort of a lot else in physics breaks, right? So, now regarding Eric Weinstein\n\n10:01.200 --> 10:06.240\n and Stephen Wolfram, like, I wouldn't say that either of them has a theory of everything. I\n\n10:06.240 --> 10:11.840\n would say that they have ideas that they hope, you know, could someday lead to a theory of everything.\n\n10:11.840 --> 10:13.120\n Is that a worthy pursuit?\n\n10:13.120 --> 10:18.640\n Well, I mean, certainly, let's say by theory of everything, you know, we don't literally mean a\n\n10:18.640 --> 10:24.800\n theory of cats and of baseball and, you know, but we just mean it in the more limited sense of\n\n10:24.800 --> 10:31.600\n everything, a fundamental theory of physics, right? Of all of the fundamental interactions of\n\n10:31.600 --> 10:38.800\n physics, of course, such a theory, even after we had it, you know, would leave the entire question\n\n10:38.800 --> 10:45.840\n of all the emergent behavior, right? You know, to be explored. So, it's only everything for a\n\n10:45.840 --> 10:50.320\n specific definition of everything. Okay, but in that sense, I would say, of course, that's worth\n\n10:50.320 --> 10:56.240\n pursuing. I mean, that is the entire program of fundamental physics, right? All of my friends who\n\n10:56.240 --> 11:02.160\n do quantum gravity, who do string theory, who do anything like that, that is what's motivating them.\n\n11:02.160 --> 11:06.960\n Yeah, it's funny, though, but, I mean, Eric Weinstein talks about this. It is, I don't know\n\n11:06.960 --> 11:11.920\n much about the physics world, but I know about the AI world, and it is a little, it is a little bit\n\n11:11.920 --> 11:22.880\n taboo to talk about AGI, for example, on the AI side. So, really, to talk about the big dream of\n\n11:22.880 --> 11:28.560\n the community, I would say, because it seems so far away, it's almost taboo to bring it up, because,\n\n11:29.760 --> 11:34.320\n you know, it's seen as the kind of people that dream about creating a truly superhuman level\n\n11:34.320 --> 11:40.080\n intelligence. That's really far out there, people, because we're not even close to that. And it feels\n\n11:40.080 --> 11:45.440\n like the same thing is true for the physics community. I mean, Stephen Hawking certainly\n\n11:45.440 --> 11:51.920\n talked constantly about theory of everything, right? You know, I mean, people, you know,\n\n11:51.920 --> 11:57.760\n use those terms who were, you know, some of the most respected people in the whole world of\n\n11:57.760 --> 12:03.040\n physics, right? But, I mean, I think that the distinction that I would make is that people\n\n12:03.040 --> 12:09.760\n might react badly if you use the term in a way that suggests that you, you know, thinking about\n\n12:09.760 --> 12:16.320\n it for five minutes, have come up with this major new insight about it, right? It's difficult. Stephen\n\n12:16.320 --> 12:23.200\n Hawking is not a great example, because I think you can do whatever the heck you want when you\n\n12:23.200 --> 12:29.280\n get to that level. And I certainly see, like, senior faculty, you know, that, you know, at that\n\n12:29.280 --> 12:35.200\n point, that's one of the nice things about getting older is you stop giving a damn. But\n\n12:35.760 --> 12:40.560\n community as a whole, they tend to roll their eyes very quickly at stuff that's outside the\n\n12:40.560 --> 12:44.720\n quote unquote mainstream. Well, let me put it this way. I mean, if you asked, you know,\n\n12:44.720 --> 12:49.680\n Ed Witten, let's say, who is, you know, you might consider the leader of the string community,\n\n12:49.680 --> 12:54.960\n and thus, you know, very, very mainstream, in a certain sense, but he would have no hesitation\n\n12:54.960 --> 13:01.840\n in saying, you know, of course, you know, they're looking for a, you know, you know, a unified\n\n13:01.840 --> 13:07.200\n description of nature of, you know, of general relativity of quantum mechanics of all the\n\n13:07.200 --> 13:13.280\n fundamental interactions of nature, right? Now, you know, whether people would call that a theory\n\n13:13.280 --> 13:18.480\n of everything, whether they would use that term, that might vary. You know, Lenny Susskind would\n\n13:18.480 --> 13:21.920\n definitely have no problem telling you that, you know, if that's what we want, right?\n\n13:21.920 --> 13:25.200\n TK For me, who loves human beings and psychology,\n\n13:25.760 --> 13:33.520\n it's kind of ridiculous to say a theory that unifies the laws of physics gets you to understand\n\n13:33.520 --> 13:36.640\n everything. I would say you're not even close to understanding everything.\n\n13:36.640 --> 13:43.200\n TK Yeah, right. I mean, the word everything is a little ambiguous here. And then people will get\n\n13:43.200 --> 13:50.480\n into debates about, you know, reductionism versus emergentism and blah, blah, blah. And so in not\n\n13:50.480 --> 13:55.600\n wanting to say theory of everything, people might just be trying to short circuit that debate and\n\n13:55.600 --> 14:01.040\n say, you know, look, you know, yes, we want a fundamental theory of, you know, the particles\n\n14:01.040 --> 14:02.320\n and interactions of nature.\n\n14:02.320 --> 14:05.680\n TK Let me bring up the next topic that people don't want to mention, although they're getting\n\n14:05.680 --> 14:10.160\n more comfortable with it, is consciousness. You mentioned that you have a talk on consciousness\n\n14:10.160 --> 14:13.920\n that I watched five minutes of, but the internet connection was really bad.\n\n14:13.920 --> 14:18.560\n TK Was this my talk about, you know, refuting the integrated information theory?\n\n14:18.560 --> 14:18.800\n TK Yes.\n\n14:18.800 --> 14:22.960\n TK Which was a particular account of consciousness that, yeah, I think one can just show it doesn't\n\n14:22.960 --> 14:25.520\n work. Much harder to say what does work.\n\n14:25.520 --> 14:34.240\n TK Let me ask, maybe it'd be nice to comment on, you talk about also like the semi hard problem\n\n14:34.240 --> 14:36.720\n of consciousness or like almost hard problem or kind of hard.\n\n14:36.720 --> 14:38.560\n TK Pretty hard problem, I think I call it.\n\n14:38.560 --> 14:47.200\n TK So maybe can you talk about that, their idea of the approach to modeling consciousness and\n\n14:47.200 --> 14:49.680\n why you don't find it convincing? What is it, first of all?\n\n14:49.680 --> 14:55.920\n TK Okay, well, so what I called the pretty hard problem of consciousness, this is my term,\n\n14:55.920 --> 15:02.400\n although many other people have said something equivalent to this, okay? But it's just, you know,\n\n15:02.400 --> 15:09.840\n the problem of, you know, giving an account of just which physical systems are conscious and\n\n15:09.840 --> 15:15.840\n which are not. Or, you know, if there are degrees of consciousness, then quantifying how conscious\n\n15:15.840 --> 15:16.960\n a given system is.\n\n15:16.960 --> 15:19.200\n TK Oh, awesome. So that's the pretty hard problem.\n\n15:19.200 --> 15:20.240\n TK Yeah, that's what I mean.\n\n15:20.240 --> 15:23.520\n TK That's it. I'm adopting it. I love it. That's a good ring to it.\n\n15:23.520 --> 15:29.440\n TK And so, you know, the infamous hard problem of consciousness is to explain how something\n\n15:29.440 --> 15:34.560\n like consciousness could arise at all, you know, in a material universe, right? Or, you know,\n\n15:34.560 --> 15:40.880\n why does it ever feel like anything to experience anything, right? And, you know, so I'm trying to\n\n15:40.880 --> 15:46.880\n distinguish from that problem, right? And say, you know, no, okay, I would merely settle for an\n\n15:46.880 --> 15:52.560\n account that could say, you know, is a fetus conscious? You know, if so, at which trimester?\n\n15:52.560 --> 15:58.160\n You know, is a dog conscious? You know, what about a frog, right?\n\n15:58.160 --> 16:02.080\n TK Or even as a precondition, you take that both these things are conscious,\n\n16:02.080 --> 16:03.680\n tell me which is more conscious.\n\n16:03.680 --> 16:09.360\n TK Yeah, for example, yes. Yeah, yeah. I mean, if consciousness is some multidimensional vector,\n\n16:09.360 --> 16:14.320\n well, just tell me in which respects these things are conscious and in which respect they aren't,\n\n16:14.320 --> 16:19.040\n right? And, you know, and have some principled way to do it where you're not, you know,\n\n16:19.040 --> 16:24.800\n carving out exceptions for things that you like or don't like, but could somehow take a description\n\n16:24.800 --> 16:32.080\n of an arbitrary physical system, and then just based on the physical properties of that system,\n\n16:32.080 --> 16:36.800\n or the informational properties, or how it's connected, or something like that,\n\n16:36.800 --> 16:42.240\n just in principle, calculate, you know, its degree of consciousness, right? I mean, this,\n\n16:42.240 --> 16:47.280\n this would be the kind of thing that we would need, you know, if we wanted to address questions,\n\n16:47.280 --> 16:52.480\n like, you know, what does it take for a machine to be conscious, right? Or when are, you know,\n\n16:52.480 --> 17:01.280\n when should we regard AIs as being conscious? So now this IIT, this integrated information theory,\n\n17:01.920 --> 17:07.520\n which has been put forward by Giulio Tinoni and a bunch of his\n\n17:09.680 --> 17:17.920\n collaborators over the last decade or two, this is noteworthy, I guess, as a direct attempt to\n\n17:17.920 --> 17:22.640\n answer that question, to, you know, answer the, to address the pretty hard problem,\n\n17:22.640 --> 17:29.840\n right? And they give a, a criterion that's just based on how a system is connected. So you,\n\n17:29.840 --> 17:36.640\n so it's up to you to sort of abstract the system, like a brain or a microchip, as a collection of\n\n17:36.640 --> 17:41.600\n components that are connected to each other by some pattern of connections, you know, and,\n\n17:41.600 --> 17:48.000\n and to specify how the components can influence each other, you know, like where the inputs go,\n\n17:48.000 --> 17:51.920\n you know, where they affect the outputs. But then once you've specified that,\n\n17:51.920 --> 17:56.240\n then they give this quantity that they call phi, you know, the Greek letter phi.\n\n17:56.800 --> 18:02.880\n And the definition of phi has actually changed over time. It changes from one paper to another,\n\n18:02.880 --> 18:08.560\n but in all of the variations, it involves something about what we in computer science\n\n18:08.560 --> 18:14.800\n would call graph expansion. So basically what this means is that they want, in order to get a\n\n18:14.800 --> 18:22.080\n large value of phi, it should not be possible to take your system and partition it into two\n\n18:22.080 --> 18:28.800\n components that are only weakly connected to each other. Okay. So whenever we take our system and\n\n18:28.800 --> 18:33.520\n sort of try to split it up into two, then there should be lots and lots of connections going\n\n18:33.520 --> 18:37.200\n between the two components. Okay. Well, I understand what that means on a graph.\n\n18:37.200 --> 18:43.120\n Do they formalize what, how to construct such a graph or data structure, whatever,\n\n18:44.160 --> 18:50.560\n or is this one of the criticism I've heard you kind of say is that a lot of the very interesting\n\n18:50.560 --> 18:56.880\n specifics are usually communicated through like natural language, like through words.\n\n18:56.880 --> 19:02.560\n So it's like the details aren't always clear. Well, it's true. I mean, they have nothing even\n\n19:02.560 --> 19:09.920\n resembling a derivation of this phi. Okay. So what they do is they state a whole bunch of postulates,\n\n19:09.920 --> 19:15.440\n you know, axioms that they think that consciousness should satisfy. And then there's some verbal\n\n19:15.440 --> 19:20.960\n discussion. And then at some point, phi appears. Right. Right. And this, this was what the first\n\n19:20.960 --> 19:26.400\n thing that really made the hair stand on my neck, to be honest, because they are acting as if there\n\n19:26.400 --> 19:31.360\n is a derivation. They're acting as if, you know, you're supposed to think that this is a derivation\n\n19:31.360 --> 19:36.800\n and there's nothing even remotely resembling a derivate. They just pull the phi out of a hat\n\n19:36.800 --> 19:41.200\n completely. Is one of the key criticisms to you is that details are missing or is there something\n\n19:41.200 --> 19:45.040\n more fundamental? That's not even the key criticism. That's just, that's just a side point.\n\n19:45.040 --> 19:50.560\n Okay. The, the core of it is that I think that the, you know, that they want to say that a system\n\n19:50.560 --> 19:57.040\n is more conscious the larger its value of phi. And I think that that is obvious nonsense. Okay. As\n\n19:57.040 --> 20:02.160\n soon as you think about it for like a minute, as soon as you think about it in terms of, could I\n\n20:02.160 --> 20:08.240\n construct a system that had an enormous value of phi, like, you know, even larger than the brain\n\n20:08.240 --> 20:13.920\n has, but that is just implementing an error correcting code, you know, doing nothing that we\n\n20:13.920 --> 20:20.080\n would associate with, you know, intelligence or consciousness or any of it. The answer is yes,\n\n20:20.080 --> 20:25.360\n it is easy to do that. Right. And so I wrote blog posts, just making this point that, yeah, it's\n\n20:25.360 --> 20:31.200\n easy to do that. Now, you know, Tinoni's response to that was actually kind of incredible, right?\n\n20:31.200 --> 20:36.800\n I mean, I, I, I admired it in a way because instead of disputing any of it, he just bit the\n\n20:36.800 --> 20:42.560\n bullet in the sense, you know, he was one of the, the, uh, the most, uh, uh, audacious bullet\n\n20:42.560 --> 20:49.520\n bitings I've ever seen in my career. Okay. He said, okay, then fine. You know, this system that\n\n20:49.520 --> 20:54.400\n just applies this error correcting code it's conscious, you know, and if it has a much larger\n\n20:54.400 --> 20:59.600\n value of phi than you or me, it's much more conscious than you and me. You know, you,\n\n20:59.600 --> 21:04.720\n we just have to accept what the theory says because, you know, science is not about confirming\n\n21:04.720 --> 21:10.080\n our intuitions. It's about challenging them. And, you know, this is what my theory predicts that\n\n21:10.080 --> 21:15.040\n this thing is conscious and, you know, or super duper conscious. And how are you going to prove\n\n21:15.040 --> 21:21.840\n me wrong? So the way I would argue against your blog posts is I would say, yes, sure. You're\n\n21:21.840 --> 21:28.320\n right in general, but for naturally arising systems developed through the process of evolution on\n\n21:28.320 --> 21:33.760\n earth, the, this rule of the larger fee being associated, being associated with more consciousness\n\n21:33.760 --> 21:38.640\n is correct. Yeah. So that's not what he said at all. Right. Right. Because he wants this to be\n\n21:38.640 --> 21:43.040\n completely general. So we can apply to even computers. Yeah. I mean, I mean, the, the whole\n\n21:43.040 --> 21:48.880\n interest of the theory is the, you know, the hope that it could be completely general apply to aliens,\n\n21:48.880 --> 21:59.040\n to computers, to animals, coma patients, to any of it. Right. And so, so, so he just said, well,\n\n21:59.040 --> 22:04.800\n you know, Scott is relying on his intuition, but, you know, I'm relying on this theory and,\n\n22:04.800 --> 22:10.160\n you know, to me it was almost like, you know, are we being serious here? Like, like, like,\n\n22:10.960 --> 22:16.640\n you know, like, like, okay, yes, in science we try to learn highly nonintuitive things,\n\n22:16.640 --> 22:22.880\n but what we do is we first test the theory on cases where we already know the answer. Right.\n\n22:22.880 --> 22:27.520\n Like if we, if someone had a new theory of temperature, right, then, you know, maybe we\n\n22:27.520 --> 22:33.440\n could check that it says that boiling water is hotter than ice. And then if it says that the sun\n\n22:33.440 --> 22:38.720\n is hotter than anything, you know, you've ever experienced, then maybe we, we trust that\n\n22:38.720 --> 22:46.320\n extrapolation. Right. But like this, this theory, like if, if, you know, it's now saying that, you\n\n22:46.320 --> 22:53.680\n know, a, a gigantic grit, like regular grid of exclusive or gates can be way more conscious than,\n\n22:53.680 --> 22:59.680\n you know, a person or than, than any animal can be, you know, even if it, you know, is, you know,\n\n22:59.680 --> 23:06.160\n is, is, is, is so uniform that it might as well just be a blank wall. Right. And, and so now the\n\n23:06.160 --> 23:11.200\n point is if, if this theory is sort of getting wrong, the question is a blank wall, you know,\n\n23:11.200 --> 23:15.920\n more conscious than a person, then I would say, what is, what is there for it to get right?\n\n23:15.920 --> 23:22.240\n So your, your sense is a blank wall is not more conscious than a human being.\n\n23:22.240 --> 23:25.920\n Yeah. I mean, I mean, I mean, you could say that I am taking that as one of my axioms.\n\n23:27.360 --> 23:33.440\n I'm saying, I'm saying that if, if a theory of consciousness is, is getting that wrong,\n\n23:33.440 --> 23:39.760\n then whatever it is talking about at that point, I, I, I'm not going to call it consciousness.\n\n23:39.760 --> 23:40.720\n I'm going to use a different word.\n\n23:40.720 --> 23:45.120\n You have to use a different word. I mean, it's also, it's possible just like with intelligence\n\n23:45.120 --> 23:49.200\n that us humans conveniently define these very difficult to understand concepts\n\n23:49.200 --> 23:55.200\n in a very human centric way. Just like the Turing test really seems to define intelligence as a\n\n23:55.200 --> 24:01.040\n thing that's human like. Right. But I would say that with any, uh, concept, you know, there's,\n\n24:01.040 --> 24:07.440\n uh, uh, uh, you know, like we, we, we, we first need to define it. Right. And a definition is\n\n24:07.440 --> 24:12.640\n only a good definition if it matches what we thought we were talking about prior to having\n\n24:12.640 --> 24:19.120\n a definition. Right. And I would say that, you know, uh, fee as a definition of consciousness\n\n24:19.120 --> 24:26.160\n fails that test. That is my argument. So, okay. So let's take a further step. So you mentioned\n\n24:26.160 --> 24:31.680\n that the universe might be a Turing machine. So like it might be computations or simulatable\n\n24:31.680 --> 24:38.240\n by one anyway, simulated by one. So what's your sense about consciousness? Do you think\n\n24:38.240 --> 24:45.200\n consciousness is computation that we don't need to go to any place outside of the computable universe\n\n24:46.080 --> 24:52.800\n to, uh, you know, to, to understand consciousness, to build consciousness, to measure consciousness,\n\n24:52.800 --> 24:57.840\n all those kinds of things? I don't know. These are what, uh, you know, have been called the,\n\n24:57.840 --> 25:02.480\n the vertiginous questions, right? There's the questions like, like, uh, you know,\n\n25:02.480 --> 25:08.240\n you get a feeling of vertigo and thinking about them. Right. I mean, I certainly feel like, uh,\n\n25:08.240 --> 25:14.640\n I am conscious in a way that is not reducible to computation, but why should you believe me?\n\n25:14.640 --> 25:19.360\n Right. I mean, and, and, and if you said the same to me, then why should I believe you?\n\n25:19.360 --> 25:26.320\n But as computer scientists, I feel like a computer could be, could achieve human level intelligence,\n\n25:27.680 --> 25:33.520\n but, and that's actually a feeling and a hope. That's not a scientific belief. It's just,\n\n25:33.520 --> 25:36.800\n we've built up enough intuition, the same kind of intuition you use in your blog.\n\n25:37.680 --> 25:41.040\n You know, that's what scientists do. They, I mean, some of it is a scientific method,\n\n25:41.040 --> 25:45.840\n but some of it is just damn good intuition. I don't have a good intuition about consciousness.\n\n25:45.840 --> 25:49.840\n Yeah. I'm not sure that anyone does or has in the, you know,\n\n25:49.840 --> 25:52.640\n 2,500 years that these things have been discussed, Lex.\n\n25:53.360 --> 25:57.360\n But do you think we will? Like one of the, I've gotten a chance to attend,\n\n25:57.920 --> 26:01.280\n can't wait to hear your opinion on this, but attend the Neuralink event.\n\n26:01.920 --> 26:07.360\n And, uh, one of the dreams there is to, uh, you know, basically push neuroscience forward.\n\n26:07.360 --> 26:14.080\n And the hope with neuroscience is that, uh, we can inspect the machinery from which all this\n\n26:14.080 --> 26:19.920\n fun stuff emerges and see, we're going to notice something special, some special sauce from which\n\n26:19.920 --> 26:24.560\n something like consciousness or cognition emerges. Yeah. Well, it's clear that we've learned an\n\n26:24.560 --> 26:30.320\n enormous amount about neuroscience. We've learned an enormous amount about computation, you know,\n\n26:30.320 --> 26:36.800\n about machine learning, about AI, how to get it to work. We've learned, uh, an enormous amount about\n\n26:36.800 --> 26:42.880\n the underpinnings of the physical world, you know, and, you know, from one point of view,\n\n26:42.880 --> 26:47.680\n that's like, uh, an enormous distance that we've traveled along the road to understanding\n\n26:47.680 --> 26:52.000\n consciousness. From another point of view, you know, the distance still to be traveled on the\n\n26:52.000 --> 26:58.240\n road, you know, maybe seems no shorter than it was at the beginning. Right? So it's very hard to say.\n\n26:58.240 --> 27:03.120\n I mean, you know, these are questions like, like in, in, in sort of trying to have a theory\n\n27:03.120 --> 27:08.000\n of consciousness, there's sort of a problem where it feels like it's not just that we don't know\n\n27:08.000 --> 27:13.280\n how to make progress. It's that it's hard to specify what could even count as progress,\n\n27:13.280 --> 27:18.160\n right? Because no matter what scientific theory someone proposed, someone else could come along\n\n27:18.160 --> 27:22.560\n and say, well, you've just talked about the mechanism. You haven't said anything about\n\n27:22.560 --> 27:27.920\n what breathes fire into the mechanism, what really makes there something that it's like to be it.\n\n27:27.920 --> 27:32.000\n Right. And that seems like an objection that you could always raise no matter,\n\n27:32.000 --> 27:35.840\n you know, how much someone elucidated the details of how the brain works.\n\n27:35.840 --> 27:40.000\n Okay. Let's go to the Turing test and the Lobner Prize. I have this intuition, call me crazy,\n\n27:40.880 --> 27:48.080\n but we, that a machine to pass the Turing test and it's full, whatever the spirit of it is,\n\n27:48.080 --> 27:54.960\n we can talk about how to formulate the perfect Turing test, that that machine has to be conscious.\n\n27:55.680 --> 28:03.280\n We at least have to, I have a very low bar of what consciousness is. I tend to, I tend to think that\n\n28:03.280 --> 28:08.640\n the emulation of consciousness is as good as consciousness. So the consciousness is just a\n\n28:08.640 --> 28:16.240\n dance, a social, a social, a shortcut, like a nice, useful tool, but I tend to connect intelligence\n\n28:16.240 --> 28:25.840\n consciousness together. So by, by that, do you, maybe just to ask what, what role does consciousness\n\n28:25.840 --> 28:29.680\n play? Do you think it passed in the Turing test? Well, look, I mean, it's almost tautologically\n\n28:29.680 --> 28:35.120\n true that if we had a machine that passed the Turing test, then it would be emulating consciousness.\n\n28:35.120 --> 28:40.320\n Right? So if your position is that, you know, emulation of consciousness is consciousness,\n\n28:40.320 --> 28:45.840\n then so, you know, by, by definition, any machine that passed the Turing test would be conscious.\n\n28:45.840 --> 28:50.480\n But it's, but I mean, we know that you could say that, you know, that, that is just a way to\n\n28:50.480 --> 28:55.840\n rephrase the original question, you know, is an emulation of consciousness, you know, necessarily\n\n28:55.840 --> 29:01.120\n conscious. Right. And you can, can, you know, I hear, I'm not saying anything new that hasn't been\n\n29:01.120 --> 29:07.360\n debated ad nauseum in the literature. Okay. But, you know, you could imagine some very hard cases,\n\n29:07.360 --> 29:13.360\n like imagine a machine that passed the Turing test, but that did so just by an enormous\n\n29:13.360 --> 29:19.840\n cosmological sized lookup table that just cashed every possible conversation that could be had.\n\n29:19.840 --> 29:21.040\n The old Chinese room.\n\n29:21.040 --> 29:26.400\n Well, well, yeah, yeah. But, but this is, I mean, I mean, the Chinese room actually would be doing\n\n29:26.400 --> 29:31.520\n some computation, at least in Searle's version. Right. Here, I'm just talking about a table lookup.\n\n29:31.520 --> 29:37.040\n Okay. Now it's true that for conversations of a reasonable length, this, you know, lookup table\n\n29:37.040 --> 29:42.000\n would be so enormous that wouldn't even fit in the observable universe. Okay. But supposing that\n\n29:42.000 --> 29:48.080\n you could build a big enough lookup table and then just, you know, pass the Turing test just\n\n29:48.080 --> 29:52.960\n by looking up what the person said. Right. Are you going to regard that as conscious?\n\n29:52.960 --> 30:00.880\n Okay. Let me try to make this formal and then you can shut it down. I think that the emulation of\n\n30:00.880 --> 30:06.880\n something is that something, if there exists in that system, a black box that's full of mystery.\n\n30:07.840 --> 30:11.440\n So like, full of mystery to whom?\n\n30:11.440 --> 30:13.920\n To human specters.\n\n30:13.920 --> 30:17.120\n So does that mean that consciousness is relative to the observer? Like,\n\n30:17.120 --> 30:22.160\n could something be conscious for us, but not conscious for an alien that understood better\n\n30:22.160 --> 30:27.360\n what was happening inside the black box? Yes. So that if inside the black box is just a lookup\n\n30:27.360 --> 30:33.680\n table, the alien that saw that would say this is not conscious. To us, another way to phrase the\n\n30:33.680 --> 30:38.960\n black box is layers of abstraction, which make it very difficult to see to the actually underlying\n\n30:38.960 --> 30:44.400\n functionality of the system. And then we observe just the abstraction. And so it looks like magic\n\n30:44.400 --> 30:51.040\n to us. But once we understand the inner machinery, it stops being magic. And so like, that's a\n\n30:51.040 --> 30:57.040\n prerequisite is that you can't know how it works, or some part of it, because then there has to be\n\n30:57.040 --> 31:04.800\n in our human mind, entry point for the magic. So that's a formal definition of the system.\n\n31:05.440 --> 31:10.960\n Yeah, well, look, I mean, I explored a view in this essay I wrote called The Ghost in the Quantum\n\n31:10.960 --> 31:17.440\n Touring Machine seven years ago that is related to that, except that I did not want to have\n\n31:17.440 --> 31:22.400\n consciousness be relative to the observer, right? Because I think that if consciousness means\n\n31:22.400 --> 31:27.840\n anything, it is something that is experienced by the entity that is conscious, right? Like,\n\n31:27.840 --> 31:35.600\n I don't need you to tell me that I'm conscious, nor do you need me to tell you that you are,\n\n31:35.600 --> 31:47.120\n right? But basically, what I explored there is are there aspects of a system like a brain that just\n\n31:47.120 --> 31:52.880\n could not be predicted even with arbitrarily advanced future technologies? It's because of\n\n31:52.880 --> 31:59.120\n chaos combined with quantum mechanical uncertainty and things like that. I mean, that actually could\n\n31:59.120 --> 32:06.000\n be a property of the brain, you know, if true, that would distinguish it in a principled way,\n\n32:06.000 --> 32:11.360\n at least from any currently existing computer. Not from any possible computer, but yeah, yeah.\n\n32:11.360 --> 32:18.560\n This is a thought experiment. So if I gave you information that the entire history of your life,\n\n32:20.000 --> 32:26.000\n basically explain away free will with a lookup table, say that this was all predetermined,\n\n32:26.000 --> 32:29.840\n that everything you experienced has already been predetermined, wouldn't that take away\n\n32:29.840 --> 32:34.640\n your consciousness? Wouldn't you, yourself, wouldn't the experience of the world change for\n\n32:34.640 --> 32:39.600\n you in a way that you can't take back? Well, let me put it this way. If you could\n\n32:39.600 --> 32:44.960\n do like in a Greek tragedy where, you know, you would just write down a prediction for what I'm\n\n32:44.960 --> 32:52.160\n going to do and then maybe you put the prediction in a sealed box and maybe, you know, you open it\n\n32:52.160 --> 32:56.480\n later and you show that you knew everything I was going to do or, you know, of course,\n\n32:56.480 --> 33:01.680\n the even creepier version would be you tell me the prediction and then I try to falsify it,\n\n33:01.680 --> 33:07.920\n my very effort to falsify it makes it come true, right? Let's even forget that, you know,\n\n33:07.920 --> 33:13.040\n that version as convenient as it is for fiction writers, right? Let's just do the version where\n\n33:13.040 --> 33:19.440\n you put the prediction into a sealed envelope, okay? But if you could reliably predict everything\n\n33:19.440 --> 33:24.320\n that I was going to do, I'm not sure that that would destroy my sense of being conscious,\n\n33:24.320 --> 33:30.320\n but I think it really would destroy my sense of having free will, you know, and much, much more\n\n33:30.320 --> 33:37.760\n than any philosophical conversation could possibly do that, right? And so I think it becomes extremely\n\n33:37.760 --> 33:43.280\n interesting to ask, you know, could such predictions be done, you know, even in principle,\n\n33:43.280 --> 33:49.360\n is it consistent with the laws of physics to make such predictions, to get enough data about someone\n\n33:49.360 --> 33:53.840\n that you could actually generate such predictions without having to kill them in the process to,\n\n33:53.840 --> 33:57.280\n you know, slice their brain up into little slivers or something.\n\n33:57.280 --> 33:59.120\n I mean, it's theoretically possible, right?\n\n33:59.120 --> 34:03.760\n Well, I don't know. I mean, it might be possible, but only at the cost of destroying the person,\n\n34:04.320 --> 34:11.040\n right? I mean, it depends on how low you have to go in sort of the substrate. Like if there was\n\n34:11.040 --> 34:16.960\n a nice digital abstraction layer, if you could think of each neuron as a kind of transistor\n\n34:16.960 --> 34:22.320\n computing a digital function, then you could imagine some nanorobots that would go in and\n\n34:22.320 --> 34:27.520\n would just scan the state of each transistor, you know, of each neuron and then, you know, make a\n\n34:28.480 --> 34:34.240\n good enough copy, right? But if it was actually important to get down to the molecular or the\n\n34:34.240 --> 34:38.720\n atomic level, then, you know, eventually you would be up against quantum effects.\n\n34:38.720 --> 34:43.760\n You would be up against the unclonability of quantum states. So I think it's a question of\n\n34:43.760 --> 34:49.760\n how good of a replica, how good does the replica have to be before you're going to count it as\n\n34:49.760 --> 34:53.600\n actually a copy of you or as being able to predict your actions.\n\n34:54.240 --> 34:55.760\n That's a totally open question.\n\n34:55.760 --> 35:02.080\n Yeah, yeah, yeah. And especially once we say that, well, look, maybe there's no way to,\n\n35:02.080 --> 35:07.440\n you know, to make a deterministic prediction because, you know, we know that there's noise\n\n35:07.440 --> 35:12.240\n buffeting the brain around, presumably even quantum mechanical uncertainty,\n\n35:12.240 --> 35:16.960\n you know, affecting the sodium ion channels, for example, whether they open or they close.\n\n35:18.720 --> 35:24.880\n You know, there's no reason why over a certain time scale that shouldn't be amplified, just like\n\n35:24.880 --> 35:33.680\n we imagine happens with the weather or with any other, you know, chaotic system. So if that stuff\n\n35:33.680 --> 35:43.600\n is important, right, then we would say, well, you know, you can't, you know, you're never going to\n\n35:43.600 --> 35:48.000\n be able to make an accurate enough copy. But now the hard part is, well, what if someone can make\n\n35:48.000 --> 35:54.320\n a copy that sort of no one else can tell apart from you, right? It says the same kinds of things\n\n35:54.320 --> 35:59.600\n that you would have said, maybe not exactly the same things because we agree that there's noise,\n\n35:59.600 --> 36:04.960\n but it says the same kinds of things. And maybe you alone would say, no, I know that that's not\n\n36:04.960 --> 36:10.480\n me, you know, it's, it doesn't share my, I haven't felt my consciousness leap over to that other\n\n36:10.480 --> 36:15.600\n thing. I still feel it localized in this version, right? And then why should anyone else believe\n\n36:15.600 --> 36:20.000\n you? What are your thoughts? I'd be curious, you're a really good person to ask, which is\n\n36:20.720 --> 36:26.080\n Penrose's, Roger Penrose's work on consciousness, saying that there, you know, there is some,\n\n36:26.080 --> 36:32.240\n there's some, with axons and so on, there might be some biological places where quantum mechanics\n\n36:32.240 --> 36:35.840\n can come into play and through that create consciousness somehow.\n\n36:35.840 --> 36:42.480\n Yeah. Okay. Well, um, uh, of course, you know, I read Penrose's books as a teenager. They had\n\n36:42.480 --> 36:47.840\n a huge impact on me. Uh, uh, five or six years ago, I had the privilege to actually talk these\n\n36:47.840 --> 36:53.440\n things over with Penrose, you know, at some length at a conference in Minnesota. And, uh, you know,\n\n36:53.440 --> 36:58.800\n he is, uh, uh, you know, an amazing, uh, personality. I admire the fact that he was\n\n36:58.800 --> 37:04.080\n even raising such, uh, audacious questions at all. Uh, but you know, to, to, to answer your\n\n37:04.080 --> 37:09.680\n question, I think the first thing we need to get clear on is that he is not merely saying that\n\n37:09.680 --> 37:15.040\n quantum mechanics is relevant to consciousness, right? That would be like, um, you know, that would\n\n37:15.040 --> 37:20.880\n be tame compared to what he is saying, right? He is saying that, you know, even quantum mechanics\n\n37:20.880 --> 37:25.280\n is not good enough, right? If, because if, if supposing for example, that the brain were a\n\n37:25.280 --> 37:30.640\n quantum computer, I know that's still a computer, you know, in fact, a quantum computer can be\n\n37:30.640 --> 37:36.320\n simulated by an ordinary computer. It might merely need exponentially more time in order to do so,\n\n37:36.320 --> 37:42.400\n right? So that's simply not good enough for him. Okay. So what he wants is for the brain to be a\n\n37:42.400 --> 37:50.960\n quantum gravitational computer or, or, uh, uh, he wants the brain to be exploiting as yet unknown\n\n37:50.960 --> 37:57.200\n laws of quantum gravity. Okay. Which would, which would be uncomputable. That's the key point. Okay.\n\n37:57.200 --> 38:02.720\n Yes. Yes. That would be literally uncomputable. And I've asked him, you know, to clarify this,\n\n38:02.720 --> 38:09.680\n but uncomputable, even if you had an Oracle for the halting problem or, you know, and, and, or,\n\n38:09.680 --> 38:15.520\n you know, as high up as you want to go and the sort of high, the usual hierarchy of uncomputability,\n\n38:15.520 --> 38:20.960\n he wants to go beyond all of that. Okay. So, so, you know, just, just to be clear, like, you know,\n\n38:20.960 --> 38:26.320\n if we're keeping count of how many speculations, you know, there's probably like at least five or\n\n38:26.320 --> 38:30.960\n six of them, right? There's first of all, that there is some quantum gravity theory that would\n\n38:30.960 --> 38:36.480\n involve this kind of uncomputability, right? Most people who study quantum gravity would not agree\n\n38:36.480 --> 38:41.360\n with that. They would say that what we've learned, you know, what little we know about quantum\n\n38:41.360 --> 38:48.160\n gravity from the, this ADS CFT correspondence, for example, has been very much consistent with\n\n38:48.160 --> 38:55.600\n the broad idea of nature being computable, right? But, but all right, but, but supposing that he's\n\n38:55.600 --> 39:01.920\n right about that, then, you know, what most physicists would say is that whatever new\n\n39:01.920 --> 39:07.920\n phenomena there are in quantum gravity, you know, they might be relevant at the singularities of\n\n39:07.920 --> 39:15.600\n black holes. They might be relevant at the big bang. They are plainly not relevant to something\n\n39:15.600 --> 39:21.920\n like the brain, you know, that is operating at ordinary temperatures, you know, with ordinary\n\n39:21.920 --> 39:28.400\n chemistry and, you know, the, the, the physics underlying the brain, they, they would say that\n\n39:28.400 --> 39:32.800\n we have, you know, the fundamental physics of the brain, they would say that we've pretty much\n\n39:32.800 --> 39:39.440\n completely known for, for generations now, right? Because, you know, quantum field theory lets us\n\n39:39.440 --> 39:44.720\n sort of parameterize our ignorance, right? I mean, Sean Carroll has made this case and,\n\n39:44.720 --> 39:49.760\n you know, in great detail, right? That sort of whatever new effects are coming from quantum\n\n39:49.760 --> 39:55.120\n gravity, you know, they are sort of screened off by quantum field theory, right? And this is,\n\n39:55.120 --> 39:59.680\n this brings, you know, brings us to the whole idea of effective theories, right? But the,\n\n39:59.680 --> 40:04.480\n like we have, you know, the, in like in the standard model of elementary particles, right?\n\n40:04.480 --> 40:12.000\n We have a quantum field theory that seems totally adequate for all of the terrestrial phenomena,\n\n40:12.000 --> 40:16.880\n right? The only things that it doesn't, you know, explain are, well, first of all, you know,\n\n40:16.880 --> 40:23.440\n the details of gravity, if you were to probe it, like at, at, you know, extremes of, you know,\n\n40:23.440 --> 40:29.760\n curvature or like incredibly small distances, it doesn't explain dark matter. It doesn't explain\n\n40:29.760 --> 40:35.200\n black hole singularities, right? But these are all very exotic things, very, you know, far removed\n\n40:35.200 --> 40:41.600\n from our life on earth, right? So for Penrose to be right, he needs, you know, these phenomena to\n\n40:41.600 --> 40:49.280\n somehow affect the brain. He needs the brain to contain antennae that are sensitive to this as\n\n40:49.280 --> 40:55.760\n yet unknown physics, right? And then he needs a modification of quantum mechanics, okay? So he\n\n40:55.760 --> 41:02.560\n needs quantum mechanics to actually be wrong, okay? He needs, what he wants is what he calls\n\n41:02.560 --> 41:09.040\n an objective reduction mechanism or an objective collapse. So this is the idea that once quantum\n\n41:09.040 --> 41:17.680\n states get large enough, then they somehow spontaneously collapse, right? That, you know,\n\n41:17.680 --> 41:23.200\n and this is an idea that lots of people have explored. You know, there's something called the\n\n41:23.200 --> 41:29.200\n GRW proposal that tries to, you know, say something along those lines, you know, and these are\n\n41:29.200 --> 41:33.760\n theories that actually make testable predictions, right? Which is a nice feature that they have.\n\n41:34.320 --> 41:39.360\n But, you know, the very fact that they're testable may mean that in the, you know, in the coming\n\n41:39.360 --> 41:45.200\n decades, we may well be able to test these theories and show that they're wrong, right? You know, we\n\n41:45.200 --> 41:50.800\n may be able to test some of Penrose's ideas. If not, not his ideas about consciousness, but at\n\n41:50.800 --> 41:56.560\n least his ideas about an objective collapse of quantum states, right? And people have actually,\n\n41:56.560 --> 42:01.520\n like Dick Balmeister, have actually been working to try to do these experiments. They haven't been\n\n42:01.520 --> 42:07.280\n able to do it yet to test Penrose's proposal, okay? But Penrose would need more than just\n\n42:07.280 --> 42:11.920\n an objective collapse of quantum states, which would already be the biggest development in\n\n42:11.920 --> 42:18.080\n physics for a century since quantum mechanics itself, okay? He would need for consciousness\n\n42:18.080 --> 42:24.240\n to somehow be able to influence the direction of the collapse so that it wouldn't be completely\n\n42:24.240 --> 42:29.440\n random, but that, you know, your dispositions would somehow influence the quantum state\n\n42:29.440 --> 42:36.160\n to collapse more likely this way or that way, okay? Finally, Penrose, you know, says that all\n\n42:36.160 --> 42:42.320\n of this has to be true because of an argument that he makes based on G\u00f6del's incompleteness theorem,\n\n42:42.320 --> 42:49.040\n okay? Now, like I would say the overwhelming majority of computer scientists and mathematicians\n\n42:49.040 --> 42:53.920\n who have thought about this, I don't think that G\u00f6del's incompleteness theorem can do what he\n\n42:53.920 --> 43:00.000\n needs it to do here, right? I don't think that that argument is sound, okay? But that is, you know,\n\n43:00.000 --> 43:04.560\n that is sort of the tower that you have to ascend to if you're going to go where Penrose goes.\n\n43:04.560 --> 43:09.440\n And the intuition he uses with the incompleteness theorem is that basically\n\n43:09.440 --> 43:13.360\n that there's important stuff that's not computable? Is that where he takes it?\n\n43:13.360 --> 43:18.000\n It's not just that because, I mean, everyone agrees that there are problems that are uncomputable,\n\n43:18.000 --> 43:25.280\n right? That's a mathematical theorem, right? But what Penrose wants to say is that, you know,\n\n43:26.480 --> 43:33.920\n for example, there are statements, you know, given any formal system, you know, for doing math,\n\n43:33.920 --> 43:39.280\n right? There will be true statements of arithmetic that that formal system, you know,\n\n43:39.280 --> 43:44.080\n if it's adequate for math at all, if it's consistent and so on, will not be able to prove.\n\n43:44.640 --> 43:49.600\n A famous example being the statement that that system itself is consistent,\n\n43:49.600 --> 43:54.400\n right? No, you know, good formal system can actually prove its own consistency.\n\n43:55.040 --> 44:00.480\n That can only be done from a stronger formal system, which then can't prove its own consistency\n\n44:00.480 --> 44:08.400\n and so on forever, okay? That's G\u00f6del's theorem. But now, why is that relevant to consciousness,\n\n44:08.400 --> 44:13.360\n right? Well, you know, I mean, the idea that it might have something to do with consciousness\n\n44:13.360 --> 44:22.160\n as an old one, G\u00f6del himself apparently thought that it did. You know, Lucas thought so, I think,\n\n44:22.160 --> 44:29.600\n in the 60s. And Penrose is really just, you know, sort of updating what they and others had said.\n\n44:29.600 --> 44:34.000\n I mean, you know, the idea that G\u00f6del's theorem could have something to do with consciousness was,\n\n44:34.000 --> 44:40.800\n you know, in 1950, when Alan Turing wrote his article about the Turing test, he already, you\n\n44:40.800 --> 44:47.600\n know, was writing about that as like an old and well known idea and as a wrong one that he wanted\n\n44:47.600 --> 44:54.400\n to dispense with. Okay, but the basic problem with this idea is, you know, Penrose wants to say\n\n44:54.400 --> 45:00.480\n that and all of his predecessors here, you know, want to say that, you know, even though, you know,\n\n45:00.480 --> 45:07.680\n this given formal system cannot prove its own consistency, we as humans sort of looking at it\n\n45:07.680 --> 45:15.280\n from the outside can just somehow see its consistency, right? And the, you know, the rejoinder\n\n45:15.280 --> 45:21.120\n to that, you know, from the very beginning has been, well, can we really? I mean, maybe, you\n\n45:21.120 --> 45:28.560\n know, maybe he, Penrose can, but, you know, can the rest of us, right? And, you know, I noticed\n\n45:28.560 --> 45:36.560\n that, you know, I mean, it is perfectly plausible to imagine a computer that could say, you know,\n\n45:36.560 --> 45:41.360\n it would not be limited to working within a single formal system, right? They could say,\n\n45:41.360 --> 45:47.760\n I am now going to adopt the hypothesis that my formal system is consistent, right? And I'm now\n\n45:47.760 --> 45:52.400\n going to see what can be done from that stronger vantage point and so on. And, you know, and I'm\n\n45:52.400 --> 45:58.640\n going to add new axioms to my system. Totally plausible. There's absolutely, G\u00f6del's theorem\n\n45:58.640 --> 46:05.440\n has nothing to say about against an AI that could repeatedly add new axioms. All it says is that\n\n46:05.440 --> 46:11.760\n there is no absolute guarantee that when the AI adds new axioms that it will always be right.\n\n46:12.320 --> 46:15.600\n Okay. And, you know, and that's, of course, the point that Penrose pounces on,\n\n46:15.600 --> 46:21.040\n but the reply is obvious. And, you know, it's one that Alan Turing made 70 years ago. Namely,\n\n46:21.040 --> 46:26.400\n we don't have an absolute guarantee that we're right when we add a new axiom. We never have,\n\n46:26.400 --> 46:31.600\n and plausibly we never will. So on Alan Turing, you took part in the Lubna Prize?\n\n46:32.880 --> 46:39.600\n Not really. No, I didn't. I mean, there was this kind of ridiculous claim that was made\n\n46:39.600 --> 46:46.080\n some almost a decade ago about a chat bot called Eugene Goostman.\n\n46:46.080 --> 46:48.640\n I guess you didn't participate as a judge in the Lubna Prize.\n\n46:48.640 --> 46:49.040\n I didn't.\n\n46:49.040 --> 46:54.160\n But you participated as a judge in that, I guess it was an exhibition event or something like that,\n\n46:54.160 --> 46:55.200\n or with Eugene...\n\n46:56.400 --> 47:01.280\n Eugene Goostman, that was just me writing a blog post because some journalist called me to ask\n\n47:01.280 --> 47:01.680\n about it.\n\n47:01.680 --> 47:03.200\n Did you ever chat with him? I thought that...\n\n47:03.200 --> 47:06.320\n I did chat with Eugene Goostman. I mean, it was available on the web.\n\n47:06.320 --> 47:07.600\n Oh, interesting. I didn't know that.\n\n47:07.600 --> 47:14.400\n So yeah. So all that happened was that a bunch of journalists started writing breathless articles\n\n47:14.400 --> 47:21.440\n about a first chat bot that passes the Turing test. And it was this thing called Eugene Goostman\n\n47:21.440 --> 47:29.200\n that was supposed to simulate a 13 year old boy. And apparently someone had done some test where\n\n47:29.920 --> 47:36.080\n people were less than perfect, let's say, distinguishing it from a human. And they said,\n\n47:36.080 --> 47:42.320\n well, if you look at Turing's paper and you look at the percentages that he talked about,\n\n47:42.320 --> 47:44.560\n then it seemed like we're past that threshold.\n\n47:45.600 --> 47:53.520\n And I had a different way to look at it instead of the legalistic way, like let's just try the\n\n47:53.520 --> 47:59.760\n actual thing out and let's see what it can do with questions like, is Mount Everest bigger\n\n47:59.760 --> 48:08.160\n than a shoebox? Or just like the most obvious questions. And the answer is, well, it just kind\n\n48:08.160 --> 48:10.720\n of parries you because it doesn't know what you're talking about.\n\n48:10.720 --> 48:16.800\n So just to clarify exactly in which way they're obvious. They're obvious in the sense that\n\n48:17.360 --> 48:22.880\n you convert the sentences into the meaning of the objects they represent and then do some basic\n\n48:23.600 --> 48:29.120\n obvious common sense reasoning with the objects that the sentences represent.\n\n48:29.120 --> 48:35.040\n Right. It was not able to answer or even intelligently respond to basic common sense\n\n48:35.040 --> 48:39.920\n questions. But let me say something stronger than that. There was a famous chatbot in the 60s\n\n48:39.920 --> 48:48.160\n called Eliza that managed to actually fool a lot of people. Or people would pour their hearts out\n\n48:48.160 --> 48:54.000\n into this Eliza because it simulated a therapist. And most of what it would do is it would just\n\n48:54.000 --> 48:59.120\n throw back at you whatever you said. And this turned out to be incredibly effective.\n\n49:00.720 --> 49:10.160\n Maybe therapists know this. This is one of their tricks. But it really had some people convinced.\n\n49:10.880 --> 49:17.120\n But this thing was just like, I think it was literally just a few hundred lines of Lisp code.\n\n49:17.120 --> 49:22.480\n It was not only was it not intelligent, it wasn't especially sophisticated. It was\n\n49:22.480 --> 49:27.840\n like a simple little hobbyist program. And Eugene Goostman, from what I could see,\n\n49:27.840 --> 49:36.880\n was not a significant advance compared to Eliza. And that was really the point I was making.\n\n49:38.560 --> 49:45.520\n In some sense, you didn't need a computer science professor to sort of say this. Anyone who was\n\n49:45.520 --> 49:50.560\n looking at it and who just had an ounce of sense could have said the same thing.\n\n49:50.560 --> 49:57.440\n But because these journalists were calling me, the first thing I said was,\n\n49:58.320 --> 50:04.640\n well, I'm a quantum computing person. I'm not an AI person. You shouldn't ask me. Then they said,\n\n50:04.640 --> 50:08.560\n look, you can go here and you can try it out. I said, all right. All right. So I'll try it out.\n\n50:10.800 --> 50:15.600\n This whole discussion, it got a whole lot more interesting in just the last few months.\n\n50:15.600 --> 50:24.400\n Yeah. I'd love to hear your thoughts about GPT3. In the last few months, the world has now seen\n\n50:24.400 --> 50:33.920\n a chat engine or a text engine, I should say, called GPT3. I think it still does not pass\n\n50:33.920 --> 50:40.880\n a Turing test. There are no real claims that it passes the Turing test. This comes out of the\n\n50:40.880 --> 50:47.280\n group at OpenAI, and they've been relatively careful in what they've claimed about the system.\n\n50:47.280 --> 50:56.960\n But I think as clearly as Eugene Goostman was not in advance over Eliza, it is equally clear that\n\n50:56.960 --> 51:03.040\n this is a major advance over Eliza or really over anything that the world has seen before.\n\n51:03.040 --> 51:12.480\n This is a text engine that can come up with kind of on topic, reasonable sounding completions to\n\n51:12.480 --> 51:20.240\n just about anything that you ask. You can ask it to write a poem about topic X in the style of poet\n\n51:20.240 --> 51:29.040\n Y and it will have a go at that. And it will do not a great job, not an amazing job, but a passable\n\n51:29.040 --> 51:36.240\n job. Definitely as good as, in many cases, I would say better than I would have done.\n\n51:37.600 --> 51:43.760\n You can ask it to write an essay, like a student essay, about pretty much any topic and it will\n\n51:43.760 --> 51:50.080\n get something that I am pretty sure would get at least a B minus in the most high school or\n\n51:50.080 --> 51:56.320\n even college classes. And in some sense, the way that it did this, the way that it achieves this,\n\n51:56.320 --> 52:03.760\n Scott Alexander of the much mourned blog, Slate Star Codex, had a wonderful way of putting it.\n\n52:03.760 --> 52:08.400\n He said that they basically just ground up the entire internet into a slurry.\n\n52:10.400 --> 52:16.640\n And to tell you the truth, I had wondered for a while why nobody had tried that. Why not write\n\n52:16.640 --> 52:24.880\n a chat bot by just doing deep learning over a corpus consisting of the entire web? And so\n\n52:24.880 --> 52:35.280\n now they finally have done that. And the results are very impressive. It's not clear that people\n\n52:35.280 --> 52:41.440\n can argue about whether this is truly a step toward general AI or not, but this is an amazing\n\n52:41.440 --> 52:50.720\n capability that we didn't have a few years ago. A few years ago, if you had told me that we would\n\n52:50.720 --> 52:55.840\n have it now, that would have surprised me. And I think that anyone who denies that is just not\n\n52:55.840 --> 53:02.720\n engaging with what's there. So their model, it takes a large part of the internet and compresses\n\n53:02.720 --> 53:09.680\n it in a small number of parameters relative to the size of the internet and is able to, without\n\n53:10.480 --> 53:16.880\n fine tuning, do a basic kind of a querying mechanism, just like you described where you\n\n53:16.880 --> 53:21.520\n specify a kind of poet and then you want to write a poem. And it somehow is able to do basically a\n\n53:21.520 --> 53:27.440\n lookup on the internet of relevant things. How else do you explain it?\n\n53:27.440 --> 53:34.080\n Well, okay. The training involved massive amounts of data from the internet and actually took\n\n53:34.080 --> 53:40.000\n lots and lots of computer power, lots of electricity. There are some very prosaic\n\n53:40.000 --> 53:46.720\n reasons why this wasn't done earlier. But it costs some tens of millions of dollars, I think.\n\n53:46.720 --> 53:49.440\n Less, but approximately like a few million dollars.\n\n53:49.440 --> 53:51.360\n Oh, okay. Oh, really? Okay.\n\n53:51.360 --> 53:53.600\n It's more like four or five.\n\n53:53.600 --> 53:57.440\n Oh, all right. All right. Thank you. I mean, as they scale it up, it will...\n\n53:57.440 --> 54:01.520\n It'll cost, but then the hope is cost comes down and all that kind of stuff.\n\n54:02.320 --> 54:09.040\n But basically, it is a neural net or what's now called a deep net,\n\n54:09.040 --> 54:15.520\n but they're basically the same thing. So it's a form of algorithm that people\n\n54:15.520 --> 54:21.920\n have known about for decades. But it is constantly trying to solve the problem,\n\n54:21.920 --> 54:30.080\n predict the next word. So it's just trying to predict what comes next. It's not trying to\n\n54:30.080 --> 54:37.120\n decide what it should say, what ought to be true. It's trying to predict what someone who had said\n\n54:37.120 --> 54:40.720\n all of the words up to the preceding one would say next.\n\n54:40.720 --> 54:43.440\n Although to push back on that, that's how it's trained.\n\n54:43.440 --> 54:45.280\n That's right. No, of course.\n\n54:45.280 --> 54:50.480\n It's arguable that our very cognition could be a mechanism as that simple.\n\n54:50.480 --> 54:52.960\n Oh, of course. Of course. I never said that it wasn't.\n\n54:52.960 --> 54:54.960\n Right. But...\n\n54:54.960 --> 55:00.400\n Yeah. I mean, and sometimes that is... If there is a deep philosophical question that's\n\n55:00.400 --> 55:06.320\n raised by GPT3, then that is it, right? Are we doing anything other than this predictive\n\n55:06.320 --> 55:12.000\n processing, just trying to constantly trying to fill in a blank of what would come next\n\n55:12.000 --> 55:15.520\n after what we just said up to this point? Is that what I'm doing right now?\n\n55:16.560 --> 55:20.480\n It's impossible. So the intuition that a lot of people have, well, look,\n\n55:20.480 --> 55:24.800\n this thing is not going to be able to reason, the Mountain Everest question.\n\n55:24.800 --> 55:31.600\n Do you think it's possible that GPT5, 6, and 7 would be able to, with this exact same process,\n\n55:31.600 --> 55:38.720\n begin to do something that looks like... Is indistinguishable to us humans from reasoning?\n\n55:38.720 --> 55:42.960\n I mean, the truth is that we don't really know what the limits are, right?\n\n55:42.960 --> 55:44.000\n Right. Exactly.\n\n55:44.000 --> 55:51.120\n Because what we've seen so far is that GPT3 was basically the same thing as GPT2,\n\n55:51.120 --> 55:59.360\n but just with a much larger network, more training time, bigger training corpus,\n\n55:59.360 --> 56:05.680\n right? And it was very noticeably better than its immediate predecessor.\n\n56:05.680 --> 56:12.320\n So we don't know where you hit the ceiling here, right? I mean, that's the amazing part and maybe\n\n56:12.320 --> 56:19.840\n also the scary part, right? Now, my guess would be that at some point, there has to be diminishing\n\n56:19.840 --> 56:27.520\n returns. It can't be that simple, can it? Right? But I wish that I had more to base that guess on.\n\n56:27.520 --> 56:31.360\n Right. Yeah. I mean, some people say that there will be a limitation on the...\n\n56:31.360 --> 56:34.640\n We're going to hit a limit on the amount of data that's on the internet.\n\n56:34.640 --> 56:39.360\n Yes. Yeah. So sure. So there's certainly that limit. I mean, there's also...\n\n56:41.600 --> 56:47.040\n If you are looking for questions that will stump GPT3, you can come up with some without...\n\n56:48.320 --> 56:55.680\n Even getting it to learn how to balance parentheses, right? It doesn't do such a great job,\n\n56:55.680 --> 57:04.000\n right? And its failures are ironic, right? Like basic arithmetic, right?\n\n57:04.000 --> 57:08.560\n And you think, isn't that what computers are supposed to be best at? Isn't that where\n\n57:08.560 --> 57:14.880\n computers already had us beat a century ago? Right? And yet that's where GPT3 struggles,\n\n57:14.880 --> 57:23.840\n right? But it's amazing that it's almost like a young child in that way, right? But somehow,\n\n57:23.840 --> 57:30.640\n because it is just trying to predict what comes next, it doesn't know when it should stop doing\n\n57:30.640 --> 57:36.240\n that and start doing something very different, like some more exact logical reasoning, right?\n\n57:36.240 --> 57:45.920\n And so one is naturally led to guess that our brain sort of has some element of predictive\n\n57:45.920 --> 57:50.240\n processing, but that it's coupled to other mechanisms, right? That it's coupled to,\n\n57:50.800 --> 57:55.120\n first of all, visual reasoning, which GPT3 also doesn't have any of, right?\n\n57:55.120 --> 57:58.560\n Although there's some demonstration that there's a lot of promise there using...\n\n57:58.560 --> 58:00.880\n Oh yeah, it can complete images. That's right.\n\n58:00.880 --> 58:05.600\n And using exact same kind of transformer mechanisms to like watch videos on YouTube.\n\n58:06.160 --> 58:11.280\n And so the same self supervised mechanism to be able to look,\n\n58:11.280 --> 58:14.240\n it'd be fascinating to think what kind of completions you could do.\n\n58:14.240 --> 58:17.840\n Oh yeah, no, absolutely. Although like if we ask it to like, you know,\n\n58:17.840 --> 58:22.400\n a word problem that involve reasoning about the locations of things in space,\n\n58:22.400 --> 58:26.160\n I don't think it does such a great job on those, right? To take an example. And so\n\n58:26.160 --> 58:31.120\n the guess would be, well, you know, humans have a lot of predictive processing,\n\n58:31.120 --> 58:35.360\n a lot of just filling in the blanks, but we also have these other mechanisms that we can\n\n58:35.360 --> 58:39.680\n couple to, or that we can sort of call as subroutines when we need to.\n\n58:39.680 --> 58:45.520\n And that maybe, you know, to go further, that one would want to integrate other forms of reasoning.\n\n58:46.800 --> 58:52.240\n Let me go on another topic that is amazing, which is complexity.\n\n58:52.240 --> 59:00.640\n And then start with the most absurdly romantic question of what's the most beautiful idea in\n\n59:00.640 --> 59:05.760\n computer science or theoretical computer science to you? Like what just early on in your life,\n\n59:05.760 --> 59:08.560\n or in general, have captivated you and just grabbed you?\n\n59:08.560 --> 59:13.280\n I think I'm going to have to go with the idea of universality. You know,\n\n59:13.280 --> 59:20.160\n if you're really asking for the most beautiful. I mean, so universality is the idea that, you know,\n\n59:20.160 --> 59:27.680\n you put together a few simple operations, like in the case of Boolean logic, that might be the AND\n\n59:27.680 --> 59:33.520\n gate, the OR gate, the NOT gate, right? And then your first guess is, okay, this is a good start,\n\n59:33.520 --> 59:38.960\n but obviously, as I want to do more complicated things, I'm going to need more complicated building\n\n59:38.960 --> 59:44.080\n blocks to express that, right? And that was actually my guess when I first learned what\n\n59:44.080 --> 59:50.800\n programming was. I mean, when I was, you know, an adolescent and someone showed me Apple basic,\n\n59:50.800 --> 59:57.920\n and then, you know, GW basic, if anyone listening remembers that. Okay. But, you know,\n\n59:57.920 --> 1:00:03.760\n I thought, okay, well, now, you know, I mean, I thought I felt like this is a revelation. You know,\n\n1:00:03.760 --> 1:00:08.000\n it's like finding out where babies come from. It's like that level of, you know, why didn't\n\n1:00:08.000 --> 1:00:12.800\n anyone tell me this before, right? But I thought, okay, this is just the beginning. Now I know how\n\n1:00:12.800 --> 1:00:18.640\n to write a basic program, but, you know, really write an interesting program, like, you know,\n\n1:00:18.640 --> 1:00:24.400\n a video game, which had always been my dream as a kid to, you know, create my own Nintendo games,\n\n1:00:24.400 --> 1:00:29.360\n right? You know, but, you know, obviously I'm going to need to learn some way more complicated\n\n1:00:29.360 --> 1:00:35.440\n form of programming than that. Okay. But, you know, eventually I learned this incredible idea\n\n1:00:35.440 --> 1:00:42.400\n of universality. And that says that, no, you throw in a few rules and then you already have\n\n1:00:42.400 --> 1:00:48.960\n enough to express everything. Okay. So for example, the AND, the OR and the NOT gate can all,\n\n1:00:48.960 --> 1:00:54.400\n or in fact, even just the AND and the NOT gate, or even just the NAND gate, for example,\n\n1:00:55.040 --> 1:01:00.480\n is already enough to express any Boolean function on any number of bits. You just have to string\n\n1:01:00.480 --> 1:01:04.800\n together enough of them. You can build a universe with NAND gates. You can build the universe out of\n\n1:01:04.800 --> 1:01:12.640\n NAND gates. Yeah. You know, the simple instructions of BASIC are already enough, at least in principle,\n\n1:01:12.640 --> 1:01:17.840\n you know, if we ignore details like how much memory can be accessed and stuff like that,\n\n1:01:17.840 --> 1:01:22.800\n that is enough to express what could be expressed by any programming language whatsoever.\n\n1:01:22.800 --> 1:01:28.240\n And the way to prove that is very simple. We simply need to show that in BASIC or whatever,\n\n1:01:28.240 --> 1:01:35.040\n we could write an interpreter or a compiler for whatever other programming language we care about,\n\n1:01:35.040 --> 1:01:41.360\n like C or Java or whatever. And as soon as we had done that, then ipso facto, anything that's\n\n1:01:41.360 --> 1:01:49.520\n expressible in C or Java is also expressible in BASIC. Okay. And so this idea of universality,\n\n1:01:49.520 --> 1:01:54.720\n you know, goes back at least to Alan Turing in the 1930s when, you know, he\n\n1:01:54.720 --> 1:02:01.040\n wrote down this incredibly simple pared down model of a computer, the Turing machine, right,\n\n1:02:01.040 --> 1:02:08.800\n which, you know, he pared down the instruction set to just read a symbol, you know, write a symbol,\n\n1:02:08.800 --> 1:02:15.440\n move to the left, move to the right, halt, change your internal state, right? That's it. Okay.\n\n1:02:15.440 --> 1:02:22.160\n And anybody proved that, you know, this could simulate all kinds of other things, you know,\n\n1:02:22.160 --> 1:02:28.560\n and so in fact, today we would say, well, we would call it a Turing universal model of computation\n\n1:02:28.560 --> 1:02:37.680\n that is, you know, just as it has just the same expressive power that BASIC or Java or C++ or any\n\n1:02:37.680 --> 1:02:43.600\n of those other languages have because anything in those other languages could be compiled down\n\n1:02:43.600 --> 1:02:48.880\n to Turing machine. Now, Turing also proved a different related thing, which is that there is\n\n1:02:48.880 --> 1:02:57.360\n a single Turing machine that can simulate any other Turing machine if you just describe that\n\n1:02:57.360 --> 1:03:03.120\n other machine on its tape, right? And likewise, there is a single Turing machine that will run\n\n1:03:03.120 --> 1:03:08.960\n any C program, you know, if you just put it on its tape. That's a second meaning of universality.\n\n1:03:08.960 --> 1:03:12.320\n First of all, he couldn't visualize it and that was in the 30s.\n\n1:03:12.320 --> 1:03:13.600\n Yeah, the 30s. That's right.\n\n1:03:13.600 --> 1:03:21.120\n That's before computers really, I mean, I don't know how, I wonder what that felt like,\n\n1:03:21.120 --> 1:03:27.760\n you know, learning that there's no Santa Claus or something. Because I don't know if that's\n\n1:03:27.760 --> 1:03:34.800\n empowering or paralyzing because it doesn't give you any, it's like you can't write a software\n\n1:03:34.800 --> 1:03:38.320\n engineering book and make that the first chapter and say we're done.\n\n1:03:38.320 --> 1:03:44.320\n Well, I mean, right. I mean, in one sense, it was this enormous flattening of the universe.\n\n1:03:44.320 --> 1:03:44.800\n Yes.\n\n1:03:44.800 --> 1:03:50.320\n I had imagined that there was going to be some infinite hierarchy of more and more powerful\n\n1:03:50.320 --> 1:03:55.440\n programming languages, you know, and then I kicked myself for having such a stupid idea.\n\n1:03:55.440 --> 1:03:58.800\n But apparently, G\u00f6del had had the same conjecture in the 30s.\n\n1:03:58.800 --> 1:04:00.880\n Oh, good. You're in good company.\n\n1:04:00.880 --> 1:04:10.000\n Yeah. And then G\u00f6del read Turing's paper and he kicked himself and he said, yeah, I was completely\n\n1:04:10.000 --> 1:04:17.760\n wrong about that. But I had thought that maybe where I can contribute will be to invent a new\n\n1:04:17.760 --> 1:04:22.800\n more powerful programming language that lets you express things that could never be expressed in\n\n1:04:22.800 --> 1:04:30.640\n BASIC. And how would you do that? Obviously, you couldn't do it itself in BASIC. But there\n\n1:04:30.640 --> 1:04:36.400\n is this incredible flattening that happens once you learn what is universality. But then it's also\n\n1:04:39.200 --> 1:04:44.720\n an opportunity because it means once you know these rules, then the sky is the limit, right?\n\n1:04:44.720 --> 1:04:51.440\n Then you have kind of the same weapons at your disposal that the world's greatest programmer has.\n\n1:04:51.440 --> 1:04:54.240\n It's now all just a question of how you wield them.\n\n1:04:54.240 --> 1:05:00.960\n Right. Exactly. So every problem is solvable, but some problems are harder than others.\n\n1:05:00.960 --> 1:05:06.960\n Well, yeah, there's the question of how much time, you know, of how hard is it to write a program?\n\n1:05:06.960 --> 1:05:11.280\n And then there's also the questions of what resources does the program need? You know,\n\n1:05:11.280 --> 1:05:15.360\n how much time, how much memory? Those are much more complicated questions. Of course,\n\n1:05:15.360 --> 1:05:17.360\n ones that we're still struggling with today.\n\n1:05:17.360 --> 1:05:21.200\n Exactly. So you've, I don't know if you created Complexity Zoo or...\n\n1:05:21.200 --> 1:05:23.120\n I did create the Complexity Zoo.\n\n1:05:23.120 --> 1:05:24.880\n What is it? What's complexity?\n\n1:05:24.880 --> 1:05:29.360\n Oh, all right, all right, all right. Complexity theory is the study of sort of the\n\n1:05:29.920 --> 1:05:38.000\n inherent resources needed to solve computational problems, okay? So it's easiest to give an example.\n\n1:05:38.560 --> 1:05:47.040\n Like, let's say we want to add two numbers, right? If I want to add them, you know, if the numbers\n\n1:05:47.040 --> 1:05:52.480\n are twice as long, then it only, it will take me twice as long to add them, but only twice as long,\n\n1:05:52.480 --> 1:05:54.480\n right? It's no worse than that.\n\n1:05:54.480 --> 1:05:55.440\n Or a computer.\n\n1:05:55.440 --> 1:05:59.120\n For a computer or for a person. We're using pencil and paper, for that matter.\n\n1:05:59.120 --> 1:06:00.400\n If you have a good algorithm.\n\n1:06:00.400 --> 1:06:05.440\n Yeah, that's right. I mean, even if you just use the elementary school algorithm of just carrying,\n\n1:06:05.440 --> 1:06:10.640\n you know, then it takes time that is linear in the length of the numbers, right? Now,\n\n1:06:10.640 --> 1:06:17.040\n multiplication, if you use the elementary school algorithm, is harder because you have to multiply\n\n1:06:17.040 --> 1:06:22.000\n each digit of the first number by each digit of the second one. And then deal with all the\n\n1:06:22.000 --> 1:06:28.800\n carries. So that's what we call a quadratic time algorithm, right? If the numbers become twice as\n\n1:06:28.800 --> 1:06:38.000\n long, now you need four times as much time, okay? So now, as it turns out, people discovered much\n\n1:06:38.000 --> 1:06:45.040\n faster ways to multiply numbers using computers. And today we know how to multiply two numbers\n\n1:06:45.040 --> 1:06:50.960\n that are n digits long using a number of steps that's nearly linear in n. These are questions you\n\n1:06:50.960 --> 1:06:56.160\n can ask. But now, let's think about a different thing that people, you know, they've encountered\n\n1:06:56.160 --> 1:07:03.040\n in elementary school, factoring a number. Okay? Take a number and find its prime factors, right?\n\n1:07:03.040 --> 1:07:08.640\n And here, you know, if I give you a number with ten digits, I ask you for its prime factors.\n\n1:07:08.640 --> 1:07:13.600\n Well, maybe it's even, so you know that two is a factor. You know, maybe it ends in zero,\n\n1:07:13.600 --> 1:07:18.880\n so you know that ten is a factor, right? But, you know, other than a few obvious things like that,\n\n1:07:18.880 --> 1:07:24.320\n you know, if the prime factors are all very large, then it's not clear how you even get started,\n\n1:07:24.320 --> 1:07:29.360\n right? You know, it seems like you have to do an exhaustive search among an enormous number of\n\n1:07:29.360 --> 1:07:39.280\n factors. Now, and as many people might know, for better or worse, the security, you know,\n\n1:07:39.280 --> 1:07:45.200\n of most of the encryption that we currently use to protect the internet is based on the belief,\n\n1:07:45.200 --> 1:07:51.280\n and this is not a theorem, it's a belief, that factoring is an inherently hard problem\n\n1:07:52.000 --> 1:07:58.000\n for our computers. We do know algorithms that are better than just trial division, than just trying\n\n1:07:58.000 --> 1:08:05.200\n all the possible divisors, but they are still basically exponential. And exponential is hard.\n\n1:08:05.840 --> 1:08:11.520\n Yeah, exactly. So the fastest algorithms that anyone has discovered, at least publicly\n\n1:08:11.520 --> 1:08:15.520\n discovered, you know, I'm assuming that the NSA doesn't know something better,\n\n1:08:15.520 --> 1:08:21.920\n okay? But they take time that basically grows exponentially with the cube root of the size of\n\n1:08:21.920 --> 1:08:26.800\n the number that you're factoring, right? So that cube root, that's the part that takes all the\n\n1:08:26.800 --> 1:08:31.600\n cleverness, okay? But there's still an exponential. There's still an exponentiality there. But what\n\n1:08:31.600 --> 1:08:37.360\n that means is that, like, when people use a thousand bit keys for their cryptography,\n\n1:08:37.360 --> 1:08:42.800\n that can probably be broken using the resources of the NSA or the world's other intelligence\n\n1:08:42.800 --> 1:08:47.600\n agencies. You know, people have done analyses that say, you know, with a few hundred million\n\n1:08:47.600 --> 1:08:53.120\n dollars of computer power, they could totally do this. And if you look at the documents that Snowden\n\n1:08:53.120 --> 1:08:59.360\n released, you know, it looks a lot like they are doing that or something like that. It would kind\n\n1:08:59.360 --> 1:09:05.520\n of be surprising if they weren't, okay? But, you know, if that's true, then in some ways that's\n\n1:09:05.520 --> 1:09:10.000\n reassuring. Because if that's the best that they can do, then that would say that they can't break\n\n1:09:10.000 --> 1:09:16.960\n 2,000 bit numbers, right? Then 2,000 bit numbers would be beyond what even they could do.\n\n1:09:16.960 --> 1:09:21.600\n They haven't found an efficient algorithm. That's where all the worries and the concerns of quantum\n\n1:09:21.600 --> 1:09:24.400\n computing came in, that there could be some kind of shortcut around that.\n\n1:09:24.400 --> 1:09:31.920\n Right. So complexity theory is a huge part of, let's say, the theoretical core of computer\n\n1:09:31.920 --> 1:09:39.280\n science. You know, it started in the 60s and 70s as, you know, sort of an autonomous field. So it\n\n1:09:39.280 --> 1:09:45.120\n was, you know, already, you know, I mean, you know, it was well developed even by the time that\n\n1:09:45.120 --> 1:09:54.160\n I was born, okay? But in 2002, I made a website called the Complexity Zoo, to answer your question,\n\n1:09:54.880 --> 1:10:01.360\n where I just tried to catalog the different complexity classes, which are classes of problems\n\n1:10:01.360 --> 1:10:06.960\n that are solvable with different kinds of resources, okay? So these are kind of, you know,\n\n1:10:06.960 --> 1:10:13.200\n you could think of complexity classes as like being almost to theoretical computer science,\n\n1:10:13.200 --> 1:10:18.320\n like what the elements are to chemistry, right? They're sort of, you know, there are our most\n\n1:10:18.320 --> 1:10:22.480\n basic objects in a certain way. I feel like the elements\n\n1:10:25.120 --> 1:10:29.200\n have a characteristic to them where you can't just add an infinite number.\n\n1:10:29.200 --> 1:10:34.960\n Well, you could, but beyond a certain point, they become unstable, right? Right. So it's like,\n\n1:10:34.960 --> 1:10:39.040\n you know, in theory, you can have atoms with, you know, and look, look, I mean, I mean,\n\n1:10:39.040 --> 1:10:48.880\n a neutron star, you know, is a nucleus with, you know, uncalled billions of neutrons in it,\n\n1:10:48.880 --> 1:10:56.400\n of hadrons in it, okay? But, you know, for sort of normal atoms, right, probably you can't get\n\n1:10:56.400 --> 1:11:04.320\n much above a hundred atomic weight, 150 or so, or sorry, sorry, I mean, beyond 150 or so protons\n\n1:11:04.320 --> 1:11:10.240\n without it, you know, very quickly fissioning. With complexity classes, well, yeah, you can have\n\n1:11:10.240 --> 1:11:16.080\n an infinity of complexity classes, but, you know, maybe there's only a finite number of them that\n\n1:11:16.080 --> 1:11:21.680\n are particularly interesting, right? Just like with anything else, you know, you care about\n\n1:11:21.680 --> 1:11:25.920\n some more than about others. So what kind of interesting classes are there? I mean,\n\n1:11:25.920 --> 1:11:31.040\n you could have just, maybe say, what are the, if you take any kind of computer science class,\n\n1:11:31.040 --> 1:11:36.400\n what are the classes you learn? Good. Let me tell you sort of the biggest ones,\n\n1:11:36.400 --> 1:11:41.840\n the ones that you would learn first. So, you know, first of all, there is P, that's what it's called,\n\n1:11:41.840 --> 1:11:47.840\n okay? It stands for polynomial time. And this is just the class of all of the problems that you\n\n1:11:47.840 --> 1:11:54.240\n could solve with a conventional computer, like your iPhone or your laptop, you know,\n\n1:11:54.240 --> 1:12:01.680\n by a completely deterministic algorithm, right? Using a number of steps that grows only like the\n\n1:12:01.680 --> 1:12:09.280\n size of the input raised to some fixed power, okay? So, if your algorithm is linear time,\n\n1:12:09.280 --> 1:12:14.800\n like, you know, for adding numbers, okay, that problem is in P. If you have an algorithm that's\n\n1:12:14.800 --> 1:12:20.480\n quadratic time, like the elementary school algorithm for multiplying two numbers, that's also\n\n1:12:20.480 --> 1:12:26.800\n in P, even if it was the size of the input to the 10th power or to the 50th power, well, that wouldn't\n\n1:12:26.800 --> 1:12:32.160\n be very good in practice. But, you know, formally, we would still count that, that would still be in\n\n1:12:32.160 --> 1:12:40.000\n P, okay? But if your algorithm takes exponential time, meaning like if every time I add one more\n\n1:12:41.520 --> 1:12:48.560\n data point to your input, if the time needed by the algorithm doubles, if you need time like two\n\n1:12:48.560 --> 1:12:56.320\n to the power of the amount of input data, then that we call an exponential time algorithm, okay?\n\n1:12:56.320 --> 1:13:03.120\n And that is not polynomial, okay? So, P is all of the problems that have some polynomial time\n\n1:13:03.120 --> 1:13:09.040\n algorithm, okay? So, that includes most of what we do with our computers on a day to day basis,\n\n1:13:09.040 --> 1:13:14.320\n you know, all the, you know, sorting, basic arithmetic, you know, whatever is going on in\n\n1:13:14.320 --> 1:13:21.840\n your email reader or in Angry Birds, okay? It's all in P. Then the next super important class\n\n1:13:21.840 --> 1:13:28.400\n is called NP. That stands for non deterministic polynomial, okay? It does not stand for not\n\n1:13:28.400 --> 1:13:35.440\n polynomial, which is a common confusion. But NP was basically all of the problems\n\n1:13:35.440 --> 1:13:41.920\n where if there is a solution, then it is easy to check the solution if someone shows it to you,\n\n1:13:41.920 --> 1:13:48.880\n okay? So, actually a perfect example of a problem in NP is factoring, the one I told you about\n\n1:13:48.880 --> 1:13:56.240\n before. Like if I gave you a number with thousands of digits and I told you that, you know, I asked\n\n1:13:56.240 --> 1:14:05.120\n you, does this have at least three non trivial divisors, right? That might be a super hard problem\n\n1:14:05.120 --> 1:14:09.920\n to solve, right? It might take you millions of years using any algorithm that's known, at least\n\n1:14:09.920 --> 1:14:16.000\n running on our existing computers, okay? But if I simply showed you the divisors, I said,\n\n1:14:16.000 --> 1:14:22.080\n here are three divisors of this number, then it would be very easy for you to ask your computer\n\n1:14:22.080 --> 1:14:27.520\n to just check each one and see if it works. Just divide it in, see if there's any remainder,\n\n1:14:27.520 --> 1:14:35.040\n right? And if they all go in, then you've checked. Well, I guess there were, right? So any problem\n\n1:14:35.040 --> 1:14:40.480\n where, you know, wherever there's a solution, there is a short witness that can be easily,\n\n1:14:40.480 --> 1:14:48.000\n like a polynomial size witness that can be checked in polynomial time, that we call an NP problem,\n\n1:14:48.000 --> 1:14:55.440\n okay? And yeah, so every problem that's in P is also in NP, right? Because, you know, you could\n\n1:14:55.440 --> 1:14:59.520\n always just ignore the witness and just, you know, if a problem is in P, you can just solve it\n\n1:14:59.520 --> 1:15:07.200\n yourself, okay? But now, in some sense, the central, you know, mystery of theoretical computer science\n\n1:15:07.200 --> 1:15:15.200\n is every NP problem in P. So if you can easily check the answer to a computational problem,\n\n1:15:15.200 --> 1:15:18.080\n does that mean that you can also easily find the answer?\n\n1:15:18.080 --> 1:15:23.600\n Even though there's all these problems that appear to be very difficult to find the answer,\n\n1:15:23.600 --> 1:15:26.880\n it's still an open question whether a good answer exists.\n\n1:15:26.880 --> 1:15:29.680\n Because no one has proven that there's no way to do it.\n\n1:15:29.680 --> 1:15:36.560\n It's arguably the most, I don't know, the most famous, the most maybe interesting,\n\n1:15:36.560 --> 1:15:40.000\n maybe you disagree with that, problem in theoretical computer science. So what's your\n\n1:15:40.000 --> 1:15:41.280\n The most famous, for sure.\n\n1:15:41.280 --> 1:15:45.280\n P equals NP. If you were to bet all your money, where do you put your money?\n\n1:15:45.280 --> 1:15:49.840\n That's an easy one. P is not equal to NP. I like to say that if we were physicists,\n\n1:15:49.840 --> 1:15:54.560\n we would have just declared that to be a law of nature, you know, just like thermodynamics.\n\n1:15:54.560 --> 1:15:55.680\n That's hilarious.\n\n1:15:55.680 --> 1:16:01.280\n Given ourselves Nobel Prizes for its discovery. Yeah, you know, and look, if later it turned out\n\n1:16:01.280 --> 1:16:04.560\n that we were wrong, we just give ourselves more Nobel Prizes.\n\n1:16:04.560 --> 1:16:09.280\n So harsh, but so true.\n\n1:16:09.280 --> 1:16:14.720\n I mean, no, I mean, I mean, it's really just because we are mathematicians or descended\n\n1:16:14.720 --> 1:16:19.760\n from mathematicians, you know, we have to call things conjectures that other people\n\n1:16:19.760 --> 1:16:23.280\n would just call empirical facts or discoveries, right?\n\n1:16:23.280 --> 1:16:26.960\n But one shouldn't read more into that difference in language, you know,\n\n1:16:26.960 --> 1:16:28.800\n about the underlying truth.\n\n1:16:28.800 --> 1:16:33.760\n So, okay, so you're a good investor and good spender of money. So then let me ask another\n\n1:16:33.760 --> 1:16:41.120\n way. Is it possible at all? And what would that look like if P indeed equals NP?\n\n1:16:41.680 --> 1:16:45.360\n Well, I do think that it's possible. I mean, in fact, you know, when people really pressed\n\n1:16:45.360 --> 1:16:50.320\n me on my blog for what odds would I put, I put, you know, two or three percent odds.\n\n1:16:50.320 --> 1:16:51.200\n Wow, that's pretty good.\n\n1:16:51.200 --> 1:16:57.200\n That P equals NP. Yeah. Well, because, you know, when P, I mean, you really have to think\n\n1:16:57.200 --> 1:17:04.160\n about, like, if there were 50, you know, mysteries like P versus NP, and if I made a guess about\n\n1:17:04.160 --> 1:17:09.040\n every single one of them, would I expect to be right 50 times? Right? And the truthful\n\n1:17:09.040 --> 1:17:10.560\n answer is no. Okay.\n\n1:17:10.560 --> 1:17:11.040\n Yeah.\n\n1:17:11.040 --> 1:17:16.560\n So, you know, and that's what you really mean in saying that, you know, you have, you know,\n\n1:17:16.560 --> 1:17:22.640\n better than 98% odds for something. Okay. But so, yeah, you know, I mean, there could\n\n1:17:22.640 --> 1:17:27.920\n certainly be surprises. And look, if P equals NP, well, then there would be the further\n\n1:17:27.920 --> 1:17:33.920\n question of, you know, is the algorithm actually efficient in practice? Right? I mean, Don\n\n1:17:33.920 --> 1:17:39.440\n Knuth, who I know that you've interviewed as well, right, he likes to conjecture that\n\n1:17:39.440 --> 1:17:44.720\n P equals NP, but that the algorithm is so inefficient that it doesn't matter anyway.\n\n1:17:44.720 --> 1:17:45.200\n Right?\n\n1:17:45.200 --> 1:17:50.160\n No, I don't know. I've listened to him say that. I don't know whether he says that just\n\n1:17:50.160 --> 1:17:54.400\n because he has an actual reason for thinking it's true or just because it sounds cool.\n\n1:17:54.400 --> 1:17:54.640\n Yeah.\n\n1:17:54.640 --> 1:18:00.960\n Okay. But, you know, that's a logical possibility, right, that the algorithm could be n to the\n\n1:18:00.960 --> 1:18:06.880\n 10,000 time, or it could even just be n squared time, but with a leading constant of, it could\n\n1:18:06.880 --> 1:18:12.080\n be a Google times n squared or something like that. And in that case, the fact that P equals\n\n1:18:12.080 --> 1:18:19.840\n NP, well, it would ravage the whole theory of complexity. We would have to rebuild from\n\n1:18:19.840 --> 1:18:25.680\n the ground up. But in practical terms, it might mean very little, right, if the algorithm\n\n1:18:25.680 --> 1:18:31.680\n was too inefficient to run. If the algorithm could actually be run in practice, like if\n\n1:18:31.680 --> 1:18:38.000\n it had small enough constants, or if you could improve it to where it had small enough constants\n\n1:18:38.000 --> 1:18:42.400\n that was efficient in practice, then that would change the world. Okay?\n\n1:18:42.400 --> 1:18:44.320\n You think it would have, like, what kind of impact would it have?\n\n1:18:44.320 --> 1:18:49.600\n Well, okay, I mean, here's an example. I mean, you could, well, okay, just for starters,\n\n1:18:49.600 --> 1:18:53.600\n you could break basically all of the encryption that people use to protect the internet.\n\n1:18:53.600 --> 1:18:54.480\n That's just for starters.\n\n1:18:54.480 --> 1:18:57.920\n You could break Bitcoin and every other cryptocurrency, or, you know,\n\n1:18:58.800 --> 1:19:06.480\n mine as much Bitcoin as you wanted, right? You know, become a super duper billionaire,\n\n1:19:06.480 --> 1:19:09.040\n right? And then plot your next move.\n\n1:19:09.040 --> 1:19:11.280\n Right. That's just for starters. That's a good point.\n\n1:19:11.280 --> 1:19:16.960\n Now, your next move might be something like, you know, you now have, like, a theoretically\n\n1:19:16.960 --> 1:19:22.240\n optimal way to train any neural network, to find parameters for any neural network, right?\n\n1:19:22.240 --> 1:19:27.840\n So you could now say, like, is there any small neural network that generates the entire content\n\n1:19:27.840 --> 1:19:33.280\n of Wikipedia, right? If, you know, and now the question is not, can you find it? The\n\n1:19:33.280 --> 1:19:39.120\n question has been reduced to, does that exist or not? If it does exist, then the answer would be,\n\n1:19:39.120 --> 1:19:44.400\n yes, you can find it, okay? If you had this algorithm in your hands, okay?\n\n1:19:44.400 --> 1:19:50.000\n You could ask your computer, you know, I mean, P versus NP is one of these seven problems that\n\n1:19:50.000 --> 1:19:54.880\n carries this million dollar prize from the Clay Foundation. You know, if you solve it,\n\n1:19:54.880 --> 1:20:00.640\n you know, and others are the Riemann hypothesis, the Poincare conjecture, which was solved,\n\n1:20:00.640 --> 1:20:06.320\n although the solver turned down the prize, right, and four others. But what I like to say,\n\n1:20:06.320 --> 1:20:10.640\n the way that we can see that P versus NP is the biggest of all of these questions\n\n1:20:11.200 --> 1:20:15.680\n is that if you had this fast algorithm, then you could solve all seven of them,\n\n1:20:15.680 --> 1:20:20.880\n okay? You just ask your computer, you know, is there a short proof of the Riemann hypothesis,\n\n1:20:20.880 --> 1:20:25.200\n right? You know, that a machine could, in a language where a machine could verify it,\n\n1:20:25.200 --> 1:20:28.560\n and provided that such a proof exists, then your computer finds it\n\n1:20:28.560 --> 1:20:33.120\n in a short amount of time without having to do a brute force search, okay? So, I mean,\n\n1:20:33.120 --> 1:20:38.560\n those are the stakes of what we're talking about. But I hope that also helps to give your listeners\n\n1:20:38.560 --> 1:20:45.120\n some intuition of why I and most of my colleagues would put our money on P not equaling NP.\n\n1:20:46.080 --> 1:20:50.400\n Is it possible, I apologize this is a really dumb question, but is it possible to,\n\n1:20:50.400 --> 1:20:58.720\n that a proof will come out that P equals NP, but an algorithm that makes P equals NP\n\n1:20:59.360 --> 1:21:05.600\n is impossible to find? Is that like crazy? Okay, well, if P equals NP, it would mean\n\n1:21:05.600 --> 1:21:08.720\n that there is such an algorithm. That it exists, yeah.\n\n1:21:09.360 --> 1:21:17.200\n But, you know, it would mean that it exists. Now, you know, in practice, normally the way that we\n\n1:21:17.200 --> 1:21:23.040\n would prove anything like that would be by finding the algorithm. But there is such a thing as a\n\n1:21:23.040 --> 1:21:28.480\n nonconstructive proof that an algorithm exists. You know, this has really only reared its head,\n\n1:21:28.480 --> 1:21:35.200\n I think, a few times in the history of our field, right? But, you know, it is theoretically possible\n\n1:21:35.200 --> 1:21:40.960\n that such a thing could happen. But, you know, there are, even here, there are some amusing\n\n1:21:40.960 --> 1:21:47.280\n observations that one could make. So there is this famous observation of Leonid Levin, who was,\n\n1:21:47.280 --> 1:21:51.680\n you know, one of the original discoverers of NP completeness, right? And he said,\n\n1:21:51.680 --> 1:21:58.960\n we'll consider the following algorithm that I guarantee will solve the NP problems efficiently,\n\n1:21:58.960 --> 1:22:05.200\n just as provided that P equals NP, okay? Here is what it does. It just runs, you know,\n\n1:22:05.200 --> 1:22:11.360\n it enumerates every possible algorithm in a gigantic infinite list, right? From like in\n\n1:22:11.360 --> 1:22:15.840\n like alphabetical order, right? You know, and many of them maybe won't even compile,\n\n1:22:15.840 --> 1:22:20.720\n so we just ignore those, okay? But now, we just, you know, run the first algorithm,\n\n1:22:20.720 --> 1:22:24.560\n then we run the second algorithm, we run the first one a little bit more,\n\n1:22:24.560 --> 1:22:28.720\n then we run the first three algorithms for a while, we run the first four for a while.\n\n1:22:28.720 --> 1:22:35.360\n This is called dovetailing, by the way. This is a known trick in theoretical computer science,\n\n1:22:35.360 --> 1:22:42.640\n okay? But we do it in such a way that, you know, whatever is the algorithm out there in our list\n\n1:22:42.640 --> 1:22:48.560\n that solves NP complete, you know, the NP problems efficiently, will eventually hit that one,\n\n1:22:48.560 --> 1:22:54.160\n right? And now, the key is that whenever we hit that one, you know, by assumption,\n\n1:22:54.160 --> 1:22:59.360\n it has to solve the problem, it has to find the solution, and once it claims to find a solution,\n\n1:22:59.360 --> 1:23:04.720\n then we can check that ourselves, right? Because these are NP problems, then we can check it.\n\n1:23:04.720 --> 1:23:11.200\n Now, this is utterly impractical, right? You know, you'd have to do this enormous exhaustive search\n\n1:23:11.200 --> 1:23:16.880\n among all the algorithms, but from a certain theoretical standpoint, that is merely a constant\n\n1:23:16.880 --> 1:23:22.640\n prefactor, right? That's merely a multiplier of your running time. So, there are tricks like that\n\n1:23:22.640 --> 1:23:27.920\n one can do to say that, in some sense, the algorithm would have to be constructive. But,\n\n1:23:27.920 --> 1:23:33.840\n you know, in the human sense, you know, it is possible that to, you know, it's conceivable\n\n1:23:33.840 --> 1:23:38.960\n that one could prove such a thing via a nonconstructive method. Is that likely? I don't\n\n1:23:38.960 --> 1:23:46.320\n think so. Not personally. So, that's P and NP, but the complexity zoo is full of wonderful\n\n1:23:46.320 --> 1:23:53.680\n creatures. Well, it's got about 500 of them. 500. So, how do you get, yeah, how do you get more?\n\n1:23:56.160 --> 1:24:02.560\n I mean, just for starters, there is everything that we could do with a conventional computer\n\n1:24:02.560 --> 1:24:08.080\n with a polynomial amount of memory, okay, but possibly an exponential amount of time,\n\n1:24:08.080 --> 1:24:13.360\n because we get to reuse the same memory over and over again. Okay, that is called P space,\n\n1:24:13.360 --> 1:24:21.200\n okay? And that's actually, we think, an even larger class than NP. Okay, well, P is contained\n\n1:24:21.200 --> 1:24:26.640\n in NP, which is contained in P space. And we think that those containments are strict.\n\n1:24:26.640 --> 1:24:30.240\n And the constraint there is on the memory. The memory has to grow\n\n1:24:31.120 --> 1:24:35.280\n polynomially with the size of the process. That's right. That's right. But in P space,\n\n1:24:35.280 --> 1:24:41.600\n we now have interesting things that were not in NP, like as a famous example, you know,\n\n1:24:41.600 --> 1:24:46.720\n from a given position in chess, you know, does white or black have the win? Let's say,\n\n1:24:46.720 --> 1:24:53.520\n assuming provided that the game lasts only for a reasonable number of moves, okay? Or likewise,\n\n1:24:53.520 --> 1:24:57.920\n for go, okay? And, you know, even for the generalizations of these games to arbitrary\n\n1:24:57.920 --> 1:25:01.760\n size boards, because with an eight by eight board, you could say that's just a constant\n\n1:25:01.760 --> 1:25:06.480\n size problem. You just, you know, in principle, you just solve it in O of one time, right?\n\n1:25:06.480 --> 1:25:14.080\n But so we really mean the generalizations of, you know, games to arbitrary size boards here.\n\n1:25:14.080 --> 1:25:21.920\n Or another thing in P space would be, like, I give you some really hard constraint satisfaction\n\n1:25:21.920 --> 1:25:28.880\n problem, like, you know, a traveling salesperson or, you know, packing boxes into the trunk of\n\n1:25:28.880 --> 1:25:33.920\n your car or something like that. And I ask, not just is there a solution, which would be an NP\n\n1:25:33.920 --> 1:25:41.200\n problem, but I ask how many solutions are there, okay? That, you know, count the number of valid\n\n1:25:41.200 --> 1:25:49.120\n solutions. That actually gives, those problems lie in a complexity class called sharp P, or like,\n\n1:25:49.120 --> 1:25:54.640\n it looks like hashtag, like hashtag P, okay, which sits between NP and P space.\n\n1:25:55.760 --> 1:26:01.760\n There's all the problems that you can do in exponential time, okay? That's called exp. So,\n\n1:26:01.760 --> 1:26:09.840\n and by the way, it was proven in the 60s that exp is larger than P, okay? So we know that much.\n\n1:26:09.840 --> 1:26:14.960\n We know that there are problems that are solvable in exponential time that are not solvable in\n\n1:26:14.960 --> 1:26:20.880\n polynomial time, okay? In fact, we even know, we know that there are problems that are solvable in\n\n1:26:20.880 --> 1:26:26.400\n n cubed time that are not solvable in n squared time. And that, those don't help us with a\n\n1:26:26.400 --> 1:26:31.920\n controversy between P and NP at all. Unfortunately, it seems not, or certainly not yet, right?\n\n1:26:31.920 --> 1:26:37.680\n The techniques that we use to establish those things, they're very, very related to how Turing\n\n1:26:37.680 --> 1:26:42.560\n proved the unsolvability of the halting problem, but they seem to break down when we're comparing\n\n1:26:42.560 --> 1:26:50.240\n two different resources, like time versus space, or like, you know, P versus NP, okay? But, you know,\n\n1:26:50.240 --> 1:26:55.840\n I mean, there's what you can do with a randomized algorithm, right? That can be done with a\n\n1:26:55.840 --> 1:27:01.520\n random algorithm, right? That can sometimes, you know, has some probability of making a mistake.\n\n1:27:01.520 --> 1:27:07.680\n That's called BPP, bounded error probabilistic polynomial time. And then, of course, there's\n\n1:27:07.680 --> 1:27:13.680\n one that's very close to my own heart, what you can efficiently do in polynomial time using a\n\n1:27:13.680 --> 1:27:20.240\n quantum computer, okay? And that's called BQP, right? And so, you know, what's understood about\n\n1:27:20.240 --> 1:27:27.520\n it? Okay, so P is contained in BPP, which is contained in BQP, which is contained in P space,\n\n1:27:27.520 --> 1:27:35.120\n okay? So anything you can, in fact, in something very similar to sharp P. BQP is basically,\n\n1:27:35.120 --> 1:27:41.040\n you know, well, it's contained in like P with the magic power to solve sharp P problems, okay?\n\n1:27:41.680 --> 1:27:44.960\n Why is BQP contained in P space?\n\n1:27:44.960 --> 1:27:52.400\n Oh, that's an excellent question. So there is, well, I mean, one has to prove that, okay? But\n\n1:27:53.040 --> 1:28:00.960\n the proof, you could think of it as using Richard Feynman's picture of quantum mechanics,\n\n1:28:00.960 --> 1:28:06.640\n which is that you can always, you know, we haven't really talked about quantum mechanics in this\n\n1:28:06.640 --> 1:28:08.480\n conversation. We did in our previous one.\n\n1:28:08.480 --> 1:28:09.600\n Yeah, we did last time.\n\n1:28:09.600 --> 1:28:16.160\n But yeah, we did last time, okay? But basically, you could always think of a quantum computation\n\n1:28:16.160 --> 1:28:24.000\n as like a branching tree of possibilities where each possible path that you could take\n\n1:28:24.000 --> 1:28:30.960\n through, you know, the space has a complex number attached to it called an amplitude, okay? And now\n\n1:28:30.960 --> 1:28:36.080\n the rule is, you know, when you make a measurement at the end, well, you see a random answer,\n\n1:28:36.080 --> 1:28:40.720\n okay? But quantum mechanics is all about calculating the probability that you're\n\n1:28:40.720 --> 1:28:47.120\n going to see one potential answer versus another one, right? And the rule for calculating the\n\n1:28:47.120 --> 1:28:53.120\n probability that you'll see some answer is that you have to add up the amplitudes for all of the\n\n1:28:53.120 --> 1:28:58.560\n paths that could have led to that answer. And then, you know, that's a complex number, so that,\n\n1:28:58.560 --> 1:29:04.400\n you know, how could that be a probability? Then you take the squared absolute value of the result.\n\n1:29:04.400 --> 1:29:10.800\n That gives you a number between zero and one, okay? So yeah, I just summarized quantum mechanics\n\n1:29:10.800 --> 1:29:17.920\n in like 30 seconds, okay? But now, you know, what this already tells us is that anything I can do\n\n1:29:17.920 --> 1:29:23.840\n with a quantum computer, I could simulate with a classical computer if I only have exponentially\n\n1:29:23.840 --> 1:29:30.480\n more time, okay? And why is that? Because if I have exponential time, I could just write down this\n\n1:29:30.480 --> 1:29:36.960\n entire branching tree and just explicitly calculate each of these amplitudes, right? You know, that\n\n1:29:36.960 --> 1:29:42.560\n will be very inefficient, but it will work, right? It's enough to show that quantum computers could\n\n1:29:42.560 --> 1:29:47.600\n not solve the halting problem or, you know, they could never do anything that is literally\n\n1:29:47.600 --> 1:29:54.400\n uncomputable in Turing's sense, okay? But now, as I said, there's even a stronger result which says\n\n1:29:54.400 --> 1:30:02.400\n that BQP is contained in PSPACE. The way that we prove that is that we say, if all I want is to\n\n1:30:02.400 --> 1:30:08.240\n calculate the probability of some particular output happening, you know, which is all I need to\n\n1:30:08.240 --> 1:30:13.520\n simulate a quantum computer, really, then I don't need to write down the entire quantum state,\n\n1:30:13.520 --> 1:30:20.400\n which is an exponentially large object. All I need to do is just calculate what is the amplitude for\n\n1:30:20.400 --> 1:30:27.840\n that final state. And to do that, I just have to sum up all the amplitudes that lead to that state.\n\n1:30:27.840 --> 1:30:34.240\n Okay, so that's an exponentially large sum, but I can calculate it just reusing the same memory over\n\n1:30:34.240 --> 1:30:38.800\n and over for each term in the sum. And hence the p, in the PSPACE? Hence the PSPACE. Yeah.\n\n1:30:39.600 --> 1:30:46.000\n So what, out of that whole complexity zoo, and it could be BQP, what do you find is the most,\n\n1:30:46.000 --> 1:30:53.680\n the class that captured your heart the most, the most beautiful class that's just, yeah.\n\n1:30:53.680 --> 1:31:03.680\n I used, as my email address, bqpqpoly at gmail.com. Yes, because BQP slash Qpoly,\n\n1:31:03.680 --> 1:31:06.240\n well, you know, amazingly no one had taken it.\n\n1:31:06.240 --> 1:31:07.760\n Amazing, amazing.\n\n1:31:07.760 --> 1:31:12.400\n But, you know, this is a class that I was involved in sort of defining,\n\n1:31:12.400 --> 1:31:18.240\n proving the first theorems about in 2003 or so. So it was kind of close to my heart.\n\n1:31:18.240 --> 1:31:24.480\n But this is like, if we extended BQP, which is the class of everything we can do efficiently\n\n1:31:24.480 --> 1:31:31.280\n with a quantum computer, to allow quantum advice, which means imagine that you had some\n\n1:31:31.280 --> 1:31:36.640\n special initial state, okay, that could somehow help you do computation. And maybe\n\n1:31:36.640 --> 1:31:43.040\n such a state would be exponentially hard to prepare, okay, but maybe somehow these states\n\n1:31:43.040 --> 1:31:46.880\n were formed in the Big Bang or something, and they've just been sitting around ever since,\n\n1:31:46.880 --> 1:31:53.040\n right? If you found one, and if this state could be like ultra power, there are no limits on how\n\n1:31:53.040 --> 1:31:58.880\n powerful it could be, except that this state doesn't know in advance which input you've got,\n\n1:31:58.880 --> 1:32:05.040\n right? It only knows the size of your input. You know, and that's BQP slash Qpoly. So that's\n\n1:32:05.040 --> 1:32:11.200\n one that I just personally happen to love, okay? But, you know, if you're asking like what's the,\n\n1:32:11.200 --> 1:32:18.960\n you know, there's a class that I think is way more beautiful or fundamental than a lot of people\n\n1:32:18.960 --> 1:32:26.720\n even within this field realize that it is. That class is called SZK, or Statistical Zero Knowledge.\n\n1:32:28.080 --> 1:32:32.880\n And, you know, there's a very, very easy way to define this class, which is to say, suppose that\n\n1:32:32.880 --> 1:32:39.280\n I have two algorithms that each sample from probability distributions, right? So each one\n\n1:32:39.280 --> 1:32:45.680\n just outputs random samples according to, you know, possibly different distributions. And now\n\n1:32:45.680 --> 1:32:50.800\n the question I ask is, you know, let's say distributions over strings of n bits, you know,\n\n1:32:50.800 --> 1:32:57.680\n so over an exponentially large space. Now I ask, are these two distributions close or far as\n\n1:32:57.680 --> 1:33:04.000\n close or far as probability distributions? Okay. Any problem that can be reduced to that,\n\n1:33:04.000 --> 1:33:10.320\n you know, that can be put into that form is an SZK problem. And the way that this class was\n\n1:33:10.320 --> 1:33:15.040\n originally discovered was completely different from that and was kind of more complicated. It\n\n1:33:15.040 --> 1:33:21.280\n was discovered as the class of all of the problems that have a certain kind of what's called zero\n\n1:33:21.280 --> 1:33:27.920\n knowledge proof. Zero knowledge proofs are one of the central ideas in cryptography. You know,\n\n1:33:27.920 --> 1:33:33.200\n Shafi Goldwasser and Silvio McCauley won the Turing Award for, you know, inventing them.\n\n1:33:33.200 --> 1:33:38.960\n And they're at the core of even some cryptocurrencies that, you know, people use\n\n1:33:38.960 --> 1:33:45.840\n nowadays. But zero knowledge proofs are ways of proving to someone that something is true,\n\n1:33:45.840 --> 1:33:53.440\n like, you know, that there is a solution to this, you know, optimization problem or that these two\n\n1:33:53.440 --> 1:33:59.440\n graphs are isomorphic to each other or something, but without revealing why it's true, without\n\n1:33:59.440 --> 1:34:06.720\n revealing anything about why it's true. Okay. SZK is all of the problems for which there is such a\n\n1:34:06.720 --> 1:34:13.680\n proof that doesn't rely on any cryptography. Okay. And if you wonder, like, how could such a thing\n\n1:34:13.680 --> 1:34:20.560\n possibly exist, right? Well, like, imagine that I had two graphs and I wanted to convince you\n\n1:34:20.560 --> 1:34:26.080\n that these two graphs are not isomorphic, meaning, you know, I cannot permute one of them so that\n\n1:34:26.080 --> 1:34:30.720\n it's the same as the other one, right? You know, that might be a very hard statement to prove,\n\n1:34:30.720 --> 1:34:35.280\n right? I might need, you know, you might have to do a very exhaustive enumeration of, you know,\n\n1:34:35.280 --> 1:34:40.000\n all the different permutations before you were convinced that it was true. But what if there were\n\n1:34:40.000 --> 1:34:45.920\n some all knowing wizard that said to you, look, I'll tell you what, just pick one of the graphs\n\n1:34:45.920 --> 1:34:52.320\n randomly, then randomly permute it, then send it to me and I will tell you which graph you started\n\n1:34:52.320 --> 1:35:02.720\n with. Okay. And I will do that every single time. Right. And let's say that that wizard did that a\n\n1:35:02.720 --> 1:35:08.240\n hundred times and it was right every time. Yeah. Right. Now, if the graphs were isomorphic, then,\n\n1:35:08.240 --> 1:35:13.120\n you know, it would have been flipping a coin each time, right? It would have had only a one and two\n\n1:35:13.120 --> 1:35:18.800\n to the 100 power chance of, you know, of guessing right each time. But, you know, so, so if it's\n\n1:35:18.800 --> 1:35:24.240\n right every time, then now you're statistically convinced that these graphs are not isomorphic,\n\n1:35:24.240 --> 1:35:28.720\n even though you've learned nothing new about why they aren't. So fascinating. So yeah. So,\n\n1:35:28.720 --> 1:35:35.040\n so SDK is all of the problems that have protocols like that one, but it has this beautiful other\n\n1:35:35.040 --> 1:35:40.160\n characterization. It's shown up again and again in my, in my own work and, you know, a lot of\n\n1:35:40.160 --> 1:35:45.200\n people's work. And I think that it really is one of the most fundamental classes. It's just that\n\n1:35:45.200 --> 1:35:49.920\n people didn't realize that when it was first discovered. So we're living in the middle of\n\n1:35:49.920 --> 1:35:56.720\n a pandemic currently. Yeah. How has your life been changed or no better to ask, like, how has your\n\n1:35:56.720 --> 1:36:03.360\n perspective of the world change with this world changing event of a pandemic overtaking the entire\n\n1:36:03.360 --> 1:36:08.240\n world? Yeah. Well, I mean, I mean, all of our lives have changed, you know, like, I guess,\n\n1:36:08.800 --> 1:36:13.760\n as with no other event since I was born, you know, you would have to go back to world war II\n\n1:36:13.760 --> 1:36:18.720\n for something, I think of this magnitude, you know, on, you know, the way that we live our lives\n\n1:36:19.280 --> 1:36:26.240\n as for how it has changed my worldview. I think that the, the failure of institutions,\n\n1:36:26.240 --> 1:36:32.720\n you know, like, like, like the CDC, like, you know, other institutions that we sort of thought\n\n1:36:32.720 --> 1:36:40.160\n were, were trustworthy, like a lot of the media was staggering, was, was absolutely breathtaking.\n\n1:36:40.720 --> 1:36:46.960\n It is something that I would not have predicted. Right. I think I, I wrote on my blog that, you\n\n1:36:46.960 --> 1:36:53.680\n know, the, you know, it's, it's, it's fascinating to like rewatch the movie Contagion from a decade\n\n1:36:53.680 --> 1:37:00.880\n ago, right. That correctly foresaw so many aspects of, you know, what was going on, you know, an\n\n1:37:00.880 --> 1:37:06.800\n airborne, you know, virus originates in China, spreads to, you know, much of the world, you know,\n\n1:37:06.800 --> 1:37:12.800\n shuts everything down until a vaccine can be developed. You know, everyone has to stay at home,\n\n1:37:12.800 --> 1:37:18.480\n you know, you know, it gets, you know, an enormous number of things, right. Okay. But the one thing\n\n1:37:18.480 --> 1:37:23.600\n that they could not imagine, you know, is that like in this movie, everyone from the government\n\n1:37:23.600 --> 1:37:30.320\n is like hyper competent, hyper, you know, dedicated to the public good, right. And you\n\n1:37:30.320 --> 1:37:33.680\n know, yeah, they're the, they're the best of the best, you know, they could, you know, and, and\n\n1:37:33.680 --> 1:37:39.760\n there are these conspiracy theorists, right. Who think, you know, you know, this is all fake news.\n\n1:37:39.760 --> 1:37:44.400\n There's no, there's not really a pandemic. And those are some random people on the internet who\n\n1:37:44.400 --> 1:37:49.680\n the hyper competent government people have to, you know, oppose, right. They, you know, in, in trying\n\n1:37:49.680 --> 1:37:55.040\n to envision the worst thing that could happen, like, you know, the, the, there was a failure of\n\n1:37:55.040 --> 1:38:01.440\n imagination. The movie makers did not imagine that the conspiracy theorists and the, you know,\n\n1:38:01.440 --> 1:38:07.200\n and the incompetence and the nutcases would have captured our institutions and be the ones actually\n\n1:38:07.200 --> 1:38:13.520\n running things. So you had a certain, I love competence in all walks of life. I love, I get\n\n1:38:13.520 --> 1:38:19.280\n so much energy. I'm so excited by people who do amazing job. And I like you, or maybe you can\n\n1:38:19.280 --> 1:38:24.240\n clarify, but I had maybe not intuition, but I hope that government at its best could be ultra\n\n1:38:24.240 --> 1:38:31.200\n competent. What, first of all, two questions, like how do you explain the lack of confidence\n\n1:38:31.200 --> 1:38:36.160\n and the other, maybe on the positive side, how can we build a more competent government?\n\n1:38:36.960 --> 1:38:41.680\n Well, there's an election in two months. I mean, you have a faith that the election,\n\n1:38:41.680 --> 1:38:45.920\n I, you know, it's not going to fix everything, but you know, it's like,\n\n1:38:45.920 --> 1:38:49.760\n I feel like there is a ship that is sinking and you could at least stop the sinking.\n\n1:38:49.760 --> 1:38:55.200\n But, you know, I think that there are much, much deeper problems. I mean, I think that,\n\n1:38:56.960 --> 1:39:03.520\n you know, it is plausible to me that, you know, a lot of the failures, you know, with the CDC,\n\n1:39:03.520 --> 1:39:09.840\n with some of the other health agencies, even, you know, predate Trump, you know, predate the,\n\n1:39:09.840 --> 1:39:16.400\n you know, right wing populism that has sort of taken over much of the world now. And, you know,\n\n1:39:16.400 --> 1:39:23.760\n I think that, you know, it is, you know, it is very, I'm actually, you know, I've actually been\n\n1:39:23.760 --> 1:39:31.360\n strongly in favor of, you know, rushing vaccines of, you know, I thought that we could have done,\n\n1:39:31.360 --> 1:39:36.880\n you know, human challenge trials, you know, which were not done, right? We could have, you know,\n\n1:39:36.880 --> 1:39:44.480\n like had, you know, volunteers, you know, to actually, you know, be, you know, get vaccines,\n\n1:39:44.480 --> 1:39:49.680\n get, you know, exposed to COVID. So innovative ways of accelerating what we've done previously\n\n1:39:49.680 --> 1:39:56.000\n over a long time. I thought that, you know, each month that a vaccine is closer is like trillions\n\n1:39:56.000 --> 1:40:01.120\n of dollars. Are you surprised? And of course, lives, you know, at least, you know, hundreds\n\n1:40:01.120 --> 1:40:05.680\n of thousands of lives. Are you surprised that it's taking this long? We still don't have a plan.\n\n1:40:05.680 --> 1:40:11.840\n There's still not a feeling like anyone is actually doing anything in terms of alleviating,\n\n1:40:11.840 --> 1:40:16.080\n like any kind of plan. So there's a bunch of stuff, there's vaccine, but you could also do\n\n1:40:16.080 --> 1:40:21.200\n a testing infrastructure where everybody's tested nonstop with contact tracing, all that kind of.\n\n1:40:21.200 --> 1:40:27.520\n Well, I mean, I'm as surprised as almost everyone else. I mean, this is a historic failure. It is\n\n1:40:27.520 --> 1:40:33.360\n one of the biggest failures in the 240 year history of the United States, right? And we should\n\n1:40:33.360 --> 1:40:38.960\n be, you know, crystal clear about that. And, you know, one thing that I think has been missing,\n\n1:40:38.960 --> 1:40:45.840\n you know, even from the more competent side is like, you know, is sort of the World War II\n\n1:40:45.840 --> 1:40:52.960\n mentality, right? The, you know, the mentality of, you know, let's just, you know, you know,\n\n1:40:52.960 --> 1:40:59.920\n if we can, by breaking a whole bunch of rules, you know, get a vaccine and, you know, and even\n\n1:40:59.920 --> 1:41:07.200\n half the amount of time as we thought, then let's just do that because, you know, like we have to\n\n1:41:07.200 --> 1:41:13.520\n weigh all of the moral qualms that we have about doing that against the moral qualms of not doing.\n\n1:41:13.520 --> 1:41:18.880\n And one key little aspect to that that's deeply important to me, and we'll go into that topic\n\n1:41:18.880 --> 1:41:24.320\n next, is the World War II mentality wasn't just about, you know, breaking all the rules to get\n\n1:41:24.320 --> 1:41:31.600\n the job done. There was a togetherness to it. So I would, if I were president right now, it seems\n\n1:41:31.600 --> 1:41:39.440\n quite elementary to unite the country because we're facing a crisis. It's easy to make the\n\n1:41:39.440 --> 1:41:46.240\n virus the enemy. And it's very surprising to me that the division has increased as opposed to\n\n1:41:46.240 --> 1:41:51.360\n decrease. That's heartbreaking. Yeah. Well, look, I mean, it's been said by others that this is the\n\n1:41:51.360 --> 1:41:57.200\n first time in the country's history that we have a president who does not even pretend to, you know,\n\n1:41:57.200 --> 1:42:06.080\n want to unite the country. I mean, Lincoln, who fought a civil war, said he wanted to unite the\n\n1:42:06.080 --> 1:42:15.120\n country. And I do worry enormously about what happens if the results of this election are\n\n1:42:15.120 --> 1:42:22.320\n contested. And will there be violence as a result of that? And will we have a clear path of succession?\n\n1:42:22.320 --> 1:42:27.120\n And, you know, look, I mean, you know, this is all we're going to find out the answers to this in\n\n1:42:27.120 --> 1:42:31.840\n two months. And if none of that happens, maybe I'll look foolish. But I am willing to go on the\n\n1:42:31.840 --> 1:42:37.040\n record and say, I am terrified about that. Yeah, I've been reading The Rise and Fall of the Third\n\n1:42:37.040 --> 1:42:46.160\n Reich. So if I can, this is like one little voice just to put out there that I think November will\n\n1:42:46.160 --> 1:42:55.680\n be a really critical month for people to breathe and put love out there. Do not, you know, anger in\n\n1:42:55.680 --> 1:43:01.360\n those in that context, no matter who wins, no matter what is said, will destroy our country,\n\n1:43:01.360 --> 1:43:05.760\n may destroy our country, may destroy the world because of the power of the country. So it's\n\n1:43:05.760 --> 1:43:11.600\n really important to be patient, loving, empathetic. Like one of the things that troubles me is that\n\n1:43:11.600 --> 1:43:17.920\n even people on the left are unable to have a love and respect for people who voted for Trump. They\n\n1:43:17.920 --> 1:43:23.600\n can't imagine that there's good people that could vote for the opposite side. Oh, I know there are\n\n1:43:23.600 --> 1:43:29.040\n because I know some of them, right? I mean, you know, it's still, you know, maybe it baffles me,\n\n1:43:29.040 --> 1:43:34.240\n but, you know, I know such people. Let me ask you this. It's also heartbreaking to me\n\n1:43:34.800 --> 1:43:39.120\n on the topic of cancel culture. So in the machine learning community, I've seen it a little bit\n\n1:43:39.120 --> 1:43:46.800\n that there's aggressive attacking of people who are trying to have a nuanced conversation about\n\n1:43:46.800 --> 1:43:55.360\n things. And it's troubling because it feels like nuanced conversation is the only way to talk about\n\n1:43:55.360 --> 1:44:02.320\n difficult topics. And when there's a thought police and speech police on any nuanced conversation\n\n1:44:02.320 --> 1:44:09.280\n that everybody has to like in a animal farm chant that racism is bad and sexism is bad, which is\n\n1:44:09.280 --> 1:44:15.440\n things that everybody believes and they can't possibly say anything nuanced. It feels like it\n\n1:44:15.440 --> 1:44:20.560\n goes against any kind of progress from my kind of shallow perspective. But you've written a little\n\n1:44:20.560 --> 1:44:28.000\n bit about cancel culture. Do you have thoughts there? Well, I mean, to say that I am opposed to,\n\n1:44:28.000 --> 1:44:35.040\n you know, this trend of cancellations or of shouting people down rather than engaging them,\n\n1:44:35.040 --> 1:44:40.640\n that would be a massive understatement, right? And I feel like, you know, I have put my money\n\n1:44:40.640 --> 1:44:46.160\n where my mouth is, you know, not as much as some people have, but, you know, I've tried to do\n\n1:44:46.160 --> 1:44:52.960\n something. I mean, I have defended, you know, some unpopular people and unpopular, you know, ideas\n\n1:44:52.960 --> 1:45:02.160\n on my blog. I've, you know, tried to defend, you know, norms of open discourse, of, you know,\n\n1:45:02.160 --> 1:45:07.760\n reasoning with our opponents, even when I've been shouted down for that on social media,\n\n1:45:07.760 --> 1:45:11.840\n you know, called a racist, called a sexist, all of those things. And which, by the way,\n\n1:45:11.840 --> 1:45:17.680\n I should say, you know, I would be perfectly happy to, you know, if we had time to say, you know,\n\n1:45:17.680 --> 1:45:25.600\n you know, 10,000 times, you know, my hatred of racism, of sexism, of homophobia, right?\n\n1:45:25.600 --> 1:45:33.600\n But what I don't want to do is to cede to some particular political faction the right to define\n\n1:45:33.600 --> 1:45:39.360\n exactly what is meant by those terms to say, well, then you have to agree with all of these other\n\n1:45:39.360 --> 1:45:46.000\n extremely contentious positions or else you are a misogynist or else you are a racist, right?\n\n1:45:46.000 --> 1:45:54.240\n I say that, well, no, you know, don't I or, you know, don't people like me also get a say in the\n\n1:45:54.240 --> 1:46:00.080\n discussion about, you know, what is racism, about what is going to be the most effective to combat\n\n1:46:00.080 --> 1:46:08.480\n racism, right? And, you know, this cancellation mentality, I think, is spectacularly ineffective\n\n1:46:08.480 --> 1:46:13.200\n at its own professed gall of, you know, combating racism and sexism.\n\n1:46:13.200 --> 1:46:19.440\n What's a positive way out? So I, I try to, I don't know if you see what I do on Twitter,\n\n1:46:19.440 --> 1:46:25.680\n but I, on Twitter, I mostly, in my whole, in my life, I've actually, it's who I am to the core is\n\n1:46:25.680 --> 1:46:31.440\n like, I really focus on the positive and I try to put love out there in the world. And still,\n\n1:46:32.720 --> 1:46:36.720\n I get attacked. And I look at that and I wonder like,\n\n1:46:36.720 --> 1:46:38.240\n You too? I didn't know.\n\n1:46:38.240 --> 1:46:43.920\n Like, I haven't actually said anything difficult and nuanced. You talk about somebody like\n\n1:46:43.920 --> 1:46:50.960\n Steven Pinker, who I'm actually don't know the full range of things that he's attacked for,\n\n1:46:50.960 --> 1:46:55.440\n but he tries to say difficult. He tries to be thoughtful about difficult topics.\n\n1:46:55.440 --> 1:46:55.840\n He does.\n\n1:46:55.840 --> 1:46:59.920\n And obviously he just gets slaughtered by.\n\n1:46:59.920 --> 1:47:06.400\n Well, I mean, yes, but it's also amazing how well Steve has withstood it. I mean,\n\n1:47:06.400 --> 1:47:10.880\n he just survived that attempt to cancel him just a couple of months ago, right?\n\n1:47:10.880 --> 1:47:15.360\n Psychologically, he survives it too, which worries me because I don't think I can.\n\n1:47:15.360 --> 1:47:19.920\n Yeah, I've gotten to know Steve a bit. He is incredibly unperturbed by this stuff.\n\n1:47:20.960 --> 1:47:26.320\n And I admire that and I envy it. I wish that I could be like that. I mean, my impulse when I'm\n\n1:47:26.320 --> 1:47:32.960\n getting attacked is I just want to engage every single like anonymous person on Twitter and Reddit\n\n1:47:32.960 --> 1:47:37.760\n who is saying mean stuff about me. And I want to just say, well, look, can we just talk this over\n\n1:47:37.760 --> 1:47:43.280\n for an hour? And then you'll see that I'm not that bad. And sometimes that even works. The\n\n1:47:43.280 --> 1:47:46.080\n problem is then there's the 20,000 other ones.\n\n1:47:48.080 --> 1:47:50.640\n That's not, but psychologically, does that wear on you?\n\n1:47:51.440 --> 1:47:56.080\n It does. It does. But yeah, I mean, in terms of what is the solution, I mean, I wish I knew,\n\n1:47:56.080 --> 1:48:02.240\n right? And so in a certain way, these problems are maybe harder than P versus NP, right?\n\n1:48:02.240 --> 1:48:10.560\n I mean, but I think that part of it has to be that I think that there's a lot of sort of silent\n\n1:48:10.560 --> 1:48:17.360\n support for what I'll call the open discourse side, the reasonable enlightenment side.\n\n1:48:17.360 --> 1:48:23.120\n And I think that that support has to become less silent, right? I think that a lot of people\n\n1:48:23.120 --> 1:48:30.560\n just sort of agree that a lot of these cancellations and attacks are ridiculous,\n\n1:48:30.560 --> 1:48:36.000\n but are just afraid to say so, right? Or else they'll get shouted down as well, right? That's\n\n1:48:36.000 --> 1:48:42.560\n just the standard witch hunt dynamic, which, of course, this faction understands and exploits to\n\n1:48:42.560 --> 1:48:52.880\n its great advantage. But more people just said, we're not going to stand for this, right? This\n\n1:48:52.880 --> 1:49:01.440\n is, guess what? We're against racism too. But what you're doing is ridiculous, right? And the\n\n1:49:01.440 --> 1:49:07.120\n hard part is it takes a lot of mental energy. It takes a lot of time. Even if you feel like\n\n1:49:07.120 --> 1:49:12.560\n you're not going to be canceled or you're staying on the safe side, it takes a lot of time to\n\n1:49:13.840 --> 1:49:19.200\n phrase things in exactly the right way and to respond to everything people say.\n\n1:49:19.200 --> 1:49:29.520\n So, but I think that the more people speak up from all political persuasions, from all walks\n\n1:49:29.520 --> 1:49:36.800\n of life, then the easier it is to move forward. Since we've been talking about love, can you,\n\n1:49:37.520 --> 1:49:43.520\n last time I talked to you about meaning of life a little bit, but here has, it's a weird question\n\n1:49:43.520 --> 1:49:50.720\n to ask a computer scientist, but has love for other human beings, for things, for the world\n\n1:49:50.720 --> 1:49:59.440\n around you played an important role in your life? Have you, it's easy for a world class\n\n1:49:59.440 --> 1:50:06.160\n computer scientist, you could even call yourself like a physicist, everything to be lost in the\n\n1:50:06.160 --> 1:50:11.040\n books. Is the connection to other humans, love for other humans played an important role?\n\n1:50:11.040 --> 1:50:24.880\n I love my kids. I love my wife. I love my parents. I'm probably not different from most people in\n\n1:50:24.880 --> 1:50:32.880\n loving their families and in that being very important in my life. Now, I should remind you\n\n1:50:32.880 --> 1:50:38.880\n that I am a theoretical computer scientist. If you're looking for deep insight about the nature\n\n1:50:38.880 --> 1:50:45.920\n of love, you're probably looking in the wrong place to ask me, but sure, it's been important.\n\n1:50:45.920 --> 1:50:53.200\n But is there something from a computer science perspective to be said about love? Is that even\n\n1:50:53.200 --> 1:50:59.840\n beyond into the realm of consciousness? There was this great cartoon, I think it\n\n1:50:59.840 --> 1:51:07.520\n was one of the classic XKCDs where it shows a heart and it's squaring the heart, taking the\n\n1:51:07.520 --> 1:51:15.680\n four year transform of the heart, integrating the heart, each thing and then it says my normal\n\n1:51:15.680 --> 1:51:21.760\n approach is useless here. I'm so glad I asked this question. I think there's no better way to\n\n1:51:22.560 --> 1:51:26.960\n end this. I hope we get a chance to talk again. This has been an amazing, cool experiment to do\n\n1:51:26.960 --> 1:51:31.040\n it outside. I'm really glad you made it out. Yeah. Well, I appreciate it a lot. It's been a\n\n1:51:31.040 --> 1:51:36.640\n pleasure and I'm glad you were able to come out to Austin. Thanks. Thanks for listening to this\n\n1:51:36.640 --> 1:51:44.480\n conversation with Scott Aaronson. And thank you to our sponsors, 8sleep, SimpliSafe, ExpressVPN,\n\n1:51:44.480 --> 1:51:50.160\n and BetterHelp. Please check out these sponsors in the description to get a discount and to\n\n1:51:50.160 --> 1:51:56.000\n support this podcast. If you enjoy this thing, subscribe on YouTube, review it with five stars\n\n1:51:56.000 --> 1:52:01.680\n on Apple Podcast, follow on Spotify, support on Patreon, or connect with me on Twitter\n\n1:52:01.680 --> 1:52:07.840\n at Lex Friedman. And now let me leave you with some words from Scott Aaronson that I also gave\n\n1:52:07.840 --> 1:52:14.240\n to you in the introduction, which is, if you always win, then you're probably doing something\n\n1:52:14.240 --> 1:52:21.120\n wrong. Thank you for listening and for putting up with the intro and outro in this strange room in\n\n1:52:21.120 --> 1:52:36.320\n the middle of nowhere. And I very much hope to see you next time in many more ways than one.\n\n"
}
{
  "title": "Risto Miikkulainen: Neuroevolution and Evolutionary Computation | Lex Fridman Podcast #177",
  "id": "CY_LEa9xQtg",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:02.860\n The following is a conversation with Risto Michaelainen,\n\n00:02.860 --> 00:05.980\n a computer scientist at University of Texas at Austin\n\n00:05.980 --> 00:07.860\n and Associate Vice President\n\n00:07.860 --> 00:11.460\n of Evolutionary Artificial Intelligence at Cognizant.\n\n00:11.460 --> 00:14.420\n He specializes in evolutionary computation,\n\n00:14.420 --> 00:17.620\n but also many other topics in artificial intelligence,\n\n00:17.620 --> 00:19.900\n cognitive science, and neuroscience.\n\n00:19.900 --> 00:21.900\n Quick mention of our sponsors,\n\n00:21.900 --> 00:26.600\n Jordan Harbin's show, Grammarly, Belcampo, and Indeed.\n\n00:26.600 --> 00:30.580\n Check them out in the description to support this podcast.\n\n00:30.580 --> 00:34.140\n As a side note, let me say that nature inspired algorithms\n\n00:34.140 --> 00:36.820\n from ant colony optimization to genetic algorithms\n\n00:36.820 --> 00:39.580\n to cellular automata to neural networks\n\n00:39.580 --> 00:41.900\n have always captivated my imagination,\n\n00:41.900 --> 00:43.940\n not only for their surprising power\n\n00:43.940 --> 00:45.580\n in the face of long odds,\n\n00:45.580 --> 00:47.780\n but because they always opened up doors\n\n00:47.780 --> 00:50.700\n to new ways of thinking about computation.\n\n00:50.700 --> 00:54.180\n It does seem that in the long arc of computing history,\n\n00:54.180 --> 00:57.560\n running toward biology, not running away from it\n\n00:57.560 --> 01:00.420\n is what leads to long term progress.\n\n01:00.420 --> 01:03.220\n This is the Lex Friedman podcast,\n\n01:03.220 --> 01:06.760\n and here is my conversation with Risto Michaelainen.\n\n01:07.720 --> 01:10.200\n If we ran the Earth experiment,\n\n01:10.200 --> 01:12.500\n this fun little experiment we're on,\n\n01:12.500 --> 01:15.220\n over and over and over and over a million times\n\n01:15.220 --> 01:19.180\n and watch the evolution of life as it pans out,\n\n01:19.180 --> 01:21.940\n how much variation in the outcomes of that evolution\n\n01:21.940 --> 01:23.180\n do you think we would see?\n\n01:23.180 --> 01:27.380\n Now, we should say that you are a computer scientist.\n\n01:27.380 --> 01:29.380\n That's actually not such a bad question\n\n01:29.380 --> 01:30.380\n for a computer scientist,\n\n01:30.380 --> 01:34.020\n because we are building simulations of these things,\n\n01:34.020 --> 01:36.220\n and we are simulating evolution,\n\n01:36.220 --> 01:38.460\n and that's a difficult question to answer in biology,\n\n01:38.460 --> 01:40.700\n but we can build a computational model\n\n01:40.700 --> 01:43.540\n and run it million times and actually answer that question.\n\n01:43.540 --> 01:47.000\n How much variation do we see when we simulate it?\n\n01:47.000 --> 01:50.620\n And that's a little bit beyond what we can do today,\n\n01:50.620 --> 01:54.140\n but I think that we will see some regularities,\n\n01:54.140 --> 01:56.540\n and it took evolution also a really long time\n\n01:56.540 --> 01:57.720\n to get started,\n\n01:57.720 --> 02:02.180\n and then things accelerated really fast towards the end.\n\n02:02.180 --> 02:04.220\n But there are things that need to be discovered,\n\n02:04.220 --> 02:06.460\n and they probably will be over and over again,\n\n02:06.460 --> 02:10.060\n like manipulation of objects,\n\n02:10.060 --> 02:11.140\n opposable thumbs,\n\n02:11.140 --> 02:16.020\n and also some way to communicate,\n\n02:16.020 --> 02:18.220\n maybe orally, like when you have speech,\n\n02:18.220 --> 02:20.820\n it might be some other kind of sounds,\n\n02:20.820 --> 02:24.060\n and decision making, but also vision.\n\n02:24.060 --> 02:26.220\n Eye has evolved many times.\n\n02:26.220 --> 02:28.180\n Various vision systems have evolved.\n\n02:28.180 --> 02:30.740\n So we would see those kinds of solutions,\n\n02:30.740 --> 02:32.900\n I believe, emerge over and over again.\n\n02:32.900 --> 02:34.260\n They may look a little different,\n\n02:34.260 --> 02:36.300\n but they get the job done.\n\n02:36.300 --> 02:37.500\n The really interesting question is,\n\n02:37.500 --> 02:38.980\n would we have primates?\n\n02:38.980 --> 02:43.620\n Would we have humans or something that resembles humans?\n\n02:43.620 --> 02:47.020\n And would that be an apex of evolution after a while?\n\n02:47.020 --> 02:48.460\n We don't know where we're going from here,\n\n02:48.460 --> 02:51.300\n but we certainly see a lot of tool use\n\n02:51.300 --> 02:54.060\n and building, constructing our environment.\n\n02:54.060 --> 02:56.380\n So I think that we will get that.\n\n02:56.380 --> 02:58.740\n We get some evolution producing,\n\n02:58.740 --> 03:00.860\n some agents that can do that,\n\n03:00.860 --> 03:02.540\n manipulate the environment and build.\n\n03:02.540 --> 03:04.140\n What do you think is special about humans?\n\n03:04.140 --> 03:06.100\n Like if you were running the simulation\n\n03:06.100 --> 03:08.700\n and you observe humans emerge,\n\n03:08.700 --> 03:09.780\n like these tool makers,\n\n03:09.780 --> 03:11.060\n they start a fire and all this stuff,\n\n03:11.060 --> 03:12.620\n start running around, building buildings,\n\n03:12.620 --> 03:15.600\n and then running for president and all those kinds of things.\n\n03:15.600 --> 03:19.180\n What would be, how would you detect that?\n\n03:19.180 --> 03:20.380\n Cause you're like really busy\n\n03:20.380 --> 03:23.180\n as the creator of this evolutionary system.\n\n03:23.180 --> 03:25.700\n So you don't have much time to observe,\n\n03:25.700 --> 03:28.940\n like detect if any cool stuff came up, right?\n\n03:28.940 --> 03:31.260\n How would you detect humans?\n\n03:31.260 --> 03:33.300\n Well, you are running the simulation.\n\n03:33.300 --> 03:37.480\n So you also put in visualization\n\n03:37.480 --> 03:39.660\n and measurement techniques there.\n\n03:39.660 --> 03:44.660\n So if you are looking for certain things like communication,\n\n03:44.660 --> 03:48.020\n you'll have detectors to find out whether that's happening,\n\n03:48.020 --> 03:50.140\n even if it's a large simulation.\n\n03:50.140 --> 03:53.520\n And I think that that's what we would do.\n\n03:53.520 --> 03:56.380\n We know roughly what we want,\n\n03:56.380 --> 04:01.200\n intelligent agents that communicate, cooperate, manipulate,\n\n04:01.200 --> 04:03.180\n and we would build detections\n\n04:03.180 --> 04:05.580\n and visualizations of those processes.\n\n04:05.580 --> 04:08.060\n Yeah, and there's a lot of,\n\n04:08.060 --> 04:09.540\n we'd have to run it many times\n\n04:09.540 --> 04:11.940\n and we have plenty of time to figure out\n\n04:11.940 --> 04:13.540\n how we detect the interesting things.\n\n04:13.540 --> 04:16.680\n But also, I think we do have to run it many times\n\n04:16.680 --> 04:21.140\n because we don't quite know what shape those will take\n\n04:21.140 --> 04:23.860\n and our detectors may not be perfect for them\n\n04:23.860 --> 04:24.700\n at the beginning.\n\n04:24.700 --> 04:27.420\n Well, that seems really difficult to build a detector\n\n04:27.420 --> 04:32.420\n of intelligent or intelligent communication.\n\n04:32.740 --> 04:35.720\n Sort of, if we take an alien perspective,\n\n04:35.720 --> 04:39.280\n observing earth, are you sure that they would be able\n\n04:39.280 --> 04:41.340\n to detect humans as the special thing?\n\n04:41.340 --> 04:43.780\n Wouldn't they be already curious about other things?\n\n04:43.780 --> 04:47.060\n There's way more insects by body mass, I think,\n\n04:47.060 --> 04:50.860\n than humans by far, and colonies.\n\n04:50.860 --> 04:53.900\n Obviously, dolphins is the most intelligent creature\n\n04:53.900 --> 04:55.220\n on earth, we all know this.\n\n04:55.220 --> 04:58.380\n So it could be the dolphins that they detect.\n\n04:58.380 --> 05:00.860\n It could be the rockets that we seem to be launching.\n\n05:00.860 --> 05:03.780\n That could be the intelligent creature they detect.\n\n05:03.780 --> 05:06.660\n It could be some other trees.\n\n05:06.660 --> 05:07.960\n Trees have been here a long time.\n\n05:07.960 --> 05:10.580\n I just learned that sharks have been here\n\n05:10.580 --> 05:13.260\n 400 million years and that's longer\n\n05:13.260 --> 05:15.020\n than trees have been here.\n\n05:15.020 --> 05:17.420\n So maybe it's the sharks, they go by age.\n\n05:17.420 --> 05:19.020\n Like there's a persistent thing.\n\n05:19.020 --> 05:20.820\n Like if you survive long enough,\n\n05:20.820 --> 05:22.380\n especially through the mass extinctions,\n\n05:22.380 --> 05:25.420\n that could be the thing your detector is detecting.\n\n05:25.420 --> 05:27.900\n Humans have been here for a very short time\n\n05:27.900 --> 05:30.660\n and we're just creating a lot of pollution,\n\n05:30.660 --> 05:31.940\n but so is the other creatures.\n\n05:31.940 --> 05:34.700\n So I don't know, do you think you'd be able\n\n05:34.700 --> 05:35.740\n to detect humans?\n\n05:35.740 --> 05:37.700\n Like how would you go about detecting\n\n05:37.700 --> 05:39.160\n in the computational sense?\n\n05:39.160 --> 05:40.980\n Maybe we can leave humans behind.\n\n05:40.980 --> 05:44.680\n In the computational sense, detect interesting things.\n\n05:46.180 --> 05:48.780\n Do you basically have to have a strict objective function\n\n05:48.780 --> 05:51.860\n by which you measure the performance of a system\n\n05:51.860 --> 05:55.420\n or can you find curiosities and interesting things?\n\n05:55.420 --> 05:59.540\n Yeah, well, I think that the first measurement\n\n05:59.540 --> 06:02.300\n would be to detect how much of an effect\n\n06:02.300 --> 06:03.620\n you can have in your environment.\n\n06:03.620 --> 06:06.940\n So if you look around, we have cities\n\n06:06.940 --> 06:08.820\n and that is constructed environments.\n\n06:08.820 --> 06:11.980\n And that's where a lot of people live, most people live.\n\n06:11.980 --> 06:15.140\n So that would be a good sign of intelligence\n\n06:15.140 --> 06:17.940\n that you don't just live in an environment,\n\n06:17.940 --> 06:20.260\n but you construct it to your liking.\n\n06:20.260 --> 06:21.900\n And that's something pretty unique.\n\n06:21.900 --> 06:24.260\n I mean, there are certainly birds build nests\n\n06:24.260 --> 06:25.520\n but they don't build quite cities.\n\n06:25.520 --> 06:29.100\n Termites build mounds and ice and things like that.\n\n06:29.100 --> 06:32.120\n But the complexity of the human construction cities,\n\n06:32.120 --> 06:34.940\n I think would stand out even to an external observer.\n\n06:34.940 --> 06:36.940\n Of course, that's what a human would say.\n\n06:36.940 --> 06:39.780\n Yeah, and you know, you can certainly say\n\n06:39.780 --> 06:41.820\n that sharks are really smart\n\n06:41.820 --> 06:43.220\n because they've been around so long\n\n06:43.220 --> 06:45.000\n and they haven't destroyed their environment,\n\n06:45.000 --> 06:46.540\n which humans are about to do,\n\n06:46.540 --> 06:48.860\n which is not a very smart thing.\n\n06:48.860 --> 06:52.000\n But we'll get over it, I believe.\n\n06:52.000 --> 06:55.220\n And we can get over it by doing some construction\n\n06:55.220 --> 06:56.780\n that actually is benign\n\n06:56.780 --> 07:01.780\n and maybe even enhances the resilience of nature.\n\n07:02.440 --> 07:05.460\n So you mentioned the simulation that we run over and over\n\n07:05.460 --> 07:08.900\n might start, it's a slow start.\n\n07:08.900 --> 07:12.560\n So do you think how unlikely, first of all,\n\n07:12.560 --> 07:14.140\n I don't know if you think about this kind of stuff,\n\n07:14.140 --> 07:18.140\n but how unlikely is step number zero,\n\n07:18.140 --> 07:20.880\n which is the springing up,\n\n07:20.880 --> 07:22.940\n like the origin of life on earth?\n\n07:22.940 --> 07:27.940\n And second, how unlikely is the,\n\n07:27.940 --> 07:30.460\n anything interesting happening beyond that?\n\n07:30.460 --> 07:34.320\n So like the start that creates\n\n07:34.320 --> 07:36.700\n all the rich complexity that we see on earth today.\n\n07:36.700 --> 07:38.580\n Yeah, there are people who are working\n\n07:38.580 --> 07:42.260\n on exactly that problem from primordial soup.\n\n07:42.260 --> 07:45.820\n How do you actually get self replicating molecules?\n\n07:45.820 --> 07:48.740\n And they are very close.\n\n07:48.740 --> 07:51.900\n With a little bit of help, you can make that happen.\n\n07:51.900 --> 07:55.660\n So of course we know what we want,\n\n07:55.660 --> 07:57.120\n so they can set up the conditions\n\n07:57.120 --> 07:59.760\n and try out conditions that are conducive to that.\n\n08:00.780 --> 08:04.080\n For evolution to discover that, that took a long time.\n\n08:04.080 --> 08:07.660\n For us to recreate it probably won't take that long.\n\n08:07.660 --> 08:09.820\n And the next steps from there,\n\n08:10.860 --> 08:12.860\n I think also with some handholding,\n\n08:12.860 --> 08:14.460\n I think we can make that happen.\n\n08:15.920 --> 08:18.500\n But with evolution, what was really fascinating\n\n08:18.500 --> 08:22.620\n was eventually the runaway evolution of the brain\n\n08:22.620 --> 08:24.420\n that created humans and created,\n\n08:24.420 --> 08:27.220\n well, also other higher animals,\n\n08:27.220 --> 08:29.700\n that that was something that happened really fast.\n\n08:29.700 --> 08:32.380\n And that's a big question.\n\n08:32.380 --> 08:33.700\n Is that something replicable?\n\n08:33.700 --> 08:35.780\n Is that something that can happen?\n\n08:35.780 --> 08:38.300\n And if it happens, does it go in the same direction?\n\n08:39.180 --> 08:40.780\n That is a big question to ask.\n\n08:40.780 --> 08:42.980\n Even in computational terms,\n\n08:42.980 --> 08:47.340\n I think that it's relatively possible to come up here,\n\n08:47.340 --> 08:49.820\n create an experiment where we look at the primordial soup\n\n08:49.820 --> 08:51.260\n and the first couple of steps\n\n08:51.260 --> 08:53.460\n of multicellular organisms even.\n\n08:53.460 --> 08:55.760\n But to get something as complex as the brain,\n\n08:57.380 --> 08:59.660\n we don't quite know the conditions for that.\n\n08:59.660 --> 09:01.420\n And how do you even get started\n\n09:01.420 --> 09:03.420\n and whether we can get this kind of runaway evolution\n\n09:03.420 --> 09:04.260\n happening?\n\n09:05.820 --> 09:09.100\n From a detector perspective,\n\n09:09.100 --> 09:10.780\n if we're observing this evolution,\n\n09:10.780 --> 09:12.360\n what do you think is the brain?\n\n09:12.360 --> 09:15.940\n What do you think is the, let's say, what is intelligence?\n\n09:15.940 --> 09:18.340\n So in terms of the thing that makes humans special,\n\n09:18.340 --> 09:20.060\n we seem to be able to reason,\n\n09:21.060 --> 09:23.500\n we seem to be able to communicate.\n\n09:23.500 --> 09:26.020\n But the core of that is this something\n\n09:26.020 --> 09:29.620\n in the broad category we might call intelligence.\n\n09:29.620 --> 09:33.500\n So if you put your computer scientist hat on,\n\n09:33.500 --> 09:37.540\n is there a favorite ways you like to think about\n\n09:37.540 --> 09:39.800\n that question of what is intelligence?\n\n09:41.300 --> 09:46.300\n Well, my goal is to create agents that are intelligent.\n\n09:48.300 --> 09:49.580\n Not to define what.\n\n09:49.580 --> 09:52.700\n And that is a way of defining it.\n\n09:52.700 --> 09:57.700\n And that means that it's some kind of an object\n\n09:57.700 --> 10:02.700\n or a program that has limited sensory\n\n10:02.980 --> 10:07.980\n and effective capabilities interacting with the world.\n\n10:08.220 --> 10:11.700\n And then also a mechanism for making decisions.\n\n10:11.700 --> 10:15.840\n So with limited abilities like that, can it survive?\n\n10:17.220 --> 10:18.780\n Survival is the simplest goal,\n\n10:18.780 --> 10:20.500\n but you could also give it other goals.\n\n10:20.500 --> 10:21.380\n Can it multiply?\n\n10:21.380 --> 10:24.420\n Can it solve problems that you give it?\n\n10:24.420 --> 10:27.220\n And that is quite a bit less than human intelligence.\n\n10:27.220 --> 10:29.740\n There are, animals would be intelligent, of course,\n\n10:29.740 --> 10:31.100\n with that definition.\n\n10:31.100 --> 10:35.000\n And you might have even some other forms of life, even.\n\n10:35.000 --> 10:40.000\n So intelligence in that sense is a survival skill\n\n10:41.220 --> 10:44.580\n given resources that you have and using your resources\n\n10:44.580 --> 10:46.080\n so that you will stay around.\n\n10:47.860 --> 10:52.860\n Do you think death, mortality is fundamental to an agent?\n\n10:53.020 --> 10:55.060\n So like there's, I don't know if you're familiar,\n\n10:55.060 --> 10:56.860\n there's a philosopher named Ernest Becker\n\n10:56.860 --> 11:01.220\n who wrote The Denial of Death and his whole idea.\n\n11:01.220 --> 11:04.020\n And there's folks, psychologists, cognitive scientists\n\n11:04.020 --> 11:06.600\n that work on terror management theory.\n\n11:06.600 --> 11:10.020\n And they think that one of the special things about humans\n\n11:10.020 --> 11:13.940\n is that we're able to sort of foresee our death, right?\n\n11:13.940 --> 11:16.620\n We can realize not just as animals do,\n\n11:16.620 --> 11:19.420\n sort of constantly fear in an instinctual sense,\n\n11:19.420 --> 11:21.600\n respond to all the dangers that are out there,\n\n11:21.600 --> 11:25.180\n but like understand that this ride ends eventually.\n\n11:25.180 --> 11:29.780\n And that in itself is the force behind\n\n11:29.780 --> 11:32.220\n all of the creative efforts of human nature.\n\n11:32.220 --> 11:33.620\n That's the philosophy.\n\n11:33.620 --> 11:35.260\n I think that makes sense, a lot of sense.\n\n11:35.260 --> 11:38.660\n I mean, animals probably don't think of death the same way,\n\n11:38.660 --> 11:40.660\n but humans know that your time is limited\n\n11:40.660 --> 11:42.060\n and you wanna make it count.\n\n11:43.180 --> 11:44.980\n And you can make it count in many different ways,\n\n11:44.980 --> 11:47.740\n but I think that has a lot to do with creativity\n\n11:47.740 --> 11:50.060\n and the need for humans to do something\n\n11:50.060 --> 11:51.720\n beyond just surviving.\n\n11:51.720 --> 11:54.520\n And now going from that simple definition\n\n11:54.520 --> 11:56.360\n to something that's the next level,\n\n11:56.360 --> 12:00.560\n I think that that could be the second level of definition,\n\n12:00.560 --> 12:03.280\n that intelligence means something,\n\n12:03.280 --> 12:05.200\n that you do something that stays behind you,\n\n12:05.200 --> 12:09.160\n that's more than your existence.\n\n12:09.160 --> 12:12.280\n You create something that is useful for others,\n\n12:12.280 --> 12:15.200\n is useful in the future, not just for yourself.\n\n12:15.200 --> 12:17.800\n And I think that's the nicest definition of intelligence\n\n12:17.800 --> 12:19.880\n within a next level.\n\n12:19.880 --> 12:23.400\n And it's also nice because it doesn't require\n\n12:23.400 --> 12:25.160\n that they are humans or biological.\n\n12:25.160 --> 12:28.160\n They could be artificial agents that are intelligence.\n\n12:28.160 --> 12:30.280\n They could achieve those kind of goals.\n\n12:30.280 --> 12:35.280\n So particular agent, the ripple effects of their existence\n\n12:35.600 --> 12:38.480\n on the entirety of the system is significant.\n\n12:38.480 --> 12:41.720\n So like they leave a trace where there's like a,\n\n12:41.720 --> 12:43.840\n yeah, like ripple effects.\n\n12:43.840 --> 12:46.000\n But see, then you go back to the butterfly\n\n12:46.000 --> 12:48.440\n with the flap of a wing and then you can trace\n\n12:48.440 --> 12:50.800\n a lot of like nuclear wars\n\n12:50.800 --> 12:52.680\n and all the conflicts of human history,\n\n12:52.680 --> 12:54.540\n somehow connected to that one butterfly\n\n12:54.540 --> 12:56.240\n that created all of the chaos.\n\n12:56.240 --> 13:00.680\n So maybe that's not, maybe that's a very poetic way\n\n13:00.680 --> 13:03.400\n to think that that's something we humans\n\n13:03.400 --> 13:07.680\n in a human centric way wanna hope we have this impact.\n\n13:09.040 --> 13:12.160\n Like that is the secondary effect of our intelligence.\n\n13:12.160 --> 13:14.540\n We've had the long lasting impact on the world,\n\n13:14.540 --> 13:19.540\n but maybe the entirety of physics in the universe\n\n13:20.380 --> 13:22.700\n has a very long lasting effects.\n\n13:22.700 --> 13:25.600\n Sure, but you can also think of it.\n\n13:25.600 --> 13:29.980\n What if like the wonderful life, what if you're not here?\n\n13:29.980 --> 13:31.600\n Will somebody else do this?\n\n13:31.600 --> 13:34.560\n Is it something that you actually contributed\n\n13:34.560 --> 13:36.480\n because you had something unique to compute?\n\n13:36.480 --> 13:39.440\n That contribute, that's a pretty high bar though.\n\n13:39.440 --> 13:40.680\n Uniqueness, yeah.\n\n13:40.680 --> 13:45.080\n So, you have to be Mozart or something to actually\n\n13:45.080 --> 13:47.800\n reach that level that nobody would have developed that,\n\n13:47.800 --> 13:50.520\n but other people might have solved this equation\n\n13:51.800 --> 13:55.920\n if you didn't do it, but also within limited scope.\n\n13:55.920 --> 14:00.140\n I mean, during your lifetime or next year,\n\n14:00.140 --> 14:02.500\n you could contribute something that unique\n\n14:02.500 --> 14:04.240\n that other people did not see.\n\n14:04.240 --> 14:09.240\n And then that could change the way things move forward\n\n14:09.240 --> 14:11.320\n for a while.\n\n14:11.320 --> 14:14.000\n So, I don't think we have to be Mozart\n\n14:14.000 --> 14:15.320\n to be called intelligence,\n\n14:15.320 --> 14:18.240\n but we have this local effect that is changing.\n\n14:18.240 --> 14:20.120\n If you weren't there, that would not have happened.\n\n14:20.120 --> 14:21.480\n And it's a positive effect, of course,\n\n14:21.480 --> 14:23.200\n you want it to be a positive effect.\n\n14:23.200 --> 14:25.080\n Do you think it's possible to engineer\n\n14:25.080 --> 14:29.720\n into computational agents, a fear of mortality?\n\n14:30.560 --> 14:35.440\n Like, does that make any sense?\n\n14:35.440 --> 14:38.200\n So, there's a very trivial thing where it's like,\n\n14:38.200 --> 14:39.680\n you could just code in a parameter,\n\n14:39.680 --> 14:41.320\n which is how long the life ends,\n\n14:41.320 --> 14:45.440\n but more of a fear of mortality,\n\n14:45.440 --> 14:48.920\n like awareness of the way that things end\n\n14:48.920 --> 14:53.920\n and somehow encoding a complex representation of that fear,\n\n14:54.800 --> 14:56.960\n which is like, maybe as it gets closer,\n\n14:56.960 --> 14:58.840\n you become more terrified.\n\n14:58.840 --> 15:01.600\n I mean, there seems to be something really profound\n\n15:01.600 --> 15:04.820\n about this fear that's not currently encodable\n\n15:04.820 --> 15:08.200\n in a trivial way into our programs.\n\n15:08.200 --> 15:11.840\n Well, I think you're referring to the emotion of fear,\n\n15:11.840 --> 15:13.520\n something, because we have cognitively,\n\n15:13.520 --> 15:16.300\n we know that we have limited lifespan\n\n15:16.300 --> 15:18.020\n and most of us cope with it by just,\n\n15:18.020 --> 15:19.640\n hey, that's what the world is like\n\n15:19.640 --> 15:20.560\n and I make the most of it.\n\n15:20.560 --> 15:25.560\n But sometimes you can have like a fear that's not healthy,\n\n15:26.200 --> 15:29.300\n that paralyzes you, that you can't do anything.\n\n15:29.300 --> 15:31.960\n And somewhere in between there,\n\n15:31.960 --> 15:36.160\n not caring at all and getting paralyzed because of fear\n\n15:36.160 --> 15:37.280\n is a normal response,\n\n15:37.280 --> 15:39.440\n which is a little bit more than just logic\n\n15:39.440 --> 15:41.440\n and it's emotion.\n\n15:41.440 --> 15:43.680\n So now the question is, what good are emotions?\n\n15:43.680 --> 15:46.160\n I mean, they are quite complex\n\n15:46.160 --> 15:48.480\n and there are multiple dimensions of emotions\n\n15:48.480 --> 15:52.560\n and they probably do serve a survival function,\n\n15:53.520 --> 15:55.840\n heightened focus, for instance.\n\n15:55.840 --> 15:59.680\n And fear of death might be a really good emotion\n\n15:59.680 --> 16:02.640\n when you are in danger, that you recognize it,\n\n16:02.640 --> 16:06.360\n even if it's not logically necessarily easy to derive\n\n16:06.360 --> 16:10.400\n and you don't have time for that logical deduction,\n\n16:10.400 --> 16:12.720\n you may be able to recognize the situation is dangerous\n\n16:12.720 --> 16:16.260\n and this fear kicks in and you all of a sudden perceive\n\n16:16.260 --> 16:18.480\n the facts that are important for that.\n\n16:18.480 --> 16:21.040\n And I think that's generally is the role of emotions.\n\n16:21.040 --> 16:24.540\n It allows you to focus what's relevant for your situation.\n\n16:24.540 --> 16:27.800\n And maybe if fear of death plays the same kind of role,\n\n16:27.800 --> 16:30.600\n but if it consumes you and it's something that you think\n\n16:30.600 --> 16:32.080\n in normal life when you don't have to,\n\n16:32.080 --> 16:34.460\n then it's not healthy and then it's not productive.\n\n16:34.460 --> 16:36.640\n Yeah, but it's fascinating to think\n\n16:36.640 --> 16:41.640\n how to incorporate emotion into a computational agent.\n\n16:41.760 --> 16:44.280\n It almost seems like a silly statement to make,\n\n16:45.120 --> 16:48.280\n but it perhaps seems silly because we have\n\n16:48.280 --> 16:51.720\n such a poor understanding of the mechanism of emotion,\n\n16:51.720 --> 16:56.720\n of fear, of, I think at the core of it\n\n16:56.720 --> 17:00.280\n is another word that we know nothing about,\n\n17:00.280 --> 17:02.400\n but say a lot, which is consciousness.\n\n17:03.800 --> 17:08.560\n Do you ever in your work, or like maybe on a coffee break,\n\n17:08.560 --> 17:11.600\n think about what the heck is this thing consciousness\n\n17:11.600 --> 17:14.960\n and is it at all useful in our thinking about AI systems?\n\n17:14.960 --> 17:17.380\n Yes, it is an important question.\n\n17:18.280 --> 17:23.120\n You can build representations and functions,\n\n17:23.120 --> 17:26.720\n I think into these agents that act like emotions\n\n17:26.720 --> 17:28.620\n and consciousness perhaps.\n\n17:28.620 --> 17:31.920\n So I mentioned emotions being something\n\n17:31.920 --> 17:34.200\n that allow you to focus and pay attention,\n\n17:34.200 --> 17:35.360\n filter out what's important.\n\n17:35.360 --> 17:38.280\n Yeah, you can have that kind of a filter mechanism\n\n17:38.280 --> 17:40.320\n and it puts you in a different state.\n\n17:40.320 --> 17:42.080\n Your computation is in a different state.\n\n17:42.080 --> 17:43.560\n Certain things don't really get through\n\n17:43.560 --> 17:45.060\n and others are heightened.\n\n17:46.040 --> 17:48.460\n Now you label that box emotion.\n\n17:48.460 --> 17:49.840\n I don't know if that means it's an emotion,\n\n17:49.840 --> 17:52.520\n but it acts very much like we understand\n\n17:52.520 --> 17:54.240\n what emotions are.\n\n17:54.240 --> 17:56.900\n And we actually did some work like that,\n\n17:56.900 --> 18:01.900\n modeling hyenas who were trying to steal a kill from lions,\n\n18:02.240 --> 18:03.480\n which happens in Africa.\n\n18:03.480 --> 18:05.960\n I mean, hyenas are quite intelligent,\n\n18:05.960 --> 18:08.280\n but not really intelligent.\n\n18:08.280 --> 18:11.560\n And they have this behavior\n\n18:11.560 --> 18:14.040\n that's more complex than anything else they do.\n\n18:14.040 --> 18:17.680\n They can band together, if there's about 30 of them or so,\n\n18:17.680 --> 18:20.040\n they can coordinate their effort\n\n18:20.040 --> 18:22.560\n so that they push the lions away from a kill.\n\n18:22.560 --> 18:24.080\n Even though the lions are so strong\n\n18:24.080 --> 18:28.440\n that they could kill a hyena by striking with a paw.\n\n18:28.440 --> 18:31.640\n But when they work together and precisely time this attack,\n\n18:31.640 --> 18:34.080\n the lions will leave and they get the kill.\n\n18:34.080 --> 18:38.880\n And probably there are some states\n\n18:38.880 --> 18:40.840\n like emotions that the hyenas go through.\n\n18:40.840 --> 18:43.640\n The first, they call for reinforcements.\n\n18:43.640 --> 18:45.660\n They really want that kill, but there's not enough of them.\n\n18:45.660 --> 18:48.480\n So they vocalize and there's more people,\n\n18:48.480 --> 18:50.920\n more hyenas that come around.\n\n18:50.920 --> 18:52.280\n And then they have two emotions.\n\n18:52.280 --> 18:55.600\n They're very afraid of the lion, so they want to stay away,\n\n18:55.600 --> 18:59.800\n but they also have a strong affiliation between each other.\n\n18:59.800 --> 19:02.140\n And then this is the balance of the two emotions.\n\n19:02.140 --> 19:04.840\n And also, yes, they also want the kill.\n\n19:04.840 --> 19:07.320\n So it's both repelled and attractive.\n\n19:07.320 --> 19:10.600\n But then this affiliation eventually is so strong\n\n19:10.600 --> 19:12.240\n that when they move, they move together,\n\n19:12.240 --> 19:15.360\n they act as a unit and they can perform that function.\n\n19:15.360 --> 19:18.400\n So there's an interesting behavior\n\n19:18.400 --> 19:21.360\n that seems to depend on these emotions strongly\n\n19:21.360 --> 19:24.280\n and makes it possible, coordinate the actions.\n\n19:24.280 --> 19:28.880\n And I think a critical aspect of that,\n\n19:28.880 --> 19:30.560\n the way you're describing is emotion there\n\n19:30.560 --> 19:34.320\n is a mechanism of social communication,\n\n19:34.320 --> 19:35.960\n of a social interaction.\n\n19:35.960 --> 19:40.520\n Maybe humans won't even be that intelligent\n\n19:40.520 --> 19:42.440\n or most things we think of as intelligent\n\n19:42.440 --> 19:45.760\n wouldn't be that intelligent without the social component\n\n19:45.760 --> 19:47.040\n of interaction.\n\n19:47.040 --> 19:48.960\n Maybe much of our intelligence\n\n19:48.960 --> 19:52.840\n is essentially an outgrowth of social interaction.\n\n19:52.840 --> 19:55.680\n And maybe for the creation of intelligent agents,\n\n19:55.680 --> 19:58.920\n we have to be creating fundamentally social systems.\n\n19:58.920 --> 20:01.140\n Yes, I strongly believe that's true.\n\n20:01.140 --> 20:05.480\n And yes, the communication is multifaceted.\n\n20:05.480 --> 20:08.080\n I mean, they vocalize and call for friends,\n\n20:08.080 --> 20:11.160\n but they also rub against each other and they push\n\n20:11.160 --> 20:14.280\n and they do all kinds of gestures and so on.\n\n20:14.280 --> 20:15.720\n So they don't act alone.\n\n20:15.720 --> 20:18.360\n And I don't think people act alone very much either,\n\n20:18.360 --> 20:21.120\n at least normal, most of the time.\n\n20:21.120 --> 20:25.040\n And social systems are so strong for humans\n\n20:25.040 --> 20:26.800\n that I think we build everything\n\n20:26.800 --> 20:28.320\n on top of these kinds of structures.\n\n20:28.320 --> 20:30.880\n And one interesting theory around that,\n\n20:30.880 --> 20:32.520\n bigotness theory, for instance, for language,\n\n20:32.520 --> 20:36.200\n but language origins is that where did language come from?\n\n20:36.200 --> 20:41.200\n And it's a plausible theory that first came social systems,\n\n20:41.320 --> 20:44.180\n that you have different roles in a society.\n\n20:45.180 --> 20:47.400\n And then those roles are exchangeable,\n\n20:47.400 --> 20:49.960\n that I scratch your back, you scratch my back,\n\n20:49.960 --> 20:51.480\n we can exchange roles.\n\n20:51.480 --> 20:53.480\n And once you have the brain structures\n\n20:53.480 --> 20:54.960\n that allow you to understand actions\n\n20:54.960 --> 20:57.280\n in terms of roles that can be changed,\n\n20:57.280 --> 20:59.920\n that's the basis for language, for grammar.\n\n20:59.920 --> 21:02.040\n And now you can start using symbols\n\n21:02.040 --> 21:04.800\n to refer to objects in the world.\n\n21:04.800 --> 21:06.760\n And you have this flexible structure.\n\n21:06.760 --> 21:09.360\n So there's a social structure\n\n21:09.360 --> 21:12.460\n that's fundamental for language to develop.\n\n21:12.460 --> 21:13.960\n Now, again, then you have language,\n\n21:13.960 --> 21:17.400\n you can refer to things that are not here right now.\n\n21:17.400 --> 21:20.920\n And that allows you to then build all the good stuff\n\n21:20.920 --> 21:24.640\n about planning, for instance, and building things and so on.\n\n21:24.640 --> 21:28.280\n So yeah, I think that very strongly humans are social\n\n21:28.280 --> 21:33.000\n and that gives us ability to structure the world.\n\n21:33.000 --> 21:35.520\n But also as a society, we can do so much more\n\n21:35.520 --> 21:38.000\n because one person does not have to do everything.\n\n21:38.000 --> 21:39.800\n You can have different roles\n\n21:39.800 --> 21:41.720\n and together achieve a lot more.\n\n21:41.720 --> 21:42.880\n And that's also something\n\n21:42.880 --> 21:44.840\n we see in computational simulations today.\n\n21:44.840 --> 21:47.800\n I mean, we have multi agent systems that can perform tasks.\n\n21:47.800 --> 21:50.640\n This fascinating demonstration, Marco Dorego,\n\n21:50.640 --> 21:53.160\n I think it was, these little robots\n\n21:53.160 --> 21:54.760\n that had to navigate through an environment\n\n21:54.760 --> 21:57.700\n and there were things that are dangerous,\n\n21:57.700 --> 22:02.160\n like maybe a big chasm or some kind of groove, a hole,\n\n22:02.160 --> 22:03.560\n and they could not get across it.\n\n22:03.560 --> 22:06.440\n But if they grab each other with their gripper,\n\n22:06.440 --> 22:09.880\n they formed a robot that was much longer under the team\n\n22:09.880 --> 22:12.320\n and this way they could get across that.\n\n22:12.320 --> 22:15.780\n So this is a great example of how together\n\n22:15.780 --> 22:17.400\n we can achieve things we couldn't otherwise.\n\n22:17.400 --> 22:19.720\n Like the hyenas, you know, alone they couldn't,\n\n22:19.720 --> 22:21.400\n but as a team they could.\n\n22:21.400 --> 22:23.160\n And I think humans do that all the time.\n\n22:23.160 --> 22:24.800\n We're really good at that.\n\n22:24.800 --> 22:27.960\n Yeah, and the way you described the system of hyenas,\n\n22:27.960 --> 22:29.720\n it almost sounds algorithmic.\n\n22:29.720 --> 22:32.800\n Like the problem with humans is they're so complex,\n\n22:32.800 --> 22:35.000\n it's hard to think of them as algorithms.\n\n22:35.000 --> 22:39.040\n But with hyenas, there's a, it's simple enough\n\n22:39.040 --> 22:42.620\n to where it feels like, at least hopeful\n\n22:42.620 --> 22:46.560\n that it's possible to create computational systems\n\n22:46.560 --> 22:47.720\n that mimic that.\n\n22:48.580 --> 22:51.960\n Yeah, that's exactly why we looked at that.\n\n22:51.960 --> 22:53.080\n As opposed to humans.\n\n22:54.080 --> 22:55.240\n Like I said, they are intelligent,\n\n22:55.240 --> 22:59.520\n but they are not quite as intelligent as say, baboons,\n\n22:59.520 --> 23:02.120\n which would learn a lot and would be much more flexible.\n\n23:02.120 --> 23:05.640\n The hyenas are relatively rigid in what they can do.\n\n23:05.640 --> 23:08.080\n And therefore you could look at this behavior,\n\n23:08.080 --> 23:11.520\n like this is a breakthrough in evolution about to happen.\n\n23:11.520 --> 23:14.680\n That they've discovered something about social structures,\n\n23:14.680 --> 23:17.520\n communication, about cooperation,\n\n23:17.520 --> 23:20.560\n and it might then spill over to other things too\n\n23:20.560 --> 23:22.640\n in thousands of years in the future.\n\n23:22.640 --> 23:24.920\n Yeah, I think the problem with baboons and humans\n\n23:24.920 --> 23:27.840\n is probably too much is going on inside the head.\n\n23:27.840 --> 23:30.320\n We won't be able to measure it if we're observing the system.\n\n23:30.320 --> 23:34.240\n With hyenas, it's probably easier to observe\n\n23:34.240 --> 23:37.640\n the actual decision making and the various motivations\n\n23:37.640 --> 23:38.640\n that are involved.\n\n23:38.640 --> 23:40.000\n Yeah, they are visible.\n\n23:40.000 --> 23:45.080\n And we can even quantify possibly their emotional state\n\n23:45.080 --> 23:48.160\n because they leave droppings behind.\n\n23:48.160 --> 23:50.760\n And there are chemicals there that can be associated\n\n23:50.760 --> 23:52.920\n with neurotransmitters.\n\n23:52.920 --> 23:55.680\n And we can separate what emotions they might have\n\n23:55.680 --> 23:58.360\n experienced in the last 24 hours.\n\n23:58.360 --> 23:59.360\n Yeah.\n\n23:59.360 --> 24:04.000\n What to you is the most beautiful, speaking of hyenas,\n\n24:04.000 --> 24:08.000\n what to you is the most beautiful nature inspired algorithm\n\n24:08.000 --> 24:09.720\n in your work that you've come across?\n\n24:09.720 --> 24:14.000\n Something maybe early on in your work or maybe today?\n\n24:14.000 --> 24:19.120\n I think evolution computation is the most amazing method.\n\n24:19.120 --> 24:23.640\n So what fascinates me most is that with computers\n\n24:23.640 --> 24:26.920\n is that you can get more out than you put in.\n\n24:26.920 --> 24:29.200\n I mean, you can write a piece of code\n\n24:29.200 --> 24:31.880\n and your machine does what you told it.\n\n24:31.880 --> 24:34.720\n I mean, this happened to me in my freshman year.\n\n24:34.720 --> 24:37.080\n It did something very simple and I was just amazed.\n\n24:37.080 --> 24:39.640\n I was blown away that it would get the number\n\n24:39.640 --> 24:41.520\n and it would compute the result.\n\n24:41.520 --> 24:43.400\n And I didn't have to do it myself.\n\n24:43.400 --> 24:44.480\n Very simple.\n\n24:44.480 --> 24:46.880\n But if you push that a little further,\n\n24:46.880 --> 24:50.880\n you can have machines that learn and they might learn patterns.\n\n24:50.880 --> 24:53.960\n And already say deep learning neural networks,\n\n24:53.960 --> 24:58.000\n they can learn to recognize objects, sounds,\n\n24:58.000 --> 25:00.400\n patterns that humans have trouble with.\n\n25:00.400 --> 25:02.480\n And sometimes they do it better than humans.\n\n25:02.480 --> 25:04.200\n And that's so fascinating.\n\n25:04.200 --> 25:06.080\n And now if you take that one more step,\n\n25:06.080 --> 25:08.120\n you get something like evolutionary algorithms\n\n25:08.120 --> 25:10.440\n that discover things, they create things,\n\n25:10.440 --> 25:13.400\n they come up with solutions that you did not think of.\n\n25:13.400 --> 25:15.120\n And that just blows me away.\n\n25:15.120 --> 25:18.600\n It's so great that we can build systems, algorithms\n\n25:18.600 --> 25:21.480\n that can be in some sense smarter than we are,\n\n25:21.480 --> 25:24.840\n that they can discover solutions that we might miss.\n\n25:24.840 --> 25:26.600\n A lot of times it is because we have as humans,\n\n25:26.600 --> 25:27.840\n we have certain biases,\n\n25:27.840 --> 25:30.000\n we expect the solutions to be certain way\n\n25:30.000 --> 25:32.200\n and you don't put those biases into the algorithm\n\n25:32.200 --> 25:34.040\n so they are more free to explore.\n\n25:34.040 --> 25:37.720\n And evolution is just absolutely fantastic explorer.\n\n25:37.720 --> 25:40.320\n And that's what really is fascinating.\n\n25:40.320 --> 25:43.760\n Yeah, I think I get made fun of a bit\n\n25:43.760 --> 25:45.840\n because I currently don't have any kids,\n\n25:45.840 --> 25:47.640\n but you mentioned programs.\n\n25:47.640 --> 25:50.680\n I mean, do you have kids?\n\n25:50.680 --> 25:51.520\n Yeah.\n\n25:51.520 --> 25:52.640\n So maybe you could speak to this,\n\n25:52.640 --> 25:55.600\n but there's a magic to the creative process.\n\n25:55.600 --> 25:59.760\n Like with Spot, the Boston Dynamics Spot,\n\n25:59.760 --> 26:02.400\n but really any robot that I've ever worked on,\n\n26:02.400 --> 26:04.480\n it just feels like the similar kind of joy\n\n26:04.480 --> 26:06.560\n I imagine I would have as a father.\n\n26:06.560 --> 26:08.360\n Not the same perhaps level,\n\n26:08.360 --> 26:10.160\n but like the same kind of wonderment.\n\n26:10.160 --> 26:11.880\n Like there's exactly this,\n\n26:11.880 --> 26:17.760\n which is like you know what you had to do initially\n\n26:17.760 --> 26:19.520\n to get this thing going.\n\n26:19.520 --> 26:21.680\n Let's speak on the computer science side,\n\n26:21.680 --> 26:23.840\n like what the program looks like,\n\n26:23.840 --> 26:27.880\n but something about it doing more\n\n26:27.880 --> 26:30.880\n than what the program was written on paper\n\n26:30.880 --> 26:34.680\n is like that somehow connects to the magic\n\n26:34.680 --> 26:36.120\n of this entire universe.\n\n26:36.120 --> 26:39.200\n Like that's like, I feel like I found God.\n\n26:39.200 --> 26:42.080\n Every time I like, it's like,\n\n26:42.080 --> 26:45.640\n because you've really created something that's living.\n\n26:45.640 --> 26:46.480\n Yeah.\n\n26:46.480 --> 26:47.320\n Even if it's a simple program.\n\n26:47.320 --> 26:48.720\n It has a life of its own, it has the intelligence of its own.\n\n26:48.720 --> 26:51.040\n It's beyond what you actually thought.\n\n26:51.040 --> 26:51.880\n Yeah.\n\n26:51.880 --> 26:53.400\n And that is, I think it's exactly spot on.\n\n26:53.400 --> 26:55.480\n That's exactly what it's about.\n\n26:55.480 --> 26:57.800\n You created something and it has a ability\n\n26:57.800 --> 27:00.920\n to live its life and do good things\n\n27:00.920 --> 27:03.240\n and you just gave it a starting point.\n\n27:03.240 --> 27:04.400\n So in that sense, I think it's,\n\n27:04.400 --> 27:06.440\n that may be part of the joy actually.\n\n27:06.440 --> 27:11.000\n But you mentioned creativity in this context,\n\n27:11.000 --> 27:14.120\n especially in the context of evolutionary computation.\n\n27:14.120 --> 27:18.360\n So, we don't often think of algorithms as creative.\n\n27:18.360 --> 27:20.280\n So how do you think about creativity?\n\n27:21.280 --> 27:24.960\n Yeah, algorithms absolutely can be creative.\n\n27:24.960 --> 27:28.320\n They can come up with solutions that you don't think about.\n\n27:28.320 --> 27:29.760\n I mean, creativity can be defined.\n\n27:29.760 --> 27:32.680\n A couple of requirements has to be new.\n\n27:32.680 --> 27:35.320\n It has to be useful and it has to be surprising.\n\n27:35.320 --> 27:38.000\n And those certainly are true with, say,\n\n27:38.000 --> 27:41.560\n evolutionary computation discovering solutions.\n\n27:41.560 --> 27:44.320\n So maybe an example, for instance,\n\n27:44.320 --> 27:47.480\n we did this collaboration with MIT Media Lab,\n\n27:47.480 --> 27:50.760\n Caleb Harbus Lab, where they had\n\n27:50.760 --> 27:54.560\n a hydroponic food computer, they called it,\n\n27:54.560 --> 27:56.920\n environment that was completely computer controlled,\n\n27:56.920 --> 27:59.520\n nutrients, water, light, temperature,\n\n27:59.520 --> 28:00.880\n everything is controlled.\n\n28:00.880 --> 28:05.560\n Now, what do you do if you can control everything?\n\n28:05.560 --> 28:08.880\n Farmers know a lot about how to make plants grow\n\n28:08.880 --> 28:10.280\n in their own patch of land.\n\n28:10.280 --> 28:13.120\n But if you can control everything, it's too much.\n\n28:13.120 --> 28:14.600\n And it turns out that we don't actually\n\n28:14.600 --> 28:16.040\n know very much about it.\n\n28:16.040 --> 28:20.320\n So we built a system, evolutionary optimization system,\n\n28:20.320 --> 28:23.680\n together with a surrogate model of how plants grow\n\n28:23.680 --> 28:28.680\n and let this system explore recipes on its own.\n\n28:28.680 --> 28:32.040\n And initially, we were focusing on light,\n\n28:32.040 --> 28:36.800\n how strong, what wavelengths, how long the light was on.\n\n28:36.800 --> 28:40.120\n And we put some boundaries which we thought were reasonable.\n\n28:40.120 --> 28:44.320\n For instance, that there was at least six hours of darkness,\n\n28:44.320 --> 28:47.120\n like night, because that's what we have in the world.\n\n28:47.120 --> 28:51.000\n And very quickly, the system, evolution,\n\n28:51.000 --> 28:54.120\n pushed all the recipes to that limit.\n\n28:54.120 --> 28:55.880\n We were trying to grow basil.\n\n28:55.880 --> 29:00.000\n And we initially had some 200, 300 recipes,\n\n29:00.000 --> 29:02.160\n exploration as well as known recipes.\n\n29:02.160 --> 29:04.040\n But now we are going beyond that.\n\n29:04.040 --> 29:06.440\n And everything was pushed to that limit.\n\n29:06.440 --> 29:09.280\n So we look at it and say, well, we can easily just change it.\n\n29:09.280 --> 29:10.720\n Let's have it your way.\n\n29:10.720 --> 29:13.440\n And it turns out the system discovered\n\n29:13.440 --> 29:15.400\n that basil does not need to sleep.\n\n29:16.720 --> 29:19.440\n 24 hours, lights on, and it will thrive.\n\n29:19.440 --> 29:21.320\n It will be bigger, it will be tastier.\n\n29:21.320 --> 29:24.480\n And this was a big surprise, not just to us,\n\n29:24.480 --> 29:26.840\n but also the biologists in the team\n\n29:26.840 --> 29:30.520\n that anticipated that there are some constraints\n\n29:30.520 --> 29:32.800\n that are in the world for a reason.\n\n29:32.800 --> 29:36.000\n It turns out that evolution did not have the same bias.\n\n29:36.000 --> 29:38.760\n And therefore, it discovered something that was creative.\n\n29:38.760 --> 29:41.320\n It was surprising, it was useful, and it was new.\n\n29:41.320 --> 29:44.360\n That's fascinating to think about the things we think\n\n29:44.360 --> 29:48.200\n that are fundamental to living systems on Earth today,\n\n29:48.200 --> 29:49.720\n whether they're actually fundamental\n\n29:49.720 --> 29:53.680\n or they somehow fit the constraints of the system.\n\n29:53.680 --> 29:56.480\n And all we have to do is just remove the constraints.\n\n29:56.480 --> 29:57.600\n Do you ever think about,\n\n29:59.320 --> 30:00.320\n I don't know how much you know\n\n30:00.320 --> 30:03.280\n about brain computer interfaces in your link.\n\n30:03.280 --> 30:08.280\n The idea there is our brains are very limited.\n\n30:08.480 --> 30:11.840\n And if we just allow, we plug in,\n\n30:11.840 --> 30:13.720\n we provide a mechanism for a computer\n\n30:13.720 --> 30:15.080\n to speak with the brain.\n\n30:15.080 --> 30:16.880\n So you're thereby expanding\n\n30:16.880 --> 30:19.240\n the computational power of the brain.\n\n30:19.240 --> 30:21.200\n The possibilities there,\n\n30:21.200 --> 30:25.560\n from a very high level philosophical perspective,\n\n30:25.560 --> 30:27.000\n is limitless.\n\n30:27.000 --> 30:30.680\n But I wonder how limitless it is.\n\n30:30.680 --> 30:33.440\n Are the constraints we have features\n\n30:33.440 --> 30:36.040\n that are fundamental to our intelligence?\n\n30:36.040 --> 30:38.440\n Or is this just this weird constraint\n\n30:38.440 --> 30:40.640\n in terms of our brain size and skull\n\n30:40.640 --> 30:44.480\n and lifespan and senses?\n\n30:44.480 --> 30:47.840\n It's just the weird little quirk of evolution.\n\n30:47.840 --> 30:49.400\n And if we just open that up,\n\n30:49.400 --> 30:51.480\n like add much more senses,\n\n30:51.480 --> 30:53.680\n add much more computational power,\n\n30:53.680 --> 30:57.840\n the intelligence will expand exponentially.\n\n30:57.840 --> 31:02.840\n Do you have a sense about constraints,\n\n31:03.320 --> 31:05.360\n the relationship of evolution and computation\n\n31:05.360 --> 31:07.200\n to the constraints of the environment?\n\n31:09.800 --> 31:12.400\n Well, at first I'd like to comment on that,\n\n31:12.400 --> 31:16.000\n like changing the inputs to human brain.\n\n31:16.000 --> 31:18.320\n And flexibility of the brain.\n\n31:18.320 --> 31:20.720\n I think there's a lot of that.\n\n31:20.720 --> 31:22.360\n There are experiments that are done in animals\n\n31:22.360 --> 31:25.000\n like Mikangazuru at MIT,\n\n31:25.000 --> 31:29.200\n switching the auditory and visual information\n\n31:29.200 --> 31:31.480\n and going to the wrong part of the cortex.\n\n31:31.480 --> 31:34.120\n And the animal was still able to hear\n\n31:34.120 --> 31:36.480\n and perceive the visual environment.\n\n31:36.480 --> 31:41.120\n And there are kids that are born with severe disorders\n\n31:41.120 --> 31:43.960\n and sometimes they have to remove half of the brain,\n\n31:43.960 --> 31:46.120\n like one half, and they still grow up.\n\n31:46.120 --> 31:48.320\n They have the functions migrate to the other parts.\n\n31:48.320 --> 31:50.360\n There's a lot of flexibility like that.\n\n31:50.360 --> 31:55.000\n So I think it's quite possible to hook up the brain\n\n31:55.000 --> 31:57.600\n with different kinds of sensors, for instance,\n\n31:57.600 --> 32:00.280\n and something that we don't even quite understand\n\n32:00.280 --> 32:02.520\n or have today on different kinds of wavelengths\n\n32:02.520 --> 32:04.640\n or whatever they are.\n\n32:04.640 --> 32:07.000\n And then the brain can learn to make sense of it.\n\n32:07.000 --> 32:09.960\n And that I think is this good hope\n\n32:09.960 --> 32:12.720\n that these prosthetic devices, for instance, work,\n\n32:12.720 --> 32:15.720\n not because we make them so good and so easy to use,\n\n32:15.720 --> 32:17.080\n but the brain adapts to them\n\n32:17.080 --> 32:19.080\n and can learn to take advantage of them.\n\n32:20.400 --> 32:23.440\n And so in that sense, if there's a trouble, a problem,\n\n32:23.440 --> 32:26.200\n I think the brain can be used to correct it.\n\n32:26.200 --> 32:29.200\n Now going beyond what we have today, can you get smarter?\n\n32:29.200 --> 32:31.560\n That's really much harder to do.\n\n32:31.560 --> 32:35.520\n Giving the brain more input probably might overwhelm it.\n\n32:35.520 --> 32:38.640\n It would have to learn to filter it and focus\n\n32:39.720 --> 32:43.320\n and in order to use the information effectively\n\n32:43.320 --> 32:46.600\n and augmenting intelligence\n\n32:46.600 --> 32:49.080\n with some kind of external devices like that\n\n32:49.080 --> 32:51.560\n might be difficult, I think.\n\n32:51.560 --> 32:55.680\n But replacing what's lost, I think is quite possible.\n\n32:55.680 --> 32:59.360\n Right, so our intuition allows us to sort of imagine\n\n32:59.360 --> 33:01.400\n that we can replace what's been lost,\n\n33:01.400 --> 33:03.480\n but expansion beyond what we have,\n\n33:03.480 --> 33:05.360\n I mean, we're already one of the most,\n\n33:05.360 --> 33:07.800\n if not the most intelligent things on this earth, right?\n\n33:07.800 --> 33:09.600\n So it's hard to imagine.\n\n33:09.600 --> 33:14.600\n But if the brain can hold up with an order of magnitude\n\n33:14.840 --> 33:18.080\n greater set of information thrown at it,\n\n33:18.080 --> 33:20.720\n if it can do, if it can reason through that.\n\n33:20.720 --> 33:22.560\n Part of me, this is the Russian thing, I think,\n\n33:22.560 --> 33:25.400\n is I tend to think that the limitations\n\n33:25.400 --> 33:27.680\n is where the superpower is,\n\n33:27.680 --> 33:32.680\n that immortality and a huge increase in bandwidth\n\n33:32.680 --> 33:37.120\n of information by connecting computers with the brain\n\n33:37.120 --> 33:39.680\n is not going to produce greater intelligence.\n\n33:39.680 --> 33:41.320\n It might produce lesser intelligence.\n\n33:41.320 --> 33:45.080\n So I don't know, there's something about the scarcity\n\n33:45.080 --> 33:50.080\n being essential to fitness or performance,\n\n33:52.200 --> 33:56.040\n but that could be just because we're so limited.\n\n33:56.040 --> 33:57.760\n No, exactly, you make do with what you have,\n\n33:57.760 --> 34:00.720\n but you don't have to be a genius\n\n34:00.720 --> 34:04.360\n but you don't have to pipe it directly to the brain.\n\n34:04.360 --> 34:07.640\n I mean, we already have devices like phones\n\n34:07.640 --> 34:10.240\n where we can look up information at any point.\n\n34:10.240 --> 34:12.400\n And that can make us more productive.\n\n34:12.400 --> 34:14.120\n You don't have to argue about, I don't know,\n\n34:14.120 --> 34:16.480\n what happened in that baseball game or whatever it is,\n\n34:16.480 --> 34:17.800\n because you can look it up right away.\n\n34:17.800 --> 34:22.160\n And I think in that sense, we can learn to utilize tools.\n\n34:22.160 --> 34:25.320\n And that's what we have been doing for a long, long time.\n\n34:27.000 --> 34:29.120\n And we are already, the brain is already drinking\n\n34:29.120 --> 34:32.360\n the water, firehose, like vision.\n\n34:32.360 --> 34:34.480\n There's way more information in vision\n\n34:34.480 --> 34:35.640\n that we actually process.\n\n34:35.640 --> 34:38.840\n So brain is already good at identifying what matters.\n\n34:39.840 --> 34:42.840\n And that we can switch that from vision\n\n34:42.840 --> 34:44.960\n to some other wavelength or some other kind of modality.\n\n34:44.960 --> 34:47.040\n But I think that the same processing principles\n\n34:47.040 --> 34:49.000\n probably still apply.\n\n34:49.000 --> 34:53.680\n But also indeed this ability to have information\n\n34:53.680 --> 34:55.320\n more accessible and more relevant,\n\n34:55.320 --> 34:57.680\n I think can enhance what we do.\n\n34:57.680 --> 35:00.880\n I mean, kids today at school, they learn about DNA.\n\n35:00.880 --> 35:02.560\n I mean, things that were discovered\n\n35:02.560 --> 35:04.560\n just a couple of years ago.\n\n35:04.560 --> 35:06.400\n And it's already common knowledge\n\n35:06.400 --> 35:07.520\n and we are building on it.\n\n35:07.520 --> 35:10.200\n And we don't see a problem where\n\n35:12.400 --> 35:15.080\n there's too much information that we can absorb and learn.\n\n35:15.080 --> 35:17.480\n Maybe people become a little bit more narrow\n\n35:17.480 --> 35:20.840\n in what they know, they are in one field.\n\n35:20.840 --> 35:23.680\n But this information that we have accumulated,\n\n35:23.680 --> 35:26.080\n it is passed on and people are picking up on it\n\n35:26.080 --> 35:27.480\n and they are building on it.\n\n35:27.480 --> 35:30.960\n So it's not like we have reached the point of saturation.\n\n35:30.960 --> 35:34.440\n We have still this process that allows us to be selective\n\n35:34.440 --> 35:37.520\n and decide what's interesting, I think still works\n\n35:37.520 --> 35:40.040\n even with the more information we have today.\n\n35:40.040 --> 35:42.120\n Yeah, it's fascinating to think about\n\n35:43.080 --> 35:45.240\n like Wikipedia becoming a sensor.\n\n35:45.240 --> 35:49.000\n Like, so the fire hose of information from Wikipedia.\n\n35:49.000 --> 35:51.720\n So it's like you integrated directly into the brain\n\n35:51.720 --> 35:54.160\n to where you're thinking, like you're observing the world\n\n35:54.160 --> 35:57.760\n with all of Wikipedia directly piping into your brain.\n\n35:57.760 --> 35:59.840\n So like when I see a light,\n\n35:59.840 --> 36:03.560\n I immediately have like the history of who invented\n\n36:03.560 --> 36:07.480\n electricity, like integrated very quickly into.\n\n36:07.480 --> 36:09.800\n So just the way you think about the world\n\n36:09.800 --> 36:11.160\n might be very interesting\n\n36:11.160 --> 36:13.200\n if you can integrate that kind of information.\n\n36:13.200 --> 36:18.200\n What are your thoughts, if I could ask on early steps\n\n36:18.960 --> 36:20.280\n on the Neuralink side?\n\n36:20.280 --> 36:21.440\n I don't know if you got a chance to see,\n\n36:21.440 --> 36:24.600\n but there was a monkey playing pong\n\n36:25.880 --> 36:27.760\n through the brain computer interface.\n\n36:27.760 --> 36:30.600\n And the dream there is sort of,\n\n36:30.600 --> 36:33.680\n you're already replacing the thumbs essentially\n\n36:33.680 --> 36:35.840\n that you would use to play video game.\n\n36:35.840 --> 36:38.880\n The dream is to be able to increase further\n\n36:40.760 --> 36:43.400\n the interface by which you interact with the computer.\n\n36:43.400 --> 36:44.600\n Are you impressed by this?\n\n36:44.600 --> 36:46.400\n Are you worried about this?\n\n36:46.400 --> 36:47.920\n What are your thoughts as a human?\n\n36:47.920 --> 36:48.840\n I think it's wonderful.\n\n36:48.840 --> 36:51.280\n I think it's great that we could do something\n\n36:51.280 --> 36:52.120\n like that.\n\n36:52.120 --> 36:56.160\n I mean, there are devices that read your EEG for instance,\n\n36:56.160 --> 37:00.120\n and humans can learn to control things\n\n37:00.120 --> 37:02.760\n using just their thoughts in that sense.\n\n37:02.760 --> 37:04.920\n And I don't think it's that different.\n\n37:04.920 --> 37:06.720\n I mean, those signals would go to limbs,\n\n37:06.720 --> 37:08.320\n they would go to thumbs.\n\n37:08.320 --> 37:11.200\n Now the same signals go through a sensor\n\n37:11.200 --> 37:13.760\n to some computing system.\n\n37:13.760 --> 37:17.520\n It still probably has to be built on human terms,\n\n37:17.520 --> 37:20.000\n not to overwhelm them, but utilize what's there\n\n37:20.000 --> 37:23.720\n and sense the right kind of patterns\n\n37:23.720 --> 37:24.840\n that are easy to generate.\n\n37:24.840 --> 37:27.760\n But, oh, that I think is really quite possible\n\n37:27.760 --> 37:30.720\n and wonderful and could be very much more efficient.\n\n37:32.160 --> 37:34.160\n Is there, so you mentioned surprising\n\n37:34.160 --> 37:37.080\n being a characteristic of creativity.\n\n37:37.080 --> 37:39.800\n Is there something, you already mentioned a few examples,\n\n37:39.800 --> 37:41.920\n but is there something that jumps out at you\n\n37:41.920 --> 37:44.560\n as was particularly surprising\n\n37:44.560 --> 37:48.680\n from the various evolutionary computation systems\n\n37:48.680 --> 37:50.840\n you've worked on, the solutions that were\n\n37:52.840 --> 37:53.920\n come up along the way?\n\n37:53.920 --> 37:55.280\n Not necessarily the final solutions,\n\n37:55.280 --> 37:58.680\n but maybe things that would even discarded.\n\n37:58.680 --> 38:00.360\n Is there something that just jumps to mind?\n\n38:00.360 --> 38:02.200\n It happens all the time.\n\n38:02.200 --> 38:05.640\n I mean, evolution is so creative,\n\n38:05.640 --> 38:09.280\n so good at discovering solutions you don't anticipate.\n\n38:09.280 --> 38:12.680\n A lot of times they are taking advantage of something\n\n38:12.680 --> 38:13.800\n that you didn't think was there,\n\n38:13.800 --> 38:15.960\n like a bug in the software, for instance.\n\n38:15.960 --> 38:17.600\n A lot of, there's a great paper,\n\n38:17.600 --> 38:19.120\n the community put it together\n\n38:19.120 --> 38:22.920\n about surprising anecdotes about evolutionary computation.\n\n38:22.920 --> 38:25.640\n A lot of them are indeed, in some software environment,\n\n38:25.640 --> 38:28.120\n there was a loophole or a bug\n\n38:28.120 --> 38:30.560\n and the system utilizes that.\n\n38:30.560 --> 38:31.960\n By the way, for people who want to read it,\n\n38:31.960 --> 38:33.080\n it's kind of fun to read.\n\n38:33.080 --> 38:36.080\n It's called The Surprising Creativity of Digital Evolution,\n\n38:36.080 --> 38:39.320\n a collection of anecdotes from the evolutionary computation\n\n38:39.320 --> 38:41.560\n and artificial life research communities.\n\n38:41.560 --> 38:43.160\n And there's just a bunch of stories\n\n38:43.160 --> 38:45.840\n from all the seminal figures in this community.\n\n38:45.840 --> 38:48.520\n You have a story in there that released to you,\n\n38:48.520 --> 38:51.000\n at least on the Tic Tac Toe memory bomb.\n\n38:51.000 --> 38:54.760\n So can you, I guess, describe that situation\n\n38:54.760 --> 38:55.720\n if you think that's still?\n\n38:55.720 --> 38:59.640\n Yeah, that's a quite a bit smaller scale\n\n38:59.640 --> 39:03.040\n than our basic doesn't need to sleep surprise,\n\n39:03.040 --> 39:06.640\n but it was actually done by students in my class,\n\n39:06.640 --> 39:09.440\n in a neural nets evolution computation class.\n\n39:09.440 --> 39:10.640\n There was an assignment.\n\n39:11.840 --> 39:13.880\n It was perhaps a final project\n\n39:13.880 --> 39:18.880\n where people built game playing AI, it was an AI class.\n\n39:19.400 --> 39:21.920\n And this one, and it was for Tic Tac Toe\n\n39:21.920 --> 39:24.560\n or five in a row in a large board.\n\n39:24.560 --> 39:28.160\n And this one team evolved a neural network\n\n39:28.160 --> 39:29.920\n to make these moves.\n\n39:29.920 --> 39:32.720\n And they set it up, the evolution.\n\n39:32.720 --> 39:35.240\n They didn't really know what would come out,\n\n39:35.240 --> 39:37.000\n but it turned out that they did really well.\n\n39:37.000 --> 39:38.840\n Evolution actually won the tournament.\n\n39:38.840 --> 39:40.520\n And most of the time when it won,\n\n39:40.520 --> 39:43.480\n it won because the other teams crashed.\n\n39:43.480 --> 39:45.760\n And then when we look at it, like what was going on\n\n39:45.760 --> 39:48.240\n was that evolution discovered that if it makes a move\n\n39:48.240 --> 39:49.960\n that's really, really far away,\n\n39:49.960 --> 39:53.440\n like millions of squares away,\n\n39:53.440 --> 39:57.800\n the other teams, the other programs has expanded memory\n\n39:57.800 --> 39:59.160\n in order to take that into account\n\n39:59.160 --> 40:01.200\n until they run out of memory and crashed.\n\n40:01.200 --> 40:03.200\n And then you win a tournament\n\n40:03.200 --> 40:05.720\n by crashing all your opponents.\n\n40:05.720 --> 40:08.920\n I think that's quite a profound example,\n\n40:08.920 --> 40:13.920\n which probably applies to most games,\n\n40:14.560 --> 40:16.920\n from even a game theoretic perspective,\n\n40:16.920 --> 40:20.480\n that sometimes to win, you don't have to be better\n\n40:20.480 --> 40:22.680\n within the rules of the game.\n\n40:22.680 --> 40:27.680\n You have to come up with ways to break your opponent's brain,\n\n40:28.480 --> 40:31.360\n if it's a human, like not through violence,\n\n40:31.360 --> 40:34.640\n but through some hack where the brain just is not,\n\n40:34.640 --> 40:39.280\n you're basically, how would you put it?\n\n40:39.280 --> 40:43.120\n You're going outside the constraints\n\n40:43.120 --> 40:45.160\n of where the brain is able to function.\n\n40:45.160 --> 40:46.560\n Expectations of your opponent.\n\n40:46.560 --> 40:49.600\n I mean, this was even Kasparov pointed that out\n\n40:49.600 --> 40:51.800\n that when Deep Blue was playing against Kasparov,\n\n40:51.800 --> 40:55.440\n that it was not playing the same way as Kasparov expected.\n\n40:55.440 --> 40:59.760\n And this has to do with not having the same biases.\n\n40:59.760 --> 41:04.760\n And that's really one of the strengths of the AI approach.\n\n41:06.280 --> 41:08.080\n Can you at a high level say,\n\n41:08.080 --> 41:10.360\n what are the basic mechanisms\n\n41:10.360 --> 41:12.760\n of evolutionary computation algorithms\n\n41:12.760 --> 41:15.760\n that use something that could be called\n\n41:15.760 --> 41:17.680\n an evolutionary approach?\n\n41:17.680 --> 41:19.600\n Like how does it work?\n\n41:19.600 --> 41:21.680\n What are the connections to the,\n\n41:21.680 --> 41:24.800\n what are the echoes of the connection to his biological?\n\n41:24.800 --> 41:27.080\n A lot of these algorithms really do take motivation\n\n41:27.080 --> 41:29.560\n from biology, but they are caricatures.\n\n41:29.560 --> 41:31.280\n You try to essentialize it\n\n41:31.280 --> 41:33.600\n and take the elements that you believe matter.\n\n41:33.600 --> 41:35.880\n So in evolutionary computation,\n\n41:35.880 --> 41:38.040\n it is the creation of variation\n\n41:38.040 --> 41:40.680\n and then the selection upon that.\n\n41:40.680 --> 41:41.840\n So the creation of variation,\n\n41:41.840 --> 41:43.080\n you have to have some mechanism\n\n41:43.080 --> 41:44.720\n that allow you to create new individuals\n\n41:44.720 --> 41:47.080\n that are very different from what you already have.\n\n41:47.080 --> 41:48.800\n That's the creativity part.\n\n41:48.800 --> 41:50.720\n And then you have to have some way of measuring\n\n41:50.720 --> 41:55.520\n how well they are doing and using that measure to select\n\n41:55.520 --> 41:58.160\n who goes to the next generation and you continue.\n\n41:58.160 --> 42:00.240\n So first you also, you have to have\n\n42:00.240 --> 42:03.160\n some kind of digital representation of an individual\n\n42:03.160 --> 42:04.520\n that can be then modified.\n\n42:04.520 --> 42:07.360\n So I guess humans in biological systems\n\n42:07.360 --> 42:09.720\n have DNA and all those kinds of things.\n\n42:09.720 --> 42:12.160\n And so you have to have similar kind of encodings\n\n42:12.160 --> 42:13.400\n in a computer program.\n\n42:13.400 --> 42:15.040\n Yes, and that is a big question.\n\n42:15.040 --> 42:16.960\n How do you encode these individuals?\n\n42:16.960 --> 42:19.560\n So there's a genotype, which is that encoding\n\n42:19.560 --> 42:23.040\n and then a decoding mechanism gives you the phenotype,\n\n42:23.040 --> 42:26.400\n which is the actual individual that then performs the task\n\n42:26.400 --> 42:31.280\n and in an environment can be evaluated how good it is.\n\n42:31.280 --> 42:33.160\n So even that mapping is a big question\n\n42:33.160 --> 42:34.960\n and how do you do it?\n\n42:34.960 --> 42:37.080\n But typically the representations are,\n\n42:37.080 --> 42:38.600\n either they are strings of numbers\n\n42:38.600 --> 42:39.760\n or they are some kind of trees.\n\n42:39.760 --> 42:41.760\n Those are something that we know very well\n\n42:41.760 --> 42:43.560\n in computer science and we try to do that.\n\n42:43.560 --> 42:48.040\n But they, and DNA in some sense is also a sequence\n\n42:48.040 --> 42:49.480\n and it's a string.\n\n42:50.600 --> 42:52.040\n So it's not that far from it,\n\n42:52.040 --> 42:54.880\n but DNA also has many other aspects\n\n42:54.880 --> 42:56.720\n that we don't take into account necessarily\n\n42:56.720 --> 43:00.040\n like there's folding and interactions\n\n43:00.040 --> 43:03.600\n that are other than just the sequence itself.\n\n43:03.600 --> 43:06.000\n And lots of that is not yet captured\n\n43:06.000 --> 43:09.000\n and we don't know whether they are really crucial.\n\n43:10.120 --> 43:12.600\n Evolution, biological evolution has produced\n\n43:12.600 --> 43:16.000\n wonderful things, but if you look at them,\n\n43:16.000 --> 43:18.560\n it's not necessarily the case that every piece\n\n43:18.560 --> 43:20.880\n is irreplaceable and essential.\n\n43:20.880 --> 43:23.680\n There's a lot of baggage because you have to construct it\n\n43:23.680 --> 43:25.360\n and it has to go through various stages\n\n43:25.360 --> 43:29.360\n and we still have appendix and we have tail bones\n\n43:29.360 --> 43:31.360\n and things like that that are not really that useful.\n\n43:31.360 --> 43:33.400\n If you try to explain them now,\n\n43:33.400 --> 43:35.200\n it would make no sense, very hard.\n\n43:35.200 --> 43:38.200\n But if you think of us as productive evolution,\n\n43:38.200 --> 43:39.240\n you can see where they came from.\n\n43:39.240 --> 43:41.280\n They were useful at one point perhaps\n\n43:41.280 --> 43:43.400\n and no longer are, but they're still there.\n\n43:43.400 --> 43:47.080\n So that process is complex\n\n43:47.080 --> 43:50.800\n and your representation should support it.\n\n43:50.800 --> 43:55.800\n And that is quite difficult if we are limited\n\n43:56.320 --> 43:59.000\n with strings or trees,\n\n43:59.000 --> 44:01.840\n and then we are pretty much limited\n\n44:01.840 --> 44:03.760\n what can be constructed.\n\n44:03.760 --> 44:05.640\n And one thing that we are still missing\n\n44:05.640 --> 44:07.560\n in evolutionary computation in particular\n\n44:07.560 --> 44:11.440\n is what we saw in biology, major transitions.\n\n44:11.440 --> 44:13.840\n So that you go from, for instance,\n\n44:13.840 --> 44:16.080\n single cell to multi cell organisms\n\n44:16.080 --> 44:17.200\n and eventually societies.\n\n44:17.200 --> 44:19.640\n There are transitions of level of selection\n\n44:19.640 --> 44:22.120\n and level of what a unit is.\n\n44:22.120 --> 44:24.240\n And that's something we haven't captured\n\n44:24.240 --> 44:26.080\n in evolutionary computation yet.\n\n44:26.080 --> 44:28.680\n Does that require a dramatic expansion\n\n44:28.680 --> 44:30.040\n of the representation?\n\n44:30.040 --> 44:31.680\n Is that what that is?\n\n44:31.680 --> 44:34.480\n Most likely it does, but it's quite,\n\n44:34.480 --> 44:36.920\n we don't even understand it in biology very well\n\n44:36.920 --> 44:37.760\n where it's coming from.\n\n44:37.760 --> 44:40.560\n So it would be really good to look at major transitions\n\n44:40.560 --> 44:42.600\n in biology, try to characterize them\n\n44:42.600 --> 44:45.400\n a little bit more in detail, what the processes are.\n\n44:45.400 --> 44:49.800\n How does a, so like a unit, a cell is no longer\n\n44:49.800 --> 44:50.760\n evaluated alone.\n\n44:50.760 --> 44:52.800\n It's evaluated as part of a community,\n\n44:52.800 --> 44:54.760\n a multi cell organism.\n\n44:54.760 --> 44:57.320\n Even though it could reproduce, now it can't alone.\n\n44:57.320 --> 44:59.360\n It has to have that environment.\n\n44:59.360 --> 45:03.400\n So there's a push to another level, at least a selection.\n\n45:03.400 --> 45:04.760\n And how do you make that jump to the next level?\n\n45:04.760 --> 45:06.080\n Yes, how do you make the jump?\n\n45:06.080 --> 45:07.280\n As part of the algorithm.\n\n45:07.280 --> 45:08.200\n Yeah, yeah.\n\n45:08.200 --> 45:12.080\n So we haven't really seen that in computation yet.\n\n45:12.080 --> 45:15.800\n And there are certainly attempts to have open ended evolution.\n\n45:15.800 --> 45:18.400\n Things that could add more complexity\n\n45:18.400 --> 45:20.840\n and start selecting at a higher level.\n\n45:20.840 --> 45:24.680\n But it is still not quite the same\n\n45:24.680 --> 45:27.080\n as going from single to multi to society,\n\n45:27.080 --> 45:29.000\n for instance, in biology.\n\n45:29.000 --> 45:31.720\n So there essentially would be,\n\n45:31.720 --> 45:33.400\n as opposed to having one agent,\n\n45:33.400 --> 45:36.240\n those agent all of a sudden spontaneously decide\n\n45:36.240 --> 45:38.360\n to then be together.\n\n45:38.360 --> 45:42.360\n And then your entire system would then be treating them\n\n45:42.360 --> 45:43.560\n as one agent.\n\n45:43.560 --> 45:44.680\n Something like that.\n\n45:44.680 --> 45:46.320\n Some kind of weird merger building.\n\n45:46.320 --> 45:47.960\n But also, so you mentioned,\n\n45:47.960 --> 45:49.160\n I think you mentioned selection.\n\n45:49.160 --> 45:53.240\n So basically there's an agent and they don't get to live on\n\n45:53.240 --> 45:54.200\n if they don't do well.\n\n45:54.200 --> 45:56.320\n So there's some kind of measure of what doing well is\n\n45:56.320 --> 45:57.280\n and isn't.\n\n45:57.280 --> 46:02.280\n And does mutation come into play at all in the process\n\n46:02.880 --> 46:04.160\n and what in the world does it serve?\n\n46:04.160 --> 46:07.080\n Yeah, so, and again, back to what the computational\n\n46:07.080 --> 46:08.640\n mechanisms of evolution computation are.\n\n46:08.640 --> 46:12.720\n So the way to create variation,\n\n46:12.720 --> 46:15.120\n you can take multiple individuals, two usually,\n\n46:15.120 --> 46:17.200\n but you could do more.\n\n46:17.200 --> 46:20.840\n And you exchange the parts of the representation.\n\n46:20.840 --> 46:22.680\n You do some kind of recombination.\n\n46:22.680 --> 46:24.920\n Could be crossover, for instance.\n\n46:25.800 --> 46:30.040\n In biology, you do have DNA strings that are cut\n\n46:30.040 --> 46:32.080\n and put together again.\n\n46:32.080 --> 46:34.280\n We could do something like that.\n\n46:34.280 --> 46:37.400\n And it seems to be that in biology, the crossover\n\n46:37.400 --> 46:42.080\n is really the workhorse in biological evolution.\n\n46:42.080 --> 46:47.000\n In computation, we tend to rely more on mutation.\n\n46:47.000 --> 46:50.080\n And that is making random changes\n\n46:50.080 --> 46:51.280\n into parts of the chromosome.\n\n46:51.280 --> 46:55.000\n You can try to be intelligent and target certain areas\n\n46:55.000 --> 47:00.000\n of it and make the mutations also follow some principle.\n\n47:00.000 --> 47:03.480\n Like you collect statistics of performance and correlations\n\n47:03.480 --> 47:05.080\n and try to make mutations you believe\n\n47:05.080 --> 47:06.800\n are going to be helpful.\n\n47:06.800 --> 47:09.360\n That's where evolution computation has moved\n\n47:09.360 --> 47:11.080\n in the last 20 years.\n\n47:11.080 --> 47:12.920\n I mean, evolution computation has been around for 50 years,\n\n47:12.920 --> 47:15.160\n but a lot of the recent...\n\n47:15.160 --> 47:16.560\n Success comes from mutation.\n\n47:16.560 --> 47:19.240\n Yes, comes from using statistics.\n\n47:19.240 --> 47:22.040\n It's like the rest of machine learning based on statistics.\n\n47:22.040 --> 47:25.000\n We use similar tools to guide evolution computation.\n\n47:25.000 --> 47:27.680\n And in that sense, it has diverged a bit\n\n47:27.680 --> 47:30.040\n from biological evolution.\n\n47:30.040 --> 47:33.640\n And that's one of the things I think we could look at again,\n\n47:33.640 --> 47:37.840\n having a weaker selection, more crossover,\n\n47:37.840 --> 47:40.160\n large populations, more time,\n\n47:40.160 --> 47:42.200\n and maybe a different kind of creativity\n\n47:42.200 --> 47:43.320\n would come out of it.\n\n47:43.320 --> 47:46.360\n We are very impatient in evolution computation today.\n\n47:46.360 --> 47:48.920\n We want answers right now, right, quickly.\n\n47:48.920 --> 47:51.600\n And if somebody doesn't perform, kill it.\n\n47:51.600 --> 47:55.840\n And biological evolution doesn't work quite that way.\n\n47:55.840 --> 47:57.800\n And it's more patient.\n\n47:57.800 --> 48:00.000\n Yes, much more patient.\n\n48:00.000 --> 48:03.640\n So I guess we need to add some kind of mating,\n\n48:03.640 --> 48:05.920\n some kind of like dating mechanisms,\n\n48:05.920 --> 48:07.360\n like marriage maybe in there.\n\n48:07.360 --> 48:12.360\n So into our algorithms to improve the combination\n\n48:13.200 --> 48:15.960\n as opposed to all mutation doing all of the work.\n\n48:15.960 --> 48:18.880\n Yeah, and many ways of being successful.\n\n48:18.880 --> 48:21.560\n Usually in evolution computation, we have one goal,\n\n48:21.560 --> 48:25.880\n play this game really well compared to others.\n\n48:25.880 --> 48:28.640\n But in biology, there are many ways of being successful.\n\n48:28.640 --> 48:29.720\n You can build niches.\n\n48:29.720 --> 48:34.040\n You can be stronger, faster, larger, or smarter,\n\n48:34.040 --> 48:36.760\n or eat this or eat that.\n\n48:36.760 --> 48:40.560\n So there are many ways to solve the same problem of survival.\n\n48:40.560 --> 48:43.800\n And that then breeds creativity.\n\n48:43.800 --> 48:46.720\n And it allows more exploration.\n\n48:46.720 --> 48:48.680\n And eventually you get solutions\n\n48:48.680 --> 48:51.120\n that are perhaps more creative\n\n48:51.120 --> 48:54.120\n rather than trying to go from initial population directly\n\n48:54.120 --> 48:57.400\n or more or less directly to your maximum fitness,\n\n48:57.400 --> 49:00.840\n which you measure as just one metric.\n\n49:00.840 --> 49:05.840\n So in a broad sense, before we talk about neuroevolution,\n\n49:07.920 --> 49:11.200\n do you see evolutionary computation\n\n49:11.200 --> 49:14.160\n as more effective than deep learning in a certain context?\n\n49:14.160 --> 49:16.640\n Machine learning, broadly speaking.\n\n49:16.640 --> 49:18.680\n Maybe even supervised machine learning.\n\n49:18.680 --> 49:21.040\n I don't know if you want to draw any kind of lines\n\n49:21.040 --> 49:23.080\n and distinctions and borders\n\n49:23.080 --> 49:25.400\n where they rub up against each other kind of thing,\n\n49:25.400 --> 49:27.000\n where one is more effective than the other\n\n49:27.000 --> 49:28.440\n in the current state of things.\n\n49:28.440 --> 49:30.240\n Yes, of course, they are very different\n\n49:30.240 --> 49:32.280\n and they address different kinds of problems.\n\n49:32.280 --> 49:36.720\n And the deep learning has been really successful\n\n49:36.720 --> 49:38.720\n in domains where we have a lot of data.\n\n49:39.800 --> 49:42.440\n And that means not just data about situations,\n\n49:42.440 --> 49:45.120\n but also what the right answers were.\n\n49:45.120 --> 49:47.840\n So labeled examples, or they might be predictions,\n\n49:47.840 --> 49:51.720\n maybe weather prediction where the data itself becomes labels.\n\n49:51.720 --> 49:53.160\n What happened, what the weather was today\n\n49:53.160 --> 49:55.520\n and what it will be tomorrow.\n\n49:57.000 --> 49:59.240\n So they are very effective deep learning methods\n\n49:59.240 --> 50:01.400\n on that kind of tasks.\n\n50:01.400 --> 50:03.400\n But there are other kinds of tasks\n\n50:03.400 --> 50:06.360\n where we don't really know what the right answer is.\n\n50:06.360 --> 50:07.520\n Game playing, for instance,\n\n50:07.520 --> 50:12.520\n but many robotics tasks and actions in the world,\n\n50:12.840 --> 50:17.720\n decision making and actual practical applications,\n\n50:17.720 --> 50:19.480\n like treatments and healthcare\n\n50:19.480 --> 50:21.400\n or investment in stock market.\n\n50:21.400 --> 50:22.720\n Many tasks are like that.\n\n50:22.720 --> 50:24.880\n We don't know and we'll never know\n\n50:24.880 --> 50:26.680\n what the optimal answers were.\n\n50:26.680 --> 50:28.640\n And there you need different kinds of approach.\n\n50:28.640 --> 50:30.880\n Reinforcement learning is one of those.\n\n50:30.880 --> 50:33.800\n Reinforcement learning comes from biology as well.\n\n50:33.800 --> 50:35.440\n Agents learn during their lifetime.\n\n50:35.440 --> 50:37.600\n They eat berries and sometimes they get sick\n\n50:37.600 --> 50:40.320\n and then they don't and get stronger.\n\n50:40.320 --> 50:42.320\n And then that's how you learn.\n\n50:42.320 --> 50:46.080\n And evolution is also a mechanism like that\n\n50:46.080 --> 50:48.920\n at a different timescale because you have a population,\n\n50:48.920 --> 50:50.840\n not an individual during his lifetime,\n\n50:50.840 --> 50:52.560\n but an entire population as a whole\n\n50:52.560 --> 50:55.200\n can discover what works.\n\n50:55.200 --> 50:58.960\n And there you can afford individuals that don't work out.\n\n50:58.960 --> 51:00.600\n They will, you know, everybody dies\n\n51:00.600 --> 51:02.080\n and you have a next generation\n\n51:02.080 --> 51:04.120\n and they will be better than the previous one.\n\n51:04.120 --> 51:07.640\n So that's the big difference between these methods.\n\n51:07.640 --> 51:09.880\n They apply to different kinds of problems.\n\n51:10.920 --> 51:15.120\n And in particular, there's often a comparison\n\n51:15.120 --> 51:16.640\n that's kind of interesting and important\n\n51:16.640 --> 51:20.120\n between reinforcement learning and evolutionary computation.\n\n51:20.120 --> 51:23.400\n And initially, reinforcement learning\n\n51:23.400 --> 51:25.960\n was about individual learning during their lifetime.\n\n51:25.960 --> 51:28.160\n And evolution is more engineering.\n\n51:28.160 --> 51:29.720\n You don't care about the lifetime.\n\n51:29.720 --> 51:32.600\n You don't care about all the individuals that are tested.\n\n51:32.600 --> 51:34.520\n You only care about the final result.\n\n51:34.520 --> 51:39.280\n The last one, the best candidate that evolution produced.\n\n51:39.280 --> 51:42.520\n In that sense, they also apply to different kinds of problems.\n\n51:42.520 --> 51:46.160\n And now that boundary is starting to blur a bit.\n\n51:46.160 --> 51:48.680\n You can use evolution as an online method\n\n51:48.680 --> 51:51.520\n and reinforcement learning to create engineering solutions,\n\n51:51.520 --> 51:55.320\n but that's still roughly the distinction.\n\n51:55.320 --> 52:00.320\n And from the point of view of what algorithm you wanna use,\n\n52:00.320 --> 52:03.360\n if you have something where there is a cost for every trial,\n\n52:03.360 --> 52:06.120\n reinforcement learning might be your choice.\n\n52:06.120 --> 52:07.800\n Now, if you have a domain\n\n52:07.800 --> 52:10.280\n where you can use a surrogate perhaps,\n\n52:10.280 --> 52:13.600\n so you don't have much of a cost for trial,\n\n52:13.600 --> 52:16.520\n and you want to have surprises,\n\n52:16.520 --> 52:18.680\n you want to explore more broadly,\n\n52:18.680 --> 52:23.400\n then this population based method is perhaps a better choice\n\n52:23.400 --> 52:27.000\n because you can try things out that you wouldn't afford\n\n52:27.000 --> 52:28.600\n when you're doing reinforcement learning.\n\n52:28.600 --> 52:31.720\n There's very few things as entertaining\n\n52:31.720 --> 52:33.840\n as watching either evolutionary computation\n\n52:33.840 --> 52:37.360\n or reinforcement learning teaching a simulated robot to walk.\n\n52:37.360 --> 52:42.360\n Maybe there's a higher level question\n\n52:42.360 --> 52:43.600\n that could be asked here,\n\n52:43.600 --> 52:47.520\n but do you find this whole space of applications\n\n52:47.520 --> 52:51.720\n in the robotics interesting for evolution computation?\n\n52:51.720 --> 52:53.480\n Yeah, yeah, very much.\n\n52:53.480 --> 52:56.440\n And indeed, there are fascinating videos of that.\n\n52:56.440 --> 52:58.320\n And that's actually one of the examples\n\n52:58.320 --> 53:00.520\n where you can contrast the difference.\n\n53:00.520 --> 53:03.160\n Between reinforcement learning and evolution.\n\n53:03.160 --> 53:06.280\n Yes, so if you have a reinforcement learning agent,\n\n53:06.280 --> 53:07.960\n it tries to be conservative\n\n53:07.960 --> 53:11.800\n because it wants to walk as long as possible and be stable.\n\n53:11.800 --> 53:13.680\n But if you have evolutionary computation,\n\n53:13.680 --> 53:17.240\n it can afford these agents that go haywire.\n\n53:17.240 --> 53:20.920\n They fall flat on their face and they could take a step\n\n53:20.920 --> 53:23.160\n and then they jump and then again fall flat.\n\n53:23.160 --> 53:25.200\n And eventually what comes out of that\n\n53:25.200 --> 53:29.120\n is something like a falling that's controlled.\n\n53:29.120 --> 53:30.400\n You take another step and another step\n\n53:30.400 --> 53:32.280\n and you no longer fall.\n\n53:32.280 --> 53:34.160\n Instead you run, you go fast.\n\n53:34.160 --> 53:36.520\n So that's a way of discovering something\n\n53:36.520 --> 53:39.440\n that's hard to discover step by step incrementally.\n\n53:39.440 --> 53:43.640\n Because you can afford these evolutionist dead ends,\n\n53:43.640 --> 53:45.480\n although they are not entirely dead ends\n\n53:45.480 --> 53:47.720\n in the sense that they can serve as stepping stones.\n\n53:47.720 --> 53:49.840\n When you take two of those, put them together,\n\n53:49.840 --> 53:52.400\n you get something that works even better.\n\n53:52.400 --> 53:55.880\n And that is a great example of this kind of discovery.\n\n53:55.880 --> 53:58.120\n Yeah, learning to walk is fascinating.\n\n53:58.120 --> 54:01.360\n I talked quite a bit to Russ Tedrick who's at MIT.\n\n54:01.360 --> 54:03.400\n There's a community of folks\n\n54:03.400 --> 54:06.600\n who just roboticists who love the elegance\n\n54:06.600 --> 54:09.720\n and beauty of movement.\n\n54:09.720 --> 54:14.720\n And walking bipedal robotics is beautiful,\n\n54:17.480 --> 54:19.440\n but also exceptionally dangerous\n\n54:19.440 --> 54:22.800\n in the sense that like you're constantly falling essentially\n\n54:22.800 --> 54:25.320\n if you want to do elegant movement.\n\n54:25.320 --> 54:28.400\n And the discovery of that is,\n\n54:28.400 --> 54:33.400\n I mean, it's such a good example\n\n54:33.760 --> 54:37.440\n of that the discovery of a good solution\n\n54:37.440 --> 54:39.720\n sometimes requires a leap of faith and patience\n\n54:39.720 --> 54:41.440\n and all those kinds of things.\n\n54:41.440 --> 54:43.080\n I wonder what other spaces\n\n54:43.080 --> 54:46.280\n where you have to discover those kinds of things in.\n\n54:46.280 --> 54:48.840\n Yeah, another interesting direction\n\n54:48.840 --> 54:53.840\n is learning for virtual creatures, learning to walk.\n\n54:53.840 --> 54:57.640\n We did a study in simulation, obviously,\n\n54:57.640 --> 55:00.280\n that you create those creatures,\n\n55:00.280 --> 55:02.920\n not just their controller, but also their body.\n\n55:02.920 --> 55:05.600\n So you have cylinders, you have muscles,\n\n55:05.600 --> 55:08.840\n you have joints and sensors,\n\n55:08.840 --> 55:11.680\n and you're creating creatures that look quite different.\n\n55:11.680 --> 55:13.080\n Some of them have multiple legs.\n\n55:13.080 --> 55:15.280\n Some of them have no legs at all.\n\n55:15.280 --> 55:19.560\n And then the goal was to get them to move, to walk, to run.\n\n55:19.560 --> 55:22.040\n And what was interesting is that\n\n55:22.040 --> 55:26.200\n when you evolve the controller together with the body,\n\n55:26.200 --> 55:28.360\n you get movements that look natural\n\n55:28.360 --> 55:31.440\n because they're optimized for that physical setup.\n\n55:31.440 --> 55:33.960\n And these creatures, you start believing them\n\n55:33.960 --> 55:35.880\n that they're alive because they walk in a way\n\n55:35.880 --> 55:37.400\n that you would expect somebody\n\n55:37.400 --> 55:39.600\n with that kind of a setup to walk.\n\n55:39.600 --> 55:43.520\n Yeah, there's something subjective also about that, right?\n\n55:43.520 --> 55:45.000\n I've been thinking a lot about that,\n\n55:45.000 --> 55:50.000\n especially in the human robot interaction context.\n\n55:50.000 --> 55:55.000\n You know, I mentioned Spot, the Boston Dynamics robot.\n\n55:55.320 --> 55:58.480\n There is something about human robot communication.\n\n55:58.480 --> 56:00.560\n Let's say, let's put it in another context,\n\n56:00.560 --> 56:05.560\n something about human and dog context,\n\n56:05.560 --> 56:07.400\n like a living dog,\n\n56:07.400 --> 56:10.480\n where there's a dance of communication.\n\n56:10.480 --> 56:12.760\n First of all, the eyes, you both look at the same thing\n\n56:12.760 --> 56:15.240\n and the dogs communicate with their eyes as well.\n\n56:15.240 --> 56:18.480\n Like if you're a human,\n\n56:18.480 --> 56:23.480\n if you and a dog want to deal with a particular object,\n\n56:24.600 --> 56:26.240\n you will look at the person,\n\n56:26.240 --> 56:28.120\n the dog will look at you and then look at the object\n\n56:28.120 --> 56:30.360\n and look back at you, all those kinds of things.\n\n56:30.360 --> 56:33.280\n But there's also just the elegance of movement.\n\n56:33.280 --> 56:35.840\n I mean, there's the, of course, the tail\n\n56:35.840 --> 56:38.080\n and all those kinds of mechanisms of communication\n\n56:38.080 --> 56:41.920\n and it all seems natural and often joyful.\n\n56:41.920 --> 56:45.200\n And for robots to communicate that,\n\n56:45.200 --> 56:47.240\n it's really difficult how to figure that out\n\n56:47.240 --> 56:50.800\n because it's almost seems impossible to hard code in.\n\n56:50.800 --> 56:54.960\n You can hard code it for demo purpose or something like that,\n\n56:54.960 --> 56:58.120\n but it's essentially choreographed.\n\n56:58.120 --> 57:00.280\n Like if you watch some of the Boston Dynamics videos\n\n57:00.280 --> 57:01.760\n where they're dancing,\n\n57:01.760 --> 57:05.640\n all of that is choreographed by human beings.\n\n57:05.640 --> 57:09.360\n But to learn how to, with your movement,\n\n57:09.360 --> 57:14.360\n demonstrate a naturalness and elegance, that's fascinating.\n\n57:14.400 --> 57:15.720\n Of course, in the physical space,\n\n57:15.720 --> 57:18.960\n that's very difficult to do to learn the kind of scale\n\n57:18.960 --> 57:20.080\n that you're referring to,\n\n57:20.080 --> 57:23.080\n but the hope is that you could do that in simulation\n\n57:23.080 --> 57:25.360\n and then transfer it into the physical space\n\n57:25.360 --> 57:28.680\n if you're able to model the robot sufficiently naturally.\n\n57:28.680 --> 57:31.680\n Yeah, and sometimes I think that that requires\n\n57:31.680 --> 57:35.000\n a theory of mind on the side of the robot\n\n57:35.000 --> 57:38.920\n that they understand what you're doing\n\n57:38.920 --> 57:41.440\n because they themselves are doing something similar.\n\n57:41.440 --> 57:44.360\n And that's a big question too.\n\n57:44.360 --> 57:47.400\n We talked about intelligence in general\n\n57:47.400 --> 57:50.040\n and the social aspect of intelligence.\n\n57:50.040 --> 57:52.040\n And I think that's what is required\n\n57:52.040 --> 57:53.840\n that we humans understand other humans\n\n57:53.840 --> 57:57.040\n because we assume that they are similar to us.\n\n57:57.040 --> 57:59.120\n We have one simulation we did a while ago.\n\n57:59.120 --> 58:01.440\n Ken Stanley did that.\n\n58:01.440 --> 58:06.440\n Two robots that were competing simulation, like I said,\n\n58:06.600 --> 58:09.320\n they were foraging for food to gain energy.\n\n58:09.320 --> 58:10.680\n And then when they were really strong,\n\n58:10.680 --> 58:12.680\n they would bounce into the other robot\n\n58:12.680 --> 58:14.880\n and win if they were stronger.\n\n58:14.880 --> 58:17.320\n And we watched evolution discover\n\n58:17.320 --> 58:18.920\n more and more complex behaviors.\n\n58:18.920 --> 58:21.040\n They first went to the nearest food\n\n58:21.040 --> 58:24.320\n and then they started to plot a trajectory\n\n58:24.320 --> 58:28.440\n so they get more, but then they started to pay attention\n\n58:28.440 --> 58:30.280\n what the other robot was doing.\n\n58:30.280 --> 58:32.720\n And in the end, there was a behavior\n\n58:32.720 --> 58:35.820\n where one of the robots, the most sophisticated one,\n\n58:37.640 --> 58:40.200\n sensed where the food pieces were\n\n58:40.200 --> 58:42.080\n and identified that the other robot\n\n58:42.080 --> 58:46.000\n was close to two of a very far distance\n\n58:46.000 --> 58:48.720\n and there was one more food nearby.\n\n58:48.720 --> 58:53.380\n So it faked, now I'm using anthropomorphizing terms,\n\n58:53.380 --> 58:55.880\n but it made a move towards those other pieces\n\n58:55.880 --> 58:59.080\n in order for the other robot to actually go and get them\n\n58:59.080 --> 59:02.400\n because it knew that the last remaining piece of food\n\n59:02.400 --> 59:04.980\n was close and the other robot would have to travel\n\n59:04.980 --> 59:06.960\n a long way, lose its energy\n\n59:06.960 --> 59:10.440\n and then lose the whole competition.\n\n59:10.440 --> 59:12.680\n So there was like emergence of something\n\n59:12.680 --> 59:13.640\n like a theory of mind,\n\n59:13.640 --> 59:15.540\n knowing what the other robot would do,\n\n59:16.640 --> 59:19.440\n to guide it towards bad behavior in order to win.\n\n59:19.440 --> 59:22.960\n So we can get things like that happen in simulation as well.\n\n59:22.960 --> 59:25.280\n But that's a complete natural emergence\n\n59:25.280 --> 59:26.120\n of a theory of mind.\n\n59:26.120 --> 59:30.120\n But I feel like if you add a little bit of a place\n\n59:30.120 --> 59:34.400\n for a theory of mind to emerge like easier,\n\n59:34.400 --> 59:37.160\n then you can go really far.\n\n59:37.160 --> 59:41.240\n I mean, some of these things with evolution, you know,\n\n59:41.240 --> 59:45.480\n you add a little bit of design in there, it'll really help.\n\n59:45.480 --> 59:50.480\n And I tend to think that a very simple theory of mind\n\n59:50.780 --> 59:54.880\n will go a really long way for cooperation between agents\n\n59:54.880 --> 59:57.520\n and certainly for human robot interaction.\n\n59:57.520 --> 59:59.760\n Like it doesn't have to be super complicated.\n\n1:00:01.120 --> 1:00:03.520\n I've gotten a chance in the autonomous vehicle space\n\n1:00:03.520 --> 1:00:07.040\n to watch vehicles interact with pedestrians\n\n1:00:07.040 --> 1:00:09.920\n or pedestrians interacting with vehicles in general.\n\n1:00:09.920 --> 1:00:13.000\n I mean, you would think that there's a very complicated\n\n1:00:13.000 --> 1:00:15.760\n theory of mind thing going on, but I have a sense,\n\n1:00:15.760 --> 1:00:17.000\n it's not well understood yet,\n\n1:00:17.000 --> 1:00:19.480\n but I have a sense it's pretty dumb.\n\n1:00:19.480 --> 1:00:21.080\n Like it's pretty simple.\n\n1:00:22.320 --> 1:00:25.560\n There's a social contract there between humans,\n\n1:00:25.560 --> 1:00:28.180\n a human driver and a human crossing the road\n\n1:00:28.180 --> 1:00:32.000\n where the human crossing the road trusts\n\n1:00:32.000 --> 1:00:34.600\n that the human in the car is not going to murder them.\n\n1:00:34.600 --> 1:00:36.360\n And there's something about, again,\n\n1:00:36.360 --> 1:00:38.240\n back to that mortality thing.\n\n1:00:38.240 --> 1:00:43.240\n There's some dance of ethics and morality that's built in,\n\n1:00:45.640 --> 1:00:47.600\n that you're mapping your own morality\n\n1:00:47.600 --> 1:00:50.040\n onto the person in the car.\n\n1:00:50.040 --> 1:00:54.080\n And even if they're driving at a speed where you think\n\n1:00:54.080 --> 1:00:56.200\n if they don't stop, they're going to kill you,\n\n1:00:56.200 --> 1:00:58.160\n you trust that if you step in front of them,\n\n1:00:58.160 --> 1:00:59.440\n they're going to hit the brakes.\n\n1:00:59.440 --> 1:01:02.200\n And there's that weird dance that we do\n\n1:01:02.200 --> 1:01:04.680\n that I think is a pretty simple model,\n\n1:01:04.680 --> 1:01:08.480\n but of course it's very difficult to introspect what it is.\n\n1:01:08.480 --> 1:01:11.560\n And autonomous robots in the human robot interaction\n\n1:01:11.560 --> 1:01:13.800\n context have to build that.\n\n1:01:13.800 --> 1:01:17.320\n Current robots are much less than what you're describing.\n\n1:01:17.320 --> 1:01:19.360\n They're currently just afraid of everything.\n\n1:01:19.360 --> 1:01:22.560\n They're more, they're not the kind that fall\n\n1:01:22.560 --> 1:01:24.080\n and discover how to run.\n\n1:01:24.080 --> 1:01:26.800\n They're more like, please don't touch anything.\n\n1:01:26.800 --> 1:01:28.120\n Don't hurt anything.\n\n1:01:28.120 --> 1:01:30.200\n Stay as far away from humans as possible.\n\n1:01:30.200 --> 1:01:34.840\n Treat humans as ballistic objects that you can't,\n\n1:01:34.840 --> 1:01:38.760\n that you do with a large spatial envelope,\n\n1:01:38.760 --> 1:01:40.800\n make sure you do not collide with.\n\n1:01:40.800 --> 1:01:42.000\n That's how, like you mentioned,\n\n1:01:42.000 --> 1:01:45.360\n Elon Musk thinks about autonomous vehicles.\n\n1:01:45.360 --> 1:01:48.100\n I tend to think autonomous vehicles need to have\n\n1:01:48.100 --> 1:01:50.680\n a beautiful dance between human and machine,\n\n1:01:50.680 --> 1:01:53.320\n where it's not just the collision avoidance problem,\n\n1:01:53.320 --> 1:01:55.920\n but a weird dance.\n\n1:01:55.920 --> 1:02:00.000\n Yeah, I think these systems need to be able to predict\n\n1:02:00.000 --> 1:02:02.320\n what will happen, what the other agent is going to do,\n\n1:02:02.320 --> 1:02:06.440\n and then have a structure of what the goals are\n\n1:02:06.440 --> 1:02:08.440\n and whether those predictions actually meet the goals.\n\n1:02:08.440 --> 1:02:10.860\n And you can go probably pretty far\n\n1:02:10.860 --> 1:02:13.600\n with that relatively simple setup already,\n\n1:02:13.600 --> 1:02:16.200\n but to call it a theory of mind, I don't think you need to.\n\n1:02:16.200 --> 1:02:18.360\n I mean, it doesn't matter whether the pedestrian\n\n1:02:18.360 --> 1:02:20.080\n has a mind, it's an object,\n\n1:02:20.080 --> 1:02:21.840\n and we can predict what we will do.\n\n1:02:21.840 --> 1:02:23.720\n And then we can predict what the states will be\n\n1:02:23.720 --> 1:02:26.180\n in the future and whether they are desirable states.\n\n1:02:26.180 --> 1:02:27.960\n Stay away from those that are undesirable\n\n1:02:27.960 --> 1:02:29.720\n and go towards those that are desirable.\n\n1:02:29.720 --> 1:02:34.520\n So it's a relatively simple functional approach to that.\n\n1:02:34.520 --> 1:02:37.020\n Where do we really need the theory of mind?\n\n1:02:37.920 --> 1:02:40.940\n Maybe when you start interacting\n\n1:02:40.940 --> 1:02:44.160\n and you're trying to get the other agent to do something\n\n1:02:44.160 --> 1:02:46.480\n and jointly, so that you can jointly,\n\n1:02:46.480 --> 1:02:48.380\n collaboratively achieve something,\n\n1:02:48.380 --> 1:02:50.560\n then it becomes more complex.\n\n1:02:50.560 --> 1:02:51.880\n Well, I mean, even with the pedestrians,\n\n1:02:51.880 --> 1:02:54.780\n you have to have a sense of where their attention,\n\n1:02:54.780 --> 1:02:57.840\n actual attention in terms of their gaze is,\n\n1:02:57.840 --> 1:03:00.480\n but also there's this vision science,\n\n1:03:00.480 --> 1:03:01.600\n people talk about this all the time.\n\n1:03:01.600 --> 1:03:02.800\n Just because I'm looking at it\n\n1:03:02.800 --> 1:03:04.680\n doesn't mean I'm paying attention to it.\n\n1:03:04.680 --> 1:03:07.400\n So figuring out what is the person looking at?\n\n1:03:07.400 --> 1:03:09.840\n What is the sensory information they've taken in?\n\n1:03:09.840 --> 1:03:12.500\n And the theory of mind piece comes in is\n\n1:03:12.500 --> 1:03:16.480\n what are they actually attending to cognitively?\n\n1:03:16.480 --> 1:03:19.000\n And also what are they thinking about?\n\n1:03:19.000 --> 1:03:21.200\n Like what is the computation they're performing?\n\n1:03:21.200 --> 1:03:24.280\n And you have probably maybe a few options\n\n1:03:24.280 --> 1:03:28.280\n for the pedestrian crossing.\n\n1:03:28.280 --> 1:03:29.280\n It doesn't have to be,\n\n1:03:29.280 --> 1:03:31.800\n it's like a variable with a few discrete states,\n\n1:03:31.800 --> 1:03:33.320\n but you have to have a good estimation\n\n1:03:33.320 --> 1:03:35.520\n which of the states that brain is in\n\n1:03:35.520 --> 1:03:36.640\n for the pedestrian case.\n\n1:03:36.640 --> 1:03:39.280\n And the same is for attending with a robot.\n\n1:03:39.280 --> 1:03:42.000\n If you're collaborating to pick up an object,\n\n1:03:42.000 --> 1:03:44.740\n you have to figure out is the human,\n\n1:03:44.740 --> 1:03:47.640\n like there's a few discrete states\n\n1:03:47.640 --> 1:03:48.600\n that the human could be in.\n\n1:03:48.600 --> 1:03:52.120\n You have to predict that by observing the human.\n\n1:03:52.120 --> 1:03:54.000\n And that seems like a machine learning problem\n\n1:03:54.000 --> 1:03:59.000\n to figure out what's the human up to.\n\n1:03:59.280 --> 1:04:02.160\n It's not as simple as sort of planning\n\n1:04:02.160 --> 1:04:03.920\n just because they move their arm\n\n1:04:03.920 --> 1:04:06.840\n means the arm will continue moving in this direction.\n\n1:04:06.840 --> 1:04:08.560\n You have to really have a model\n\n1:04:08.560 --> 1:04:09.880\n of what they're thinking about\n\n1:04:09.880 --> 1:04:12.520\n and what's the motivation behind the movement of the arm.\n\n1:04:12.520 --> 1:04:16.560\n Here we are talking about relatively simple physical actions,\n\n1:04:16.560 --> 1:04:19.280\n but you can take that the higher levels also\n\n1:04:19.280 --> 1:04:21.760\n like to predict what the people are going to do,\n\n1:04:21.760 --> 1:04:26.080\n you need to know what their goals are.\n\n1:04:26.080 --> 1:04:27.980\n What are they trying to, are they exercising?\n\n1:04:27.980 --> 1:04:29.440\n Are they just starting to get somewhere?\n\n1:04:29.440 --> 1:04:30.880\n But even higher level, I mean,\n\n1:04:30.880 --> 1:04:33.920\n you are predicting what people will do in their career,\n\n1:04:33.920 --> 1:04:35.120\n what their life themes are.\n\n1:04:35.120 --> 1:04:37.800\n Do they want to be famous, rich, or do good?\n\n1:04:37.800 --> 1:04:40.600\n And that takes a lot more information,\n\n1:04:40.600 --> 1:04:43.380\n but it allows you to then predict their actions,\n\n1:04:43.380 --> 1:04:44.820\n what choices they might make.\n\n1:04:45.720 --> 1:04:49.200\n So how does evolution and computation apply\n\n1:04:49.200 --> 1:04:50.800\n to the world of neural networks?\n\n1:04:50.800 --> 1:04:53.440\n I've seen quite a bit of work from you and others\n\n1:04:53.440 --> 1:04:55.520\n in the world of neural evolution.\n\n1:04:55.520 --> 1:04:58.600\n So maybe first, can you say, what is this field?\n\n1:04:58.600 --> 1:05:02.880\n Yeah, neural evolution is a combination of neural networks\n\n1:05:02.880 --> 1:05:05.460\n and evolution computation in many different forms,\n\n1:05:05.460 --> 1:05:10.460\n but the early versions were simply using evolution\n\n1:05:11.840 --> 1:05:13.920\n as a way to construct a neural network\n\n1:05:13.920 --> 1:05:17.200\n instead of say, stochastic gradient descent\n\n1:05:17.200 --> 1:05:18.340\n or backpropagation.\n\n1:05:18.340 --> 1:05:21.460\n Because evolution can evolve these parameters,\n\n1:05:21.460 --> 1:05:22.980\n weight values in a neural network,\n\n1:05:22.980 --> 1:05:26.260\n just like any other string of numbers, you can do that.\n\n1:05:26.260 --> 1:05:29.700\n And that's useful because some cases you don't have\n\n1:05:29.700 --> 1:05:33.780\n those targets that you need to backpropagate from.\n\n1:05:33.780 --> 1:05:35.940\n And it might be an agent that's running a maze\n\n1:05:35.940 --> 1:05:38.780\n or a robot playing a game or something.\n\n1:05:38.780 --> 1:05:41.060\n You don't, again, you don't know what the right answers are,\n\n1:05:41.060 --> 1:05:42.100\n you don't have backprop,\n\n1:05:42.100 --> 1:05:44.820\n but this way you can still evolve a neural net.\n\n1:05:44.820 --> 1:05:47.460\n And neural networks are really good at these tasks,\n\n1:05:47.460 --> 1:05:49.900\n because they recognize patterns\n\n1:05:49.900 --> 1:05:53.860\n and they generalize, interpolate between known situations.\n\n1:05:53.860 --> 1:05:56.380\n So you want to have a neural network in such a task,\n\n1:05:56.380 --> 1:05:59.140\n even if you don't have a supervised targets.\n\n1:05:59.140 --> 1:06:01.180\n So that's a reason and that's a solution.\n\n1:06:01.180 --> 1:06:02.580\n And also more recently,\n\n1:06:02.580 --> 1:06:05.620\n now when we have all this deep learning literature,\n\n1:06:05.620 --> 1:06:07.500\n it turns out that we can use evolution\n\n1:06:07.500 --> 1:06:11.180\n to optimize many aspects of those designs.\n\n1:06:11.180 --> 1:06:14.980\n The deep learning architectures have become so complex\n\n1:06:14.980 --> 1:06:17.420\n that there's little hope for us little humans\n\n1:06:17.420 --> 1:06:18.780\n to understand their complexity\n\n1:06:18.780 --> 1:06:21.380\n and what actually makes a good design.\n\n1:06:21.380 --> 1:06:24.500\n And now we can use evolution to give that design for you.\n\n1:06:24.500 --> 1:06:28.380\n And it might mean optimizing hyperparameters,\n\n1:06:28.380 --> 1:06:30.660\n like the depth of layers and so on,\n\n1:06:30.660 --> 1:06:33.340\n or the topology of the network,\n\n1:06:33.340 --> 1:06:35.260\n how many layers, how they're connected,\n\n1:06:35.260 --> 1:06:37.580\n but also other aspects like what activation functions\n\n1:06:37.580 --> 1:06:40.620\n you use where in the network during the learning process,\n\n1:06:40.620 --> 1:06:42.420\n or what loss function you use,\n\n1:06:42.420 --> 1:06:43.740\n you could generalize that.\n\n1:06:43.740 --> 1:06:47.580\n You could generate that, even data augmentation,\n\n1:06:47.580 --> 1:06:49.940\n all the different aspects of the design\n\n1:06:49.940 --> 1:06:53.740\n of deep learning experiments could be optimized that way.\n\n1:06:53.740 --> 1:06:56.940\n So that's an interaction between two mechanisms.\n\n1:06:56.940 --> 1:07:00.780\n But there's also, when we get more into cognitive science\n\n1:07:00.780 --> 1:07:02.540\n and the topics that we've been talking about,\n\n1:07:02.540 --> 1:07:04.300\n you could have learning mechanisms\n\n1:07:04.300 --> 1:07:06.140\n at two level timescales.\n\n1:07:06.140 --> 1:07:07.900\n So you do have an evolution\n\n1:07:07.900 --> 1:07:10.580\n that gives you baby neural networks\n\n1:07:10.580 --> 1:07:12.860\n that then learn during their lifetime.\n\n1:07:12.860 --> 1:07:15.900\n And you have this interaction of two timescales.\n\n1:07:15.900 --> 1:07:18.460\n And I think that can potentially be really powerful.\n\n1:07:19.340 --> 1:07:23.420\n Now, in biology, we are not born with all our faculties.\n\n1:07:23.420 --> 1:07:25.380\n We have to learn, we have a developmental period.\n\n1:07:25.380 --> 1:07:29.300\n In humans, it's really long and most animals have something.\n\n1:07:29.300 --> 1:07:32.700\n And probably the reason is that evolution of DNA\n\n1:07:32.700 --> 1:07:36.660\n is not detailed enough or plentiful enough to describe them.\n\n1:07:36.660 --> 1:07:38.780\n We can describe how to set the brain up,\n\n1:07:38.780 --> 1:07:43.780\n but we can, evolution can decide on a starting point\n\n1:07:44.300 --> 1:07:46.140\n and then have a learning algorithm\n\n1:07:46.140 --> 1:07:48.900\n that will construct the final product.\n\n1:07:48.900 --> 1:07:53.900\n And this interaction of intelligent, well,\n\n1:07:54.140 --> 1:07:56.660\n evolution that has produced a good starting point\n\n1:07:56.660 --> 1:07:59.740\n for the specific purpose of learning from it\n\n1:07:59.740 --> 1:08:02.220\n with the interaction with the environment,\n\n1:08:02.220 --> 1:08:03.660\n that can be a really powerful mechanism\n\n1:08:03.660 --> 1:08:06.980\n for constructing brains and constructing behaviors.\n\n1:08:06.980 --> 1:08:10.060\n I like how you walk back from intelligence.\n\n1:08:10.060 --> 1:08:12.380\n So optimize starting point, maybe.\n\n1:08:12.380 --> 1:08:17.380\n Yeah, okay, there's a lot of fascinating things to ask here.\n\n1:08:18.540 --> 1:08:22.100\n And this is basically this dance between neural networks\n\n1:08:22.100 --> 1:08:23.420\n and evolution and computation\n\n1:08:23.420 --> 1:08:26.260\n could go into the category of automated machine learning\n\n1:08:26.260 --> 1:08:28.860\n to where you're optimizing,\n\n1:08:28.860 --> 1:08:31.020\n whether it's hyperparameters of the topology\n\n1:08:31.020 --> 1:08:33.540\n or hyperparameters taken broadly.\n\n1:08:34.420 --> 1:08:36.380\n But the topology thing is really interesting.\n\n1:08:36.380 --> 1:08:40.260\n I mean, that's not really done that effectively\n\n1:08:40.260 --> 1:08:41.900\n or throughout the history of machine learning\n\n1:08:41.900 --> 1:08:43.300\n has not been done.\n\n1:08:43.300 --> 1:08:45.020\n Usually there's a fixed architecture.\n\n1:08:45.020 --> 1:08:47.300\n Maybe there's a few components you're playing with,\n\n1:08:47.300 --> 1:08:50.140\n but to grow a neural network, essentially,\n\n1:08:50.140 --> 1:08:52.940\n the way you grow an organism is really fascinating space.\n\n1:08:52.940 --> 1:08:57.940\n How hard is it, do you think, to grow a neural network?\n\n1:08:58.060 --> 1:09:00.860\n And maybe what kind of neural networks\n\n1:09:00.860 --> 1:09:04.700\n are more amenable to this kind of idea than others?\n\n1:09:04.700 --> 1:09:06.980\n I've seen quite a bit of work on recurrent neural networks.\n\n1:09:06.980 --> 1:09:10.940\n Is there some architectures that are friendlier than others?\n\n1:09:10.940 --> 1:09:15.300\n And is this just a fun, small scale set of experiments\n\n1:09:15.300 --> 1:09:18.780\n or do you have hope that we can be able to grow\n\n1:09:18.780 --> 1:09:20.300\n powerful neural networks?\n\n1:09:20.300 --> 1:09:21.780\n I think we can.\n\n1:09:21.780 --> 1:09:24.820\n And most of the work up to now\n\n1:09:24.820 --> 1:09:27.060\n is taking architectures that already exist\n\n1:09:27.060 --> 1:09:30.900\n that humans have designed and try to optimize them further.\n\n1:09:30.900 --> 1:09:32.860\n And you can totally do that.\n\n1:09:32.860 --> 1:09:34.260\n A few years ago, we did an experiment.\n\n1:09:34.260 --> 1:09:39.260\n We took a winner of the image captioning competition\n\n1:09:39.260 --> 1:09:42.620\n and the architecture and just broke it into pieces\n\n1:09:42.620 --> 1:09:43.740\n and took the pieces.\n\n1:09:43.740 --> 1:09:45.500\n And that was our search base.\n\n1:09:45.500 --> 1:09:46.700\n See if you can do better.\n\n1:09:46.700 --> 1:09:49.300\n And we indeed could, 15% better performance\n\n1:09:49.300 --> 1:09:52.740\n by just searching around the network design\n\n1:09:52.740 --> 1:09:53.980\n that humans had come up with,\n\n1:09:53.980 --> 1:09:56.300\n Oreo vinyls and others.\n\n1:09:56.300 --> 1:09:59.220\n So, but that's starting from a point\n\n1:09:59.220 --> 1:10:00.820\n that humans have produced,\n\n1:10:00.820 --> 1:10:03.500\n but we could do something more general.\n\n1:10:03.500 --> 1:10:05.820\n It doesn't have to be that kind of network.\n\n1:10:05.820 --> 1:10:08.820\n The hard part is, there are a couple of challenges.\n\n1:10:08.820 --> 1:10:10.740\n One of them is to define the search base.\n\n1:10:10.740 --> 1:10:14.620\n What are your elements and how you put them together.\n\n1:10:14.620 --> 1:10:18.900\n And the space is just really, really big.\n\n1:10:18.900 --> 1:10:21.020\n So you have to somehow constrain it\n\n1:10:21.020 --> 1:10:23.340\n and have some hunch what will work\n\n1:10:23.340 --> 1:10:25.380\n because otherwise everything is possible.\n\n1:10:25.380 --> 1:10:28.540\n And another challenge is that in order to evaluate\n\n1:10:28.540 --> 1:10:32.260\n how good your design is, you have to train it.\n\n1:10:32.260 --> 1:10:34.980\n I mean, you have to actually try it out.\n\n1:10:34.980 --> 1:10:37.260\n And that's currently very expensive, right?\n\n1:10:37.260 --> 1:10:40.380\n I mean, deep learning networks may take days to train\n\n1:10:40.380 --> 1:10:42.260\n while imagine you having a population of a hundred\n\n1:10:42.260 --> 1:10:44.660\n and have to run it for a hundred generations.\n\n1:10:44.660 --> 1:10:48.020\n It's not yet quite feasible computationally.\n\n1:10:48.020 --> 1:10:51.620\n It will be, but also there's a large carbon footprint\n\n1:10:51.620 --> 1:10:52.460\n and all that.\n\n1:10:52.460 --> 1:10:54.300\n I mean, we are using a lot of computation for doing it.\n\n1:10:54.300 --> 1:10:57.540\n So intelligent methods and intelligent,\n\n1:10:57.540 --> 1:11:00.580\n I mean, we have to do some science\n\n1:11:00.580 --> 1:11:03.580\n in order to figure out what the right representations are\n\n1:11:03.580 --> 1:11:07.300\n and right operators are, and how do we evaluate them\n\n1:11:07.300 --> 1:11:09.180\n without having to fully train them.\n\n1:11:09.180 --> 1:11:11.380\n And that is where the current research is\n\n1:11:11.380 --> 1:11:13.580\n and we're making progress on all those fronts.\n\n1:11:14.460 --> 1:11:17.860\n So yes, there are certain architectures\n\n1:11:17.860 --> 1:11:20.940\n that are more amenable to that approach,\n\n1:11:20.940 --> 1:11:23.580\n but also I think we can create our own architecture\n\n1:11:23.580 --> 1:11:26.300\n and all representations that are even better at that.\n\n1:11:26.300 --> 1:11:30.180\n And do you think it's possible to do like a tiny baby network\n\n1:11:30.180 --> 1:11:32.700\n that grows into something that can do state of the art\n\n1:11:32.700 --> 1:11:35.380\n on like even the simple data set like MNIST,\n\n1:11:35.380 --> 1:11:39.900\n and just like it just grows into a gigantic monster\n\n1:11:39.900 --> 1:11:42.460\n that's the world's greatest handwriting recognition system?\n\n1:11:42.460 --> 1:11:44.340\n Yeah, there are approaches like that.\n\n1:11:44.340 --> 1:11:45.980\n Esteban Real and Cochlear for instance,\n\n1:11:45.980 --> 1:11:48.500\n I worked on evolving a smaller network\n\n1:11:48.500 --> 1:11:51.940\n and then systematically expanding it to a larger one.\n\n1:11:51.940 --> 1:11:54.980\n Your elements are already there and scaling it up\n\n1:11:54.980 --> 1:11:56.500\n will just give you more power.\n\n1:11:56.500 --> 1:11:59.340\n So again, evolution gives you that starting point\n\n1:11:59.340 --> 1:12:02.820\n and then there's a mechanism that gives you the final result\n\n1:12:02.820 --> 1:12:04.580\n and a very powerful approach.\n\n1:12:05.980 --> 1:12:10.980\n But you could also simulate the actual growth process.\n\n1:12:12.660 --> 1:12:15.340\n And like I said before, evolving a starting point\n\n1:12:15.340 --> 1:12:18.420\n and then evolving or training the network,\n\n1:12:18.420 --> 1:12:21.980\n there's not that much work that's been done on that yet.\n\n1:12:21.980 --> 1:12:24.660\n We need some kind of a simulation environment\n\n1:12:24.660 --> 1:12:27.420\n so the interactions at will,\n\n1:12:27.420 --> 1:12:29.540\n the supervised environment doesn't really,\n\n1:12:29.540 --> 1:12:33.060\n it's not as easily usable here.\n\n1:12:33.060 --> 1:12:35.580\n Sorry, the interaction between neural networks?\n\n1:12:35.580 --> 1:12:37.300\n Yeah, the neural networks that you're creating,\n\n1:12:37.300 --> 1:12:39.020\n interacting with the world\n\n1:12:39.020 --> 1:12:43.060\n and learning from these sequences of interactions,\n\n1:12:43.060 --> 1:12:44.700\n perhaps communication with others.\n\n1:12:46.900 --> 1:12:47.740\n That's awesome.\n\n1:12:47.740 --> 1:12:48.900\n We would like to get there,\n\n1:12:48.900 --> 1:12:51.620\n but just the task of simulating something\n\n1:12:51.620 --> 1:12:53.260\n is at that level is very hard.\n\n1:12:53.260 --> 1:12:54.100\n It's very difficult.\n\n1:12:54.100 --> 1:12:55.420\n I love the idea.\n\n1:12:55.420 --> 1:12:58.220\n I mean, one of the powerful things about evolution\n\n1:12:58.220 --> 1:13:01.300\n on Earth is the predators and prey emerged.\n\n1:13:01.300 --> 1:13:03.540\n And like there's just like,\n\n1:13:03.540 --> 1:13:05.340\n there's bigger fish and smaller fish\n\n1:13:05.340 --> 1:13:07.100\n and it's fascinating to think\n\n1:13:07.100 --> 1:13:08.900\n that you could have neural networks competing\n\n1:13:08.900 --> 1:13:10.340\n against each other in one neural network\n\n1:13:10.340 --> 1:13:12.260\n being able to destroy another one.\n\n1:13:12.260 --> 1:13:14.860\n There's like wars of neural networks competing\n\n1:13:14.860 --> 1:13:16.820\n to solve the MNIST problem, I don't know.\n\n1:13:16.820 --> 1:13:17.900\n Yeah, yeah.\n\n1:13:17.900 --> 1:13:19.260\n Oh, totally, yeah, yeah, yeah.\n\n1:13:19.260 --> 1:13:22.700\n And we actually simulated also that prey\n\n1:13:22.700 --> 1:13:25.220\n and it was interesting what happened there,\n\n1:13:25.220 --> 1:13:26.900\n Padmini Rajagopalan did this\n\n1:13:26.900 --> 1:13:29.580\n and Kay Holkamp was a zoologist.\n\n1:13:29.580 --> 1:13:31.060\n So we had, again,\n\n1:13:33.940 --> 1:13:37.420\n we had simulated hyenas, simulated zebras.\n\n1:13:37.420 --> 1:13:38.260\n Nice.\n\n1:13:38.260 --> 1:13:42.860\n And initially, the hyenas just tried to hunt them\n\n1:13:42.860 --> 1:13:45.340\n and when they actually stumbled upon the zebra,\n\n1:13:45.340 --> 1:13:47.700\n they ate it and were happy.\n\n1:13:47.700 --> 1:13:51.540\n And then the zebras learned to escape\n\n1:13:51.540 --> 1:13:54.300\n and the hyenas learned to team up.\n\n1:13:54.300 --> 1:13:55.700\n And actually two of them approached\n\n1:13:55.700 --> 1:13:56.900\n in different directions.\n\n1:13:56.900 --> 1:13:59.020\n And now the zebras, their next step,\n\n1:13:59.020 --> 1:14:02.820\n they generated a behavior where they split\n\n1:14:02.820 --> 1:14:03.900\n in different directions,\n\n1:14:03.900 --> 1:14:06.220\n just like actually gazelles do\n\n1:14:07.380 --> 1:14:08.420\n when they are being hunted.\n\n1:14:08.420 --> 1:14:09.620\n They confuse the predator\n\n1:14:09.620 --> 1:14:10.940\n by going in different directions.\n\n1:14:10.940 --> 1:14:14.380\n That emerged and then more hyenas joined\n\n1:14:14.380 --> 1:14:16.540\n and kind of circled them.\n\n1:14:16.540 --> 1:14:18.820\n And then when they circled them,\n\n1:14:18.820 --> 1:14:21.060\n they could actually herd the zebras together\n\n1:14:21.060 --> 1:14:23.540\n and eat multiple zebras.\n\n1:14:23.540 --> 1:14:28.340\n So there was like an arms race of predators and prey.\n\n1:14:28.340 --> 1:14:31.020\n And they gradually developed more complex behaviors,\n\n1:14:31.020 --> 1:14:33.860\n some of which we actually do see in nature.\n\n1:14:33.860 --> 1:14:36.820\n And this kind of coevolution,\n\n1:14:36.820 --> 1:14:38.060\n that's competitive coevolution,\n\n1:14:38.060 --> 1:14:39.580\n it's a fascinating topic\n\n1:14:39.580 --> 1:14:42.900\n because there's a promise or possibility\n\n1:14:42.900 --> 1:14:45.540\n that you will discover something new\n\n1:14:45.540 --> 1:14:46.460\n that you don't already know.\n\n1:14:46.460 --> 1:14:48.100\n You didn't build it in.\n\n1:14:48.100 --> 1:14:50.700\n It came from this arms race.\n\n1:14:50.700 --> 1:14:52.500\n It's hard to keep the arms race going.\n\n1:14:52.500 --> 1:14:55.300\n It's hard to have rich enough simulation\n\n1:14:55.300 --> 1:14:58.260\n that supports all of these complex behaviors.\n\n1:14:58.260 --> 1:15:00.020\n But at least for several steps,\n\n1:15:00.020 --> 1:15:03.580\n we've already seen it in this predator prey scenario, yeah.\n\n1:15:03.580 --> 1:15:06.260\n First of all, it's fascinating to think about this context\n\n1:15:06.260 --> 1:15:09.580\n in terms of evolving architectures.\n\n1:15:09.580 --> 1:15:12.700\n So I've studied Tesla autopilot for a long time.\n\n1:15:12.700 --> 1:15:17.540\n It's one particular implementation of an AI system\n\n1:15:17.540 --> 1:15:18.820\n that's operating in the real world.\n\n1:15:18.820 --> 1:15:20.940\n I find it fascinating because of the scale\n\n1:15:20.940 --> 1:15:23.340\n at which it's used out in the real world.\n\n1:15:23.340 --> 1:15:26.220\n And I'm not sure if you're familiar with that system much,\n\n1:15:26.220 --> 1:15:28.540\n but, you know, Andre Kapathy leads that team\n\n1:15:28.540 --> 1:15:30.060\n on the machine learning side.\n\n1:15:30.060 --> 1:15:34.900\n And there's a multitask network, multiheaded network,\n\n1:15:34.900 --> 1:15:38.900\n where there's a core, but it's trained on particular tasks.\n\n1:15:38.900 --> 1:15:40.260\n And there's a bunch of different heads\n\n1:15:40.260 --> 1:15:41.740\n that are trained on that.\n\n1:15:41.740 --> 1:15:46.260\n Is there some lessons from evolutionary computation\n\n1:15:46.260 --> 1:15:48.340\n or neuroevolution that could be applied\n\n1:15:48.340 --> 1:15:50.940\n to this kind of multiheaded beast\n\n1:15:50.940 --> 1:15:52.460\n that's operating in the real world?\n\n1:15:52.460 --> 1:15:55.700\n Yes, it's a very good problem for neuroevolution.\n\n1:15:56.580 --> 1:15:59.500\n And the reason is that when you have multiple tasks,\n\n1:16:00.660 --> 1:16:01.980\n they support each other.\n\n1:16:02.860 --> 1:16:07.860\n So let's say you're learning to classify X ray images\n\n1:16:08.020 --> 1:16:09.500\n to different pathologies.\n\n1:16:09.500 --> 1:16:13.820\n So you have one task is to classify this disease\n\n1:16:13.820 --> 1:16:15.900\n and another one, this disease, another one, this one.\n\n1:16:15.900 --> 1:16:18.420\n And when you're learning from one disease,\n\n1:16:19.300 --> 1:16:21.620\n that forces certain kinds of internal representations\n\n1:16:21.620 --> 1:16:24.820\n and embeddings, and they can serve\n\n1:16:24.820 --> 1:16:27.580\n as a helpful starting point for the other tasks.\n\n1:16:27.580 --> 1:16:30.940\n So you are combining the wisdom of multiple tasks\n\n1:16:30.940 --> 1:16:32.380\n into these representations.\n\n1:16:32.380 --> 1:16:34.300\n And it turns out that you can do better\n\n1:16:34.300 --> 1:16:35.860\n in each of these tasks\n\n1:16:35.860 --> 1:16:38.060\n when you are learning simultaneously other tasks\n\n1:16:38.060 --> 1:16:39.820\n than you would by one task alone.\n\n1:16:39.820 --> 1:16:41.700\n Which is a fascinating idea in itself, yeah.\n\n1:16:41.700 --> 1:16:43.820\n Yes, and people do that all the time.\n\n1:16:43.820 --> 1:16:46.020\n I mean, you use knowledge of domains that you know\n\n1:16:46.020 --> 1:16:49.700\n in new domains, and certainly neural network can do that.\n\n1:16:49.700 --> 1:16:52.300\n When neuroevolution comes in is that,\n\n1:16:52.300 --> 1:16:55.140\n what's the best way to combine these tasks?\n\n1:16:55.140 --> 1:16:58.140\n Now there's architectural design that allow you to decide\n\n1:16:58.140 --> 1:17:01.420\n where and how the embeddings,\n\n1:17:01.420 --> 1:17:03.300\n the internal representations are combined\n\n1:17:03.300 --> 1:17:05.980\n and how much you combine them.\n\n1:17:05.980 --> 1:17:08.020\n And there's quite a bit of research on that.\n\n1:17:08.020 --> 1:17:11.380\n And my team, Elliot Meyerson has worked on that\n\n1:17:11.380 --> 1:17:14.860\n in particular, like what is a good internal representation\n\n1:17:14.860 --> 1:17:17.140\n that supports multiple tasks?\n\n1:17:17.140 --> 1:17:20.620\n And we're getting to understand how that's constructed\n\n1:17:20.620 --> 1:17:24.100\n and what's in it, so that it is in a space\n\n1:17:24.100 --> 1:17:27.260\n that supports multiple different heads, like you said.\n\n1:17:28.260 --> 1:17:31.780\n And that I think is fundamentally\n\n1:17:31.780 --> 1:17:34.380\n how biological intelligence works as well.\n\n1:17:34.380 --> 1:17:38.020\n You don't build a representation just for one task.\n\n1:17:38.020 --> 1:17:40.100\n You try to build something that's general,\n\n1:17:40.100 --> 1:17:42.740\n not only so that you can do better in one task\n\n1:17:42.740 --> 1:17:45.060\n or multiple tasks, but also future tasks\n\n1:17:45.060 --> 1:17:46.380\n and future challenges.\n\n1:17:46.380 --> 1:17:50.180\n So you learn the structure of the world\n\n1:17:50.180 --> 1:17:54.020\n and that helps you in all kinds of future challenges.\n\n1:17:54.020 --> 1:17:56.100\n And so you're trying to design a representation\n\n1:17:56.100 --> 1:17:58.420\n that will support an arbitrary set of tasks\n\n1:17:58.420 --> 1:18:01.020\n in a particular sort of class of problem.\n\n1:18:01.020 --> 1:18:03.100\n Yeah, and also it turns out,\n\n1:18:03.100 --> 1:18:05.980\n and that's again, a surprise that Elliot found\n\n1:18:05.980 --> 1:18:10.460\n was that those tasks don't have to be very related.\n\n1:18:10.460 --> 1:18:12.420\n You know, you can learn to do better vision\n\n1:18:12.420 --> 1:18:15.340\n by learning language or better language\n\n1:18:15.340 --> 1:18:17.900\n by learning about DNA structure.\n\n1:18:17.900 --> 1:18:20.020\n No, somehow the world.\n\n1:18:20.020 --> 1:18:22.660\n Yeah, it rhymes.\n\n1:18:23.700 --> 1:18:28.220\n The world rhymes, even if it's very disparate fields.\n\n1:18:29.220 --> 1:18:31.420\n I mean, on that small topic, let me ask you,\n\n1:18:31.420 --> 1:18:36.260\n because you've also on the competition neuroscience side,\n\n1:18:36.260 --> 1:18:38.260\n you worked on both language and vision.\n\n1:18:41.340 --> 1:18:44.460\n What's the connection between the two?\n\n1:18:44.460 --> 1:18:46.900\n What's more, maybe there's a bunch of ways to ask this,\n\n1:18:46.900 --> 1:18:48.620\n but what's more difficult to build\n\n1:18:48.620 --> 1:18:50.620\n from an engineering perspective\n\n1:18:50.620 --> 1:18:52.380\n and evolutionary perspective,\n\n1:18:52.380 --> 1:18:56.100\n the human language system or the human vision system\n\n1:18:56.100 --> 1:19:00.620\n or the equivalent of in the AI space language and vision,\n\n1:19:00.620 --> 1:19:03.660\n or is it the best as the multitask idea\n\n1:19:03.660 --> 1:19:04.700\n that you're speaking to\n\n1:19:04.700 --> 1:19:07.420\n that they need to be deeply integrated?\n\n1:19:07.420 --> 1:19:09.980\n Yeah, absolutely the latter.\n\n1:19:09.980 --> 1:19:11.620\n Learning both at the same time,\n\n1:19:11.620 --> 1:19:15.180\n I think is a fascinating direction in the future.\n\n1:19:15.180 --> 1:19:17.500\n So we have data sets where there's visual component\n\n1:19:17.500 --> 1:19:20.020\n as well as verbal descriptions, for instance,\n\n1:19:20.020 --> 1:19:22.740\n and that way you can learn a deeper representation,\n\n1:19:22.740 --> 1:19:25.140\n a more useful representation for both.\n\n1:19:25.140 --> 1:19:26.620\n But it's still an interesting question\n\n1:19:26.620 --> 1:19:29.460\n of which one is easier.\n\n1:19:29.460 --> 1:19:31.140\n I mean, recognizing objects\n\n1:19:31.140 --> 1:19:35.780\n or even understanding sentences, that's relatively possible,\n\n1:19:35.780 --> 1:19:37.860\n but where it becomes, where the challenges are\n\n1:19:37.860 --> 1:19:39.820\n is to understand the world.\n\n1:19:39.820 --> 1:19:42.300\n Like the visual world, the 3D,\n\n1:19:42.300 --> 1:19:43.580\n what are the objects doing\n\n1:19:43.580 --> 1:19:46.740\n and predicting what will happen, the relationships.\n\n1:19:46.740 --> 1:19:48.180\n That's what makes vision difficult.\n\n1:19:48.180 --> 1:19:51.500\n And language, obviously it's what is being said,\n\n1:19:51.500 --> 1:19:52.700\n what the meaning is.\n\n1:19:52.700 --> 1:19:57.300\n And the meaning doesn't stop at who did what to whom.\n\n1:19:57.300 --> 1:19:59.740\n There are goals and plans and themes,\n\n1:19:59.740 --> 1:20:01.700\n and you eventually have to understand\n\n1:20:01.700 --> 1:20:04.700\n the entire human society and history\n\n1:20:04.700 --> 1:20:07.580\n in order to understand the sentence very much fully.\n\n1:20:07.580 --> 1:20:09.940\n There are plenty of examples of those kinds\n\n1:20:09.940 --> 1:20:11.500\n of short sentences when you bring in\n\n1:20:11.500 --> 1:20:14.300\n all the world knowledge to understand it.\n\n1:20:14.300 --> 1:20:15.900\n And that's the big challenge.\n\n1:20:15.900 --> 1:20:17.300\n Now we are far from that,\n\n1:20:17.300 --> 1:20:20.620\n but even just bringing in the visual world\n\n1:20:20.620 --> 1:20:24.100\n together with the sentence will give you already\n\n1:20:24.100 --> 1:20:26.860\n a lot deeper understanding of what's happening.\n\n1:20:26.860 --> 1:20:29.700\n And I think that that's where we're going very soon.\n\n1:20:29.700 --> 1:20:32.980\n I mean, we've had ImageNet for a long time,\n\n1:20:32.980 --> 1:20:36.020\n and now we have all these text collections,\n\n1:20:36.020 --> 1:20:40.020\n but having both together and then learning\n\n1:20:40.020 --> 1:20:42.740\n a semantic understanding of what is happening,\n\n1:20:42.740 --> 1:20:44.540\n I think that that will be the next step\n\n1:20:44.540 --> 1:20:45.380\n in the next few years.\n\n1:20:45.380 --> 1:20:46.340\n Yeah, you're starting to see that\n\n1:20:46.340 --> 1:20:47.980\n with all the work with Transformers,\n\n1:20:47.980 --> 1:20:50.820\n was the community, the AI community\n\n1:20:50.820 --> 1:20:53.340\n starting to dip their toe into this idea\n\n1:20:53.340 --> 1:20:58.340\n of having language models that are now doing stuff\n\n1:20:59.340 --> 1:21:03.940\n with images, with vision, and then connecting the two.\n\n1:21:03.940 --> 1:21:05.900\n I mean, right now it's like these little explorations\n\n1:21:05.900 --> 1:21:07.780\n we're literally dipping the toe in,\n\n1:21:07.780 --> 1:21:11.780\n but maybe at some point we'll just dive into the pool\n\n1:21:11.780 --> 1:21:13.860\n and it'll just be all seen as the same thing.\n\n1:21:13.860 --> 1:21:16.860\n I do still wonder what's more fundamental,\n\n1:21:16.860 --> 1:21:21.380\n whether vision is, whether we don't think\n\n1:21:21.380 --> 1:21:23.300\n about vision correctly.\n\n1:21:23.300 --> 1:21:24.700\n Maybe the fact, because we're humans\n\n1:21:24.700 --> 1:21:26.700\n and we see things as beautiful and so on,\n\n1:21:28.820 --> 1:21:31.020\n and because we have cameras that are taking pixels\n\n1:21:31.020 --> 1:21:35.820\n as a 2D image, that we don't sufficiently think\n\n1:21:35.820 --> 1:21:37.700\n about vision as language.\n\n1:21:38.820 --> 1:21:41.700\n Maybe Chomsky is right all along,\n\n1:21:41.700 --> 1:21:43.820\n that vision is fundamental to,\n\n1:21:43.820 --> 1:21:46.820\n sorry, that language is fundamental to everything,\n\n1:21:46.820 --> 1:21:49.340\n to even cognition, to even consciousness.\n\n1:21:49.340 --> 1:21:51.420\n The base layer is all language,\n\n1:21:51.420 --> 1:21:54.940\n not necessarily like English, but some weird\n\n1:21:54.940 --> 1:21:59.380\n abstract representation, linguistic representation.\n\n1:21:59.380 --> 1:22:02.580\n Yeah, well, earlier we talked about the social structures\n\n1:22:02.580 --> 1:22:05.380\n and that may be what's underlying the language,\n\n1:22:05.380 --> 1:22:06.700\n and that's the more fundamental part,\n\n1:22:06.700 --> 1:22:08.740\n and then language has been added on top of that.\n\n1:22:08.740 --> 1:22:11.140\n Language emerges from the social interaction.\n\n1:22:11.140 --> 1:22:13.060\n Yeah, that's a very good guess.\n\n1:22:13.900 --> 1:22:15.420\n We are visual animals, though.\n\n1:22:15.420 --> 1:22:17.780\n A lot of the brain is dedicated to vision,\n\n1:22:17.780 --> 1:22:22.740\n and also, when we think about various abstract concepts,\n\n1:22:22.740 --> 1:22:27.740\n we usually reduce that to vision and images,\n\n1:22:27.860 --> 1:22:29.740\n and that's, you know, we go to a whiteboard,\n\n1:22:29.740 --> 1:22:33.100\n you draw pictures of very abstract concepts.\n\n1:22:33.100 --> 1:22:35.860\n So we tend to resort to that quite a bit,\n\n1:22:35.860 --> 1:22:37.460\n and that's a fundamental representation.\n\n1:22:37.460 --> 1:22:41.740\n It's probably possible that it predated language even.\n\n1:22:41.740 --> 1:22:43.900\n I mean, animals, a lot of, they don't talk,\n\n1:22:43.900 --> 1:22:45.820\n but they certainly do have vision,\n\n1:22:45.820 --> 1:22:49.820\n and language is interesting development\n\n1:22:49.820 --> 1:22:53.140\n in from mastication, from eating.\n\n1:22:53.140 --> 1:22:55.980\n You develop an organ that actually can produce sound\n\n1:22:55.980 --> 1:22:57.060\n to manipulate them.\n\n1:22:58.140 --> 1:22:59.220\n Maybe that was an accident.\n\n1:22:59.220 --> 1:23:00.900\n Maybe that was something that was available\n\n1:23:00.900 --> 1:23:05.020\n and then allowed us to do the communication,\n\n1:23:05.020 --> 1:23:06.820\n or maybe it was gestures.\n\n1:23:06.820 --> 1:23:10.060\n Sign language could have been the original proto language.\n\n1:23:10.060 --> 1:23:13.300\n We don't quite know, but the language is more fundamental\n\n1:23:13.300 --> 1:23:16.820\n than the medium in which it's communicated,\n\n1:23:16.820 --> 1:23:19.260\n and I think that it comes from those representations.\n\n1:23:20.980 --> 1:23:25.980\n Now, in current world, they are so strongly integrated,\n\n1:23:26.100 --> 1:23:28.260\n it's really hard to say which one is fundamental.\n\n1:23:28.260 --> 1:23:32.220\n You look at the brain structures and even visual cortex,\n\n1:23:32.220 --> 1:23:34.580\n which is supposed to be very much just vision.\n\n1:23:34.580 --> 1:23:37.460\n Well, if you are thinking of semantic concepts,\n\n1:23:37.460 --> 1:23:40.940\n you're thinking of language, visual cortex lights up.\n\n1:23:40.940 --> 1:23:44.500\n It's still useful, even for language computations.\n\n1:23:44.500 --> 1:23:47.140\n So there are common structures underlying them.\n\n1:23:47.140 --> 1:23:49.220\n So utilize what you need.\n\n1:23:49.220 --> 1:23:51.460\n And when you are understanding a scene,\n\n1:23:51.460 --> 1:23:53.100\n you're understanding relationships.\n\n1:23:53.100 --> 1:23:55.340\n Well, that's not so far from understanding relationships\n\n1:23:55.340 --> 1:23:56.820\n between words and concepts.\n\n1:23:56.820 --> 1:23:59.100\n So I think that that's how they are integrated.\n\n1:23:59.100 --> 1:24:02.340\n Yeah, and there's dreams, and once we close our eyes,\n\n1:24:02.340 --> 1:24:04.380\n there's still a world in there somehow operating\n\n1:24:04.380 --> 1:24:08.460\n and somehow possibly the visual system somehow integrated\n\n1:24:08.460 --> 1:24:09.860\n into all of it.\n\n1:24:09.860 --> 1:24:12.940\n I tend to enjoy thinking about aliens\n\n1:24:12.940 --> 1:24:17.340\n and thinking about the sad thing to me\n\n1:24:17.340 --> 1:24:21.020\n about extraterrestrial intelligent life,\n\n1:24:21.020 --> 1:24:24.780\n that if it visited us here on Earth,\n\n1:24:24.780 --> 1:24:29.060\n or if we came on Mars or maybe another solar system,\n\n1:24:29.060 --> 1:24:30.900\n another galaxy one day,\n\n1:24:30.900 --> 1:24:34.860\n that us humans would not be able to detect it\n\n1:24:34.860 --> 1:24:37.060\n or communicate with it or appreciate,\n\n1:24:37.060 --> 1:24:38.740\n like it'd be right in front of our nose\n\n1:24:38.740 --> 1:24:43.340\n and we were too self obsessed to see it.\n\n1:24:43.340 --> 1:24:48.340\n Not self obsessed, but our tools,\n\n1:24:48.580 --> 1:24:52.500\n our frameworks of thinking would not detect it.\n\n1:24:52.500 --> 1:24:55.060\n As a good movie, Arrival and so on,\n\n1:24:55.060 --> 1:24:56.700\n where Stephen Wolfram and his son,\n\n1:24:56.700 --> 1:24:59.300\n I think were part of developing this alien language\n\n1:24:59.300 --> 1:25:01.540\n of how aliens would communicate with humans.\n\n1:25:01.540 --> 1:25:02.900\n Do you ever think about that kind of stuff\n\n1:25:02.900 --> 1:25:07.620\n where if humans and aliens would be able to communicate\n\n1:25:07.620 --> 1:25:11.420\n with each other, like if we met each other at some,\n\n1:25:11.420 --> 1:25:13.660\n okay, we could do SETI, which is communicating\n\n1:25:13.660 --> 1:25:15.980\n from across a very big distance,\n\n1:25:15.980 --> 1:25:20.980\n but also just us, if you did a podcast with an alien,\n\n1:25:22.140 --> 1:25:25.380\n do you think we'd be able to find a common language\n\n1:25:25.380 --> 1:25:28.420\n and a common methodology of communication?\n\n1:25:28.420 --> 1:25:30.860\n I think from a computational perspective,\n\n1:25:30.860 --> 1:25:33.380\n the way to ask that is you have very fundamentally\n\n1:25:33.380 --> 1:25:35.460\n different creatures, agents that are created,\n\n1:25:35.460 --> 1:25:38.500\n would they be able to find a common language?\n\n1:25:38.500 --> 1:25:40.980\n Yes, I do think about that.\n\n1:25:40.980 --> 1:25:42.980\n I mean, I think a lot of people who are in computing,\n\n1:25:42.980 --> 1:25:46.220\n they, and AI in particular, they got into it\n\n1:25:46.220 --> 1:25:48.860\n because they were fascinated with science fiction\n\n1:25:48.860 --> 1:25:50.740\n and all of these options.\n\n1:25:50.740 --> 1:25:54.060\n I mean, Star Trek generated all kinds of devices\n\n1:25:54.060 --> 1:25:56.540\n that we have now, they envisioned it first\n\n1:25:56.540 --> 1:26:00.700\n and it's a great motivator to think about things like that.\n\n1:26:00.700 --> 1:26:05.700\n And I, so one, and again, being a computational scientist\n\n1:26:06.340 --> 1:26:10.260\n and trying to build intelligent agents,\n\n1:26:10.260 --> 1:26:13.500\n what I would like to do is have a simulation\n\n1:26:13.500 --> 1:26:17.380\n where the agents actually evolve communication,\n\n1:26:17.380 --> 1:26:18.860\n not just communication, we've done that,\n\n1:26:18.860 --> 1:26:20.260\n people have done that many times,\n\n1:26:20.260 --> 1:26:22.860\n that they communicate, they signal and so on,\n\n1:26:22.860 --> 1:26:24.940\n but actually develop a language.\n\n1:26:24.940 --> 1:26:26.860\n And language means grammar, it means all these\n\n1:26:26.860 --> 1:26:28.540\n social structures and on top of that,\n\n1:26:28.540 --> 1:26:30.860\n grammatical structures.\n\n1:26:30.860 --> 1:26:35.020\n And we do it under various conditions\n\n1:26:35.020 --> 1:26:36.740\n and actually try to identify what conditions\n\n1:26:36.740 --> 1:26:39.980\n are necessary for it to come out.\n\n1:26:39.980 --> 1:26:43.380\n And then we can start asking that kind of questions.\n\n1:26:43.380 --> 1:26:45.380\n Are those languages that emerge\n\n1:26:45.380 --> 1:26:47.980\n in those different simulated environments,\n\n1:26:47.980 --> 1:26:49.940\n are they understandable to us?\n\n1:26:49.940 --> 1:26:52.700\n Can we somehow make a translation?\n\n1:26:52.700 --> 1:26:55.180\n We can make it a concrete question.\n\n1:26:55.180 --> 1:26:58.980\n So machine translation of evolved languages.\n\n1:26:58.980 --> 1:27:01.980\n And so like languages that evolve come up with,\n\n1:27:01.980 --> 1:27:04.940\n can we translate, like I have a Google translate\n\n1:27:04.940 --> 1:27:07.140\n for the evolved languages.\n\n1:27:07.140 --> 1:27:09.740\n Yes, and if we do that enough,\n\n1:27:09.740 --> 1:27:14.060\n we have perhaps an idea what an alien language\n\n1:27:14.060 --> 1:27:17.180\n might be like, the space of where those languages can be.\n\n1:27:17.180 --> 1:27:19.940\n Because we can set up their environment differently.\n\n1:27:19.940 --> 1:27:22.020\n It doesn't need to be gravity.\n\n1:27:22.020 --> 1:27:24.860\n You can have all kinds of, societies can be different.\n\n1:27:24.860 --> 1:27:26.300\n They may have no predators.\n\n1:27:26.300 --> 1:27:28.460\n They may have all, everybody's a predator.\n\n1:27:28.460 --> 1:27:30.100\n All kinds of situations.\n\n1:27:30.100 --> 1:27:32.860\n And then see what the space possibly is\n\n1:27:32.860 --> 1:27:35.900\n where those languages are and what the difficulties are.\n\n1:27:35.900 --> 1:27:37.660\n That'd be really good actually to do that\n\n1:27:37.660 --> 1:27:39.460\n before the aliens come here.\n\n1:27:39.460 --> 1:27:40.900\n Yes, it's good practice.\n\n1:27:41.820 --> 1:27:44.100\n On the similar connection,\n\n1:27:45.260 --> 1:27:48.220\n you can think of AI systems as aliens.\n\n1:27:48.220 --> 1:27:51.500\n Is there ways to evolve a communication scheme\n\n1:27:51.500 --> 1:27:55.020\n for, there's a field you can call it explainable AI,\n\n1:27:55.020 --> 1:27:58.940\n for AI systems to be able to communicate.\n\n1:27:58.940 --> 1:28:01.620\n So you evolve a bunch of agents,\n\n1:28:01.620 --> 1:28:05.420\n but for some of them to be able to talk to you also.\n\n1:28:05.420 --> 1:28:08.460\n So to evolve a way for agents to be able to communicate\n\n1:28:08.460 --> 1:28:11.020\n about their world to us humans.\n\n1:28:11.020 --> 1:28:13.420\n Do you think that there's possible mechanisms\n\n1:28:13.420 --> 1:28:14.740\n for doing that?\n\n1:28:14.740 --> 1:28:16.220\n We can certainly try.\n\n1:28:16.220 --> 1:28:20.540\n And if it's an evolution competition system,\n\n1:28:20.540 --> 1:28:22.580\n for instance, you reward those solutions\n\n1:28:22.580 --> 1:28:24.100\n that are actually functional.\n\n1:28:24.100 --> 1:28:25.580\n That communication makes sense.\n\n1:28:25.580 --> 1:28:29.420\n It allows us to together again, achieve common goals.\n\n1:28:29.420 --> 1:28:30.860\n I think that's possible.\n\n1:28:30.860 --> 1:28:35.100\n But even from that paper that you mentioned,\n\n1:28:35.100 --> 1:28:37.820\n the anecdotes, it's quite likely also\n\n1:28:37.820 --> 1:28:42.820\n that the agents learn to lie and fake\n\n1:28:43.540 --> 1:28:45.300\n and do all kinds of things like that.\n\n1:28:45.300 --> 1:28:47.660\n I mean, we see that in even very low level,\n\n1:28:47.660 --> 1:28:48.860\n like bacterial evolution.\n\n1:28:48.860 --> 1:28:51.740\n There are cheaters.\n\n1:28:51.740 --> 1:28:53.860\n And who's to say that what they say\n\n1:28:53.860 --> 1:28:55.340\n is actually what they think.\n\n1:28:56.620 --> 1:28:57.620\n But that's what I'm saying,\n\n1:28:57.620 --> 1:29:00.860\n that there would have to be some common goal\n\n1:29:00.860 --> 1:29:02.700\n so that we can evaluate whether that communication\n\n1:29:02.700 --> 1:29:03.860\n is at least useful.\n\n1:29:05.980 --> 1:29:08.980\n They may be saying things just to make us feel good\n\n1:29:08.980 --> 1:29:10.620\n or get us to do what we want,\n\n1:29:10.620 --> 1:29:12.380\n but they would not turn them off or something.\n\n1:29:12.380 --> 1:29:15.100\n But so we would have to understand\n\n1:29:15.100 --> 1:29:16.700\n their internal representations much better\n\n1:29:16.700 --> 1:29:20.100\n to really make sure that that translation is critical.\n\n1:29:20.100 --> 1:29:21.340\n But it can be useful.\n\n1:29:21.340 --> 1:29:23.940\n And I think it's possible to do that.\n\n1:29:23.940 --> 1:29:27.620\n There are examples where visualizations\n\n1:29:27.620 --> 1:29:29.940\n are automatically created\n\n1:29:29.940 --> 1:29:33.540\n so that we can look into the system\n\n1:29:33.540 --> 1:29:35.820\n and that language is not that far from it.\n\n1:29:35.820 --> 1:29:38.620\n I mean, it is a way of communicating and logging\n\n1:29:38.620 --> 1:29:41.420\n what you're doing in some interpretable way.\n\n1:29:43.140 --> 1:29:45.380\n I think a fascinating topic, yeah, to do that.\n\n1:29:45.380 --> 1:29:47.740\n Yeah, you're making me realize\n\n1:29:47.740 --> 1:29:51.060\n that it's a good scientific question\n\n1:29:51.060 --> 1:29:54.460\n whether lying is an effective mechanism\n\n1:29:54.460 --> 1:29:56.220\n for integrating yourself and succeeding\n\n1:29:56.220 --> 1:30:00.380\n in a social network, in a world that is social.\n\n1:30:00.380 --> 1:30:04.540\n I tend to believe that honesty and love\n\n1:30:04.540 --> 1:30:09.540\n are evolutionary advantages in an environment\n\n1:30:09.940 --> 1:30:12.620\n where there's a network of intelligent agents.\n\n1:30:12.620 --> 1:30:14.820\n But it's also very possible that dishonesty\n\n1:30:14.820 --> 1:30:19.820\n and manipulation and even violence,\n\n1:30:20.540 --> 1:30:23.100\n all those kinds of things might be more beneficial.\n\n1:30:23.100 --> 1:30:25.900\n That's the old open question about good versus evil.\n\n1:30:25.900 --> 1:30:29.220\n But I tend to, I mean, I don't know if it's a hopeful,\n\n1:30:29.220 --> 1:30:34.220\n maybe I'm delusional, but it feels like karma is a thing,\n\n1:30:35.100 --> 1:30:39.540\n which is like long term, the agents,\n\n1:30:39.540 --> 1:30:42.500\n they're just kind to others sometimes for no reason\n\n1:30:42.500 --> 1:30:43.780\n will do better.\n\n1:30:43.780 --> 1:30:48.380\n In a society that's not highly constrained on resources.\n\n1:30:48.380 --> 1:30:49.940\n So like people start getting weird\n\n1:30:49.940 --> 1:30:51.860\n and evil towards each other and bad\n\n1:30:51.860 --> 1:30:54.660\n when the resources are very low relative\n\n1:30:54.660 --> 1:30:56.940\n to the needs of the populace,\n\n1:30:56.940 --> 1:31:00.180\n especially at the basic level, like survival, shelter,\n\n1:31:01.100 --> 1:31:02.660\n food, all those kinds of things.\n\n1:31:02.660 --> 1:31:07.660\n But I tend to believe that once you have\n\n1:31:07.740 --> 1:31:11.500\n those things established, then, well, not to believe,\n\n1:31:11.500 --> 1:31:14.900\n I guess I hope that AI systems will be honest.\n\n1:31:14.900 --> 1:31:19.900\n But it's scary to think about the Turing test,\n\n1:31:19.980 --> 1:31:23.940\n AI systems that will eventually pass the Turing test\n\n1:31:23.940 --> 1:31:26.740\n will be ones that are exceptionally good at lying.\n\n1:31:26.740 --> 1:31:28.380\n That's a terrifying concept.\n\n1:31:29.540 --> 1:31:31.260\n I mean, I don't know.\n\n1:31:31.260 --> 1:31:34.220\n First of all, sort of from somebody who studied language\n\n1:31:34.220 --> 1:31:37.860\n and obviously are not just a world expert in AI,\n\n1:31:37.860 --> 1:31:41.540\n but somebody who dreams about the future of the field.\n\n1:31:41.540 --> 1:31:45.620\n Do you hope, do you think there'll be human level\n\n1:31:45.620 --> 1:31:48.700\n or superhuman level intelligences in the future\n\n1:31:48.700 --> 1:31:51.220\n that we eventually build?\n\n1:31:52.300 --> 1:31:56.180\n Well, I definitely hope that we can get there.\n\n1:31:56.180 --> 1:31:59.260\n One, I think important perspective\n\n1:31:59.260 --> 1:32:02.260\n is that we are building AI to help us.\n\n1:32:02.260 --> 1:32:06.580\n That it is a tool like cars or language\n\n1:32:06.580 --> 1:32:11.580\n or communication, AI will help us be more productive.\n\n1:32:13.700 --> 1:32:17.580\n And that is always a condition.\n\n1:32:17.580 --> 1:32:20.340\n It's not something that we build and let run\n\n1:32:20.340 --> 1:32:22.500\n and it becomes an entity of its own\n\n1:32:22.500 --> 1:32:23.860\n that doesn't care about us.\n\n1:32:25.180 --> 1:32:27.340\n Now, of course, really find the future,\n\n1:32:27.340 --> 1:32:28.780\n maybe that might be possible,\n\n1:32:28.780 --> 1:32:32.220\n but not in the foreseeable future when we are building it.\n\n1:32:32.220 --> 1:32:35.860\n And therefore we always in a position of limiting\n\n1:32:35.860 --> 1:32:37.780\n what it can or cannot do.\n\n1:32:38.860 --> 1:32:43.860\n And your point about lying is very interesting.\n\n1:32:45.900 --> 1:32:49.380\n Even in these hyenas societies, for instance,\n\n1:32:49.380 --> 1:32:52.700\n when a number of these hyenas band together\n\n1:32:52.700 --> 1:32:56.300\n and they take a risk and steal the kill,\n\n1:32:56.300 --> 1:32:58.620\n there are always hyenas that hang back\n\n1:32:58.620 --> 1:33:02.100\n and don't participate in that risky behavior,\n\n1:33:02.100 --> 1:33:05.220\n but they walk in later and join the party\n\n1:33:05.220 --> 1:33:06.940\n after the kill.\n\n1:33:06.940 --> 1:33:10.020\n And there are even some that may be ineffective\n\n1:33:10.020 --> 1:33:12.900\n and cause others to have harm.\n\n1:33:12.900 --> 1:33:15.460\n So, and like I said, even bacteria cheat.\n\n1:33:15.460 --> 1:33:17.340\n And we see it in biology,\n\n1:33:17.340 --> 1:33:20.540\n there's always some element on opportunity.\n\n1:33:20.540 --> 1:33:22.700\n If you have a society, I think that is just because\n\n1:33:22.700 --> 1:33:24.180\n if you have a society,\n\n1:33:24.180 --> 1:33:26.020\n in order for society to be effective,\n\n1:33:26.020 --> 1:33:27.580\n you have to have this cooperation\n\n1:33:27.580 --> 1:33:29.900\n and you have to have trust.\n\n1:33:29.900 --> 1:33:32.100\n And if you have enough of agents\n\n1:33:32.100 --> 1:33:33.980\n who are able to trust each other,\n\n1:33:33.980 --> 1:33:36.580\n you can achieve a lot more.\n\n1:33:36.580 --> 1:33:37.500\n But if you have trust,\n\n1:33:37.500 --> 1:33:40.620\n you also have opportunity for cheaters and liars.\n\n1:33:40.620 --> 1:33:43.620\n And I don't think that's ever gonna go away.\n\n1:33:43.620 --> 1:33:45.220\n There will be hopefully a minority\n\n1:33:45.220 --> 1:33:46.660\n so that they don't get in the way.\n\n1:33:46.660 --> 1:33:48.740\n And we studied in these hyena simulations,\n\n1:33:48.740 --> 1:33:50.500\n like what the proportion needs to be\n\n1:33:50.500 --> 1:33:52.660\n before it is no longer functional.\n\n1:33:52.660 --> 1:33:55.060\n And you can point out that you can tolerate\n\n1:33:55.060 --> 1:33:57.260\n a few cheaters and a few liars\n\n1:33:57.260 --> 1:33:59.660\n and the society can still function.\n\n1:33:59.660 --> 1:34:02.300\n And that's probably going to happen\n\n1:34:02.300 --> 1:34:05.420\n when we build these systems at Autonomously Learn.\n\n1:34:07.100 --> 1:34:09.260\n The really successful ones are honest\n\n1:34:09.260 --> 1:34:11.980\n because that's the best way of getting things done.\n\n1:34:13.100 --> 1:34:15.900\n But there probably are also intelligent agents\n\n1:34:15.900 --> 1:34:17.940\n that find that they can achieve their goals\n\n1:34:17.940 --> 1:34:20.860\n by bending the rules or cheating.\n\n1:34:20.860 --> 1:34:22.380\n So that could be a huge benefit\n\n1:34:23.780 --> 1:34:25.620\n as opposed to having fixed AI systems.\n\n1:34:25.620 --> 1:34:29.980\n Say we build an AGI system and deploying millions of them,\n\n1:34:29.980 --> 1:34:32.380\n it'd be that are exactly the same.\n\n1:34:33.500 --> 1:34:37.100\n There might be a huge benefit to introducing\n\n1:34:37.100 --> 1:34:39.620\n sort of from like an evolution computation perspective,\n\n1:34:39.620 --> 1:34:41.340\n a lot of variation.\n\n1:34:41.340 --> 1:34:46.340\n Sort of like diversity in all its forms is beneficial\n\n1:34:46.540 --> 1:34:48.420\n even if some people are assholes\n\n1:34:48.420 --> 1:34:49.980\n or some robots are assholes.\n\n1:34:49.980 --> 1:34:51.980\n So like it's beneficial to have that\n\n1:34:51.980 --> 1:34:56.780\n because you can't always a priori know\n\n1:34:56.780 --> 1:34:58.500\n what's good, what's bad.\n\n1:34:58.500 --> 1:35:01.380\n But that's a fascinating.\n\n1:35:01.380 --> 1:35:02.300\n Absolutely.\n\n1:35:02.300 --> 1:35:04.380\n Diversity is the bread and butter.\n\n1:35:04.380 --> 1:35:05.820\n I mean, if you're running an evolution,\n\n1:35:05.820 --> 1:35:08.100\n you see diversity is the one fundamental thing\n\n1:35:08.100 --> 1:35:09.100\n you have to have.\n\n1:35:09.100 --> 1:35:12.660\n And absolutely, also, it's not always good diversity.\n\n1:35:12.660 --> 1:35:14.980\n It may be something that can be destructive.\n\n1:35:14.980 --> 1:35:16.380\n We had in these hyenas simulations,\n\n1:35:16.380 --> 1:35:19.220\n we have hyenas that just are suicidal.\n\n1:35:19.220 --> 1:35:20.580\n They just run and get killed.\n\n1:35:20.580 --> 1:35:22.820\n But they form the basis of those\n\n1:35:22.820 --> 1:35:24.460\n who actually are really fast,\n\n1:35:24.460 --> 1:35:26.060\n but stop before they get killed\n\n1:35:26.060 --> 1:35:28.380\n and eventually turn into this mob.\n\n1:35:28.380 --> 1:35:30.020\n So there might be something useful there\n\n1:35:30.020 --> 1:35:32.180\n if it's recombined with something else.\n\n1:35:32.180 --> 1:35:34.980\n So I think that as long as we can tolerate some of that,\n\n1:35:34.980 --> 1:35:36.860\n it may turn into something better.\n\n1:35:36.860 --> 1:35:38.500\n You may change the rules\n\n1:35:38.500 --> 1:35:40.660\n because it's so much more efficient to do something\n\n1:35:40.660 --> 1:35:43.300\n that was actually against the rules before.\n\n1:35:43.300 --> 1:35:46.500\n And we've seen society change over time\n\n1:35:46.500 --> 1:35:47.780\n quite a bit along those lines.\n\n1:35:47.780 --> 1:35:49.940\n That there were rules in society\n\n1:35:49.940 --> 1:35:52.180\n that we don't believe are fair anymore,\n\n1:35:52.180 --> 1:35:57.180\n even though they were considered proper behavior before.\n\n1:35:57.180 --> 1:35:58.540\n So things are changing.\n\n1:35:58.540 --> 1:35:59.780\n And I think that in that sense,\n\n1:35:59.780 --> 1:36:03.100\n I think it's a good idea to be able to tolerate\n\n1:36:03.100 --> 1:36:04.820\n some of that cheating\n\n1:36:04.820 --> 1:36:07.220\n because eventually we might turn into something better.\n\n1:36:07.220 --> 1:36:08.940\n So yeah, I think this is a message\n\n1:36:08.940 --> 1:36:11.140\n to the trolls and the assholes of the internet\n\n1:36:11.140 --> 1:36:13.220\n that you too have a beautiful purpose\n\n1:36:13.220 --> 1:36:15.380\n in this human ecosystem.\n\n1:36:15.380 --> 1:36:16.660\n So I appreciate you very much.\n\n1:36:16.660 --> 1:36:18.300\n In moderate quantities, yeah.\n\n1:36:18.300 --> 1:36:20.100\n In moderate quantities.\n\n1:36:20.100 --> 1:36:22.820\n So there's a whole field of artificial life.\n\n1:36:22.820 --> 1:36:24.580\n I don't know if you're connected to this field,\n\n1:36:24.580 --> 1:36:26.340\n if you pay attention.\n\n1:36:26.340 --> 1:36:28.700\n Is, do you think about this kind of thing?\n\n1:36:29.580 --> 1:36:32.260\n Is there impressive demonstration to you\n\n1:36:32.260 --> 1:36:33.140\n of artificial life?\n\n1:36:33.140 --> 1:36:35.300\n Do you think of the agency you work with\n\n1:36:35.300 --> 1:36:40.300\n in the evolutionary computation perspective as life?\n\n1:36:41.140 --> 1:36:43.620\n And where do you think this is headed?\n\n1:36:43.620 --> 1:36:45.100\n Like, is there interesting systems\n\n1:36:45.100 --> 1:36:47.060\n that we'll be creating more and more\n\n1:36:47.060 --> 1:36:50.740\n that make us redefine, maybe rethink\n\n1:36:50.740 --> 1:36:52.420\n about the nature of life?\n\n1:36:52.420 --> 1:36:55.780\n Different levels of definition and goals there.\n\n1:36:55.780 --> 1:36:58.620\n I mean, at some level, artificial life\n\n1:36:58.620 --> 1:37:01.300\n can be considered multiagent systems\n\n1:37:01.300 --> 1:37:04.100\n that build a society that again, achieves a goal.\n\n1:37:04.100 --> 1:37:06.020\n And it might be robots that go into a building\n\n1:37:06.020 --> 1:37:09.380\n and clean it up or after an earthquake or something.\n\n1:37:09.380 --> 1:37:11.980\n You can think of that as an artificial life problem\n\n1:37:11.980 --> 1:37:13.620\n in some sense.\n\n1:37:13.620 --> 1:37:15.860\n Or you can really think of it, artificial life,\n\n1:37:15.860 --> 1:37:20.860\n as a simulation of life and a tool to understand\n\n1:37:20.860 --> 1:37:24.660\n what life is and how life evolved on earth.\n\n1:37:24.660 --> 1:37:26.820\n And like I said, in artificial life conference,\n\n1:37:26.820 --> 1:37:29.780\n there are branches of that conference sessions\n\n1:37:29.780 --> 1:37:33.460\n of people who really worry about molecular designs\n\n1:37:33.460 --> 1:37:36.020\n and the start of life, like I said,\n\n1:37:36.020 --> 1:37:37.860\n primordial soup where eventually\n\n1:37:37.860 --> 1:37:39.740\n you get something self replicating.\n\n1:37:39.740 --> 1:37:41.980\n And they're really trying to build that.\n\n1:37:41.980 --> 1:37:44.860\n So it's a whole range of topics.\n\n1:37:46.500 --> 1:37:50.820\n And I think that artificial life is a great tool\n\n1:37:50.820 --> 1:37:53.020\n to understand life.\n\n1:37:53.020 --> 1:37:55.300\n And there are questions like sustainability,\n\n1:37:56.420 --> 1:37:59.300\n species, we're losing species.\n\n1:37:59.300 --> 1:38:00.860\n How bad is it?\n\n1:38:00.860 --> 1:38:02.540\n Is it natural?\n\n1:38:02.540 --> 1:38:03.980\n Is there a tipping point?\n\n1:38:05.260 --> 1:38:06.500\n And where are we going?\n\n1:38:06.500 --> 1:38:08.100\n I mean, like the hyena evolution,\n\n1:38:08.100 --> 1:38:11.380\n we may have understood that there's a pivotal point\n\n1:38:11.380 --> 1:38:12.220\n in their evolution.\n\n1:38:12.220 --> 1:38:14.860\n They discovered cooperation and coordination.\n\n1:38:16.220 --> 1:38:18.700\n Artificial life simulations can identify that\n\n1:38:18.700 --> 1:38:21.300\n and maybe encourage things like that.\n\n1:38:22.900 --> 1:38:27.900\n And also societies can be seen as a form of life itself.\n\n1:38:28.020 --> 1:38:30.380\n I mean, we're not talking about biological evolution,\n\n1:38:30.380 --> 1:38:31.940\n evolution of societies.\n\n1:38:31.940 --> 1:38:36.540\n Maybe some of the same phenomena emerge in that domain\n\n1:38:36.540 --> 1:38:40.100\n and having artificial life simulations and understanding\n\n1:38:40.100 --> 1:38:42.540\n could help us build better societies.\n\n1:38:42.540 --> 1:38:45.780\n Yeah, and thinking from a meme perspective\n\n1:38:45.780 --> 1:38:49.540\n of from Richard Dawkins,\n\n1:38:50.860 --> 1:38:54.060\n that maybe the organisms, ideas of the organisms,\n\n1:38:54.060 --> 1:38:58.460\n not the humans in these societies that from,\n\n1:38:58.460 --> 1:39:01.900\n it's almost like reframing what is exactly evolving.\n\n1:39:01.900 --> 1:39:02.940\n Maybe the interesting,\n\n1:39:02.940 --> 1:39:04.540\n the humans aren't the interesting thing\n\n1:39:04.540 --> 1:39:07.340\n as the contents of our minds is the interesting thing.\n\n1:39:07.340 --> 1:39:09.220\n And that's what's multiplying.\n\n1:39:09.220 --> 1:39:10.860\n And that's actually multiplying and evolving\n\n1:39:10.860 --> 1:39:13.020\n in a much faster timescale.\n\n1:39:13.020 --> 1:39:16.220\n And that maybe has more power on the trajectory\n\n1:39:16.220 --> 1:39:19.500\n of life on earth than does biological evolution\n\n1:39:19.500 --> 1:39:20.940\n is the evolution of these ideas.\n\n1:39:20.940 --> 1:39:23.820\n Yes, and it's fascinating, like I said before,\n\n1:39:23.820 --> 1:39:27.500\n that we can keep up somehow biologically.\n\n1:39:27.500 --> 1:39:30.060\n We evolved to a point where we can keep up\n\n1:39:30.060 --> 1:39:35.060\n with this meme evolution, literature, internet.\n\n1:39:35.180 --> 1:39:38.980\n We understand DNA and we understand fundamental particles.\n\n1:39:38.980 --> 1:39:41.260\n We didn't start that way a thousand years ago.\n\n1:39:41.260 --> 1:39:43.300\n And we haven't evolved biologically very much,\n\n1:39:43.300 --> 1:39:46.980\n but somehow our minds are able to extend.\n\n1:39:46.980 --> 1:39:51.220\n And therefore AI can be seen also as one such step\n\n1:39:51.220 --> 1:39:53.420\n that we created and it's our tool.\n\n1:39:53.420 --> 1:39:56.340\n And it's part of that meme evolution that we created,\n\n1:39:56.340 --> 1:39:59.620\n even if our biological evolution does not progress as fast.\n\n1:39:59.620 --> 1:40:03.700\n And us humans might only be able to understand so much.\n\n1:40:03.700 --> 1:40:05.780\n We're keeping up so far,\n\n1:40:05.780 --> 1:40:07.300\n or we think we're keeping up so far,\n\n1:40:07.300 --> 1:40:09.500\n but we might need AI systems to understand.\n\n1:40:09.500 --> 1:40:13.780\n Maybe like the physics of the universe is operating,\n\n1:40:13.780 --> 1:40:14.740\n look at strength theory.\n\n1:40:14.740 --> 1:40:17.420\n Maybe it's operating in much higher dimensions.\n\n1:40:17.420 --> 1:40:21.220\n Maybe we're totally, because of our cognitive limitations,\n\n1:40:21.220 --> 1:40:25.740\n are not able to truly internalize the way this world works.\n\n1:40:25.740 --> 1:40:28.900\n And so we're running up against the limitation\n\n1:40:28.900 --> 1:40:30.220\n of our own minds.\n\n1:40:30.220 --> 1:40:33.100\n And we have to create these next level organisms\n\n1:40:33.100 --> 1:40:36.300\n like AI systems that would be able to understand much deeper,\n\n1:40:36.300 --> 1:40:38.460\n like really understand what it means to live\n\n1:40:38.460 --> 1:40:41.220\n in a multi dimensional world\n\n1:40:41.220 --> 1:40:42.580\n that's outside of the four dimensions,\n\n1:40:42.580 --> 1:40:45.340\n the three of space and one of time.\n\n1:40:45.340 --> 1:40:48.100\n Translation, and generally we can deal with the world,\n\n1:40:48.100 --> 1:40:49.620\n even if you don't understand all the details,\n\n1:40:49.620 --> 1:40:52.020\n we can use computers, even though we don't,\n\n1:40:52.020 --> 1:40:54.380\n most of us don't know all the structure\n\n1:40:54.380 --> 1:40:55.740\n that's underneath or drive a car.\n\n1:40:55.740 --> 1:40:57.220\n I mean, there are many components,\n\n1:40:57.220 --> 1:40:59.820\n especially new cars that you don't quite fully know,\n\n1:40:59.820 --> 1:41:02.620\n but you have the interface, you have an abstraction of it\n\n1:41:02.620 --> 1:41:05.020\n that allows you to operate it and utilize it.\n\n1:41:05.020 --> 1:41:08.140\n And I think that that's perfectly adequate\n\n1:41:08.140 --> 1:41:09.180\n and we can build on it.\n\n1:41:09.180 --> 1:41:12.140\n And AI can play a similar role.\n\n1:41:13.580 --> 1:41:18.060\n I have to ask about beautiful artificial life systems\n\n1:41:18.060 --> 1:41:20.900\n or evolutionary computation systems.\n\n1:41:20.900 --> 1:41:22.580\n Cellular automata to me,\n\n1:41:23.860 --> 1:41:26.580\n I remember it was a game changer for me early on in life\n\n1:41:26.580 --> 1:41:28.780\n when I saw Conway's Game of Life\n\n1:41:28.780 --> 1:41:31.380\n who recently passed away, unfortunately.\n\n1:41:31.380 --> 1:41:35.540\n And it's beautiful\n\n1:41:36.540 --> 1:41:40.020\n how much complexity can emerge from such simple rules.\n\n1:41:40.020 --> 1:41:44.420\n I just don't, somehow that simplicity\n\n1:41:44.420 --> 1:41:47.340\n is such a powerful illustration\n\n1:41:47.340 --> 1:41:50.060\n and also humbling because it feels like I personally,\n\n1:41:50.060 --> 1:41:50.900\n from my perspective,\n\n1:41:50.900 --> 1:41:54.900\n understand almost nothing about this world\n\n1:41:54.900 --> 1:41:58.420\n because like my intuition fails completely\n\n1:41:58.420 --> 1:42:01.260\n how complexity can emerge from such simplicity.\n\n1:42:01.260 --> 1:42:02.660\n Like my intuition fails, I think,\n\n1:42:02.660 --> 1:42:04.140\n is the biggest problem I have.\n\n1:42:05.980 --> 1:42:08.500\n Do you find systems like that beautiful?\n\n1:42:08.500 --> 1:42:11.380\n Is there, do you think about cellular automata?\n\n1:42:11.380 --> 1:42:14.020\n Because cellular automata don't really have,\n\n1:42:15.260 --> 1:42:17.140\n and many other artificial life systems\n\n1:42:17.140 --> 1:42:18.900\n don't necessarily have an objective.\n\n1:42:18.900 --> 1:42:21.620\n Maybe that's a wrong way to say it.\n\n1:42:21.620 --> 1:42:26.620\n It's almost like it's just evolving and creating.\n\n1:42:28.140 --> 1:42:29.700\n And there's not even a good definition\n\n1:42:29.700 --> 1:42:33.020\n of what it means to create something complex\n\n1:42:33.020 --> 1:42:34.540\n and interesting and surprising,\n\n1:42:34.540 --> 1:42:35.980\n all those words that you said.\n\n1:42:37.540 --> 1:42:41.060\n Is there some of those systems that you find beautiful?\n\n1:42:41.060 --> 1:42:41.900\n Yeah, yeah.\n\n1:42:41.900 --> 1:42:44.460\n And similarly, evolution does not have a goal.\n\n1:42:45.340 --> 1:42:49.500\n It is responding to current situation\n\n1:42:49.500 --> 1:42:52.700\n and survival then creates more complexity\n\n1:42:52.700 --> 1:42:56.060\n and therefore we have something that we perceive as progress\n\n1:42:56.060 --> 1:43:00.620\n but that's not what evolution is inherently set to do.\n\n1:43:00.620 --> 1:43:03.220\n And yeah, that's really fascinating\n\n1:43:03.220 --> 1:43:08.220\n how a simple set of rules or simple mappings can,\n\n1:43:10.180 --> 1:43:14.460\n how from such simple mappings, complexity can emerge.\n\n1:43:14.460 --> 1:43:17.620\n So it's a question of emergence and self organization.\n\n1:43:17.620 --> 1:43:21.420\n And the game of life is one of the simplest ones\n\n1:43:21.420 --> 1:43:25.580\n and very visual and therefore it drives home the point\n\n1:43:25.580 --> 1:43:29.580\n that it's possible that nonlinear interactions\n\n1:43:29.580 --> 1:43:34.580\n and this kind of complexity can emerge from them.\n\n1:43:34.660 --> 1:43:37.860\n And biology and evolution is along the same lines.\n\n1:43:37.860 --> 1:43:40.020\n We have simple representations.\n\n1:43:40.020 --> 1:43:43.140\n DNA, if you really think of it, it's not that complex.\n\n1:43:44.140 --> 1:43:46.140\n It's a long sequence of them, there's lots of them\n\n1:43:46.140 --> 1:43:48.140\n but it's a very simple representation.\n\n1:43:48.140 --> 1:43:49.820\n And similarly with evolutionary computation,\n\n1:43:49.820 --> 1:43:52.580\n whatever string or tree representation we have\n\n1:43:52.580 --> 1:43:57.540\n and the operations, the amount of code that's required\n\n1:43:57.540 --> 1:44:00.460\n to manipulate those, it's really, really little.\n\n1:44:00.460 --> 1:44:02.420\n And of course, game of life even less.\n\n1:44:02.420 --> 1:44:06.140\n So how complexity emerges from such simple principles,\n\n1:44:06.140 --> 1:44:08.220\n that's absolutely fascinating.\n\n1:44:09.100 --> 1:44:11.420\n The challenge is to be able to control it\n\n1:44:11.420 --> 1:44:15.500\n and guide it and direct it so that it becomes useful.\n\n1:44:15.500 --> 1:44:17.900\n And like game of life is fascinating to look at\n\n1:44:17.900 --> 1:44:21.140\n and evolution, all the forms that come out is fascinating\n\n1:44:21.140 --> 1:44:24.020\n but can we actually make it useful for us?\n\n1:44:24.020 --> 1:44:26.980\n And efficient because if you actually think about\n\n1:44:26.980 --> 1:44:30.260\n each of the cells in the game of life as a living organism,\n\n1:44:30.260 --> 1:44:32.540\n there's a lot of death that has to happen\n\n1:44:32.540 --> 1:44:34.300\n to create anything interesting.\n\n1:44:34.300 --> 1:44:36.460\n And so I guess the question is for us humans\n\n1:44:36.460 --> 1:44:38.860\n that are mortal and then life ends quickly,\n\n1:44:38.860 --> 1:44:43.860\n we wanna kinda hurry up and make sure we take evolution,\n\n1:44:44.940 --> 1:44:47.380\n the trajectory that is a little bit more efficient\n\n1:44:47.380 --> 1:44:49.300\n than the alternatives.\n\n1:44:49.300 --> 1:44:51.220\n And that touches upon something we talked about earlier\n\n1:44:51.220 --> 1:44:54.580\n that evolution competition is very impatient.\n\n1:44:54.580 --> 1:44:57.140\n We have a goal, we want it right away\n\n1:44:57.140 --> 1:45:01.020\n whereas this biology has a lot of time and deep time\n\n1:45:01.020 --> 1:45:04.460\n and weak pressure and large populations.\n\n1:45:04.460 --> 1:45:08.900\n One great example of this is the novelty search.\n\n1:45:08.900 --> 1:45:11.020\n So evolutionary computation\n\n1:45:11.020 --> 1:45:14.820\n where you don't actually specify a fitness goal,\n\n1:45:14.820 --> 1:45:17.300\n something that is your actual thing that you want\n\n1:45:17.300 --> 1:45:20.860\n but you just reward solutions that are different\n\n1:45:20.860 --> 1:45:23.700\n from what you've seen before, nothing else.\n\n1:45:23.700 --> 1:45:25.060\n And you know what?\n\n1:45:25.060 --> 1:45:26.540\n You actually discover things\n\n1:45:26.540 --> 1:45:29.220\n that are interesting and useful that way.\n\n1:45:29.220 --> 1:45:31.020\n Ken Stanley and Joel Lehmann did this one study\n\n1:45:31.020 --> 1:45:34.380\n where they actually tried to evolve walking behavior\n\n1:45:34.380 --> 1:45:35.260\n on robots.\n\n1:45:35.260 --> 1:45:36.540\n And that's actually, we talked about earlier\n\n1:45:36.540 --> 1:45:39.580\n where your robot actually failed in all kinds of ways\n\n1:45:39.580 --> 1:45:40.940\n and eventually discovered something\n\n1:45:40.940 --> 1:45:43.820\n that was a very efficient walk.\n\n1:45:43.820 --> 1:45:48.740\n And it was because they rewarded things that were different\n\n1:45:48.740 --> 1:45:50.660\n that you were able to discover something.\n\n1:45:50.660 --> 1:45:52.900\n And I think that this is crucial\n\n1:45:52.900 --> 1:45:55.020\n because in order to be really different\n\n1:45:55.020 --> 1:45:56.540\n from what you already have,\n\n1:45:56.540 --> 1:45:59.020\n you have to utilize what is there in a domain\n\n1:45:59.020 --> 1:46:00.700\n to create something really different.\n\n1:46:00.700 --> 1:46:05.700\n So you have encoded the fundamentals of your world\n\n1:46:05.700 --> 1:46:08.020\n and then you make changes to those fundamentals\n\n1:46:08.020 --> 1:46:09.660\n you get further away.\n\n1:46:09.660 --> 1:46:11.460\n So that's probably what's happening\n\n1:46:11.460 --> 1:46:14.220\n in these systems of emergence.\n\n1:46:14.220 --> 1:46:17.300\n That the fundamentals are there.\n\n1:46:17.300 --> 1:46:18.940\n And when you follow those fundamentals\n\n1:46:18.940 --> 1:46:20.020\n you get into points\n\n1:46:20.020 --> 1:46:22.820\n and some of those are actually interesting and useful.\n\n1:46:22.820 --> 1:46:25.140\n Now, even in that robotic Walker simulation\n\n1:46:25.140 --> 1:46:28.300\n there was a large set of garbage,\n\n1:46:28.300 --> 1:46:31.780\n but among them, there were some of these gems.\n\n1:46:31.780 --> 1:46:32.740\n And then those are the ones\n\n1:46:32.740 --> 1:46:36.540\n that somehow you have to outside recognize and make useful.\n\n1:46:36.540 --> 1:46:38.620\n But this kind of productive systems\n\n1:46:38.620 --> 1:46:41.540\n if you code them the right kind of principles\n\n1:46:41.540 --> 1:46:45.580\n I think that encode the structure of the domain\n\n1:46:45.580 --> 1:46:48.260\n then you will get to these solutions and discoveries.\n\n1:46:49.980 --> 1:46:52.740\n It feels like that might also be a good way to live life.\n\n1:46:52.740 --> 1:46:57.740\n So let me ask, do you have advice for young people today\n\n1:46:58.060 --> 1:47:01.460\n about how to live life or how to succeed in their career\n\n1:47:01.460 --> 1:47:04.580\n or forget career, just succeed in life\n\n1:47:04.580 --> 1:47:08.700\n from an evolution and computation perspective?\n\n1:47:08.700 --> 1:47:11.460\n Yes, yes, definitely.\n\n1:47:11.460 --> 1:47:16.460\n Explore, diversity, exploration and individuals\n\n1:47:17.780 --> 1:47:22.100\n take classes in music, history, philosophy,\n\n1:47:22.100 --> 1:47:27.100\n math, engineering, see connections between them,\n\n1:47:27.380 --> 1:47:30.020\n travel, learn a language.\n\n1:47:30.020 --> 1:47:32.060\n I mean, all this diversity is fascinating\n\n1:47:32.060 --> 1:47:35.380\n and we have it at our fingertips today.\n\n1:47:35.380 --> 1:47:37.740\n It's possible, you have to make a bit of an effort\n\n1:47:37.740 --> 1:47:41.940\n because it's not easy, but the rewards are wonderful.\n\n1:47:42.780 --> 1:47:43.740\n Yeah, there's something interesting\n\n1:47:43.740 --> 1:47:47.300\n about an objective function of new experiences.\n\n1:47:47.300 --> 1:47:49.340\n So try to figure out, I mean,\n\n1:47:51.100 --> 1:47:55.500\n what is the maximally new experience I could have today?\n\n1:47:56.700 --> 1:47:59.300\n And that sort of that novelty, optimizing for novelty\n\n1:47:59.300 --> 1:48:01.780\n for some period of time might be very interesting way\n\n1:48:01.780 --> 1:48:06.780\n to sort of maximally expand the sets of experiences you had\n\n1:48:06.940 --> 1:48:10.300\n and then ground from that perspective,\n\n1:48:11.620 --> 1:48:14.460\n like what will be the most fulfilling trajectory\n\n1:48:14.460 --> 1:48:15.300\n through life.\n\n1:48:15.300 --> 1:48:19.140\n Of course, the flip side of that is where I come from.\n\n1:48:19.140 --> 1:48:20.940\n Again, maybe Russian, I don't know.\n\n1:48:20.940 --> 1:48:25.940\n But the choice has a detrimental effect, I think,\n\n1:48:25.940 --> 1:48:30.940\n at least from my mind where scarcity has an empowering effect.\n\n1:48:31.300 --> 1:48:36.300\n So if I sort of, if I have very little of something\n\n1:48:37.300 --> 1:48:40.980\n and only one of that something, I will appreciate it deeply\n\n1:48:40.980 --> 1:48:44.540\n until I came to Texas recently\n\n1:48:44.540 --> 1:48:47.620\n and I've been pigging out on delicious, incredible meat.\n\n1:48:47.620 --> 1:48:49.860\n I've been fasting a lot, so I need to do that again.\n\n1:48:49.860 --> 1:48:52.220\n But when you fast for a few days,\n\n1:48:52.220 --> 1:48:56.580\n that the first taste of a food is incredible.\n\n1:48:56.580 --> 1:49:01.580\n So the downside of exploration is that somehow,\n\n1:49:05.660 --> 1:49:06.980\n maybe you can correct me,\n\n1:49:06.980 --> 1:49:10.220\n but somehow you don't get to experience deeply\n\n1:49:11.140 --> 1:49:13.420\n any one of the particular moments,\n\n1:49:13.420 --> 1:49:15.620\n but that could be a psychology thing.\n\n1:49:15.620 --> 1:49:18.660\n That could be just a very human peculiar,\n\n1:49:18.660 --> 1:49:23.660\n flaw.\n\n1:49:23.660 --> 1:49:26.740\n Yeah, I didn't mean that you superficially explore.\n\n1:49:26.740 --> 1:49:27.580\n I mean, you can.\n\n1:49:27.580 --> 1:49:28.420\n Explore deeply.\n\n1:49:28.420 --> 1:49:31.100\n Yeah, so you don't have to explore 100 things,\n\n1:49:31.100 --> 1:49:33.100\n but maybe a few topics\n\n1:49:33.100 --> 1:49:36.500\n where you can take a deep enough dive\n\n1:49:36.500 --> 1:49:39.980\n that you gain an understanding.\n\n1:49:39.980 --> 1:49:42.620\n You yourself have to decide at some point\n\n1:49:42.620 --> 1:49:44.380\n that this is deep enough.\n\n1:49:44.380 --> 1:49:49.220\n And I obtained what I can from this topic\n\n1:49:49.220 --> 1:49:51.340\n and now it's time to move on.\n\n1:49:51.340 --> 1:49:53.980\n And that might take years.\n\n1:49:53.980 --> 1:49:56.220\n People sometimes switch careers\n\n1:49:56.220 --> 1:49:59.100\n and they may stay on some career for a decade\n\n1:49:59.100 --> 1:50:00.460\n and switch to another one.\n\n1:50:00.460 --> 1:50:01.780\n You can do it.\n\n1:50:01.780 --> 1:50:04.620\n You're not pretty determined to stay where you are,\n\n1:50:04.620 --> 1:50:09.060\n but in order to achieve something,\n\n1:50:09.060 --> 1:50:10.460\n 10,000 hours makes,\n\n1:50:10.460 --> 1:50:13.580\n you need 10,000 hours to become an expert on something.\n\n1:50:13.580 --> 1:50:15.300\n So you don't have to become an expert,\n\n1:50:15.300 --> 1:50:17.100\n but they even develop an understanding\n\n1:50:17.100 --> 1:50:19.260\n and gain the experience that you can use later.\n\n1:50:19.260 --> 1:50:21.860\n You probably have to spend, like I said, it's not easy.\n\n1:50:21.860 --> 1:50:24.340\n You've got to spend some effort on it.\n\n1:50:24.340 --> 1:50:26.220\n Now, also at some point then,\n\n1:50:26.220 --> 1:50:28.060\n when you have this diversity\n\n1:50:28.060 --> 1:50:30.260\n and you have these experiences, exploration,\n\n1:50:30.260 --> 1:50:31.580\n you may want to,\n\n1:50:32.740 --> 1:50:35.820\n you may find something that you can't stay away from.\n\n1:50:35.820 --> 1:50:38.660\n Like for us, it was computers, it was AI.\n\n1:50:38.660 --> 1:50:41.980\n It was, you know, that I just have to do it.\n\n1:50:41.980 --> 1:50:45.220\n And I, you know, and then it will take decades maybe\n\n1:50:45.220 --> 1:50:46.540\n and you are pursuing it\n\n1:50:46.540 --> 1:50:49.300\n because you figured out that this is really exciting\n\n1:50:49.300 --> 1:50:51.260\n and you can bring in your experiences.\n\n1:50:51.260 --> 1:50:52.740\n And there's nothing wrong with that either,\n\n1:50:52.740 --> 1:50:55.860\n but you asked what's the advice for young people.\n\n1:50:55.860 --> 1:50:57.500\n That's the exploration part.\n\n1:50:57.500 --> 1:51:00.140\n And then beyond that, after that exploration,\n\n1:51:00.140 --> 1:51:03.220\n you actually can focus and build a career.\n\n1:51:03.220 --> 1:51:05.820\n And, you know, even there you can switch multiple times,\n\n1:51:05.820 --> 1:51:09.140\n but I think that diversity exploration is fundamental\n\n1:51:09.140 --> 1:51:13.340\n to having a successful career as is concentration\n\n1:51:13.340 --> 1:51:15.540\n and spending an effort where it matters.\n\n1:51:15.540 --> 1:51:18.980\n And, but you are in better position to make the choice\n\n1:51:18.980 --> 1:51:20.380\n when you have done your homework.\n\n1:51:20.380 --> 1:51:21.220\n Explored.\n\n1:51:21.220 --> 1:51:24.900\n So exploration precedes commitment, but both are beautiful.\n\n1:51:24.900 --> 1:51:26.140\n Yeah.\n\n1:51:26.140 --> 1:51:29.460\n So again, from an evolutionary computation perspective,\n\n1:51:29.460 --> 1:51:32.460\n we'll look at all the agents that had to die\n\n1:51:32.460 --> 1:51:35.740\n in order to come up with different solutions in simulation.\n\n1:51:35.740 --> 1:51:40.260\n What do you think from that individual agent's perspective\n\n1:51:40.260 --> 1:51:41.820\n is the meaning of it all?\n\n1:51:41.820 --> 1:51:43.820\n So far as humans, you're just one agent\n\n1:51:43.820 --> 1:51:47.540\n who's going to be dead, unfortunately, one day too soon.\n\n1:51:48.740 --> 1:51:51.860\n What do you think is the why\n\n1:51:51.860 --> 1:51:55.180\n of why that agent came to be\n\n1:51:55.180 --> 1:51:57.540\n and eventually will be no more?\n\n1:51:58.540 --> 1:52:00.060\n Is there a meaning to it all?\n\n1:52:00.060 --> 1:52:00.900\n Yeah.\n\n1:52:00.900 --> 1:52:02.460\n In evolution, there is meaning.\n\n1:52:02.460 --> 1:52:05.620\n Everything is a potential direction.\n\n1:52:05.620 --> 1:52:07.820\n Everything is a potential stepping stone.\n\n1:52:09.540 --> 1:52:11.380\n Not all of them are going to work out.\n\n1:52:11.380 --> 1:52:16.380\n Some of them are foundations for further improvement.\n\n1:52:16.860 --> 1:52:21.100\n And even those that are perhaps going to die out\n\n1:52:21.100 --> 1:52:24.700\n were potential energies, potential solutions.\n\n1:52:25.580 --> 1:52:28.700\n In biology, we see a lot of species die off naturally.\n\n1:52:28.700 --> 1:52:29.860\n And you know, like the dinosaurs,\n\n1:52:29.860 --> 1:52:31.860\n I mean, they were really good solution for a while,\n\n1:52:31.860 --> 1:52:33.980\n but then it didn't turned out to be\n\n1:52:33.980 --> 1:52:37.780\n not such a good solution in the long term.\n\n1:52:37.780 --> 1:52:39.420\n When there's an environmental change,\n\n1:52:39.420 --> 1:52:40.660\n you have to have diversity.\n\n1:52:40.660 --> 1:52:42.660\n Some other solutions become better.\n\n1:52:42.660 --> 1:52:45.020\n Doesn't mean that that was an attempt.\n\n1:52:45.020 --> 1:52:47.540\n It didn't quite work out or last,\n\n1:52:47.540 --> 1:52:49.380\n but there are still dinosaurs among us,\n\n1:52:49.380 --> 1:52:51.220\n at least their relatives.\n\n1:52:51.220 --> 1:52:55.580\n And they may one day again be useful, who knows?\n\n1:52:55.580 --> 1:52:57.220\n So from an individual's perspective,\n\n1:52:57.220 --> 1:52:59.100\n you got to think of a bigger picture\n\n1:52:59.100 --> 1:53:04.100\n that it is a huge engine that is innovative.\n\n1:53:04.420 --> 1:53:06.780\n And these elements are all part of it,\n\n1:53:06.780 --> 1:53:09.380\n potential innovations on their own.\n\n1:53:09.380 --> 1:53:12.340\n And also as raw material perhaps,\n\n1:53:12.340 --> 1:53:16.380\n or stepping stones for other things that could come after.\n\n1:53:16.380 --> 1:53:18.740\n But it still feels from an individual perspective\n\n1:53:18.740 --> 1:53:21.100\n that I matter a lot.\n\n1:53:21.100 --> 1:53:24.500\n But even if I'm just a little cog in a giant machine,\n\n1:53:24.500 --> 1:53:28.140\n is that just a silly human notion\n\n1:53:28.140 --> 1:53:31.220\n in an individualistic society, no, she'll let go of that?\n\n1:53:32.780 --> 1:53:35.740\n Do you find beauty in being part of the giant machine?\n\n1:53:36.700 --> 1:53:38.980\n Yeah, I think it's meaningful.\n\n1:53:38.980 --> 1:53:41.500\n I think it adds purpose to your life\n\n1:53:41.500 --> 1:53:43.540\n that you are part of something bigger.\n\n1:53:45.340 --> 1:53:50.340\n That said, do you ponder your individual agent's mortality?\n\n1:53:51.780 --> 1:53:53.700\n Do you think about death?\n\n1:53:53.700 --> 1:53:54.700\n Do you fear death?\n\n1:53:56.660 --> 1:54:00.620\n Well, certainly more now than when I was a youngster\n\n1:54:00.620 --> 1:54:05.580\n and did skydiving and paragliding and all these things.\n\n1:54:05.580 --> 1:54:06.820\n You've become wiser.\n\n1:54:09.020 --> 1:54:13.900\n There is a reason for this life arc\n\n1:54:13.900 --> 1:54:17.100\n that younger folks are more fearless in many ways.\n\n1:54:17.100 --> 1:54:18.740\n That's part of the exploration.\n\n1:54:20.660 --> 1:54:22.100\n They are the individuals who think,\n\n1:54:22.100 --> 1:54:24.780\n hmm, I wonder what's over those mountains\n\n1:54:24.780 --> 1:54:27.020\n or what if I go really far in that ocean?\n\n1:54:27.020 --> 1:54:27.940\n What would I find?\n\n1:54:27.940 --> 1:54:32.140\n I mean, older folks don't necessarily think that way,\n\n1:54:32.140 --> 1:54:34.820\n but younger do and it's kind of counterintuitive.\n\n1:54:34.820 --> 1:54:39.100\n So yeah, but logically it's like,\n\n1:54:39.100 --> 1:54:40.060\n you have a limited amount of time,\n\n1:54:40.060 --> 1:54:42.420\n what can you do with it that matters?\n\n1:54:42.420 --> 1:54:45.300\n So you try to, you have done your exploration,\n\n1:54:45.300 --> 1:54:48.100\n you committed to a certain direction\n\n1:54:48.100 --> 1:54:50.340\n and you become an expert perhaps in it.\n\n1:54:50.340 --> 1:54:52.460\n What can I do that matters\n\n1:54:52.460 --> 1:54:55.500\n with the limited resources that I have?\n\n1:54:55.500 --> 1:54:59.700\n That's how I think a lot of people, myself included,\n\n1:54:59.700 --> 1:55:02.380\n start thinking later on in their career.\n\n1:55:02.380 --> 1:55:05.540\n And like you said, leave a bit of a trace\n\n1:55:05.540 --> 1:55:08.460\n and a bit of an impact even though after the agent is gone.\n\n1:55:08.460 --> 1:55:10.060\n Yeah, that's the goal.\n\n1:55:11.180 --> 1:55:13.580\n Well, this was a fascinating conversation.\n\n1:55:13.580 --> 1:55:15.860\n I don't think there's a better way to end it.\n\n1:55:15.860 --> 1:55:16.980\n Thank you so much.\n\n1:55:16.980 --> 1:55:19.380\n So first of all, I'm very inspired\n\n1:55:19.380 --> 1:55:22.900\n of how vibrant the community at UT Austin and Austin is.\n\n1:55:22.900 --> 1:55:25.500\n It's really exciting for me to see it.\n\n1:55:25.500 --> 1:55:29.900\n And this whole field seems like profound philosophically,\n\n1:55:29.900 --> 1:55:31.220\n but also the path forward\n\n1:55:31.220 --> 1:55:33.260\n for the artificial intelligence community.\n\n1:55:33.260 --> 1:55:35.300\n So thank you so much for explaining\n\n1:55:35.300 --> 1:55:36.780\n so many cool things to me today\n\n1:55:36.780 --> 1:55:39.140\n and for wasting all of your valuable time with me.\n\n1:55:39.140 --> 1:55:40.340\n Oh, it was a pleasure.\n\n1:55:40.340 --> 1:55:41.180\n Thanks.\n\n1:55:41.180 --> 1:55:42.740\n I appreciate it.\n\n1:55:42.740 --> 1:55:44.420\n Thanks for listening to this conversation\n\n1:55:44.420 --> 1:55:45.860\n with Risto McAlignan.\n\n1:55:45.860 --> 1:55:48.620\n And thank you to the Jordan Harbinger Show,\n\n1:55:48.620 --> 1:55:51.940\n Grammarly, Belcampo, and Indeed.\n\n1:55:51.940 --> 1:55:55.500\n Check them out in the description to support this podcast.\n\n1:55:55.500 --> 1:55:59.300\n And now let me leave you with some words from Carl Sagan.\n\n1:55:59.300 --> 1:56:01.700\n Extinction is the rule.\n\n1:56:01.700 --> 1:56:03.980\n Survival is the exception.\n\n1:56:04.860 --> 1:56:05.980\n Thank you for listening.\n\n1:56:05.980 --> 1:56:18.980\n I hope to see you next time.\n\n"
}
{
  "title": "Peter Norvig: Artificial Intelligence: A Modern Approach | Lex Fridman Podcast #42",
  "id": "_VPxEcT_Adc",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:02.800\n The following is a conversation with Peter Norvig.\n\n00:02.800 --> 00:05.000\n He's the Director of Research at Google\n\n00:05.000 --> 00:07.880\n and the coauthor with Stuart Russell of the book\n\n00:07.880 --> 00:10.640\n Artificial Intelligence, A Modern Approach,\n\n00:10.640 --> 00:13.680\n that educated and inspired a whole generation\n\n00:13.680 --> 00:15.640\n of researchers, including myself,\n\n00:15.640 --> 00:18.840\n to get into the field of artificial intelligence.\n\n00:18.840 --> 00:21.720\n This is the Artificial Intelligence Podcast.\n\n00:21.720 --> 00:24.120\n If you enjoy it, subscribe on YouTube,\n\n00:24.120 --> 00:27.160\n give five stars on iTunes, support on Patreon,\n\n00:27.160 --> 00:29.040\n or simply connect with me on Twitter.\n\n00:29.040 --> 00:32.800\n I'm Lex Friedman, spelled F R I D M A N.\n\n00:32.800 --> 00:36.640\n And now, here's my conversation with Peter Norvig.\n\n00:37.680 --> 00:40.800\n Most researchers in the AI community, including myself,\n\n00:40.800 --> 00:43.040\n own all three editions, red, green, and blue,\n\n00:43.040 --> 00:46.400\n of the Artificial Intelligence, A Modern Approach.\n\n00:46.400 --> 00:49.360\n It's a field defining textbook, as many people are aware,\n\n00:49.360 --> 00:52.120\n that you wrote with Stuart Russell.\n\n00:52.120 --> 00:55.320\n How has the book changed and how have you changed\n\n00:55.320 --> 00:57.200\n in relation to it from the first edition\n\n00:57.200 --> 01:00.040\n to the second to the third and now fourth edition\n\n01:00.040 --> 01:00.880\n as you work on it?\n\n01:00.880 --> 01:04.280\n Yeah, so it's been a lot of years, a lot of changes.\n\n01:04.280 --> 01:05.960\n One of the things changing from the first\n\n01:05.960 --> 01:08.600\n to maybe the second or third\n\n01:09.480 --> 01:12.920\n was just the rise of computing power, right?\n\n01:12.920 --> 01:17.720\n So I think in the first edition, we said,\n\n01:17.720 --> 01:22.520\n here's predicate logic, but that only goes so far\n\n01:22.520 --> 01:27.520\n because pretty soon you have millions of short little\n\n01:27.520 --> 01:30.400\n predicate expressions and they can possibly fit in memory.\n\n01:31.480 --> 01:34.640\n So we're gonna use first order logic that's more concise.\n\n01:35.720 --> 01:38.000\n And then we quickly realized,\n\n01:38.000 --> 01:40.400\n oh, predicate logic is pretty nice\n\n01:40.400 --> 01:44.200\n because there are really fast SAT solvers and other things.\n\n01:44.200 --> 01:46.320\n And look, there's only millions of expressions\n\n01:46.320 --> 01:48.280\n and that fits easily into memory,\n\n01:48.280 --> 01:51.200\n or maybe even billions fit into memory now.\n\n01:51.200 --> 01:54.560\n So that was a change of the type of technology we needed\n\n01:54.560 --> 01:56.720\n just because the hardware expanded.\n\n01:56.720 --> 01:58.200\n Even to the second edition,\n\n01:58.200 --> 02:00.720\n resource constraints were loosened significantly\n\n02:00.720 --> 02:01.880\n for the second.\n\n02:01.880 --> 02:04.880\n And that was early 2000s second edition.\n\n02:04.880 --> 02:09.880\n Right, so 95 was the first and then 2000, 2001 or so.\n\n02:10.520 --> 02:12.280\n And then moving on from there,\n\n02:12.280 --> 02:17.040\n I think we're starting to see that again with the GPUs\n\n02:17.040 --> 02:20.640\n and then more specific type of machinery\n\n02:20.640 --> 02:25.440\n like the TPUs and you're seeing custom ASICs and so on\n\n02:25.440 --> 02:26.280\n for deep learning.\n\n02:26.280 --> 02:30.520\n So we're seeing another advance in terms of the hardware.\n\n02:30.520 --> 02:33.640\n Then I think another thing that we especially noticed\n\n02:33.640 --> 02:37.160\n this time around is in all three of the first editions,\n\n02:37.160 --> 02:40.200\n we kind of said, well, we're gonna find AI\n\n02:40.200 --> 02:43.000\n as maximizing expected utility\n\n02:43.000 --> 02:45.520\n and you tell me your utility function.\n\n02:45.520 --> 02:49.560\n And now we've got 27 chapters where the cool techniques\n\n02:49.560 --> 02:51.840\n for how to optimize that.\n\n02:51.840 --> 02:54.080\n I think in this edition, we're saying more,\n\n02:54.080 --> 02:56.880\n you know what, maybe that optimization part\n\n02:56.880 --> 02:59.920\n is the easy part and the hard part is deciding\n\n02:59.920 --> 03:01.640\n what is my utility function?\n\n03:01.640 --> 03:03.040\n What do I want?\n\n03:03.040 --> 03:06.360\n And if I'm a collection of agents or a society,\n\n03:06.360 --> 03:08.400\n what do we want as a whole?\n\n03:08.400 --> 03:10.120\n So you touched that topic in this edition.\n\n03:10.120 --> 03:11.960\n You get a little bit more into utility.\n\n03:11.960 --> 03:12.800\n Yeah.\n\n03:12.800 --> 03:13.640\n That's really interesting.\n\n03:13.640 --> 03:15.480\n On a technical level,\n\n03:15.480 --> 03:17.560\n we're almost pushing the philosophical.\n\n03:17.560 --> 03:19.320\n I guess it is philosophical, right?\n\n03:19.320 --> 03:21.640\n So we've always had a philosophy chapter,\n\n03:21.640 --> 03:26.040\n which I was glad that we were supporting.\n\n03:27.360 --> 03:32.360\n And now it's less kind of the Chinese room type argument\n\n03:33.000 --> 03:37.560\n and more of these ethical and societal type issues.\n\n03:37.560 --> 03:41.920\n So we get into the issues of fairness and bias\n\n03:41.920 --> 03:45.960\n and just the issue of aggregating utilities.\n\n03:45.960 --> 03:49.800\n So how do you encode human values into a utility function?\n\n03:49.800 --> 03:53.520\n Is this something that you can do purely through data\n\n03:53.520 --> 03:56.840\n in a learned way or is there some systematic,\n\n03:56.840 --> 03:58.560\n obviously there's no good answers yet.\n\n03:58.560 --> 04:01.560\n There's just beginnings to this,\n\n04:01.560 --> 04:02.880\n to even opening the doors to these questions.\n\n04:02.880 --> 04:04.320\n So there is no one answer.\n\n04:04.320 --> 04:07.520\n Yes, there are techniques to try to learn that.\n\n04:07.520 --> 04:10.800\n So we talk about inverse reinforcement learning, right?\n\n04:10.800 --> 04:14.120\n So reinforcement learning, you take some actions,\n\n04:14.120 --> 04:16.200\n you get some rewards and you figure out\n\n04:16.200 --> 04:18.000\n what actions you should take.\n\n04:18.000 --> 04:20.160\n And inverse reinforcement learning,\n\n04:20.160 --> 04:24.520\n you observe somebody taking actions and you figure out,\n\n04:24.520 --> 04:27.240\n well, this must be what they were trying to do.\n\n04:27.240 --> 04:30.360\n If they did this action, it must be because they want it.\n\n04:30.360 --> 04:33.000\n Of course, there's restrictions to that, right?\n\n04:33.000 --> 04:36.200\n So lots of people take actions that are self destructive\n\n04:37.120 --> 04:39.200\n or they're suboptimal in certain ways.\n\n04:39.200 --> 04:40.640\n So you don't wanna learn that.\n\n04:40.640 --> 04:44.800\n You wanna somehow learn the perfect actions\n\n04:44.800 --> 04:46.480\n rather than the ones they actually take.\n\n04:46.480 --> 04:50.080\n So that's a challenge for that field.\n\n04:51.360 --> 04:55.800\n Then another big part of it is just kind of theoretical\n\n04:55.800 --> 04:58.720\n of saying, what can we accomplish?\n\n04:58.720 --> 05:03.720\n And so you look at like this work on the programs\n\n05:04.480 --> 05:09.480\n to predict recidivism and decide who should get parole\n\n05:09.480 --> 05:11.280\n or who should get bail or whatever.\n\n05:12.240 --> 05:13.960\n And how are you gonna evaluate that?\n\n05:13.960 --> 05:16.880\n And one of the big issues is fairness\n\n05:16.880 --> 05:18.960\n across protected classes.\n\n05:18.960 --> 05:23.960\n Protected classes being things like sex and race and so on.\n\n05:23.960 --> 05:27.840\n And so two things you want is you wanna say,\n\n05:27.840 --> 05:32.000\n well, if I get a score of say six out of 10,\n\n05:32.000 --> 05:34.320\n then I want that to mean the same\n\n05:34.320 --> 05:37.040\n whether no matter what race I'm on, right?\n\n05:37.040 --> 05:39.840\n Yes, right, so I wanna have a 60% chance\n\n05:39.840 --> 05:43.320\n of reoccurring regardless.\n\n05:44.360 --> 05:48.560\n And one of the makers of a commercial program to do that\n\n05:48.560 --> 05:50.040\n says that's what we're trying to optimize\n\n05:50.040 --> 05:51.280\n and look, we achieved that.\n\n05:51.280 --> 05:56.120\n We've reached that kind of balance.\n\n05:56.120 --> 05:57.520\n And then on the other side,\n\n05:57.520 --> 06:01.840\n you also wanna say, well, if it makes mistakes,\n\n06:01.840 --> 06:04.680\n I want that to affect both sides\n\n06:04.680 --> 06:07.240\n of the protected class equally.\n\n06:07.240 --> 06:09.000\n And it turns out they don't do that, right?\n\n06:09.000 --> 06:12.160\n So they're twice as likely to make a mistake\n\n06:12.160 --> 06:14.800\n that would harm a black person over a white person.\n\n06:14.800 --> 06:16.480\n So that seems unfair.\n\n06:16.480 --> 06:17.320\n So you'd like to say,\n\n06:17.320 --> 06:19.600\n well, I wanna achieve both those goals.\n\n06:19.600 --> 06:21.360\n And then it turns out you do the analysis\n\n06:21.360 --> 06:22.960\n and it's theoretically impossible\n\n06:22.960 --> 06:24.120\n to achieve both those goals.\n\n06:24.120 --> 06:27.080\n So you have to trade them off one against the other.\n\n06:27.080 --> 06:29.040\n So that analysis is really helpful\n\n06:29.040 --> 06:32.360\n to know what you can aim for and how much you can get.\n\n06:32.360 --> 06:33.920\n You can't have everything.\n\n06:33.920 --> 06:35.480\n But the analysis certainly can't tell you\n\n06:35.480 --> 06:38.440\n where should we make that trade off point.\n\n06:38.440 --> 06:41.960\n But nevertheless, then we can as humans deliberate\n\n06:41.960 --> 06:43.120\n where that trade off should be.\n\n06:43.120 --> 06:45.840\n Yeah, so at least we now we're arguing in an informed way.\n\n06:45.840 --> 06:48.240\n We're not asking for something impossible.\n\n06:48.240 --> 06:50.040\n We're saying, here's where we are\n\n06:50.040 --> 06:51.720\n and here's what we aim for.\n\n06:51.720 --> 06:55.840\n And this strategy is better than that strategy.\n\n06:55.840 --> 06:58.880\n So that's, I would argue is a really powerful\n\n06:58.880 --> 07:00.560\n and really important first step,\n\n07:00.560 --> 07:02.800\n but it's a doable one sort of removing\n\n07:02.800 --> 07:07.560\n undesirable degrees of bias in systems\n\n07:07.560 --> 07:08.920\n in terms of protected classes.\n\n07:08.920 --> 07:10.120\n And then there's something I listened\n\n07:10.120 --> 07:12.480\n to your commencement speech,\n\n07:12.480 --> 07:15.560\n or there's some fuzzier things like,\n\n07:15.560 --> 07:17.640\n you mentioned angry birds.\n\n07:17.640 --> 07:22.640\n Do you wanna create systems that feed the dopamine enjoyment\n\n07:23.040 --> 07:26.720\n that feed, that optimize for you returning to the system,\n\n07:26.720 --> 07:30.480\n enjoying the moment of playing the game of getting likes\n\n07:30.480 --> 07:32.000\n or whatever, this kind of thing,\n\n07:32.000 --> 07:34.800\n or some kind of longterm improvement?\n\n07:34.800 --> 07:36.040\n Right.\n\n07:36.040 --> 07:39.600\n Are you even thinking about that?\n\n07:39.600 --> 07:43.200\n That's really going to the philosophical area.\n\n07:43.200 --> 07:45.720\n No, I think that's a really important issue too.\n\n07:45.720 --> 07:46.760\n Certainly thinking about that.\n\n07:46.760 --> 07:50.720\n I don't think about that as an AI issue as much.\n\n07:52.240 --> 07:57.240\n But as you say, the point is we've built this society\n\n07:57.240 --> 08:02.240\n and this infrastructure where we say we have a marketplace\n\n08:02.240 --> 08:07.240\n for attention and we've decided as a society\n\n08:07.240 --> 08:09.360\n that we like things that are free.\n\n08:09.360 --> 08:13.160\n And so we want all the apps on our phone to be free.\n\n08:13.160 --> 08:15.360\n And that means they're all competing for your attention.\n\n08:15.360 --> 08:17.880\n And then eventually they make some money some way\n\n08:17.880 --> 08:21.040\n through ads or in game sales or whatever.\n\n08:22.400 --> 08:26.560\n But they can only win by defeating all the other apps\n\n08:26.560 --> 08:28.680\n by instilling your attention.\n\n08:28.680 --> 08:33.680\n And we build a marketplace where it seems like\n\n08:34.320 --> 08:38.320\n they're working against you rather than working with you.\n\n08:38.320 --> 08:41.120\n And I'd like to find a way where we can change\n\n08:41.120 --> 08:43.200\n the playing field so you feel more like,\n\n08:43.200 --> 08:44.920\n well, these things are on my side.\n\n08:46.040 --> 08:49.040\n Yes, they're letting me have some fun in the short term,\n\n08:49.040 --> 08:51.520\n but they're also helping me in the long term\n\n08:52.520 --> 08:54.280\n rather than competing against me.\n\n08:54.280 --> 08:56.680\n And those aren't necessarily conflicting objectives.\n\n08:56.680 --> 09:00.760\n They're just the incentives, the direct current incentives\n\n09:00.760 --> 09:02.720\n as we try to figure out this whole new world\n\n09:02.720 --> 09:06.120\n seem to be on the easier part of that,\n\n09:06.120 --> 09:08.720\n which is feeding the dopamine, the rush.\n\n09:08.720 --> 09:09.560\n Right.\n\n09:09.560 --> 09:14.560\n But so maybe taking a quick step back at the beginning\n\n09:15.960 --> 09:17.480\n of the Artificial Intelligence,\n\n09:17.480 --> 09:19.640\n the Modern Approach book of writing.\n\n09:19.640 --> 09:21.760\n So here you are in the 90s.\n\n09:21.760 --> 09:25.720\n When you first sat down with Stuart to write the book\n\n09:25.720 --> 09:27.840\n to cover an entire field,\n\n09:27.840 --> 09:30.600\n which is one of the only books that's successfully done that\n\n09:30.600 --> 09:33.720\n for AI and actually in a lot of other computer science\n\n09:33.720 --> 09:37.400\n fields, it's a huge undertaking.\n\n09:37.400 --> 09:40.840\n So it must've been quite daunting.\n\n09:40.840 --> 09:42.120\n What was that process like?\n\n09:42.120 --> 09:44.960\n Did you envision that you would be trying to cover\n\n09:44.960 --> 09:46.080\n the entire field?\n\n09:47.280 --> 09:48.840\n Was there a systematic approach to it\n\n09:48.840 --> 09:50.360\n that was more step by step?\n\n09:50.360 --> 09:52.200\n How was, how did it feel?\n\n09:52.200 --> 09:54.440\n So I guess it came about,\n\n09:54.440 --> 09:57.440\n go to lunch with the other AI faculty at Berkeley\n\n09:57.440 --> 10:00.760\n and we'd say, the field is changing.\n\n10:00.760 --> 10:03.680\n It seems like the current books are a little bit behind.\n\n10:03.680 --> 10:05.280\n Nobody's come out with a new book recently.\n\n10:05.280 --> 10:06.880\n We should do that.\n\n10:06.880 --> 10:09.120\n And everybody said, yeah, yeah, that's a great thing to do.\n\n10:09.120 --> 10:10.120\n And we never did anything.\n\n10:10.120 --> 10:11.120\n Right.\n\n10:11.120 --> 10:14.400\n And then I ended up heading off to industry.\n\n10:14.400 --> 10:16.000\n I went to Sun Labs.\n\n10:16.000 --> 10:19.000\n So I thought, well, that's the end of my possible\n\n10:19.000 --> 10:20.800\n academic publishing career.\n\n10:21.840 --> 10:25.280\n But I met Stuart again at a conference like a year later\n\n10:25.280 --> 10:28.240\n and said, you know that book we were always talking about,\n\n10:28.240 --> 10:30.400\n you guys must be half done with it by now, right?\n\n10:30.400 --> 10:34.160\n And he said, well, we keep talking, we never do anything.\n\n10:34.160 --> 10:36.120\n So I said, well, you know, we should do it.\n\n10:36.120 --> 10:40.600\n And I think the reason is that we all felt\n\n10:40.600 --> 10:43.480\n it was a time where the field was changing.\n\n10:44.640 --> 10:46.640\n And that was in two ways.\n\n10:46.640 --> 10:49.080\n So, you know, the good old fashioned AI\n\n10:49.080 --> 10:52.160\n was based primarily on Boolean logic.\n\n10:52.160 --> 10:55.680\n And you had a few tricks to deal with uncertainty.\n\n10:55.680 --> 10:59.040\n And it was based primarily on knowledge engineering.\n\n10:59.040 --> 11:00.920\n That the way you got something done is you went out,\n\n11:00.920 --> 11:03.600\n you interviewed an expert and you wrote down by hand\n\n11:03.600 --> 11:04.600\n everything they knew.\n\n11:05.520 --> 11:10.520\n And we saw in 95 that the field was changing in two ways.\n\n11:10.520 --> 11:13.760\n One, we're moving more towards probability\n\n11:13.760 --> 11:15.240\n rather than Boolean logic.\n\n11:15.240 --> 11:17.640\n And we're moving more towards machine learning\n\n11:17.640 --> 11:20.440\n rather than knowledge engineering.\n\n11:20.440 --> 11:22.920\n And the other books hadn't caught that way\n\n11:22.920 --> 11:26.680\n if they were still in the, more in the old school.\n\n11:26.680 --> 11:29.920\n Although, so certainly they had part of that on the way.\n\n11:29.920 --> 11:33.600\n But we said, if we start now completely taking\n\n11:33.600 --> 11:36.640\n that point of view, we can have a different kind of book.\n\n11:36.640 --> 11:38.480\n And we were able to put that together.\n\n11:39.920 --> 11:44.200\n And what was literally the process if you remember,\n\n11:44.200 --> 11:46.800\n did you start writing a chapter?\n\n11:46.800 --> 11:48.680\n Did you outline?\n\n11:48.680 --> 11:50.640\n Yeah, I guess we did an outline\n\n11:50.640 --> 11:54.920\n and then we sort of assigned chapters to each person.\n\n11:55.960 --> 11:58.200\n At the time I had moved to Boston\n\n11:58.200 --> 12:00.080\n and Stuart was in Berkeley.\n\n12:00.080 --> 12:04.440\n So basically we did it over the internet.\n\n12:04.440 --> 12:08.000\n And, you know, that wasn't the same as doing it today.\n\n12:08.000 --> 12:13.000\n It meant, you know, dial up lines and telnetting in.\n\n12:13.000 --> 12:18.000\n And, you know, you telnet it into one shell\n\n12:19.320 --> 12:21.040\n and you type cat file name\n\n12:21.040 --> 12:23.840\n and you hoped it was captured at the other end.\n\n12:23.840 --> 12:26.120\n And certainly you're not sending images\n\n12:26.120 --> 12:27.200\n and figures back and forth.\n\n12:27.200 --> 12:29.640\n Right, right, that didn't work.\n\n12:29.640 --> 12:31.440\n But, you know, did you anticipate\n\n12:31.440 --> 12:36.440\n where the field would go from that day, from the 90s?\n\n12:37.680 --> 12:42.680\n Did you see the growth into learning based methods\n\n12:42.680 --> 12:44.640\n and to data driven methods\n\n12:44.640 --> 12:47.040\n that followed in the future decades?\n\n12:47.040 --> 12:50.920\n We certainly thought that learning was important.\n\n12:51.960 --> 12:56.960\n I guess we missed it as being as important as it is today.\n\n12:58.040 --> 13:00.080\n We missed this idea of big data.\n\n13:00.080 --> 13:02.760\n We missed that the idea of deep learning\n\n13:02.760 --> 13:04.440\n hadn't been invented yet.\n\n13:04.440 --> 13:07.480\n We could have taken the book\n\n13:07.480 --> 13:11.160\n from a complete machine learning point of view\n\n13:11.160 --> 13:12.400\n right from the start.\n\n13:12.400 --> 13:15.080\n We chose to do it more from a point of view\n\n13:15.080 --> 13:16.920\n of we're gonna first develop\n\n13:16.920 --> 13:19.120\n different types of representations.\n\n13:19.120 --> 13:22.600\n And we're gonna talk about different types of environments.\n\n13:24.000 --> 13:26.600\n Is it fully observable or partially observable?\n\n13:26.600 --> 13:29.720\n And is it deterministic or stochastic and so on?\n\n13:29.720 --> 13:33.360\n And we made it more complex along those axes\n\n13:33.360 --> 13:38.000\n rather than focusing on the machine learning axis first.\n\n13:38.000 --> 13:40.000\n Do you think, you know, there's some sense\n\n13:40.000 --> 13:44.160\n in which the deep learning craze is extremely successful\n\n13:44.160 --> 13:46.320\n for a particular set of problems.\n\n13:46.320 --> 13:49.360\n And, you know, eventually it's going to,\n\n13:49.360 --> 13:52.520\n in the general case, hit challenges.\n\n13:52.520 --> 13:56.280\n So in terms of the difference between perception systems\n\n13:56.280 --> 13:59.000\n and robots that have to act in the world,\n\n13:59.000 --> 14:01.360\n do you think we're gonna return\n\n14:01.360 --> 14:06.200\n to AI modern approach type breadth\n\n14:06.200 --> 14:08.760\n in addition five and six?\n\n14:08.760 --> 14:12.360\n In future decades, do you think deep learning\n\n14:12.360 --> 14:14.080\n will take its place as a chapter\n\n14:14.080 --> 14:17.920\n in this bigger view of AI?\n\n14:17.920 --> 14:19.320\n Yeah, I think we don't know yet\n\n14:19.320 --> 14:21.080\n how it's all gonna play out.\n\n14:21.080 --> 14:26.080\n So in the new edition, we have a chapter on deep learning.\n\n14:26.240 --> 14:29.480\n We got Ian Goodfellow to be the guest author\n\n14:29.480 --> 14:30.600\n for that chapter.\n\n14:30.600 --> 14:34.800\n So he said he could condense his whole deep learning book\n\n14:34.800 --> 14:35.960\n into one chapter.\n\n14:35.960 --> 14:38.240\n I think he did a great job.\n\n14:38.240 --> 14:40.560\n We were also encouraged that he's, you know,\n\n14:40.560 --> 14:43.600\n we gave him the old neural net chapter\n\n14:43.600 --> 14:47.280\n and said, modernize that.\n\n14:47.280 --> 14:50.280\n And he said, you know, half of that was okay.\n\n14:50.280 --> 14:52.960\n That certainly there's lots of new things\n\n14:52.960 --> 14:54.000\n that have been developed,\n\n14:54.000 --> 14:56.400\n but some of the core was still the same.\n\n14:58.000 --> 15:02.320\n So I think we'll gain a better understanding\n\n15:02.320 --> 15:04.240\n of what you can do there.\n\n15:04.240 --> 15:07.040\n I think we'll need to incorporate\n\n15:07.040 --> 15:10.040\n all the things we can do with the other technologies, right?\n\n15:10.040 --> 15:14.680\n So deep learning started out with convolutional networks\n\n15:14.680 --> 15:17.840\n and very close to perception.\n\n15:18.880 --> 15:23.280\n And it's since moved to be able to do more\n\n15:23.280 --> 15:27.340\n with actions and some degree of longer term planning.\n\n15:28.680 --> 15:30.160\n But we need to do a better job\n\n15:30.160 --> 15:32.640\n with representation than reasoning\n\n15:32.640 --> 15:36.280\n and one shot learning and so on.\n\n15:36.280 --> 15:41.120\n And I think we don't know yet how that's gonna play out.\n\n15:41.120 --> 15:45.840\n So do you think looking at some success,\n\n15:45.840 --> 15:49.840\n but certainly eventual demise,\n\n15:49.840 --> 15:51.520\n a partial demise of experts\n\n15:51.520 --> 15:54.160\n to symbolic systems in the 80s,\n\n15:54.160 --> 15:56.560\n do you think there is kernels of wisdom\n\n15:56.560 --> 15:59.040\n and the work that was done there\n\n15:59.040 --> 16:01.080\n with logic and reasoning and so on\n\n16:01.080 --> 16:05.700\n that will rise again in your view?\n\n16:05.700 --> 16:08.640\n So certainly I think the idea of representation\n\n16:08.640 --> 16:10.360\n and reasoning is crucial\n\n16:10.360 --> 16:13.980\n that sometimes you just don't have enough data\n\n16:13.980 --> 16:17.360\n about the world to learn de novo.\n\n16:17.360 --> 16:22.000\n So you've got to have some idea of representation,\n\n16:22.000 --> 16:24.920\n whether that was programmed in or told or whatever,\n\n16:24.920 --> 16:28.600\n and then be able to take steps of reasoning.\n\n16:28.600 --> 16:33.600\n I think the problem with the good old fashioned AI\n\n16:33.600 --> 16:38.600\n was one, we tried to base everything on these symbols\n\n16:39.940 --> 16:41.420\n that were atomic.\n\n16:42.540 --> 16:45.500\n And that's great if you're like trying to define\n\n16:45.500 --> 16:47.580\n the properties of a triangle, right?\n\n16:47.580 --> 16:50.700\n Because they have necessary and sufficient conditions.\n\n16:50.700 --> 16:52.020\n But things in the real world don't.\n\n16:52.020 --> 16:55.260\n The real world is messy and doesn't have sharp edges\n\n16:55.260 --> 16:57.380\n and atomic symbols do.\n\n16:57.380 --> 16:59.300\n So that was a poor match.\n\n16:59.300 --> 17:04.300\n And then the other aspect was that the reasoning\n\n17:05.740 --> 17:09.740\n was universal and applied anywhere,\n\n17:09.740 --> 17:11.140\n which in some sense is good,\n\n17:11.140 --> 17:13.260\n but it also means there's no guidance\n\n17:13.260 --> 17:15.140\n as to where to apply.\n\n17:15.140 --> 17:17.780\n And so you started getting these paradoxes\n\n17:17.780 --> 17:20.640\n like, well, if I have a mountain\n\n17:20.640 --> 17:22.980\n and I remove one grain of sand,\n\n17:22.980 --> 17:25.140\n then it's still a mountain.\n\n17:25.140 --> 17:28.780\n But if I do that repeatedly, at some point it's not, right?\n\n17:28.780 --> 17:32.300\n And with logic, there's nothing to stop you\n\n17:32.300 --> 17:35.900\n from applying things repeatedly.\n\n17:37.340 --> 17:42.020\n But maybe with something like deep learning,\n\n17:42.020 --> 17:44.660\n and I don't really know what the right name for it is,\n\n17:44.660 --> 17:46.240\n we could separate out those ideas.\n\n17:46.240 --> 17:51.240\n So one, we could say a mountain isn't just an atomic notion.\n\n17:52.860 --> 17:56.060\n It's some sort of something like a word embedding\n\n17:56.060 --> 18:01.060\n that has a more complex representation.\n\n18:02.300 --> 18:05.080\n And secondly, we could somehow learn,\n\n18:05.080 --> 18:06.740\n yeah, there's this rule that you can remove\n\n18:06.740 --> 18:09.260\n one grain of sand and you can do that a bunch of times,\n\n18:09.260 --> 18:12.860\n but you can't do it a near infinite amount of times.\n\n18:12.860 --> 18:15.240\n But on the other hand, when you're doing induction\n\n18:15.240 --> 18:17.260\n on the integer, sure, then it's fine to do it\n\n18:17.260 --> 18:18.800\n an infinite number of times.\n\n18:18.800 --> 18:22.180\n And if we could, somehow we have to learn\n\n18:22.180 --> 18:24.660\n when these strategies are applicable\n\n18:24.660 --> 18:28.220\n rather than having the strategies be completely neutral\n\n18:28.220 --> 18:31.220\n and available everywhere.\n\n18:31.220 --> 18:32.380\n Anytime you use neural networks,\n\n18:32.380 --> 18:34.340\n anytime you learn from data,\n\n18:34.340 --> 18:36.980\n form representation from data in an automated way,\n\n18:36.980 --> 18:41.020\n it's not very explainable as to,\n\n18:41.020 --> 18:44.180\n or it's not introspective to us humans\n\n18:45.100 --> 18:48.180\n in terms of how this neural network sees the world,\n\n18:48.180 --> 18:53.180\n where, why does it succeed so brilliantly in so many cases\n\n18:53.180 --> 18:56.460\n and fail so miserably in surprising ways and small.\n\n18:56.460 --> 19:00.980\n So what do you think is the future there?\n\n19:00.980 --> 19:03.460\n Can simply more data, better data,\n\n19:03.460 --> 19:06.100\n more organized data solve that problem?\n\n19:06.100 --> 19:09.280\n Or is there elements of symbolic systems\n\n19:09.280 --> 19:10.380\n that need to be brought in\n\n19:10.380 --> 19:12.140\n which are a little bit more explainable?\n\n19:12.140 --> 19:16.820\n Yeah, so I prefer to talk about trust\n\n19:16.820 --> 19:20.340\n and validation and verification\n\n19:20.340 --> 19:22.500\n rather than just about explainability.\n\n19:22.500 --> 19:25.300\n And then I think explanations are one tool\n\n19:25.300 --> 19:27.720\n that you use towards those goals.\n\n19:28.900 --> 19:30.660\n And I think it is an important issue\n\n19:30.660 --> 19:33.980\n that we don't wanna use these systems unless we trust them\n\n19:33.980 --> 19:35.500\n and we wanna understand where they work\n\n19:35.500 --> 19:37.060\n and where they don't work.\n\n19:37.060 --> 19:40.820\n And an explanation can be part of that, right?\n\n19:40.820 --> 19:44.460\n So I apply for a loan and I get denied,\n\n19:44.460 --> 19:46.140\n I want some explanation of why.\n\n19:46.140 --> 19:50.220\n And you have, in Europe, we have the GDPR\n\n19:50.220 --> 19:52.700\n that says you're required to be able to get that.\n\n19:53.940 --> 19:54.860\n But on the other hand,\n\n19:54.860 --> 19:57.220\n the explanation alone is not enough, right?\n\n19:57.220 --> 20:01.300\n So we are used to dealing with people\n\n20:01.300 --> 20:04.820\n and with organizations and corporations and so on,\n\n20:04.820 --> 20:06.260\n and they can give you an explanation\n\n20:06.260 --> 20:07.360\n and you have no guarantee\n\n20:07.360 --> 20:11.220\n that that explanation relates to reality, right?\n\n20:11.220 --> 20:13.980\n So the bank can tell me, well, you didn't get the loan\n\n20:13.980 --> 20:16.100\n because you didn't have enough collateral.\n\n20:16.100 --> 20:18.240\n And that may be true, or it may be true\n\n20:18.240 --> 20:22.220\n that they just didn't like my religion or something else.\n\n20:22.220 --> 20:24.620\n I can't tell from the explanation,\n\n20:24.620 --> 20:27.660\n and that's true whether the decision was made\n\n20:27.660 --> 20:29.500\n by a computer or by a person.\n\n20:30.940 --> 20:32.100\n So I want more.\n\n20:33.420 --> 20:35.060\n I do wanna have the explanations\n\n20:35.060 --> 20:37.300\n and I wanna be able to have a conversation\n\n20:37.300 --> 20:39.380\n to go back and forth and said,\n\n20:39.380 --> 20:41.940\n well, you gave this explanation, but what about this?\n\n20:41.940 --> 20:44.180\n And what would have happened if this had happened?\n\n20:44.180 --> 20:48.020\n And what would I need to change that?\n\n20:48.020 --> 20:50.860\n So I think a conversation is a better way to think about it\n\n20:50.860 --> 20:54.380\n than just an explanation as a single output.\n\n20:55.300 --> 20:58.040\n And I think we need testing of various kinds, right?\n\n20:58.040 --> 20:59.380\n So in order to know,\n\n21:00.740 --> 21:03.460\n was the decision really based on my collateral\n\n21:03.460 --> 21:08.420\n or was it based on my religion or skin color or whatever?\n\n21:08.420 --> 21:10.900\n I can't tell if I'm only looking at my case,\n\n21:10.900 --> 21:12.940\n but if I look across all the cases,\n\n21:12.940 --> 21:15.620\n then I can detect the pattern, right?\n\n21:15.620 --> 21:18.340\n So you wanna have that kind of capability.\n\n21:18.340 --> 21:21.180\n You wanna have these adversarial testing, right?\n\n21:21.180 --> 21:23.060\n So we thought we were doing pretty good\n\n21:23.060 --> 21:25.860\n at object recognition in images.\n\n21:25.860 --> 21:28.500\n We said, look, we're at sort of pretty close\n\n21:28.500 --> 21:31.380\n to human level performance on ImageNet and so on.\n\n21:32.300 --> 21:34.860\n And then you start seeing these adversarial images\n\n21:34.860 --> 21:36.220\n and you say, wait a minute,\n\n21:36.220 --> 21:39.500\n that part is nothing like human performance.\n\n21:39.500 --> 21:40.900\n You can mess with it really easily.\n\n21:40.900 --> 21:42.700\n You can mess with it really easily, right?\n\n21:42.700 --> 21:45.500\n And yeah, you can do that to humans too, right?\n\n21:45.500 --> 21:46.340\n So we.\n\n21:46.340 --> 21:47.180\n In a different way perhaps.\n\n21:47.180 --> 21:49.500\n Right, humans don't know what color the dress was.\n\n21:49.500 --> 21:50.540\n Right.\n\n21:50.540 --> 21:52.460\n And so they're vulnerable to certain attacks\n\n21:52.460 --> 21:55.680\n that are different than the attacks on the machines,\n\n21:55.680 --> 21:59.420\n but the attacks on the machines are so striking.\n\n21:59.420 --> 22:00.800\n They really change the way you think\n\n22:00.800 --> 22:03.060\n about what we've done, right?\n\n22:03.060 --> 22:05.660\n And the way I think about it is,\n\n22:05.660 --> 22:08.300\n I think part of the problem is we're seduced\n\n22:08.300 --> 22:13.300\n by our low dimensional metaphors, right?\n\n22:13.660 --> 22:14.500\n Yeah.\n\n22:14.500 --> 22:15.700\n I like that phrase.\n\n22:15.700 --> 22:18.580\n You look in a textbook and you say,\n\n22:18.580 --> 22:20.340\n okay, now we've mapped out the space\n\n22:20.340 --> 22:24.980\n and a cat is here and dog is here\n\n22:24.980 --> 22:27.540\n and maybe there's a tiny little spot in the middle\n\n22:27.540 --> 22:28.600\n where you can't tell the difference,\n\n22:28.600 --> 22:30.740\n but mostly we've got it all covered.\n\n22:30.740 --> 22:33.300\n And if you believe that metaphor,\n\n22:33.300 --> 22:35.060\n then you say, well, we're nearly there.\n\n22:35.060 --> 22:39.220\n And there's only gonna be a couple adversarial images.\n\n22:39.220 --> 22:40.620\n But I think that's the wrong metaphor\n\n22:40.620 --> 22:42.300\n and what you should really say is,\n\n22:42.300 --> 22:45.940\n it's not a 2D flat space that we've got mostly covered.\n\n22:45.940 --> 22:47.620\n It's a million dimension space\n\n22:47.620 --> 22:52.620\n and a cat is this string that goes out in this crazy path.\n\n22:52.800 --> 22:55.820\n And if you step a little bit off the path in any direction,\n\n22:55.820 --> 22:57.820\n you're in nowhere's land\n\n22:57.820 --> 22:59.420\n and you don't know what's gonna happen.\n\n22:59.420 --> 23:01.160\n And so I think that's where we are\n\n23:01.160 --> 23:03.400\n and now we've got to deal with that.\n\n23:03.400 --> 23:06.180\n So it wasn't so much an explanation,\n\n23:06.180 --> 23:09.980\n but it was an understanding of what the models are\n\n23:09.980 --> 23:10.800\n and what they're doing\n\n23:10.800 --> 23:12.860\n and now we can start exploring, how do you fix that?\n\n23:12.860 --> 23:15.340\n Yeah, validating the robustness of the system and so on,\n\n23:15.340 --> 23:20.060\n but take it back to this word trust.\n\n23:20.060 --> 23:22.980\n Do you think we're a little too hard on our robots\n\n23:22.980 --> 23:25.740\n in terms of the standards we apply?\n\n23:25.740 --> 23:27.860\n So, you know,\n\n23:30.580 --> 23:34.100\n there's a dance in nonverbal\n\n23:34.100 --> 23:36.100\n and verbal communication between humans.\n\n23:37.100 --> 23:40.740\n If we apply the same kind of standard in terms of humans,\n\n23:40.740 --> 23:43.060\n we trust each other pretty quickly.\n\n23:43.940 --> 23:45.620\n You know, you and I haven't met before\n\n23:45.620 --> 23:48.360\n and there's some degree of trust, right?\n\n23:48.360 --> 23:50.580\n That nothing's gonna go crazy wrong\n\n23:50.580 --> 23:53.620\n and yet to AI, when we look at AI systems\n\n23:53.620 --> 23:58.620\n or we seem to approach skepticism always, always.\n\n23:58.700 --> 24:03.060\n And it's like they have to prove through a lot of hard work\n\n24:03.060 --> 24:06.700\n that they're even worthy of even inkling of our trust.\n\n24:06.700 --> 24:08.380\n What do you think about that?\n\n24:08.380 --> 24:11.180\n How do we break that barrier, close that gap?\n\n24:11.180 --> 24:12.020\n I think that's right.\n\n24:12.020 --> 24:13.780\n I think that's a big issue.\n\n24:13.780 --> 24:18.780\n Just listening, my friend Mark Moffat is a naturalist\n\n24:18.780 --> 24:22.220\n and he says, the most amazing thing about humans\n\n24:22.220 --> 24:25.120\n is that you can walk into a coffee shop\n\n24:25.120 --> 24:28.500\n or a busy street in a city\n\n24:28.500 --> 24:30.460\n and there's lots of people around you\n\n24:30.460 --> 24:34.100\n that you've never met before and you don't kill each other.\n\n24:34.100 --> 24:34.920\n Yeah.\n\n24:34.920 --> 24:36.580\n He says, chimpanzees cannot do that.\n\n24:36.580 --> 24:37.420\n Yeah, right.\n\n24:37.420 --> 24:38.660\n Right?\n\n24:38.660 --> 24:42.140\n If a chimpanzee's in a situation where here's some\n\n24:42.140 --> 24:46.660\n that aren't from my tribe, bad things happen.\n\n24:46.660 --> 24:47.580\n Especially in a coffee shop,\n\n24:47.580 --> 24:48.940\n there's delicious food around, you know.\n\n24:48.940 --> 24:49.900\n Yeah, yeah.\n\n24:49.900 --> 24:53.140\n But we humans have figured that out, right?\n\n24:53.140 --> 24:54.220\n And you know.\n\n24:54.220 --> 24:55.040\n For the most part.\n\n24:55.040 --> 24:55.880\n For the most part.\n\n24:55.880 --> 24:58.180\n We still go to war, we still do terrible things\n\n24:58.180 --> 25:01.020\n but for the most part, we've learned to trust each other\n\n25:01.020 --> 25:02.780\n and live together.\n\n25:02.780 --> 25:07.420\n So that's gonna be important for our AI systems as well.\n\n25:08.420 --> 25:13.420\n And also I think a lot of the emphasis is on AI\n\n25:13.660 --> 25:18.000\n but in many cases, AI is part of the technology\n\n25:18.000 --> 25:19.300\n but isn't really the main thing.\n\n25:19.300 --> 25:22.820\n So a lot of what we've seen is more due\n\n25:22.820 --> 25:27.380\n to communications technology than AI technology.\n\n25:27.380 --> 25:30.120\n Yeah, you wanna make these good decisions\n\n25:30.120 --> 25:33.900\n but the reason we're able to have any kind of system at all\n\n25:33.900 --> 25:35.820\n is we've got the communication\n\n25:35.820 --> 25:37.560\n so that we're collecting the data\n\n25:37.560 --> 25:41.500\n and so that we can reach lots of people around the world.\n\n25:41.500 --> 25:45.060\n I think that's a bigger change that we're dealing with.\n\n25:45.060 --> 25:47.780\n Speaking of reaching a lot of people around the world,\n\n25:47.780 --> 25:49.260\n on the side of education,\n\n25:51.380 --> 25:53.660\n one of the many things in terms of education you've done,\n\n25:53.660 --> 25:56.980\n you've taught the Intro to Artificial Intelligence course\n\n25:56.980 --> 26:00.640\n that signed up 160,000 students.\n\n26:00.640 --> 26:02.300\n There's one of the first successful example\n\n26:02.300 --> 26:06.780\n of a MOOC, Massive Open Online Course.\n\n26:06.780 --> 26:09.180\n What did you learn from that experience?\n\n26:09.180 --> 26:11.620\n What do you think is the future of MOOCs,\n\n26:11.620 --> 26:12.860\n of education online?\n\n26:12.860 --> 26:15.340\n Yeah, it was a great fun doing it,\n\n26:15.340 --> 26:18.460\n particularly being right at the start\n\n26:19.940 --> 26:21.660\n just because it was exciting and new\n\n26:21.660 --> 26:24.940\n but it also meant that we had less competition, right?\n\n26:24.940 --> 26:27.860\n So one of the things you hear about,\n\n26:27.860 --> 26:31.180\n well, the problem with MOOCs is the completion rates\n\n26:31.180 --> 26:33.820\n are so low so there must be a failure\n\n26:33.820 --> 26:37.580\n and I gotta admit, I'm a prime contributor, right?\n\n26:37.580 --> 26:40.780\n I probably started 50 different courses\n\n26:40.780 --> 26:42.400\n that I haven't finished\n\n26:42.400 --> 26:44.260\n but I got exactly what I wanted out of them\n\n26:44.260 --> 26:46.100\n because I had never intended to finish them.\n\n26:46.100 --> 26:48.680\n I just wanted to dabble in a little bit\n\n26:48.680 --> 26:50.300\n either to see the topic matter\n\n26:50.300 --> 26:53.340\n or just to see the pedagogy of how are they doing this class.\n\n26:53.340 --> 26:58.060\n So I guess the main thing I learned is when I came in,\n\n26:58.060 --> 27:03.060\n I thought the challenge was information,\n\n27:03.140 --> 27:07.460\n saying if I'm just, take the stuff I want you to know\n\n27:07.460 --> 27:10.540\n and I'm very clear and explain it well,\n\n27:10.540 --> 27:13.720\n then my job is done and good things are gonna happen.\n\n27:14.580 --> 27:17.300\n And then in doing the course, I learned,\n\n27:17.300 --> 27:19.220\n well, yeah, you gotta have the information\n\n27:19.220 --> 27:23.020\n but really the motivation is the most important thing\n\n27:23.020 --> 27:26.140\n that if students don't stick with it,\n\n27:26.140 --> 27:28.340\n it doesn't matter how good the content is.\n\n27:29.500 --> 27:32.780\n And I think being one of the first classes,\n\n27:32.780 --> 27:36.780\n we were helped by sort of exterior motivation.\n\n27:36.780 --> 27:39.340\n So we tried to do a good job of making it enticing\n\n27:39.340 --> 27:44.340\n and setting up ways for the community\n\n27:44.460 --> 27:46.980\n to work with each other to make it more motivating\n\n27:46.980 --> 27:49.500\n but really a lot of it was, hey, this is a new thing\n\n27:49.500 --> 27:51.580\n and I'm really excited to be part of a new thing.\n\n27:51.580 --> 27:54.580\n And so the students brought their own motivation.\n\n27:54.580 --> 27:56.860\n And so I think this is great\n\n27:56.860 --> 27:58.660\n because there's lots of people around the world\n\n27:58.660 --> 28:00.620\n who have never had this before,\n\n28:03.620 --> 28:07.060\n would never have the opportunity to go to Stanford\n\n28:07.060 --> 28:08.540\n and take a class or go to MIT\n\n28:08.540 --> 28:10.460\n or go to one of the other schools\n\n28:10.460 --> 28:12.860\n but now we can bring that to them\n\n28:12.860 --> 28:15.820\n and if they bring their own motivation,\n\n28:15.820 --> 28:18.940\n they can be successful in a way they couldn't before.\n\n28:18.940 --> 28:21.580\n But that's really just the top tier of people\n\n28:21.580 --> 28:22.780\n that are ready to do that.\n\n28:22.780 --> 28:26.980\n The rest of the people just don't see\n\n28:26.980 --> 28:29.500\n or don't have the motivation\n\n28:29.500 --> 28:31.620\n and don't see how if they push through\n\n28:31.620 --> 28:34.660\n and were able to do it, what advantage that would get them.\n\n28:34.660 --> 28:36.220\n So I think we got a long way to go\n\n28:36.220 --> 28:37.900\n before we were able to do that.\n\n28:37.900 --> 28:40.940\n And I think some of it is based on technology\n\n28:40.940 --> 28:43.980\n but more of it's based on the idea of community.\n\n28:43.980 --> 28:46.140\n You gotta actually get people together.\n\n28:46.140 --> 28:49.340\n Some of the getting together can be done online.\n\n28:49.340 --> 28:52.300\n I think some of it really has to be done in person\n\n28:52.300 --> 28:56.460\n in order to build that type of community and trust.\n\n28:56.460 --> 28:59.500\n You know, there's an intentional mechanism\n\n28:59.500 --> 29:02.660\n that we've developed a short attention span,\n\n29:02.660 --> 29:04.500\n especially younger people\n\n29:04.500 --> 29:08.820\n because sort of shorter and shorter videos online,\n\n29:08.820 --> 29:13.700\n there's a whatever the way the brain is developing now\n\n29:13.700 --> 29:16.660\n and with people that have grown up with the internet,\n\n29:16.660 --> 29:18.460\n they have quite a short attention span.\n\n29:18.460 --> 29:21.100\n So, and I would say I had the same\n\n29:21.100 --> 29:23.940\n when I was growing up too, probably for different reasons.\n\n29:23.940 --> 29:28.100\n So I probably wouldn't have learned as much as I have\n\n29:28.100 --> 29:31.380\n if I wasn't forced to sit in a physical classroom,\n\n29:31.380 --> 29:33.980\n sort of bored, sometimes falling asleep,\n\n29:33.980 --> 29:36.660\n but sort of forcing myself through that process.\n\n29:36.660 --> 29:39.700\n So sometimes extremely difficult computer science courses.\n\n29:39.700 --> 29:42.140\n What's the difference in your view\n\n29:42.140 --> 29:46.340\n between in person education experience,\n\n29:46.340 --> 29:48.940\n which you, first of all, yourself had\n\n29:48.940 --> 29:52.100\n and you yourself taught and online education\n\n29:52.100 --> 29:54.340\n and how do we close that gap if it's even possible?\n\n29:54.340 --> 29:56.380\n Yeah, so I think there's two issues.\n\n29:56.380 --> 30:00.740\n One is whether it's in person or online.\n\n30:00.740 --> 30:03.020\n So it's sort of the physical location\n\n30:03.020 --> 30:07.100\n and then the other is kind of the affiliation, right?\n\n30:07.100 --> 30:10.900\n So you stuck with it in part\n\n30:10.900 --> 30:12.540\n because you were in the classroom\n\n30:12.540 --> 30:15.380\n and you saw everybody else was suffering\n\n30:15.380 --> 30:16.540\n the same way you were,\n\n30:17.420 --> 30:20.140\n but also because you were enrolled,\n\n30:20.140 --> 30:22.180\n you had paid tuition,\n\n30:22.180 --> 30:25.380\n sort of everybody was expecting you to stick with it.\n\n30:25.380 --> 30:29.420\n Society, parents, peers.\n\n30:29.420 --> 30:31.140\n And so those are two separate things.\n\n30:31.140 --> 30:32.980\n I mean, you could certainly imagine\n\n30:32.980 --> 30:35.220\n I pay a huge amount of tuition\n\n30:35.220 --> 30:38.180\n and everybody signed up and says, yes, you're doing this,\n\n30:38.180 --> 30:40.740\n but then I'm in my room\n\n30:40.740 --> 30:43.220\n and my classmates are in different rooms, right?\n\n30:43.220 --> 30:45.020\n We could have things set up that way.\n\n30:45.980 --> 30:48.900\n So it's not just the online versus offline.\n\n30:48.900 --> 30:50.020\n I think what's more important\n\n30:50.020 --> 30:52.860\n is the commitment that you've made.\n\n30:53.940 --> 30:56.100\n And certainly it is important\n\n30:56.100 --> 30:59.660\n to have that kind of informal,\n\n30:59.660 --> 31:01.780\n you know, I meet people outside of class,\n\n31:01.780 --> 31:05.020\n we talk together because we're all in it together.\n\n31:05.020 --> 31:07.580\n I think that's really important,\n\n31:07.580 --> 31:10.140\n both in keeping your motivation\n\n31:10.140 --> 31:11.260\n and also that's where\n\n31:11.260 --> 31:13.460\n some of the most important learning goes on.\n\n31:13.460 --> 31:15.380\n So you wanna have that.\n\n31:15.380 --> 31:17.460\n Maybe, you know, especially now\n\n31:17.460 --> 31:19.780\n we start getting into higher bandwidths\n\n31:19.780 --> 31:22.580\n and augmented reality and virtual reality,\n\n31:22.580 --> 31:23.620\n you might be able to get that\n\n31:23.620 --> 31:25.900\n without being in the same physical place.\n\n31:25.900 --> 31:30.740\n Do you think it's possible we'll see a course at Stanford,\n\n31:30.740 --> 31:33.940\n for example, that for students,\n\n31:33.940 --> 31:37.380\n enrolled students is only online in the near future\n\n31:37.380 --> 31:39.740\n or literally sort of it's part of the curriculum\n\n31:39.740 --> 31:41.180\n and there is no...\n\n31:41.180 --> 31:42.700\n Yeah, so you're starting to see that.\n\n31:42.700 --> 31:46.660\n I know Georgia Tech has a master's that's done that way.\n\n31:46.660 --> 31:48.380\n Oftentimes it's sort of,\n\n31:48.380 --> 31:50.980\n they're creeping in in terms of a master's program\n\n31:50.980 --> 31:54.300\n or sort of further education,\n\n31:54.300 --> 31:56.620\n considering the constraints of students and so on.\n\n31:56.620 --> 32:00.780\n But I mean, literally, is it possible that we,\n\n32:00.780 --> 32:02.740\n you know, Stanford, MIT, Berkeley,\n\n32:02.740 --> 32:07.740\n all these places go online only in the next few decades?\n\n32:07.820 --> 32:08.780\n Yeah, probably not,\n\n32:08.780 --> 32:11.300\n because, you know, they've got a big commitment\n\n32:11.300 --> 32:13.300\n to a physical campus.\n\n32:13.300 --> 32:16.500\n Sure, so there's a momentum\n\n32:16.500 --> 32:18.300\n that's both financial and culturally.\n\n32:18.300 --> 32:21.180\n Right, and then there are certain things\n\n32:21.180 --> 32:25.060\n that's just hard to do virtually, right?\n\n32:25.060 --> 32:29.300\n So, you know, we're in a field where,\n\n32:29.300 --> 32:32.660\n if you have your own computer and your own paper,\n\n32:32.660 --> 32:35.580\n and so on, you can do the work anywhere.\n\n32:36.740 --> 32:39.380\n But if you're in a biology lab or something,\n\n32:39.380 --> 32:42.820\n you know, you don't have all the right stuff at home.\n\n32:42.820 --> 32:45.700\n Right, so our field, programming,\n\n32:45.700 --> 32:49.300\n you've also done a lot of programming yourself.\n\n32:50.860 --> 32:54.260\n In 2001, you wrote a great article about programming\n\n32:54.260 --> 32:57.260\n called Teach Yourself Programming in 10 Years,\n\n32:57.260 --> 32:59.300\n sort of response to all the books\n\n32:59.300 --> 33:01.500\n that say teach yourself programming in 21 days.\n\n33:01.500 --> 33:02.940\n So if you were giving advice to someone\n\n33:02.940 --> 33:04.780\n getting into programming today,\n\n33:04.780 --> 33:07.220\n this is a few years since you've written that article,\n\n33:07.220 --> 33:09.620\n what's the best way to undertake that journey?\n\n33:10.820 --> 33:12.300\n I think there's lots of different ways,\n\n33:12.300 --> 33:15.900\n and I think programming means more things now.\n\n33:17.420 --> 33:20.060\n And I guess, you know, when I wrote that article,\n\n33:20.060 --> 33:21.740\n I was thinking more about\n\n33:23.180 --> 33:25.620\n becoming a professional software engineer,\n\n33:25.620 --> 33:27.660\n and I thought that's a, you know,\n\n33:27.660 --> 33:31.500\n sort of a career long field of study.\n\n33:31.500 --> 33:33.340\n But I think there's lots of things now\n\n33:33.340 --> 33:37.580\n that people can do where programming is a part\n\n33:37.580 --> 33:40.980\n of solving what they wanna solve\n\n33:40.980 --> 33:44.860\n without achieving that professional level status, right?\n\n33:44.860 --> 33:45.780\n So I'm not gonna be going\n\n33:45.780 --> 33:47.620\n and writing a million lines of code,\n\n33:47.620 --> 33:51.620\n but, you know, I'm a biologist or a physicist or something,\n\n33:51.620 --> 33:55.620\n or even a historian, and I've got some data,\n\n33:55.620 --> 33:58.420\n and I wanna ask a question of that data.\n\n33:58.420 --> 34:02.100\n And I think for that, you don't need 10 years, right?\n\n34:02.100 --> 34:04.220\n So there are many shortcuts\n\n34:04.220 --> 34:08.460\n to being able to answer those kinds of questions.\n\n34:08.460 --> 34:11.860\n And, you know, you see today a lot of emphasis\n\n34:11.860 --> 34:15.860\n on learning to code, teaching kids how to code.\n\n34:16.700 --> 34:18.740\n I think that's great,\n\n34:18.740 --> 34:21.700\n but I wish they would change the message a little bit,\n\n34:21.700 --> 34:24.700\n right, so I think code isn't the main thing.\n\n34:24.700 --> 34:28.260\n I don't really care if you know the syntax of JavaScript\n\n34:28.260 --> 34:31.500\n or if you can connect these blocks together\n\n34:31.500 --> 34:33.420\n in this visual language.\n\n34:33.420 --> 34:38.220\n But what I do care about is that you can analyze a problem,\n\n34:38.220 --> 34:43.220\n you can think of a solution, you can carry out,\n\n34:43.700 --> 34:46.620\n you know, make a model, run that model,\n\n34:46.620 --> 34:49.460\n test the model, see the results,\n\n34:50.980 --> 34:53.660\n verify that they're reasonable,\n\n34:53.660 --> 34:55.660\n ask questions and answer them, right?\n\n34:55.660 --> 34:58.540\n So it's more modeling and problem solving,\n\n34:58.540 --> 35:01.860\n and you use coding in order to do that,\n\n35:01.860 --> 35:04.300\n but it's not just learning coding for its own sake.\n\n35:04.300 --> 35:05.140\n That's really interesting.\n\n35:05.140 --> 35:08.140\n So it's actually almost, in many cases,\n\n35:08.140 --> 35:10.060\n it's learning to work with data,\n\n35:10.060 --> 35:11.980\n to extract something useful out of data.\n\n35:11.980 --> 35:13.660\n So when you say problem solving,\n\n35:13.660 --> 35:15.300\n you really mean taking some kind of,\n\n35:15.300 --> 35:17.700\n maybe collecting some kind of data set,\n\n35:17.700 --> 35:20.300\n cleaning it up, and saying something interesting about it,\n\n35:20.300 --> 35:23.020\n which is useful in all kinds of domains.\n\n35:23.020 --> 35:28.020\n And, you know, and I see myself being stuck sometimes\n\n35:28.100 --> 35:30.460\n in kind of the old ways, right?\n\n35:30.460 --> 35:34.180\n So, you know, I'll be working on a project,\n\n35:34.180 --> 35:37.740\n maybe with a younger employee, and we say,\n\n35:37.740 --> 35:39.260\n oh, well, here's this new package\n\n35:39.260 --> 35:42.300\n that could help solve this problem.\n\n35:42.300 --> 35:44.500\n And I'll go and I'll start reading the manuals,\n\n35:44.500 --> 35:48.180\n and, you know, I'll be two hours into reading the manuals,\n\n35:48.180 --> 35:51.100\n and then my colleague comes back and says, I'm done.\n\n35:51.100 --> 35:53.820\n You know, I downloaded the package, I installed it,\n\n35:53.820 --> 35:56.500\n I tried calling some things, the first one didn't work,\n\n35:56.500 --> 35:58.740\n the second one worked, now I'm done.\n\n35:58.740 --> 36:00.620\n And I say, but I have a hundred questions\n\n36:00.620 --> 36:02.100\n about how does this work and how does that work?\n\n36:02.100 --> 36:04.140\n And they say, who cares, right?\n\n36:04.140 --> 36:05.540\n I don't need to understand the whole thing.\n\n36:05.540 --> 36:09.180\n I answered my question, it's a big, complicated package,\n\n36:09.180 --> 36:10.540\n I don't understand the rest of it,\n\n36:10.540 --> 36:12.180\n but I got the right answer.\n\n36:12.180 --> 36:15.900\n And I'm just, it's hard for me to get into that mindset.\n\n36:15.900 --> 36:17.620\n I want to understand the whole thing.\n\n36:17.620 --> 36:19.420\n And, you know, if they wrote a manual,\n\n36:19.420 --> 36:21.380\n I should probably read it.\n\n36:21.380 --> 36:23.660\n And, but that's not necessarily the right way.\n\n36:23.660 --> 36:28.580\n I think I have to get used to dealing with more,\n\n36:28.580 --> 36:30.500\n being more comfortable with uncertainty\n\n36:30.500 --> 36:32.060\n and not knowing everything.\n\n36:32.060 --> 36:33.620\n Yeah, so I struggle with the same,\n\n36:33.620 --> 36:37.300\n instead of the spectrum between Donald and Don Knuth.\n\n36:37.300 --> 36:38.140\n Yeah.\n\n36:38.140 --> 36:39.620\n It's kind of the very, you know,\n\n36:39.620 --> 36:42.460\n before he can say anything about a problem,\n\n36:42.460 --> 36:45.420\n he really has to get down to the machine code assembly.\n\n36:45.420 --> 36:46.260\n Yeah.\n\n36:46.260 --> 36:50.220\n And that forces exactly what you said of several students\n\n36:50.220 --> 36:53.460\n in my group that, you know, 20 years old,\n\n36:53.460 --> 36:56.820\n and they can solve almost any problem within a few hours.\n\n36:56.820 --> 36:58.260\n That would take me probably weeks\n\n36:58.260 --> 37:00.980\n because I would try to, as you said, read the manual.\n\n37:00.980 --> 37:04.380\n So do you think the nature of mastery,\n\n37:04.380 --> 37:06.820\n you're mentioning biology,\n\n37:06.820 --> 37:11.300\n sort of outside disciplines, applying programming,\n\n37:11.300 --> 37:13.860\n but computer scientists.\n\n37:13.860 --> 37:16.420\n So over time, there's higher and higher levels\n\n37:16.420 --> 37:18.340\n of abstraction available now.\n\n37:18.340 --> 37:23.340\n So with this week, there's the TensorFlow Summit, right?\n\n37:23.700 --> 37:27.500\n So if you're not particularly into deep learning,\n\n37:27.500 --> 37:29.940\n but you're still a computer scientist,\n\n37:29.940 --> 37:33.180\n you can accomplish an incredible amount with TensorFlow\n\n37:33.180 --> 37:35.940\n without really knowing any fundamental internals\n\n37:35.940 --> 37:37.460\n of machine learning.\n\n37:37.460 --> 37:40.860\n Do you think the nature of mastery is changing,\n\n37:40.860 --> 37:42.340\n even for computer scientists,\n\n37:42.340 --> 37:45.660\n like what it means to be an expert programmer?\n\n37:45.660 --> 37:47.700\n Yeah, I think that's true.\n\n37:47.700 --> 37:51.180\n You know, we never really should have focused on programmer,\n\n37:51.180 --> 37:53.660\n right, because it's still, it's the skill,\n\n37:53.660 --> 37:56.540\n and what we really want to focus on is the result.\n\n37:56.540 --> 37:59.140\n So we built this ecosystem\n\n37:59.140 --> 38:01.260\n where the way you can get stuff done\n\n38:01.260 --> 38:03.140\n is by programming it yourself.\n\n38:04.100 --> 38:06.780\n At least when I started, you know,\n\n38:06.780 --> 38:09.020\n library functions meant you had square root,\n\n38:09.020 --> 38:10.860\n and that was about it, right?\n\n38:10.860 --> 38:13.060\n Everything else you built from scratch.\n\n38:13.060 --> 38:16.140\n And then we built up an ecosystem where a lot of times,\n\n38:16.140 --> 38:17.460\n well, you can download a lot of stuff\n\n38:17.460 --> 38:20.220\n that does a big part of what you need.\n\n38:20.220 --> 38:23.740\n And so now it's more a question of assembly\n\n38:23.740 --> 38:27.240\n rather than manufacturing.\n\n38:28.300 --> 38:32.220\n And that's a different way of looking at problems.\n\n38:32.220 --> 38:34.260\n From another perspective in terms of mastery\n\n38:34.260 --> 38:37.660\n and looking at programmers or people that reason\n\n38:37.660 --> 38:39.780\n about problems in a computational way.\n\n38:39.780 --> 38:44.120\n So Google, you know, from the hiring perspective,\n\n38:44.120 --> 38:45.140\n from the perspective of hiring\n\n38:45.140 --> 38:47.420\n or building a team of programmers,\n\n38:47.420 --> 38:50.280\n how do you determine if someone's a good programmer?\n\n38:50.280 --> 38:53.500\n Or if somebody, again, so I want to deviate from,\n\n38:53.500 --> 38:55.400\n I want to move away from the word programmer,\n\n38:55.400 --> 38:57.720\n but somebody who could solve problems\n\n38:57.720 --> 38:59.720\n of large scale data and so on.\n\n38:59.720 --> 39:02.740\n What's, how do you build a team like that\n\n39:02.740 --> 39:03.980\n through the interviewing process?\n\n39:03.980 --> 39:08.860\n Yeah, and I think as a company grows,\n\n39:08.860 --> 39:12.260\n you get more expansive in the types\n\n39:12.260 --> 39:14.460\n of people you're looking for, right?\n\n39:14.460 --> 39:16.580\n So I think, you know, in the early days,\n\n39:16.580 --> 39:19.380\n we'd interview people and the question we were trying\n\n39:19.380 --> 39:22.820\n to ask is how close are they to Jeff Dean?\n\n39:22.820 --> 39:26.780\n And most people were pretty far away,\n\n39:26.780 --> 39:29.380\n but we take the ones that were not that far away.\n\n39:29.380 --> 39:31.760\n And so we got kind of a homogeneous group\n\n39:31.760 --> 39:34.560\n of people who were really great programmers.\n\n39:34.560 --> 39:37.000\n Then as a company grows, you say,\n\n39:37.000 --> 39:39.100\n well, we don't want everybody to be the same,\n\n39:39.100 --> 39:40.660\n to have the same skill set.\n\n39:40.660 --> 39:45.660\n And so now we're hiring biologists in our health areas\n\n39:47.380 --> 39:48.940\n and we're hiring physicists,\n\n39:48.940 --> 39:51.180\n we're hiring mechanical engineers,\n\n39:51.180 --> 39:56.080\n we're hiring, you know, social scientists and ethnographers\n\n39:56.080 --> 39:59.140\n and people with different backgrounds\n\n39:59.140 --> 40:00.880\n who bring different skills.\n\n40:01.740 --> 40:06.260\n So you have mentioned that you still may partake\n\n40:06.260 --> 40:10.720\n in code reviews, given that you have a wealth of experience,\n\n40:10.720 --> 40:12.020\n as you've also mentioned.\n\n40:13.900 --> 40:16.660\n What errors do you often see and tend to highlight\n\n40:16.660 --> 40:20.020\n in the code of junior developers of people coming up now,\n\n40:20.020 --> 40:23.460\n given your background from Blisp\n\n40:23.460 --> 40:26.020\n to a couple of decades of programming?\n\n40:26.020 --> 40:28.420\n Yeah, that's a great question.\n\n40:28.420 --> 40:31.920\n You know, sometimes I try to look at the flexibility\n\n40:31.920 --> 40:36.920\n of the design of, yes, you know, this API solves this problem,\n\n40:37.560 --> 40:39.900\n but where is it gonna go in the future?\n\n40:39.900 --> 40:41.940\n Who else is gonna wanna call this?\n\n40:41.940 --> 40:46.940\n And, you know, are you making it easier for them to do that?\n\n40:46.940 --> 40:50.640\n That's a matter of design, is it documentation,\n\n40:50.640 --> 40:53.880\n is it sort of an amorphous thing\n\n40:53.880 --> 40:55.140\n you can't really put into words?\n\n40:55.140 --> 40:56.660\n It's just how it feels.\n\n40:56.660 --> 40:58.340\n If you put yourself in the shoes of a developer,\n\n40:58.340 --> 40:59.540\n would you use this kind of thing?\n\n40:59.540 --> 41:01.500\n I think it is how you feel, right?\n\n41:01.500 --> 41:03.900\n And so yeah, documentation is good,\n\n41:03.900 --> 41:06.460\n but it's more a design question, right?\n\n41:06.460 --> 41:07.620\n If you get the design right,\n\n41:07.620 --> 41:10.220\n then people will figure it out,\n\n41:10.220 --> 41:12.140\n whether the documentation is good or not.\n\n41:12.140 --> 41:16.180\n And if the design's wrong, then it'd be harder to use.\n\n41:16.180 --> 41:21.180\n How have you yourself changed as a programmer over the years?\n\n41:22.900 --> 41:26.660\n In a way, you already started to say sort of,\n\n41:26.660 --> 41:28.100\n you want to read the manual,\n\n41:28.100 --> 41:30.860\n you want to understand the core of the syntax\n\n41:30.860 --> 41:33.780\n to how the language is supposed to be used and so on.\n\n41:33.780 --> 41:36.540\n But what's the evolution been like\n\n41:36.540 --> 41:39.800\n from the 80s, 90s to today?\n\n41:40.700 --> 41:42.820\n I guess one thing is you don't have to worry\n\n41:42.820 --> 41:46.340\n about the small details of efficiency\n\n41:46.340 --> 41:48.060\n as much as you used to, right?\n\n41:48.060 --> 41:53.060\n So like I remember I did my list book in the 90s,\n\n41:53.380 --> 41:56.300\n and one of the things I wanted to do was say,\n\n41:56.300 --> 41:58.900\n here's how you do an object system.\n\n41:58.900 --> 42:01.540\n And basically, we're going to make it\n\n42:01.540 --> 42:03.620\n so each object is a hash table,\n\n42:03.620 --> 42:05.580\n and you look up the methods, and here's how it works.\n\n42:05.580 --> 42:07.380\n And then I said, of course,\n\n42:07.380 --> 42:12.220\n the real Common Lisp object system is much more complicated.\n\n42:12.220 --> 42:15.200\n It's got all these efficiency type issues,\n\n42:15.200 --> 42:16.620\n and this is just a toy,\n\n42:16.620 --> 42:18.980\n and nobody would do this in real life.\n\n42:18.980 --> 42:21.420\n And it turns out Python pretty much did exactly\n\n42:22.740 --> 42:27.500\n what I said and said objects are just dictionaries.\n\n42:27.500 --> 42:30.140\n And yeah, they have a few little tricks as well.\n\n42:30.140 --> 42:34.260\n But mostly, the thing that would have been\n\n42:34.260 --> 42:36.660\n 100 times too slow in the 80s\n\n42:36.660 --> 42:39.200\n is now plenty fast for most everything.\n\n42:39.200 --> 42:40.700\n So you had to, as a programmer,\n\n42:40.700 --> 42:44.520\n let go of perhaps an obsession\n\n42:44.520 --> 42:45.920\n that I remember coming up with\n\n42:45.920 --> 42:48.380\n of trying to write efficient code.\n\n42:48.380 --> 42:51.340\n Yeah, to say what really matters\n\n42:51.340 --> 42:56.140\n is the total time it takes to get the project done.\n\n42:56.140 --> 42:59.100\n And most of that's gonna be the programmer time.\n\n42:59.100 --> 43:00.700\n So if you're a little bit less efficient,\n\n43:00.700 --> 43:04.260\n but it makes it easier to understand and modify,\n\n43:04.260 --> 43:05.920\n then that's the right trade off.\n\n43:05.920 --> 43:07.700\n So you've written quite a bit about Lisp.\n\n43:07.700 --> 43:10.180\n Your book on programming is in Lisp.\n\n43:10.180 --> 43:12.920\n You have a lot of code out there that's in Lisp.\n\n43:12.920 --> 43:16.980\n So myself and people who don't know what Lisp is\n\n43:16.980 --> 43:18.060\n should look it up.\n\n43:18.060 --> 43:20.820\n It's my favorite language for many AI researchers.\n\n43:20.820 --> 43:22.460\n It is a favorite language.\n\n43:22.460 --> 43:25.540\n The favorite language they never use these days.\n\n43:25.540 --> 43:28.980\n So what part of Lisp do you find most beautiful and powerful?\n\n43:28.980 --> 43:31.700\n So I think the beautiful part is the simplicity\n\n43:31.700 --> 43:35.220\n that in half a page, you can define the whole language.\n\n43:36.340 --> 43:38.460\n And other languages don't have that.\n\n43:38.460 --> 43:41.380\n So you feel like you can hold everything in your head.\n\n43:42.780 --> 43:46.980\n And then a lot of people say,\n\n43:46.980 --> 43:48.740\n well, then that's too simple.\n\n43:48.740 --> 43:50.420\n Here's all these things I wanna do.\n\n43:50.420 --> 43:54.500\n And my Java or Python or whatever\n\n43:54.500 --> 43:58.740\n has 100 or 200 or 300 different syntax rules\n\n43:58.740 --> 44:00.360\n and don't I need all those?\n\n44:00.360 --> 44:03.860\n And Lisp's answer was, no, we're only gonna give you\n\n44:03.860 --> 44:06.020\n eight or so syntax rules,\n\n44:06.020 --> 44:09.020\n but we're gonna allow you to define your own.\n\n44:09.020 --> 44:11.340\n And so that was a very powerful idea.\n\n44:11.340 --> 44:15.880\n And I think this idea of saying,\n\n44:15.880 --> 44:20.300\n I can start with my problem and with my data,\n\n44:20.300 --> 44:24.420\n and then I can build the language I want for that problem\n\n44:24.420 --> 44:25.940\n and for that data.\n\n44:25.940 --> 44:28.440\n And then I can make Lisp define that language.\n\n44:28.440 --> 44:32.660\n So you're sort of mixing levels and saying,\n\n44:32.660 --> 44:36.120\n I'm simultaneously a programmer in a language\n\n44:36.120 --> 44:37.480\n and a language designer.\n\n44:38.620 --> 44:41.900\n And that allows a better match between your problem\n\n44:41.900 --> 44:43.700\n and your eventual code.\n\n44:43.700 --> 44:47.500\n And I think Lisp had done that better than other languages.\n\n44:47.500 --> 44:49.460\n Yeah, it's a very elegant implementation\n\n44:49.460 --> 44:51.300\n of functional programming.\n\n44:51.300 --> 44:55.220\n But why do you think Lisp has not had the mass adoption\n\n44:55.220 --> 44:57.260\n and success of languages like Python?\n\n44:57.260 --> 44:58.440\n Is it the parentheses?\n\n44:59.300 --> 45:00.620\n Is it all the parentheses?\n\n45:02.020 --> 45:04.020\n Yeah, so I think a couple things.\n\n45:05.340 --> 45:10.220\n So one was, I think it was designed for a single programmer\n\n45:10.220 --> 45:14.940\n or a small team and a skilled programmer\n\n45:14.940 --> 45:17.140\n who had the good taste to say,\n\n45:17.140 --> 45:19.600\n well, I am doing language design\n\n45:19.600 --> 45:21.780\n and I have to make good choices.\n\n45:21.780 --> 45:23.840\n And if you make good choices, that's great.\n\n45:23.840 --> 45:28.100\n If you make bad choices, you can hurt yourself\n\n45:28.100 --> 45:30.300\n and it can be hard for other people on the team\n\n45:30.300 --> 45:31.140\n to understand it.\n\n45:31.140 --> 45:34.300\n So I think there was a limit to the scale\n\n45:34.300 --> 45:37.020\n of the size of a project in terms of number of people\n\n45:37.020 --> 45:38.580\n that Lisp was good for.\n\n45:38.580 --> 45:42.160\n And as an industry, we kind of grew beyond that.\n\n45:43.180 --> 45:46.000\n I think it is in part the parentheses.\n\n45:46.000 --> 45:49.640\n You know, one of the jokes is the acronym for Lisp\n\n45:49.640 --> 45:52.320\n is lots of irritating, silly parentheses.\n\n45:53.960 --> 45:57.200\n My acronym was Lisp is syntactically pure,\n\n45:58.360 --> 46:01.440\n saying all you need is parentheses and atoms.\n\n46:01.440 --> 46:05.200\n But I remember, you know, as we had the AI textbook\n\n46:05.200 --> 46:08.660\n and because we did it in the nineties,\n\n46:08.660 --> 46:11.380\n we had pseudocode in the book,\n\n46:11.380 --> 46:13.360\n but then we said, well, we'll have Lisp online\n\n46:13.360 --> 46:16.200\n because that's the language of AI at the time.\n\n46:16.200 --> 46:18.280\n And I remember some of the students complaining\n\n46:18.280 --> 46:20.020\n because they hadn't had Lisp before\n\n46:20.020 --> 46:22.080\n and they didn't quite understand what was going on.\n\n46:22.080 --> 46:24.820\n And I remember one student complained,\n\n46:24.820 --> 46:26.600\n I don't understand how this pseudocode\n\n46:26.600 --> 46:29.160\n corresponds to this Lisp.\n\n46:29.160 --> 46:31.480\n And there was a one to one correspondence\n\n46:31.480 --> 46:35.760\n between the symbols in the code and the pseudocode.\n\n46:35.760 --> 46:38.120\n And the only thing difference was the parentheses.\n\n46:39.160 --> 46:41.240\n So I said, it must be that for some people,\n\n46:41.240 --> 46:44.040\n a certain number of left parentheses shuts off their brain.\n\n46:45.040 --> 46:47.160\n Yeah, it's very possible in that sense\n\n46:47.160 --> 46:49.520\n and Python just goes the other way.\n\n46:49.520 --> 46:51.100\n So that was the point at which I said,\n\n46:51.100 --> 46:54.300\n okay, can't have only Lisp as a language.\n\n46:54.300 --> 46:56.640\n Cause I don't wanna, you know,\n\n46:56.640 --> 46:59.160\n you only got 10 or 12 or 15 weeks or whatever it is\n\n46:59.160 --> 47:01.400\n to teach AI and I don't want to waste two weeks\n\n47:01.400 --> 47:03.000\n of that teaching Lisp.\n\n47:03.000 --> 47:04.440\n So I say, I gotta have another language.\n\n47:04.440 --> 47:06.920\n Java was the most popular language at the time.\n\n47:06.920 --> 47:08.240\n I started doing that.\n\n47:08.240 --> 47:12.080\n And then I said, it's really hard to have a one to one\n\n47:12.080 --> 47:14.480\n correspondence between the pseudocode and the Java\n\n47:14.480 --> 47:16.020\n because Java is so verbose.\n\n47:16.980 --> 47:18.920\n So then I said, I'm gonna do a survey\n\n47:18.920 --> 47:22.920\n and find the language that's most like my pseudocode.\n\n47:22.920 --> 47:26.240\n And it turned out Python basically was my pseudocode.\n\n47:26.240 --> 47:29.280\n Somehow I had channeled Guido,\n\n47:30.360 --> 47:32.680\n designed a pseudocode that was the same as Python,\n\n47:32.680 --> 47:36.160\n although I hadn't heard of Python at that point.\n\n47:36.160 --> 47:38.320\n And from then on, that's what I've been using\n\n47:38.320 --> 47:39.720\n cause it's been a good match.\n\n47:41.220 --> 47:45.680\n So what's the story in Python behind PyTudes?\n\n47:45.680 --> 47:48.360\n Your GitHub repository with puzzles and exercises\n\n47:48.360 --> 47:49.760\n in Python is pretty fun.\n\n47:49.760 --> 47:53.160\n Yeah, just it, it seems like fun, you know,\n\n47:53.160 --> 47:57.480\n I like doing puzzles and I like being an educator.\n\n47:57.480 --> 48:02.200\n I did a class with Udacity, Udacity 212, I think it was.\n\n48:02.200 --> 48:07.200\n It was basically problem solving using Python\n\n48:07.320 --> 48:08.960\n and looking at different problems.\n\n48:08.960 --> 48:11.920\n Does PyTudes feed that class in terms of the exercises?\n\n48:11.920 --> 48:12.760\n I was wondering what the...\n\n48:12.760 --> 48:15.040\n Yeah, so the class came first.\n\n48:15.040 --> 48:17.640\n Some of the stuff that's in PyTudes was write ups\n\n48:17.640 --> 48:19.240\n of what was in the class and then some of it\n\n48:19.240 --> 48:23.200\n was just continuing to work on new problems.\n\n48:24.240 --> 48:26.840\n So what's the organizing madness of PyTudes?\n\n48:26.840 --> 48:30.080\n Is it just a collection of cool exercises?\n\n48:30.080 --> 48:31.320\n Just whatever I thought was fun.\n\n48:31.320 --> 48:32.800\n Okay, awesome.\n\n48:32.800 --> 48:35.880\n So you were the director of search quality at Google\n\n48:35.880 --> 48:40.560\n from 2001 to 2005 in the early days\n\n48:40.560 --> 48:41.840\n when there's just a few employees\n\n48:41.840 --> 48:46.400\n and when the company was growing like crazy, right?\n\n48:46.400 --> 48:51.400\n So, I mean, Google revolutionized the way we discover,\n\n48:52.040 --> 48:55.360\n share and aggregate knowledge.\n\n48:55.360 --> 49:00.280\n So just, this is one of the fundamental aspects\n\n49:00.280 --> 49:03.160\n of civilization, right, is information being shared\n\n49:03.160 --> 49:04.920\n and there's different mechanisms throughout history\n\n49:04.920 --> 49:08.360\n but Google has just 10x improved that, right?\n\n49:08.360 --> 49:10.240\n And you're a part of that, right?\n\n49:10.240 --> 49:11.880\n People discovering that information.\n\n49:11.880 --> 49:15.240\n So what were some of the challenges on a philosophical\n\n49:15.240 --> 49:17.440\n or the technical level in those early days?\n\n49:18.360 --> 49:20.080\n It definitely was an exciting time\n\n49:20.080 --> 49:23.040\n and as you say, we were doubling in size every year\n\n49:24.560 --> 49:26.920\n and the challenges were we wanted\n\n49:26.920 --> 49:29.040\n to get the right answers, right?\n\n49:29.040 --> 49:32.520\n And we had to figure out what that meant.\n\n49:32.520 --> 49:36.360\n We had to implement that and we had to make it all efficient\n\n49:36.360 --> 49:41.360\n and we had to keep on testing\n\n49:41.600 --> 49:44.120\n and seeing if we were delivering good answers.\n\n49:44.120 --> 49:45.640\n And now when you say good answers,\n\n49:45.640 --> 49:47.760\n it means whatever people are typing in\n\n49:47.760 --> 49:50.320\n in terms of keywords, in terms of that kind of thing\n\n49:50.320 --> 49:53.640\n that the results they get are ordered\n\n49:53.640 --> 49:56.520\n by the desirability for them of those results.\n\n49:56.520 --> 49:58.560\n Like they're like, the first thing they click on\n\n49:58.560 --> 50:01.520\n will likely be the thing that they were actually looking for.\n\n50:01.520 --> 50:03.160\n Right, one of the metrics we had\n\n50:03.160 --> 50:05.040\n was focused on the first thing.\n\n50:05.040 --> 50:07.560\n Some of it was focused on the whole page.\n\n50:07.560 --> 50:10.680\n Some of it was focused on top three or so.\n\n50:11.800 --> 50:13.440\n So we looked at a lot of different metrics\n\n50:13.440 --> 50:15.720\n for how well we were doing\n\n50:15.720 --> 50:19.280\n and we broke it down into subclasses of,\n\n50:19.280 --> 50:23.520\n maybe here's a type of query that we're not doing well on\n\n50:23.520 --> 50:25.520\n and we try to fix that.\n\n50:25.520 --> 50:29.400\n Early on we started to realize that we were in an adversarial\n\n50:29.400 --> 50:32.760\n position, right, so we started thinking,\n\n50:32.760 --> 50:35.960\n well, we're kind of like the card catalog in the library,\n\n50:35.960 --> 50:39.480\n right, so the books are here and we're off to the side\n\n50:39.480 --> 50:42.640\n and we're just reflecting what's there.\n\n50:42.640 --> 50:45.600\n And then we realized every time we make a change,\n\n50:45.600 --> 50:50.040\n the webmasters make a change and it's game theoretic.\n\n50:50.040 --> 50:54.440\n And so we had to think not only of is this the right move\n\n50:54.440 --> 50:57.760\n for us to make now, but also if we make this move,\n\n50:57.760 --> 50:59.800\n what's the counter move gonna be?\n\n50:59.800 --> 51:02.240\n Is that gonna get us into a worse place,\n\n51:02.240 --> 51:03.720\n in which case we won't make that move,\n\n51:03.720 --> 51:05.520\n we'll make a different move.\n\n51:05.520 --> 51:08.160\n And did you find, I mean, I assume with the popularity\n\n51:08.160 --> 51:09.440\n and the growth of the internet\n\n51:09.440 --> 51:11.520\n that people were creating new content,\n\n51:11.520 --> 51:14.240\n so you're almost helping guide the creation of new content.\n\n51:14.240 --> 51:15.800\n Yeah, so that's certainly true, right,\n\n51:15.800 --> 51:20.800\n so we definitely changed the structure of the network.\n\n51:20.800 --> 51:24.520\n So if you think back in the very early days,\n\n51:24.520 --> 51:28.320\n Larry and Sergey had the PageRank paper\n\n51:28.320 --> 51:33.240\n and John Kleinberg had this hubs and authorities model,\n\n51:33.240 --> 51:38.240\n which says the web is made out of these hubs,\n\n51:38.480 --> 51:43.480\n which will be my page of cool links about dogs or whatever,\n\n51:44.480 --> 51:46.880\n and people would just list links.\n\n51:46.880 --> 51:47.960\n And then there'd be authorities,\n\n51:47.960 --> 51:51.920\n which were the page about dogs that most people linked to.\n\n51:53.080 --> 51:54.240\n That doesn't happen anymore.\n\n51:54.240 --> 51:57.800\n People don't bother to say my page of cool links,\n\n51:57.800 --> 52:00.080\n because we took over that function, right,\n\n52:00.080 --> 52:03.360\n so we changed the way that worked.\n\n52:03.360 --> 52:05.680\n Did you imagine back then that the internet\n\n52:05.680 --> 52:08.840\n would be as massively vibrant as it is today?\n\n52:08.840 --> 52:10.320\n I mean, it was already growing quickly,\n\n52:10.320 --> 52:14.800\n but it's just another, I don't know if you've ever,\n\n52:14.800 --> 52:18.000\n today, if you sit back and just look at the internet\n\n52:18.000 --> 52:20.520\n with wonder the amount of content\n\n52:20.520 --> 52:22.000\n that's just constantly being created,\n\n52:22.000 --> 52:24.200\n constantly being shared and deployed.\n\n52:24.200 --> 52:27.400\n Yeah, it's always been surprising to me.\n\n52:27.400 --> 52:31.200\n I guess I'm not very good at predicting the future.\n\n52:31.200 --> 52:35.720\n And I remember being a graduate student in 1980 or so,\n\n52:35.720 --> 52:39.480\n and we had the ARPANET,\n\n52:39.480 --> 52:44.480\n and then there was this proposal to commercialize it,\n\n52:44.480 --> 52:48.320\n and have this internet, and this crazy Senator Gore\n\n52:49.520 --> 52:51.280\n thought that might be a good idea.\n\n52:51.280 --> 52:53.040\n And I remember thinking, oh, come on,\n\n52:53.040 --> 52:55.840\n you can't expect a commercial company\n\n52:55.840 --> 52:58.360\n to understand this technology.\n\n52:58.360 --> 52:59.360\n They'll never be able to do it.\n\n52:59.360 --> 53:01.560\n Yeah, okay, we can have this.com domain,\n\n53:01.560 --> 53:03.360\n but it won't go anywhere.\n\n53:03.360 --> 53:05.560\n So I was wrong, Al Gore was right.\n\n53:05.560 --> 53:07.920\n At the same time, the nature of what it means\n\n53:07.920 --> 53:09.880\n to be a commercial company has changed, too.\n\n53:09.880 --> 53:12.720\n So Google, in many ways, at its founding\n\n53:12.720 --> 53:16.840\n is different than what companies were before, I think.\n\n53:16.840 --> 53:19.760\n Right, so there's all these business models\n\n53:19.760 --> 53:23.080\n that are so different than what was possible back then.\n\n53:23.080 --> 53:25.000\n So in terms of predicting the future,\n\n53:25.000 --> 53:27.280\n what do you think it takes to build a system\n\n53:27.280 --> 53:29.960\n that approaches human level intelligence?\n\n53:29.960 --> 53:31.780\n You've talked about, of course,\n\n53:31.780 --> 53:34.160\n that we shouldn't be so obsessed\n\n53:34.160 --> 53:36.360\n about creating human level intelligence.\n\n53:36.360 --> 53:39.320\n We just create systems that are very useful for humans.\n\n53:39.320 --> 53:40.800\n But what do you think it takes\n\n53:40.800 --> 53:44.960\n to approach that level?\n\n53:44.960 --> 53:47.400\n Right, so certainly I don't think\n\n53:47.400 --> 53:49.880\n human level intelligence is one thing, right?\n\n53:49.880 --> 53:51.680\n So I think there's lots of different tasks,\n\n53:51.680 --> 53:53.200\n lots of different capabilities.\n\n53:54.080 --> 53:56.760\n I also don't think that should be the goal, right?\n\n53:56.760 --> 54:01.640\n So I wouldn't wanna create a calculator\n\n54:01.640 --> 54:04.320\n that could do multiplication at human level, right?\n\n54:04.320 --> 54:06.020\n That would be a step backwards.\n\n54:06.020 --> 54:07.520\n And so for many things,\n\n54:07.520 --> 54:09.600\n we should be aiming far beyond human level\n\n54:09.600 --> 54:12.280\n for other things.\n\n54:12.280 --> 54:15.320\n Maybe human level is a good level to aim at.\n\n54:15.320 --> 54:16.900\n And for others, we'd say,\n\n54:16.900 --> 54:18.080\n well, let's not bother doing this\n\n54:18.080 --> 54:20.880\n because we already have humans can take on those tasks.\n\n54:21.980 --> 54:26.380\n So as you say, I like to focus on what's a useful tool.\n\n54:26.380 --> 54:30.480\n And in some cases, being at human level\n\n54:30.480 --> 54:32.880\n is an important part of crossing that threshold\n\n54:32.880 --> 54:34.560\n to make the tool useful.\n\n54:34.560 --> 54:39.400\n So we see in things like these personal assistants now\n\n54:39.400 --> 54:41.080\n that you get either on your phone\n\n54:41.080 --> 54:44.600\n or on a speaker that sits on the table,\n\n54:44.600 --> 54:47.440\n you wanna be able to have a conversation with those.\n\n54:47.440 --> 54:49.880\n And I think as an industry,\n\n54:49.880 --> 54:51.880\n we haven't quite figured out what the right model is\n\n54:51.880 --> 54:53.960\n for what these things can do.\n\n54:55.040 --> 54:56.280\n And we're aiming towards,\n\n54:56.280 --> 54:57.960\n well, you just have a conversation with them\n\n54:57.960 --> 55:00.280\n the way you can with a person.\n\n55:00.280 --> 55:02.960\n But we haven't delivered on that model yet, right?\n\n55:02.960 --> 55:04.960\n So you can ask it, what's the weather?\n\n55:04.960 --> 55:08.380\n You can ask it, play some nice songs.\n\n55:08.380 --> 55:11.660\n And five or six other things,\n\n55:11.660 --> 55:14.020\n and then you run out of stuff that it can do.\n\n55:14.020 --> 55:16.380\n In terms of a deep, meaningful connection.\n\n55:16.380 --> 55:18.020\n So you've mentioned the movie Her\n\n55:18.020 --> 55:20.260\n as one of your favorite AI movies.\n\n55:20.260 --> 55:22.020\n Do you think it's possible for a human being\n\n55:22.020 --> 55:25.760\n to fall in love with an AI assistant, as you mentioned?\n\n55:25.760 --> 55:28.900\n So taking this big leap from what's the weather\n\n55:28.900 --> 55:31.300\n to having a deep connection.\n\n55:31.300 --> 55:35.900\n Yeah, I think as people, that's what we love to do.\n\n55:35.900 --> 55:39.420\n And I was at a showing of Her\n\n55:39.420 --> 55:43.580\n where we had a panel discussion and somebody asked me,\n\n55:43.580 --> 55:46.940\n what other movie do you think Her is similar to?\n\n55:46.940 --> 55:50.340\n And my answer was Life of Brian,\n\n55:50.340 --> 55:52.600\n which is not a science fiction movie,\n\n55:53.580 --> 55:57.260\n but both movies are about wanting to believe\n\n55:57.260 --> 55:59.380\n in something that's not necessarily real.\n\n56:00.660 --> 56:01.860\n Yeah, by the way, for people that don't know,\n\n56:01.860 --> 56:03.000\n it's Monty Python.\n\n56:03.000 --> 56:05.100\n Yeah, it's been brilliantly put.\n\n56:05.100 --> 56:07.580\n Right, so I think that's just the way we are.\n\n56:07.580 --> 56:11.060\n We want to trust, we want to believe,\n\n56:11.060 --> 56:12.500\n we want to fall in love,\n\n56:12.500 --> 56:15.980\n and it doesn't necessarily take that much, right?\n\n56:15.980 --> 56:20.760\n So my kids fell in love with their teddy bear,\n\n56:20.760 --> 56:23.400\n and the teddy bear was not very interactive.\n\n56:23.400 --> 56:26.820\n So that's all us pushing our feelings\n\n56:26.820 --> 56:29.700\n onto our devices and our things,\n\n56:29.700 --> 56:31.900\n and I think that that's what we like to do,\n\n56:31.900 --> 56:33.340\n so we'll continue to do that.\n\n56:33.340 --> 56:36.260\n So yeah, as human beings, we long for that connection,\n\n56:36.260 --> 56:39.620\n and just AI has to do a little bit of work\n\n56:39.620 --> 56:41.900\n to catch us in the other end.\n\n56:41.900 --> 56:46.180\n Yeah, and certainly, if you can get to dog level,\n\n56:46.180 --> 56:49.500\n a lot of people have invested a lot of love in their pets.\n\n56:49.500 --> 56:50.340\n In their pets.\n\n56:50.340 --> 56:52.980\n Some people, as I've been told,\n\n56:52.980 --> 56:54.460\n in working with autonomous vehicles,\n\n56:54.460 --> 56:58.300\n have invested a lot of love into their inanimate cars,\n\n56:58.300 --> 57:00.920\n so it really doesn't take much.\n\n57:00.920 --> 57:05.260\n So what is a good test to linger on a topic\n\n57:05.260 --> 57:07.900\n that may be silly or a little bit philosophical?\n\n57:07.900 --> 57:10.340\n What is a good test of intelligence in your view?\n\n57:12.220 --> 57:14.460\n Is natural conversation like in the Turing test\n\n57:14.460 --> 57:16.500\n a good test?\n\n57:16.500 --> 57:20.000\n Put another way, what would impress you\n\n57:20.000 --> 57:22.740\n if you saw a computer do it these days?\n\n57:22.740 --> 57:24.460\n Yeah, I mean, I get impressed all the time.\n\n57:24.460 --> 57:32.940\n Go playing, StarCraft playing, those are all pretty cool.\n\n57:35.220 --> 57:39.820\n And I think, sure, conversation is important.\n\n57:39.820 --> 57:44.780\n I think we sometimes have these tests\n\n57:44.780 --> 57:46.980\n where it's easy to fool the system, where\n\n57:46.980 --> 57:51.340\n you can have a chat bot that can have a conversation,\n\n57:51.340 --> 57:54.500\n but it never gets into a situation\n\n57:54.500 --> 57:58.660\n where it has to be deep enough that it really reveals itself\n\n57:58.660 --> 58:00.940\n as being intelligent or not.\n\n58:00.940 --> 58:07.620\n I think Turing suggested that, but I think if he were alive,\n\n58:07.620 --> 58:11.580\n he'd say, you know, I didn't really mean that seriously.\n\n58:11.580 --> 58:15.100\n And I think, this is just my opinion,\n\n58:15.100 --> 58:17.820\n but I think Turing's point was not\n\n58:17.820 --> 58:21.460\n that this test of conversation is a good test.\n\n58:21.460 --> 58:25.340\n I think his point was having a test is the right thing.\n\n58:25.340 --> 58:28.620\n So rather than having the philosophers say, oh, no,\n\n58:28.620 --> 58:31.180\n AI is impossible, you should say, well,\n\n58:31.180 --> 58:33.420\n we'll just have a test, and then the result of that\n\n58:33.420 --> 58:34.620\n will tell us the answer.\n\n58:34.620 --> 58:37.220\n And it doesn't necessarily have to be a conversation test.\n\n58:37.220 --> 58:37.740\n That's right.\n\n58:37.740 --> 58:40.220\n And coming up a new, better test as the technology evolves\n\n58:40.220 --> 58:42.140\n is probably the right way.\n\n58:42.140 --> 58:46.580\n Do you worry, as a lot of the general public does about,\n\n58:46.580 --> 58:51.020\n not a lot, but some vocal part of the general public\n\n58:51.020 --> 58:53.580\n about the existential threat of artificial intelligence?\n\n58:53.580 --> 58:56.940\n So looking farther into the future, as you said,\n\n58:56.940 --> 58:59.020\n most of us are not able to predict much.\n\n58:59.020 --> 59:02.460\n So when shrouded in such mystery, there's a concern of,\n\n59:02.460 --> 59:05.020\n well, you start thinking about worst case.\n\n59:05.020 --> 59:09.060\n Is that something that occupies your mind, space, much?\n\n59:09.060 --> 59:11.420\n So I certainly think about threats.\n\n59:11.420 --> 59:13.860\n I think about dangers.\n\n59:13.860 --> 59:19.820\n And I think any new technology has positives and negatives.\n\n59:19.820 --> 59:21.460\n And if it's a powerful technology,\n\n59:21.460 --> 59:24.700\n it can be used for bad as well as for good.\n\n59:24.700 --> 59:27.820\n So I'm certainly not worried about the robot\n\n59:27.820 --> 59:32.540\n apocalypse and the Terminator type scenarios.\n\n59:32.540 --> 59:37.620\n I am worried about change in employment.\n\n59:37.620 --> 59:41.020\n And are we going to be able to react fast enough\n\n59:41.020 --> 59:41.900\n to deal with that?\n\n59:41.900 --> 59:44.380\n I think we're already seeing it today, where\n\n59:44.380 --> 59:48.420\n a lot of people are disgruntled about the way\n\n59:48.420 --> 59:50.180\n income inequality is working.\n\n59:50.180 --> 59:53.300\n And automation could help accelerate\n\n59:53.300 --> 59:55.500\n those kinds of problems.\n\n59:55.500 --> 59:59.980\n I see powerful technologies can always be used as weapons,\n\n59:59.980 --> 1:00:03.380\n whether they're robots or drones or whatever.\n\n1:00:03.380 --> 1:00:06.180\n Some of that we're seeing due to AI.\n\n1:00:06.180 --> 1:00:09.420\n A lot of it, you don't need AI.\n\n1:00:09.420 --> 1:00:12.500\n And I don't know what's a worst threat,\n\n1:00:12.500 --> 1:00:17.660\n if it's an autonomous drone or it's CRISPR technology\n\n1:00:17.660 --> 1:00:18.860\n becoming available.\n\n1:00:18.860 --> 1:00:21.340\n Or we have lots of threats to face.\n\n1:00:21.340 --> 1:00:24.660\n And some of them involve AI, and some of them don't.\n\n1:00:24.660 --> 1:00:27.220\n So the threats that technology presents,\n\n1:00:27.220 --> 1:00:31.020\n are you, for the most part, optimistic about technology\n\n1:00:31.020 --> 1:00:34.340\n also alleviating those threats or creating new opportunities\n\n1:00:34.340 --> 1:00:38.300\n or protecting us from the more detrimental effects\n\n1:00:38.300 --> 1:00:38.820\n of these new technologies?\n\n1:00:38.820 --> 1:00:39.780\n I don't know.\n\n1:00:39.780 --> 1:00:41.420\n Again, it's hard to predict the future.\n\n1:00:41.420 --> 1:00:47.580\n And as a society so far, we've survived\n\n1:00:47.580 --> 1:00:50.780\n nuclear bombs and other things.\n\n1:00:50.780 --> 1:00:53.660\n Of course, only societies that have survived\n\n1:00:53.660 --> 1:00:54.780\n are having this conversation.\n\n1:00:54.780 --> 1:00:59.260\n So maybe that's survivorship bias there.\n\n1:00:59.260 --> 1:01:02.780\n What problem stands out to you as exciting, challenging,\n\n1:01:02.780 --> 1:01:06.540\n impactful to work on in the near future for yourself,\n\n1:01:06.540 --> 1:01:09.340\n for the community, and broadly?\n\n1:01:09.340 --> 1:01:13.060\n So we talked about these assistance and conversation.\n\n1:01:13.060 --> 1:01:14.980\n I think that's a great area.\n\n1:01:14.980 --> 1:01:20.980\n I think combining common sense reasoning\n\n1:01:20.980 --> 1:01:26.420\n with the power of data is a great area.\n\n1:01:26.420 --> 1:01:27.300\n In which application?\n\n1:01:27.300 --> 1:01:29.340\n In conversation, or just broadly speaking?\n\n1:01:29.340 --> 1:01:31.300\n Just in general, yeah.\n\n1:01:31.300 --> 1:01:35.500\n As a programmer, I'm interested in programming tools,\n\n1:01:35.500 --> 1:01:38.980\n both in terms of the current systems\n\n1:01:38.980 --> 1:01:41.660\n we have today with TensorFlow and so on.\n\n1:01:41.660 --> 1:01:43.460\n Can we make them much easier to use\n\n1:01:43.460 --> 1:01:45.980\n for a broader class of people?\n\n1:01:45.980 --> 1:01:49.340\n And also, can we apply machine learning\n\n1:01:49.340 --> 1:01:52.380\n to the more traditional type of programming?\n\n1:01:52.380 --> 1:01:57.460\n So when you go to Google and you type in a query\n\n1:01:57.460 --> 1:02:00.300\n and you spell something wrong, it says, did you mean?\n\n1:02:00.300 --> 1:02:01.900\n And the reason we're able to do that\n\n1:02:01.900 --> 1:02:04.460\n is because lots of other people made a similar error,\n\n1:02:04.460 --> 1:02:06.540\n and then they corrected it.\n\n1:02:06.540 --> 1:02:10.140\n We should be able to go into our code bases and our bug fix\n\n1:02:10.140 --> 1:02:10.820\n bases.\n\n1:02:10.820 --> 1:02:13.940\n And when I type a line of code, it should be able to say,\n\n1:02:13.940 --> 1:02:15.180\n did you mean such and such?\n\n1:02:15.180 --> 1:02:17.780\n If you type this today, you're probably going to type\n\n1:02:17.780 --> 1:02:20.540\n in this bug fix tomorrow.\n\n1:02:20.540 --> 1:02:22.620\n Yeah, that's a really exciting application\n\n1:02:22.620 --> 1:02:27.660\n of almost an assistant for the coding programming experience\n\n1:02:27.660 --> 1:02:29.420\n at every level.\n\n1:02:29.420 --> 1:02:35.260\n So I think I could safely speak for the entire AI community,\n\n1:02:35.260 --> 1:02:37.900\n first of all, for thanking you for the amazing work you've\n\n1:02:37.900 --> 1:02:40.620\n done, certainly for the amazing work you've done\n\n1:02:40.620 --> 1:02:43.380\n with AI and Modern Approach book.\n\n1:02:43.380 --> 1:02:45.260\n I think we're all looking forward very much\n\n1:02:45.260 --> 1:02:48.500\n for the fourth edition, and then the fifth edition, and so on.\n\n1:02:48.500 --> 1:02:51.380\n So Peter, thank you so much for talking today.\n\n1:02:51.380 --> 1:02:51.980\n Yeah, thank you.\n\n1:02:51.980 --> 1:03:12.300\n My pleasure.\n\n"
}
{
  "title": "Chris Lattner: Compilers, LLVM, Swift, TPU, and ML Accelerators | Lex Fridman Podcast #21",
  "id": "yCd3CzGSte8",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:02.680\n The following is a conversation with Chris Latner.\n\n00:02.680 --> 00:04.560\n Currently, he's a senior director\n\n00:04.560 --> 00:08.400\n at Google working on several projects, including CPU, GPU,\n\n00:08.400 --> 00:12.040\n TPU accelerators for TensorFlow, Swift for TensorFlow,\n\n00:12.040 --> 00:14.400\n and all kinds of machine learning compiler magic\n\n00:14.400 --> 00:16.360\n going on behind the scenes.\n\n00:16.360 --> 00:18.440\n He's one of the top experts in the world\n\n00:18.440 --> 00:21.160\n on compiler technologies, which means he deeply\n\n00:21.160 --> 00:25.560\n understands the intricacies of how hardware and software come\n\n00:25.560 --> 00:27.920\n together to create efficient code.\n\n00:27.920 --> 00:31.400\n He created the LLVM compiler infrastructure project\n\n00:31.400 --> 00:33.360\n and the Clang compiler.\n\n00:33.360 --> 00:36.000\n He led major engineering efforts at Apple,\n\n00:36.000 --> 00:39.000\n including the creation of the Swift programming language.\n\n00:39.000 --> 00:41.720\n He also briefly spent time at Tesla\n\n00:41.720 --> 00:44.280\n as vice president of Autopilot software\n\n00:44.280 --> 00:46.760\n during the transition from Autopilot hardware 1\n\n00:46.760 --> 00:49.600\n to hardware 2, when Tesla essentially\n\n00:49.600 --> 00:52.640\n started from scratch to build an in house software\n\n00:52.640 --> 00:54.800\n infrastructure for Autopilot.\n\n00:54.800 --> 00:58.040\n I could have easily talked to Chris for many more hours.\n\n00:58.040 --> 01:01.200\n Compiling code down across the levels of abstraction\n\n01:01.200 --> 01:04.160\n is one of the most fundamental and fascinating aspects\n\n01:04.160 --> 01:06.640\n of what computers do, and he is one of the world\n\n01:06.640 --> 01:08.560\n experts in this process.\n\n01:08.560 --> 01:12.880\n It's rigorous science, and it's messy, beautiful art.\n\n01:12.880 --> 01:15.920\n This conversation is part of the Artificial Intelligence\n\n01:15.920 --> 01:16.760\n podcast.\n\n01:16.760 --> 01:19.440\n If you enjoy it, subscribe on YouTube, iTunes,\n\n01:19.440 --> 01:22.760\n or simply connect with me on Twitter at Lex Friedman,\n\n01:22.760 --> 01:24.680\n spelled F R I D.\n\n01:24.680 --> 01:29.360\n And now, here's my conversation with Chris Ladner.\n\n01:29.360 --> 01:33.160\n What was the first program you've ever written?\n\n01:33.160 --> 01:34.120\n My first program.\n\n01:34.120 --> 01:35.360\n Back, and when was it?\n\n01:35.360 --> 01:39.080\n I think I started as a kid, and my parents\n\n01:39.080 --> 01:41.560\n got a basic programming book.\n\n01:41.560 --> 01:44.200\n And so when I started, it was typing out programs\n\n01:44.200 --> 01:46.880\n from a book, and seeing how they worked,\n\n01:46.880 --> 01:49.680\n and then typing them in wrong, and trying\n\n01:49.680 --> 01:51.680\n to figure out why they were not working right,\n\n01:51.680 --> 01:52.960\n that kind of stuff.\n\n01:52.960 --> 01:54.880\n So BASIC, what was the first language\n\n01:54.880 --> 01:58.360\n that you remember yourself maybe falling in love with,\n\n01:58.360 --> 01:59.720\n like really connecting with?\n\n01:59.720 --> 02:00.400\n I don't know.\n\n02:00.400 --> 02:02.680\n I mean, I feel like I've learned a lot along the way,\n\n02:02.680 --> 02:05.800\n and each of them have a different special thing\n\n02:05.800 --> 02:06.640\n about them.\n\n02:06.640 --> 02:09.720\n So I started in BASIC, and then went like GW BASIC,\n\n02:09.720 --> 02:11.440\n which was the thing back in the DOS days,\n\n02:11.440 --> 02:15.280\n and then upgraded to QBASIC, and eventually QuickBASIC,\n\n02:15.280 --> 02:18.200\n which are all slightly more fancy versions of Microsoft\n\n02:18.200 --> 02:19.440\n BASIC.\n\n02:19.440 --> 02:21.360\n Made the jump to Pascal, and started\n\n02:21.360 --> 02:23.920\n doing machine language programming and assembly\n\n02:23.920 --> 02:25.280\n in Pascal, which was really cool.\n\n02:25.280 --> 02:28.080\n Turbo Pascal was amazing for its day.\n\n02:28.080 --> 02:31.600\n Eventually got into C, C++, and then kind of did\n\n02:31.600 --> 02:33.400\n lots of other weird things.\n\n02:33.400 --> 02:37.080\n I feel like you took the dark path, which is the,\n\n02:37.080 --> 02:39.480\n you could have gone Lisp.\n\n02:39.480 --> 02:40.000\n Yeah.\n\n02:40.000 --> 02:41.680\n You could have gone higher level sort\n\n02:41.680 --> 02:44.600\n of functional philosophical hippie route.\n\n02:44.600 --> 02:48.080\n Instead, you went into like the dark arts of the C.\n\n02:48.080 --> 02:49.720\n It was straight into the machine.\n\n02:49.720 --> 02:50.680\n Straight to the machine.\n\n02:50.680 --> 02:53.880\n So I started with BASIC, Pascal, and then Assembly,\n\n02:53.880 --> 02:55.320\n and then wrote a lot of Assembly.\n\n02:55.320 --> 03:00.080\n And I eventually did Smalltalk and other things like that.\n\n03:00.080 --> 03:01.880\n But that was not the starting point.\n\n03:01.880 --> 03:05.080\n But so what is this journey to C?\n\n03:05.080 --> 03:06.320\n Is that in high school?\n\n03:06.320 --> 03:07.560\n Is that in college?\n\n03:07.560 --> 03:09.320\n That was in high school, yeah.\n\n03:09.320 --> 03:13.720\n And then that was really about trying\n\n03:13.720 --> 03:16.240\n to be able to do more powerful things than what Pascal could\n\n03:16.240 --> 03:18.960\n do, and also to learn a different world.\n\n03:18.960 --> 03:20.760\n So he was really confusing to me with pointers\n\n03:20.760 --> 03:23.000\n and the syntax and everything, and it took a while.\n\n03:23.000 --> 03:28.800\n But Pascal's much more principled in various ways.\n\n03:28.800 --> 03:33.400\n C is more, I mean, it has its historical roots,\n\n03:33.400 --> 03:35.520\n but it's not as easy to learn.\n\n03:35.520 --> 03:39.880\n With pointers, there's this memory management thing\n\n03:39.880 --> 03:41.680\n that you have to become conscious of.\n\n03:41.680 --> 03:43.880\n Is that the first time you start to understand\n\n03:43.880 --> 03:46.520\n that there's resources that you're supposed to manage?\n\n03:46.520 --> 03:48.480\n Well, so you have that in Pascal as well.\n\n03:48.480 --> 03:51.440\n But in Pascal, like the caret instead of the star,\n\n03:51.440 --> 03:53.160\n there's some small differences like that.\n\n03:53.160 --> 03:55.680\n But it's not about pointer arithmetic.\n\n03:55.680 --> 03:58.760\n And in C, you end up thinking about how things get\n\n03:58.760 --> 04:00.840\n laid out in memory a lot more.\n\n04:00.840 --> 04:04.160\n And so in Pascal, you have allocating and deallocating\n\n04:04.160 --> 04:07.560\n and owning the memory, but just the programs are simpler,\n\n04:07.560 --> 04:10.080\n and you don't have to.\n\n04:10.080 --> 04:12.640\n Well, for example, Pascal has a string type.\n\n04:12.640 --> 04:14.040\n And so you can think about a string\n\n04:14.040 --> 04:15.880\n instead of an array of characters\n\n04:15.880 --> 04:17.720\n which are consecutive in memory.\n\n04:17.720 --> 04:20.400\n So it's a little bit of a higher level abstraction.\n\n04:20.400 --> 04:22.800\n So let's get into it.\n\n04:22.800 --> 04:25.560\n Let's talk about LLVM, C lang, and compilers.\n\n04:25.560 --> 04:26.560\n Sure.\n\n04:26.560 --> 04:32.160\n So can you tell me first what LLVM and C lang are?\n\n04:32.160 --> 04:33.960\n And how is it that you find yourself\n\n04:33.960 --> 04:35.720\n the creator and lead developer, one\n\n04:35.720 --> 04:39.400\n of the most powerful compiler optimization systems\n\n04:39.400 --> 04:40.080\n in use today?\n\n04:40.080 --> 04:40.580\n Sure.\n\n04:40.580 --> 04:43.320\n So I guess they're different things.\n\n04:43.320 --> 04:47.080\n So let's start with what is a compiler?\n\n04:47.080 --> 04:48.840\n Is that a good place to start?\n\n04:48.840 --> 04:50.200\n What are the phases of a compiler?\n\n04:50.200 --> 04:50.920\n Where are the parts?\n\n04:50.920 --> 04:51.600\n Yeah, what is it?\n\n04:51.600 --> 04:53.400\n So what is even a compiler used for?\n\n04:53.400 --> 04:57.880\n So the way I look at this is you have a two sided problem of you\n\n04:57.880 --> 05:00.120\n have humans that need to write code.\n\n05:00.120 --> 05:01.880\n And then you have machines that need to run\n\n05:01.880 --> 05:03.400\n the program that the human wrote.\n\n05:03.400 --> 05:05.280\n And for lots of reasons, the humans\n\n05:05.280 --> 05:07.040\n don't want to be writing in binary\n\n05:07.040 --> 05:09.080\n and want to think about every piece of hardware.\n\n05:09.080 --> 05:12.100\n And so at the same time that you have lots of humans,\n\n05:12.100 --> 05:14.800\n you also have lots of kinds of hardware.\n\n05:14.800 --> 05:17.400\n And so compilers are the art of allowing\n\n05:17.400 --> 05:19.240\n humans to think at a level of abstraction\n\n05:19.240 --> 05:20.920\n that they want to think about.\n\n05:20.920 --> 05:23.600\n And then get that program, get the thing that they wrote,\n\n05:23.600 --> 05:26.080\n to run on a specific piece of hardware.\n\n05:26.080 --> 05:29.480\n And the interesting and exciting part of all this\n\n05:29.480 --> 05:32.080\n is that there's now lots of different kinds of hardware,\n\n05:32.080 --> 05:35.780\n chips like x86 and PowerPC and ARM and things like that.\n\n05:35.780 --> 05:37.320\n But also high performance accelerators\n\n05:37.320 --> 05:38.900\n for machine learning and other things like that\n\n05:38.900 --> 05:41.520\n are also just different kinds of hardware, GPUs.\n\n05:41.520 --> 05:42.940\n These are new kinds of hardware.\n\n05:42.940 --> 05:45.640\n And at the same time, on the programming side of it,\n\n05:45.640 --> 05:48.680\n you have basic, you have C, you have JavaScript,\n\n05:48.680 --> 05:50.560\n you have Python, you have Swift.\n\n05:50.560 --> 05:52.840\n You have lots of other languages\n\n05:52.840 --> 05:55.200\n that are all trying to talk to the human in a different way\n\n05:55.200 --> 05:58.320\n to make them more expressive and capable and powerful.\n\n05:58.320 --> 06:01.500\n And so compilers are the thing\n\n06:01.500 --> 06:03.460\n that goes from one to the other.\n\n06:03.460 --> 06:05.200\n End to end, from the very beginning to the very end.\n\n06:05.200 --> 06:06.040\n End to end.\n\n06:06.040 --> 06:08.120\n And so you go from what the human wrote\n\n06:08.120 --> 06:11.600\n and programming languages end up being about\n\n06:11.600 --> 06:14.560\n expressing intent, not just for the compiler\n\n06:14.560 --> 06:17.980\n and the hardware, but the programming language's job\n\n06:17.980 --> 06:20.920\n is really to capture an expression\n\n06:20.920 --> 06:22.680\n of what the programmer wanted\n\n06:22.680 --> 06:25.120\n that then can be maintained and adapted\n\n06:25.120 --> 06:27.120\n and evolved by other humans,\n\n06:27.120 --> 06:29.720\n as well as interpreted by the compiler.\n\n06:29.720 --> 06:31.560\n So when you look at this problem,\n\n06:31.560 --> 06:34.200\n you have, on the one hand, humans, which are complicated.\n\n06:34.200 --> 06:36.760\n And you have hardware, which is complicated.\n\n06:36.760 --> 06:39.900\n And so compilers typically work in multiple phases.\n\n06:39.900 --> 06:42.760\n And so the software engineering challenge\n\n06:42.760 --> 06:45.000\n that you have here is try to get maximum reuse\n\n06:45.000 --> 06:47.140\n out of the amount of code that you write,\n\n06:47.140 --> 06:49.800\n because these compilers are very complicated.\n\n06:49.800 --> 06:51.240\n And so the way it typically works out\n\n06:51.240 --> 06:54.480\n is that you have something called a front end or a parser\n\n06:54.480 --> 06:56.640\n that is language specific.\n\n06:56.640 --> 06:59.500\n And so you'll have a C parser, and that's what Clang is,\n\n07:00.400 --> 07:03.480\n or C++ or JavaScript or Python or whatever.\n\n07:03.480 --> 07:05.000\n That's the front end.\n\n07:05.000 --> 07:07.120\n Then you'll have a middle part,\n\n07:07.120 --> 07:09.020\n which is often the optimizer.\n\n07:09.020 --> 07:11.120\n And then you'll have a late part,\n\n07:11.120 --> 07:13.320\n which is hardware specific.\n\n07:13.320 --> 07:15.020\n And so compilers end up,\n\n07:15.020 --> 07:16.680\n there's many different layers often,\n\n07:16.680 --> 07:20.860\n but these three big groups are very common in compilers.\n\n07:20.860 --> 07:22.200\n And what LLVM is trying to do\n\n07:22.200 --> 07:25.360\n is trying to standardize that middle and last part.\n\n07:25.360 --> 07:27.880\n And so one of the cool things about LLVM\n\n07:27.880 --> 07:29.740\n is that there are a lot of different languages\n\n07:29.740 --> 07:31.080\n that compile through to it.\n\n07:31.080 --> 07:35.600\n And so things like Swift, but also Julia, Rust,\n\n07:35.600 --> 07:39.140\n Clang for C, C++, Subjective C,\n\n07:39.140 --> 07:40.940\n like these are all very different languages\n\n07:40.940 --> 07:43.780\n and they can all use the same optimization infrastructure,\n\n07:43.780 --> 07:45.340\n which gets better performance,\n\n07:45.340 --> 07:47.240\n and the same code generation infrastructure\n\n07:47.240 --> 07:48.780\n for hardware support.\n\n07:48.780 --> 07:52.240\n And so LLVM is really that layer that is common,\n\n07:52.240 --> 07:55.580\n that all these different specific compilers can use.\n\n07:55.580 --> 07:59.300\n And is it a standard, like a specification,\n\n07:59.300 --> 08:01.140\n or is it literally an implementation?\n\n08:01.140 --> 08:02.140\n It's an implementation.\n\n08:02.140 --> 08:05.900\n And so I think there's a couple of different ways\n\n08:05.900 --> 08:06.740\n of looking at it, right?\n\n08:06.740 --> 08:09.700\n Because it depends on which angle you're looking at it from.\n\n08:09.700 --> 08:12.660\n LLVM ends up being a bunch of code, okay?\n\n08:12.660 --> 08:14.460\n So it's a bunch of code that people reuse\n\n08:14.460 --> 08:16.540\n and they build compilers with.\n\n08:16.540 --> 08:18.060\n We call it a compiler infrastructure\n\n08:18.060 --> 08:20.060\n because it's kind of the underlying platform\n\n08:20.060 --> 08:22.580\n that you build a concrete compiler on top of.\n\n08:22.580 --> 08:23.740\n But it's also a community.\n\n08:23.740 --> 08:26.820\n And the LLVM community is hundreds of people\n\n08:26.820 --> 08:27.980\n that all collaborate.\n\n08:27.980 --> 08:30.620\n And one of the most fascinating things about LLVM\n\n08:30.620 --> 08:34.260\n over the course of time is that we've managed somehow\n\n08:34.260 --> 08:37.060\n to successfully get harsh competitors\n\n08:37.060 --> 08:39.060\n in the commercial space to collaborate\n\n08:39.060 --> 08:41.120\n on shared infrastructure.\n\n08:41.120 --> 08:43.900\n And so you have Google and Apple,\n\n08:43.900 --> 08:45.860\n you have AMD and Intel,\n\n08:45.860 --> 08:48.860\n you have Nvidia and AMD on the graphics side,\n\n08:48.860 --> 08:52.620\n you have Cray and everybody else doing these things.\n\n08:52.620 --> 08:55.420\n And all these companies are collaborating together\n\n08:55.420 --> 08:58.520\n to make that shared infrastructure really, really great.\n\n08:58.520 --> 09:01.380\n And they do this not out of the goodness of their heart,\n\n09:01.380 --> 09:03.420\n but they do it because it's in their commercial interest\n\n09:03.420 --> 09:05.140\n of having really great infrastructure\n\n09:05.140 --> 09:06.740\n that they can build on top of\n\n09:06.740 --> 09:09.080\n and facing the reality that it's so expensive\n\n09:09.080 --> 09:11.160\n that no one company, even the big companies,\n\n09:11.160 --> 09:14.580\n no one company really wants to implement it all themselves.\n\n09:14.580 --> 09:16.100\n Expensive or difficult?\n\n09:16.100 --> 09:16.940\n Both.\n\n09:16.940 --> 09:20.540\n That's a great point because it's also about the skill sets.\n\n09:20.540 --> 09:25.540\n And the skill sets are very hard to find.\n\n09:26.020 --> 09:27.980\n How big is the LLVM?\n\n09:27.980 --> 09:30.780\n It always seems like with open source projects,\n\n09:30.780 --> 09:33.500\n the kind, an LLVM is open source?\n\n09:33.500 --> 09:34.420\n Yes, it's open source.\n\n09:34.420 --> 09:38.660\n It's about, it's 19 years old now, so it's fairly old.\n\n09:38.660 --> 09:40.940\n It seems like the magic often happens\n\n09:40.940 --> 09:43.020\n within a very small circle of people.\n\n09:43.020 --> 09:43.860\n Yes.\n\n09:43.860 --> 09:46.060\n At least their early birth and whatever.\n\n09:46.060 --> 09:49.660\n Yes, so the LLVM came from a university project,\n\n09:49.660 --> 09:51.540\n and so I was at the University of Illinois.\n\n09:51.540 --> 09:53.900\n And there it was myself, my advisor,\n\n09:53.900 --> 09:57.500\n and then a team of two or three research students\n\n09:57.500 --> 09:58.380\n in the research group,\n\n09:58.380 --> 10:02.100\n and we built many of the core pieces initially.\n\n10:02.100 --> 10:03.740\n I then graduated and went to Apple,\n\n10:03.740 --> 10:06.480\n and at Apple brought it to the products,\n\n10:06.480 --> 10:09.340\n first in the OpenGL graphics stack,\n\n10:09.340 --> 10:11.580\n but eventually to the C compiler realm,\n\n10:11.580 --> 10:12.780\n and eventually built Clang,\n\n10:12.780 --> 10:14.640\n and eventually built Swift and these things.\n\n10:14.640 --> 10:16.380\n Along the way, building a team of people\n\n10:16.380 --> 10:18.620\n that are really amazing compiler engineers\n\n10:18.620 --> 10:20.060\n that helped build a lot of that.\n\n10:20.060 --> 10:21.860\n And so as it was gaining momentum\n\n10:21.860 --> 10:24.780\n and as Apple was using it, being open source and public\n\n10:24.780 --> 10:26.440\n and encouraging contribution,\n\n10:26.440 --> 10:28.780\n many others, for example, at Google,\n\n10:28.780 --> 10:30.220\n came in and started contributing.\n\n10:30.220 --> 10:33.740\n And in some cases, Google effectively owns Clang now\n\n10:33.740 --> 10:35.540\n because it cares so much about C++\n\n10:35.540 --> 10:37.340\n and the evolution of that ecosystem,\n\n10:37.340 --> 10:41.420\n and so it's investing a lot in the C++ world\n\n10:41.420 --> 10:42.980\n and the tooling and things like that.\n\n10:42.980 --> 10:47.860\n And so likewise, NVIDIA cares a lot about CUDA.\n\n10:47.860 --> 10:50.780\n And so CUDA uses Clang and uses LLVM\n\n10:50.780 --> 10:54.060\n for graphics and GPGPU.\n\n10:54.060 --> 10:58.940\n And so when you first started as a master's project,\n\n10:58.940 --> 11:02.980\n I guess, did you think it was gonna go as far as it went?\n\n11:02.980 --> 11:06.340\n Were you crazy ambitious about it?\n\n11:06.340 --> 11:07.180\n No.\n\n11:07.180 --> 11:09.840\n It seems like a really difficult undertaking, a brave one.\n\n11:09.840 --> 11:11.380\n Yeah, no, no, no, it was nothing like that.\n\n11:11.380 --> 11:13.740\n So my goal when I went to the University of Illinois\n\n11:13.740 --> 11:17.540\n was to get in and out with a non thesis masters in a year\n\n11:17.540 --> 11:18.720\n and get back to work.\n\n11:18.720 --> 11:22.200\n So I was not planning to stay for five years\n\n11:22.200 --> 11:24.460\n and build this massive infrastructure.\n\n11:24.460 --> 11:27.380\n I got nerd sniped into staying.\n\n11:27.380 --> 11:29.580\n And a lot of it was because LLVM was fun\n\n11:29.580 --> 11:30.900\n and I was building cool stuff\n\n11:30.900 --> 11:33.420\n and learning really interesting things\n\n11:33.420 --> 11:36.900\n and facing both software engineering challenges,\n\n11:36.900 --> 11:38.540\n but also learning how to work in a team\n\n11:38.540 --> 11:40.100\n and things like that.\n\n11:40.100 --> 11:43.620\n I had worked at many companies as interns before that,\n\n11:43.620 --> 11:45.860\n but it was really a different thing\n\n11:45.860 --> 11:48.060\n to have a team of people that are working together\n\n11:48.060 --> 11:50.460\n and try and collaborate in version control.\n\n11:50.460 --> 11:52.420\n And it was just a little bit different.\n\n11:52.420 --> 11:54.060\n Like I said, I just talked to Don Knuth\n\n11:54.060 --> 11:56.860\n and he believes that 2% of the world population\n\n11:56.860 --> 11:58.820\n have something weird with their brain,\n\n11:58.820 --> 12:01.100\n that they're geeks, they understand computers,\n\n12:01.100 --> 12:02.580\n they're connected with computers.\n\n12:02.580 --> 12:04.380\n He put it at exactly 2%.\n\n12:04.380 --> 12:05.540\n Okay, so.\n\n12:05.540 --> 12:06.580\n He's a specific guy.\n\n12:06.580 --> 12:08.780\n It's very specific.\n\n12:08.780 --> 12:10.180\n Well, he says, I can't prove it,\n\n12:10.180 --> 12:11.780\n but it's very empirically there.\n\n12:13.180 --> 12:14.500\n Is there something that attracts you\n\n12:14.500 --> 12:16.940\n to the idea of optimizing code?\n\n12:16.940 --> 12:19.180\n And he seems like that's one of the biggest,\n\n12:19.180 --> 12:20.900\n coolest things about LLVM.\n\n12:20.900 --> 12:22.500\n Yeah, that's one of the major things it does.\n\n12:22.500 --> 12:26.460\n So I got into that because of a person, actually.\n\n12:26.460 --> 12:28.220\n So when I was in my undergraduate,\n\n12:28.220 --> 12:32.060\n I had an advisor, or a professor named Steve Vegdahl.\n\n12:32.060 --> 12:35.740\n And he, I went to this little tiny private school.\n\n12:35.740 --> 12:38.300\n There were like seven or nine people\n\n12:38.300 --> 12:40.340\n in my computer science department,\n\n12:40.340 --> 12:43.100\n students in my class.\n\n12:43.100 --> 12:47.460\n So it was a very tiny, very small school.\n\n12:47.460 --> 12:49.940\n It was kind of a wart on the side of the math department\n\n12:49.940 --> 12:51.260\n kind of a thing at the time.\n\n12:51.260 --> 12:53.820\n I think it's evolved a lot in the many years since then.\n\n12:53.820 --> 12:58.300\n But Steve Vegdahl was a compiler guy.\n\n12:58.300 --> 12:59.580\n And he was super passionate.\n\n12:59.580 --> 13:02.740\n And his passion rubbed off on me.\n\n13:02.740 --> 13:04.460\n And one of the things I like about compilers\n\n13:04.460 --> 13:09.100\n is that they're large, complicated software pieces.\n\n13:09.100 --> 13:12.940\n And so one of the culminating classes\n\n13:12.940 --> 13:14.540\n that many computer science departments,\n\n13:14.540 --> 13:16.700\n at least at the time, did was to say\n\n13:16.700 --> 13:18.380\n that you would take algorithms and data structures\n\n13:18.380 --> 13:19.460\n and all these core classes.\n\n13:19.460 --> 13:21.740\n But then the compilers class was one of the last classes\n\n13:21.740 --> 13:24.380\n you take because it pulls everything together.\n\n13:24.380 --> 13:26.980\n And then you work on one piece of code\n\n13:26.980 --> 13:28.700\n over the entire semester.\n\n13:28.700 --> 13:32.180\n And so you keep building on your own work,\n\n13:32.180 --> 13:33.460\n which is really interesting.\n\n13:33.460 --> 13:36.060\n And it's also very challenging because in many classes,\n\n13:36.060 --> 13:38.380\n if you don't get a project done, you just forget about it\n\n13:38.380 --> 13:41.300\n and move on to the next one and get your B or whatever it is.\n\n13:41.300 --> 13:43.860\n But here you have to live with the decisions you make\n\n13:43.860 --> 13:45.220\n and continue to reinvest in it.\n\n13:45.220 --> 13:48.500\n And I really like that.\n\n13:48.500 --> 13:50.700\n And so I did an extra study project\n\n13:50.700 --> 13:52.420\n with him the following semester.\n\n13:52.420 --> 13:53.940\n And he was just really great.\n\n13:53.940 --> 13:56.860\n And he was also a great mentor in a lot of ways.\n\n13:56.860 --> 13:59.500\n And so from him and from his advice,\n\n13:59.500 --> 14:01.380\n he encouraged me to go to graduate school.\n\n14:01.380 --> 14:03.420\n I wasn't super excited about going to grad school.\n\n14:03.420 --> 14:05.540\n I wanted the master's degree, but I\n\n14:05.540 --> 14:08.940\n didn't want to be an academic.\n\n14:08.940 --> 14:11.100\n But like I said, I kind of got tricked into saying\n\n14:11.100 --> 14:12.180\n and was having a lot of fun.\n\n14:12.180 --> 14:14.540\n And I definitely do not regret it.\n\n14:14.540 --> 14:17.940\n What aspects of compilers were the things you connected with?\n\n14:17.940 --> 14:22.100\n So LLVM, there's also the other part\n\n14:22.100 --> 14:24.940\n that's really interesting if you're interested in languages\n\n14:24.940 --> 14:29.620\n is parsing and just analyzing the language,\n\n14:29.620 --> 14:31.220\n breaking it down, parsing, and so on.\n\n14:31.220 --> 14:32.580\n Was that interesting to you, or were you\n\n14:32.580 --> 14:34.060\n more interested in optimization?\n\n14:34.060 --> 14:37.420\n For me, it was more so I'm not really a math person.\n\n14:37.420 --> 14:38.180\n I could do math.\n\n14:38.180 --> 14:41.540\n I understand some bits of it when I get into it.\n\n14:41.540 --> 14:43.940\n But math is never the thing that attracted me.\n\n14:43.940 --> 14:46.100\n And so a lot of the parser part of the compiler\n\n14:46.100 --> 14:47.820\n has a lot of good formal theories\n\n14:47.820 --> 14:50.060\n that Don, for example, knows quite well.\n\n14:50.060 --> 14:51.540\n I'm still waiting for his book on that.\n\n14:54.740 --> 14:57.900\n But I just like building a thing and seeing what it could do\n\n14:57.900 --> 15:00.740\n and exploring and getting it to do more things\n\n15:00.740 --> 15:04.020\n and then setting new goals and reaching for them.\n\n15:04.020 --> 15:09.580\n And in the case of LLVM, when I started working on that,\n\n15:09.580 --> 15:13.420\n my research advisor that I was working for was a compiler guy.\n\n15:13.420 --> 15:15.620\n And so he and I specifically found each other\n\n15:15.620 --> 15:16.940\n because we were both interested in compilers.\n\n15:16.940 --> 15:19.500\n And so I started working with him and taking his class.\n\n15:19.500 --> 15:21.580\n And a lot of LLVM initially was, it's\n\n15:21.580 --> 15:24.380\n fun implementing all the standard algorithms and all\n\n15:24.380 --> 15:26.380\n the things that people had been talking about\n\n15:26.380 --> 15:27.220\n and were well known.\n\n15:27.220 --> 15:30.620\n And they were in the curricula for advanced studies\n\n15:30.620 --> 15:31.340\n and compilers.\n\n15:31.340 --> 15:34.580\n And so just being able to build that was really fun.\n\n15:34.580 --> 15:37.660\n And I was learning a lot by, instead of reading about it,\n\n15:37.660 --> 15:38.660\n just building.\n\n15:38.660 --> 15:40.220\n And so I enjoyed that.\n\n15:40.220 --> 15:42.820\n So you said compilers are these complicated systems.\n\n15:42.820 --> 15:46.180\n Can you even just with language try\n\n15:46.180 --> 15:52.220\n to describe how you turn a C++ program into code?\n\n15:52.220 --> 15:53.460\n Like, what are the hard parts?\n\n15:53.460 --> 15:54.620\n Why is it so hard?\n\n15:54.620 --> 15:57.020\n So I'll give you examples of the hard parts along the way.\n\n15:57.020 --> 16:01.060\n So C++ is a very complicated programming language.\n\n16:01.060 --> 16:03.500\n It's something like 1,400 pages in the spec.\n\n16:03.500 --> 16:06.060\n So C++ by itself is crazy complicated.\n\n16:06.060 --> 16:07.140\n Can we just pause?\n\n16:07.140 --> 16:09.140\n What makes the language complicated in terms\n\n16:09.140 --> 16:12.340\n of what's syntactically?\n\n16:12.340 --> 16:14.300\n So it's what they call syntax.\n\n16:14.300 --> 16:16.700\n So the actual how the characters are arranged, yes.\n\n16:16.700 --> 16:20.020\n It's also semantics, how it behaves.\n\n16:20.020 --> 16:21.900\n It's also, in the case of C++, there's\n\n16:21.900 --> 16:23.380\n a huge amount of history.\n\n16:23.380 --> 16:26.700\n C++ is built on top of C. You play that forward.\n\n16:26.700 --> 16:29.860\n And then a bunch of suboptimal, in some cases, decisions\n\n16:29.860 --> 16:31.620\n were made, and they compound.\n\n16:31.620 --> 16:33.380\n And then more and more and more things\n\n16:33.380 --> 16:36.980\n keep getting added to C++, and it will probably never stop.\n\n16:36.980 --> 16:38.540\n But the language is very complicated\n\n16:38.540 --> 16:39.540\n from that perspective.\n\n16:39.540 --> 16:41.200\n And so the interactions between subsystems\n\n16:41.200 --> 16:42.420\n is very complicated.\n\n16:42.420 --> 16:43.580\n There's just a lot there.\n\n16:43.580 --> 16:45.660\n And when you talk about the front end,\n\n16:45.660 --> 16:47.060\n one of the major challenges, which\n\n16:47.060 --> 16:51.140\n clang as a project, the C, C++ compiler that I built,\n\n16:51.140 --> 16:54.480\n I and many people built, one of the challenges we took on\n\n16:54.480 --> 16:57.780\n was we looked at GCC.\n\n16:57.780 --> 17:02.540\n GCC, at the time, was a really good industry standardized\n\n17:02.540 --> 17:05.260\n compiler that had really consolidated\n\n17:05.260 --> 17:08.340\n a lot of the other compilers in the world and was a standard.\n\n17:08.340 --> 17:10.620\n But it wasn't really great for research.\n\n17:10.620 --> 17:12.580\n The design was very difficult to work with.\n\n17:12.580 --> 17:16.620\n And it was full of global variables and other things\n\n17:16.620 --> 17:18.540\n that made it very difficult to reuse in ways\n\n17:18.540 --> 17:20.420\n that it wasn't originally designed for.\n\n17:20.420 --> 17:22.740\n And so with clang, one of the things that we wanted to do\n\n17:22.740 --> 17:25.500\n is push forward on better user interface,\n\n17:25.500 --> 17:28.060\n so make error messages that are just better than GCC's.\n\n17:28.060 --> 17:29.580\n And that's actually hard, because you\n\n17:29.580 --> 17:32.780\n have to do a lot of bookkeeping in an efficient way\n\n17:32.780 --> 17:33.700\n to be able to do that.\n\n17:33.700 --> 17:35.180\n We want to make compile time better.\n\n17:35.180 --> 17:37.500\n And so compile time is about making it efficient,\n\n17:37.500 --> 17:38.900\n which is also really hard when you're keeping\n\n17:38.900 --> 17:40.540\n track of extra information.\n\n17:40.540 --> 17:43.380\n We wanted to make new tools available,\n\n17:43.380 --> 17:46.380\n so refactoring tools and other analysis tools\n\n17:46.380 --> 17:50.540\n that GCC never supported, also leveraging the extra information\n\n17:50.540 --> 17:54.060\n we kept, but enabling those new classes of tools\n\n17:54.060 --> 17:55.940\n that then get built into IDEs.\n\n17:55.940 --> 17:59.380\n And so that's been one of the areas that clang has really\n\n17:59.380 --> 18:01.300\n helped push the world forward in,\n\n18:01.300 --> 18:05.060\n is in the tooling for C and C++ and things like that.\n\n18:05.060 --> 18:07.500\n But C++ and the front end piece is complicated.\n\n18:07.500 --> 18:09.000\n And you have to build syntax trees.\n\n18:09.000 --> 18:11.340\n And you have to check every rule in the spec.\n\n18:11.340 --> 18:14.020\n And you have to turn that back into an error message\n\n18:14.020 --> 18:16.020\n to the human that the human can understand\n\n18:16.020 --> 18:17.820\n when they do something wrong.\n\n18:17.820 --> 18:20.740\n But then you start doing what's called lowering,\n\n18:20.740 --> 18:23.060\n so going from C++ and the way that it represents\n\n18:23.060 --> 18:24.980\n code down to the machine.\n\n18:24.980 --> 18:27.380\n And when you do that, there's many different phases\n\n18:27.380 --> 18:29.660\n you go through.\n\n18:29.660 --> 18:33.020\n Often, there are, I think LLVM has something like 150\n\n18:33.020 --> 18:36.260\n different what are called passes in the compiler\n\n18:36.260 --> 18:38.780\n that the code passes through.\n\n18:38.780 --> 18:41.860\n And these get organized in very complicated ways,\n\n18:41.860 --> 18:44.360\n which affect the generated code and the performance\n\n18:44.360 --> 18:45.980\n and compile time and many other things.\n\n18:45.980 --> 18:47.300\n What are they passing through?\n\n18:47.300 --> 18:53.980\n So after you do the clang parsing, what's the graph?\n\n18:53.980 --> 18:54.900\n What does it look like?\n\n18:54.900 --> 18:56.100\n What's the data structure here?\n\n18:56.100 --> 18:59.060\n Yeah, so in the parser, it's usually a tree.\n\n18:59.060 --> 19:01.100\n And it's called an abstract syntax tree.\n\n19:01.100 --> 19:04.580\n And so the idea is you have a node for the plus\n\n19:04.580 --> 19:06.820\n that the human wrote in their code.\n\n19:06.820 --> 19:09.020\n Or the function call, you'll have a node for call\n\n19:09.020 --> 19:11.900\n with the function that they call and the arguments they pass,\n\n19:11.900 --> 19:14.460\n things like that.\n\n19:14.460 --> 19:16.620\n This then gets lowered into what's\n\n19:16.620 --> 19:18.620\n called an intermediate representation.\n\n19:18.620 --> 19:22.100\n And intermediate representations are like LLVM has one.\n\n19:22.100 --> 19:26.940\n And there, it's what's called a control flow graph.\n\n19:26.940 --> 19:31.220\n And so you represent each operation in the program\n\n19:31.220 --> 19:34.480\n as a very simple, like this is going to add two numbers.\n\n19:34.480 --> 19:35.980\n This is going to multiply two things.\n\n19:35.980 --> 19:37.460\n Maybe we'll do a call.\n\n19:37.460 --> 19:40.260\n But then they get put in what are called blocks.\n\n19:40.260 --> 19:43.580\n And so you get blocks of these straight line operations,\n\n19:43.580 --> 19:45.340\n where instead of being nested like in a tree,\n\n19:45.340 --> 19:46.900\n it's straight line operations.\n\n19:46.900 --> 19:49.780\n And so there's a sequence and an ordering to these operations.\n\n19:49.780 --> 19:51.820\n So within the block or outside the block?\n\n19:51.820 --> 19:52.980\n That's within the block.\n\n19:52.980 --> 19:54.980\n And so it's a straight line sequence of operations\n\n19:54.980 --> 19:55.740\n within the block.\n\n19:55.740 --> 19:58.980\n And then you have branches, like conditional branches,\n\n19:58.980 --> 20:00.140\n between blocks.\n\n20:00.140 --> 20:04.860\n And so when you write a loop, for example, in a syntax tree,\n\n20:04.860 --> 20:08.060\n you would have a for node, like for a for statement\n\n20:08.060 --> 20:10.540\n in a C like language, you'd have a for node.\n\n20:10.540 --> 20:12.200\n And you have a pointer to the expression\n\n20:12.200 --> 20:14.080\n for the initializer, a pointer to the expression\n\n20:14.080 --> 20:16.040\n for the increment, a pointer to the expression\n\n20:16.040 --> 20:18.900\n for the comparison, a pointer to the body.\n\n20:18.900 --> 20:21.060\n And these are all nested underneath it.\n\n20:21.060 --> 20:22.900\n In a control flow graph, you get a block\n\n20:22.900 --> 20:26.820\n for the code that runs before the loop, so the initializer\n\n20:26.820 --> 20:27.620\n code.\n\n20:27.620 --> 20:30.340\n And you have a block for the body of the loop.\n\n20:30.340 --> 20:33.780\n And so the body of the loop code goes in there,\n\n20:33.780 --> 20:35.660\n but also the increment and other things like that.\n\n20:35.660 --> 20:37.860\n And then you have a branch that goes back to the top\n\n20:37.860 --> 20:39.900\n and a comparison and a branch that goes out.\n\n20:39.900 --> 20:43.820\n And so it's more of an assembly level kind of representation.\n\n20:43.820 --> 20:46.060\n But the nice thing about this level of representation\n\n20:46.060 --> 20:48.700\n is it's much more language independent.\n\n20:48.700 --> 20:51.900\n And so there's lots of different kinds of languages\n\n20:51.900 --> 20:54.540\n with different kinds of, you know,\n\n20:54.540 --> 20:56.840\n JavaScript has a lot of different ideas of what\n\n20:56.840 --> 20:58.180\n is false, for example.\n\n20:58.180 --> 21:00.780\n And all that can stay in the front end.\n\n21:00.780 --> 21:04.220\n But then that middle part can be shared across all those.\n\n21:04.220 --> 21:07.540\n How close is that intermediate representation\n\n21:07.540 --> 21:10.620\n to neural networks, for example?\n\n21:10.620 --> 21:13.540\n Are they, because everything you describe\n\n21:13.540 --> 21:16.100\n is a kind of echoes of a neural network graph.\n\n21:16.100 --> 21:18.940\n Are they neighbors or what?\n\n21:18.940 --> 21:20.980\n They're quite different in details,\n\n21:20.980 --> 21:22.520\n but they're very similar in idea.\n\n21:22.520 --> 21:24.320\n So one of the things that neural networks do\n\n21:24.320 --> 21:26.900\n is they learn representations for data\n\n21:26.900 --> 21:29.140\n at different levels of abstraction.\n\n21:29.140 --> 21:33.940\n And then they transform those through layers, right?\n\n21:33.940 --> 21:35.660\n So the compiler does very similar things.\n\n21:35.660 --> 21:37.320\n But one of the things the compiler does\n\n21:37.320 --> 21:40.660\n is it has relatively few different representations.\n\n21:40.660 --> 21:43.100\n Where a neural network often, as you get deeper, for example,\n\n21:43.100 --> 21:44.820\n you get many different representations\n\n21:44.820 --> 21:47.380\n in each layer or set of ops.\n\n21:47.380 --> 21:50.260\n It's transforming between these different representations.\n\n21:50.260 --> 21:53.100\n In a compiler, often you get one representation\n\n21:53.100 --> 21:55.240\n and they do many transformations to it.\n\n21:55.240 --> 21:59.540\n And these transformations are often applied iteratively.\n\n21:59.540 --> 22:02.940\n And for programmers, there's familiar types of things.\n\n22:02.940 --> 22:06.180\n For example, trying to find expressions inside of a loop\n\n22:06.180 --> 22:08.540\n and pulling them out of a loop so they execute for times.\n\n22:08.540 --> 22:10.740\n Or find redundant computation.\n\n22:10.740 --> 22:15.380\n Or find constant folding or other simplifications,\n\n22:15.380 --> 22:19.060\n turning two times x into x shift left by one.\n\n22:19.060 --> 22:21.980\n And things like this are all the examples\n\n22:21.980 --> 22:23.340\n of the things that happen.\n\n22:23.340 --> 22:26.180\n But compilers end up getting a lot of theorem proving\n\n22:26.180 --> 22:27.760\n and other kinds of algorithms that\n\n22:27.760 --> 22:30.100\n try to find higher level properties of the program that\n\n22:30.100 --> 22:32.280\n then can be used by the optimizer.\n\n22:32.280 --> 22:32.780\n Cool.\n\n22:32.780 --> 22:38.140\n So what's the biggest bang for the buck with optimization?\n\n22:38.140 --> 22:38.640\n Today?\n\n22:38.640 --> 22:39.140\n Yeah.\n\n22:39.140 --> 22:40.900\n Well, no, not even today.\n\n22:40.900 --> 22:42.900\n At the very beginning, the 80s, I don't know.\n\n22:42.900 --> 22:44.300\n Yeah, so for the 80s, a lot of it\n\n22:44.300 --> 22:46.420\n was things like register allocation.\n\n22:46.420 --> 22:50.460\n So the idea of in a modern microprocessor,\n\n22:50.460 --> 22:51.880\n what you'll end up having is you'll\n\n22:51.880 --> 22:54.340\n end up having memory, which is relatively slow.\n\n22:54.340 --> 22:57.060\n And then you have registers that are relatively fast.\n\n22:57.060 --> 23:00.340\n But registers, you don't have very many of them.\n\n23:00.340 --> 23:02.600\n And so when you're writing a bunch of code,\n\n23:02.600 --> 23:04.180\n you're just saying, compute this,\n\n23:04.180 --> 23:05.940\n put in a temporary variable, compute this, compute this,\n\n23:05.940 --> 23:07.780\n compute this, put in a temporary variable.\n\n23:07.780 --> 23:08.220\n I have a loop.\n\n23:08.220 --> 23:09.780\n I have some other stuff going on.\n\n23:09.780 --> 23:11.660\n Well, now you're running on an x86,\n\n23:11.660 --> 23:13.900\n like a desktop PC or something.\n\n23:13.900 --> 23:16.860\n Well, it only has, in some cases, some modes,\n\n23:16.860 --> 23:18.700\n eight registers.\n\n23:18.700 --> 23:21.620\n And so now the compiler has to choose what values get\n\n23:21.620 --> 23:24.820\n put in what registers at what points in the program.\n\n23:24.820 --> 23:26.580\n And this is actually a really big deal.\n\n23:26.580 --> 23:29.500\n So if you think about, you have a loop, an inner loop\n\n23:29.500 --> 23:31.620\n that executes millions of times maybe.\n\n23:31.620 --> 23:33.620\n If you're doing loads and stores inside that loop,\n\n23:33.620 --> 23:35.040\n then it's going to be really slow.\n\n23:35.040 --> 23:37.740\n But if you can somehow fit all the values inside that loop\n\n23:37.740 --> 23:40.180\n in registers, now it's really fast.\n\n23:40.180 --> 23:43.020\n And so getting that right requires a lot of work,\n\n23:43.020 --> 23:44.940\n because there's many different ways to do that.\n\n23:44.940 --> 23:46.980\n And often what the compiler ends up doing\n\n23:46.980 --> 23:48.840\n is it ends up thinking about things\n\n23:48.840 --> 23:52.020\n in a different representation than what the human wrote.\n\n23:52.020 --> 23:53.340\n You wrote into x.\n\n23:53.340 --> 23:56.820\n Well, the compiler thinks about that as four different values,\n\n23:56.820 --> 23:59.280\n each which have different lifetimes across the function\n\n23:59.280 --> 24:00.420\n that it's in.\n\n24:00.420 --> 24:03.180\n And each of those could be put in a register or memory\n\n24:03.180 --> 24:06.140\n or different memory or maybe in some parts of the code\n\n24:06.140 --> 24:08.360\n recomputed instead of stored and reloaded.\n\n24:08.360 --> 24:10.700\n And there are many of these different kinds of techniques\n\n24:10.700 --> 24:11.460\n that can be used.\n\n24:11.460 --> 24:15.780\n So it's adding almost like a time dimension to it's\n\n24:15.780 --> 24:18.300\n trying to optimize across time.\n\n24:18.300 --> 24:20.340\n So it's considering when you're programming,\n\n24:20.340 --> 24:21.860\n you're not thinking in that way.\n\n24:21.860 --> 24:23.220\n Yeah, absolutely.\n\n24:23.220 --> 24:27.100\n And so the RISC era made things.\n\n24:27.100 --> 24:32.020\n So RISC chips, R I S C. The RISC chips,\n\n24:32.020 --> 24:33.740\n as opposed to CISC chips.\n\n24:33.740 --> 24:36.700\n The RISC chips made things more complicated for the compiler,\n\n24:36.700 --> 24:40.660\n because what they ended up doing is ending up\n\n24:40.660 --> 24:42.500\n adding pipelines to the processor, where\n\n24:42.500 --> 24:45.020\n the processor can do more than one thing at a time.\n\n24:45.020 --> 24:47.740\n But this means that the order of operations matters a lot.\n\n24:47.740 --> 24:50.260\n So one of the classical compiler techniques that you use\n\n24:50.260 --> 24:51.940\n is called scheduling.\n\n24:51.940 --> 24:54.220\n And so moving the instructions around\n\n24:54.220 --> 24:57.740\n so that the processor can keep its pipelines full instead\n\n24:57.740 --> 24:59.220\n of stalling and getting blocked.\n\n24:59.220 --> 25:01.180\n And so there's a lot of things like that that\n\n25:01.180 --> 25:03.620\n are kind of bread and butter compiler techniques\n\n25:03.620 --> 25:06.220\n that have been studied a lot over the course of decades now.\n\n25:06.220 --> 25:08.540\n But the engineering side of making them real\n\n25:08.540 --> 25:10.580\n is also still quite hard.\n\n25:10.580 --> 25:12.460\n And you talk about machine learning.\n\n25:12.460 --> 25:14.420\n This is a huge opportunity for machine learning,\n\n25:14.420 --> 25:17.620\n because many of these algorithms are full of these\n\n25:17.620 --> 25:19.300\n hokey, hand rolled heuristics, which\n\n25:19.300 --> 25:21.820\n work well on specific benchmarks that don't generalize,\n\n25:21.820 --> 25:23.940\n and full of magic numbers.\n\n25:23.940 --> 25:26.620\n And I hear there's some techniques that\n\n25:26.620 --> 25:28.060\n are good at handling that.\n\n25:28.060 --> 25:32.220\n So what would be the, if you were to apply machine learning\n\n25:32.220 --> 25:34.740\n to this, what's the thing you're trying to optimize?\n\n25:34.740 --> 25:39.100\n Is it ultimately the running time?\n\n25:39.100 --> 25:41.180\n You can pick your metric, and there's running time,\n\n25:41.180 --> 25:43.900\n there's memory use, there's lots of different things\n\n25:43.900 --> 25:44.940\n that you can optimize for.\n\n25:44.940 --> 25:47.220\n Code size is another one that some people care about\n\n25:47.220 --> 25:48.860\n in the embedded space.\n\n25:48.860 --> 25:51.700\n Is this like the thinking into the future,\n\n25:51.700 --> 25:54.500\n or has somebody actually been crazy enough\n\n25:54.500 --> 25:58.060\n to try to have machine learning based parameter\n\n25:58.060 --> 26:01.060\n tuning for the optimization of compilers?\n\n26:01.060 --> 26:04.860\n So this is something that is, I would say, research right now.\n\n26:04.860 --> 26:06.820\n There are a lot of research systems\n\n26:06.820 --> 26:09.100\n that have been applying search in various forms.\n\n26:09.100 --> 26:11.460\n And using reinforcement learning is one form,\n\n26:11.460 --> 26:14.460\n but also brute force search has been tried for quite a while.\n\n26:14.460 --> 26:18.180\n And usually, these are in small problem spaces.\n\n26:18.180 --> 26:21.900\n So find the optimal way to code generate a matrix\n\n26:21.900 --> 26:24.460\n multiply for a GPU, something like that,\n\n26:24.460 --> 26:28.580\n where you say, there, there's a lot of design space of,\n\n26:28.580 --> 26:29.900\n do you unroll loops a lot?\n\n26:29.900 --> 26:32.660\n Do you execute multiple things in parallel?\n\n26:32.660 --> 26:35.340\n And there's many different confounding factors here\n\n26:35.340 --> 26:38.100\n because graphics cards have different numbers of threads\n\n26:38.100 --> 26:41.020\n and registers and execution ports and memory bandwidth\n\n26:41.020 --> 26:42.740\n and many different constraints that interact\n\n26:42.740 --> 26:44.460\n in nonlinear ways.\n\n26:44.460 --> 26:46.500\n And so search is very powerful for that.\n\n26:46.500 --> 26:49.820\n And it gets used in certain ways,\n\n26:49.820 --> 26:51.220\n but it's not very structured.\n\n26:51.220 --> 26:52.620\n This is something that we need,\n\n26:52.620 --> 26:54.500\n we as an industry need to fix.\n\n26:54.500 --> 26:59.220\n So you said 80s, but like, so have there been like big jumps\n\n26:59.220 --> 27:01.260\n in improvement and optimization?\n\n27:01.260 --> 27:02.340\n Yeah.\n\n27:02.340 --> 27:05.300\n Yeah, since then, what's the coolest thing?\n\n27:05.300 --> 27:07.100\n It's largely been driven by hardware.\n\n27:07.100 --> 27:09.860\n So, well, it's hardware and software.\n\n27:09.860 --> 27:13.700\n So in the mid nineties, Java totally changed the world,\n\n27:13.700 --> 27:14.540\n right?\n\n27:14.540 --> 27:17.540\n And I'm still amazed by how much change was introduced\n\n27:17.540 --> 27:19.340\n by the way or in a good way.\n\n27:19.340 --> 27:22.420\n So like reflecting back, Java introduced things like,\n\n27:22.420 --> 27:25.860\n all at once introduced things like JIT compilation.\n\n27:25.860 --> 27:27.780\n None of these were novel, but it pulled it together\n\n27:27.780 --> 27:30.580\n and made it mainstream and made people invest in it.\n\n27:30.580 --> 27:33.620\n JIT compilation, garbage collection, portable code,\n\n27:33.620 --> 27:36.620\n safe code, like memory safe code,\n\n27:36.620 --> 27:41.380\n like a very dynamic dispatch execution model.\n\n27:41.380 --> 27:42.620\n Like many of these things,\n\n27:42.620 --> 27:44.060\n which had been done in research systems\n\n27:44.060 --> 27:46.900\n and had been done in small ways in various places,\n\n27:46.900 --> 27:47.980\n really came to the forefront,\n\n27:47.980 --> 27:49.740\n really changed how things worked\n\n27:49.740 --> 27:51.980\n and therefore changed the way people thought\n\n27:51.980 --> 27:53.060\n about the problem.\n\n27:53.060 --> 27:56.300\n JavaScript was another major world change\n\n27:56.300 --> 27:57.740\n based on the way it works.\n\n27:59.300 --> 28:01.300\n But also on the hardware side of things,\n\n28:01.300 --> 28:06.300\n multi core and vector instructions really change\n\n28:06.660 --> 28:08.380\n the problem space and are very,\n\n28:09.460 --> 28:10.820\n they don't remove any of the problems\n\n28:10.820 --> 28:12.380\n that compilers faced in the past,\n\n28:12.380 --> 28:14.540\n but they add new kinds of problems\n\n28:14.540 --> 28:16.380\n of how do you find enough work\n\n28:16.380 --> 28:20.020\n to keep a four wide vector busy, right?\n\n28:20.020 --> 28:22.660\n Or if you're doing a matrix multiplication,\n\n28:22.660 --> 28:25.860\n how do you do different columns out of that matrix\n\n28:25.860 --> 28:26.700\n at the same time?\n\n28:26.700 --> 28:30.140\n And how do you maximally utilize the arithmetic compute\n\n28:30.140 --> 28:31.460\n that one core has?\n\n28:31.460 --> 28:33.500\n And then how do you take it to multiple cores?\n\n28:33.500 --> 28:35.780\n How did the whole virtual machine thing change\n\n28:35.780 --> 28:38.020\n the compilation pipeline?\n\n28:38.020 --> 28:40.460\n Yeah, so what the Java virtual machine does\n\n28:40.460 --> 28:44.180\n is it splits, just like I was talking about before,\n\n28:44.180 --> 28:46.300\n where you have a front end that parses the code,\n\n28:46.300 --> 28:48.020\n and then you have an intermediate representation\n\n28:48.020 --> 28:49.460\n that gets transformed.\n\n28:49.460 --> 28:51.020\n What Java did was they said,\n\n28:51.020 --> 28:53.100\n we will parse the code and then compile to\n\n28:53.100 --> 28:55.500\n what's known as Java byte code.\n\n28:55.500 --> 28:58.580\n And that byte code is now a portable code representation\n\n28:58.580 --> 29:02.420\n that is industry standard and locked down and can't change.\n\n29:02.420 --> 29:05.100\n And then the back part of the compiler\n\n29:05.100 --> 29:07.300\n that does optimization and code generation\n\n29:07.300 --> 29:09.460\n can now be built by different vendors.\n\n29:09.460 --> 29:10.300\n Okay.\n\n29:10.300 --> 29:13.020\n And Java byte code can be shipped around across the wire.\n\n29:13.020 --> 29:15.860\n It's memory safe and relatively trusted.\n\n29:16.860 --> 29:18.660\n And because of that, it can run in the browser.\n\n29:18.660 --> 29:20.540\n And that's why it runs in the browser, right?\n\n29:20.540 --> 29:22.980\n And so that way you can be in,\n\n29:22.980 --> 29:25.020\n again, back in the day, you would write a Java applet\n\n29:25.020 --> 29:29.300\n and as a web developer, you'd build this mini app\n\n29:29.300 --> 29:30.860\n that would run on a webpage.\n\n29:30.860 --> 29:33.620\n Well, a user of that is running a web browser\n\n29:33.620 --> 29:34.460\n on their computer.\n\n29:34.460 --> 29:37.860\n You download that Java byte code, which can be trusted,\n\n29:37.860 --> 29:41.060\n and then you do all the compiler stuff on your machine\n\n29:41.060 --> 29:42.460\n so that you know that you trust that.\n\n29:42.460 --> 29:44.060\n Now, is that a good idea or a bad idea?\n\n29:44.060 --> 29:44.900\n It's a great idea.\n\n29:44.900 --> 29:46.240\n I mean, it's a great idea for certain problems.\n\n29:46.240 --> 29:49.540\n And I'm very much a believer that technology is itself\n\n29:49.540 --> 29:50.520\n neither good nor bad.\n\n29:50.520 --> 29:51.620\n It's how you apply it.\n\n29:52.940 --> 29:54.660\n You know, this would be a very, very bad thing\n\n29:54.660 --> 29:56.980\n for very low levels of the software stack.\n\n29:56.980 --> 30:00.300\n But in terms of solving some of these software portability\n\n30:00.300 --> 30:02.820\n and transparency, or portability problems,\n\n30:02.820 --> 30:04.240\n I think it's been really good.\n\n30:04.240 --> 30:06.600\n Now, Java ultimately didn't win out on the desktop.\n\n30:06.600 --> 30:09.420\n And like, there are good reasons for that.\n\n30:09.420 --> 30:13.220\n But it's been very successful on servers and in many places,\n\n30:13.220 --> 30:16.300\n it's been a very successful thing over decades.\n\n30:16.300 --> 30:21.300\n So what has been LLVMs and C langs improvements\n\n30:21.300 --> 30:26.300\n and optimization that throughout its history,\n\n30:28.640 --> 30:31.080\n what are some moments we had set back\n\n30:31.080 --> 30:33.280\n and really proud of what's been accomplished?\n\n30:33.280 --> 30:36.160\n Yeah, I think that the interesting thing about LLVM\n\n30:36.160 --> 30:40.120\n is not the innovations and compiler research.\n\n30:40.120 --> 30:41.900\n It has very good implementations\n\n30:41.900 --> 30:44.000\n of various important algorithms, no doubt.\n\n30:44.880 --> 30:48.280\n And a lot of really smart people have worked on it.\n\n30:48.280 --> 30:50.560\n But I think that the thing that's most profound about LLVM\n\n30:50.560 --> 30:53.840\n is that through standardization, it made things possible\n\n30:53.840 --> 30:56.200\n that otherwise wouldn't have happened, okay?\n\n30:56.200 --> 30:59.120\n And so interesting things that have happened with LLVM,\n\n30:59.120 --> 31:01.260\n for example, Sony has picked up LLVM\n\n31:01.260 --> 31:03.920\n and used it to do all the graphics compilation\n\n31:03.920 --> 31:06.080\n in their movie production pipeline.\n\n31:06.080 --> 31:07.920\n And so now they're able to have better special effects\n\n31:07.920 --> 31:09.660\n because of LLVM.\n\n31:09.660 --> 31:11.180\n That's kind of cool.\n\n31:11.180 --> 31:13.000\n That's not what it was designed for, right?\n\n31:13.000 --> 31:15.480\n But that's the sign of good infrastructure\n\n31:15.480 --> 31:18.800\n when it can be used in ways it was never designed for\n\n31:18.800 --> 31:20.960\n because it has good layering and software engineering\n\n31:20.960 --> 31:23.440\n and it's composable and things like that.\n\n31:23.440 --> 31:26.120\n Which is where, as you said, it differs from GCC.\n\n31:26.120 --> 31:28.240\n Yes, GCC is also great in various ways,\n\n31:28.240 --> 31:31.800\n but it's not as good as infrastructure technology.\n\n31:31.800 --> 31:36.160\n It's really a C compiler, or it's a Fortran compiler.\n\n31:36.160 --> 31:38.920\n It's not infrastructure in the same way.\n\n31:38.920 --> 31:41.560\n Now you can tell I don't know what I'm talking about\n\n31:41.560 --> 31:44.500\n because I keep saying C lang.\n\n31:44.500 --> 31:48.080\n You can always tell when a person has clues,\n\n31:48.080 --> 31:49.400\n by the way, to pronounce something.\n\n31:49.400 --> 31:52.580\n I don't think, have I ever used C lang?\n\n31:52.580 --> 31:54.120\n Entirely possible, have you?\n\n31:54.120 --> 31:58.200\n Well, so you've used code, it's generated probably.\n\n31:58.200 --> 32:01.760\n So C lang and LLVM are used to compile\n\n32:01.760 --> 32:05.240\n all the apps on the iPhone effectively and the OSs.\n\n32:05.240 --> 32:09.380\n It compiles Google's production server applications.\n\n32:10.560 --> 32:14.840\n It's used to build GameCube games and PlayStation 4\n\n32:14.840 --> 32:16.680\n and things like that.\n\n32:16.680 --> 32:20.120\n So as a user, I have, but just everything I've done\n\n32:20.120 --> 32:22.120\n that I experienced with Linux has been,\n\n32:22.120 --> 32:23.560\n I believe, always GCC.\n\n32:23.560 --> 32:26.520\n Yeah, I think Linux still defaults to GCC.\n\n32:26.520 --> 32:27.800\n And is there a reason for that?\n\n32:27.800 --> 32:29.440\n Or is it because, I mean, is there a reason for that?\n\n32:29.440 --> 32:32.040\n It's a combination of technical and social reasons.\n\n32:32.040 --> 32:35.960\n Many Linux developers do use C lang,\n\n32:35.960 --> 32:39.720\n but the distributions, for lots of reasons,\n\n32:40.560 --> 32:44.240\n use GCC historically, and they've not switched, yeah.\n\n32:44.240 --> 32:46.640\n Because it's just anecdotally online,\n\n32:46.640 --> 32:50.640\n it seems that LLVM has either reached the level of GCC\n\n32:50.640 --> 32:53.520\n or superseded on different features or whatever.\n\n32:53.520 --> 32:55.200\n The way I would say it is that they're so close,\n\n32:55.200 --> 32:56.040\n it doesn't matter.\n\n32:56.040 --> 32:56.860\n Yeah, exactly.\n\n32:56.860 --> 32:58.160\n Like, they're slightly better in some ways,\n\n32:58.160 --> 32:59.160\n slightly worse than otherwise,\n\n32:59.160 --> 33:03.280\n but it doesn't actually really matter anymore, that level.\n\n33:03.280 --> 33:06.280\n So in terms of optimization breakthroughs,\n\n33:06.280 --> 33:09.160\n it's just been solid incremental work.\n\n33:09.160 --> 33:12.520\n Yeah, yeah, which describes a lot of compilers.\n\n33:12.520 --> 33:15.000\n The hard thing about compilers, in my experience,\n\n33:15.000 --> 33:17.440\n is the engineering, the software engineering,\n\n33:17.440 --> 33:20.160\n making it so that you can have hundreds of people\n\n33:20.160 --> 33:23.600\n collaborating on really detailed, low level work\n\n33:23.600 --> 33:25.400\n and scaling that.\n\n33:25.400 --> 33:27.880\n And that's really hard.\n\n33:27.880 --> 33:30.680\n And that's one of the things I think LLVM has done well.\n\n33:32.160 --> 33:34.200\n And that kind of goes back to the original design goals\n\n33:34.200 --> 33:37.200\n with it to be modular and things like that.\n\n33:37.200 --> 33:38.880\n And incidentally, I don't want to take all the credit\n\n33:38.880 --> 33:39.720\n for this, right?\n\n33:39.720 --> 33:41.760\n I mean, some of the best parts about LLVM\n\n33:41.760 --> 33:43.600\n is that it was designed to be modular.\n\n33:43.600 --> 33:45.600\n And when I started, I would write, for example,\n\n33:45.600 --> 33:48.500\n a register allocator, and then somebody much smarter than me\n\n33:48.500 --> 33:50.720\n would come in and pull it out and replace it\n\n33:50.720 --> 33:52.680\n with something else that they would come up with.\n\n33:52.680 --> 33:55.200\n And because it's modular, they were able to do that.\n\n33:55.200 --> 33:58.280\n And that's one of the challenges with GCC, for example,\n\n33:58.280 --> 34:01.280\n is replacing subsystems is incredibly difficult.\n\n34:01.280 --> 34:04.680\n It can be done, but it wasn't designed for that.\n\n34:04.680 --> 34:06.080\n And that's one of the reasons that LLVM's been\n\n34:06.080 --> 34:08.760\n very successful in the research world as well.\n\n34:08.760 --> 34:12.960\n But in a community sense, Guido van Rossum, right,\n\n34:12.960 --> 34:17.960\n from Python, just retired from, what is it?\n\n34:18.480 --> 34:20.500\n Benevolent Dictator for Life, right?\n\n34:20.500 --> 34:24.720\n So in managing this community of brilliant compiler folks,\n\n34:24.720 --> 34:28.660\n is there, did it, for a time at least,\n\n34:28.660 --> 34:31.480\n fall on you to approve things?\n\n34:31.480 --> 34:34.240\n Oh yeah, so I mean, I still have something like\n\n34:34.240 --> 34:37.980\n an order of magnitude more patches in LLVM\n\n34:37.980 --> 34:42.760\n than anybody else, and many of those I wrote myself.\n\n34:42.760 --> 34:47.760\n But you still write, I mean, you're still close to the,\n\n34:47.880 --> 34:49.480\n to the, I don't know what the expression is,\n\n34:49.480 --> 34:51.000\n to the metal, you still write code.\n\n34:51.000 --> 34:52.220\n Yeah, I still write code.\n\n34:52.220 --> 34:54.240\n Not as much as I was able to in grad school,\n\n34:54.240 --> 34:56.760\n but that's an important part of my identity.\n\n34:56.760 --> 34:58.880\n But the way that LLVM has worked over time\n\n34:58.880 --> 35:01.360\n is that when I was a grad student, I could do all the work\n\n35:01.360 --> 35:04.120\n and steer everything and review every patch\n\n35:04.120 --> 35:05.800\n and make sure everything was done\n\n35:05.800 --> 35:09.040\n exactly the way my opinionated sense\n\n35:09.040 --> 35:11.760\n felt like it should be done, and that was fine.\n\n35:11.760 --> 35:14.300\n But as things scale, you can't do that, right?\n\n35:14.300 --> 35:17.100\n And so what ends up happening is LLVM\n\n35:17.100 --> 35:20.520\n has a hierarchical system of what's called code owners.\n\n35:20.520 --> 35:22.880\n These code owners are given the responsibility\n\n35:22.880 --> 35:24.880\n not to do all the work,\n\n35:24.880 --> 35:26.640\n not necessarily to review all the patches,\n\n35:26.640 --> 35:28.800\n but to make sure that the patches do get reviewed\n\n35:28.800 --> 35:30.320\n and make sure that the right thing's happening\n\n35:30.320 --> 35:32.160\n architecturally in their area.\n\n35:32.160 --> 35:36.720\n And so what you'll see is you'll see that, for example,\n\n35:36.720 --> 35:38.560\n hardware manufacturers end up owning\n\n35:38.560 --> 35:43.560\n the hardware specific parts of their hardware.\n\n35:43.600 --> 35:44.520\n That's very common.\n\n35:45.520 --> 35:47.720\n Leaders in the community that have done really good work\n\n35:47.720 --> 35:50.880\n naturally become the de facto owner of something.\n\n35:50.880 --> 35:53.400\n And then usually somebody else is like,\n\n35:53.400 --> 35:55.520\n how about we make them the official code owner?\n\n35:55.520 --> 35:58.600\n And then we'll have somebody to make sure\n\n35:58.600 --> 36:00.320\n that all the patches get reviewed in a timely manner.\n\n36:00.320 --> 36:02.080\n And then everybody's like, yes, that's obvious.\n\n36:02.080 --> 36:03.240\n And then it happens, right?\n\n36:03.240 --> 36:06.080\n And usually this is a very organic thing, which is great.\n\n36:06.080 --> 36:08.740\n And so I'm nominally the top of that stack still,\n\n36:08.740 --> 36:11.560\n but I don't spend a lot of time reviewing patches.\n\n36:11.560 --> 36:16.520\n What I do is I help negotiate a lot of the technical\n\n36:16.520 --> 36:18.040\n disagreements that end up happening\n\n36:18.040 --> 36:19.660\n and making sure that the community as a whole\n\n36:19.660 --> 36:22.040\n makes progress and is moving in the right direction\n\n36:22.040 --> 36:23.920\n and doing that.\n\n36:23.920 --> 36:28.240\n So we also started a nonprofit six years ago,\n\n36:28.240 --> 36:30.840\n seven years ago, time's gone away.\n\n36:30.840 --> 36:34.600\n And the LLVM Foundation nonprofit helps oversee\n\n36:34.600 --> 36:36.440\n all the business sides of things and make sure\n\n36:36.440 --> 36:38.800\n that the events that the LLVM community has\n\n36:38.800 --> 36:41.600\n are funded and set up and run correctly\n\n36:41.600 --> 36:42.800\n and stuff like that.\n\n36:42.800 --> 36:45.160\n But the foundation is very much stays out\n\n36:45.160 --> 36:49.060\n of the technical side of where the project is going.\n\n36:49.060 --> 36:52.160\n Right, so it sounds like a lot of it is just organic.\n\n36:53.160 --> 36:55.680\n Yeah, well, LLVM is almost 20 years old,\n\n36:55.680 --> 36:56.600\n which is hard to believe.\n\n36:56.600 --> 36:59.720\n Somebody pointed out to me recently that LLVM\n\n36:59.720 --> 37:04.600\n is now older than GCC was when LLVM started, right?\n\n37:04.600 --> 37:06.860\n So time has a way of getting away from you.\n\n37:06.860 --> 37:10.400\n But the good thing about that is it has a really robust,\n\n37:10.400 --> 37:13.520\n really amazing community of people that are\n\n37:13.520 --> 37:15.460\n in their professional lives, spread across lots\n\n37:15.460 --> 37:17.720\n of different companies, but it's a community\n\n37:17.720 --> 37:21.120\n of people that are interested in similar kinds of problems\n\n37:21.120 --> 37:23.680\n and have been working together effectively for years\n\n37:23.680 --> 37:26.460\n and have a lot of trust and respect for each other.\n\n37:26.460 --> 37:29.240\n And even if they don't always agree that we're able\n\n37:29.240 --> 37:31.200\n to find a path forward.\n\n37:31.200 --> 37:34.480\n So then in a slightly different flavor of effort,\n\n37:34.480 --> 37:38.120\n you started at Apple in 2005 with the task\n\n37:38.120 --> 37:41.800\n of making, I guess, LLVM production ready.\n\n37:41.800 --> 37:44.640\n And then eventually 2013 through 2017,\n\n37:44.640 --> 37:48.360\n leading the entire developer tools department.\n\n37:48.360 --> 37:52.960\n We're talking about LLVM, Xcode, Objective C to Swift.\n\n37:53.920 --> 37:58.580\n So in a quick overview of your time there,\n\n37:58.580 --> 37:59.600\n what were the challenges?\n\n37:59.600 --> 38:03.240\n First of all, leading such a huge group of developers,\n\n38:03.240 --> 38:06.540\n what was the big motivator, dream, mission\n\n38:06.540 --> 38:11.400\n behind creating Swift, the early birth of it\n\n38:11.400 --> 38:13.400\n from Objective C and so on, and Xcode,\n\n38:13.400 --> 38:14.240\n what are some challenges?\n\n38:14.240 --> 38:15.900\n So these are different questions.\n\n38:15.900 --> 38:19.720\n Yeah, I know, but I wanna talk about the other stuff too.\n\n38:19.720 --> 38:21.240\n I'll stay on the technical side,\n\n38:21.240 --> 38:24.480\n then we can talk about the big team pieces, if that's okay.\n\n38:24.480 --> 38:29.060\n So it's to really oversimplify many years of hard work.\n\n38:29.060 --> 38:32.440\n LLVM started, joined Apple, became a thing,\n\n38:32.440 --> 38:34.600\n became successful and became deployed.\n\n38:34.600 --> 38:35.960\n But then there's a question about\n\n38:35.960 --> 38:38.880\n how do we actually parse the source code?\n\n38:38.880 --> 38:40.320\n So LLVM is that back part,\n\n38:40.320 --> 38:42.320\n the optimizer and the code generator.\n\n38:42.320 --> 38:44.060\n And LLVM was really good for Apple\n\n38:44.060 --> 38:46.060\n as it went through a couple of harder transitions.\n\n38:46.060 --> 38:47.960\n I joined right at the time of the Intel transition,\n\n38:47.960 --> 38:51.820\n for example, and 64 bit transitions,\n\n38:51.820 --> 38:53.500\n and then the transition to ARM with the iPhone.\n\n38:53.500 --> 38:54.720\n And so LLVM was very useful\n\n38:54.720 --> 38:57.000\n for some of these kinds of things.\n\n38:57.000 --> 38:58.480\n But at the same time, there's a lot of questions\n\n38:58.480 --> 39:00.120\n around developer experience.\n\n39:00.120 --> 39:01.960\n And so if you're a programmer pounding out\n\n39:01.960 --> 39:03.460\n at the time Objective C code,\n\n39:04.480 --> 39:06.520\n the error message you get, the compile time,\n\n39:06.520 --> 39:09.760\n the turnaround cycle, the tooling and the IDE,\n\n39:09.760 --> 39:13.000\n were not great, were not as good as they could be.\n\n39:13.000 --> 39:18.000\n And so, as I occasionally do, I'm like,\n\n39:18.080 --> 39:20.720\n well, okay, how hard is it to write a C compiler?\n\n39:20.720 --> 39:22.560\n And so I'm not gonna commit to anybody,\n\n39:22.560 --> 39:25.320\n I'm not gonna tell anybody, I'm just gonna just do it\n\n39:25.320 --> 39:27.480\n nights and weekends and start working on it.\n\n39:27.480 --> 39:29.740\n And then I built up in C,\n\n39:29.740 --> 39:31.160\n there's this thing called the preprocessor,\n\n39:31.160 --> 39:33.040\n which people don't like,\n\n39:33.040 --> 39:35.480\n but it's actually really hard and complicated\n\n39:35.480 --> 39:37.700\n and includes a bunch of really weird things\n\n39:37.700 --> 39:39.280\n like trigraphs and other stuff like that\n\n39:39.280 --> 39:40.960\n that are really nasty,\n\n39:40.960 --> 39:44.080\n and it's the crux of a bunch of the performance issues\n\n39:44.080 --> 39:45.640\n in the compiler.\n\n39:45.640 --> 39:46.640\n Started working on the parser\n\n39:46.640 --> 39:47.800\n and kind of got to the point where I'm like,\n\n39:47.800 --> 39:49.880\n ah, you know what, we could actually do this.\n\n39:49.880 --> 39:51.460\n Everybody's saying that this is impossible to do,\n\n39:51.460 --> 39:53.960\n but it's actually just hard, it's not impossible.\n\n39:53.960 --> 39:57.560\n And eventually told my manager about it,\n\n39:57.560 --> 39:59.220\n and he's like, oh, wow, this is great,\n\n39:59.220 --> 40:00.360\n we do need to solve this problem.\n\n40:00.360 --> 40:02.560\n Oh, this is great, we can get you one other person\n\n40:02.560 --> 40:04.440\n to work with you on this, you know?\n\n40:04.440 --> 40:08.360\n And slowly a team is formed and it starts taking off.\n\n40:08.360 --> 40:12.040\n And C++, for example, huge, complicated language.\n\n40:12.040 --> 40:14.360\n People always assume that it's impossible to implement\n\n40:14.360 --> 40:16.260\n and it's very nearly impossible,\n\n40:16.260 --> 40:18.720\n but it's just really, really hard.\n\n40:18.720 --> 40:20.840\n And the way to get there is to build it\n\n40:20.840 --> 40:22.480\n one piece at a time incrementally.\n\n40:22.480 --> 40:26.440\n And that was only possible because we were lucky\n\n40:26.440 --> 40:28.160\n to hire some really exceptional engineers\n\n40:28.160 --> 40:30.380\n that knew various parts of it very well\n\n40:30.380 --> 40:32.680\n and could do great things.\n\n40:32.680 --> 40:34.440\n Swift was kind of a similar thing.\n\n40:34.440 --> 40:39.160\n So Swift came from, we were just finishing off\n\n40:39.160 --> 40:42.600\n the first version of C++ support in Clang.\n\n40:42.600 --> 40:47.260\n And C++ is a very formidable and very important language,\n\n40:47.260 --> 40:49.280\n but it's also ugly in lots of ways.\n\n40:49.280 --> 40:52.320\n And you can't influence C++ without thinking\n\n40:52.320 --> 40:54.380\n there has to be a better thing, right?\n\n40:54.380 --> 40:56.120\n And so I started working on Swift, again,\n\n40:56.120 --> 40:58.560\n with no hope or ambition that would go anywhere,\n\n40:58.560 --> 41:00.800\n just let's see what could be done,\n\n41:00.800 --> 41:02.620\n let's play around with this thing.\n\n41:02.620 --> 41:06.700\n It was me in my spare time, not telling anybody about it,\n\n41:06.700 --> 41:09.420\n kind of a thing, and it made some good progress.\n\n41:09.420 --> 41:11.260\n I'm like, actually, it would make sense to do this.\n\n41:11.260 --> 41:14.800\n At the same time, I started talking with the senior VP\n\n41:14.800 --> 41:17.720\n of software at the time, a guy named Bertrand Serlet.\n\n41:17.720 --> 41:19.280\n And Bertrand was very encouraging.\n\n41:19.280 --> 41:22.080\n He was like, well, let's have fun, let's talk about this.\n\n41:22.080 --> 41:23.440\n And he was a little bit of a language guy,\n\n41:23.440 --> 41:26.160\n and so he helped guide some of the early work\n\n41:26.160 --> 41:30.420\n and encouraged me and got things off the ground.\n\n41:30.420 --> 41:34.280\n And eventually told my manager and told other people,\n\n41:34.280 --> 41:38.800\n and it started making progress.\n\n41:38.800 --> 41:40.960\n The complicating thing with Swift\n\n41:40.960 --> 41:43.880\n was that the idea of doing a new language\n\n41:43.880 --> 41:47.840\n was not obvious to anybody, including myself.\n\n41:47.840 --> 41:50.240\n And the tone at the time was that the iPhone\n\n41:50.240 --> 41:53.440\n was successful because of Objective C.\n\n41:53.440 --> 41:54.440\n Oh, interesting.\n\n41:54.440 --> 41:57.160\n Not despite of or just because of.\n\n41:57.160 --> 42:01.160\n And you have to understand that at the time,\n\n42:01.160 --> 42:05.400\n Apple was hiring software people that loved Objective C.\n\n42:05.400 --> 42:07.960\n And it wasn't that they came despite Objective C.\n\n42:07.960 --> 42:10.240\n They loved Objective C, and that's why they got hired.\n\n42:10.240 --> 42:13.080\n And so you had a software team that the leadership,\n\n42:13.080 --> 42:15.200\n in many cases, went all the way back to Next,\n\n42:15.200 --> 42:19.400\n where Objective C really became real.\n\n42:19.400 --> 42:23.240\n And so they, quote unquote, grew up writing Objective C.\n\n42:23.240 --> 42:25.720\n And many of the individual engineers\n\n42:25.720 --> 42:28.360\n all were hired because they loved Objective C.\n\n42:28.360 --> 42:30.560\n And so this notion of, OK, let's do new language\n\n42:30.560 --> 42:34.120\n was kind of heretical in many ways.\n\n42:34.120 --> 42:36.960\n Meanwhile, my sense was that the outside community wasn't really\n\n42:36.960 --> 42:38.560\n in love with Objective C. Some people were,\n\n42:38.560 --> 42:40.360\n and some of the most outspoken people were.\n\n42:40.360 --> 42:42.620\n But other people were hitting challenges\n\n42:42.620 --> 42:44.760\n because it has very sharp corners\n\n42:44.760 --> 42:46.840\n and it's difficult to learn.\n\n42:46.840 --> 42:50.160\n And so one of the challenges of making Swift happen that\n\n42:50.160 --> 42:57.720\n was totally non technical is the social part of what do we do?\n\n42:57.720 --> 43:00.320\n If we do a new language, which at Apple, many things\n\n43:00.320 --> 43:02.240\n happen that don't ship.\n\n43:02.240 --> 43:05.560\n So if we ship it, what is the metrics of success?\n\n43:05.560 --> 43:06.400\n Why would we do this?\n\n43:06.400 --> 43:08.060\n Why wouldn't we make Objective C better?\n\n43:08.060 --> 43:10.160\n If Objective C has problems, let's file off\n\n43:10.160 --> 43:12.160\n those rough corners and edges.\n\n43:12.160 --> 43:15.640\n And one of the major things that became the reason to do this\n\n43:15.640 --> 43:18.960\n was this notion of safety, memory safety.\n\n43:18.960 --> 43:23.240\n And the way Objective C works is that a lot of the object system\n\n43:23.240 --> 43:27.560\n and everything else is built on top of pointers in C.\n\n43:27.560 --> 43:29.960\n Objective C is an extension on top of C.\n\n43:29.960 --> 43:32.680\n And so pointers are unsafe.\n\n43:32.680 --> 43:34.640\n And if you get rid of the pointers,\n\n43:34.640 --> 43:36.480\n it's not Objective C anymore.\n\n43:36.480 --> 43:39.080\n And so fundamentally, that was an issue\n\n43:39.080 --> 43:42.200\n that you could not fix safety or memory safety\n\n43:42.200 --> 43:45.640\n without fundamentally changing the language.\n\n43:45.640 --> 43:49.920\n And so once we got through that part of the mental process\n\n43:49.920 --> 43:53.200\n and the thought process, it became a design process\n\n43:53.200 --> 43:55.400\n of saying, OK, well, if we're going to do something new,\n\n43:55.400 --> 43:56.280\n what is good?\n\n43:56.280 --> 43:57.400\n How do we think about this?\n\n43:57.400 --> 43:58.200\n And what do we like?\n\n43:58.200 --> 44:00.040\n And what are we looking for?\n\n44:00.040 --> 44:02.440\n And that was a very different phase of it.\n\n44:02.440 --> 44:05.960\n So what are some design choices early on in Swift?\n\n44:05.960 --> 44:10.120\n Like we're talking about braces, are you\n\n44:10.120 --> 44:13.240\n making a typed language or not, all those kinds of things.\n\n44:13.240 --> 44:16.040\n Yeah, so some of those were obvious given the context.\n\n44:16.040 --> 44:17.800\n So a typed language, for example,\n\n44:17.800 --> 44:19.200\n Objective C is a typed language.\n\n44:19.200 --> 44:22.480\n And going with an untyped language\n\n44:22.480 --> 44:24.320\n wasn't really seriously considered.\n\n44:24.320 --> 44:26.000\n We wanted the performance, and we\n\n44:26.000 --> 44:27.680\n wanted refactoring tools and other things\n\n44:27.680 --> 44:29.600\n like that that go with typed languages.\n\n44:29.600 --> 44:31.440\n Quick, dumb question.\n\n44:31.440 --> 44:34.600\n Was it obvious, I think this would be a dumb question,\n\n44:34.600 --> 44:36.360\n but was it obvious that the language\n\n44:36.360 --> 44:40.120\n has to be a compiled language?\n\n44:40.120 --> 44:42.080\n Yes, that's not a dumb question.\n\n44:42.080 --> 44:44.520\n Earlier, I think late 90s, Apple had seriously\n\n44:44.520 --> 44:49.000\n considered moving its development experience to Java.\n\n44:49.000 --> 44:53.160\n But Swift started in 2010, which was several years\n\n44:53.160 --> 44:53.880\n after the iPhone.\n\n44:53.880 --> 44:55.380\n It was when the iPhone was definitely\n\n44:55.380 --> 44:56.640\n on an upward trajectory.\n\n44:56.640 --> 44:58.760\n And the iPhone was still extremely,\n\n44:58.760 --> 45:01.800\n and is still a bit memory constrained.\n\n45:01.800 --> 45:04.440\n And so being able to compile the code\n\n45:04.440 --> 45:08.160\n and then ship it and then having standalone code that\n\n45:08.160 --> 45:11.320\n is not JIT compiled is a very big deal\n\n45:11.320 --> 45:15.200\n and is very much part of the Apple value system.\n\n45:15.200 --> 45:17.480\n Now, JavaScript's also a thing.\n\n45:17.480 --> 45:19.360\n I mean, it's not that this is exclusive,\n\n45:19.360 --> 45:21.640\n and technologies are good depending\n\n45:21.640 --> 45:23.880\n on how they're applied.\n\n45:23.880 --> 45:26.600\n But in the design of Swift, saying,\n\n45:26.600 --> 45:28.320\n how can we make Objective C better?\n\n45:28.320 --> 45:29.760\n Objective C is statically compiled,\n\n45:29.760 --> 45:32.520\n and that was the contiguous, natural thing to do.\n\n45:32.520 --> 45:35.360\n Just skip ahead a little bit, and we'll go right back.\n\n45:35.360 --> 45:40.040\n Just as a question, as you think about today in 2019\n\n45:40.040 --> 45:42.400\n in your work at Google, TensorFlow and so on,\n\n45:42.400 --> 45:48.600\n is, again, compilations, static compilation still\n\n45:48.600 --> 45:49.460\n the right thing?\n\n45:49.460 --> 45:52.000\n Yeah, so the funny thing after working\n\n45:52.000 --> 45:55.880\n on compilers for a really long time is that,\n\n45:55.880 --> 45:59.040\n and this is one of the things that LLVM has helped with,\n\n45:59.040 --> 46:01.440\n is that I don't look at compilations\n\n46:01.440 --> 46:05.240\n being static or dynamic or interpreted or not.\n\n46:05.240 --> 46:07.680\n This is a spectrum.\n\n46:07.680 --> 46:09.140\n And one of the cool things about Swift\n\n46:09.140 --> 46:12.160\n is that Swift is not just statically compiled.\n\n46:12.160 --> 46:14.080\n It's actually dynamically compiled as well,\n\n46:14.080 --> 46:15.320\n and it can also be interpreted.\n\n46:15.320 --> 46:17.440\n Though, nobody's actually done that.\n\n46:17.440 --> 46:20.400\n And so what ends up happening when\n\n46:20.400 --> 46:24.080\n you use Swift in a workbook, for example in Colab or in Jupyter,\n\n46:24.080 --> 46:26.360\n is it's actually dynamically compiling the statements\n\n46:26.360 --> 46:28.160\n as you execute them.\n\n46:28.160 --> 46:32.840\n And so this gets back to the software engineering problems,\n\n46:32.840 --> 46:34.960\n where if you layer the stack properly,\n\n46:34.960 --> 46:37.320\n you can actually completely change\n\n46:37.320 --> 46:39.360\n how and when things get compiled because you\n\n46:39.360 --> 46:41.120\n have the right abstractions there.\n\n46:41.120 --> 46:44.800\n And so the way that a Colab workbook works with Swift\n\n46:44.800 --> 46:47.720\n is that when you start typing into it,\n\n46:47.720 --> 46:50.280\n it creates a process, a Unix process.\n\n46:50.280 --> 46:52.160\n And then each line of code you type in,\n\n46:52.160 --> 46:56.120\n it compiles it through the Swift compiler, the front end part,\n\n46:56.120 --> 46:58.360\n and then sends it through the optimizer,\n\n46:58.360 --> 47:01.120\n JIT compiles machine code, and then\n\n47:01.120 --> 47:03.800\n injects it into that process.\n\n47:03.800 --> 47:05.400\n And so as you're typing new stuff,\n\n47:05.400 --> 47:09.360\n it's like squirting in new code and overwriting and replacing\n\n47:09.360 --> 47:11.200\n and updating code in place.\n\n47:11.200 --> 47:13.680\n And the fact that it can do this is not an accident.\n\n47:13.680 --> 47:15.560\n Swift was designed for this.\n\n47:15.560 --> 47:18.120\n But it's an important part of how the language was set up\n\n47:18.120 --> 47:21.320\n and how it's layered, and this is a nonobvious piece.\n\n47:21.320 --> 47:23.160\n And one of the things with Swift that\n\n47:23.160 --> 47:25.880\n was, for me, a very strong design point\n\n47:25.880 --> 47:29.640\n is to make it so that you can learn it very quickly.\n\n47:29.640 --> 47:31.880\n And so from a language design perspective,\n\n47:31.880 --> 47:33.340\n the thing that I always come back to\n\n47:33.340 --> 47:36.440\n is this UI principle of progressive disclosure\n\n47:36.440 --> 47:37.960\n of complexity.\n\n47:37.960 --> 47:41.680\n And so in Swift, you can start by saying print, quote,\n\n47:41.680 --> 47:44.040\n hello world, quote.\n\n47:44.040 --> 47:47.160\n And there's no slash n, just like Python, one line of code,\n\n47:47.160 --> 47:51.520\n no main, no header files, no public static class void,\n\n47:51.520 --> 47:55.640\n blah, blah, blah, string like Java has, one line of code.\n\n47:55.640 --> 47:58.400\n And you can teach that, and it works great.\n\n47:58.400 --> 48:00.400\n Then you can say, well, let's introduce variables.\n\n48:00.400 --> 48:02.400\n And so you can declare a variable with var.\n\n48:02.400 --> 48:03.780\n So var x equals 4.\n\n48:03.780 --> 48:04.700\n What is a variable?\n\n48:04.700 --> 48:06.280\n You can use x, x plus 1.\n\n48:06.280 --> 48:07.600\n This is what it means.\n\n48:07.600 --> 48:09.520\n Then you can say, well, how about control flow?\n\n48:09.520 --> 48:10.860\n Well, this is what an if statement is.\n\n48:10.860 --> 48:12.280\n This is what a for statement is.\n\n48:12.280 --> 48:15.280\n This is what a while statement is.\n\n48:15.280 --> 48:17.280\n Then you can say, let's introduce functions.\n\n48:17.280 --> 48:20.020\n And many languages like Python have\n\n48:20.020 --> 48:22.820\n had this kind of notion of let's introduce small things,\n\n48:22.820 --> 48:24.400\n and then you can add complexity.\n\n48:24.400 --> 48:25.760\n Then you can introduce classes.\n\n48:25.760 --> 48:28.040\n And then you can add generics, in the case of Swift.\n\n48:28.040 --> 48:29.520\n And then you can build in modules\n\n48:29.520 --> 48:32.200\n and build out in terms of the things that you're expressing.\n\n48:32.200 --> 48:35.800\n But this is not very typical for compiled languages.\n\n48:35.800 --> 48:38.000\n And so this was a very strong design point,\n\n48:38.000 --> 48:40.960\n and one of the reasons that Swift, in general,\n\n48:40.960 --> 48:43.480\n is designed with this factoring of complexity in mind\n\n48:43.480 --> 48:46.440\n so that the language can express powerful things.\n\n48:46.440 --> 48:49.280\n You can write firmware in Swift if you want to.\n\n48:49.280 --> 48:51.900\n But it has a very high level feel,\n\n48:51.900 --> 48:55.200\n which is really this perfect blend, because often you\n\n48:55.200 --> 48:57.520\n have very advanced library writers that\n\n48:57.520 --> 49:00.520\n want to be able to use the nitty gritty details.\n\n49:00.520 --> 49:02.960\n But then other people just want to use the libraries\n\n49:02.960 --> 49:04.880\n and work at a higher abstraction level.\n\n49:04.880 --> 49:07.240\n It's kind of cool that I saw that you can just\n\n49:07.240 --> 49:09.240\n interoperability.\n\n49:09.240 --> 49:11.320\n I don't think I pronounced that word enough.\n\n49:11.320 --> 49:14.960\n But you can just drag in Python.\n\n49:14.960 --> 49:16.000\n It's just strange.\n\n49:16.000 --> 49:19.640\n You can import, like I saw this in the demo.\n\n49:19.640 --> 49:21.280\n How do you make that happen?\n\n49:21.280 --> 49:23.120\n What's up with that?\n\n49:23.120 --> 49:25.560\n Is that as easy as it looks, or is it?\n\n49:25.560 --> 49:27.000\n Yes, as easy as it looks.\n\n49:27.000 --> 49:29.600\n That's not a stage magic hack or anything like that.\n\n49:29.600 --> 49:31.400\n I don't mean from the user perspective.\n\n49:31.400 --> 49:34.120\n I mean from the implementation perspective to make it happen.\n\n49:34.120 --> 49:37.000\n So it's easy once all the pieces are in place.\n\n49:37.000 --> 49:39.280\n The way it works, so if you think about a dynamically typed\n\n49:39.280 --> 49:41.480\n language like Python, you can think about it\n\n49:41.480 --> 49:42.360\n in two different ways.\n\n49:42.360 --> 49:45.800\n You can say it has no types, which\n\n49:45.800 --> 49:47.480\n is what most people would say.\n\n49:47.480 --> 49:50.400\n Or you can say it has one type.\n\n49:50.400 --> 49:53.320\n And you can say it has one type, and it's the Python object.\n\n49:53.320 --> 49:55.000\n And the Python object gets passed around.\n\n49:55.000 --> 49:58.200\n And because there's only one type, it's implicit.\n\n49:58.200 --> 50:00.880\n And so what happens with Swift and Python talking\n\n50:00.880 --> 50:02.760\n to each other, Swift has lots of types.\n\n50:02.760 --> 50:05.840\n It has arrays, and it has strings, and all classes,\n\n50:05.840 --> 50:07.000\n and that kind of stuff.\n\n50:07.000 --> 50:11.120\n But it now has a Python object type.\n\n50:11.120 --> 50:12.720\n So there is one Python object type.\n\n50:12.720 --> 50:16.440\n And so when you say import NumPy, what you get\n\n50:16.440 --> 50:19.840\n is a Python object, which is the NumPy module.\n\n50:19.840 --> 50:21.960\n And then you say np.array.\n\n50:21.960 --> 50:24.960\n It says, OK, hey, Python object, I have no idea what you are.\n\n50:24.960 --> 50:27.280\n Give me your array member.\n\n50:27.280 --> 50:27.960\n OK, cool.\n\n50:27.960 --> 50:31.160\n And it just uses dynamic stuff, talks to the Python interpreter,\n\n50:31.160 --> 50:33.680\n and says, hey, Python, what's the.array member\n\n50:33.680 --> 50:35.720\n in that Python object?\n\n50:35.720 --> 50:37.400\n It gives you back another Python object.\n\n50:37.400 --> 50:40.040\n And now you say parentheses for the call and the arguments\n\n50:40.040 --> 50:40.920\n you're going to pass.\n\n50:40.920 --> 50:43.520\n And so then it says, hey, a Python object\n\n50:43.520 --> 50:47.840\n that is the result of np.array, call with these arguments.\n\n50:47.840 --> 50:50.320\n Again, calling into the Python interpreter to do that work.\n\n50:50.320 --> 50:53.680\n And so right now, this is all really simple.\n\n50:53.680 --> 50:55.960\n And if you dive into the code, what you'll see\n\n50:55.960 --> 50:58.440\n is that the Python module in Swift\n\n50:58.440 --> 51:01.360\n is something like 1,200 lines of code or something.\n\n51:01.360 --> 51:02.400\n It's written in pure Swift.\n\n51:02.400 --> 51:03.560\n It's super simple.\n\n51:03.560 --> 51:06.560\n And it's built on top of the C interoperability\n\n51:06.560 --> 51:09.520\n because it just talks to the Python interpreter.\n\n51:09.520 --> 51:11.080\n But making that possible required\n\n51:11.080 --> 51:13.480\n us to add two major language features to Swift\n\n51:13.480 --> 51:15.400\n to be able to express these dynamic calls\n\n51:15.400 --> 51:17.240\n and the dynamic member lookups.\n\n51:17.240 --> 51:19.480\n And so what we've done over the last year\n\n51:19.480 --> 51:23.960\n is we've proposed, implement, standardized, and contributed\n\n51:23.960 --> 51:26.160\n new language features to the Swift language\n\n51:26.160 --> 51:29.560\n in order to make it so it is really trivial.\n\n51:29.560 --> 51:31.320\n And this is one of the things about Swift\n\n51:31.320 --> 51:35.000\n that is critical to the Swift for TensorFlow work, which\n\n51:35.000 --> 51:37.200\n is that we can actually add new language features.\n\n51:37.200 --> 51:39.160\n And the bar for adding those is high,\n\n51:39.160 --> 51:42.280\n but it's what makes it possible.\n\n51:42.280 --> 51:45.240\n So you're now at Google doing incredible work\n\n51:45.240 --> 51:47.680\n on several things, including TensorFlow.\n\n51:47.680 --> 51:53.080\n So TensorFlow 2.0 or whatever leading up to 2.0 has,\n\n51:53.080 --> 51:56.840\n by default, in 2.0, has eager execution.\n\n51:56.840 --> 52:00.520\n And yet, in order to make code optimized for GPU or TPU\n\n52:00.520 --> 52:04.120\n or some of these systems, computation\n\n52:04.120 --> 52:06.000\n needs to be converted to a graph.\n\n52:06.000 --> 52:07.440\n So what's that process like?\n\n52:07.440 --> 52:08.960\n What are the challenges there?\n\n52:08.960 --> 52:11.720\n Yeah, so I am tangentially involved in this.\n\n52:11.720 --> 52:15.280\n But the way that it works with Autograph\n\n52:15.280 --> 52:21.600\n is that you mark your function with a decorator.\n\n52:21.600 --> 52:24.280\n And when Python calls it, that decorator is invoked.\n\n52:24.280 --> 52:28.240\n And then it says, before I call this function,\n\n52:28.240 --> 52:29.480\n you can transform it.\n\n52:29.480 --> 52:32.400\n And so the way Autograph works is, as far as I understand,\n\n52:32.400 --> 52:34.440\n is it actually uses the Python parser\n\n52:34.440 --> 52:37.160\n to go parse that, turn it into a syntax tree,\n\n52:37.160 --> 52:39.400\n and now apply compiler techniques to, again,\n\n52:39.400 --> 52:42.320\n transform this down into TensorFlow graphs.\n\n52:42.320 --> 52:44.920\n And so you can think of it as saying, hey,\n\n52:44.920 --> 52:45.880\n I have an if statement.\n\n52:45.880 --> 52:48.360\n I'm going to create an if node in the graph,\n\n52:48.360 --> 52:51.080\n like you say tf.cond.\n\n52:51.080 --> 52:53.040\n You have a multiply.\n\n52:53.040 --> 52:55.320\n Well, I'll turn that into a multiply node in the graph.\n\n52:55.320 --> 52:57.760\n And it becomes this tree transformation.\n\n52:57.760 --> 53:00.480\n So where does the Swift for TensorFlow\n\n53:00.480 --> 53:04.960\n come in, which is parallels?\n\n53:04.960 --> 53:06.960\n For one, Swift is an interface.\n\n53:06.960 --> 53:09.200\n Like, Python is an interface to TensorFlow.\n\n53:09.200 --> 53:11.760\n But it seems like there's a lot more going on in just\n\n53:11.760 --> 53:13.120\n a different language interface.\n\n53:13.120 --> 53:15.960\n There's optimization methodology.\n\n53:15.960 --> 53:17.920\n So the TensorFlow world has a couple\n\n53:17.920 --> 53:21.240\n of different what I'd call front end technologies.\n\n53:21.240 --> 53:25.240\n And so Swift and Python and Go and Rust and Julia\n\n53:25.240 --> 53:29.320\n and all these things share the TensorFlow graphs\n\n53:29.320 --> 53:32.760\n and all the runtime and everything that's later.\n\n53:32.760 --> 53:36.640\n And so Swift for TensorFlow is merely another front end\n\n53:36.640 --> 53:40.640\n for TensorFlow, just like any of these other systems are.\n\n53:40.640 --> 53:43.080\n There's a major difference between, I would say,\n\n53:43.080 --> 53:44.600\n three camps of technologies here.\n\n53:44.600 --> 53:46.880\n There's Python, which is a special case,\n\n53:46.880 --> 53:49.160\n because the vast majority of the community effort\n\n53:49.160 --> 53:51.120\n is going to the Python interface.\n\n53:51.120 --> 53:52.920\n And Python has its own approaches\n\n53:52.920 --> 53:54.480\n for automatic differentiation.\n\n53:54.480 --> 53:58.160\n It has its own APIs and all this kind of stuff.\n\n53:58.160 --> 54:00.320\n There's Swift, which I'll talk about in a second.\n\n54:00.320 --> 54:02.040\n And then there's kind of everything else.\n\n54:02.040 --> 54:05.400\n And so the everything else are effectively language bindings.\n\n54:05.400 --> 54:07.960\n So they call into the TensorFlow runtime,\n\n54:07.960 --> 54:10.920\n but they usually don't have automatic differentiation\n\n54:10.920 --> 54:14.560\n or they usually don't provide anything other than APIs\n\n54:14.560 --> 54:16.440\n that call the C APIs in TensorFlow.\n\n54:16.440 --> 54:18.360\n And so they're kind of wrappers for that.\n\n54:18.360 --> 54:19.840\n Swift is really kind of special.\n\n54:19.840 --> 54:22.760\n And it's a very different approach.\n\n54:22.760 --> 54:25.360\n Swift for TensorFlow, that is, is a very different approach.\n\n54:25.360 --> 54:26.880\n Because there we're saying, let's\n\n54:26.880 --> 54:28.400\n look at all the problems that need\n\n54:28.400 --> 54:34.080\n to be solved in the full stack of the TensorFlow compilation\n\n54:34.080 --> 54:35.680\n process, if you think about it that way.\n\n54:35.680 --> 54:38.200\n Because TensorFlow is fundamentally a compiler.\n\n54:38.200 --> 54:42.760\n It takes models, and then it makes them go fast on hardware.\n\n54:42.760 --> 54:43.880\n That's what a compiler does.\n\n54:43.880 --> 54:47.560\n And it has a front end, it has an optimizer,\n\n54:47.560 --> 54:49.320\n and it has many back ends.\n\n54:49.320 --> 54:51.680\n And so if you think about it the right way,\n\n54:51.680 --> 54:54.800\n or if you look at it in a particular way,\n\n54:54.800 --> 54:55.560\n it is a compiler.\n\n54:59.280 --> 55:02.120\n And so Swift is merely another front end.\n\n55:02.120 --> 55:05.560\n But it's saying, and the design principle is saying,\n\n55:05.560 --> 55:08.240\n let's look at all the problems that we face as machine\n\n55:08.240 --> 55:11.320\n learning practitioners and what is the best possible way we\n\n55:11.320 --> 55:13.840\n can do that, given the fact that we can change literally\n\n55:13.840 --> 55:15.920\n anything in this entire stack.\n\n55:15.920 --> 55:18.440\n And Python, for example, where the vast majority\n\n55:18.440 --> 55:22.600\n of the engineering and effort has gone into,\n\n55:22.600 --> 55:25.000\n is constrained by being the best possible thing you\n\n55:25.000 --> 55:27.320\n can do with a Python library.\n\n55:27.320 --> 55:29.320\n There are no Python language features\n\n55:29.320 --> 55:31.040\n that are added because of machine learning\n\n55:31.040 --> 55:32.600\n that I'm aware of.\n\n55:32.600 --> 55:34.640\n They added a matrix multiplication operator\n\n55:34.640 --> 55:38.320\n with that, but that's as close as you get.\n\n55:38.320 --> 55:41.460\n And so with Swift, it's hard, but you\n\n55:41.460 --> 55:43.800\n can add language features to the language.\n\n55:43.800 --> 55:46.040\n And there's a community process for that.\n\n55:46.040 --> 55:48.200\n And so we look at these things and say, well,\n\n55:48.200 --> 55:49.720\n what is the right division of labor\n\n55:49.720 --> 55:52.000\n between the human programmer and the compiler?\n\n55:52.000 --> 55:55.280\n And Swift has a number of things that shift that balance.\n\n55:55.280 --> 56:00.560\n So because it has a type system, for example,\n\n56:00.560 --> 56:02.680\n that makes certain things possible for analysis\n\n56:02.680 --> 56:05.560\n of the code, and the compiler can automatically\n\n56:05.560 --> 56:08.880\n build graphs for you without you thinking about them.\n\n56:08.880 --> 56:10.520\n That's a big deal for a programmer.\n\n56:10.520 --> 56:11.680\n You just get free performance.\n\n56:11.680 --> 56:14.400\n You get clustering and fusion and optimization,\n\n56:14.400 --> 56:17.040\n things like that, without you as a programmer\n\n56:17.040 --> 56:20.080\n having to manually do it because the compiler can do it for you.\n\n56:20.080 --> 56:22.240\n Automatic differentiation is another big deal.\n\n56:22.240 --> 56:25.960\n And I think one of the key contributions of the Swift\n\n56:25.960 --> 56:29.640\n TensorFlow project is that there's\n\n56:29.640 --> 56:32.120\n this entire body of work on automatic differentiation\n\n56:32.120 --> 56:34.120\n that dates back to the Fortran days.\n\n56:34.120 --> 56:36.400\n People doing a tremendous amount of numerical computing\n\n56:36.400 --> 56:39.360\n in Fortran used to write these what they call source\n\n56:39.360 --> 56:43.280\n to source translators, where you take a bunch of code,\n\n56:43.280 --> 56:46.640\n shove it into a mini compiler, and it would push out\n\n56:46.640 --> 56:48.080\n more Fortran code.\n\n56:48.080 --> 56:50.240\n But it would generate the backwards passes\n\n56:50.240 --> 56:53.000\n for your functions for you, the derivatives.\n\n56:53.000 --> 56:57.840\n And so in that work in the 70s, a tremendous number\n\n56:57.840 --> 57:01.160\n of optimizations, a tremendous number of techniques\n\n57:01.160 --> 57:02.920\n for fixing numerical instability,\n\n57:02.920 --> 57:05.080\n and other kinds of problems were developed.\n\n57:05.080 --> 57:07.600\n But they're very difficult to port into a world\n\n57:07.600 --> 57:11.280\n where, in eager execution, you get an op by op at a time.\n\n57:11.280 --> 57:13.280\n You need to be able to look at an entire function\n\n57:13.280 --> 57:15.720\n and be able to reason about what's going on.\n\n57:15.720 --> 57:18.720\n And so when you have a language integrated automatic\n\n57:18.720 --> 57:20.520\n differentiation, which is one of the things\n\n57:20.520 --> 57:22.760\n that the Swift project is focusing on,\n\n57:22.760 --> 57:24.680\n you can open all these techniques\n\n57:24.680 --> 57:28.640\n and reuse them in familiar ways.\n\n57:28.640 --> 57:30.120\n But the language integration piece\n\n57:30.120 --> 57:33.240\n has a bunch of design room in it, and it's also complicated.\n\n57:33.240 --> 57:35.680\n The other piece of the puzzle here that's kind of interesting\n\n57:35.680 --> 57:37.560\n is TPUs at Google.\n\n57:37.560 --> 57:40.200\n So we're in a new world with deep learning.\n\n57:40.200 --> 57:42.960\n It constantly is changing, and I imagine,\n\n57:42.960 --> 57:46.360\n without disclosing anything, I imagine\n\n57:46.360 --> 57:48.400\n you're still innovating on the TPU front, too.\n\n57:48.400 --> 57:49.040\n Indeed.\n\n57:49.040 --> 57:53.560\n So how much interplay is there between software and hardware\n\n57:53.560 --> 57:55.240\n in trying to figure out how to together move\n\n57:55.240 --> 57:56.680\n towards an optimized solution?\n\n57:56.680 --> 57:57.760\n There's an incredible amount.\n\n57:57.760 --> 57:59.480\n So we're on our third generation of TPUs,\n\n57:59.480 --> 58:04.640\n which are now 100 petaflops in a very large liquid cooled box,\n\n58:04.640 --> 58:07.720\n virtual box with no cover.\n\n58:07.720 --> 58:11.240\n And as you might imagine, we're not out of ideas yet.\n\n58:11.240 --> 58:14.360\n The great thing about TPUs is that they're\n\n58:14.360 --> 58:17.520\n a perfect example of hardware software co design.\n\n58:17.520 --> 58:19.800\n And so it's about saying, what hardware\n\n58:19.800 --> 58:23.240\n do we build to solve certain classes of machine learning\n\n58:23.240 --> 58:23.840\n problems?\n\n58:23.840 --> 58:26.480\n Well, the algorithms are changing.\n\n58:26.480 --> 58:30.360\n The hardware takes some cases years to produce.\n\n58:30.360 --> 58:32.760\n And so you have to make bets and decide\n\n58:32.760 --> 58:36.520\n what is going to happen and what is the best way to spend\n\n58:36.520 --> 58:39.920\n the transistors to get the maximum performance per watt\n\n58:39.920 --> 58:44.000\n or area per cost or whatever it is that you're optimizing for.\n\n58:44.000 --> 58:46.560\n And so one of the amazing things about TPUs\n\n58:46.560 --> 58:49.960\n is this numeric format called bfloat16.\n\n58:49.960 --> 58:54.120\n bfloat16 is a compressed 16 bit floating point format,\n\n58:54.120 --> 58:55.960\n but it puts the bits in different places.\n\n58:55.960 --> 58:58.960\n And in numeric terms, it has a smaller mantissa\n\n58:58.960 --> 59:00.400\n and a larger exponent.\n\n59:00.400 --> 59:02.960\n That means that it's less precise,\n\n59:02.960 --> 59:05.680\n but it can represent larger ranges of values,\n\n59:05.680 --> 59:07.280\n which in the machine learning context\n\n59:07.280 --> 59:09.960\n is really important and useful because sometimes you\n\n59:09.960 --> 59:13.920\n have very small gradients you want to accumulate\n\n59:13.920 --> 59:17.480\n and very, very small numbers that\n\n59:17.480 --> 59:20.520\n are important to move things as you're learning.\n\n59:20.520 --> 59:23.160\n But sometimes you have very large magnitude numbers as well.\n\n59:23.160 --> 59:26.880\n And bfloat16 is not as precise.\n\n59:26.880 --> 59:28.040\n The mantissa is small.\n\n59:28.040 --> 59:30.360\n But it turns out the machine learning algorithms actually\n\n59:30.360 --> 59:31.520\n want to generalize.\n\n59:31.520 --> 59:34.320\n And so there's theories that this actually\n\n59:34.320 --> 59:36.440\n increases the ability for the network\n\n59:36.440 --> 59:37.960\n to generalize across data sets.\n\n59:37.960 --> 59:41.160\n And regardless of whether it's good or bad,\n\n59:41.160 --> 59:43.680\n it's much cheaper at the hardware level to implement\n\n59:43.680 --> 59:48.080\n because the area and time of a multiplier\n\n59:48.080 --> 59:50.840\n is n squared in the number of bits in the mantissa,\n\n59:50.840 --> 59:53.320\n but it's linear with size of the exponent.\n\n59:53.320 --> 59:55.400\n And you're connected to both efforts\n\n59:55.400 --> 59:57.160\n here both on the hardware and the software side?\n\n59:57.160 --> 59:58.880\n Yeah, and so that was a breakthrough\n\n59:58.880 --> 1:00:01.440\n coming from the research side and people\n\n1:00:01.440 --> 1:00:06.000\n working on optimizing network transport of weights\n\n1:00:06.000 --> 1:00:08.240\n across the network originally and trying\n\n1:00:08.240 --> 1:00:10.160\n to find ways to compress that.\n\n1:00:10.160 --> 1:00:12.120\n But then it got burned into silicon.\n\n1:00:12.120 --> 1:00:14.560\n And it's a key part of what makes TPU performance\n\n1:00:14.560 --> 1:00:17.880\n so amazing and great.\n\n1:00:17.880 --> 1:00:20.680\n Now, TPUs have many different aspects that are important.\n\n1:00:20.680 --> 1:00:25.080\n But the co design between the low level compiler bits\n\n1:00:25.080 --> 1:00:27.360\n and the software bits and the algorithms\n\n1:00:27.360 --> 1:00:28.680\n is all super important.\n\n1:00:28.680 --> 1:00:32.880\n And it's this amazing trifecta that only Google can do.\n\n1:00:32.880 --> 1:00:34.240\n Yeah, that's super exciting.\n\n1:00:34.240 --> 1:00:39.800\n So can you tell me about MLIR project, previously\n\n1:00:39.800 --> 1:00:41.400\n the secretive one?\n\n1:00:41.400 --> 1:00:43.040\n Yeah, so MLIR is a project that we\n\n1:00:43.040 --> 1:00:47.000\n announced at a compiler conference three weeks ago\n\n1:00:47.000 --> 1:00:49.280\n or something at the Compilers for Machine Learning\n\n1:00:49.280 --> 1:00:50.920\n conference.\n\n1:00:50.920 --> 1:00:53.760\n Basically, again, if you look at TensorFlow as a compiler stack,\n\n1:00:53.760 --> 1:00:56.120\n it has a number of compiler algorithms within it.\n\n1:00:56.120 --> 1:00:57.660\n It also has a number of compilers\n\n1:00:57.660 --> 1:00:59.000\n that get embedded into it.\n\n1:00:59.000 --> 1:01:00.480\n And they're made by different vendors.\n\n1:01:00.480 --> 1:01:02.840\n For example, Google has XLA, which\n\n1:01:02.840 --> 1:01:04.680\n is a great compiler system.\n\n1:01:04.680 --> 1:01:06.480\n NVIDIA has TensorRT.\n\n1:01:06.480 --> 1:01:08.640\n Intel has NGRAPH.\n\n1:01:08.640 --> 1:01:10.840\n There's a number of these different compiler systems.\n\n1:01:10.840 --> 1:01:13.840\n And they're very hardware specific.\n\n1:01:13.840 --> 1:01:16.480\n And they're trying to solve different parts of the problems.\n\n1:01:16.480 --> 1:01:19.400\n But they're all kind of similar in a sense of they\n\n1:01:19.400 --> 1:01:20.880\n want to integrate with TensorFlow.\n\n1:01:20.880 --> 1:01:22.960\n Now, TensorFlow has an optimizer.\n\n1:01:22.960 --> 1:01:25.540\n And it has these different code generation technologies\n\n1:01:25.540 --> 1:01:26.440\n built in.\n\n1:01:26.440 --> 1:01:28.720\n The idea of MLIR is to build a common infrastructure\n\n1:01:28.720 --> 1:01:31.160\n to support all these different subsystems.\n\n1:01:31.160 --> 1:01:33.500\n And initially, it's to be able to make it\n\n1:01:33.500 --> 1:01:34.880\n so that they all plug in together\n\n1:01:34.880 --> 1:01:37.880\n and they can share a lot more code and can be reusable.\n\n1:01:37.880 --> 1:01:39.680\n But over time, we hope that the industry\n\n1:01:39.680 --> 1:01:42.480\n will start collaborating and sharing code.\n\n1:01:42.480 --> 1:01:45.320\n And instead of reinventing the same things over and over again,\n\n1:01:45.320 --> 1:01:49.280\n that we can actually foster some of that working together\n\n1:01:49.280 --> 1:01:51.560\n to solve common problem energy that\n\n1:01:51.560 --> 1:01:54.480\n has been useful in the compiler field before.\n\n1:01:54.480 --> 1:01:57.360\n Beyond that, MLIR is some people have joked\n\n1:01:57.360 --> 1:01:59.320\n that it's kind of LLVM too.\n\n1:01:59.320 --> 1:02:01.840\n It learns a lot about what LLVM has been good\n\n1:02:01.840 --> 1:02:04.360\n and what LLVM has done wrong.\n\n1:02:04.360 --> 1:02:06.880\n And it's a chance to fix that.\n\n1:02:06.880 --> 1:02:09.840\n And also, there are challenges in the LLVM ecosystem as well,\n\n1:02:09.840 --> 1:02:12.760\n where LLVM is very good at the thing it was designed to do.\n\n1:02:12.760 --> 1:02:15.560\n But 20 years later, the world has changed.\n\n1:02:15.560 --> 1:02:17.980\n And people are trying to solve higher level problems.\n\n1:02:17.980 --> 1:02:20.360\n And we need some new technology.\n\n1:02:20.360 --> 1:02:24.720\n And what's the future of open source in this context?\n\n1:02:24.720 --> 1:02:25.760\n Very soon.\n\n1:02:25.760 --> 1:02:27.480\n So it is not yet open source.\n\n1:02:27.480 --> 1:02:29.320\n But it will be hopefully in the next couple months.\n\n1:02:29.320 --> 1:02:31.040\n So you still believe in the value of open source\n\n1:02:31.040 --> 1:02:31.640\n in these kinds of contexts?\n\n1:02:31.640 --> 1:02:31.880\n Oh, yeah.\n\n1:02:31.880 --> 1:02:32.440\n Absolutely.\n\n1:02:32.440 --> 1:02:36.160\n And I think that the TensorFlow community at large\n\n1:02:36.160 --> 1:02:37.720\n fully believes in open source.\n\n1:02:37.720 --> 1:02:40.120\n So I mean, there is a difference between Apple,\n\n1:02:40.120 --> 1:02:42.480\n where you were previously, and Google now,\n\n1:02:42.480 --> 1:02:43.520\n in spirit and culture.\n\n1:02:43.520 --> 1:02:45.480\n And I would say the open source in TensorFlow\n\n1:02:45.480 --> 1:02:48.400\n was a seminal moment in the history of software,\n\n1:02:48.400 --> 1:02:51.680\n because here's this large company releasing\n\n1:02:51.680 --> 1:02:56.200\n a very large code base that's open sourcing.\n\n1:02:56.200 --> 1:02:58.520\n What are your thoughts on that?\n\n1:02:58.520 --> 1:03:00.840\n Happy or not, were you to see that kind\n\n1:03:00.840 --> 1:03:02.920\n of degree of open sourcing?\n\n1:03:02.920 --> 1:03:05.360\n So between the two, I prefer the Google approach,\n\n1:03:05.360 --> 1:03:07.800\n if that's what you're saying.\n\n1:03:07.800 --> 1:03:12.400\n The Apple approach makes sense, given the historical context\n\n1:03:12.400 --> 1:03:13.400\n that Apple came from.\n\n1:03:13.400 --> 1:03:15.760\n But that's been 35 years ago.\n\n1:03:15.760 --> 1:03:18.200\n And I think that Apple is definitely adapting.\n\n1:03:18.200 --> 1:03:20.280\n And the way I look at it is that there's\n\n1:03:20.280 --> 1:03:23.160\n different kinds of concerns in the space.\n\n1:03:23.160 --> 1:03:24.880\n It is very rational for a business\n\n1:03:24.880 --> 1:03:28.720\n to care about making money.\n\n1:03:28.720 --> 1:03:31.640\n That fundamentally is what a business is about.\n\n1:03:31.640 --> 1:03:34.880\n But I think it's also incredibly realistic to say,\n\n1:03:34.880 --> 1:03:36.360\n it's not your string library that's\n\n1:03:36.360 --> 1:03:38.080\n the thing that's going to make you money.\n\n1:03:38.080 --> 1:03:41.480\n It's going to be the amazing UI product differentiating\n\n1:03:41.480 --> 1:03:43.840\n features and other things like that that you built on top\n\n1:03:43.840 --> 1:03:45.280\n of your string library.\n\n1:03:45.280 --> 1:03:48.280\n And so keeping your string library\n\n1:03:48.280 --> 1:03:50.360\n proprietary and secret and things\n\n1:03:50.360 --> 1:03:54.760\n like that is maybe not the important thing anymore.\n\n1:03:54.760 --> 1:03:57.720\n Where before, platforms were different.\n\n1:03:57.720 --> 1:04:01.520\n And even 15 years ago, things were a little bit different.\n\n1:04:01.520 --> 1:04:02.920\n But the world is changing.\n\n1:04:02.920 --> 1:04:04.840\n So Google strikes a very good balance,\n\n1:04:04.840 --> 1:04:05.340\n I think.\n\n1:04:05.340 --> 1:04:09.040\n And I think that TensorFlow being open source really\n\n1:04:09.040 --> 1:04:12.000\n changed the entire machine learning field\n\n1:04:12.000 --> 1:04:14.080\n and caused a revolution in its own right.\n\n1:04:14.080 --> 1:04:17.560\n And so I think it's amazingly forward looking\n\n1:04:17.560 --> 1:04:20.880\n because I could have imagined, and I wasn't at Google\n\n1:04:20.880 --> 1:04:23.160\n at the time, but I could imagine a different context\n\n1:04:23.160 --> 1:04:25.520\n and different world where a company says,\n\n1:04:25.520 --> 1:04:27.640\n machine learning is critical to what we're doing.\n\n1:04:27.640 --> 1:04:29.640\n We're not going to give it to other people.\n\n1:04:29.640 --> 1:04:35.560\n And so that decision is a profoundly brilliant insight\n\n1:04:35.560 --> 1:04:37.480\n that I think has really led to the world being\n\n1:04:37.480 --> 1:04:40.120\n better and better for Google as well.\n\n1:04:40.120 --> 1:04:42.200\n And has all kinds of ripple effects.\n\n1:04:42.200 --> 1:04:45.160\n I think it is really, I mean, you\n\n1:04:45.160 --> 1:04:48.800\n can't understate Google deciding how profound that\n\n1:04:48.800 --> 1:04:49.840\n is for software.\n\n1:04:49.840 --> 1:04:50.880\n It's awesome.\n\n1:04:50.880 --> 1:04:54.900\n Well, and again, I can understand the concern\n\n1:04:54.900 --> 1:04:58.440\n about if we release our machine learning software,\n\n1:04:58.440 --> 1:05:00.000\n our competitors could go faster.\n\n1:05:00.000 --> 1:05:02.500\n But on the other hand, I think that open sourcing TensorFlow\n\n1:05:02.500 --> 1:05:03.960\n has been fantastic for Google.\n\n1:05:03.960 --> 1:05:09.120\n And I'm sure that decision was very nonobvious at the time,\n\n1:05:09.120 --> 1:05:11.480\n but I think it's worked out very well.\n\n1:05:11.480 --> 1:05:13.240\n So let's try this real quick.\n\n1:05:13.240 --> 1:05:15.640\n You were at Tesla for five months\n\n1:05:15.640 --> 1:05:17.640\n as the VP of autopilot software.\n\n1:05:17.640 --> 1:05:20.520\n You led the team during the transition from H hardware\n\n1:05:20.520 --> 1:05:22.360\n one to hardware two.\n\n1:05:22.360 --> 1:05:23.520\n I have a couple of questions.\n\n1:05:23.520 --> 1:05:26.320\n So one, first of all, to me, that's\n\n1:05:26.320 --> 1:05:33.000\n one of the bravest engineering decisions undertaking really\n\n1:05:33.000 --> 1:05:36.040\n ever in the automotive industry to me, software wise,\n\n1:05:36.040 --> 1:05:37.440\n starting from scratch.\n\n1:05:37.440 --> 1:05:39.200\n It's a really brave engineering decision.\n\n1:05:39.200 --> 1:05:42.600\n So my one question there is, what was that like?\n\n1:05:42.600 --> 1:05:43.920\n What was the challenge of that?\n\n1:05:43.920 --> 1:05:45.720\n Do you mean the career decision of jumping\n\n1:05:45.720 --> 1:05:48.800\n from a comfortable good job into the unknown, or?\n\n1:05:48.800 --> 1:05:51.480\n That combined, so at the individual level,\n\n1:05:51.480 --> 1:05:54.560\n you making that decision.\n\n1:05:54.560 --> 1:05:57.960\n And then when you show up, it's a really hard engineering\n\n1:05:57.960 --> 1:05:58.760\n problem.\n\n1:05:58.760 --> 1:06:03.560\n So you could just stay, maybe slow down,\n\n1:06:03.560 --> 1:06:06.680\n say hardware one, or those kinds of decisions.\n\n1:06:06.680 --> 1:06:10.160\n Just taking it full on, let's do this from scratch.\n\n1:06:10.160 --> 1:06:11.080\n What was that like?\n\n1:06:11.080 --> 1:06:12.640\n Well, so I mean, I don't think Tesla\n\n1:06:12.640 --> 1:06:16.080\n has a culture of taking things slow and seeing how it goes.\n\n1:06:16.080 --> 1:06:18.080\n And one of the things that attracted me about Tesla\n\n1:06:18.080 --> 1:06:20.020\n is it's very much a gung ho, let's change the world,\n\n1:06:20.020 --> 1:06:21.520\n let's figure it out kind of a place.\n\n1:06:21.520 --> 1:06:25.640\n And so I have a huge amount of respect for that.\n\n1:06:25.640 --> 1:06:28.680\n Tesla has done very smart things with hardware one\n\n1:06:28.680 --> 1:06:29.400\n in particular.\n\n1:06:29.400 --> 1:06:32.200\n And the hardware one design was originally\n\n1:06:32.200 --> 1:06:36.560\n designed to be very simple automation features\n\n1:06:36.560 --> 1:06:39.360\n in the car for like traffic aware cruise control and things\n\n1:06:39.360 --> 1:06:39.840\n like that.\n\n1:06:39.840 --> 1:06:42.920\n And the fact that they were able to effectively feature creep\n\n1:06:42.920 --> 1:06:47.720\n it into lane holding and a very useful driver assistance\n\n1:06:47.720 --> 1:06:50.120\n feature is pretty astounding, particularly given\n\n1:06:50.120 --> 1:06:52.560\n the details of the hardware.\n\n1:06:52.560 --> 1:06:54.640\n Hardware two built on that in a lot of ways.\n\n1:06:54.640 --> 1:06:56.180\n And the challenge there was that they\n\n1:06:56.180 --> 1:07:00.040\n were transitioning from a third party provided vision stack\n\n1:07:00.040 --> 1:07:01.720\n to an in house built vision stack.\n\n1:07:01.720 --> 1:07:05.680\n And so for the first step, which I mostly helped with,\n\n1:07:05.680 --> 1:07:08.480\n was getting onto that new vision stack.\n\n1:07:08.480 --> 1:07:10.800\n And that was very challenging.\n\n1:07:10.800 --> 1:07:14.000\n And it was time critical for various reasons,\n\n1:07:14.000 --> 1:07:14.960\n and it was a big leap.\n\n1:07:14.960 --> 1:07:16.640\n But it was fortunate that it built\n\n1:07:16.640 --> 1:07:18.800\n on a lot of the knowledge and expertise and the team\n\n1:07:18.800 --> 1:07:22.920\n that had built hardware one's driver assistance features.\n\n1:07:22.920 --> 1:07:25.360\n So you spoke in a collected and kind way\n\n1:07:25.360 --> 1:07:28.960\n about your time at Tesla, but it was ultimately not a good fit.\n\n1:07:28.960 --> 1:07:31.840\n Elon Musk, we've talked on this podcast,\n\n1:07:31.840 --> 1:07:33.880\n several guests to the course, Elon Musk\n\n1:07:33.880 --> 1:07:36.880\n continues to do some of the most bold and innovative engineering\n\n1:07:36.880 --> 1:07:39.560\n work in the world, at times at the cost\n\n1:07:39.560 --> 1:07:41.280\n some of the members of the Tesla team.\n\n1:07:41.280 --> 1:07:45.080\n What did you learn about working in this chaotic world\n\n1:07:45.080 --> 1:07:46.720\n with Elon?\n\n1:07:46.720 --> 1:07:50.560\n Yeah, so I guess I would say that when I was at Tesla,\n\n1:07:50.560 --> 1:07:54.440\n I experienced and saw the highest degree of turnover\n\n1:07:54.440 --> 1:07:58.240\n I'd ever seen in a company, which was a bit of a shock.\n\n1:07:58.240 --> 1:08:00.520\n But one of the things I learned and I came to respect\n\n1:08:00.520 --> 1:08:03.760\n is that Elon's able to attract amazing talent because he\n\n1:08:03.760 --> 1:08:05.660\n has a very clear vision of the future,\n\n1:08:05.660 --> 1:08:07.200\n and he can get people to buy into it\n\n1:08:07.200 --> 1:08:09.840\n because they want that future to happen.\n\n1:08:09.840 --> 1:08:11.840\n And the power of vision is something\n\n1:08:11.840 --> 1:08:14.240\n that I have a tremendous amount of respect for.\n\n1:08:14.240 --> 1:08:17.040\n And I think that Elon is fairly singular\n\n1:08:17.040 --> 1:08:20.120\n in the world in terms of the things\n\n1:08:20.120 --> 1:08:22.360\n he's able to get people to believe in.\n\n1:08:22.360 --> 1:08:27.360\n And there are many people that stand in the street corner\n\n1:08:27.360 --> 1:08:30.200\n and say, ah, we're going to go to Mars, right?\n\n1:08:30.200 --> 1:08:31.600\n But then there are a few people that\n\n1:08:31.600 --> 1:08:35.200\n can get others to buy into it and believe and build the path\n\n1:08:35.200 --> 1:08:36.160\n and make it happen.\n\n1:08:36.160 --> 1:08:39.120\n And so I respect that.\n\n1:08:39.120 --> 1:08:41.880\n I don't respect all of his methods,\n\n1:08:41.880 --> 1:08:45.000\n but I have a huge amount of respect for that.\n\n1:08:45.000 --> 1:08:46.920\n You've mentioned in a few places,\n\n1:08:46.920 --> 1:08:50.440\n including in this context, working hard.\n\n1:08:50.440 --> 1:08:52.000\n What does it mean to work hard?\n\n1:08:52.000 --> 1:08:53.520\n And when you look back at your life,\n\n1:08:53.520 --> 1:08:57.080\n what were some of the most brutal periods\n\n1:08:57.080 --> 1:09:00.760\n of having to really put everything\n\n1:09:00.760 --> 1:09:03.360\n you have into something?\n\n1:09:03.360 --> 1:09:05.040\n Yeah, good question.\n\n1:09:05.040 --> 1:09:07.440\n So working hard can be defined a lot of different ways,\n\n1:09:07.440 --> 1:09:12.480\n so a lot of hours, and so that is true.\n\n1:09:12.480 --> 1:09:14.520\n The thing to me that's the hardest\n\n1:09:14.520 --> 1:09:18.760\n is both being short term focused on delivering and executing\n\n1:09:18.760 --> 1:09:21.120\n and making a thing happen while also thinking\n\n1:09:21.120 --> 1:09:24.400\n about the longer term and trying to balance that.\n\n1:09:24.400 --> 1:09:28.520\n Because if you are myopically focused on solving a task\n\n1:09:28.520 --> 1:09:31.240\n and getting that done and only think\n\n1:09:31.240 --> 1:09:32.600\n about that incremental next step,\n\n1:09:32.600 --> 1:09:36.440\n you will miss the next big hill you should jump over to.\n\n1:09:36.440 --> 1:09:39.600\n And so I've been really fortunate that I've\n\n1:09:39.600 --> 1:09:42.120\n been able to kind of oscillate between the two.\n\n1:09:42.120 --> 1:09:45.480\n And historically at Apple, for example, that\n\n1:09:45.480 --> 1:09:47.920\n was made possible because I was able to work with some really\n\n1:09:47.920 --> 1:09:50.360\n amazing people and build up teams and leadership\n\n1:09:50.360 --> 1:09:55.280\n structures and allow them to grow in their careers\n\n1:09:55.280 --> 1:09:58.280\n and take on responsibility, thereby freeing up\n\n1:09:58.280 --> 1:10:02.960\n me to be a little bit crazy and thinking about the next thing.\n\n1:10:02.960 --> 1:10:04.640\n And so it's a lot of that.\n\n1:10:04.640 --> 1:10:06.760\n But it's also about with experience,\n\n1:10:06.760 --> 1:10:10.080\n you make connections that other people don't necessarily make.\n\n1:10:10.080 --> 1:10:12.880\n And so I think that's a big part as well.\n\n1:10:12.880 --> 1:10:16.000\n But the bedrock is just a lot of hours.\n\n1:10:16.000 --> 1:10:19.600\n And that's OK with me.\n\n1:10:19.600 --> 1:10:21.480\n There's different theories on work life balance.\n\n1:10:21.480 --> 1:10:25.200\n And my theory for myself, which I do not project onto the team,\n\n1:10:25.200 --> 1:10:28.520\n but my theory for myself is that I\n\n1:10:28.520 --> 1:10:30.400\n want to love what I'm doing and work really hard.\n\n1:10:30.400 --> 1:10:35.000\n And my purpose, I feel like, and my goal is to change the world\n\n1:10:35.000 --> 1:10:36.280\n and make it a better place.\n\n1:10:36.280 --> 1:10:40.000\n And that's what I'm really motivated to do.\n\n1:10:40.000 --> 1:10:44.760\n So last question, LLVM logo is a dragon.\n\n1:10:44.760 --> 1:10:47.880\n You explain that this is because dragons have connotations\n\n1:10:47.880 --> 1:10:50.320\n of power, speed, intelligence.\n\n1:10:50.320 --> 1:10:53.320\n It can also be sleek, elegant, and modular,\n\n1:10:53.320 --> 1:10:56.280\n though you remove the modular part.\n\n1:10:56.280 --> 1:10:58.920\n What is your favorite dragon related character\n\n1:10:58.920 --> 1:11:01.440\n from fiction, video, or movies?\n\n1:11:01.440 --> 1:11:03.840\n So those are all very kind ways of explaining it.\n\n1:11:03.840 --> 1:11:06.200\n Do you want to know the real reason it's a dragon?\n\n1:11:06.200 --> 1:11:07.000\n Yeah.\n\n1:11:07.000 --> 1:11:07.920\n Is that better?\n\n1:11:07.920 --> 1:11:11.040\n So there is a seminal book on compiler design\n\n1:11:11.040 --> 1:11:12.520\n called The Dragon Book.\n\n1:11:12.520 --> 1:11:16.320\n And so this is a really old now book on compilers.\n\n1:11:16.320 --> 1:11:22.080\n And so the dragon logo for LLVM came about because at Apple,\n\n1:11:22.080 --> 1:11:24.720\n we kept talking about LLVM related technologies\n\n1:11:24.720 --> 1:11:26.960\n and there's no logo to put on a slide.\n\n1:11:26.960 --> 1:11:28.480\n And so we're like, what do we do?\n\n1:11:28.480 --> 1:11:30.480\n And somebody's like, well, what kind of logo\n\n1:11:30.480 --> 1:11:32.160\n should a compiler technology have?\n\n1:11:32.160 --> 1:11:33.360\n And I'm like, I don't know.\n\n1:11:33.360 --> 1:11:37.320\n I mean, the dragon is the best thing that we've got.\n\n1:11:37.320 --> 1:11:41.520\n And Apple somehow magically came up with the logo.\n\n1:11:41.520 --> 1:11:42.680\n And it was a great thing.\n\n1:11:42.680 --> 1:11:44.520\n And the whole community rallied around it.\n\n1:11:44.520 --> 1:11:46.760\n And then it got better as other graphic designers\n\n1:11:46.760 --> 1:11:47.360\n got involved.\n\n1:11:47.360 --> 1:11:49.360\n But that's originally where it came from.\n\n1:11:49.360 --> 1:11:50.160\n The story.\n\n1:11:50.160 --> 1:11:51.960\n Is there dragons from fiction that you\n\n1:11:51.960 --> 1:11:57.240\n connect with, that Game of Thrones, Lord of the Rings,\n\n1:11:57.240 --> 1:11:58.080\n that kind of thing?\n\n1:11:58.080 --> 1:11:59.200\n Lord of the Rings is great.\n\n1:11:59.200 --> 1:12:00.760\n I also like role playing games and things\n\n1:12:00.760 --> 1:12:02.240\n like computer role playing games.\n\n1:12:02.240 --> 1:12:04.280\n And so dragons often show up in there.\n\n1:12:04.280 --> 1:12:07.160\n But really, it comes back to the book.\n\n1:12:07.160 --> 1:12:09.960\n Oh, no, we need a thing.\n\n1:12:09.960 --> 1:12:13.720\n And hilariously, one of the funny things about LLVM\n\n1:12:13.720 --> 1:12:19.520\n is that my wife, who's amazing, runs the LLVM Foundation.\n\n1:12:19.520 --> 1:12:21.080\n And she goes to Grace Hopper and is\n\n1:12:21.080 --> 1:12:23.360\n trying to get more women involved in the.\n\n1:12:23.360 --> 1:12:24.640\n She's also a compiler engineer.\n\n1:12:24.640 --> 1:12:26.080\n So she's trying to get other women\n\n1:12:26.080 --> 1:12:28.020\n to get interested in compilers and things like this.\n\n1:12:28.020 --> 1:12:30.000\n And so she hands out the stickers.\n\n1:12:30.000 --> 1:12:34.320\n And people like the LLVM sticker because of Game of Thrones.\n\n1:12:34.320 --> 1:12:36.880\n And so sometimes culture has this helpful effect\n\n1:12:36.880 --> 1:12:39.960\n to get the next generation of compiler engineers\n\n1:12:39.960 --> 1:12:42.400\n engaged with the cause.\n\n1:12:42.400 --> 1:12:43.320\n OK, awesome.\n\n1:12:43.320 --> 1:12:44.800\n Chris, thanks so much for talking with us.\n\n1:12:44.800 --> 1:13:05.920\n It's been great talking with you.\n\n"
}
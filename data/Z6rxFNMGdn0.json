{
  "title": "Ian Goodfellow: Generative Adversarial Networks (GANs) | Lex Fridman Podcast #19",
  "id": "Z6rxFNMGdn0",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:03.720\n The following is a conversation with Ian Goodfellow.\n\n00:03.720 --> 00:06.360\n He's the author of the popular textbook on deep learning\n\n00:06.360 --> 00:08.800\n simply titled Deep Learning.\n\n00:08.800 --> 00:12.320\n He coined the term of Generative Adversarial Networks,\n\n00:12.320 --> 00:14.560\n otherwise known as GANs,\n\n00:14.560 --> 00:18.160\n and with his 2014 paper is responsible\n\n00:18.160 --> 00:20.440\n for launching the incredible growth\n\n00:20.440 --> 00:23.140\n of research and innovation in this subfield\n\n00:23.140 --> 00:24.720\n of deep learning.\n\n00:24.720 --> 00:27.520\n He got his BS and MS at Stanford,\n\n00:27.520 --> 00:30.120\n his PhD at University of Montreal\n\n00:30.120 --> 00:33.200\n with Yoshua Bengio and Aaron Kerrville.\n\n00:33.200 --> 00:35.240\n He held several research positions\n\n00:35.240 --> 00:37.600\n including at OpenAI, Google Brain,\n\n00:37.600 --> 00:41.560\n and now at Apple as the Director of Machine Learning.\n\n00:41.560 --> 00:45.400\n This recording happened while Ian was still at Google Brain,\n\n00:45.400 --> 00:48.520\n but we don't talk about anything specific to Google\n\n00:48.520 --> 00:50.760\n or any other organization.\n\n00:50.760 --> 00:52.480\n This conversation is part\n\n00:52.480 --> 00:54.520\n of the Artificial Intelligence Podcast.\n\n00:54.520 --> 00:57.560\n If you enjoy it, subscribe on YouTube, iTunes,\n\n00:57.560 --> 01:00.880\n or simply connect with me on Twitter at Lex Friedman,\n\n01:00.880 --> 01:03.000\n spelled F R I D.\n\n01:03.000 --> 01:07.100\n And now here's my conversation with Ian Goodfellow.\n\n01:08.240 --> 01:11.000\n You open your popular deep learning book\n\n01:11.000 --> 01:13.620\n with a Russian doll type diagram\n\n01:13.620 --> 01:15.880\n that shows deep learning is a subset\n\n01:15.880 --> 01:17.140\n of representation learning,\n\n01:17.140 --> 01:19.960\n which in turn is a subset of machine learning\n\n01:19.960 --> 01:22.520\n and finally a subset of AI.\n\n01:22.520 --> 01:25.280\n So this kind of implies that there may be limits\n\n01:25.280 --> 01:27.720\n to deep learning in the context of AI.\n\n01:27.720 --> 01:31.580\n So what do you think is the current limits of deep learning\n\n01:31.580 --> 01:33.140\n and are those limits something\n\n01:33.140 --> 01:35.760\n that we can overcome with time?\n\n01:35.760 --> 01:37.740\n Yeah, I think one of the biggest limitations\n\n01:37.740 --> 01:40.120\n of deep learning is that right now it requires\n\n01:40.120 --> 01:42.920\n really a lot of data, especially labeled data.\n\n01:43.960 --> 01:45.480\n There are some unsupervised\n\n01:45.480 --> 01:47.160\n and semi supervised learning algorithms\n\n01:47.160 --> 01:49.480\n that can reduce the amount of labeled data you need,\n\n01:49.480 --> 01:52.200\n but they still require a lot of unlabeled data,\n\n01:52.200 --> 01:53.480\n reinforcement learning algorithms.\n\n01:53.480 --> 01:54.320\n They don't need labels,\n\n01:54.320 --> 01:56.280\n but they need really a lot of experiences.\n\n01:57.280 --> 01:58.920\n As human beings, we don't learn to play Pong\n\n01:58.920 --> 02:01.560\n by failing at Pong 2 million times.\n\n02:02.720 --> 02:05.880\n So just getting the generalization ability better\n\n02:05.880 --> 02:08.040\n is one of the most important bottlenecks\n\n02:08.040 --> 02:10.540\n in the capability of the technology today.\n\n02:10.540 --> 02:12.360\n And then I guess I'd also say deep learning\n\n02:12.360 --> 02:15.620\n is like a component of a bigger system.\n\n02:16.620 --> 02:19.020\n So far, nobody is really proposing to have\n\n02:19.020 --> 02:22.000\n only what you'd call deep learning\n\n02:22.000 --> 02:25.520\n as the entire ingredient of intelligence.\n\n02:25.520 --> 02:29.860\n You use deep learning as sub modules of other systems,\n\n02:29.860 --> 02:32.320\n like AlphaGo has a deep learning model\n\n02:32.320 --> 02:34.140\n that estimates the value function.\n\n02:35.200 --> 02:36.600\n Most reinforcement learning algorithms\n\n02:36.600 --> 02:37.880\n have a deep learning module\n\n02:37.880 --> 02:40.320\n that estimates which action to take next,\n\n02:40.320 --> 02:42.480\n but you might have other components.\n\n02:42.480 --> 02:46.100\n So you're basically building a function estimator.\n\n02:46.100 --> 02:48.600\n Do you think it's possible,\n\n02:48.600 --> 02:51.000\n you said nobody's kind of been thinking about this so far,\n\n02:51.000 --> 02:54.320\n but do you think neural networks could be made to reason\n\n02:54.320 --> 02:57.720\n in the way symbolic systems did in the 80s and 90s\n\n02:57.720 --> 03:00.160\n to do more, create more like programs\n\n03:00.160 --> 03:01.440\n as opposed to functions?\n\n03:01.440 --> 03:03.940\n Yeah, I think we already see that a little bit.\n\n03:04.880 --> 03:06.360\n I already kind of think of neural nets\n\n03:06.360 --> 03:08.860\n as a kind of program.\n\n03:08.860 --> 03:12.920\n I think of deep learning as basically learning programs\n\n03:12.920 --> 03:15.280\n that have more than one step.\n\n03:15.280 --> 03:16.960\n So if you draw a flow chart\n\n03:16.960 --> 03:19.540\n or if you draw a TensorFlow graph\n\n03:19.540 --> 03:21.860\n describing your machine learning model,\n\n03:21.860 --> 03:23.500\n I think of the depth of that graph\n\n03:23.500 --> 03:25.860\n as describing the number of steps that run in sequence.\n\n03:25.860 --> 03:27.640\n And then the width of that graph\n\n03:27.640 --> 03:30.120\n is the number of steps that run in parallel.\n\n03:30.120 --> 03:31.680\n Now it's been long enough\n\n03:31.680 --> 03:32.880\n that we've had deep learning working\n\n03:32.880 --> 03:33.880\n that it's a little bit silly\n\n03:33.880 --> 03:35.740\n to even discuss shallow learning anymore.\n\n03:35.740 --> 03:38.880\n But back when I first got involved in AI,\n\n03:38.880 --> 03:40.080\n when we used machine learning,\n\n03:40.080 --> 03:43.680\n we were usually learning things like support vector machines.\n\n03:43.680 --> 03:45.640\n You could have a lot of input features to the model\n\n03:45.640 --> 03:48.080\n and you could multiply each feature by a different weight.\n\n03:48.080 --> 03:49.560\n All those multiplications were done\n\n03:49.560 --> 03:51.200\n in parallel to each other.\n\n03:51.200 --> 03:52.680\n There wasn't a lot done in series.\n\n03:52.680 --> 03:54.320\n I think what we got with deep learning\n\n03:54.320 --> 03:58.360\n was really the ability to have steps of a program\n\n03:58.360 --> 04:00.280\n that run in sequence.\n\n04:00.280 --> 04:03.160\n And I think that we've actually started to see\n\n04:03.160 --> 04:05.000\n that what's important with deep learning\n\n04:05.000 --> 04:07.960\n is more the fact that we have a multi step program\n\n04:07.960 --> 04:10.760\n rather than the fact that we've learned a representation.\n\n04:10.760 --> 04:15.100\n If you look at things like resonance, for example,\n\n04:15.100 --> 04:18.640\n they take one particular kind of representation\n\n04:18.640 --> 04:21.320\n and they update it several times.\n\n04:21.320 --> 04:23.560\n Back when deep learning first really took off\n\n04:23.560 --> 04:25.760\n in the academic world in 2006,\n\n04:25.760 --> 04:28.400\n when Jeff Hinton showed that you could train\n\n04:28.400 --> 04:30.160\n deep belief networks,\n\n04:30.160 --> 04:31.960\n everybody who was interested in the idea\n\n04:31.960 --> 04:33.560\n thought of it as each layer\n\n04:33.560 --> 04:35.940\n learns a different level of abstraction.\n\n04:35.940 --> 04:37.820\n That the first layer trained on images\n\n04:37.820 --> 04:38.960\n learns something like edges\n\n04:38.960 --> 04:40.420\n and the second layer learns corners.\n\n04:40.420 --> 04:43.320\n And eventually you get these kind of grandmother cell units\n\n04:43.320 --> 04:45.920\n that recognize specific objects.\n\n04:45.920 --> 04:48.560\n Today I think most people think of it more\n\n04:48.560 --> 04:52.000\n as a computer program where as you add more layers\n\n04:52.000 --> 04:55.120\n you can do more updates before you output your final number.\n\n04:55.120 --> 04:57.160\n But I don't think anybody believes that\n\n04:57.160 --> 05:02.060\n layer 150 of the ResNet is a grandmother cell\n\n05:02.060 --> 05:05.080\n and layer 100 is contours or something like that.\n\n05:06.040 --> 05:08.160\n Okay, so you're not thinking of it\n\n05:08.160 --> 05:11.520\n as a singular representation that keeps building.\n\n05:11.520 --> 05:14.040\n You think of it as a program,\n\n05:14.040 --> 05:15.920\n sort of almost like a state.\n\n05:15.920 --> 05:18.720\n Representation is a state of understanding.\n\n05:18.720 --> 05:20.260\n Yeah, I think of it as a program\n\n05:20.260 --> 05:21.500\n that makes several updates\n\n05:21.500 --> 05:23.840\n and arrives at better and better understandings,\n\n05:23.840 --> 05:27.500\n but it's not replacing the representation at each step.\n\n05:27.500 --> 05:29.160\n It's refining it.\n\n05:29.160 --> 05:31.640\n And in some sense, that's a little bit like reasoning.\n\n05:31.640 --> 05:33.560\n It's not reasoning in the form of deduction,\n\n05:33.560 --> 05:36.960\n but it's reasoning in the form of taking a thought\n\n05:36.960 --> 05:39.440\n and refining it and refining it carefully\n\n05:39.440 --> 05:41.240\n until it's good enough to use.\n\n05:41.240 --> 05:43.560\n So do you think, and I hope you don't mind,\n\n05:43.560 --> 05:46.040\n we'll jump philosophical every once in a while.\n\n05:46.040 --> 05:50.460\n Do you think of cognition, human cognition,\n\n05:50.460 --> 05:53.520\n or even consciousness as simply a result\n\n05:53.520 --> 05:58.120\n of this kind of sequential representation learning?\n\n05:58.120 --> 06:00.440\n Do you think that can emerge?\n\n06:00.440 --> 06:02.460\n Cognition, yes, I think so.\n\n06:02.460 --> 06:05.160\n Consciousness, it's really hard to even define\n\n06:05.160 --> 06:06.420\n what we mean by that.\n\n06:07.400 --> 06:09.840\n I guess there's, consciousness is often defined\n\n06:09.840 --> 06:12.080\n as things like having self awareness,\n\n06:12.080 --> 06:16.080\n and that's relatively easy to turn into something actionable\n\n06:16.080 --> 06:18.400\n for a computer scientist to reason about.\n\n06:18.400 --> 06:19.720\n People also define consciousness\n\n06:19.720 --> 06:22.440\n in terms of having qualitative states of experience,\n\n06:22.440 --> 06:25.300\n like qualia, and there's all these philosophical problems,\n\n06:25.300 --> 06:27.880\n like could you imagine a zombie\n\n06:27.880 --> 06:30.740\n who does all the same information processing as a human,\n\n06:30.740 --> 06:33.500\n but doesn't really have the qualitative experiences\n\n06:33.500 --> 06:34.720\n that we have?\n\n06:34.720 --> 06:37.600\n That sort of thing, I have no idea how to formalize\n\n06:37.600 --> 06:40.000\n or turn it into a scientific question.\n\n06:40.000 --> 06:41.620\n I don't know how you could run an experiment\n\n06:41.620 --> 06:44.880\n to tell whether a person is a zombie or not.\n\n06:44.880 --> 06:46.680\n And similarly, I don't know how you could run\n\n06:46.680 --> 06:49.680\n an experiment to tell whether an advanced AI system\n\n06:49.680 --> 06:53.060\n had become conscious in the sense of qualia or not.\n\n06:53.060 --> 06:54.600\n But in the more practical sense,\n\n06:54.600 --> 06:56.320\n like almost like self attention,\n\n06:56.320 --> 06:58.920\n you think consciousness and cognition can,\n\n06:58.920 --> 07:03.240\n in an impressive way, emerge from current types\n\n07:03.240 --> 07:06.200\n of architectures that we think of as learning.\n\n07:06.200 --> 07:07.920\n Or if you think of consciousness\n\n07:07.920 --> 07:12.160\n in terms of self awareness and just making plans\n\n07:12.160 --> 07:16.600\n based on the fact that the agent itself exists in the world,\n\n07:16.600 --> 07:18.000\n reinforcement learning algorithms\n\n07:18.000 --> 07:20.140\n are already more or less forced\n\n07:20.140 --> 07:23.040\n to model the agent's effect on the environment.\n\n07:23.040 --> 07:26.340\n So that more limited version of consciousness\n\n07:26.340 --> 07:31.340\n is already something that we get limited versions of\n\n07:31.400 --> 07:32.960\n with reinforcement learning algorithms\n\n07:32.960 --> 07:34.640\n if they're trained well.\n\n07:34.640 --> 07:39.240\n But you say limited, so the big question really\n\n07:39.240 --> 07:42.120\n is how you jump from limited to human level, right?\n\n07:42.120 --> 07:44.620\n And whether it's possible,\n\n07:46.840 --> 07:49.000\n even just building common sense reasoning\n\n07:49.000 --> 07:50.520\n seems to be exceptionally difficult.\n\n07:50.520 --> 07:52.480\n So if we scale things up,\n\n07:52.480 --> 07:55.000\n if we get much better on supervised learning,\n\n07:55.000 --> 07:56.620\n if we get better at labeling,\n\n07:56.620 --> 08:00.640\n if we get bigger data sets, more compute,\n\n08:00.640 --> 08:03.880\n do you think we'll start to see really impressive things\n\n08:03.880 --> 08:08.320\n that go from limited to something,\n\n08:08.320 --> 08:10.320\n echoes of human level cognition?\n\n08:10.320 --> 08:11.200\n I think so, yeah.\n\n08:11.200 --> 08:13.340\n I'm optimistic about what can happen\n\n08:13.340 --> 08:16.420\n just with more computation and more data.\n\n08:16.420 --> 08:17.500\n I do think it'll be important\n\n08:17.500 --> 08:20.100\n to get the right kind of data.\n\n08:20.100 --> 08:23.160\n Today, most of the machine learning systems we train\n\n08:23.160 --> 08:27.540\n are mostly trained on one type of data for each model.\n\n08:27.540 --> 08:31.380\n But the human brain, we get all of our different senses\n\n08:31.380 --> 08:33.880\n and we have many different experiences\n\n08:33.880 --> 08:36.320\n like riding a bike, driving a car,\n\n08:36.320 --> 08:37.960\n talking to people, reading.\n\n08:39.160 --> 08:42.420\n I think when we get that kind of integrated data set,\n\n08:42.420 --> 08:44.420\n working with a machine learning model\n\n08:44.420 --> 08:47.660\n that can actually close the loop and interact,\n\n08:47.660 --> 08:50.480\n we may find that algorithms not so different\n\n08:50.480 --> 08:53.240\n from what we have today learn really interesting things\n\n08:53.240 --> 08:54.400\n when you scale them up a lot\n\n08:54.400 --> 08:58.240\n and train them on a large amount of multimodal data.\n\n08:58.240 --> 08:59.640\n So multimodal is really interesting,\n\n08:59.640 --> 09:04.000\n but within, like you're working adversarial examples.\n\n09:04.000 --> 09:09.000\n So selecting within modal, within one mode of data,\n\n09:11.120 --> 09:13.780\n selecting better at what are the difficult cases\n\n09:13.780 --> 09:16.120\n from which you're most useful to learn from.\n\n09:16.120 --> 09:18.880\n Oh yeah, like could we get a whole lot of mileage\n\n09:18.880 --> 09:22.280\n out of designing a model that's resistant\n\n09:22.280 --> 09:24.120\n to adversarial examples or something like that?\n\n09:24.120 --> 09:26.280\n Right, that's the question.\n\n09:26.280 --> 09:27.760\n My thinking on that has evolved a lot\n\n09:27.760 --> 09:29.960\n over the last few years.\n\n09:29.960 --> 09:31.280\n When I first started to really invest\n\n09:31.280 --> 09:32.760\n in studying adversarial examples,\n\n09:32.760 --> 09:36.320\n I was thinking of it mostly as adversarial examples\n\n09:36.320 --> 09:38.980\n reveal a big problem with machine learning\n\n09:38.980 --> 09:41.160\n and we would like to close the gap\n\n09:41.160 --> 09:44.120\n between how machine learning models respond\n\n09:44.120 --> 09:46.560\n to adversarial examples and how humans respond.\n\n09:47.640 --> 09:49.200\n After studying the problem more,\n\n09:49.200 --> 09:51.940\n I still think that adversarial examples are important.\n\n09:51.940 --> 09:55.440\n I think of them now more of as a security liability\n\n09:55.440 --> 09:57.800\n than as an issue that necessarily shows\n\n09:57.800 --> 09:59.880\n there's something uniquely wrong\n\n09:59.880 --> 10:02.800\n with machine learning as opposed to humans.\n\n10:02.800 --> 10:04.600\n Also, do you see them as a tool\n\n10:04.600 --> 10:06.480\n to improve the performance of the system?\n\n10:06.480 --> 10:10.760\n Not on the security side, but literally just accuracy.\n\n10:10.760 --> 10:13.480\n I do see them as a kind of tool on that side,\n\n10:13.480 --> 10:16.640\n but maybe not quite as much as I used to think.\n\n10:16.640 --> 10:18.500\n We've started to find that there's a trade off\n\n10:18.500 --> 10:21.680\n between accuracy on adversarial examples\n\n10:21.680 --> 10:24.360\n and accuracy on clean examples.\n\n10:24.360 --> 10:27.120\n Back in 2014, when I did the first\n\n10:27.120 --> 10:30.840\n adversarily trained classifier that showed resistance\n\n10:30.840 --> 10:33.040\n to some kinds of adversarial examples,\n\n10:33.040 --> 10:36.040\n it also got better at the clean data on MNIST.\n\n10:36.040 --> 10:37.700\n And that's something we've replicated several times\n\n10:37.700 --> 10:39.640\n on MNIST, that when we train\n\n10:39.640 --> 10:41.500\n against weak adversarial examples,\n\n10:41.500 --> 10:43.880\n MNIST classifiers get more accurate.\n\n10:43.880 --> 10:47.080\n So far that hasn't really held up on other data sets\n\n10:47.080 --> 10:48.880\n and hasn't held up when we train\n\n10:48.880 --> 10:50.760\n against stronger adversaries.\n\n10:50.760 --> 10:53.160\n It seems like when you confront\n\n10:53.160 --> 10:55.680\n a really strong adversary,\n\n10:55.680 --> 10:58.040\n you tend to have to give something up.\n\n10:58.040 --> 10:59.040\n Interesting.\n\n10:59.040 --> 11:00.480\n But it's such a compelling idea\n\n11:00.480 --> 11:04.720\n because it feels like that's how us humans learn\n\n11:04.720 --> 11:06.280\n is through the difficult cases.\n\n11:06.280 --> 11:08.760\n We try to think of what would we screw up\n\n11:08.760 --> 11:11.000\n and then we make sure we fix that.\n\n11:11.000 --> 11:13.560\n It's also in a lot of branches of engineering,\n\n11:13.560 --> 11:15.800\n you do a worst case analysis\n\n11:15.800 --> 11:18.720\n and make sure that your system will work in the worst case.\n\n11:18.720 --> 11:20.400\n And then that guarantees that it'll work\n\n11:20.400 --> 11:24.360\n in all of the messy average cases that happen\n\n11:24.360 --> 11:27.440\n when you go out into a really randomized world.\n\n11:27.440 --> 11:29.560\n Yeah, with driving with autonomous vehicles,\n\n11:29.560 --> 11:33.080\n there seems to be a desire to just look for,\n\n11:33.080 --> 11:34.880\n think adversarially,\n\n11:34.880 --> 11:36.920\n try to figure out how to mess up the system.\n\n11:36.920 --> 11:40.620\n And if you can be robust to all those difficult cases,\n\n11:40.620 --> 11:43.580\n then you can, it's a hand wavy empirical way\n\n11:43.580 --> 11:47.040\n to show your system is safe.\n\n11:47.040 --> 11:49.120\n Today, most adversarial example research\n\n11:49.120 --> 11:51.640\n isn't really focused on a particular use case,\n\n11:51.640 --> 11:54.000\n but there are a lot of different use cases\n\n11:54.000 --> 11:56.940\n where you'd like to make sure that the adversary\n\n11:56.940 --> 12:00.200\n can't interfere with the operation of your system.\n\n12:00.200 --> 12:01.060\n Like in finance,\n\n12:01.060 --> 12:03.320\n if you have an algorithm making trades for you,\n\n12:03.320 --> 12:04.660\n people go to a lot of an effort\n\n12:04.660 --> 12:06.680\n to obfuscate their algorithm.\n\n12:06.680 --> 12:08.080\n That's both to protect their IP\n\n12:08.080 --> 12:10.880\n because you don't want to research\n\n12:10.880 --> 12:13.580\n and develop a profitable trading algorithm\n\n12:13.580 --> 12:16.120\n then have somebody else capture the gains.\n\n12:16.120 --> 12:17.160\n But it's at least partly\n\n12:17.160 --> 12:19.520\n because you don't want people to make adversarial examples\n\n12:19.520 --> 12:22.580\n that fool your algorithm into making bad trades.\n\n12:24.380 --> 12:26.580\n Or I guess one area that's been popular\n\n12:26.580 --> 12:30.180\n in the academic literature is speech recognition.\n\n12:30.180 --> 12:34.440\n If you use speech recognition to hear an audio wave form\n\n12:34.440 --> 12:37.720\n and then turn that into a command\n\n12:37.720 --> 12:39.680\n that a phone executes for you,\n\n12:39.680 --> 12:41.880\n you don't want a malicious adversary\n\n12:41.880 --> 12:43.640\n to be able to produce audio\n\n12:43.640 --> 12:46.300\n that gets interpreted as malicious commands,\n\n12:46.300 --> 12:48.520\n especially if a human in the room doesn't realize\n\n12:48.520 --> 12:50.320\n that something like that is happening.\n\n12:50.320 --> 12:52.000\n And speech recognition,\n\n12:52.000 --> 12:53.880\n has there been much success\n\n12:53.880 --> 12:58.440\n in being able to create adversarial examples\n\n12:58.440 --> 12:59.760\n that fool the system?\n\n12:59.760 --> 13:00.880\n Yeah, actually.\n\n13:00.880 --> 13:02.420\n I guess the first work that I'm aware of\n\n13:02.420 --> 13:05.120\n is a paper called Hidden Voice Commands\n\n13:05.120 --> 13:08.480\n that came out in 2016, I believe.\n\n13:08.480 --> 13:11.920\n And they were able to show that they could make sounds\n\n13:11.920 --> 13:14.960\n that are not understandable by a human\n\n13:14.960 --> 13:18.400\n but are recognized as the target phrase\n\n13:18.400 --> 13:21.320\n that the attacker wants the phone to recognize it as.\n\n13:21.320 --> 13:24.020\n Since then, things have gotten a little bit better\n\n13:24.020 --> 13:25.200\n on the attacker's side\n\n13:25.200 --> 13:27.580\n when worse on the defender's side.\n\n13:28.680 --> 13:33.360\n It's become possible to make sounds\n\n13:33.360 --> 13:35.600\n that sound like normal speech\n\n13:35.600 --> 13:38.980\n but are actually interpreted as a different sentence\n\n13:38.980 --> 13:40.720\n than the human hears.\n\n13:40.720 --> 13:42.720\n The level of perceptibility\n\n13:42.720 --> 13:45.320\n of the adversarial perturbation is still kind of high.\n\n13:46.640 --> 13:48.160\n When you listen to the recording,\n\n13:48.160 --> 13:51.040\n it sounds like there's some noise in the background,\n\n13:51.040 --> 13:52.960\n just like rustling sounds.\n\n13:52.960 --> 13:53.940\n But those rustling sounds\n\n13:53.940 --> 13:55.560\n are actually the adversarial perturbation\n\n13:55.560 --> 13:58.040\n that makes the phone hear a completely different sentence.\n\n13:58.040 --> 14:00.120\n Yeah, that's so fascinating.\n\n14:00.120 --> 14:01.080\n Peter Norvig mentioned\n\n14:01.080 --> 14:02.780\n that you're writing the deep learning chapter\n\n14:02.780 --> 14:04.280\n for the fourth edition\n\n14:04.280 --> 14:07.340\n of the Artificial Intelligence, A Modern Approach book.\n\n14:07.340 --> 14:10.700\n So how do you even begin summarizing\n\n14:10.700 --> 14:13.080\n the field of deep learning in a chapter?\n\n14:13.080 --> 14:16.880\n Well, in my case, I waited like a year\n\n14:16.880 --> 14:19.200\n before I actually wrote anything.\n\n14:19.200 --> 14:22.660\n Even having written a full length textbook before,\n\n14:22.660 --> 14:25.600\n it's still pretty intimidating\n\n14:25.600 --> 14:27.840\n to try to start writing just one chapter\n\n14:27.840 --> 14:29.080\n that covers everything.\n\n14:31.160 --> 14:33.200\n One thing that helped me make that plan\n\n14:33.200 --> 14:34.320\n was actually the experience\n\n14:34.320 --> 14:36.740\n of having written the full book before\n\n14:36.740 --> 14:39.160\n and then watching how the field changed\n\n14:39.160 --> 14:41.000\n after the book came out.\n\n14:41.000 --> 14:42.340\n I've realized there's a lot of topics\n\n14:42.340 --> 14:45.040\n that were maybe extraneous in the first book\n\n14:45.040 --> 14:47.620\n and just seeing what stood the test\n\n14:47.620 --> 14:49.440\n of a few years of being published\n\n14:49.440 --> 14:52.240\n and what seems a little bit less important\n\n14:52.240 --> 14:54.320\n to have included now helped me pare down the topics\n\n14:54.320 --> 14:55.880\n I wanted to cover for the book.\n\n14:56.920 --> 14:58.060\n It's also really nice now\n\n14:58.060 --> 15:00.600\n that the field is kind of stabilized\n\n15:00.600 --> 15:02.840\n to the point where some core ideas from the 1980s\n\n15:02.840 --> 15:04.800\n are still used today.\n\n15:04.800 --> 15:06.720\n When I first started studying machine learning,\n\n15:06.720 --> 15:09.600\n almost everything from the 1980s had been rejected\n\n15:09.600 --> 15:11.400\n and now some of it has come back.\n\n15:11.400 --> 15:13.520\n So that stuff that's really stood the test of time\n\n15:13.520 --> 15:15.980\n is what I focused on putting into the book.\n\n15:16.960 --> 15:21.320\n There's also, I guess, two different philosophies\n\n15:21.320 --> 15:23.160\n about how you might write a book.\n\n15:23.160 --> 15:24.840\n One philosophy is you try to write a reference\n\n15:24.840 --> 15:26.240\n that covers everything.\n\n15:26.240 --> 15:28.040\n The other philosophy is you try to provide\n\n15:28.040 --> 15:31.160\n a high level summary that gives people the language\n\n15:31.160 --> 15:32.440\n to understand a field\n\n15:32.440 --> 15:35.000\n and tells them what the most important concepts are.\n\n15:35.000 --> 15:37.080\n The first deep learning book that I wrote\n\n15:37.080 --> 15:39.260\n with Joshua and Aaron was somewhere\n\n15:39.260 --> 15:41.240\n between the two philosophies,\n\n15:41.240 --> 15:43.640\n that it's trying to be both a reference\n\n15:43.640 --> 15:45.760\n and an introductory guide.\n\n15:45.760 --> 15:48.920\n Writing this chapter for Russell Norvig's book,\n\n15:48.920 --> 15:52.780\n I was able to focus more on just a concise introduction\n\n15:52.780 --> 15:54.240\n of the key concepts and the language\n\n15:54.240 --> 15:55.980\n you need to read about them more.\n\n15:55.980 --> 15:57.560\n In a lot of cases, I actually just wrote paragraphs\n\n15:57.560 --> 16:00.060\n that said, here's a rapidly evolving area\n\n16:00.060 --> 16:02.360\n that you should pay attention to.\n\n16:02.360 --> 16:04.760\n It's pointless to try to tell you what the latest\n\n16:04.760 --> 16:09.760\n and best version of a learn to learn model is.\n\n16:11.680 --> 16:13.660\n I can point you to a paper that's recent right now,\n\n16:13.660 --> 16:16.880\n but there isn't a whole lot of a reason to delve\n\n16:16.880 --> 16:18.640\n into exactly what's going on\n\n16:18.640 --> 16:21.600\n with the latest learning to learn approach\n\n16:21.600 --> 16:23.400\n or the latest module produced\n\n16:23.400 --> 16:25.000\n by a learning to learn algorithm.\n\n16:25.000 --> 16:26.800\n You should know that learning to learn is a thing\n\n16:26.800 --> 16:30.680\n and that it may very well be the source of the latest\n\n16:30.680 --> 16:33.800\n and greatest convolutional net or recurrent net module\n\n16:33.800 --> 16:36.060\n that you would want to use in your latest project.\n\n16:36.060 --> 16:38.200\n But there isn't a lot of point in trying to summarize\n\n16:38.200 --> 16:42.300\n exactly which architecture and which learning approach\n\n16:42.300 --> 16:44.060\n got to which level of performance.\n\n16:44.060 --> 16:49.060\n So you maybe focus more on the basics of the methodology.\n\n16:49.260 --> 16:52.500\n So from back propagation to feed forward\n\n16:52.500 --> 16:54.480\n to recurrent neural networks, convolutional,\n\n16:54.480 --> 16:55.320\n that kind of thing?\n\n16:55.320 --> 16:56.480\n Yeah, yeah.\n\n16:56.480 --> 17:00.360\n So if I were to ask you, I remember I took algorithms\n\n17:00.360 --> 17:03.720\n and data structures algorithms course.\n\n17:03.720 --> 17:08.100\n I remember the professor asked, what is an algorithm?\n\n17:09.160 --> 17:12.200\n And yelled at everybody in a good way\n\n17:12.200 --> 17:14.040\n that nobody was answering it correctly.\n\n17:14.040 --> 17:16.380\n Everybody knew what the algorithm, it was graduate course.\n\n17:16.380 --> 17:18.140\n Everybody knew what an algorithm was,\n\n17:18.140 --> 17:19.760\n but they weren't able to answer it well.\n\n17:19.760 --> 17:22.360\n So let me ask you in that same spirit,\n\n17:22.360 --> 17:23.580\n what is deep learning?\n\n17:24.540 --> 17:29.540\n I would say deep learning is any kind of machine learning\n\n17:29.540 --> 17:34.540\n that involves learning parameters of more than one\n\n17:34.620 --> 17:35.900\n consecutive step.\n\n17:37.140 --> 17:39.460\n So that, I mean, shallow learning is things\n\n17:39.460 --> 17:43.620\n where you learn a lot of operations that happen in parallel.\n\n17:43.620 --> 17:46.580\n You might have a system that makes multiple steps.\n\n17:46.580 --> 17:50.700\n Like you might have hand designed feature extractors,\n\n17:50.700 --> 17:52.500\n but really only one step is learned.\n\n17:52.500 --> 17:55.900\n Deep learning is anything where you have multiple operations\n\n17:55.900 --> 17:58.420\n in sequence, and that includes the things\n\n17:58.420 --> 17:59.780\n that are really popular today,\n\n17:59.780 --> 18:03.580\n like convolutional networks and recurrent networks.\n\n18:03.580 --> 18:06.580\n But it also includes some of the things that have died out\n\n18:06.580 --> 18:08.260\n like Bolton machines,\n\n18:08.260 --> 18:10.880\n where we weren't using back propagation.\n\n18:11.980 --> 18:14.220\n Today, I hear a lot of people define deep learning\n\n18:14.220 --> 18:18.020\n as gradient descent applied\n\n18:18.020 --> 18:21.460\n to these differentiable functions.\n\n18:21.460 --> 18:24.780\n And I think that's a legitimate usage of the term.\n\n18:24.780 --> 18:27.820\n It's just different from the way that I use the term myself.\n\n18:27.820 --> 18:31.740\n So what's an example of deep learning\n\n18:31.740 --> 18:34.740\n that is not gradient descent and differentiable functions?\n\n18:34.740 --> 18:37.420\n In your, I mean, not specifically perhaps,\n\n18:37.420 --> 18:39.780\n but more even looking into the future,\n\n18:39.780 --> 18:44.300\n what's your thought about that space of approaches?\n\n18:44.300 --> 18:46.340\n Yeah, so I tend to think of machine learning algorithms\n\n18:46.340 --> 18:50.180\n as decomposed into really three different pieces.\n\n18:50.180 --> 18:52.980\n There's the model, which can be something like a neural net\n\n18:52.980 --> 18:56.580\n or a Bolton machine or a recurrent model.\n\n18:56.580 --> 18:59.500\n And that basically just describes how do you take data\n\n18:59.500 --> 19:01.140\n and how do you take parameters?\n\n19:01.140 --> 19:04.300\n And what function do you use to make a prediction\n\n19:04.300 --> 19:07.320\n given the data and the parameters?\n\n19:07.320 --> 19:09.260\n Another piece of the learning algorithm\n\n19:09.260 --> 19:12.380\n is the optimization algorithm.\n\n19:12.380 --> 19:14.900\n Or not every algorithm can be really described\n\n19:14.900 --> 19:15.900\n in terms of optimization,\n\n19:15.900 --> 19:18.860\n but what's the algorithm for updating the parameters\n\n19:18.860 --> 19:21.680\n or updating whatever the state of the network is?\n\n19:22.620 --> 19:26.280\n And then the last part is the data set,\n\n19:26.280 --> 19:29.180\n like how do you actually represent the world\n\n19:29.180 --> 19:32.120\n as it comes into your machine learning system?\n\n19:33.140 --> 19:36.740\n So I think of deep learning as telling us something about\n\n19:36.740 --> 19:39.060\n what does the model look like?\n\n19:39.060 --> 19:41.260\n And basically to qualify as deep,\n\n19:41.260 --> 19:44.540\n I say that it just has to have multiple layers.\n\n19:44.540 --> 19:46.340\n That can be multiple steps\n\n19:46.340 --> 19:49.220\n in a feed forward differentiable computation.\n\n19:49.220 --> 19:52.020\n That can be multiple layers in a graphical model.\n\n19:52.020 --> 19:53.560\n There's a lot of ways that you could satisfy me\n\n19:53.560 --> 19:56.140\n that something has multiple steps\n\n19:56.140 --> 19:58.900\n that are each parameterized separately.\n\n19:58.900 --> 19:59.940\n I think of gradient descent\n\n19:59.940 --> 20:01.540\n as being all about that other piece,\n\n20:01.540 --> 20:04.260\n the how do you actually update the parameters piece?\n\n20:04.260 --> 20:05.980\n So you could imagine having a deep model\n\n20:05.980 --> 20:07.540\n like a convolutional net\n\n20:07.540 --> 20:09.660\n and training it with something like evolution\n\n20:09.660 --> 20:11.300\n or a genetic algorithm.\n\n20:11.300 --> 20:14.780\n And I would say that still qualifies as deep learning.\n\n20:14.780 --> 20:16.060\n And then in terms of models\n\n20:16.060 --> 20:18.740\n that aren't necessarily differentiable,\n\n20:18.740 --> 20:21.260\n I guess Bolton machines are probably\n\n20:21.260 --> 20:23.580\n the main example of something\n\n20:23.580 --> 20:25.540\n where you can't really take a derivative\n\n20:25.540 --> 20:27.980\n and use that for the learning process.\n\n20:27.980 --> 20:30.780\n But you can still argue that the model\n\n20:30.780 --> 20:33.740\n has many steps of processing that it applies\n\n20:33.740 --> 20:35.760\n when you run inference in the model.\n\n20:35.760 --> 20:38.900\n So it's the steps of processing that's key.\n\n20:38.900 --> 20:41.300\n So Jeff Hinton suggests that we need to throw away\n\n20:41.300 --> 20:44.900\n back propagation and start all over.\n\n20:44.900 --> 20:46.500\n What do you think about that?\n\n20:46.500 --> 20:48.540\n What could an alternative direction\n\n20:48.540 --> 20:50.940\n of training neural networks look like?\n\n20:50.940 --> 20:52.860\n I don't know that back propagation\n\n20:52.860 --> 20:54.660\n is gonna go away entirely.\n\n20:54.660 --> 20:57.140\n Most of the time when we decide\n\n20:57.140 --> 20:59.220\n that a machine learning algorithm\n\n20:59.220 --> 21:03.460\n isn't on the critical path to research for improving AI,\n\n21:03.460 --> 21:04.660\n the algorithm doesn't die.\n\n21:04.660 --> 21:07.720\n It just becomes used for some specialized set of things.\n\n21:08.820 --> 21:11.180\n A lot of algorithms like logistic regression\n\n21:11.180 --> 21:13.980\n don't seem that exciting to AI researchers\n\n21:13.980 --> 21:16.760\n who are working on things like speech recognition\n\n21:16.760 --> 21:18.420\n or autonomous cars today.\n\n21:18.420 --> 21:21.100\n But there's still a lot of use for logistic regression\n\n21:21.100 --> 21:24.000\n and things like analyzing really noisy data\n\n21:24.000 --> 21:25.700\n in medicine and finance\n\n21:25.700 --> 21:28.780\n or making really rapid predictions\n\n21:28.780 --> 21:30.700\n in really time limited contexts.\n\n21:30.700 --> 21:33.480\n So I think back propagation and gradient descent\n\n21:33.480 --> 21:37.420\n are around to stay, but they may not end up being\n\n21:38.340 --> 21:40.860\n everything that we need to get to real human level\n\n21:40.860 --> 21:42.380\n or super human AI.\n\n21:42.380 --> 21:44.660\n Are you optimistic about us discovering\n\n21:46.700 --> 21:50.220\n back propagation has been around for a few decades?\n\n21:50.220 --> 21:54.100\n So are you optimistic about us as a community\n\n21:54.100 --> 21:56.800\n being able to discover something better?\n\n21:56.800 --> 21:57.640\n Yeah, I am.\n\n21:57.640 --> 22:01.820\n I think we likely will find something that works better.\n\n22:01.820 --> 22:05.500\n You could imagine things like having stacks of models\n\n22:05.500 --> 22:07.580\n where some of the lower level models\n\n22:07.580 --> 22:10.200\n predict parameters of the higher level models.\n\n22:10.200 --> 22:12.140\n And so at the top level,\n\n22:12.140 --> 22:13.500\n you're not learning in terms of literally\n\n22:13.500 --> 22:14.460\n calculating gradients,\n\n22:14.460 --> 22:17.700\n but just predicting how different values will perform.\n\n22:17.700 --> 22:19.580\n You can kind of see that already in some areas\n\n22:19.580 --> 22:21.380\n like Bayesian optimization,\n\n22:21.380 --> 22:22.940\n where you have a Gaussian process\n\n22:22.940 --> 22:24.800\n that predicts how well different parameter values\n\n22:24.800 --> 22:25.880\n will perform.\n\n22:25.880 --> 22:27.700\n We already use those kinds of algorithms\n\n22:27.700 --> 22:30.260\n for things like hyper parameter optimization.\n\n22:30.260 --> 22:32.500\n And in general, we know a lot of things other than back prop\n\n22:32.500 --> 22:34.980\n that work really well for specific problems.\n\n22:34.980 --> 22:37.460\n The main thing we haven't found is\n\n22:37.460 --> 22:38.880\n a way of taking one of these other\n\n22:38.880 --> 22:41.160\n non back prop based algorithms\n\n22:41.160 --> 22:43.500\n and having it really advanced the state of the art\n\n22:43.500 --> 22:46.160\n on an AI level problem.\n\n22:46.160 --> 22:47.100\n Right.\n\n22:47.100 --> 22:49.180\n But I wouldn't be surprised if eventually\n\n22:49.180 --> 22:50.780\n we find that some of these algorithms\n\n22:50.780 --> 22:52.780\n that even the ones that already exist,\n\n22:52.780 --> 22:54.220\n not even necessarily new one,\n\n22:54.220 --> 22:58.180\n we might find some way of customizing\n\n22:58.180 --> 23:00.540\n one of these algorithms to do something really interesting\n\n23:00.540 --> 23:05.240\n at the level of cognition or the level of,\n\n23:06.420 --> 23:08.660\n I think one system that we really don't have working\n\n23:08.660 --> 23:12.060\n quite right yet is like short term memory.\n\n23:12.940 --> 23:14.500\n We have things like LSTMs,\n\n23:14.500 --> 23:16.980\n they're called long short term memory.\n\n23:16.980 --> 23:20.020\n They still don't do quite what a human does\n\n23:20.020 --> 23:21.760\n with short term memory.\n\n23:22.860 --> 23:26.940\n Like gradient descent to learn a specific fact\n\n23:26.940 --> 23:29.380\n has to do multiple steps on that fact.\n\n23:29.380 --> 23:34.140\n Like if I tell you the meeting today is at 3 p.m.,\n\n23:34.140 --> 23:35.460\n I don't need to say over and over again,\n\n23:35.460 --> 23:37.780\n it's at 3 p.m., it's at 3 p.m., it's at 3 p.m.,\n\n23:37.780 --> 23:38.940\n it's at 3 p.m.\n\n23:38.940 --> 23:40.380\n for you to do a gradient step on each one.\n\n23:40.380 --> 23:43.180\n You just hear it once and you remember it.\n\n23:43.180 --> 23:46.940\n There's been some work on things like self attention\n\n23:46.940 --> 23:48.340\n and attention like mechanisms,\n\n23:48.340 --> 23:50.420\n like the neural Turing machine\n\n23:50.420 --> 23:52.220\n that can write to memory cells\n\n23:52.220 --> 23:54.900\n and update themselves with facts like that right away.\n\n23:54.900 --> 23:56.900\n But I don't think we've really nailed it yet.\n\n23:56.900 --> 23:59.580\n And that's one area where I'd imagine\n\n23:59.580 --> 24:02.660\n that new optimization algorithms\n\n24:02.660 --> 24:03.780\n or different ways of applying\n\n24:03.780 --> 24:05.980\n existing optimization algorithms\n\n24:05.980 --> 24:08.800\n could give us a way of just lightning fast\n\n24:08.800 --> 24:11.180\n updating the state of a machine learning system\n\n24:11.180 --> 24:14.100\n to contain a specific fact like that\n\n24:14.100 --> 24:15.340\n without needing to have it presented\n\n24:15.340 --> 24:16.980\n over and over and over again.\n\n24:16.980 --> 24:21.420\n So some of the success of symbolic systems in the 80s\n\n24:21.420 --> 24:26.220\n is they were able to assemble these kinds of facts better.\n\n24:26.220 --> 24:29.100\n But there's a lot of expert input required\n\n24:29.100 --> 24:31.140\n and it's very limited in that sense.\n\n24:31.140 --> 24:33.700\n Do you ever look back to that\n\n24:33.700 --> 24:36.560\n as something that we'll have to return to eventually?\n\n24:36.560 --> 24:38.440\n Sort of dust off the book from the shelf\n\n24:38.440 --> 24:41.340\n and think about how we build knowledge,\n\n24:41.340 --> 24:42.940\n representation, knowledge base.\n\n24:42.940 --> 24:44.820\n Like will we have to use graph searches?\n\n24:44.820 --> 24:45.780\n Graph searches, right.\n\n24:45.780 --> 24:47.700\n And like first order logic and entailment\n\n24:47.700 --> 24:48.540\n and things like that.\n\n24:48.540 --> 24:49.540\n That kind of thing, yeah, exactly.\n\n24:49.540 --> 24:51.180\n In my particular line of work,\n\n24:51.180 --> 24:54.540\n which has mostly been machine learning security\n\n24:54.540 --> 24:56.740\n and also generative modeling,\n\n24:56.740 --> 25:00.560\n I haven't usually found myself moving in that direction.\n\n25:00.560 --> 25:03.500\n For generative models, I could see a little bit of,\n\n25:03.500 --> 25:04.920\n it could be useful if you had something\n\n25:04.920 --> 25:09.660\n like a differentiable knowledge base\n\n25:09.660 --> 25:10.980\n or some other kind of knowledge base\n\n25:10.980 --> 25:13.140\n where it's possible for some of our\n\n25:13.140 --> 25:14.860\n fuzzier machine learning algorithms\n\n25:14.860 --> 25:16.900\n to interact with a knowledge base.\n\n25:16.900 --> 25:19.060\n I mean, your network is kind of like that.\n\n25:19.060 --> 25:21.480\n It's a differentiable knowledge base of sorts.\n\n25:21.480 --> 25:22.320\n Yeah.\n\n25:22.320 --> 25:23.660\n But.\n\n25:23.660 --> 25:27.660\n If we had a really easy way of giving feedback\n\n25:27.660 --> 25:29.260\n to machine learning models,\n\n25:29.260 --> 25:32.420\n that would clearly help a lot with generative models.\n\n25:32.420 --> 25:33.940\n And so you could imagine one way of getting there\n\n25:33.940 --> 25:36.760\n would be get a lot better at natural language processing.\n\n25:36.760 --> 25:38.960\n But another way of getting there would be\n\n25:38.960 --> 25:40.300\n take some kind of knowledge base\n\n25:40.300 --> 25:42.340\n and figure out a way for it to actually\n\n25:42.340 --> 25:44.100\n interact with a neural network.\n\n25:44.100 --> 25:46.100\n Being able to have a chat with a neural network.\n\n25:46.100 --> 25:46.940\n Yeah.\n\n25:47.900 --> 25:50.020\n So like one thing in generative models we see a lot today\n\n25:50.020 --> 25:53.580\n is you'll get things like faces that are not symmetrical,\n\n25:54.780 --> 25:58.580\n like people that have two eyes that are different colors.\n\n25:58.580 --> 25:59.580\n I mean, there are people with eyes\n\n25:59.580 --> 26:00.900\n that are different colors in real life,\n\n26:00.900 --> 26:03.500\n but not nearly as many of them as you tend to see\n\n26:03.500 --> 26:06.140\n in the machine learning generated data.\n\n26:06.140 --> 26:08.140\n So if you had either a knowledge base\n\n26:08.140 --> 26:10.220\n that could contain the fact,\n\n26:10.220 --> 26:13.380\n people's faces are generally approximately symmetric\n\n26:13.380 --> 26:15.940\n and eye color is especially likely\n\n26:15.940 --> 26:17.980\n to be the same on both sides.\n\n26:17.980 --> 26:20.200\n Being able to just inject that hint\n\n26:20.200 --> 26:22.060\n into the machine learning model\n\n26:22.060 --> 26:23.860\n without it having to discover that itself\n\n26:23.860 --> 26:25.820\n after studying a lot of data\n\n26:25.820 --> 26:28.380\n would be a really useful feature.\n\n26:28.380 --> 26:30.180\n I could see a lot of ways of getting there\n\n26:30.180 --> 26:32.220\n without bringing back some of the 1980s technology,\n\n26:32.220 --> 26:35.180\n but I also see some ways that you could imagine\n\n26:35.180 --> 26:38.260\n extending the 1980s technology to play nice with neural nets\n\n26:38.260 --> 26:40.080\n and have it help get there.\n\n26:40.080 --> 26:40.920\n Awesome.\n\n26:40.920 --> 26:44.380\n So you talked about the story of you coming up\n\n26:44.380 --> 26:47.020\n with the idea of GANs at a bar with some friends.\n\n26:47.020 --> 26:51.380\n You were arguing that this, you know, GANs would work,\n\n26:51.380 --> 26:53.060\n generative adversarial networks,\n\n26:53.060 --> 26:54.660\n and the others didn't think so.\n\n26:54.660 --> 26:58.420\n Then you went home at midnight, coded it up, and it worked.\n\n26:58.420 --> 27:01.340\n So if I was a friend of yours at the bar,\n\n27:01.340 --> 27:02.700\n I would also have doubts.\n\n27:02.700 --> 27:03.860\n It's a really nice idea,\n\n27:03.860 --> 27:06.820\n but I'm very skeptical that it would work.\n\n27:06.820 --> 27:09.300\n What was the basis of their skepticism?\n\n27:09.300 --> 27:13.180\n What was the basis of your intuition why it should work?\n\n27:14.340 --> 27:15.980\n I don't want to be someone who goes around\n\n27:15.980 --> 27:18.280\n promoting alcohol for the purposes of science,\n\n27:18.280 --> 27:20.020\n but in this case,\n\n27:20.020 --> 27:23.060\n I do actually think that drinking helped a little bit.\n\n27:23.060 --> 27:25.360\n When your inhibitions are lowered,\n\n27:25.360 --> 27:27.380\n you're more willing to try out things\n\n27:27.380 --> 27:29.620\n that you wouldn't try out otherwise.\n\n27:29.620 --> 27:32.460\n So I have noticed in general\n\n27:32.460 --> 27:34.540\n that I'm less prone to shooting down some of my own ideas\n\n27:34.540 --> 27:37.960\n when I have had a little bit to drink.\n\n27:37.960 --> 27:41.020\n I think if I had had that idea at lunchtime,\n\n27:41.020 --> 27:42.260\n I probably would have thought,\n\n27:42.260 --> 27:43.720\n it's hard enough to train one neural net,\n\n27:43.720 --> 27:44.880\n you can't train a second neural net\n\n27:44.880 --> 27:48.080\n in the inner loop of the outer neural net.\n\n27:48.080 --> 27:49.820\n That was basically my friend's objection,\n\n27:49.820 --> 27:52.740\n was that trying to train two neural nets at the same time\n\n27:52.740 --> 27:54.260\n would be too hard.\n\n27:54.260 --> 27:56.140\n So it was more about the training process,\n\n27:56.140 --> 27:58.300\n unless, so my skepticism would be,\n\n27:58.300 --> 28:01.140\n you know, I'm sure you could train it,\n\n28:01.140 --> 28:03.180\n but the thing it would converge to\n\n28:03.180 --> 28:05.820\n would not be able to generate anything reasonable,\n\n28:05.820 --> 28:08.260\n any kind of reasonable realism.\n\n28:08.260 --> 28:11.360\n Yeah, so part of what all of us were thinking about\n\n28:11.360 --> 28:15.280\n when we had this conversation was deep Bolton machines,\n\n28:15.280 --> 28:16.980\n which a lot of us in the lab, including me,\n\n28:16.980 --> 28:19.580\n were a big fan of deep Bolton machines at the time.\n\n28:20.660 --> 28:22.920\n They involved two separate processes\n\n28:22.920 --> 28:24.180\n running at the same time.\n\n28:25.060 --> 28:28.140\n One of them is called the positive phase,\n\n28:28.140 --> 28:31.160\n where you load data into the model\n\n28:31.160 --> 28:33.540\n and tell the model to make the data more likely.\n\n28:33.540 --> 28:35.140\n The other one is called the negative phase,\n\n28:35.140 --> 28:37.020\n where you draw samples from the model\n\n28:37.020 --> 28:39.620\n and tell the model to make those samples less likely.\n\n28:41.180 --> 28:42.220\n In a deep Bolton machine,\n\n28:42.220 --> 28:43.960\n it's not trivial to generate a sample.\n\n28:43.960 --> 28:46.980\n You have to actually run an iterative process\n\n28:46.980 --> 28:49.140\n that gets better and better samples\n\n28:49.140 --> 28:51.380\n coming closer and closer to the distribution\n\n28:51.380 --> 28:52.840\n the model represents.\n\n28:52.840 --> 28:53.900\n So during the training process,\n\n28:53.900 --> 28:56.940\n you're always running these two systems at the same time,\n\n28:56.940 --> 28:58.940\n one that's updating the parameters of the model\n\n28:58.940 --> 29:00.500\n and another one that's trying to generate samples\n\n29:00.500 --> 29:01.660\n from the model.\n\n29:01.660 --> 29:04.340\n And they worked really well in things like MNIST,\n\n29:04.340 --> 29:05.820\n but a lot of us in the lab, including me,\n\n29:05.820 --> 29:07.500\n had tried to get deep Bolton machines\n\n29:07.500 --> 29:11.900\n to scale past MNIST to things like generating color photos,\n\n29:11.900 --> 29:14.120\n and we just couldn't get the two processes\n\n29:14.120 --> 29:15.940\n to stay synchronized.\n\n29:17.380 --> 29:18.740\n So when I had the idea for GANs,\n\n29:18.740 --> 29:20.340\n a lot of people thought that the discriminator\n\n29:20.340 --> 29:22.580\n would have more or less the same problem\n\n29:22.580 --> 29:25.320\n as the negative phase in the Bolton machine,\n\n29:25.320 --> 29:27.800\n that trying to train the discriminator in the inner loop,\n\n29:27.800 --> 29:29.920\n you just couldn't get it to keep up\n\n29:29.920 --> 29:31.540\n with the generator in the outer loop,\n\n29:31.540 --> 29:33.820\n and that would prevent it from converging\n\n29:33.820 --> 29:35.220\n to anything useful.\n\n29:35.220 --> 29:36.840\n Yeah, I share that intuition.\n\n29:36.840 --> 29:37.680\n Yeah.\n\n29:39.540 --> 29:41.940\n But turns out to not be the case.\n\n29:41.940 --> 29:43.760\n A lot of the time with machine learning algorithms,\n\n29:43.760 --> 29:45.180\n it's really hard to predict ahead of time\n\n29:45.180 --> 29:46.900\n how well they'll actually perform.\n\n29:46.900 --> 29:49.140\n You have to just run the experiment and see what happens.\n\n29:49.140 --> 29:52.500\n And I would say I still today don't have\n\n29:52.500 --> 29:54.780\n like one factor I can put my finger on and say,\n\n29:54.780 --> 29:58.340\n this is why GANs worked for photo generation\n\n29:58.340 --> 30:00.200\n and deep Bolton machines don't.\n\n30:01.980 --> 30:03.300\n There are a lot of theory papers\n\n30:03.300 --> 30:06.340\n showing that under some theoretical settings,\n\n30:06.340 --> 30:09.640\n the GAN algorithm does actually converge,\n\n30:10.680 --> 30:14.140\n but those settings are restricted enough\n\n30:14.140 --> 30:17.520\n that they don't necessarily explain the whole picture\n\n30:17.520 --> 30:20.740\n in terms of all the results that we see in practice.\n\n30:20.740 --> 30:22.300\n So taking a step back,\n\n30:22.300 --> 30:24.860\n can you, in the same way as we talked about deep learning,\n\n30:24.860 --> 30:28.400\n can you tell me what generative adversarial networks are?\n\n30:29.420 --> 30:31.380\n Yeah, so generative adversarial networks\n\n30:31.380 --> 30:33.980\n are a particular kind of generative model.\n\n30:33.980 --> 30:36.280\n A generative model is a machine learning model\n\n30:36.280 --> 30:38.860\n that can train on some set of data.\n\n30:38.860 --> 30:41.220\n Like, so you have a collection of photos of cats\n\n30:41.220 --> 30:43.980\n and you want to generate more photos of cats,\n\n30:43.980 --> 30:47.700\n or you want to estimate a probability distribution over cats.\n\n30:47.700 --> 30:49.800\n So you can ask how likely it is\n\n30:49.800 --> 30:51.820\n that some new image is a photo of a cat.\n\n30:52.860 --> 30:55.800\n GANs are one way of doing this.\n\n30:55.800 --> 30:59.180\n Some generative models are good at creating new data.\n\n30:59.180 --> 31:01.620\n Other generative models are good at estimating\n\n31:01.620 --> 31:04.140\n that density function and telling you how likely\n\n31:04.140 --> 31:07.180\n particular pieces of data are to come\n\n31:07.180 --> 31:09.700\n from the same distribution as the training data.\n\n31:09.700 --> 31:12.420\n GANs are more focused on generating samples\n\n31:12.420 --> 31:15.600\n rather than estimating the density function.\n\n31:15.600 --> 31:18.500\n There are some kinds of GANs like FlowGAN that can do both,\n\n31:18.500 --> 31:21.620\n but mostly GANs are about generating samples,\n\n31:21.620 --> 31:24.220\n generating new photos of cats that look realistic.\n\n31:24.220 --> 31:29.220\n And they do that completely from scratch.\n\n31:29.340 --> 31:32.240\n It's analogous to human imagination.\n\n31:32.240 --> 31:34.780\n When a GAN creates a new image of a cat,\n\n31:34.780 --> 31:39.300\n it's using a neural network to produce a cat\n\n31:39.300 --> 31:41.040\n that has not existed before.\n\n31:41.040 --> 31:44.540\n It isn't doing something like compositing photos together.\n\n31:44.540 --> 31:47.100\n You're not literally taking the eye off of one cat\n\n31:47.100 --> 31:48.300\n and the ear off of another cat.\n\n31:48.300 --> 31:51.380\n It's more of this digestive process\n\n31:51.380 --> 31:53.940\n where the neural net trains in a lot of data\n\n31:53.940 --> 31:55.580\n and comes up with some representation\n\n31:55.580 --> 31:57.420\n of the probability distribution\n\n31:57.420 --> 31:59.820\n and generates entirely new cats.\n\n31:59.820 --> 32:00.900\n There are a lot of different ways\n\n32:00.900 --> 32:01.980\n of building a generative model.\n\n32:01.980 --> 32:05.680\n What's specific to GANs is that we have a two player game\n\n32:05.680 --> 32:08.100\n in the game theoretic sense.\n\n32:08.100 --> 32:10.340\n And as the players in this game compete,\n\n32:10.340 --> 32:13.940\n one of them becomes able to generate realistic data.\n\n32:13.940 --> 32:16.140\n The first player is called the generator.\n\n32:16.140 --> 32:20.660\n It produces output data such as just images, for example.\n\n32:20.660 --> 32:22.460\n And at the start of the learning process,\n\n32:22.460 --> 32:25.140\n it'll just produce completely random images.\n\n32:25.140 --> 32:27.400\n The other player is called the discriminator.\n\n32:27.400 --> 32:29.700\n The discriminator takes images as input\n\n32:29.700 --> 32:32.540\n and guesses whether they're real or fake.\n\n32:32.540 --> 32:34.260\n You train it both on real data,\n\n32:34.260 --> 32:36.140\n so photos that come from your training set,\n\n32:36.140 --> 32:37.860\n actual photos of cats,\n\n32:37.860 --> 32:39.900\n and you train it to say that those are real.\n\n32:39.900 --> 32:41.980\n You also train it on images\n\n32:41.980 --> 32:43.860\n that come from the generator network\n\n32:43.860 --> 32:46.740\n and you train it to say that those are fake.\n\n32:46.740 --> 32:49.220\n As the two players compete in this game,\n\n32:49.220 --> 32:50.960\n the discriminator tries to become better\n\n32:50.960 --> 32:53.340\n at recognizing whether images are real or fake.\n\n32:53.340 --> 32:54.800\n And the generator becomes better\n\n32:54.800 --> 32:57.020\n at fooling the discriminator into thinking\n\n32:57.020 --> 32:59.580\n that its outputs are real.\n\n33:00.820 --> 33:03.580\n And you can analyze this through the language of game theory\n\n33:03.580 --> 33:06.940\n and find that there's a Nash equilibrium\n\n33:06.940 --> 33:08.620\n where the generator has captured\n\n33:08.620 --> 33:10.820\n the correct probability distribution.\n\n33:10.820 --> 33:12.180\n So in the cat example,\n\n33:12.180 --> 33:14.580\n it makes perfectly realistic cat photos.\n\n33:14.580 --> 33:17.180\n And the discriminator is unable to do better\n\n33:17.180 --> 33:18.740\n than random guessing\n\n33:18.740 --> 33:21.860\n because all the samples coming from both the data\n\n33:21.860 --> 33:24.060\n and the generator look equally likely\n\n33:24.060 --> 33:25.860\n to have come from either source.\n\n33:25.860 --> 33:28.380\n So do you ever sit back\n\n33:28.380 --> 33:31.300\n and does it just blow your mind that this thing works?\n\n33:31.300 --> 33:33.380\n So from very,\n\n33:33.380 --> 33:35.860\n so it's able to estimate that density function\n\n33:35.860 --> 33:38.700\n enough to generate realistic images.\n\n33:38.700 --> 33:40.860\n I mean, does it, yeah.\n\n33:40.860 --> 33:44.700\n Do you ever sit back and think how does this even,\n\n33:44.700 --> 33:46.780\n why, this is quite incredible,\n\n33:46.780 --> 33:49.260\n especially where GANs have gone in terms of realism.\n\n33:49.260 --> 33:51.620\n Yeah, and not just to flatter my own work,\n\n33:51.620 --> 33:53.840\n but generative models,\n\n33:53.840 --> 33:56.500\n all of them have this property that\n\n33:56.500 --> 33:58.800\n if they really did what we ask them to do,\n\n33:58.800 --> 34:01.060\n they would do nothing but memorize the training data.\n\n34:01.060 --> 34:02.920\n Right, exactly.\n\n34:02.920 --> 34:05.740\n Models that are based on maximizing the likelihood,\n\n34:05.740 --> 34:08.140\n the way that you obtain the maximum likelihood\n\n34:08.140 --> 34:09.700\n for a specific training set\n\n34:09.700 --> 34:12.380\n is you assign all of your probability mass\n\n34:12.380 --> 34:15.100\n to the training examples and nowhere else.\n\n34:15.100 --> 34:18.380\n For GANs, the game is played using a training set.\n\n34:18.380 --> 34:21.140\n So the way that you become unbeatable in the game\n\n34:21.140 --> 34:23.420\n is you literally memorize training examples.\n\n34:25.340 --> 34:28.860\n One of my former interns wrote a paper,\n\n34:28.860 --> 34:31.020\n his name is Vaishnav Nagarajan,\n\n34:31.020 --> 34:33.860\n and he showed that it's actually hard for the generator\n\n34:33.860 --> 34:36.060\n to memorize the training data,\n\n34:36.060 --> 34:39.100\n hard in a statistical learning theory sense,\n\n34:39.100 --> 34:42.140\n that you can actually create reasons\n\n34:42.140 --> 34:47.140\n for why it would require quite a lot of learning steps\n\n34:48.340 --> 34:52.140\n and a lot of observations of different latent variables\n\n34:52.140 --> 34:54.300\n before you could memorize the training data.\n\n34:54.300 --> 34:56.140\n That still doesn't really explain why\n\n34:56.140 --> 34:58.200\n when you produce samples that are new,\n\n34:58.200 --> 34:59.820\n why do you get compelling images\n\n34:59.820 --> 35:01.820\n rather than just garbage\n\n35:01.820 --> 35:03.720\n that's different from the training set.\n\n35:03.720 --> 35:06.900\n And I don't think we really have a good answer for that,\n\n35:06.900 --> 35:07.880\n especially if you think about\n\n35:07.880 --> 35:10.180\n how many possible images are out there\n\n35:10.180 --> 35:14.020\n and how few images the generative model sees\n\n35:14.020 --> 35:15.420\n during training.\n\n35:15.420 --> 35:16.900\n It seems just unreasonable\n\n35:16.900 --> 35:20.740\n that generative models create new images as well as they do,\n\n35:20.740 --> 35:22.700\n especially considering that we're basically\n\n35:22.700 --> 35:25.140\n training them to memorize rather than generalize.\n\n35:26.180 --> 35:28.180\n I think part of the answer is\n\n35:28.180 --> 35:30.820\n there's a paper called Deep Image Prior\n\n35:30.820 --> 35:33.060\n where they show that you can take a convolutional net\n\n35:33.060 --> 35:34.020\n and you don't even need to learn\n\n35:34.020 --> 35:34.980\n the parameters of it at all,\n\n35:34.980 --> 35:36.780\n you just use the model architecture.\n\n35:36.780 --> 35:40.260\n And it's already useful for things like inpainting images.\n\n35:40.260 --> 35:41.500\n I think that shows us\n\n35:41.500 --> 35:43.580\n that the convolutional network architecture\n\n35:43.580 --> 35:45.100\n captures something really important\n\n35:45.100 --> 35:47.180\n about the structure of images.\n\n35:47.180 --> 35:50.180\n And we don't need to actually use the learning\n\n35:50.180 --> 35:51.460\n to capture all the information\n\n35:51.460 --> 35:53.300\n coming out of the convolutional net.\n\n35:54.500 --> 35:57.660\n That would imply that it would be much harder\n\n35:57.660 --> 36:00.500\n to make generative models in other domains.\n\n36:00.500 --> 36:02.900\n So far, we're able to make reasonable speech models\n\n36:02.900 --> 36:04.100\n and things like that.\n\n36:04.100 --> 36:06.780\n But to be honest, we haven't actually explored\n\n36:06.780 --> 36:09.100\n a whole lot of different data sets all that much.\n\n36:09.100 --> 36:13.260\n We don't, for example, see a lot of deep learning models\n\n36:13.260 --> 36:17.780\n of like biology data sets\n\n36:17.780 --> 36:20.260\n where you have lots of microarrays measuring\n\n36:20.260 --> 36:22.180\n the amount of different enzymes and things like that.\n\n36:22.180 --> 36:24.620\n So we may find that some of the progress\n\n36:24.620 --> 36:26.220\n that we've seen for images and speech\n\n36:26.220 --> 36:29.460\n turns out to really rely heavily on the model architecture.\n\n36:29.460 --> 36:32.300\n And we were able to do what we did for vision\n\n36:32.300 --> 36:35.540\n by trying to reverse engineer the human visual system.\n\n36:35.540 --> 36:39.380\n And maybe it'll turn out that we can't just use\n\n36:39.380 --> 36:41.980\n that same trick for arbitrary kinds of data.\n\n36:42.860 --> 36:45.340\n Right, so there's aspect to the human vision system,\n\n36:45.340 --> 36:49.540\n the hardware of it, that makes it without learning,\n\n36:49.540 --> 36:51.980\n without cognition, just makes it really effective\n\n36:51.980 --> 36:54.340\n at detecting the patterns we see in the visual world.\n\n36:54.340 --> 36:55.180\n Yeah.\n\n36:55.180 --> 36:57.140\n Yeah, that's really interesting.\n\n36:57.140 --> 37:01.660\n What, in a big, quick overview,\n\n37:01.660 --> 37:05.740\n in your view, what types of GANs are there\n\n37:05.740 --> 37:09.540\n and what other generative models besides GANs are there?\n\n37:09.540 --> 37:12.820\n Yeah, so it's maybe a little bit easier to start\n\n37:12.820 --> 37:14.420\n with what kinds of generative models are there\n\n37:14.420 --> 37:15.340\n other than GANs.\n\n37:16.340 --> 37:20.340\n So most generative models are likelihood based\n\n37:20.340 --> 37:24.340\n where to train them, you have a model that tells you\n\n37:24.340 --> 37:28.580\n how much probability it assigns to a particular example\n\n37:28.580 --> 37:30.980\n and you just maximize the probability assigned\n\n37:30.980 --> 37:33.220\n to all the training examples.\n\n37:33.220 --> 37:35.740\n It turns out that it's hard to design a model\n\n37:35.740 --> 37:38.740\n that can create really complicated images\n\n37:38.740 --> 37:41.820\n or really complicated audio waveforms\n\n37:41.820 --> 37:45.740\n and still have it be possible to estimate\n\n37:45.740 --> 37:50.740\n the likelihood function from a computational point of view.\n\n37:51.740 --> 37:53.740\n Most interesting models that you would just write down\n\n37:53.740 --> 37:56.580\n intuitively, it turns out that it's almost impossible\n\n37:56.580 --> 37:58.980\n to calculate the amount of probability they assign\n\n37:58.980 --> 38:01.300\n to a particular point.\n\n38:01.300 --> 38:04.380\n So there's a few different schools of generative models\n\n38:04.380 --> 38:05.860\n in the likelihood family.\n\n38:07.060 --> 38:09.860\n One approach is to very carefully design the model\n\n38:09.860 --> 38:12.420\n so that it is computationally tractable\n\n38:12.420 --> 38:15.180\n to measure the density it assigns to a particular point.\n\n38:15.180 --> 38:18.780\n So there are things like autoregressive models,\n\n38:18.780 --> 38:23.580\n like PixelCNN, those basically break down\n\n38:23.580 --> 38:26.460\n the probability distribution into a product\n\n38:26.460 --> 38:28.300\n over every single feature.\n\n38:28.300 --> 38:31.180\n So for an image, you estimate the probability\n\n38:31.180 --> 38:35.420\n of each pixel given all of the pixels that came before it.\n\n38:35.420 --> 38:37.300\n There's tricks where if you want to measure\n\n38:37.300 --> 38:40.260\n the density function, you can actually calculate\n\n38:40.260 --> 38:43.140\n the density for all these pixels more or less in parallel.\n\n38:44.100 --> 38:46.500\n Generating the image still tends to require you\n\n38:46.500 --> 38:50.460\n to go one pixel at a time, and that can be very slow.\n\n38:50.460 --> 38:52.620\n But there are, again, tricks for doing this\n\n38:52.620 --> 38:54.180\n in a hierarchical pattern where you can keep\n\n38:54.180 --> 38:55.780\n the runtime under control.\n\n38:55.780 --> 38:58.340\n Are the quality of the images it generates,\n\n38:59.340 --> 39:01.660\n putting runtime aside, pretty good?\n\n39:02.660 --> 39:04.420\n They're reasonable, yeah.\n\n39:04.420 --> 39:07.460\n I would say a lot of the best results\n\n39:07.460 --> 39:11.060\n are from GANs these days, but it can be hard to tell\n\n39:11.060 --> 39:14.700\n how much of that is based on who's studying\n\n39:14.700 --> 39:17.260\n which type of algorithm, if that makes sense.\n\n39:17.260 --> 39:18.900\n The amount of effort invested in a particular.\n\n39:18.900 --> 39:21.420\n Yeah, or like the kind of expertise.\n\n39:21.420 --> 39:23.140\n So a lot of people who've traditionally been excited\n\n39:23.140 --> 39:25.060\n about graphics or art and things like that\n\n39:25.060 --> 39:27.020\n have gotten interested in GANs.\n\n39:27.020 --> 39:28.740\n And to some extent, it's hard to tell\n\n39:28.740 --> 39:31.740\n are GANs doing better because they have a lot\n\n39:31.740 --> 39:34.700\n of graphics and art experts behind them,\n\n39:34.700 --> 39:37.060\n or are GANs doing better because they're more\n\n39:37.060 --> 39:40.300\n computationally efficient, or are GANs doing better\n\n39:40.300 --> 39:43.460\n because they prioritize the realism of samples\n\n39:43.460 --> 39:45.540\n over the accuracy of the density function.\n\n39:45.540 --> 39:48.660\n I think all of those are potentially valid explanations,\n\n39:48.660 --> 39:51.300\n and it's hard to tell.\n\n39:51.300 --> 39:55.460\n So can you give a brief history of GANs from 2014?\n\n39:57.620 --> 39:59.260\n Were you paper 13?\n\n39:59.260 --> 40:00.980\n Yeah, so a few highlights.\n\n40:00.980 --> 40:03.140\n In the first paper, we just showed\n\n40:03.140 --> 40:04.740\n that GANs basically work.\n\n40:04.740 --> 40:06.620\n If you look back at the samples we had now,\n\n40:06.620 --> 40:08.820\n they look terrible.\n\n40:08.820 --> 40:10.020\n On the CIFAR 10 data set,\n\n40:10.020 --> 40:12.220\n you can't even recognize objects in them.\n\n40:12.220 --> 40:15.020\n Your paper, sorry, you used CIFAR 10?\n\n40:15.020 --> 40:18.060\n We used MNIST, which is little handwritten digits.\n\n40:18.060 --> 40:19.860\n We used the Toronto Face database,\n\n40:19.860 --> 40:22.660\n which is small grayscale photos of faces.\n\n40:22.660 --> 40:24.180\n We did have recognizable faces.\n\n40:24.180 --> 40:25.660\n My colleague Bing Xu put together\n\n40:25.660 --> 40:28.500\n the first GAN face model for that paper.\n\n40:29.660 --> 40:32.940\n We also had the CIFAR 10 data set,\n\n40:32.940 --> 40:36.060\n which is things like very small 32 by 32 pixels\n\n40:36.060 --> 40:40.660\n of cars and cats and dogs.\n\n40:40.660 --> 40:42.980\n For that, we didn't get recognizable objects,\n\n40:42.980 --> 40:46.140\n but all the deep learning people back then\n\n40:46.140 --> 40:48.380\n were really used to looking at these failed samples\n\n40:48.380 --> 40:50.420\n and kind of reading them like tea leaves.\n\n40:50.420 --> 40:53.020\n And people who are used to reading the tea leaves\n\n40:53.020 --> 40:56.500\n recognize that our tea leaves at least look different.\n\n40:56.500 --> 40:57.820\n Maybe not necessarily better,\n\n40:57.820 --> 40:59.980\n but there was something unusual about them.\n\n41:01.220 --> 41:03.620\n And that got a lot of us excited.\n\n41:03.620 --> 41:06.180\n One of the next really big steps was LAPGAN\n\n41:06.180 --> 41:10.900\n by Emily Denton and Sumit Chintala at Facebook AI Research,\n\n41:10.900 --> 41:14.460\n where they actually got really good high resolution photos\n\n41:14.460 --> 41:16.580\n working with GANs for the first time.\n\n41:16.580 --> 41:18.140\n They had a complicated system\n\n41:18.140 --> 41:20.100\n where they generated the image starting at low res\n\n41:20.100 --> 41:22.900\n and then scaling up to high res,\n\n41:22.900 --> 41:24.900\n but they were able to get it to work.\n\n41:24.900 --> 41:29.900\n And then in 2015, I believe later that same year,\n\n41:31.700 --> 41:34.940\n Alec Radford and Sumit Chintala and Luke Metz\n\n41:35.940 --> 41:38.420\n published the DCGAN paper,\n\n41:38.420 --> 41:40.980\n which it stands for deep convolutional GAN.\n\n41:41.860 --> 41:43.740\n It's kind of a non unique name\n\n41:43.740 --> 41:46.420\n because these days basically all GANs\n\n41:46.420 --> 41:48.380\n and even some before that were deep and convolutional,\n\n41:48.380 --> 41:50.220\n but they just kind of picked a name\n\n41:50.220 --> 41:52.260\n for a really great recipe\n\n41:52.260 --> 41:55.380\n where they were able to actually using only one model\n\n41:55.380 --> 41:57.300\n instead of a multi step process,\n\n41:57.300 --> 41:59.700\n actually generate realistic images of faces\n\n41:59.700 --> 42:00.740\n and things like that.\n\n42:01.980 --> 42:05.260\n That was sort of like the beginning\n\n42:05.260 --> 42:07.380\n of the Cambrian explosion of GANs.\n\n42:07.380 --> 42:09.740\n Like once you had animals that had a backbone,\n\n42:09.740 --> 42:12.900\n you suddenly got lots of different versions of fish\n\n42:12.900 --> 42:15.340\n and four legged animals and things like that.\n\n42:15.340 --> 42:17.940\n So DCGAN became kind of the backbone\n\n42:17.940 --> 42:19.420\n for many different models that came out.\n\n42:19.420 --> 42:21.620\n It's used as a baseline even still.\n\n42:21.620 --> 42:23.140\n Yeah, yeah.\n\n42:23.140 --> 42:24.820\n And so from there,\n\n42:24.820 --> 42:26.580\n I would say some interesting things we've seen\n\n42:26.580 --> 42:29.420\n are there's a lot you can say\n\n42:29.420 --> 42:30.940\n about how just the quality\n\n42:30.940 --> 42:33.580\n of standard image generation GANs has increased,\n\n42:33.580 --> 42:35.100\n but what's also maybe more interesting\n\n42:35.100 --> 42:36.020\n on an intellectual level\n\n42:36.020 --> 42:40.060\n is how the things you can use GANs for has also changed.\n\n42:41.020 --> 42:44.580\n One thing is that you can use them to learn classifiers\n\n42:44.580 --> 42:46.660\n without having to have class labels\n\n42:46.660 --> 42:48.940\n for every example in your training set.\n\n42:48.940 --> 42:51.780\n So that's called semi supervised learning.\n\n42:51.780 --> 42:53.820\n My colleague at OpenAI, Tim Solomons,\n\n42:53.820 --> 42:55.820\n who's at Brain now,\n\n42:55.820 --> 42:59.780\n wrote a paper called Improve Techniques for Training GANs.\n\n42:59.780 --> 43:00.900\n I'm a coauthor on this paper,\n\n43:00.900 --> 43:03.700\n but I can't claim any credit for this particular part.\n\n43:03.700 --> 43:04.900\n One thing he showed in the paper\n\n43:04.900 --> 43:07.820\n is that you can take the GAN discriminator\n\n43:07.820 --> 43:11.540\n and use it as a classifier that actually tells you,\n\n43:11.540 --> 43:13.620\n this image is a cat, this image is a dog,\n\n43:13.620 --> 43:16.420\n this image is a car, this image is a truck, and so on.\n\n43:16.420 --> 43:18.820\n Not just to say whether the image is real or fake,\n\n43:18.820 --> 43:20.700\n but if it is real to say specifically\n\n43:20.700 --> 43:22.620\n what kind of object it is.\n\n43:22.620 --> 43:25.340\n And he found that you can train these classifiers\n\n43:25.340 --> 43:28.580\n with far fewer labeled examples\n\n43:28.580 --> 43:30.620\n than traditional classifiers.\n\n43:30.620 --> 43:33.660\n So if you supervise based on also\n\n43:33.660 --> 43:35.300\n not just your discrimination ability,\n\n43:35.300 --> 43:36.820\n but your ability to classify,\n\n43:36.820 --> 43:38.660\n you're going to do much,\n\n43:38.660 --> 43:40.100\n you're going to converge much faster\n\n43:40.100 --> 43:43.300\n to being effective at being a discriminator.\n\n43:43.300 --> 43:44.260\n Yeah.\n\n43:44.260 --> 43:46.340\n So for example, for the MNIST dataset,\n\n43:46.340 --> 43:48.860\n you want to look at an image of a handwritten digit\n\n43:48.860 --> 43:52.700\n and say whether it's a zero, a one, or a two, and so on.\n\n43:54.180 --> 43:56.980\n To get down to less than 1% accuracy\n\n43:56.980 --> 44:00.260\n required around 60,000 examples\n\n44:00.260 --> 44:02.780\n until maybe about 2014 or so.\n\n44:02.780 --> 44:07.460\n In 2016 with this semi supervised GAN project,\n\n44:07.460 --> 44:11.060\n Tim was able to get below 1% error\n\n44:11.060 --> 44:13.620\n using only 100 labeled examples.\n\n44:13.620 --> 44:15.980\n So that was about a 600X decrease\n\n44:15.980 --> 44:17.980\n in the amount of labels that he needed.\n\n44:17.980 --> 44:21.060\n He's still using more images than that,\n\n44:21.060 --> 44:22.740\n but he doesn't need to have each of them labeled\n\n44:22.740 --> 44:25.100\n as this one's a one, this one's a two,\n\n44:25.100 --> 44:27.020\n this one's a zero, and so on.\n\n44:27.020 --> 44:28.460\n Then to be able to,\n\n44:28.460 --> 44:31.220\n for GANs to be able to generate recognizable objects,\n\n44:31.220 --> 44:33.420\n so objects from a particular class,\n\n44:33.420 --> 44:37.020\n you still need labeled data\n\n44:37.020 --> 44:38.900\n because you need to know what it means\n\n44:38.900 --> 44:41.740\n to be a particular class cat, dog.\n\n44:41.740 --> 44:44.580\n How do you think we can move away from that?\n\n44:44.580 --> 44:46.620\n Yeah, some researchers at Brain Zurich\n\n44:46.620 --> 44:49.020\n actually just released a really great paper\n\n44:49.020 --> 44:51.780\n on semi supervised GANs\n\n44:51.780 --> 44:53.940\n where their goal isn't to classify,\n\n44:53.940 --> 44:56.180\n it's to make recognizable objects\n\n44:56.180 --> 44:58.660\n despite not having a lot of labeled data.\n\n44:58.660 --> 45:02.380\n They were working off of DeepMind's BigGAN project\n\n45:02.380 --> 45:05.180\n and they showed that they can match the performance\n\n45:05.180 --> 45:08.660\n of BigGAN using only 10%, I believe,\n\n45:08.660 --> 45:10.540\n of the labels.\n\n45:10.540 --> 45:12.300\n BigGAN was trained on the ImageNet data set,\n\n45:12.300 --> 45:14.420\n which is about 1.2 million images\n\n45:14.420 --> 45:15.860\n and had all of them labeled.\n\n45:17.460 --> 45:19.060\n This latest project from Brain Zurich\n\n45:19.060 --> 45:20.220\n shows that they're able to get away\n\n45:20.220 --> 45:24.580\n with only having about 10% of the images labeled.\n\n45:25.500 --> 45:29.860\n And they do that essentially using a clustering algorithm\n\n45:29.860 --> 45:31.140\n where the discriminator learns\n\n45:31.140 --> 45:34.580\n to assign the objects to groups\n\n45:34.580 --> 45:38.220\n and then this understanding that objects can be grouped\n\n45:38.220 --> 45:43.220\n into similar types helps it to form more realistic ideas\n\n45:43.340 --> 45:45.300\n of what should be appearing in the image\n\n45:45.300 --> 45:47.860\n because it knows that every image it creates\n\n45:47.860 --> 45:50.060\n has to come from one of these archetypal groups\n\n45:50.060 --> 45:53.100\n rather than just being some arbitrary image.\n\n45:53.100 --> 45:54.980\n If you train a GAN with no class labels,\n\n45:54.980 --> 45:57.700\n you tend to get things that look sort of like grass\n\n45:57.700 --> 46:00.380\n or water or brick or dirt,\n\n46:00.380 --> 46:04.340\n but without necessarily a lot going on in them.\n\n46:04.340 --> 46:05.700\n And I think that's partly because\n\n46:05.700 --> 46:07.820\n if you look at a large ImageNet image,\n\n46:07.820 --> 46:11.180\n the object doesn't necessarily occupy the whole image.\n\n46:11.180 --> 46:15.580\n And so you learn to create realistic sets of pixels,\n\n46:15.580 --> 46:17.460\n but you don't necessarily learn\n\n46:17.460 --> 46:20.060\n that the object is the star of the show\n\n46:20.060 --> 46:22.100\n and you want it to be in every image you make.\n\n46:22.100 --> 46:25.380\n Yeah, I've heard you talk about the horse,\n\n46:25.380 --> 46:26.980\n the zebra cycle GAN mapping\n\n46:26.980 --> 46:31.900\n and how it turns out, again, thought provoking\n\n46:31.900 --> 46:33.580\n that horses are usually on grass\n\n46:33.580 --> 46:35.660\n and zebras are usually on drier terrain.\n\n46:35.660 --> 46:38.140\n So when you're doing that kind of generation,\n\n46:38.140 --> 46:41.740\n you're going to end up generating greener horses\n\n46:41.740 --> 46:45.340\n or whatever, so those are connected together.\n\n46:45.340 --> 46:49.020\n It's not just, you're not able to segment,\n\n46:49.980 --> 46:52.300\n be able to generate in a segment away.\n\n46:52.300 --> 46:54.980\n So are there other types of games you come across\n\n46:54.980 --> 46:59.540\n in your mind that neural networks can play\n\n46:59.540 --> 47:04.540\n with each other to be able to solve problems?\n\n47:04.540 --> 47:07.660\n Yeah, the one that I spend most of my time on\n\n47:07.660 --> 47:09.340\n is in security.\n\n47:09.340 --> 47:13.060\n You can model most interactions as a game\n\n47:13.060 --> 47:15.820\n where there's attackers trying to break your system\n\n47:15.820 --> 47:19.140\n and you're the defender trying to build a resilient system.\n\n47:20.140 --> 47:23.060\n There's also domain adversarial learning,\n\n47:23.060 --> 47:25.500\n which is an approach to domain adaptation\n\n47:25.500 --> 47:27.220\n that looks really a lot like GANs.\n\n47:28.100 --> 47:31.780\n The authors had the idea before the GAN paper came out,\n\n47:31.780 --> 47:33.740\n their paper came out a little bit later\n\n47:33.740 --> 47:38.220\n and they're very nice and cited the GAN paper,\n\n47:38.220 --> 47:40.180\n but I know that they actually had the idea\n\n47:40.180 --> 47:41.180\n before it came out.\n\n47:42.420 --> 47:44.300\n Domain adaptation is when you want to train\n\n47:44.300 --> 47:47.620\n a machine learning model in one setting called a domain\n\n47:47.620 --> 47:50.260\n and then deploy it in another domain later.\n\n47:50.260 --> 47:52.660\n And you would like it to perform well in the new domain,\n\n47:52.660 --> 47:53.980\n even though the new domain is different\n\n47:53.980 --> 47:55.900\n from how it was trained.\n\n47:55.900 --> 47:58.460\n So for example, you might want to train\n\n47:58.460 --> 48:01.340\n on a really clean image data set like ImageNet,\n\n48:01.340 --> 48:03.340\n but then deploy on users phones\n\n48:03.340 --> 48:05.980\n where the user is taking pictures in the dark\n\n48:05.980 --> 48:07.780\n and pictures while moving quickly\n\n48:07.780 --> 48:09.980\n and just pictures that aren't really centered\n\n48:09.980 --> 48:11.300\n or composed all that well.\n\n48:13.380 --> 48:15.820\n When you take a normal machine learning model,\n\n48:15.820 --> 48:17.820\n it often degrades really badly\n\n48:17.820 --> 48:18.980\n when you move to the new domain\n\n48:18.980 --> 48:20.020\n because it looks so different\n\n48:20.020 --> 48:22.100\n from what the model was trained on.\n\n48:22.100 --> 48:25.420\n Domain adaptation algorithms try to smooth out that gap\n\n48:25.420 --> 48:27.300\n and the domain adversarial approach\n\n48:27.300 --> 48:29.780\n is based on training a feature extractor\n\n48:29.780 --> 48:32.140\n where the features have the same statistics\n\n48:32.140 --> 48:35.140\n regardless of which domain you extracted them on.\n\n48:35.140 --> 48:36.860\n So in the domain adversarial game,\n\n48:36.860 --> 48:39.140\n you have one player that's a feature extractor\n\n48:39.140 --> 48:42.060\n and another player that's a domain recognizer.\n\n48:42.060 --> 48:44.260\n The domain recognizer wants to look at the output\n\n48:44.260 --> 48:45.700\n of the feature extractor\n\n48:45.700 --> 48:49.300\n and guess which of the two domains the features came from.\n\n48:49.300 --> 48:51.420\n So it's a lot like the real versus fake discriminator\n\n48:51.420 --> 48:54.940\n in GANs and then the feature extractor,\n\n48:54.940 --> 48:56.820\n you can think of as loosely analogous\n\n48:56.820 --> 48:57.940\n to the generator in GANs,\n\n48:57.940 --> 48:59.100\n except what it's trying to do here\n\n48:59.100 --> 49:02.460\n is both fool the domain recognizer\n\n49:02.460 --> 49:05.340\n into not knowing which domain the data came from\n\n49:05.340 --> 49:09.060\n and also extract features that are good for classification.\n\n49:09.060 --> 49:10.540\n So at the end of the day,\n\n49:12.180 --> 49:13.780\n in the cases where it works out,\n\n49:13.780 --> 49:16.860\n you can actually get features\n\n49:16.860 --> 49:20.620\n that work about the same in both domains.\n\n49:20.620 --> 49:21.980\n Sometimes this has a drawback\n\n49:21.980 --> 49:24.820\n where in order to make things work the same in both domains,\n\n49:24.820 --> 49:26.780\n it just gets worse at the first one.\n\n49:26.780 --> 49:27.820\n But there are a lot of cases\n\n49:27.820 --> 49:30.780\n where it actually works out well on both.\n\n49:30.780 --> 49:32.980\n So do you think of GANs being useful\n\n49:32.980 --> 49:35.420\n in the context of data augmentation?\n\n49:35.420 --> 49:38.100\n Yeah, one thing you could hope for with GANs\n\n49:38.100 --> 49:41.340\n is you could imagine I've got a limited training set\n\n49:41.340 --> 49:43.860\n and I'd like to make more training data\n\n49:43.860 --> 49:46.020\n to train something else like a classifier.\n\n49:47.180 --> 49:50.500\n You could train the GAN on the training set\n\n49:50.500 --> 49:52.380\n and then create more data\n\n49:52.380 --> 49:54.300\n and then maybe the classifier\n\n49:54.300 --> 49:55.940\n would perform better on the test set\n\n49:55.940 --> 49:58.860\n after training on this bigger GAN generated data set.\n\n49:58.860 --> 50:00.420\n So that's the simplest version\n\n50:00.420 --> 50:03.060\n of something you might hope would work.\n\n50:03.060 --> 50:05.460\n I've never heard of that particular approach working,\n\n50:05.460 --> 50:08.940\n but I think there's some closely related things\n\n50:08.940 --> 50:11.540\n that I think could work in the future\n\n50:11.540 --> 50:14.100\n and some that actually already have worked.\n\n50:14.100 --> 50:15.820\n So if we think a little bit about what we'd be hoping for\n\n50:15.820 --> 50:18.220\n if we use the GAN to make more training data,\n\n50:18.220 --> 50:22.060\n we're hoping that the GAN will generalize to new examples\n\n50:22.060 --> 50:24.140\n better than the classifier would have generalized\n\n50:24.140 --> 50:25.980\n if it was trained on the same data.\n\n50:25.980 --> 50:27.740\n And I don't know of any reason to believe\n\n50:27.740 --> 50:28.940\n that the GAN would generalize better\n\n50:28.940 --> 50:30.300\n than the classifier would,\n\n50:31.460 --> 50:33.100\n but what we might hope for\n\n50:33.100 --> 50:35.580\n is that the GAN could generalize differently\n\n50:35.580 --> 50:37.500\n from a specific classifier.\n\n50:37.500 --> 50:39.180\n So one thing I think is worth trying\n\n50:39.180 --> 50:41.740\n that I haven't personally tried but someone could try is\n\n50:41.740 --> 50:44.020\n what if you trained a whole lot of different\n\n50:44.020 --> 50:46.500\n generative models on the same training set,\n\n50:46.500 --> 50:48.380\n create samples from all of them\n\n50:48.380 --> 50:50.580\n and then train a classifier on that?\n\n50:50.580 --> 50:52.380\n Because each of the generative models\n\n50:52.380 --> 50:54.460\n might generalize in a slightly different way.\n\n50:54.460 --> 50:56.980\n They might capture many different axes of variation\n\n50:56.980 --> 50:58.860\n that one individual model wouldn't\n\n50:58.860 --> 51:01.900\n and then the classifier can capture all of those ideas\n\n51:01.900 --> 51:03.580\n by training in all of their data.\n\n51:03.580 --> 51:04.740\n So it'd be a little bit like making\n\n51:04.740 --> 51:06.340\n an ensemble of classifiers.\n\n51:06.340 --> 51:07.180\n And I think that...\n\n51:07.180 --> 51:08.860\n Ensemble of GANs in a way.\n\n51:08.860 --> 51:10.100\n I think that could generalize better.\n\n51:10.100 --> 51:12.700\n The other thing that GANs are really good for\n\n51:12.700 --> 51:17.020\n is not necessarily generating new data\n\n51:17.020 --> 51:19.380\n that's exactly like what you already have,\n\n51:19.380 --> 51:23.580\n but by generating new data that has different properties\n\n51:23.580 --> 51:25.340\n from the data you already had.\n\n51:25.340 --> 51:27.260\n One thing that you can do is you can create\n\n51:27.260 --> 51:29.140\n differentially private data.\n\n51:29.140 --> 51:31.900\n So suppose that you have something like medical records\n\n51:31.900 --> 51:33.860\n and you don't want to train a classifier\n\n51:33.860 --> 51:36.500\n on the medical records and then publish the classifier\n\n51:36.500 --> 51:38.180\n because someone might be able to reverse engineer\n\n51:38.180 --> 51:40.580\n some of the medical records you trained on.\n\n51:40.580 --> 51:42.820\n There's a paper from Casey Green's lab\n\n51:42.820 --> 51:45.060\n that shows how you can train a GAN\n\n51:45.060 --> 51:47.020\n using differential privacy.\n\n51:47.020 --> 51:49.020\n And then the samples from the GAN\n\n51:49.020 --> 51:51.180\n still have the same differential privacy guarantees\n\n51:51.180 --> 51:52.740\n as the parameters of the GAN.\n\n51:52.740 --> 51:55.700\n So you can make fake patient data\n\n51:55.700 --> 51:57.260\n for other researchers to use.\n\n51:57.260 --> 51:59.220\n And they can do almost anything they want with that data\n\n51:59.220 --> 52:02.020\n because it doesn't come from real people.\n\n52:02.020 --> 52:04.300\n And the differential privacy mechanism\n\n52:04.300 --> 52:06.500\n gives you clear guarantees\n\n52:06.500 --> 52:09.940\n on how much the original people's data has been protected.\n\n52:09.940 --> 52:11.380\n That's really interesting, actually.\n\n52:11.380 --> 52:13.780\n I haven't heard you talk about that before.\n\n52:13.780 --> 52:17.780\n In terms of fairness, I've seen from AAAI,\n\n52:17.780 --> 52:21.260\n your talk, how can adversarial machine learning\n\n52:21.260 --> 52:25.740\n help models be more fair with respect to sensitive variables?\n\n52:25.740 --> 52:28.460\n Yeah, so there's a paper from Amos Starkey's lab\n\n52:28.460 --> 52:31.420\n about how to learn machine learning models\n\n52:31.420 --> 52:34.820\n that are incapable of using specific variables.\n\n52:34.820 --> 52:36.700\n So say, for example, you wanted to make predictions\n\n52:36.700 --> 52:39.580\n that are not affected by gender.\n\n52:39.580 --> 52:41.220\n It isn't enough to just leave gender\n\n52:41.220 --> 52:42.820\n out of the input to the model.\n\n52:42.820 --> 52:44.020\n You can often infer gender\n\n52:44.020 --> 52:45.500\n from a lot of other characteristics.\n\n52:45.500 --> 52:47.500\n Like say that you have the person's name,\n\n52:47.500 --> 52:48.620\n but you're not told their gender.\n\n52:48.620 --> 52:51.820\n Well, if their name is Ian, they're kind of obviously a man.\n\n52:53.740 --> 52:55.660\n So what you'd like to do is make a machine learning model\n\n52:55.660 --> 52:59.020\n that can still take in a lot of different attributes\n\n52:59.020 --> 53:02.620\n and make a really accurate informed prediction,\n\n53:02.620 --> 53:05.780\n but be confident that it isn't reverse engineering gender\n\n53:05.780 --> 53:08.420\n or another sensitive variable internally.\n\n53:08.420 --> 53:10.300\n You can do that using something very similar\n\n53:10.300 --> 53:12.860\n to the domain adversarial approach,\n\n53:12.860 --> 53:16.140\n where you have one player that's a feature extractor\n\n53:16.140 --> 53:19.100\n and another player that's a feature analyzer.\n\n53:19.100 --> 53:21.460\n And you want to make sure that the feature analyzer\n\n53:21.460 --> 53:24.740\n is not able to guess the value of the sensitive variable\n\n53:24.740 --> 53:26.660\n that you're trying to keep private.\n\n53:26.660 --> 53:29.100\n Right, that's, yeah, I love this approach.\n\n53:29.100 --> 53:31.660\n So yeah, with the feature,\n\n53:31.660 --> 53:36.340\n you're not able to infer the sensitive variables.\n\n53:36.340 --> 53:39.500\n Brilliant, that's quite brilliant and simple actually.\n\n53:39.500 --> 53:42.780\n Another way I think that GANs in particular\n\n53:42.780 --> 53:44.260\n could be used for fairness\n\n53:44.260 --> 53:46.780\n would be to make something like a CycleGAN,\n\n53:46.780 --> 53:49.740\n where you can take data from one domain\n\n53:49.740 --> 53:51.180\n and convert it into another.\n\n53:51.180 --> 53:53.900\n We've seen CycleGAN turning horses into zebras.\n\n53:53.900 --> 53:58.900\n We've seen other unsupervised GANs made by Mingyu Liu\n\n53:59.260 --> 54:02.020\n doing things like turning day photos into night photos.\n\n54:03.700 --> 54:04.820\n I think for fairness,\n\n54:04.820 --> 54:08.460\n you could imagine taking records for people in one group\n\n54:08.460 --> 54:11.580\n and transforming them into analogous people in another group\n\n54:11.580 --> 54:14.980\n and testing to see if they're treated equitably\n\n54:14.980 --> 54:16.460\n across those two groups.\n\n54:16.460 --> 54:18.100\n There's a lot of things that'd be hard to get right\n\n54:18.100 --> 54:21.140\n to make sure that the conversion process itself is fair.\n\n54:21.140 --> 54:23.900\n And I don't think it's anywhere near\n\n54:23.900 --> 54:25.420\n something that we could actually use yet,\n\n54:25.420 --> 54:27.140\n but if you could design that conversion process\n\n54:27.140 --> 54:30.540\n very carefully, it might give you a way of doing audits\n\n54:30.540 --> 54:33.140\n where you say, what if we took people from this group,\n\n54:33.140 --> 54:35.460\n converted them into equivalent people in another group,\n\n54:35.460 --> 54:38.740\n does the system actually treat them how it ought to?\n\n54:38.740 --> 54:41.780\n That's also really interesting.\n\n54:41.780 --> 54:46.780\n You know, in popular press and in general,\n\n54:47.500 --> 54:49.500\n in our imagination, you think,\n\n54:49.500 --> 54:51.700\n well, GANs are able to generate data\n\n54:51.700 --> 54:54.540\n and you start to think about deep fakes\n\n54:54.540 --> 54:57.940\n or being able to sort of maliciously generate data\n\n54:57.940 --> 55:01.220\n that fakes the identity of other people.\n\n55:01.220 --> 55:03.180\n Is this something of a concern to you?\n\n55:03.180 --> 55:06.900\n Is this something, if you look 10, 20 years into the future,\n\n55:06.900 --> 55:10.380\n is that something that pops up in your work,\n\n55:10.380 --> 55:11.380\n in the work of the community\n\n55:11.380 --> 55:13.540\n that's working on generating models?\n\n55:13.540 --> 55:15.860\n I'm a lot less concerned about 20 years from now\n\n55:15.860 --> 55:17.380\n than the next few years.\n\n55:17.380 --> 55:20.820\n I think there'll be a kind of bumpy cultural transition\n\n55:20.820 --> 55:23.180\n as people encounter this idea\n\n55:23.180 --> 55:24.700\n that there can be very realistic videos\n\n55:24.700 --> 55:26.260\n and audio that aren't real.\n\n55:26.260 --> 55:28.700\n I think 20 years from now,\n\n55:28.700 --> 55:30.100\n people will mostly understand\n\n55:30.100 --> 55:31.940\n that you shouldn't believe something is real\n\n55:31.940 --> 55:34.060\n just because you saw a video of it.\n\n55:34.060 --> 55:35.220\n People will expect to see\n\n55:35.220 --> 55:37.300\n that it's been cryptographically signed\n\n55:38.220 --> 55:41.900\n or have some other mechanism to make them believe\n\n55:41.900 --> 55:44.300\n that the content is real.\n\n55:44.300 --> 55:45.700\n There's already people working on this.\n\n55:45.700 --> 55:47.660\n Like there's a startup called Truepick\n\n55:47.660 --> 55:50.180\n that provides a lot of mechanisms\n\n55:50.180 --> 55:52.780\n for authenticating that an image is real.\n\n55:52.780 --> 55:56.100\n They're maybe not quite up to having a state actor\n\n55:56.100 --> 55:59.820\n try to evade their verification techniques,\n\n55:59.820 --> 56:02.380\n but it's something that people are already working on\n\n56:02.380 --> 56:04.100\n and I think we'll get right eventually.\n\n56:04.100 --> 56:08.260\n So you think authentication will eventually win out.\n\n56:08.260 --> 56:10.700\n So being able to authenticate that this is real\n\n56:10.700 --> 56:11.860\n and this is not.\n\n56:11.860 --> 56:13.260\n Yeah.\n\n56:13.260 --> 56:15.740\n As opposed to GANs just getting better and better\n\n56:15.740 --> 56:18.180\n or generative models being able to get better and better\n\n56:18.180 --> 56:21.460\n to where the nature of what is real is normal.\n\n56:21.460 --> 56:22.940\n I don't think we'll ever be able\n\n56:22.940 --> 56:25.460\n to look at the pixels of a photo\n\n56:25.460 --> 56:28.540\n and tell you for sure that it's real or not real.\n\n56:28.540 --> 56:32.740\n And I think it would actually be somewhat dangerous\n\n56:32.740 --> 56:35.140\n to rely on that approach too much.\n\n56:35.140 --> 56:36.820\n If you make a really good fake detector\n\n56:36.820 --> 56:38.900\n and then someone's able to fool your fake detector\n\n56:38.900 --> 56:42.140\n and your fake detector says this image is not fake,\n\n56:42.140 --> 56:43.500\n then it's even more credible\n\n56:43.500 --> 56:45.060\n than if you've never made a fake detector\n\n56:45.060 --> 56:46.260\n in the first place.\n\n56:46.260 --> 56:50.380\n What I do think we'll get to is systems\n\n56:50.380 --> 56:53.300\n that we can kind of use behind the scenes\n\n56:53.300 --> 56:55.580\n to make estimates of what's going on\n\n56:55.580 --> 56:57.820\n and maybe not like use them in court\n\n56:57.820 --> 56:59.580\n for a definitive analysis.\n\n56:59.580 --> 57:04.180\n I also think we will likely get better authentication systems\n\n57:04.180 --> 57:08.500\n where, imagine that every phone cryptographically signs\n\n57:08.500 --> 57:10.540\n everything that comes out of it.\n\n57:10.540 --> 57:12.820\n You wouldn't be able to conclusively tell\n\n57:12.820 --> 57:14.540\n that an image was real,\n\n57:14.540 --> 57:17.700\n but you would be able to tell somebody\n\n57:17.700 --> 57:21.300\n who knew the appropriate private key for this phone\n\n57:21.300 --> 57:24.340\n was actually able to sign this image\n\n57:24.340 --> 57:27.460\n and upload it to this server at this timestamp.\n\n57:27.460 --> 57:31.340\n Okay, so you could imagine maybe you make phones\n\n57:31.340 --> 57:34.260\n that have the private keys hardware embedded in them.\n\n57:35.540 --> 57:37.460\n If like a state security agency\n\n57:37.460 --> 57:39.220\n really wants to infiltrate the company,\n\n57:39.220 --> 57:42.540\n they could probably plant a private key of their choice\n\n57:42.540 --> 57:45.060\n or break open the chip and learn the private key\n\n57:45.060 --> 57:46.180\n or something like that.\n\n57:46.180 --> 57:47.420\n But it would make it a lot harder\n\n57:47.420 --> 57:51.460\n for an adversary with fewer resources to fake things.\n\n57:51.460 --> 57:53.700\n For most of us it would be okay.\n\n57:53.700 --> 57:58.300\n So you mentioned the beer and the bar and the new ideas.\n\n57:58.300 --> 57:59.740\n You were able to implement this\n\n57:59.740 --> 58:02.860\n or come up with this new idea pretty quickly\n\n58:02.860 --> 58:04.380\n and implement it pretty quickly.\n\n58:04.380 --> 58:07.700\n Do you think there's still many such groundbreaking ideas\n\n58:07.700 --> 58:10.980\n in deep learning that could be developed so quickly?\n\n58:10.980 --> 58:12.980\n Yeah, I do think that there are a lot of ideas\n\n58:12.980 --> 58:14.820\n that can be developed really quickly.\n\n58:15.940 --> 58:17.820\n GANs were probably a little bit of an outlier\n\n58:17.820 --> 58:20.180\n on the whole like one hour timescale.\n\n58:20.180 --> 58:24.220\n But just in terms of like low resource ideas\n\n58:24.220 --> 58:25.540\n where you do something really different\n\n58:25.540 --> 58:28.780\n on the algorithm scale and get a big payback.\n\n58:30.140 --> 58:31.900\n I think it's not as likely that you'll see that\n\n58:31.900 --> 58:34.940\n in terms of things like core machine learning technologies\n\n58:34.940 --> 58:36.580\n like a better classifier\n\n58:36.580 --> 58:38.180\n or a better reinforcement learning algorithm\n\n58:38.180 --> 58:39.580\n or a better generative model.\n\n58:41.020 --> 58:42.420\n If I had the GAN idea today,\n\n58:42.420 --> 58:45.260\n it would be a lot harder to prove that it was useful\n\n58:45.260 --> 58:46.940\n than it was back in 2014\n\n58:46.940 --> 58:49.540\n because I would need to get it running\n\n58:49.540 --> 58:54.060\n on something like ImageNet or Celeb A at high resolution.\n\n58:54.060 --> 58:55.540\n You know, those take a while to train.\n\n58:55.540 --> 58:57.580\n You couldn't train it in an hour\n\n58:57.580 --> 59:01.020\n and know that it was something really new and exciting.\n\n59:01.020 --> 59:03.260\n Back in 2014, training on MNIST was enough.\n\n59:04.260 --> 59:06.780\n But there are other areas of machine learning\n\n59:06.780 --> 59:09.380\n where I think a new idea\n\n59:09.380 --> 59:11.940\n could actually be developed really quickly\n\n59:11.940 --> 59:13.260\n with low resources.\n\n59:13.260 --> 59:15.420\n What's your intuition about what areas\n\n59:15.420 --> 59:17.740\n of machine learning are ripe for this?\n\n59:17.740 --> 59:22.740\n Yeah, so I think fairness and interpretability\n\n59:23.140 --> 59:27.020\n are areas where we just really don't have any idea\n\n59:27.020 --> 59:29.020\n how anything should be done yet.\n\n59:29.020 --> 59:30.340\n Like for interpretability,\n\n59:30.340 --> 59:32.700\n I don't think we even have the right definitions.\n\n59:32.700 --> 59:36.060\n And even just defining a really useful concept,\n\n59:36.060 --> 59:38.100\n you don't even need to run any experiments,\n\n59:38.100 --> 59:40.100\n could have a huge impact on the field.\n\n59:40.100 --> 59:42.540\n We've seen that, for example, in differential privacy\n\n59:42.540 --> 59:45.300\n that Cynthia Dwork and her collaborators\n\n59:45.300 --> 59:48.020\n made this technical definition of privacy\n\n59:48.020 --> 59:50.020\n where before a lot of things were really mushy.\n\n59:50.020 --> 59:51.580\n And then with that definition,\n\n59:51.580 --> 59:54.220\n you could actually design randomized algorithms\n\n59:54.220 --> 59:56.180\n for accessing databases and guarantee\n\n59:56.180 --> 59:58.820\n that they preserved individual people's privacy\n\n59:58.820 --> 1:00:01.780\n in like a mathematical quantitative sense.\n\n1:00:03.460 --> 1:00:05.060\n Right now, we all talk a lot about\n\n1:00:05.060 --> 1:00:07.540\n how interpretable different machine learning algorithms are,\n\n1:00:07.540 --> 1:00:09.820\n but it's really just people's opinion.\n\n1:00:09.820 --> 1:00:11.300\n And everybody probably has a different idea\n\n1:00:11.300 --> 1:00:13.820\n of what interpretability means in their head.\n\n1:00:13.820 --> 1:00:16.940\n If we could define some concept related to interpretability\n\n1:00:16.940 --> 1:00:18.700\n that's actually measurable,\n\n1:00:18.700 --> 1:00:20.540\n that would be a huge leap forward\n\n1:00:20.540 --> 1:00:24.140\n even without a new algorithm that increases that quantity.\n\n1:00:24.140 --> 1:00:28.740\n And also once we had the definition of differential privacy,\n\n1:00:28.740 --> 1:00:31.340\n it was fast to get the algorithms that guaranteed it.\n\n1:00:31.340 --> 1:00:33.500\n So you could imagine once we have definitions\n\n1:00:33.500 --> 1:00:35.700\n of good concepts and interpretability,\n\n1:00:35.700 --> 1:00:37.540\n we might be able to provide the algorithms\n\n1:00:37.540 --> 1:00:40.500\n that have the interpretability guarantees quickly too.\n\n1:00:40.500 --> 1:00:45.500\n So what do you think it takes to build a system\n\n1:00:46.900 --> 1:00:48.660\n with human level intelligence\n\n1:00:48.660 --> 1:00:51.980\n as we quickly venture into the philosophical?\n\n1:00:51.980 --> 1:00:55.660\n So artificial general intelligence, what do you think it takes?\n\n1:00:55.660 --> 1:01:00.660\n I think that it definitely takes better environments\n\n1:01:01.820 --> 1:01:03.780\n than we currently have for training agents\n\n1:01:03.780 --> 1:01:05.260\n that we want them to have\n\n1:01:05.260 --> 1:01:08.740\n a really wide diversity of experiences.\n\n1:01:08.740 --> 1:01:11.780\n I also think it's gonna take really a lot of computation.\n\n1:01:11.780 --> 1:01:13.780\n It's hard to imagine exactly how much.\n\n1:01:13.780 --> 1:01:16.300\n So you're optimistic about simulation,\n\n1:01:16.300 --> 1:01:19.540\n simulating a variety of environments as the path forward?\n\n1:01:19.540 --> 1:01:21.980\n I think it's a necessary ingredient.\n\n1:01:21.980 --> 1:01:24.700\n Yeah, I don't think that we're going to get\n\n1:01:24.700 --> 1:01:27.340\n to artificial general intelligence\n\n1:01:27.340 --> 1:01:29.700\n by training on fixed data sets\n\n1:01:29.700 --> 1:01:32.100\n or by thinking really hard about the problem.\n\n1:01:32.100 --> 1:01:35.860\n I think that the agent really needs to interact\n\n1:01:35.860 --> 1:01:40.860\n and have a variety of experiences within the same lifespan.\n\n1:01:41.580 --> 1:01:44.100\n And today we have many different models\n\n1:01:44.100 --> 1:01:45.700\n that can each do one thing.\n\n1:01:45.700 --> 1:01:47.500\n And we tend to train them on one data set\n\n1:01:47.500 --> 1:01:48.940\n or one RL environment.\n\n1:01:50.100 --> 1:01:51.380\n Sometimes there are actually papers\n\n1:01:51.380 --> 1:01:54.180\n about getting one set of parameters to perform well\n\n1:01:54.180 --> 1:01:56.980\n in many different RL environments.\n\n1:01:56.980 --> 1:01:59.500\n But we don't really have anything like an agent\n\n1:01:59.500 --> 1:02:02.900\n that goes seamlessly from one type of experience to another\n\n1:02:02.900 --> 1:02:05.260\n and really integrates all the different things\n\n1:02:05.260 --> 1:02:08.020\n that it does over the course of its life.\n\n1:02:08.020 --> 1:02:10.580\n When we do see multi agent environments,\n\n1:02:10.580 --> 1:02:12.340\n they tend to be,\n\n1:02:12.340 --> 1:02:14.660\n or so many multi environment agents,\n\n1:02:14.660 --> 1:02:16.740\n they tend to be similar environments.\n\n1:02:16.740 --> 1:02:20.420\n Like all of them are playing like an action based video game.\n\n1:02:20.420 --> 1:02:23.220\n We don't really have an agent that goes from\n\n1:02:23.220 --> 1:02:27.500\n playing a video game to like reading the Wall Street Journal\n\n1:02:27.500 --> 1:02:31.260\n to predicting how effective a molecule will be as a drug\n\n1:02:31.260 --> 1:02:33.260\n or something like that.\n\n1:02:33.260 --> 1:02:35.940\n What do you think is a good test for intelligence\n\n1:02:35.940 --> 1:02:37.020\n in your view?\n\n1:02:37.020 --> 1:02:40.300\n There's been a lot of benchmarks started with the,\n\n1:02:40.300 --> 1:02:41.700\n with Alan Turing,\n\n1:02:41.700 --> 1:02:46.260\n natural conversation being a good benchmark for intelligence.\n\n1:02:46.260 --> 1:02:51.260\n What would Ian Goodfellow sit back\n\n1:02:51.340 --> 1:02:53.380\n and be really damn impressed\n\n1:02:53.380 --> 1:02:56.060\n if a system was able to accomplish?\n\n1:02:56.060 --> 1:02:58.500\n Something that doesn't take a lot of glue\n\n1:02:58.500 --> 1:02:59.780\n from human engineers.\n\n1:02:59.780 --> 1:03:03.540\n So imagine that instead of having to\n\n1:03:03.540 --> 1:03:07.940\n go to the CIFAR website and download CIFAR 10\n\n1:03:07.940 --> 1:03:11.300\n and then write a Python script to parse it and all that,\n\n1:03:11.300 --> 1:03:16.300\n you could just point an agent at the CIFAR 10 problem\n\n1:03:16.460 --> 1:03:19.180\n and it downloads and extracts the data\n\n1:03:19.180 --> 1:03:22.420\n and trains a model and starts giving you predictions.\n\n1:03:22.420 --> 1:03:25.980\n I feel like something that doesn't need to have\n\n1:03:25.980 --> 1:03:28.620\n every step of the pipeline assembled for it,\n\n1:03:28.620 --> 1:03:30.460\n definitely understands what it's doing.\n\n1:03:30.460 --> 1:03:32.380\n Is AutoML moving into that direction\n\n1:03:32.380 --> 1:03:34.380\n or are you thinking way even bigger?\n\n1:03:34.380 --> 1:03:37.220\n AutoML has mostly been moving toward,\n\n1:03:38.180 --> 1:03:39.900\n once we've built all the glue,\n\n1:03:39.900 --> 1:03:42.180\n can the machine learning system\n\n1:03:42.180 --> 1:03:44.340\n design the architecture really well?\n\n1:03:44.340 --> 1:03:46.100\n And so I'm more of saying like,\n\n1:03:47.260 --> 1:03:49.580\n if something knows how to pre process the data\n\n1:03:49.580 --> 1:03:52.340\n so that it successfully accomplishes the task,\n\n1:03:52.340 --> 1:03:53.460\n then it would be very hard to argue\n\n1:03:53.460 --> 1:03:56.180\n that it doesn't truly understand the task\n\n1:03:56.180 --> 1:03:58.460\n in some fundamental sense.\n\n1:03:58.460 --> 1:04:00.020\n And I don't necessarily know that that's like\n\n1:04:00.020 --> 1:04:02.260\n the philosophical definition of intelligence,\n\n1:04:02.260 --> 1:04:03.780\n but that's something that would be really cool to build\n\n1:04:03.780 --> 1:04:05.580\n that would be really useful and would impress me\n\n1:04:05.580 --> 1:04:08.180\n and would convince me that we've made a step forward\n\n1:04:08.180 --> 1:04:09.420\n in real AI.\n\n1:04:09.420 --> 1:04:13.380\n So you give it like the URL for Wikipedia\n\n1:04:13.380 --> 1:04:18.380\n and then next day expect it to be able to solve CIFAR 10.\n\n1:04:18.700 --> 1:04:20.820\n Or like you type in a paragraph\n\n1:04:20.820 --> 1:04:22.180\n explaining what you want it to do\n\n1:04:22.180 --> 1:04:24.780\n and it figures out what web searches it should run\n\n1:04:24.780 --> 1:04:28.300\n and downloads all the necessary ingredients.\n\n1:04:28.300 --> 1:04:33.300\n So you have a very clear, calm way of speaking,\n\n1:04:34.780 --> 1:04:37.580\n no ums, easy to edit.\n\n1:04:37.580 --> 1:04:40.220\n I've seen comments for both you and I\n\n1:04:40.220 --> 1:04:44.180\n have been identified as both potentially being robots.\n\n1:04:44.180 --> 1:04:47.220\n If you have to prove to the world that you are indeed human,\n\n1:04:47.220 --> 1:04:48.580\n how would you do it?\n\n1:04:48.580 --> 1:04:53.060\n I can understand thinking that I'm a robot.\n\n1:04:55.300 --> 1:04:57.780\n It's the flip side of the Turing test, I think.\n\n1:04:57.780 --> 1:05:00.420\n Yeah, yeah, the prove your human test.\n\n1:05:01.900 --> 1:05:04.460\n Intellectually, so you have to...\n\n1:05:04.460 --> 1:05:08.620\n Is there something that's truly unique in your mind?\n\n1:05:08.620 --> 1:05:11.620\n Does it go back to just natural language again?\n\n1:05:11.620 --> 1:05:13.860\n Just being able to talk the way out of it.\n\n1:05:13.860 --> 1:05:17.060\n Proving that I'm not a robot with today's technology.\n\n1:05:17.060 --> 1:05:18.340\n Yeah, that's pretty straightforward.\n\n1:05:18.340 --> 1:05:20.780\n Like my conversation today hasn't veered off\n\n1:05:20.780 --> 1:05:24.380\n into talking about the stock market or something\n\n1:05:24.380 --> 1:05:25.940\n because of my training data.\n\n1:05:25.940 --> 1:05:28.060\n But I guess more generally trying to prove\n\n1:05:28.060 --> 1:05:30.500\n that something is real from the content alone\n\n1:05:30.500 --> 1:05:31.380\n is incredibly hard.\n\n1:05:31.380 --> 1:05:32.460\n That's one of the main things I've gotten\n\n1:05:32.460 --> 1:05:33.460\n out of my GAN research,\n\n1:05:33.460 --> 1:05:37.660\n that you can simulate almost anything.\n\n1:05:37.660 --> 1:05:41.020\n And so you have to really step back to a separate channel\n\n1:05:41.020 --> 1:05:42.220\n to prove that something is real.\n\n1:05:42.220 --> 1:05:45.100\n So like, I guess I should have had myself\n\n1:05:45.100 --> 1:05:47.660\n stamped on a blockchain when I was born or something,\n\n1:05:47.660 --> 1:05:48.580\n but I didn't do that.\n\n1:05:48.580 --> 1:05:50.780\n So according to my own research methodology,\n\n1:05:50.780 --> 1:05:52.940\n there's just no way to know at this point.\n\n1:05:52.940 --> 1:05:56.300\n So what, last question, problem stands out for you\n\n1:05:56.300 --> 1:05:58.340\n that you're really excited about challenging\n\n1:05:58.340 --> 1:05:59.900\n in the near future?\n\n1:05:59.900 --> 1:06:02.900\n So I think resistance to adversarial examples,\n\n1:06:02.900 --> 1:06:05.500\n figuring out how to make machine learning secure\n\n1:06:05.500 --> 1:06:07.380\n against an adversary who wants to interfere\n\n1:06:07.380 --> 1:06:10.660\n and control it, that is one of the most important things\n\n1:06:10.660 --> 1:06:12.140\n researchers today could solve.\n\n1:06:12.140 --> 1:06:17.140\n In all domains, image, language, driving, and everything.\n\n1:06:17.700 --> 1:06:19.780\n I guess I'm most concerned about domains\n\n1:06:19.780 --> 1:06:21.980\n we haven't really encountered yet.\n\n1:06:21.980 --> 1:06:24.020\n Like imagine 20 years from now,\n\n1:06:24.020 --> 1:06:26.820\n when we're using advanced AIs to do things\n\n1:06:26.820 --> 1:06:28.940\n we haven't even thought of yet.\n\n1:06:28.940 --> 1:06:30.620\n Like if you ask people,\n\n1:06:30.620 --> 1:06:35.100\n what are the important problems in security of phones\n\n1:06:35.100 --> 1:06:37.620\n in like 2002?\n\n1:06:37.620 --> 1:06:38.900\n I don't think we would have anticipated\n\n1:06:38.900 --> 1:06:42.140\n that we're using them for nearly as many things\n\n1:06:42.140 --> 1:06:43.620\n as we're using them for today.\n\n1:06:43.620 --> 1:06:44.860\n I think it's gonna be like that with AI\n\n1:06:44.860 --> 1:06:46.900\n that you can kind of try to speculate\n\n1:06:46.900 --> 1:06:47.900\n about where it's going,\n\n1:06:47.900 --> 1:06:49.580\n but really the business opportunities\n\n1:06:49.580 --> 1:06:52.100\n that end up taking off would be hard\n\n1:06:52.100 --> 1:06:54.140\n to predict ahead of time.\n\n1:06:54.140 --> 1:06:55.300\n What you can predict ahead of time\n\n1:06:55.300 --> 1:06:58.340\n is that almost anything you can do with machine learning,\n\n1:06:58.340 --> 1:06:59.420\n you would like to make sure\n\n1:06:59.420 --> 1:07:03.100\n that people can't get it to do what they want\n\n1:07:03.100 --> 1:07:04.580\n rather than what you want,\n\n1:07:04.580 --> 1:07:06.460\n just by showing it a funny QR code\n\n1:07:06.460 --> 1:07:08.460\n or a funny input pattern.\n\n1:07:08.460 --> 1:07:10.980\n And you think that the set of methodology to do that\n\n1:07:10.980 --> 1:07:13.140\n can be bigger than any one domain?\n\n1:07:13.140 --> 1:07:14.140\n I think so, yeah.\n\n1:07:14.140 --> 1:07:19.140\n Yeah, like one methodology that I think is,\n\n1:07:19.140 --> 1:07:20.620\n not a specific methodology,\n\n1:07:20.620 --> 1:07:22.740\n but like a category of solutions\n\n1:07:22.740 --> 1:07:25.660\n that I'm excited about today is making dynamic models\n\n1:07:25.660 --> 1:07:28.180\n that change every time they make a prediction.\n\n1:07:28.180 --> 1:07:31.100\n So right now we tend to train models\n\n1:07:31.100 --> 1:07:33.060\n and then after they're trained, we freeze them\n\n1:07:33.060 --> 1:07:35.180\n and we just use the same rule\n\n1:07:35.180 --> 1:07:38.180\n to classify everything that comes in from then on.\n\n1:07:38.180 --> 1:07:41.500\n That's really a sitting duck from a security point of view.\n\n1:07:41.500 --> 1:07:45.420\n If you always output the same answer for the same input,\n\n1:07:45.420 --> 1:07:48.220\n then people can just run inputs through\n\n1:07:48.220 --> 1:07:50.140\n until they find a mistake that benefits them.\n\n1:07:50.140 --> 1:07:51.700\n And then they use the same mistake\n\n1:07:51.700 --> 1:07:53.100\n over and over and over again.\n\n1:07:54.020 --> 1:07:56.460\n I think having a model that updates its predictions\n\n1:07:56.460 --> 1:08:00.340\n so that it's harder to predict what you're gonna get\n\n1:08:00.340 --> 1:08:02.740\n will make it harder for an adversary\n\n1:08:02.740 --> 1:08:04.820\n to really take control of the system\n\n1:08:04.820 --> 1:08:06.100\n and make it do what they want it to do.\n\n1:08:06.100 --> 1:08:09.740\n Yeah, models that maintain a bit of a sense of mystery\n\n1:08:09.740 --> 1:08:12.740\n about them, because they always keep changing.\n\n1:08:12.740 --> 1:08:14.900\n Ian, thanks so much for talking today, it was awesome.\n\n1:08:14.900 --> 1:08:19.900\n Thank you for coming in, it's great to see you.\n\n"
}
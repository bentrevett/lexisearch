{
  "title": "Fran\u00e7ois Chollet: Measures of Intelligence | Lex Fridman Podcast #120",
  "id": "PUAdj3w3wO4",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:03.220\n The following is a conversation with Francois Chollet,\n\n00:03.220 --> 00:05.260\n his second time on the podcast.\n\n00:05.260 --> 00:09.580\n He's both a world class engineer and a philosopher\n\n00:09.580 --> 00:13.180\n in the realm of deep learning and artificial intelligence.\n\n00:13.180 --> 00:16.200\n This time, we talk a lot about his paper titled\n\n00:16.200 --> 00:19.040\n on the measure of intelligence that discusses\n\n00:19.040 --> 00:22.440\n how we might define and measure general intelligence\n\n00:22.440 --> 00:24.640\n in our computing machinery.\n\n00:24.640 --> 00:26.420\n Quick summary of the sponsors,\n\n00:26.420 --> 00:29.460\n Babbel, Masterclass, and Cash App.\n\n00:29.460 --> 00:31.240\n Click the sponsor links in the description\n\n00:31.240 --> 00:34.500\n to get a discount and to support this podcast.\n\n00:34.500 --> 00:36.880\n As a side note, let me say that the serious,\n\n00:36.880 --> 00:38.720\n rigorous scientific study\n\n00:38.720 --> 00:42.220\n of artificial general intelligence is a rare thing.\n\n00:42.220 --> 00:44.080\n The mainstream machine learning community works\n\n00:44.080 --> 00:47.740\n on very narrow AI with very narrow benchmarks.\n\n00:47.740 --> 00:49.920\n This is very good for incremental\n\n00:49.920 --> 00:53.200\n and sometimes big incremental progress.\n\n00:53.200 --> 00:56.060\n On the other hand, the outside the mainstream,\n\n00:56.060 --> 01:00.020\n renegade, you could say, AGI community works\n\n01:00.020 --> 01:03.000\n on approaches that verge on the philosophical\n\n01:03.000 --> 01:07.300\n and even the literary without big public benchmarks.\n\n01:07.300 --> 01:10.640\n Walking the line between the two worlds is a rare breed,\n\n01:10.640 --> 01:12.360\n but it doesn't have to be.\n\n01:12.360 --> 01:15.320\n I ran the AGI series at MIT as an attempt\n\n01:15.320 --> 01:17.700\n to inspire more people to walk this line.\n\n01:17.700 --> 01:20.020\n Deep mind and open AI for a time\n\n01:20.020 --> 01:23.180\n and still on occasion walk this line.\n\n01:23.180 --> 01:25.860\n Francois Chollet does as well.\n\n01:25.860 --> 01:27.620\n I hope to also.\n\n01:27.620 --> 01:29.880\n It's a beautiful dream to work towards\n\n01:29.880 --> 01:32.480\n and to make real one day.\n\n01:32.480 --> 01:34.580\n If you enjoy this thing, subscribe on YouTube,\n\n01:34.580 --> 01:36.760\n review it with five stars on Apple Podcast,\n\n01:36.760 --> 01:39.020\n follow on Spotify, support on Patreon,\n\n01:39.020 --> 01:42.020\n or connect with me on Twitter at Lex Friedman.\n\n01:42.020 --> 01:44.240\n As usual, I'll do a few minutes of ads now\n\n01:44.240 --> 01:45.780\n and no ads in the middle.\n\n01:45.780 --> 01:47.440\n I try to make these interesting,\n\n01:47.440 --> 01:50.620\n but I give you timestamps so you can skip.\n\n01:50.620 --> 01:52.660\n But still, please do check out the sponsors\n\n01:52.660 --> 01:54.580\n by clicking the links in the description.\n\n01:54.580 --> 01:57.900\n It's the best way to support this podcast.\n\n01:57.900 --> 02:00.100\n This show is sponsored by Babbel,\n\n02:00.100 --> 02:02.460\n an app and website that gets you speaking\n\n02:02.460 --> 02:04.360\n in a new language within weeks.\n\n02:04.360 --> 02:08.200\n Go to babbel.com and use code Lex to get three months free.\n\n02:08.200 --> 02:11.460\n They offer 14 languages, including Spanish, French,\n\n02:11.460 --> 02:15.220\n Italian, German, and yes, Russian.\n\n02:15.220 --> 02:17.340\n Daily lessons are 10 to 15 minutes,\n\n02:17.340 --> 02:19.060\n super easy, effective,\n\n02:19.060 --> 02:22.240\n designed by over 100 language experts.\n\n02:22.240 --> 02:24.700\n Let me read a few lines from the Russian poem\n\n02:24.700 --> 02:29.020\n Noch, ulitsa, fanar, apteka, by Alexander Bloch,\n\n02:29.020 --> 02:32.580\n that you'll start to understand if you sign up to Babbel.\n\n02:32.580 --> 02:35.220\n Noch, ulitsa, fanar, apteka,\n\n02:35.220 --> 02:38.100\n Bessmysliny, ituskly, svet,\n\n02:38.100 --> 02:41.140\n Zhevi esho, khod chetvert veka,\n\n02:41.140 --> 02:44.700\n Vse budet tak, ishoda, net.\n\n02:44.700 --> 02:48.500\n Now, I say that you'll start to understand this poem\n\n02:48.500 --> 02:51.420\n because Russian starts with a language\n\n02:51.420 --> 02:54.020\n and ends with vodka.\n\n02:54.020 --> 02:56.600\n Now, the latter part is definitely not endorsed\n\n02:56.600 --> 02:58.020\n or provided by Babbel.\n\n02:58.020 --> 03:00.340\n It will probably lose me this sponsorship,\n\n03:00.340 --> 03:02.460\n although it hasn't yet.\n\n03:02.460 --> 03:04.460\n But once you graduate with Babbel,\n\n03:04.460 --> 03:06.120\n you can enroll in my advanced course\n\n03:06.120 --> 03:09.200\n of late night Russian conversation over vodka.\n\n03:09.200 --> 03:11.260\n No app for that yet.\n\n03:11.260 --> 03:13.740\n So get started by visiting babbel.com\n\n03:13.740 --> 03:17.080\n and use code Lex to get three months free.\n\n03:18.180 --> 03:20.980\n This show is also sponsored by Masterclass.\n\n03:20.980 --> 03:23.380\n Sign up at masterclass.com slash Lex\n\n03:23.380 --> 03:26.580\n to get a discount and to support this podcast.\n\n03:26.580 --> 03:28.060\n When I first heard about Masterclass,\n\n03:28.060 --> 03:29.980\n I thought it was too good to be true.\n\n03:29.980 --> 03:32.340\n I still think it's too good to be true.\n\n03:32.340 --> 03:35.420\n For $180 a year, you get an all access pass\n\n03:35.420 --> 03:38.740\n to watch courses from, to list some of my favorites.\n\n03:38.740 --> 03:41.340\n Chris Hatfield on space exploration,\n\n03:41.340 --> 03:43.500\n hope to have him in this podcast one day.\n\n03:43.500 --> 03:46.660\n Neil Dugras Tyson on scientific thinking and communication,\n\n03:46.660 --> 03:47.900\n Neil too.\n\n03:47.900 --> 03:50.140\n Will Wright, creator of SimCity and Sims\n\n03:50.140 --> 03:52.780\n on game design, Carlos Santana on guitar,\n\n03:52.780 --> 03:55.980\n Kary Kasparov on chess, Daniel Nagrano on poker,\n\n03:55.980 --> 03:57.240\n and many more.\n\n03:57.240 --> 03:59.700\n Chris Hatfield explaining how rockets work\n\n03:59.700 --> 04:01.740\n and the experience of being watched at the space\n\n04:01.740 --> 04:03.300\n alone is worth the money.\n\n04:03.300 --> 04:06.540\n By the way, you can watch it on basically any device.\n\n04:06.540 --> 04:09.380\n Once again, sign up at masterclass.com slash Lex\n\n04:09.380 --> 04:12.460\n to get a discount and to support this podcast.\n\n04:13.340 --> 04:16.460\n This show finally is presented by Cash App,\n\n04:16.460 --> 04:18.720\n the number one finance app in the App Store.\n\n04:18.720 --> 04:21.220\n When you get it, use code LexPodcast.\n\n04:21.220 --> 04:23.300\n Cash App lets you send money to friends,\n\n04:23.300 --> 04:25.460\n buy Bitcoin, and invest in the stock market\n\n04:25.460 --> 04:27.260\n with as little as $1.\n\n04:27.260 --> 04:28.980\n Since Cash App allows you to send\n\n04:28.980 --> 04:30.540\n and receive money digitally,\n\n04:30.540 --> 04:33.860\n let me mention a surprising fact related to physical money.\n\n04:33.860 --> 04:35.700\n Of all the currency in the world,\n\n04:35.700 --> 04:39.300\n roughly 8% of it is actually physical money.\n\n04:39.300 --> 04:42.820\n The other 92% of the money only exists digitally,\n\n04:42.820 --> 04:45.280\n and that's only going to increase.\n\n04:45.280 --> 04:47.400\n So again, if you get Cash App from the App Store\n\n04:47.400 --> 04:50.660\n through Google Play and use code LexPodcast,\n\n04:50.660 --> 04:51.740\n you get 10 bucks,\n\n04:51.740 --> 04:54.420\n and Cash App will also donate $10 to FIRST,\n\n04:54.420 --> 04:57.000\n an organization that is helping to advance robotics\n\n04:57.000 --> 05:00.500\n and STEM education for young people around the world.\n\n05:00.500 --> 05:03.900\n And now here's my conversation with Francois Chalet.\n\n05:05.060 --> 05:07.360\n What philosophers, thinkers, or ideas\n\n05:07.360 --> 05:10.700\n had a big impact on you growing up and today?\n\n05:10.700 --> 05:14.860\n So one author that had a big impact on me\n\n05:14.860 --> 05:18.820\n when I read his books as a teenager was Jean Piaget,\n\n05:18.820 --> 05:21.380\n who is a Swiss psychologist,\n\n05:21.380 --> 05:25.540\n is considered to be the father of developmental psychology.\n\n05:25.540 --> 05:27.620\n And he has a large body of work about\n\n05:28.700 --> 05:33.380\n basically how intelligence develops in children.\n\n05:33.380 --> 05:35.500\n And so it's very old work,\n\n05:35.500 --> 05:39.140\n like most of it is from the 1930s, 1940s.\n\n05:39.140 --> 05:40.900\n So it's not quite up to date.\n\n05:40.900 --> 05:43.820\n It's actually superseded by many newer developments\n\n05:43.820 --> 05:45.660\n in developmental psychology.\n\n05:45.660 --> 05:49.600\n But to me, it was very interesting, very striking,\n\n05:49.600 --> 05:51.340\n and actually shaped the early ways\n\n05:51.340 --> 05:53.820\n in which I started thinking about the mind\n\n05:53.820 --> 05:56.220\n and the development of intelligence as a teenager.\n\n05:56.220 --> 05:58.460\n His actual ideas or the way he thought about it\n\n05:58.460 --> 05:59.840\n or just the fact that you could think\n\n05:59.840 --> 06:01.600\n about the developing mind at all?\n\n06:01.600 --> 06:02.500\n I guess both.\n\n06:02.500 --> 06:04.940\n Jean Piaget is the author that really introduced me\n\n06:04.940 --> 06:07.980\n to the notion that intelligence and the mind\n\n06:07.980 --> 06:11.120\n is something that you construct throughout your life\n\n06:11.120 --> 06:15.780\n and that children construct it in stages.\n\n06:15.780 --> 06:17.460\n And I thought that was a very interesting idea,\n\n06:17.460 --> 06:20.460\n which is, of course, very relevant to AI,\n\n06:20.460 --> 06:22.020\n to building artificial minds.\n\n06:23.180 --> 06:25.860\n Another book that I read around the same time\n\n06:25.860 --> 06:27.260\n that had a big impact on me,\n\n06:28.900 --> 06:32.100\n and there was actually a little bit of overlap\n\n06:32.100 --> 06:32.980\n with Jean Piaget as well,\n\n06:32.980 --> 06:35.340\n and I read it around the same time,\n\n06:35.340 --> 06:39.860\n is Geoff Hawking's On Intelligence, which is a classic.\n\n06:39.860 --> 06:42.500\n And he has this vision of the mind\n\n06:42.500 --> 06:47.500\n as a multi scale hierarchy of temporal prediction modules.\n\n06:47.820 --> 06:50.020\n And these ideas really resonated with me,\n\n06:50.020 --> 06:53.940\n like the notion of a modular hierarchy\n\n06:55.440 --> 07:00.100\n of potentially compression functions\n\n07:00.100 --> 07:01.700\n or prediction functions.\n\n07:01.700 --> 07:03.980\n I thought it was really, really interesting,\n\n07:03.980 --> 07:07.100\n and it shaped the way I started thinking\n\n07:07.100 --> 07:09.760\n about how to build minds.\n\n07:09.760 --> 07:13.740\n The hierarchical nature, which aspect?\n\n07:13.740 --> 07:17.520\n Also, he's a neuroscientist, so he was thinking actual,\n\n07:17.520 --> 07:20.580\n he was basically talking about how our mind works.\n\n07:20.580 --> 07:23.260\n Yeah, the notion that cognition is prediction\n\n07:23.260 --> 07:25.460\n was an idea that was kind of new to me at the time\n\n07:25.460 --> 07:27.840\n and that I really loved at the time.\n\n07:27.840 --> 07:31.900\n And yeah, and the notion that there are multiple scales\n\n07:31.900 --> 07:34.020\n of processing in the brain.\n\n07:35.320 --> 07:36.260\n The hierarchy.\n\n07:36.260 --> 07:37.100\n Yes.\n\n07:37.100 --> 07:38.600\n This was before deep learning.\n\n07:38.600 --> 07:41.140\n These ideas of hierarchies in AI\n\n07:41.140 --> 07:43.180\n have been around for a long time,\n\n07:43.180 --> 07:45.020\n even before on intelligence.\n\n07:45.020 --> 07:47.100\n They've been around since the 1980s.\n\n07:48.980 --> 07:50.500\n And yeah, that was before deep learning.\n\n07:50.500 --> 07:53.500\n But of course, I think these ideas really found\n\n07:53.500 --> 07:58.100\n their practical implementation in deep learning.\n\n07:58.100 --> 07:59.740\n What about the memory side of things?\n\n07:59.740 --> 08:02.860\n I think he was talking about knowledge representation.\n\n08:02.860 --> 08:04.420\n Do you think about memory a lot?\n\n08:04.420 --> 08:06.340\n One way you can think of neural networks\n\n08:06.340 --> 08:10.780\n as a kind of memory, you're memorizing things,\n\n08:10.780 --> 08:14.260\n but it doesn't seem to be the kind of memory\n\n08:14.260 --> 08:15.980\n that's in our brains,\n\n08:16.880 --> 08:18.660\n or it doesn't have the same rich complexity,\n\n08:18.660 --> 08:20.660\n long term nature that's in our brains.\n\n08:20.660 --> 08:23.980\n Yes, the brain is more of a sparse access memory\n\n08:23.980 --> 08:27.740\n so that you can actually retrieve very precisely\n\n08:27.740 --> 08:30.100\n like bits of your experience.\n\n08:30.100 --> 08:33.500\n The retrieval aspect, you can like introspect,\n\n08:33.500 --> 08:35.300\n you can ask yourself questions.\n\n08:35.300 --> 08:38.260\n I guess you can program your own memory\n\n08:38.260 --> 08:41.700\n and language is actually the tool you use to do that.\n\n08:41.700 --> 08:46.360\n I think language is a kind of operating system for the mind\n\n08:46.360 --> 08:47.820\n and use language.\n\n08:47.820 --> 08:51.800\n Well, one of the uses of language is as a query\n\n08:51.800 --> 08:53.860\n that you run over your own memory,\n\n08:53.860 --> 08:57.940\n use words as keys to retrieve specific experiences\n\n08:57.940 --> 09:00.140\n or specific concepts, specific thoughts.\n\n09:00.140 --> 09:02.380\n Like language is a way you store thoughts,\n\n09:02.380 --> 09:04.740\n not just in writing, in the physical world,\n\n09:04.740 --> 09:06.100\n but also in your own mind.\n\n09:06.100 --> 09:07.580\n And it's also how you retrieve them.\n\n09:07.580 --> 09:10.000\n Like, imagine if you didn't have language,\n\n09:10.000 --> 09:11.740\n then you would have to,\n\n09:11.740 --> 09:14.340\n you would not really have a self,\n\n09:14.340 --> 09:18.620\n internally triggered way of retrieving past thoughts.\n\n09:18.620 --> 09:21.300\n You would have to rely on external experiences.\n\n09:21.300 --> 09:24.020\n For instance, you see a specific site,\n\n09:24.020 --> 09:26.780\n you smell a specific smell and that brings up memories,\n\n09:26.780 --> 09:28.700\n but you would not really have a way\n\n09:28.700 --> 09:32.740\n to deliberately access these memories without language.\n\n09:32.740 --> 09:33.980\n Well, the interesting thing you mentioned\n\n09:33.980 --> 09:37.420\n is you can also program the memory.\n\n09:37.420 --> 09:39.980\n You can change it probably with language.\n\n09:39.980 --> 09:41.500\n Yeah, using language, yes.\n\n09:41.500 --> 09:44.100\n Well, let me ask you a Chomsky question,\n\n09:44.100 --> 09:45.980\n which is like, first of all,\n\n09:45.980 --> 09:49.100\n do you think language is like fundamental,\n\n09:49.100 --> 09:54.100\n like there's turtles, what's at the bottom of the turtles?\n\n09:54.460 --> 09:57.260\n They don't go, it can't be turtles all the way down.\n\n09:57.260 --> 10:00.260\n Is language at the bottom of cognition of everything?\n\n10:00.260 --> 10:05.260\n Is like language, the fundamental aspect\n\n10:05.300 --> 10:10.300\n of like what it means to be a thinking thing?\n\n10:10.700 --> 10:12.100\n No, I don't think so.\n\n10:12.100 --> 10:12.940\n I think language is.\n\n10:12.940 --> 10:14.620\n You disagree with Norm Chomsky?\n\n10:14.620 --> 10:17.900\n Yes, I think language is a layer on top of cognition.\n\n10:17.900 --> 10:21.740\n So it is fundamental to cognition in the sense that\n\n10:21.740 --> 10:23.380\n to use a computing metaphor,\n\n10:23.380 --> 10:28.060\n I see language as the operating system of the brain,\n\n10:28.060 --> 10:29.500\n of the human mind.\n\n10:29.500 --> 10:33.180\n And the operating system is a layer on top of the computer.\n\n10:33.180 --> 10:36.140\n The computer exists before the operating system,\n\n10:36.140 --> 10:39.500\n but the operating system is how you make it truly useful.\n\n10:39.500 --> 10:43.940\n And the operating system is most likely Windows, not Linux,\n\n10:43.940 --> 10:45.860\n because language is messy.\n\n10:45.860 --> 10:49.460\n Yeah, it's messy and it's pretty difficult\n\n10:49.460 --> 10:53.140\n to inspect it, introspect it.\n\n10:53.140 --> 10:55.100\n How do you think about language?\n\n10:55.100 --> 11:00.060\n Like we use actually sort of human interpretable language,\n\n11:00.060 --> 11:03.100\n but is there something like a deeper,\n\n11:03.100 --> 11:07.900\n that's closer to like logical type of statements?\n\n11:08.860 --> 11:13.860\n Like, yeah, what is the nature of language, do you think?\n\n11:16.140 --> 11:18.540\n Like is there something deeper than like the syntactic rules\n\n11:18.540 --> 11:19.380\n we construct?\n\n11:19.380 --> 11:22.860\n Is there something that doesn't require utterances\n\n11:22.860 --> 11:25.580\n or writing or so on?\n\n11:25.580 --> 11:27.460\n Are you asking about the possibility\n\n11:27.460 --> 11:30.900\n that there could exist languages for thinking\n\n11:30.900 --> 11:32.820\n that are not made of words?\n\n11:32.820 --> 11:33.660\n Yeah.\n\n11:33.660 --> 11:34.500\n Yeah, I think so.\n\n11:34.500 --> 11:38.580\n I think, so the mind is layers, right?\n\n11:38.580 --> 11:41.780\n And language is almost like the outermost,\n\n11:41.780 --> 11:43.140\n the uppermost layer.\n\n11:44.620 --> 11:46.780\n But before we think in words,\n\n11:46.780 --> 11:51.100\n I think we think in terms of emotion in space\n\n11:51.100 --> 11:54.180\n and we think in terms of physical actions.\n\n11:54.180 --> 11:56.860\n And I think babies in particular,\n\n11:56.860 --> 12:01.380\n probably expresses thoughts in terms of the actions\n\n12:01.380 --> 12:03.700\n that they've seen or that they can perform\n\n12:03.700 --> 12:08.020\n and in terms of motions of objects in their environment\n\n12:08.020 --> 12:10.860\n before they start thinking in terms of words.\n\n12:10.860 --> 12:13.900\n It's amazing to think about that\n\n12:13.900 --> 12:16.780\n as the building blocks of language.\n\n12:16.780 --> 12:21.780\n So like the kind of actions and ways the babies see the world\n\n12:21.820 --> 12:23.260\n as like more fundamental\n\n12:23.260 --> 12:26.220\n than the beautiful Shakespearean language\n\n12:26.220 --> 12:27.540\n you construct on top of it.\n\n12:28.620 --> 12:30.500\n And we probably don't have any idea\n\n12:30.500 --> 12:31.700\n what that looks like, right?\n\n12:31.700 --> 12:34.020\n Like what, because it's important\n\n12:34.020 --> 12:37.460\n for them trying to engineer it into AI systems.\n\n12:38.460 --> 12:42.060\n I think visual analogies and motion\n\n12:42.060 --> 12:45.380\n is a fundamental building block of the mind.\n\n12:45.380 --> 12:48.540\n And you actually see it reflected in language.\n\n12:48.540 --> 12:51.820\n Like language is full of special metaphors.\n\n12:51.820 --> 12:53.820\n And when you think about things,\n\n12:53.820 --> 12:57.380\n I consider myself very much as a visual thinker.\n\n12:57.380 --> 13:01.140\n You often express these thoughts\n\n13:01.140 --> 13:05.260\n by using things like visualizing concepts\n\n13:06.500 --> 13:09.940\n in 2D space or like you solve problems\n\n13:09.940 --> 13:14.940\n by imagining yourself navigating a concept space.\n\n13:14.940 --> 13:17.940\n So I don't know if you have this sort of experience.\n\n13:17.940 --> 13:19.860\n You said visualizing concept space.\n\n13:19.860 --> 13:22.300\n So like, so I certainly think about,\n\n13:24.820 --> 13:27.980\n I certainly visualize mathematical concepts,\n\n13:27.980 --> 13:31.420\n but you mean like in concept space,\n\n13:32.340 --> 13:34.860\n visually you're embedding ideas\n\n13:34.860 --> 13:36.940\n into a three dimensional space\n\n13:36.940 --> 13:38.820\n you can explore with your mind essentially?\n\n13:38.820 --> 13:40.340\n You should be more like 2D, but yeah.\n\n13:40.340 --> 13:41.180\n 2D?\n\n13:41.180 --> 13:42.100\n Yeah.\n\n13:42.100 --> 13:43.180\n You're a flatlander.\n\n13:43.180 --> 13:45.700\n You're, okay.\n\n13:45.700 --> 13:49.660\n No, I do not.\n\n13:49.660 --> 13:52.780\n I always have to, before I jump from concept to concept,\n\n13:52.780 --> 13:57.100\n I have to put it back down on paper.\n\n13:57.100 --> 13:58.060\n It has to be on paper.\n\n13:58.060 --> 14:03.060\n I can only travel on 2D paper, not inside my mind.\n\n14:03.340 --> 14:05.340\n You're able to move inside your mind.\n\n14:05.340 --> 14:07.900\n But even if you're writing like a paper, for instance,\n\n14:07.900 --> 14:11.020\n don't you have like a spatial representation of your paper?\n\n14:11.020 --> 14:16.020\n Like you visualize where ideas lie topologically\n\n14:16.660 --> 14:18.980\n in relationship to other ideas,\n\n14:18.980 --> 14:22.500\n kind of like a subway map of the ideas in your paper.\n\n14:22.500 --> 14:23.380\n Yeah, that's true.\n\n14:23.380 --> 14:27.900\n I mean, there is, in papers, I don't know about you,\n\n14:27.900 --> 14:30.540\n but it feels like there's a destination.\n\n14:32.540 --> 14:36.220\n There's a key idea that you want to arrive at.\n\n14:36.220 --> 14:39.340\n And a lot of it is in the fog\n\n14:39.340 --> 14:40.820\n and you're trying to kind of,\n\n14:40.820 --> 14:45.820\n it's almost like, what's that called\n\n14:46.180 --> 14:49.900\n when you do a path planning search from both directions,\n\n14:49.900 --> 14:51.500\n from the start and from the end.\n\n14:52.700 --> 14:54.740\n And then you find, you do like shortest path,\n\n14:54.740 --> 14:57.380\n but like, you know, in game playing,\n\n14:57.380 --> 15:01.020\n you do this with like A star from both sides.\n\n15:01.020 --> 15:03.420\n And you see where we're on the join.\n\n15:03.420 --> 15:05.740\n Yeah, so you kind of do, at least for me,\n\n15:05.740 --> 15:07.100\n I think like, first of all,\n\n15:07.100 --> 15:10.800\n just exploring from the start from like first principles,\n\n15:10.800 --> 15:15.620\n what do I know, what can I start proving from that, right?\n\n15:15.620 --> 15:18.060\n And then from the destination,\n\n15:18.060 --> 15:20.460\n if you start backtracking,\n\n15:20.460 --> 15:25.400\n like if I want to show some kind of sets of ideas,\n\n15:25.400 --> 15:28.300\n what would it take to show them and you kind of backtrack,\n\n15:28.300 --> 15:29.140\n but like, yeah,\n\n15:29.140 --> 15:31.260\n I don't think I'm doing all that in my mind though.\n\n15:31.260 --> 15:33.180\n Like I'm putting it down on paper.\n\n15:33.180 --> 15:35.500\n Do you use mind maps to organize your ideas?\n\n15:35.500 --> 15:37.740\n Yeah, I like mind maps.\n\n15:37.740 --> 15:38.580\n Let's get into this,\n\n15:38.580 --> 15:41.180\n because I've been so jealous of people.\n\n15:41.180 --> 15:42.120\n I haven't really tried it.\n\n15:42.120 --> 15:45.500\n I've been jealous of people that seem to like,\n\n15:45.500 --> 15:48.140\n they get like this fire of passion in their eyes\n\n15:48.140 --> 15:50.020\n because everything starts making sense.\n\n15:50.020 --> 15:51.940\n It's like Tom Cruise in the movie\n\n15:51.940 --> 15:53.820\n was like moving stuff around.\n\n15:53.820 --> 15:55.900\n Some of the most brilliant people I know use mind maps.\n\n15:55.900 --> 15:57.660\n I haven't tried really.\n\n15:57.660 --> 16:01.240\n Can you explain what the hell a mind map is?\n\n16:01.240 --> 16:03.700\n I guess mind map is a way to make\n\n16:03.700 --> 16:05.940\n kind of like the mess inside your mind\n\n16:05.940 --> 16:10.020\n to just put it on paper so that you gain more control over it.\n\n16:10.020 --> 16:13.020\n It's a way to organize things on paper\n\n16:13.020 --> 16:16.420\n and as kind of like a consequence\n\n16:16.420 --> 16:17.940\n of organizing things on paper,\n\n16:17.940 --> 16:20.300\n they start being more organized inside your own mind.\n\n16:20.300 --> 16:21.540\n So what does that look like?\n\n16:21.540 --> 16:23.980\n You put, like, do you have an example?\n\n16:23.980 --> 16:27.360\n Like what's the first thing you write on paper?\n\n16:27.360 --> 16:28.980\n What's the second thing you write?\n\n16:28.980 --> 16:31.660\n I mean, typically you draw a mind map\n\n16:31.660 --> 16:34.860\n to organize the way you think about a topic.\n\n16:34.860 --> 16:37.340\n So you would start by writing down\n\n16:37.340 --> 16:39.580\n like the key concept about that topic.\n\n16:39.580 --> 16:42.220\n Like you would write intelligence or something,\n\n16:42.220 --> 16:45.660\n and then you would start adding associative connections.\n\n16:45.660 --> 16:46.860\n Like what do you think about\n\n16:46.860 --> 16:48.100\n when you think about intelligence?\n\n16:48.100 --> 16:50.460\n What do you think are the key elements of intelligence?\n\n16:50.460 --> 16:52.340\n So maybe you would have language, for instance,\n\n16:52.340 --> 16:53.420\n and you'd have motion.\n\n16:53.420 --> 16:55.460\n And so you would start drawing notes with these things.\n\n16:55.460 --> 16:57.220\n And then you would see what do you think about\n\n16:57.220 --> 16:59.140\n when you think about motion and so on.\n\n16:59.140 --> 17:00.620\n And you would go like that, like a tree.\n\n17:00.620 --> 17:05.620\n Is it a tree mostly or is it a graph too, like a tree?\n\n17:05.660 --> 17:07.980\n Oh, it's more of a graph than a tree.\n\n17:07.980 --> 17:12.980\n And it's not limited to just writing down words.\n\n17:13.260 --> 17:15.940\n You can also draw things.\n\n17:15.940 --> 17:19.660\n And it's not supposed to be purely hierarchical, right?\n\n17:21.660 --> 17:24.540\n The point is that once you start writing it down,\n\n17:24.540 --> 17:27.500\n you can start reorganizing it so that it makes more sense,\n\n17:27.500 --> 17:29.940\n so that it's connected in a more effective way.\n\n17:29.940 --> 17:34.460\n See, but I'm so OCD that you just mentioned\n\n17:34.460 --> 17:37.060\n intelligence and language and motion.\n\n17:37.060 --> 17:39.100\n I would start becoming paranoid\n\n17:39.100 --> 17:41.980\n that the categorization isn't perfect.\n\n17:41.980 --> 17:46.980\n Like that I would become paralyzed with the mind map\n\n17:47.860 --> 17:49.660\n that like this may not be.\n\n17:49.660 --> 17:52.660\n So like the, even though you're just doing\n\n17:52.660 --> 17:55.380\n associative kind of connections,\n\n17:55.380 --> 17:58.460\n there's an implied hierarchy that's emerging.\n\n17:58.460 --> 17:59.900\n And I would start becoming paranoid\n\n17:59.900 --> 18:02.340\n that it's not the proper hierarchy.\n\n18:02.340 --> 18:04.940\n So you're not just, one way to see mind maps\n\n18:04.940 --> 18:07.060\n is you're putting thoughts on paper.\n\n18:07.060 --> 18:10.580\n It's like a stream of consciousness,\n\n18:10.580 --> 18:12.220\n but then you can also start getting paranoid.\n\n18:12.220 --> 18:15.140\n Well, is this the right hierarchy?\n\n18:15.140 --> 18:17.780\n Sure, which it's mind maps, your mind map.\n\n18:17.780 --> 18:19.420\n You're free to draw anything you want.\n\n18:19.420 --> 18:20.860\n You're free to draw any connection you want.\n\n18:20.860 --> 18:23.420\n And you can just make a different mind map\n\n18:23.420 --> 18:26.260\n if you think the central node is not the right node.\n\n18:26.260 --> 18:29.700\n Yeah, I suppose there's a fear of being wrong.\n\n18:29.700 --> 18:32.660\n If you want to organize your ideas\n\n18:32.660 --> 18:35.540\n by writing down what you think,\n\n18:35.540 --> 18:37.380\n which I think is very effective.\n\n18:37.380 --> 18:40.140\n Like how do you know what you think about something\n\n18:40.140 --> 18:42.940\n if you don't write it down, right?\n\n18:42.940 --> 18:46.180\n If you do that, the thing is that it imposes\n\n18:46.180 --> 18:49.980\n much more syntactic structure over your ideas,\n\n18:49.980 --> 18:51.540\n which is not required with mind maps.\n\n18:51.540 --> 18:54.180\n So mind map is kind of like a lower level,\n\n18:54.180 --> 18:57.900\n more freehand way of organizing your thoughts.\n\n18:57.900 --> 18:59.580\n And once you've drawn it,\n\n18:59.580 --> 19:03.620\n then you can start actually voicing your thoughts\n\n19:03.620 --> 19:05.380\n in terms of, you know, paragraphs.\n\n19:05.380 --> 19:08.780\n It's a two dimensional aspect of layout too, right?\n\n19:08.780 --> 19:09.620\n Yeah.\n\n19:09.620 --> 19:12.860\n It's a kind of flower, I guess, you start.\n\n19:12.860 --> 19:15.820\n There's usually, you want to start with a central concept?\n\n19:15.820 --> 19:16.660\n Yes.\n\n19:16.660 --> 19:17.500\n Then you move out.\n\n19:17.500 --> 19:19.140\n Typically it ends up more like a subway map.\n\n19:19.140 --> 19:20.660\n So it ends up more like a graph,\n\n19:20.660 --> 19:23.500\n a topological graph without a root node.\n\n19:23.500 --> 19:25.020\n Yeah, so like in a subway map,\n\n19:25.020 --> 19:27.300\n there are some nodes that are more connected than others.\n\n19:27.300 --> 19:30.940\n And there are some nodes that are more important than others.\n\n19:30.940 --> 19:32.380\n So there are destinations,\n\n19:32.380 --> 19:36.420\n but it's not going to be purely like a tree, for instance.\n\n19:36.420 --> 19:38.540\n Yeah, it's fascinating to think that\n\n19:38.540 --> 19:42.420\n if there's something to that about the way our mind thinks.\n\n19:42.420 --> 19:45.820\n By the way, I just kind of remembered obvious thing\n\n19:45.820 --> 19:49.020\n that I have probably thousands of documents\n\n19:49.020 --> 19:53.620\n in Google Doc at this point, that are bullet point lists,\n\n19:53.620 --> 19:57.860\n which is, you can probably map a mind map\n\n19:57.860 --> 19:59.660\n to a bullet point list.\n\n20:01.460 --> 20:05.060\n It's the same, it's a, no, it's not, it's a tree.\n\n20:05.060 --> 20:06.220\n It's a tree, yeah.\n\n20:06.220 --> 20:07.900\n So I create trees,\n\n20:07.900 --> 20:10.740\n but also they don't have the visual element.\n\n20:10.740 --> 20:13.460\n Like, I guess I'm comfortable with the structure.\n\n20:13.460 --> 20:15.740\n It feels like the narrowness,\n\n20:15.740 --> 20:18.260\n the constraints feel more comforting.\n\n20:18.260 --> 20:20.300\n If you have thousands of documents\n\n20:20.300 --> 20:23.100\n with your own thoughts in Google Docs,\n\n20:23.100 --> 20:26.580\n why don't you write some kind of search engine,\n\n20:26.580 --> 20:30.900\n like maybe a mind map, a piece of software,\n\n20:30.900 --> 20:33.980\n mind mapping software, where you write down a concept\n\n20:33.980 --> 20:37.500\n and then it gives you sentences or paragraphs\n\n20:37.500 --> 20:39.700\n from your thousand Google Docs document\n\n20:39.700 --> 20:41.220\n that match this concept.\n\n20:41.220 --> 20:45.300\n The problem is it's so deeply, unlike mind maps,\n\n20:45.300 --> 20:48.460\n it's so deeply rooted in natural language.\n\n20:48.460 --> 20:53.460\n So it's not, it's not semantically searchable,\n\n20:54.420 --> 20:57.220\n I would say, because the categories are very,\n\n20:57.220 --> 21:00.700\n you kind of mentioned intelligence, language, and motion.\n\n21:00.700 --> 21:02.580\n They're very strong, semantic.\n\n21:02.580 --> 21:05.020\n Like, it feels like the mind map forces you\n\n21:05.020 --> 21:09.780\n to be semantically clear and specific.\n\n21:09.780 --> 21:13.860\n The bullet points list I have are sparse,\n\n21:13.860 --> 21:18.860\n desperate thoughts that poetically represent\n\n21:20.340 --> 21:24.220\n a category like motion, as opposed to saying motion.\n\n21:25.260 --> 21:28.980\n So unfortunately, that's the same problem with the internet.\n\n21:28.980 --> 21:32.340\n That's why the idea of semantic web is difficult to get.\n\n21:32.340 --> 21:37.340\n It's, most language on the internet is a giant mess\n\n21:37.980 --> 21:42.500\n of natural language that's hard to interpret, which,\n\n21:42.500 --> 21:46.180\n so do you think there's something to mind maps as,\n\n21:46.180 --> 21:48.100\n you actually originally brought it up\n\n21:48.100 --> 21:53.100\n as we were talking about kind of cognition and language.\n\n21:53.580 --> 21:55.300\n Do you think there's something to mind maps\n\n21:55.300 --> 21:58.100\n about how our brain actually deals,\n\n21:58.100 --> 22:00.300\n like think reasons about things?\n\n22:01.740 --> 22:02.580\n It's possible.\n\n22:02.580 --> 22:05.660\n I think it's reasonable to assume that there is\n\n22:07.100 --> 22:10.620\n some level of topological processing in the brain,\n\n22:10.620 --> 22:15.140\n that the brain is very associative in nature.\n\n22:15.140 --> 22:20.140\n And I also believe that a topological space\n\n22:20.660 --> 22:25.420\n is a better medium to encode thoughts\n\n22:25.420 --> 22:27.540\n than a geometric space.\n\n22:27.540 --> 22:28.380\n So I think...\n\n22:28.380 --> 22:29.740\n What's the difference in a topological\n\n22:29.740 --> 22:31.060\n and a geometric space?\n\n22:31.060 --> 22:34.100\n Well, if you're talking about topologies,\n\n22:34.100 --> 22:36.220\n then points are either connected or not.\n\n22:36.220 --> 22:38.660\n So a topology is more like a subway map.\n\n22:38.660 --> 22:41.660\n And geometry is when you're interested\n\n22:41.660 --> 22:43.900\n in the distance between things.\n\n22:43.900 --> 22:44.740\n And in a subway map,\n\n22:44.740 --> 22:46.340\n you don't really have the concept of distance.\n\n22:46.340 --> 22:48.420\n You only have the concept of whether there is a train\n\n22:48.420 --> 22:51.500\n going from station A to station B.\n\n22:52.820 --> 22:55.620\n And what we do in deep learning is that we're actually\n\n22:55.620 --> 22:57.740\n dealing with geometric spaces.\n\n22:57.740 --> 23:00.700\n We are dealing with concept vectors, word vectors,\n\n23:01.540 --> 23:03.300\n that have a distance between them\n\n23:03.300 --> 23:05.340\n to express in terms of that product.\n\n23:05.340 --> 23:10.340\n So we are not really building topological models usually.\n\n23:10.780 --> 23:11.820\n I think you're absolutely right.\n\n23:11.820 --> 23:16.540\n Like distance is a fundamental importance in deep learning.\n\n23:16.540 --> 23:19.300\n I mean, it's the continuous aspect of it.\n\n23:19.300 --> 23:21.180\n Yes, because everything is a vector\n\n23:21.180 --> 23:22.500\n and everything has to be a vector\n\n23:22.500 --> 23:24.500\n because everything has to be differentiable.\n\n23:24.500 --> 23:26.860\n If your space is discrete, it's no longer differentiable.\n\n23:26.860 --> 23:29.660\n You cannot do deep learning in it anymore.\n\n23:29.660 --> 23:32.420\n Well, you could, but you can only do it by embedding it\n\n23:32.420 --> 23:35.620\n in a bigger continuous space.\n\n23:35.620 --> 23:39.380\n So if you do topology in the context of deep learning,\n\n23:39.380 --> 23:41.100\n you have to do it by embedding your topology\n\n23:41.100 --> 23:41.940\n in the geometry.\n\n23:42.820 --> 23:46.220\n Well, let me zoom out for a second.\n\n23:46.220 --> 23:49.060\n Let's get into your paper on the measure of intelligence\n\n23:50.180 --> 23:52.860\n that you put out in 2019.\n\n23:52.860 --> 23:53.700\n Yes.\n\n23:53.700 --> 23:54.540\n Okay.\n\n23:54.540 --> 23:55.380\n November.\n\n23:55.380 --> 23:56.220\n November.\n\n23:57.700 --> 23:59.420\n Yeah, remember 2019?\n\n23:59.420 --> 24:01.100\n That was a different time.\n\n24:01.100 --> 24:02.780\n Yeah, I remember.\n\n24:02.780 --> 24:03.700\n I still remember.\n\n24:06.500 --> 24:09.620\n It feels like a different world.\n\n24:09.620 --> 24:12.620\n You could travel, you could actually go outside\n\n24:12.620 --> 24:14.060\n and see friends.\n\n24:15.100 --> 24:16.260\n Yeah.\n\n24:16.260 --> 24:18.940\n Let me ask the most absurd question.\n\n24:18.940 --> 24:21.740\n I think there's some nonzero probability\n\n24:21.740 --> 24:25.220\n there'll be a textbook one day, like 200 years from now\n\n24:25.220 --> 24:27.740\n on artificial intelligence,\n\n24:27.740 --> 24:30.660\n or it'll be called like just intelligence\n\n24:30.660 --> 24:32.460\n cause humans will already be gone.\n\n24:32.460 --> 24:35.220\n It'll be your picture with a quote.\n\n24:35.220 --> 24:39.020\n This is, you know, one of the early biological systems\n\n24:39.020 --> 24:41.580\n would consider the nature of intelligence\n\n24:41.580 --> 24:43.180\n and there'll be like a definition\n\n24:43.180 --> 24:45.180\n of how they thought about intelligence.\n\n24:45.180 --> 24:46.860\n Which is one of the things you do in your paper\n\n24:46.860 --> 24:50.100\n on measure intelligence is to ask like,\n\n24:51.060 --> 24:52.620\n well, what is intelligence\n\n24:52.620 --> 24:55.540\n and how to test for intelligence and so on.\n\n24:55.540 --> 25:00.540\n So is there a spiffy quote about what is intelligence?\n\n25:01.860 --> 25:03.900\n What is the definition of intelligence\n\n25:03.900 --> 25:05.420\n according to Francois Chollet?\n\n25:06.740 --> 25:10.740\n Yeah, so do you think the super intelligent AIs\n\n25:10.740 --> 25:13.900\n of the future will want to remember us\n\n25:13.900 --> 25:16.060\n the way we remember humans from the past?\n\n25:16.060 --> 25:18.500\n And do you think they will be, you know,\n\n25:18.500 --> 25:21.300\n they won't be ashamed of having a biological origin?\n\n25:22.340 --> 25:24.660\n No, I think it would be a niche topic.\n\n25:24.660 --> 25:25.820\n It won't be that interesting,\n\n25:25.820 --> 25:29.420\n but it'll be like the people that study\n\n25:29.420 --> 25:33.100\n in certain contexts like historical civilization\n\n25:33.100 --> 25:36.340\n that no longer exists, the Aztecs and so on.\n\n25:36.340 --> 25:38.260\n That's how it'll be seen.\n\n25:38.260 --> 25:42.340\n And it'll be study in also the context on social media.\n\n25:42.340 --> 25:46.700\n There'll be hashtags about the atrocity\n\n25:46.700 --> 25:48.140\n committed to human beings\n\n25:49.340 --> 25:52.500\n when the robots finally got rid of them.\n\n25:52.500 --> 25:55.180\n Like it was a mistake.\n\n25:55.180 --> 25:57.020\n You'll be seen as a giant mistake,\n\n25:57.020 --> 26:00.060\n but ultimately in the name of progress\n\n26:00.060 --> 26:01.540\n and it created a better world\n\n26:01.540 --> 26:05.220\n because humans were over consuming the resources\n\n26:05.220 --> 26:07.260\n and they were not very rational\n\n26:07.260 --> 26:11.060\n and were destructive in the end in terms of productivity\n\n26:11.060 --> 26:13.820\n and putting more love in the world.\n\n26:13.820 --> 26:15.300\n And so within that context,\n\n26:15.300 --> 26:17.420\n there'll be a chapter about these biological systems.\n\n26:17.420 --> 26:20.380\n It seems to have a very detailed vision of that hit here.\n\n26:20.380 --> 26:22.340\n You should write a sci fi novel about it.\n\n26:22.340 --> 26:26.460\n I'm working on a sci fi novel currently, yes.\n\n26:28.100 --> 26:29.460\n Self published, yeah.\n\n26:29.460 --> 26:30.740\n The definition of intelligence.\n\n26:30.740 --> 26:34.660\n So intelligence is the efficiency\n\n26:34.660 --> 26:39.380\n with which you acquire new skills at tasks\n\n26:39.380 --> 26:41.940\n that you did not previously know about,\n\n26:41.940 --> 26:44.700\n that you did not prepare for, right?\n\n26:44.700 --> 26:47.780\n So intelligence is not skill itself.\n\n26:47.780 --> 26:50.740\n It's not what you know, it's not what you can do.\n\n26:50.740 --> 26:52.900\n It's how well and how efficiently\n\n26:52.900 --> 26:54.580\n you can learn new things.\n\n26:54.580 --> 26:55.580\n New things.\n\n26:55.580 --> 26:56.420\n Yes.\n\n26:56.420 --> 26:58.100\n The idea of newness there\n\n26:58.100 --> 27:00.100\n seems to be fundamentally important.\n\n27:01.180 --> 27:02.020\n Yes.\n\n27:02.020 --> 27:05.780\n So you would see intelligence on display, for instance.\n\n27:05.780 --> 27:09.980\n Whenever you see a human being or an AI creature\n\n27:09.980 --> 27:13.900\n adapt to a new environment that it does not see before,\n\n27:13.900 --> 27:16.620\n that its creators did not anticipate.\n\n27:16.620 --> 27:19.340\n When you see adaptation, when you see improvisation,\n\n27:19.340 --> 27:22.500\n when you see generalization, that's intelligence.\n\n27:22.500 --> 27:24.460\n In reverse, if you have a system\n\n27:24.460 --> 27:27.100\n that when you put it in a slightly new environment,\n\n27:27.100 --> 27:30.060\n it cannot adapt, it cannot improvise,\n\n27:30.060 --> 27:33.380\n it cannot deviate from what it's hard coded to do\n\n27:33.380 --> 27:37.660\n or what it has been trained to do,\n\n27:38.700 --> 27:41.060\n that is a system that is not intelligent.\n\n27:41.060 --> 27:43.580\n There's actually a quote from Einstein\n\n27:43.580 --> 27:46.780\n that captures this idea, which is,\n\n27:46.780 --> 27:50.740\n the measure of intelligence is the ability to change.\n\n27:50.740 --> 27:51.740\n I like that quote.\n\n27:51.740 --> 27:54.940\n I think it captures at least part of this idea.\n\n27:54.940 --> 27:56.460\n You know, there might be something interesting\n\n27:56.460 --> 27:59.500\n about the difference between your definition and Einstein's.\n\n27:59.500 --> 28:03.700\n I mean, he's just being Einstein and clever,\n\n28:04.740 --> 28:09.740\n but acquisition of new ability to deal with new things\n\n28:09.740 --> 28:14.100\n versus ability to just change.\n\n28:14.100 --> 28:16.820\n What's the difference between those two things?\n\n28:16.820 --> 28:19.260\n So just change in itself.\n\n28:19.260 --> 28:21.300\n Do you think there's something to that?\n\n28:21.300 --> 28:23.780\n Just being able to change.\n\n28:23.780 --> 28:25.540\n Yes, being able to adapt.\n\n28:25.540 --> 28:30.060\n So not change, but certainly change its direction.\n\n28:30.060 --> 28:33.460\n Being able to adapt yourself to your environment.\n\n28:34.420 --> 28:35.660\n Whatever the environment is.\n\n28:35.660 --> 28:37.460\n That's a big part of intelligence.\n\n28:37.460 --> 28:40.020\n And intelligence is more precisely, you know,\n\n28:40.020 --> 28:42.460\n how efficiently you're able to adapt,\n\n28:42.460 --> 28:45.740\n how efficiently you're able to basically master your environment,\n\n28:45.740 --> 28:49.140\n how efficiently you can acquire new skills.\n\n28:49.140 --> 28:52.300\n And I think there's a big distinction to be drawn\n\n28:52.300 --> 28:56.220\n between intelligence, which is a process,\n\n28:56.220 --> 28:59.740\n and the output of that process, which is skill.\n\n29:01.420 --> 29:04.900\n So for instance, if you have a very smart human brain,\n\n29:04.900 --> 29:08.980\n so for instance, if you have a very smart human programmer\n\n29:08.980 --> 29:10.780\n that considers the game of chess,\n\n29:10.780 --> 29:15.780\n and that writes down a static program that can play chess,\n\n29:16.180 --> 29:19.140\n then the intelligence is the process\n\n29:19.140 --> 29:20.660\n of developing that program.\n\n29:20.660 --> 29:24.460\n But the program itself is just encoding\n\n29:25.660 --> 29:28.100\n the output artifact of that process.\n\n29:28.100 --> 29:30.020\n The program itself is not intelligent.\n\n29:30.020 --> 29:31.860\n And the way you tell it's not intelligent\n\n29:31.860 --> 29:34.020\n is that if you put it in a different context,\n\n29:34.020 --> 29:36.060\n you ask it to play Go or something,\n\n29:36.060 --> 29:37.780\n it's not going to be able to perform well\n\n29:37.780 --> 29:38.900\n without human involvement,\n\n29:38.900 --> 29:41.100\n because the source of intelligence,\n\n29:41.100 --> 29:43.140\n the entity that is capable of that process\n\n29:43.140 --> 29:44.380\n is the human programmer.\n\n29:44.380 --> 29:47.940\n So we should be able to tell the difference\n\n29:47.940 --> 29:50.100\n between the process and its output.\n\n29:50.100 --> 29:53.260\n We should not confuse the output and the process.\n\n29:53.260 --> 29:54.860\n It's the same as, you know,\n\n29:54.860 --> 29:58.780\n do not confuse a road building company\n\n29:58.780 --> 30:00.180\n and one specific road,\n\n30:00.180 --> 30:03.460\n because one specific road takes you from point A to point B,\n\n30:03.460 --> 30:06.180\n but a road building company can take you from,\n\n30:06.180 --> 30:08.980\n can make a path from anywhere to anywhere else.\n\n30:08.980 --> 30:10.140\n Yeah, that's beautifully put,\n\n30:10.140 --> 30:15.140\n but it's also to play devil's advocate a little bit.\n\n30:15.460 --> 30:18.740\n You know, it's possible that there's something\n\n30:18.740 --> 30:21.260\n more fundamental than us humans.\n\n30:21.260 --> 30:24.660\n So you kind of said the programmer creates\n\n30:25.860 --> 30:28.940\n the difference between the choir,\n\n30:28.940 --> 30:31.340\n the skill and the skill itself.\n\n30:31.340 --> 30:32.780\n There could be something like,\n\n30:32.780 --> 30:36.420\n you could argue the universe is more intelligent.\n\n30:36.420 --> 30:41.420\n Like the base intelligence that we should be trying\n\n30:43.020 --> 30:45.380\n to measure is something that created humans.\n\n30:46.500 --> 30:51.500\n We should be measuring God or the source of the universe\n\n30:51.540 --> 30:55.140\n as opposed to, like there could be a deeper intelligence.\n\n30:55.140 --> 30:55.980\n Sure.\n\n30:55.980 --> 30:57.140\n There's always deeper intelligence, I guess.\n\n30:57.140 --> 30:58.020\n You can argue that,\n\n30:58.020 --> 31:00.100\n but that does not take anything away\n\n31:00.100 --> 31:01.900\n from the fact that humans are intelligent.\n\n31:01.900 --> 31:03.260\n And you can tell that\n\n31:03.260 --> 31:07.020\n because they are capable of adaptation and generality.\n\n31:07.020 --> 31:07.860\n Got it.\n\n31:07.860 --> 31:09.700\n And you see that in particular in the fact\n\n31:09.700 --> 31:14.700\n that humans are capable of handling situations and tasks\n\n31:16.780 --> 31:19.780\n that are quite different from anything\n\n31:19.780 --> 31:22.940\n that any of our evolutionary ancestors\n\n31:22.940 --> 31:24.540\n has ever encountered.\n\n31:24.540 --> 31:27.140\n So we are capable of generalizing very much\n\n31:27.140 --> 31:28.100\n out of distribution,\n\n31:28.100 --> 31:30.260\n if you consider our evolutionary history\n\n31:30.260 --> 31:32.220\n as being in a way our training data.\n\n31:33.260 --> 31:35.060\n Of course, evolutionary biologists would argue\n\n31:35.060 --> 31:37.660\n that we're not going too far out of the distribution.\n\n31:37.660 --> 31:41.380\n We're like mapping the skills we've learned previously,\n\n31:41.380 --> 31:43.540\n desperately trying to like jam them\n\n31:43.540 --> 31:47.060\n into like these new situations.\n\n31:47.060 --> 31:49.460\n I mean, there's definitely a little bit of that,\n\n31:49.460 --> 31:52.220\n but it's pretty clear to me that we're able to,\n\n31:53.660 --> 31:56.580\n most of the things we do any given day\n\n31:56.580 --> 31:58.060\n in our modern civilization\n\n31:58.060 --> 32:00.860\n are things that are very, very different\n\n32:00.860 --> 32:03.900\n from what our ancestors a million years ago\n\n32:03.900 --> 32:05.900\n would have been doing in a given day.\n\n32:05.900 --> 32:07.540\n And your environment is very different.\n\n32:07.540 --> 32:12.180\n So I agree that everything we do,\n\n32:12.180 --> 32:14.220\n we do it with cognitive building blocks\n\n32:14.220 --> 32:17.820\n that we acquired over the course of evolution, right?\n\n32:17.820 --> 32:22.180\n And that anchors our cognition to a certain context,\n\n32:22.180 --> 32:25.260\n which is the human condition very much.\n\n32:25.260 --> 32:29.500\n But still our mind is capable of a pretty remarkable degree\n\n32:29.500 --> 32:32.700\n of generality far beyond anything we can create\n\n32:32.700 --> 32:34.100\n in artificial systems today.\n\n32:34.100 --> 32:37.740\n Like the degree in which the mind can generalize\n\n32:37.740 --> 32:40.420\n from its evolutionary history,\n\n32:41.620 --> 32:43.940\n can generalize away from its evolutionary history\n\n32:43.940 --> 32:46.500\n is much greater than the degree\n\n32:46.500 --> 32:48.860\n to which a deep learning system today\n\n32:48.860 --> 32:51.020\n can generalize away from its training data.\n\n32:51.020 --> 32:52.380\n And like the key point you're making,\n\n32:52.380 --> 32:54.220\n which I think is quite beautiful is like,\n\n32:54.220 --> 32:58.660\n we shouldn't measure, if we're talking about measurement,\n\n32:58.660 --> 33:00.340\n we shouldn't measure the skill.\n\n33:01.620 --> 33:04.340\n We should measure like the creation of the new skill,\n\n33:04.340 --> 33:06.780\n the ability to create that new skill.\n\n33:06.780 --> 33:10.940\n But it's tempting, like it's weird\n\n33:10.940 --> 33:13.620\n because the skill is a little bit of a small window\n\n33:13.620 --> 33:16.380\n into the system.\n\n33:16.380 --> 33:18.300\n So whenever you have a lot of skills,\n\n33:19.420 --> 33:21.900\n it's tempting to measure the skills.\n\n33:21.900 --> 33:25.820\n I mean, the skill is the only thing you can objectively\n\n33:25.820 --> 33:27.540\n measure, but yeah.\n\n33:27.540 --> 33:30.780\n So the thing to keep in mind is that\n\n33:30.780 --> 33:33.460\n when you see skill in the human,\n\n33:35.060 --> 33:39.220\n it gives you a strong signal that that human is intelligent\n\n33:39.220 --> 33:42.740\n because you know they weren't born with that skill typically.\n\n33:42.740 --> 33:45.220\n Like you see a very strong chess player,\n\n33:45.220 --> 33:47.540\n maybe you're a very strong chess player yourself.\n\n33:47.540 --> 33:51.020\n I think you're saying that because I'm Russian\n\n33:51.020 --> 33:53.860\n and now you're prejudiced, you assume.\n\n33:53.860 --> 33:54.700\n All Russians are good at chess.\n\n33:54.700 --> 33:55.540\n I'm biased, exactly.\n\n33:55.540 --> 33:56.900\n I'm biased, yeah.\n\n33:56.900 --> 34:00.020\n Well, you're definitely biased.\n\n34:00.020 --> 34:01.900\n So if you see a very strong chess player,\n\n34:01.900 --> 34:05.460\n you know they weren't born knowing how to play chess.\n\n34:05.460 --> 34:07.780\n So they had to acquire that skill\n\n34:07.780 --> 34:10.940\n with their limited resources, with their limited lifetime.\n\n34:10.940 --> 34:15.420\n And they did that because they are generally intelligent.\n\n34:15.420 --> 34:18.980\n And so they may as well have acquired any other skill.\n\n34:18.980 --> 34:21.180\n You know they have this potential.\n\n34:21.180 --> 34:25.700\n And on the other hand, if you see a computer playing chess,\n\n34:25.700 --> 34:27.860\n you cannot make the same assumptions\n\n34:27.860 --> 34:29.380\n because you cannot just assume\n\n34:29.380 --> 34:30.860\n the computer is generally intelligent.\n\n34:30.860 --> 34:35.300\n The computer may be born knowing how to play chess\n\n34:35.300 --> 34:38.220\n in the sense that it may have been programmed by a human\n\n34:38.220 --> 34:40.900\n that has understood chess for the computer\n\n34:40.900 --> 34:44.180\n and that has just encoded the output\n\n34:44.180 --> 34:46.020\n of that understanding in a static program.\n\n34:46.020 --> 34:49.420\n And that program is not intelligent.\n\n34:49.420 --> 34:52.380\n So let's zoom out just for a second and say like,\n\n34:52.380 --> 34:57.380\n what is the goal on the measure of intelligence paper?\n\n34:57.460 --> 34:59.020\n Like what do you hope to achieve with it?\n\n34:59.020 --> 35:01.700\n So the goal of the paper is to clear up\n\n35:01.700 --> 35:04.580\n some longstanding misunderstandings\n\n35:04.580 --> 35:08.380\n about the way we've been conceptualizing intelligence\n\n35:08.380 --> 35:12.500\n in the AI community and in the way we've been\n\n35:12.500 --> 35:16.780\n evaluating progress in AI.\n\n35:16.780 --> 35:19.060\n There's been a lot of progress recently in machine learning\n\n35:19.060 --> 35:22.140\n and people are extrapolating from that progress\n\n35:22.140 --> 35:26.380\n that we are about to solve general intelligence.\n\n35:26.380 --> 35:30.500\n And if you want to be able to evaluate these statements,\n\n35:30.500 --> 35:33.820\n you need to precisely define what you're talking about\n\n35:33.820 --> 35:35.580\n when you're talking about general intelligence.\n\n35:35.580 --> 35:40.580\n And you need a formal way, a reliable way to measure\n\n35:40.580 --> 35:42.380\n how much intelligence,\n\n35:42.380 --> 35:45.900\n how much general intelligence a system processes.\n\n35:45.900 --> 35:48.420\n And ideally this measure of intelligence\n\n35:48.420 --> 35:50.260\n should be actionable.\n\n35:50.260 --> 35:54.620\n So it should not just describe what intelligence is.\n\n35:54.620 --> 35:56.860\n It should not just be a binary indicator\n\n35:56.860 --> 36:00.540\n that tells you the system is intelligent or it isn't.\n\n36:01.620 --> 36:03.060\n It should be actionable.\n\n36:03.060 --> 36:05.740\n It should have explanatory power, right?\n\n36:05.740 --> 36:08.580\n So you could use it as a feedback signal.\n\n36:08.580 --> 36:10.980\n It would show you the way\n\n36:10.980 --> 36:13.100\n towards building more intelligent systems.\n\n36:13.100 --> 36:16.500\n So at the first level, you draw a distinction\n\n36:16.500 --> 36:19.020\n between two divergent views of intelligence.\n\n36:21.780 --> 36:22.860\n As we just talked about,\n\n36:22.860 --> 36:26.820\n intelligence is a collection of task specific skills\n\n36:26.820 --> 36:29.900\n and a general learning ability.\n\n36:29.900 --> 36:31.420\n So what's the difference between\n\n36:32.300 --> 36:35.580\n kind of this memorization of skills\n\n36:35.580 --> 36:37.820\n and a general learning ability?\n\n36:37.820 --> 36:39.580\n We've talked about it a little bit,\n\n36:39.580 --> 36:43.060\n but can you try to linger on this topic for a bit?\n\n36:43.060 --> 36:45.460\n Yeah, so the first part of the paper\n\n36:45.460 --> 36:49.100\n is an assessment of the different ways\n\n36:49.100 --> 36:50.500\n we've been thinking about intelligence\n\n36:50.500 --> 36:54.540\n and the different ways we've been evaluating progress in AI.\n\n36:54.540 --> 36:57.700\n And this tree of cognitive sciences\n\n36:57.700 --> 37:01.220\n has been shaped by two views of the human mind.\n\n37:01.220 --> 37:04.740\n And one view is the evolutionary psychology view\n\n37:04.740 --> 37:09.740\n in which the mind is a collection of fairly static\n\n37:10.660 --> 37:14.220\n special purpose ad hoc mechanisms\n\n37:14.220 --> 37:17.620\n that have been hard coded by evolution\n\n37:17.620 --> 37:22.500\n over our history as a species for a very long time.\n\n37:22.500 --> 37:27.500\n And early AI researchers,\n\n37:27.940 --> 37:30.340\n people like Marvin Minsky, for instance,\n\n37:30.340 --> 37:33.300\n they clearly subscribed to this view.\n\n37:33.300 --> 37:36.860\n And they saw the mind as a kind of\n\n37:36.860 --> 37:38.740\n collection of static programs\n\n37:39.820 --> 37:42.140\n similar to the programs they would run\n\n37:42.140 --> 37:43.580\n on like mainframe computers.\n\n37:43.580 --> 37:48.060\n And in fact, I think they very much understood the mind\n\n37:48.060 --> 37:50.540\n through the metaphor of the mainframe computer\n\n37:50.540 --> 37:53.580\n because that was the tool they were working with, right?\n\n37:53.580 --> 37:55.100\n And so you had these static programs,\n\n37:55.100 --> 37:57.180\n this collection of very different static programs\n\n37:57.180 --> 38:00.060\n operating over a database like memory.\n\n38:00.060 --> 38:03.580\n And in this picture, learning was not very important.\n\n38:03.580 --> 38:05.660\n Learning was considered to be just memorization.\n\n38:05.660 --> 38:10.380\n And in fact, learning is basically not featured\n\n38:10.380 --> 38:14.620\n in AI textbooks until the 1980s\n\n38:14.620 --> 38:16.940\n with the rise of machine learning.\n\n38:16.940 --> 38:18.780\n It's kind of fun to think about\n\n38:18.780 --> 38:20.500\n that learning was the outcast.\n\n38:21.500 --> 38:24.060\n Like the weird people working on learning,\n\n38:24.060 --> 38:28.100\n like the mainstream AI world was,\n\n38:28.100 --> 38:31.780\n I mean, I don't know what the best term is,\n\n38:31.780 --> 38:32.980\n but it's non learning.\n\n38:33.900 --> 38:37.940\n It was seen as like reasoning would not be learning based.\n\n38:37.940 --> 38:40.620\n Yes, it was considered that the mind\n\n38:40.620 --> 38:43.180\n was a collection of programs\n\n38:43.180 --> 38:46.620\n that were primarily logical in nature.\n\n38:46.620 --> 38:49.140\n And that's all you needed to do to create a mind\n\n38:49.140 --> 38:50.860\n was to write down these programs\n\n38:50.860 --> 38:52.860\n and they would operate over knowledge,\n\n38:52.860 --> 38:55.100\n which would be stored in some kind of database.\n\n38:55.100 --> 38:57.300\n And as long as your database would encompass,\n\n38:57.300 --> 38:59.380\n you know, everything about the world\n\n38:59.380 --> 39:03.340\n and your logical rules were comprehensive,\n\n39:03.340 --> 39:04.940\n then you would have a mind.\n\n39:04.940 --> 39:06.420\n So the other view of the mind\n\n39:06.420 --> 39:11.420\n is the brain as a sort of blank slate, right?\n\n39:11.940 --> 39:13.180\n This is a very old idea.\n\n39:13.180 --> 39:16.140\n You find it in John Locke's writings.\n\n39:16.140 --> 39:17.580\n This is the tabula rasa.\n\n39:19.220 --> 39:21.140\n And this is this idea that the mind\n\n39:21.140 --> 39:23.340\n is some kind of like information sponge\n\n39:23.340 --> 39:27.340\n that starts empty, that starts blank.\n\n39:27.340 --> 39:32.340\n And that absorbs knowledge and skills from experience, right?\n\n39:34.340 --> 39:38.700\n So it's a sponge that reflects the complexity of the world,\n\n39:38.700 --> 39:41.780\n the complexity of your life experience, essentially.\n\n39:41.780 --> 39:44.340\n That everything you know and everything you can do\n\n39:44.340 --> 39:47.740\n is a reflection of something you found\n\n39:47.740 --> 39:49.580\n in the outside world, essentially.\n\n39:49.580 --> 39:51.580\n So this is an idea that's very old.\n\n39:51.580 --> 39:56.580\n That was not very popular, for instance, in the 1970s.\n\n39:56.780 --> 39:58.820\n But that gained a lot of vitality recently\n\n39:58.820 --> 40:02.300\n with the rise of connectionism, in particular deep learning.\n\n40:02.300 --> 40:03.780\n And so today, deep learning\n\n40:03.780 --> 40:06.540\n is the dominant paradigm in AI.\n\n40:06.540 --> 40:10.420\n And I feel like lots of AI researchers\n\n40:10.420 --> 40:14.980\n are conceptualizing the mind via a deep learning metaphor.\n\n40:14.980 --> 40:17.820\n Like they see the mind as a kind of\n\n40:17.820 --> 40:21.660\n randomly initialized neural network that starts blank\n\n40:21.660 --> 40:22.500\n when you're born.\n\n40:22.500 --> 40:26.100\n And then that gets trained via exposure to trained data\n\n40:26.100 --> 40:27.740\n that acquires knowledge and skills\n\n40:27.740 --> 40:29.220\n via exposure to trained data.\n\n40:29.220 --> 40:31.740\n By the way, it's a small tangent.\n\n40:32.700 --> 40:36.700\n I feel like people who are thinking about intelligence\n\n40:36.700 --> 40:39.700\n are not conceptualizing it that way.\n\n40:39.700 --> 40:41.820\n I actually haven't met too many people\n\n40:41.820 --> 40:44.700\n who believe that a neural network\n\n40:44.700 --> 40:49.700\n will be able to reason, who seriously think that rigorously.\n\n40:51.660 --> 40:54.260\n Because I think it's actually an interesting worldview.\n\n40:54.260 --> 40:56.420\n And we'll talk about it more,\n\n40:56.420 --> 41:00.420\n but it's been impressive what neural networks\n\n41:00.420 --> 41:02.100\n have been able to accomplish.\n\n41:02.100 --> 41:04.540\n And to me, I don't know, you might disagree,\n\n41:04.540 --> 41:09.540\n but it's an open question whether like scaling size\n\n41:09.820 --> 41:13.660\n eventually might lead to incredible results\n\n41:13.660 --> 41:17.060\n to us mere humans will appear as if it's general.\n\n41:17.060 --> 41:19.860\n I mean, if you ask people who are seriously thinking\n\n41:19.860 --> 41:22.660\n about intelligence, they will definitely not say\n\n41:22.660 --> 41:24.900\n that all you need to do is,\n\n41:24.900 --> 41:27.420\n like the mind is just a neural network.\n\n41:27.420 --> 41:30.420\n However, it's actually a view that's very popular,\n\n41:30.420 --> 41:31.780\n I think, in the deep learning community\n\n41:31.780 --> 41:35.460\n that many people are kind of conceptually\n\n41:35.460 --> 41:37.140\n intellectually lazy about it.\n\n41:37.140 --> 41:40.500\n Right, it's a, but I guess what I'm saying exactly right,\n\n41:40.500 --> 41:44.740\n it's, I mean, I haven't met many people\n\n41:44.740 --> 41:47.740\n and I think it would be interesting to meet a person\n\n41:47.740 --> 41:50.260\n who is not intellectually lazy about this particular topic\n\n41:50.260 --> 41:54.460\n and still believes that neural networks will go all the way.\n\n41:54.460 --> 41:56.820\n I think Yama is probably closest to that\n\n41:56.820 --> 41:57.660\n with self supervised.\n\n41:57.660 --> 41:59.660\n There are definitely people who argue\n\n41:59.660 --> 42:03.100\n that current deep learning techniques\n\n42:03.100 --> 42:06.860\n are already the way to general artificial intelligence.\n\n42:06.860 --> 42:09.460\n And that all you need to do is to scale it up\n\n42:09.460 --> 42:12.780\n to all the available trained data.\n\n42:12.780 --> 42:16.300\n And that's, if you look at the waves\n\n42:16.300 --> 42:19.500\n that OpenAI's GPT3 model has made,\n\n42:19.500 --> 42:22.700\n you see echoes of this idea.\n\n42:22.700 --> 42:27.700\n So on that topic, GPT3, similar to GPT2 actually,\n\n42:28.980 --> 42:33.060\n have captivated some part of the imagination of the public.\n\n42:33.060 --> 42:35.580\n There's just a bunch of hype of different kind.\n\n42:35.580 --> 42:37.940\n That's, I would say it's emergent.\n\n42:37.940 --> 42:39.820\n It's not artificially manufactured.\n\n42:39.820 --> 42:42.580\n It's just like people just get excited\n\n42:42.580 --> 42:43.780\n for some strange reason.\n\n42:43.780 --> 42:46.500\n And in the case of GPT3, which is funny,\n\n42:46.500 --> 42:49.100\n that there's, I believe, a couple months delay\n\n42:49.100 --> 42:51.580\n from release to hype.\n\n42:51.580 --> 42:56.580\n Maybe I'm not historically correct on that,\n\n42:56.780 --> 43:01.260\n but it feels like there was a little bit of a lack of hype\n\n43:01.260 --> 43:04.780\n and then there's a phase shift into hype.\n\n43:04.780 --> 43:07.460\n But nevertheless, there's a bunch of cool applications\n\n43:07.460 --> 43:10.380\n that seem to captivate the imagination of the public\n\n43:10.380 --> 43:12.140\n about what this language model\n\n43:12.140 --> 43:15.180\n that's trained in unsupervised way\n\n43:15.180 --> 43:19.500\n without any fine tuning is able to achieve.\n\n43:19.500 --> 43:20.900\n So what do you make of that?\n\n43:20.900 --> 43:22.940\n What are your thoughts about GPT3?\n\n43:22.940 --> 43:25.700\n Yeah, so I think what's interesting about GPT3\n\n43:25.700 --> 43:29.900\n is the idea that it may be able to learn new tasks\n\n43:31.180 --> 43:33.580\n after just being shown a few examples.\n\n43:33.580 --> 43:35.620\n So I think if it's actually capable of doing that,\n\n43:35.620 --> 43:37.580\n that's novel and that's very interesting\n\n43:37.580 --> 43:39.900\n and that's something we should investigate.\n\n43:39.900 --> 43:43.140\n That said, I must say, I'm not entirely convinced\n\n43:43.140 --> 43:47.300\n that we have shown it's capable of doing that.\n\n43:47.300 --> 43:50.980\n It's very likely, given the amount of data\n\n43:50.980 --> 43:52.220\n that the model is trained on,\n\n43:52.220 --> 43:55.700\n that what it's actually doing is pattern matching\n\n43:55.700 --> 43:58.060\n a new task you give it with a task\n\n43:58.060 --> 44:00.100\n that it's been exposed to in its trained data.\n\n44:00.100 --> 44:01.620\n It's just recognizing the task\n\n44:01.620 --> 44:05.540\n instead of just developing a model of the task, right?\n\n44:05.540 --> 44:07.660\n But there's, sorry to interrupt,\n\n44:07.660 --> 44:10.020\n there's a parallel as to what you said before,\n\n44:10.020 --> 44:14.620\n which is it's possible to see GPT3 as like the prompts\n\n44:14.620 --> 44:17.780\n it's given as a kind of SQL query\n\n44:17.780 --> 44:19.580\n into this thing that it's learned,\n\n44:19.580 --> 44:20.860\n similar to what you said before,\n\n44:20.860 --> 44:23.340\n which is language is used to query the memory.\n\n44:23.340 --> 44:24.180\n Yes.\n\n44:24.180 --> 44:26.940\n So is it possible that neural network\n\n44:26.940 --> 44:29.300\n is a giant memorization thing,\n\n44:29.300 --> 44:32.260\n but then if it gets sufficiently giant,\n\n44:32.260 --> 44:35.100\n it'll memorize sufficiently large amounts\n\n44:35.100 --> 44:37.860\n of things in the world or it becomes,\n\n44:37.860 --> 44:40.580\n or intelligence becomes a querying machine?\n\n44:40.580 --> 44:44.180\n I think it's possible that a significant chunk\n\n44:44.180 --> 44:47.500\n of intelligence is this giant associative memory.\n\n44:48.740 --> 44:51.340\n I definitely don't believe that intelligence\n\n44:51.340 --> 44:53.740\n is just a giant associative memory,\n\n44:53.740 --> 44:56.300\n but it may well be a big component.\n\n44:57.660 --> 45:02.660\n So do you think GPT3, 4, 5,\n\n45:02.660 --> 45:07.140\n GPT10 will eventually, like, what do you think,\n\n45:07.140 --> 45:08.340\n where's the ceiling?\n\n45:08.340 --> 45:10.540\n Do you think you'll be able to reason?\n\n45:11.980 --> 45:13.420\n No, that's a bad question.\n\n45:14.620 --> 45:17.340\n Like, what is the ceiling is the better question.\n\n45:17.340 --> 45:18.500\n How well is it gonna scale?\n\n45:18.500 --> 45:21.180\n How good is GPTN going to be?\n\n45:21.180 --> 45:22.020\n Yeah.\n\n45:22.020 --> 45:25.420\n So I believe GPTN is gonna.\n\n45:25.420 --> 45:26.860\n GPTN.\n\n45:26.860 --> 45:30.940\n Is gonna improve on the strength of GPT2 and 3,\n\n45:30.940 --> 45:33.980\n which is it will be able to generate, you know,\n\n45:33.980 --> 45:37.660\n ever more plausible text in context.\n\n45:37.660 --> 45:39.900\n Just monotonically increasing performance.\n\n45:41.260 --> 45:44.340\n Yes, if you train a bigger model on more data,\n\n45:44.340 --> 45:49.340\n then your text will be increasingly more context aware\n\n45:49.340 --> 45:51.220\n and increasingly more plausible\n\n45:51.220 --> 45:54.700\n in the same way that GPT3 is much better\n\n45:54.700 --> 45:57.500\n at generating plausible text compared to GPT2.\n\n45:57.500 --> 46:01.940\n But that said, I don't think just scaling up the model\n\n46:01.940 --> 46:04.180\n to more transformer layers and more trained data\n\n46:04.180 --> 46:07.020\n is gonna address the flaws of GPT3,\n\n46:07.020 --> 46:09.900\n which is that it can generate plausible text,\n\n46:09.900 --> 46:13.620\n but that text is not constrained by anything else\n\n46:13.620 --> 46:15.180\n other than plausibility.\n\n46:15.180 --> 46:19.180\n So in particular, it's not constrained by factualness\n\n46:19.180 --> 46:21.820\n or even consistency, which is why it's very easy\n\n46:21.820 --> 46:23.860\n to get GPT3 to generate statements\n\n46:23.860 --> 46:26.260\n that are factually untrue.\n\n46:26.260 --> 46:29.580\n Or to generate statements that are even self contradictory.\n\n46:29.580 --> 46:30.420\n Right?\n\n46:30.420 --> 46:35.420\n Because it's only goal is plausibility,\n\n46:35.420 --> 46:37.620\n and it has no other constraints.\n\n46:37.620 --> 46:40.300\n It's not constrained to be self consistent, for instance.\n\n46:40.300 --> 46:41.140\n Right?\n\n46:41.140 --> 46:43.540\n And so for this reason, one thing that I thought\n\n46:43.540 --> 46:46.780\n was very interesting with GPT3 is that you can\n\n46:46.780 --> 46:49.780\n predetermine the answer it will give you\n\n46:49.780 --> 46:52.020\n by asking the question in a specific way,\n\n46:52.020 --> 46:55.260\n because it's very responsive to the way you ask the question.\n\n46:55.260 --> 47:00.260\n Since it has no understanding of the content of the question.\n\n47:00.260 --> 47:01.100\n Right.\n\n47:01.100 --> 47:05.620\n And if you have the same question in two different ways\n\n47:05.620 --> 47:09.020\n that are basically adversarially engineered\n\n47:09.020 --> 47:10.260\n to produce certain answer,\n\n47:10.260 --> 47:12.740\n you will get two different answers,\n\n47:12.740 --> 47:14.180\n two contradictory answers.\n\n47:14.180 --> 47:16.660\n It's very susceptible to adversarial attacks, essentially.\n\n47:16.660 --> 47:17.780\n Potentially, yes.\n\n47:17.780 --> 47:20.820\n So in general, the problem with these models,\n\n47:20.820 --> 47:24.180\n these generative models, is that they are very good\n\n47:24.180 --> 47:27.220\n at generating plausible text,\n\n47:27.220 --> 47:29.660\n but that's just not enough.\n\n47:29.660 --> 47:30.500\n Right?\n\n47:33.620 --> 47:36.500\n I think one avenue that would be very interesting\n\n47:36.500 --> 47:39.460\n to make progress is to make it possible\n\n47:40.780 --> 47:43.860\n to write programs over the latent space\n\n47:43.860 --> 47:45.620\n that these models operate on.\n\n47:45.620 --> 47:49.460\n That you would rely on these self supervised models\n\n47:49.460 --> 47:54.340\n to generate a sort of like pool of knowledge and concepts\n\n47:54.340 --> 47:55.260\n and common sense.\n\n47:55.260 --> 47:57.180\n And then you would be able to write\n\n47:57.180 --> 48:01.460\n explicit reasoning programs over it.\n\n48:01.460 --> 48:03.660\n Because the current problem with GPT3 is that\n\n48:03.660 --> 48:08.660\n it can be quite difficult to get it to do what you want to do.\n\n48:09.420 --> 48:12.420\n If you want to turn GPT3 into products,\n\n48:12.420 --> 48:14.780\n you need to put constraints on it.\n\n48:14.780 --> 48:19.500\n You need to force it to obey certain rules.\n\n48:19.500 --> 48:22.540\n So you need a way to program it explicitly.\n\n48:22.540 --> 48:24.220\n Yeah, so if you look at its ability\n\n48:24.220 --> 48:26.140\n to do program synthesis,\n\n48:26.140 --> 48:29.060\n it generates, like you said, something that's plausible.\n\n48:29.060 --> 48:32.580\n Yeah, so if you try to make it generate programs,\n\n48:32.580 --> 48:35.940\n it will perform well for any program\n\n48:35.940 --> 48:38.700\n that it has seen in its training data.\n\n48:38.700 --> 48:42.940\n But because program space is not interpretive, right?\n\n48:42.940 --> 48:46.740\n It's not going to be able to generalize to problems\n\n48:46.740 --> 48:48.700\n it hasn't seen before.\n\n48:48.700 --> 48:53.700\n Now that's currently, do you think sort of an absurd,\n\n48:54.980 --> 48:59.980\n but I think useful, I guess, intuition builder is,\n\n49:00.340 --> 49:05.340\n you know, the GPT3 has 175 billion parameters.\n\n49:07.340 --> 49:11.740\n Human brain has 100, has about a thousand times that\n\n49:11.740 --> 49:14.820\n or more in terms of number of synapses.\n\n49:16.380 --> 49:21.180\n Do you think, obviously, very different kinds of things,\n\n49:21.180 --> 49:26.180\n but there is some degree of similarity.\n\n49:26.380 --> 49:30.700\n Do you think, what do you think GPT will look like\n\n49:30.700 --> 49:34.180\n when it has 100 trillion parameters?\n\n49:34.180 --> 49:39.100\n You think our conversation might be in nature different?\n\n49:39.100 --> 49:42.940\n Like, because you've criticized GPT3 very effectively now.\n\n49:42.940 --> 49:43.900\n Do you think?\n\n49:45.420 --> 49:46.940\n No, I don't think so.\n\n49:46.940 --> 49:51.020\n So to begin with, the bottleneck with scaling up GPT3,\n\n49:51.020 --> 49:54.860\n GPT models, generative pre trained transformer models,\n\n49:54.860 --> 49:57.620\n is not going to be the size of the model\n\n49:57.620 --> 49:59.580\n or how long it takes to train it.\n\n49:59.580 --> 50:01.860\n The bottleneck is going to be the trained data\n\n50:01.860 --> 50:05.540\n because OpenAI is already training GPT3\n\n50:05.540 --> 50:08.860\n on a core of basically the entire web, right?\n\n50:08.860 --> 50:09.820\n And that's a lot of data.\n\n50:09.820 --> 50:12.140\n So you could imagine training on more data than that,\n\n50:12.140 --> 50:14.460\n like Google could train on more data than that,\n\n50:14.460 --> 50:17.500\n but it would still be only incrementally more data.\n\n50:17.500 --> 50:21.340\n And I don't recall exactly how much more data GPT3\n\n50:21.340 --> 50:22.820\n was trained on compared to GPT2,\n\n50:22.820 --> 50:25.100\n but it's probably at least like a hundred,\n\n50:25.100 --> 50:26.620\n maybe even a thousand X.\n\n50:26.620 --> 50:28.460\n I don't have the exact number.\n\n50:28.460 --> 50:30.140\n You're not going to be able to train a model\n\n50:30.140 --> 50:34.180\n on a hundred more data than what you're already doing.\n\n50:34.180 --> 50:35.300\n So that's brilliant.\n\n50:35.300 --> 50:38.940\n So it's easier to think of compute as a bottleneck\n\n50:38.940 --> 50:41.380\n and then arguing that we can remove that bottleneck.\n\n50:41.380 --> 50:43.060\n But we can remove the compute bottleneck.\n\n50:43.060 --> 50:44.580\n I don't think it's a big problem.\n\n50:44.580 --> 50:48.500\n If you look at the pace at which we've improved\n\n50:48.500 --> 50:51.340\n the efficiency of deep learning models\n\n50:51.340 --> 50:54.060\n in the past few years,\n\n50:54.060 --> 50:57.180\n I'm not worried about train time bottlenecks\n\n50:57.180 --> 50:58.740\n or model size bottlenecks.\n\n50:59.580 --> 51:01.140\n The bottleneck in the case\n\n51:01.140 --> 51:03.420\n of these generative transformer models\n\n51:03.420 --> 51:05.540\n is absolutely the trained data.\n\n51:05.540 --> 51:07.740\n What about the quality of the data?\n\n51:07.740 --> 51:08.580\n So, yeah.\n\n51:08.580 --> 51:10.900\n So the quality of the data is an interesting point.\n\n51:10.900 --> 51:11.900\n The thing is,\n\n51:11.900 --> 51:14.460\n if you're going to want to use these models\n\n51:14.460 --> 51:15.820\n in real products,\n\n51:16.900 --> 51:20.060\n then you want to feed them data\n\n51:20.060 --> 51:23.460\n that's as high quality, as factual,\n\n51:23.460 --> 51:25.620\n I would say as unbiased as possible,\n\n51:25.620 --> 51:27.340\n that there's not really such a thing\n\n51:27.340 --> 51:30.500\n as unbiased data in the first place.\n\n51:30.500 --> 51:34.020\n But you probably don't want to train it on Reddit,\n\n51:34.020 --> 51:34.860\n for instance.\n\n51:34.860 --> 51:37.060\n It sounds like a bad plan.\n\n51:37.060 --> 51:38.620\n So from my personal experience,\n\n51:38.620 --> 51:42.740\n working with large scale deep learning models.\n\n51:42.740 --> 51:46.580\n So at some point I was working on a model at Google\n\n51:46.580 --> 51:51.580\n that's trained on 350 million labeled images.\n\n51:52.340 --> 51:53.660\n It's an image classification model.\n\n51:53.660 --> 51:54.660\n That's a lot of images.\n\n51:54.660 --> 51:58.140\n That's like probably most publicly available images\n\n51:58.140 --> 52:00.980\n on the web at the time.\n\n52:00.980 --> 52:03.900\n And it was a very noisy data set\n\n52:03.900 --> 52:07.820\n because the labels were not originally annotated by hand,\n\n52:07.820 --> 52:08.660\n by humans.\n\n52:08.660 --> 52:12.420\n They were automatically derived from like tags\n\n52:12.420 --> 52:14.300\n on social media,\n\n52:14.300 --> 52:16.820\n or just keywords in the same page\n\n52:16.820 --> 52:18.220\n as the image was found and so on.\n\n52:18.220 --> 52:19.140\n So it was very noisy.\n\n52:19.140 --> 52:24.140\n And it turned out that you could easily get a better model,\n\n52:25.340 --> 52:26.500\n not just by training,\n\n52:26.500 --> 52:29.980\n like if you train on more of the noisy data,\n\n52:29.980 --> 52:31.540\n you get an incrementally better model,\n\n52:31.540 --> 52:35.500\n but you very quickly hit diminishing returns.\n\n52:35.500 --> 52:36.660\n On the other hand,\n\n52:36.660 --> 52:38.420\n if you train on smaller data set\n\n52:38.420 --> 52:40.020\n with higher quality annotations,\n\n52:40.020 --> 52:45.020\n quality annotations that are actually made by humans,\n\n52:45.380 --> 52:47.340\n you get a better model.\n\n52:47.340 --> 52:49.860\n And it also takes less time to train it.\n\n52:49.860 --> 52:51.580\n Yeah, that's fascinating.\n\n52:51.580 --> 52:53.500\n It's the self supervised learning.\n\n52:53.500 --> 52:58.500\n There's a way to get better doing the automated labeling.\n\n52:58.780 --> 53:03.780\n Yeah, so you can enrich or refine your labels\n\n53:04.620 --> 53:05.860\n in an automated way.\n\n53:05.860 --> 53:07.460\n That's correct.\n\n53:07.460 --> 53:08.700\n Do you have a hope for,\n\n53:08.700 --> 53:09.580\n I don't know if you're familiar\n\n53:09.580 --> 53:11.980\n with the idea of a semantic web.\n\n53:11.980 --> 53:15.620\n Is a semantic web just for people who are not familiar\n\n53:15.620 --> 53:20.620\n and is the idea of being able to convert the internet\n\n53:20.620 --> 53:25.620\n or be able to attach like semantic meaning\n\n53:25.700 --> 53:27.940\n to the words on the internet,\n\n53:27.940 --> 53:29.780\n the sentences, the paragraphs,\n\n53:29.780 --> 53:33.940\n to be able to convert information on the internet\n\n53:33.940 --> 53:35.660\n or some fraction of the internet\n\n53:35.660 --> 53:38.180\n into something that's interpretable by machines.\n\n53:39.140 --> 53:42.980\n That was kind of a dream for,\n\n53:44.260 --> 53:47.020\n I think the semantic web papers in the nineties,\n\n53:47.020 --> 53:49.740\n it's kind of the dream that, you know,\n\n53:49.740 --> 53:52.340\n the internet is full of rich, exciting information.\n\n53:52.340 --> 53:54.420\n Even just looking at Wikipedia,\n\n53:54.420 --> 53:57.780\n we should be able to use that as data for machines.\n\n53:57.780 --> 53:58.980\n And so far it's not,\n\n53:58.980 --> 54:01.220\n it's not really in a format that's available to machines.\n\n54:01.220 --> 54:04.540\n So no, I don't think the semantic web will ever work\n\n54:04.540 --> 54:08.020\n simply because it would be a lot of work, right?\n\n54:08.020 --> 54:12.020\n To make, to provide that information in structured form.\n\n54:12.020 --> 54:13.820\n And there is not really any incentive\n\n54:13.820 --> 54:16.340\n for anyone to provide that work.\n\n54:16.340 --> 54:21.180\n So I think the way forward to make the knowledge\n\n54:21.180 --> 54:22.820\n on the web available to machines\n\n54:22.820 --> 54:26.620\n is actually something closer to unsupervised deep learning.\n\n54:29.140 --> 54:32.220\n So GPT3 is actually a bigger step in the direction\n\n54:32.220 --> 54:34.940\n of making the knowledge of the web available to machines\n\n54:34.940 --> 54:36.660\n than the semantic web was.\n\n54:36.660 --> 54:40.140\n Yeah, perhaps in a human centric sense,\n\n54:40.140 --> 54:47.300\n it feels like GPT3 hasn't learned anything\n\n54:47.300 --> 54:50.340\n that could be used to reason.\n\n54:50.340 --> 54:52.820\n But that might be just the early days.\n\n54:52.820 --> 54:54.300\n Yeah, I think that's correct.\n\n54:54.300 --> 54:57.340\n I think the forms of reasoning that you see it perform\n\n54:57.340 --> 55:00.660\n are basically just reproducing patterns\n\n55:00.660 --> 55:02.380\n that it has seen in string data.\n\n55:02.380 --> 55:06.580\n So of course, if you're trained on the entire web,\n\n55:06.580 --> 55:09.340\n then you can produce an illusion of reasoning\n\n55:09.340 --> 55:10.740\n in many different situations.\n\n55:10.740 --> 55:13.100\n But it will break down if it's presented\n\n55:13.100 --> 55:15.260\n with a novel situation.\n\n55:15.260 --> 55:17.660\n That's the open question between the illusion of reasoning\n\n55:17.660 --> 55:18.700\n and actual reasoning, yeah.\n\n55:18.700 --> 55:19.660\n Yes.\n\n55:19.660 --> 55:22.780\n The power to adapt to something that is genuinely new.\n\n55:22.780 --> 55:28.020\n Because the thing is, even imagine you had,\n\n55:28.020 --> 55:31.100\n you could train on every bit of data\n\n55:31.100 --> 55:35.500\n ever generated in the history of humanity.\n\n55:35.500 --> 55:38.540\n It remains, that model would be capable\n\n55:38.540 --> 55:43.220\n of anticipating many different possible situations.\n\n55:43.220 --> 55:45.660\n But it remains that the future is\n\n55:45.660 --> 55:48.940\n going to be something different.\n\n55:48.940 --> 55:52.940\n For instance, if you train a GPT3 model on data\n\n55:52.940 --> 55:55.700\n from the year 2002, for instance,\n\n55:55.700 --> 55:58.260\n and then use it today, it's going to be missing many things.\n\n55:58.260 --> 56:00.740\n It's going to be missing many common sense\n\n56:00.740 --> 56:02.620\n facts about the world.\n\n56:02.620 --> 56:05.820\n It's even going to be missing vocabulary and so on.\n\n56:05.820 --> 56:09.580\n Yeah, it's interesting that GPT3 even doesn't have,\n\n56:09.580 --> 56:13.580\n I think, any information about the coronavirus.\n\n56:13.580 --> 56:14.980\n Yes.\n\n56:14.980 --> 56:19.620\n Which is why a system that's, you\n\n56:19.620 --> 56:21.300\n tell that the system is intelligent\n\n56:21.300 --> 56:22.860\n when it's capable to adapt.\n\n56:22.860 --> 56:25.580\n So intelligence is going to require\n\n56:25.580 --> 56:28.140\n some amount of continuous learning.\n\n56:28.140 --> 56:31.020\n It's also going to require some amount of improvisation.\n\n56:31.020 --> 56:33.980\n It's not enough to assume that what you're\n\n56:33.980 --> 56:36.780\n going to be asked to do is something\n\n56:36.780 --> 56:39.300\n that you've seen before, or something\n\n56:39.300 --> 56:42.700\n that is a simple interpolation of things you've seen before.\n\n56:42.700 --> 56:43.340\n Yeah.\n\n56:43.340 --> 56:49.060\n In fact, that model breaks down for even very\n\n56:49.060 --> 56:52.300\n tasks that look relatively simple from a distance,\n\n56:52.300 --> 56:55.660\n like L5 self driving, for instance.\n\n56:55.660 --> 56:58.420\n Google had a paper a couple of years\n\n56:58.420 --> 57:04.540\n back showing that something like 30 million different road\n\n57:04.540 --> 57:07.180\n situations were actually completely insufficient\n\n57:07.180 --> 57:09.780\n to train a driving model.\n\n57:09.780 --> 57:11.740\n It wasn't even L2, right?\n\n57:11.740 --> 57:12.820\n And that's a lot of data.\n\n57:12.820 --> 57:16.940\n That's a lot more data than the 20 or 30 hours of driving\n\n57:16.940 --> 57:19.580\n that a human needs to learn to drive,\n\n57:19.580 --> 57:21.900\n given the knowledge they've already accumulated.\n\n57:21.900 --> 57:25.540\n Well, let me ask you on that topic.\n\n57:25.540 --> 57:31.100\n Elon Musk, Tesla Autopilot, one of the only companies,\n\n57:31.100 --> 57:34.660\n I believe, is really pushing for a learning based approach.\n\n57:34.660 --> 57:37.020\n Are you skeptical that that kind of network\n\n57:37.020 --> 57:39.460\n can achieve level 4?\n\n57:39.460 --> 57:42.660\n L4 is probably achievable.\n\n57:42.660 --> 57:44.420\n L5 probably not.\n\n57:44.420 --> 57:45.860\n What's the distinction there?\n\n57:45.860 --> 57:49.340\n Is L5 is completely you can just fall asleep?\n\n57:49.340 --> 57:51.060\n Yeah, L5 is basically human level.\n\n57:51.060 --> 57:53.740\n Well, with driving, we have to be careful saying human level,\n\n57:53.740 --> 57:57.180\n because that's the most of the drivers.\n\n57:57.180 --> 58:00.620\n Yeah, that's the clearest example of cars\n\n58:00.620 --> 58:05.020\n will most likely be much safer than humans in many situations\n\n58:05.020 --> 58:06.540\n where humans fail.\n\n58:06.540 --> 58:09.860\n It's the vice versa question.\n\n58:09.860 --> 58:13.820\n I'll tell you, the thing is the amount of trained data\n\n58:13.820 --> 58:17.020\n you would need to anticipate for pretty much every possible\n\n58:17.020 --> 58:20.460\n situation you learn content in the real world\n\n58:20.460 --> 58:23.500\n is such that it's not entirely unrealistic\n\n58:23.500 --> 58:25.540\n to think that at some point in the future,\n\n58:25.540 --> 58:27.700\n we'll develop a system that's trained on enough data,\n\n58:27.700 --> 58:32.340\n especially provided that we can simulate a lot of that data.\n\n58:32.340 --> 58:34.500\n We don't necessarily need actual cars\n\n58:34.500 --> 58:37.620\n on the road for everything.\n\n58:37.620 --> 58:39.780\n But it's a massive effort.\n\n58:39.780 --> 58:42.100\n And it turns out you can create a system that's\n\n58:42.100 --> 58:45.180\n much more adaptive, that can generalize much better\n\n58:45.180 --> 58:52.060\n if you just add explicit models of the surroundings\n\n58:52.060 --> 58:53.580\n of the car.\n\n58:53.580 --> 58:55.180\n And if you use deep learning for what\n\n58:55.180 --> 58:57.460\n it's good at, which is to provide\n\n58:57.460 --> 58:59.500\n perceptive information.\n\n58:59.500 --> 59:02.460\n So in general, deep learning is a way\n\n59:02.460 --> 59:05.740\n to encode perception and a way to encode intuition.\n\n59:05.740 --> 59:11.100\n But it is not a good medium for any sort of explicit reasoning.\n\n59:11.100 --> 59:15.940\n And in AI systems today, strong generalization\n\n59:15.940 --> 59:21.020\n tends to come from explicit models,\n\n59:21.020 --> 59:24.540\n tend to come from abstractions in the human mind that\n\n59:24.540 --> 59:29.540\n are encoded in program form by a human engineer.\n\n59:29.540 --> 59:31.580\n These are the abstractions you can actually generalize, not\n\n59:31.580 --> 59:33.380\n the sort of weak abstraction that\n\n59:33.380 --> 59:34.860\n is learned by a neural network.\n\n59:34.860 --> 59:38.540\n Yeah, and the question is how much reasoning,\n\n59:38.540 --> 59:41.940\n how much strong abstractions are required\n\n59:41.940 --> 59:44.620\n to solve particular tasks like driving.\n\n59:44.620 --> 59:46.540\n That's the question.\n\n59:46.540 --> 59:48.860\n Or human life existence.\n\n59:48.860 --> 59:53.340\n How much strong abstractions does existence require?\n\n59:53.340 --> 59:58.100\n But more specifically on driving,\n\n59:58.100 --> 1:00:02.180\n that seems to be a coupled question about intelligence.\n\n1:00:02.180 --> 1:00:05.740\n How much intelligence, how do you\n\n1:00:05.740 --> 1:00:07.140\n build an intelligent system?\n\n1:00:07.140 --> 1:00:11.420\n And the coupled problem, how hard is this problem?\n\n1:00:11.420 --> 1:00:14.380\n How much intelligence does this problem actually require?\n\n1:00:14.380 --> 1:00:18.460\n So we get to cheat because we get\n\n1:00:18.460 --> 1:00:20.700\n to look at the problem.\n\n1:00:20.700 --> 1:00:22.860\n It's not like you get to close our eyes\n\n1:00:22.860 --> 1:00:24.740\n and completely new to driving.\n\n1:00:24.740 --> 1:00:27.020\n We get to do what we do as human beings, which\n\n1:00:27.020 --> 1:00:31.100\n is for the majority of our life before we ever\n\n1:00:31.100 --> 1:00:32.460\n learn, quote unquote, to drive.\n\n1:00:32.460 --> 1:00:35.460\n We get to watch other cars and other people drive.\n\n1:00:35.460 --> 1:00:36.540\n We get to be in cars.\n\n1:00:36.540 --> 1:00:37.540\n We get to watch.\n\n1:00:37.540 --> 1:00:39.500\n We get to see movies about cars.\n\n1:00:39.500 --> 1:00:42.700\n We get to observe all this stuff.\n\n1:00:42.700 --> 1:00:45.060\n And that's similar to what neural networks are doing.\n\n1:00:45.060 --> 1:00:50.340\n It's getting a lot of data, and the question\n\n1:00:50.340 --> 1:00:55.740\n is, yeah, how many leaps of reasoning genius\n\n1:00:55.740 --> 1:00:59.420\n is required to be able to actually effectively drive?\n\n1:00:59.420 --> 1:01:01.260\n I think it's a good example of driving.\n\n1:01:01.260 --> 1:01:06.260\n I mean, sure, you've seen a lot of cars in your life\n\n1:01:06.260 --> 1:01:07.700\n before you learned to drive.\n\n1:01:07.700 --> 1:01:10.620\n But let's say you've learned to drive in Silicon Valley,\n\n1:01:10.620 --> 1:01:14.100\n and now you rent a car in Tokyo.\n\n1:01:14.100 --> 1:01:16.820\n Well, now everyone is driving on the other side of the road,\n\n1:01:16.820 --> 1:01:19.220\n and the signs are different, and the roads\n\n1:01:19.220 --> 1:01:20.500\n are more narrow and so on.\n\n1:01:20.500 --> 1:01:22.660\n So it's a very, very different environment.\n\n1:01:22.660 --> 1:01:26.780\n And a smart human, even an average human,\n\n1:01:26.780 --> 1:01:29.300\n should be able to just zero shot it,\n\n1:01:29.300 --> 1:01:34.260\n to just be operational in this very different environment\n\n1:01:34.260 --> 1:01:40.500\n right away, despite having had no contact with the novel\n\n1:01:40.500 --> 1:01:44.140\n complexity that is contained in this environment.\n\n1:01:44.140 --> 1:01:49.780\n And that novel complexity is not just an interpolation\n\n1:01:49.780 --> 1:01:52.420\n over the situations that you've encountered previously,\n\n1:01:52.420 --> 1:01:55.060\n like learning to drive in the US.\n\n1:01:55.060 --> 1:01:57.300\n I would say the reason I ask is one\n\n1:01:57.300 --> 1:01:59.940\n of the most interesting tests of intelligence\n\n1:01:59.940 --> 1:02:04.460\n we have today actively, which is driving,\n\n1:02:04.460 --> 1:02:06.740\n in terms of having an impact on the world.\n\n1:02:06.740 --> 1:02:09.900\n When do you think we'll pass that test of intelligence?\n\n1:02:09.900 --> 1:02:13.380\n So I don't think driving is that much of a test of intelligence,\n\n1:02:13.380 --> 1:02:18.500\n because again, there is no task for which skill at that task\n\n1:02:18.500 --> 1:02:21.980\n demonstrates intelligence, unless it's\n\n1:02:21.980 --> 1:02:26.540\n a kind of meta task that involves acquiring new skills.\n\n1:02:26.540 --> 1:02:28.260\n So I don't think, I think you can actually\n\n1:02:28.260 --> 1:02:35.060\n solve driving without having any real amount of intelligence.\n\n1:02:35.060 --> 1:02:39.540\n For instance, if you did have infinite trained data,\n\n1:02:39.540 --> 1:02:42.660\n you could just literally train an end to end deep learning\n\n1:02:42.660 --> 1:02:45.700\n model that does driving, provided infinite trained data.\n\n1:02:45.700 --> 1:02:48.940\n The only problem with the whole idea\n\n1:02:48.940 --> 1:02:53.500\n is collecting a data set that's sufficiently comprehensive,\n\n1:02:53.500 --> 1:02:56.380\n that covers the very long tail of possible situations\n\n1:02:56.380 --> 1:02:57.260\n you might encounter.\n\n1:02:57.260 --> 1:02:59.380\n And it's really just a scale problem.\n\n1:02:59.380 --> 1:03:04.500\n So I think there's nothing fundamentally wrong\n\n1:03:04.500 --> 1:03:06.500\n with this plan, with this idea.\n\n1:03:06.500 --> 1:03:11.260\n It's just that it strikes me as a fairly inefficient thing\n\n1:03:11.260 --> 1:03:17.340\n to do, because you run into this scaling issue with diminishing\n\n1:03:17.340 --> 1:03:17.860\n returns.\n\n1:03:17.860 --> 1:03:21.980\n Whereas if instead you took a more manual engineering\n\n1:03:21.980 --> 1:03:29.020\n approach, where you use deep learning modules in combination\n\n1:03:29.020 --> 1:03:33.220\n with engineering an explicit model of the surrounding\n\n1:03:33.220 --> 1:03:36.100\n of the cars, and you bridge the two in a clever way,\n\n1:03:36.100 --> 1:03:38.900\n your model will actually start generalizing\n\n1:03:38.900 --> 1:03:40.900\n much earlier and more effectively\n\n1:03:40.900 --> 1:03:42.540\n than the end to end deep learning model.\n\n1:03:42.540 --> 1:03:46.500\n So why would you not go with the more manual engineering\n\n1:03:46.500 --> 1:03:47.900\n oriented approach?\n\n1:03:47.900 --> 1:03:50.620\n Even if you created that system, either the end\n\n1:03:50.620 --> 1:03:52.500\n to end deep learning model system that's\n\n1:03:52.500 --> 1:03:58.500\n running infinite data, or the slightly more human system,\n\n1:03:58.500 --> 1:04:02.740\n I don't think achieving L5 would demonstrate\n\n1:04:02.740 --> 1:04:04.540\n general intelligence or intelligence\n\n1:04:04.540 --> 1:04:05.740\n of any generality at all.\n\n1:04:05.740 --> 1:04:10.580\n Again, the only possible test of generality in AI\n\n1:04:10.580 --> 1:04:12.740\n would be a test that looks at skill acquisition\n\n1:04:12.740 --> 1:04:14.500\n over unknown tasks.\n\n1:04:14.500 --> 1:04:17.380\n For instance, you could take your L5 driver\n\n1:04:17.380 --> 1:04:21.540\n and ask it to learn to pilot a commercial airplane,\n\n1:04:21.540 --> 1:04:22.420\n for instance.\n\n1:04:22.420 --> 1:04:25.180\n And then you would look at how much human involvement is\n\n1:04:25.180 --> 1:04:26.740\n required and how much strength data\n\n1:04:26.740 --> 1:04:29.860\n is required for the system to learn to pilot an airplane.\n\n1:04:29.860 --> 1:04:35.020\n And that gives you a measure of how intelligent\n\n1:04:35.020 --> 1:04:35.860\n that system really is.\n\n1:04:35.860 --> 1:04:37.540\n Yeah, well, I mean, that's a big leap.\n\n1:04:37.540 --> 1:04:38.060\n I get you.\n\n1:04:38.060 --> 1:04:42.820\n But I'm more interested, as a problem, I would see,\n\n1:04:42.820 --> 1:04:47.380\n to me, driving is a black box that\n\n1:04:47.380 --> 1:04:51.180\n can generate novel situations at some rate,\n\n1:04:51.180 --> 1:04:53.500\n what people call edge cases.\n\n1:04:53.500 --> 1:04:56.380\n So it does have newness that keeps being like,\n\n1:04:56.380 --> 1:04:59.460\n we're confronted, let's say, once a month.\n\n1:04:59.460 --> 1:05:00.660\n It is a very long tail, yes.\n\n1:05:00.660 --> 1:05:01.460\n It's a long tail.\n\n1:05:01.460 --> 1:05:05.620\n That doesn't mean you cannot solve it just\n\n1:05:05.620 --> 1:05:08.740\n by training a statistical model and a lot of data.\n\n1:05:08.740 --> 1:05:09.820\n Huge amount of data.\n\n1:05:09.820 --> 1:05:11.900\n It's really a matter of scale.\n\n1:05:11.900 --> 1:05:16.020\n But I guess what I'm saying is if you have a vehicle that\n\n1:05:16.020 --> 1:05:21.580\n achieves level 5, it is going to be able to deal\n\n1:05:21.580 --> 1:05:23.980\n with new situations.\n\n1:05:23.980 --> 1:05:30.860\n Or, I mean, the data is so large that the rate of new situations\n\n1:05:30.860 --> 1:05:32.100\n is very low.\n\n1:05:32.100 --> 1:05:33.140\n Yes.\n\n1:05:33.140 --> 1:05:34.220\n That's not intelligent.\n\n1:05:34.220 --> 1:05:37.780\n So if we go back to your kind of definition of intelligence,\n\n1:05:37.780 --> 1:05:39.460\n it's the efficiency.\n\n1:05:39.460 --> 1:05:42.380\n With which you can adapt to new situations,\n\n1:05:42.380 --> 1:05:45.700\n to truly new situations, not situations you've seen before.\n\n1:05:45.700 --> 1:05:48.460\n Not situations that could be anticipated by your creators,\n\n1:05:48.460 --> 1:05:51.740\n by the creators of the system, but truly new situations.\n\n1:05:51.740 --> 1:05:54.940\n The efficiency with which you acquire new skills.\n\n1:05:54.940 --> 1:05:58.260\n If you require, if in order to pick up a new skill,\n\n1:05:58.260 --> 1:06:03.180\n you require a very extensive training\n\n1:06:03.180 --> 1:06:05.900\n data set of most possible situations\n\n1:06:05.900 --> 1:06:08.940\n that can occur in the practice of that skill,\n\n1:06:08.940 --> 1:06:10.620\n then the system is not intelligent.\n\n1:06:10.620 --> 1:06:15.060\n It is mostly just a lookup table.\n\n1:06:15.060 --> 1:06:16.140\n Yeah.\n\n1:06:16.140 --> 1:06:20.100\n Well, likewise, if in order to acquire a skill,\n\n1:06:20.100 --> 1:06:23.300\n you need a human engineer to write down\n\n1:06:23.300 --> 1:06:26.940\n a bunch of rules that cover most or every possible situation.\n\n1:06:26.940 --> 1:06:29.620\n Likewise, the system is not intelligent.\n\n1:06:29.620 --> 1:06:33.100\n The system is merely the output artifact\n\n1:06:33.100 --> 1:06:39.300\n of a process that happens in the minds of the engineers that\n\n1:06:39.300 --> 1:06:40.820\n are creating it.\n\n1:06:40.820 --> 1:06:44.700\n It is encoding an abstraction that's\n\n1:06:44.700 --> 1:06:46.420\n produced by the human mind.\n\n1:06:46.420 --> 1:06:51.500\n And intelligence would actually be\n\n1:06:51.500 --> 1:06:56.260\n the process of autonomously producing this abstraction.\n\n1:06:56.260 --> 1:06:57.180\n Yeah.\n\n1:06:57.180 --> 1:06:59.260\n Not like if you take an abstraction\n\n1:06:59.260 --> 1:07:02.900\n and you encode it on a piece of paper or in a computer program,\n\n1:07:02.900 --> 1:07:05.940\n the abstraction itself is not intelligent.\n\n1:07:05.940 --> 1:07:09.220\n What's intelligent is the agent that's\n\n1:07:09.220 --> 1:07:11.780\n capable of producing these abstractions.\n\n1:07:11.780 --> 1:07:16.500\n Yeah, it feels like there's a little bit of a gray area.\n\n1:07:16.500 --> 1:07:18.860\n Because you're basically saying that deep learning forms\n\n1:07:18.860 --> 1:07:21.500\n abstractions, too.\n\n1:07:21.500 --> 1:07:24.660\n But those abstractions do not seem\n\n1:07:24.660 --> 1:07:29.140\n to be effective for generalizing far outside of the things\n\n1:07:29.140 --> 1:07:30.100\n that it's already seen.\n\n1:07:30.100 --> 1:07:31.620\n But generalize a little bit.\n\n1:07:31.620 --> 1:07:32.620\n Yeah, absolutely.\n\n1:07:32.620 --> 1:07:34.820\n No, deep learning does generalize a little bit.\n\n1:07:34.820 --> 1:07:36.980\n Generalization is not binary.\n\n1:07:36.980 --> 1:07:38.140\n It's more like a spectrum.\n\n1:07:38.140 --> 1:07:38.740\n Yeah.\n\n1:07:38.740 --> 1:07:40.860\n And there's a certain point, it's a gray area,\n\n1:07:40.860 --> 1:07:42.500\n but there's a certain point where\n\n1:07:42.500 --> 1:07:47.340\n there's an impressive degree of generalization that happens.\n\n1:07:47.340 --> 1:07:50.420\n No, I guess exactly what you were saying\n\n1:07:50.420 --> 1:07:56.420\n is intelligence is how efficiently you're\n\n1:07:56.420 --> 1:08:02.300\n able to generalize far outside of the distribution of things\n\n1:08:02.300 --> 1:08:03.260\n you've seen already.\n\n1:08:03.260 --> 1:08:03.780\n Yes.\n\n1:08:03.780 --> 1:08:07.180\n So it's both the distance of how far you can,\n\n1:08:07.180 --> 1:08:10.180\n how new, how radically new something is,\n\n1:08:10.180 --> 1:08:12.740\n and how efficiently you're able to deal with that.\n\n1:08:12.740 --> 1:08:17.420\n So you can think of intelligence as a measure of an information\n\n1:08:17.420 --> 1:08:19.140\n conversion ratio.\n\n1:08:19.140 --> 1:08:23.420\n Imagine a space of possible situations.\n\n1:08:23.420 --> 1:08:27.860\n And you've covered some of them.\n\n1:08:27.860 --> 1:08:30.180\n So you have some amount of information\n\n1:08:30.180 --> 1:08:32.020\n about your space of possible situations\n\n1:08:32.020 --> 1:08:34.420\n that's provided by the situations you already know.\n\n1:08:34.420 --> 1:08:36.540\n And that's, on the other hand, also provided\n\n1:08:36.540 --> 1:08:40.420\n by the prior knowledge that the system brings\n\n1:08:40.420 --> 1:08:42.340\n to the table, the prior knowledge embedded\n\n1:08:42.340 --> 1:08:43.660\n in the system.\n\n1:08:43.660 --> 1:08:46.420\n So the system starts with some information\n\n1:08:46.420 --> 1:08:48.860\n about the problem, about the task.\n\n1:08:48.860 --> 1:08:52.500\n And it's about going from that information\n\n1:08:52.500 --> 1:08:55.340\n to a program, what we would call a skill program,\n\n1:08:55.340 --> 1:08:58.860\n a behavioral program, that can cover a large area\n\n1:08:58.860 --> 1:09:01.660\n of possible situation space.\n\n1:09:01.660 --> 1:09:04.100\n And essentially, the ratio between that area\n\n1:09:04.100 --> 1:09:09.740\n and the amount of information you start with is intelligence.\n\n1:09:09.740 --> 1:09:14.180\n So a very smart agent can make efficient use\n\n1:09:14.180 --> 1:09:17.580\n of very little information about a new problem\n\n1:09:17.580 --> 1:09:19.580\n and very little prior knowledge as well\n\n1:09:19.580 --> 1:09:23.380\n to cover a very large area of potential situations\n\n1:09:23.380 --> 1:09:28.500\n in that problem without knowing what these future new situations\n\n1:09:28.500 --> 1:09:31.140\n are going to be.\n\n1:09:31.140 --> 1:09:34.540\n So one of the other big things you talk about in the paper,\n\n1:09:34.540 --> 1:09:36.300\n we've talked about a little bit already,\n\n1:09:36.300 --> 1:09:37.860\n but let's talk about it some more,\n\n1:09:37.860 --> 1:09:41.020\n is the actual tests of intelligence.\n\n1:09:41.020 --> 1:09:45.980\n So if we look at human and machine intelligence,\n\n1:09:45.980 --> 1:09:48.100\n do you think tests of intelligence\n\n1:09:48.100 --> 1:09:50.340\n should be different for humans and machines,\n\n1:09:50.340 --> 1:09:54.420\n or how we think about testing of intelligence?\n\n1:09:54.420 --> 1:09:59.740\n Are these fundamentally the same kind of intelligences\n\n1:09:59.740 --> 1:10:03.780\n that we're after, and therefore, the tests should be similar?\n\n1:10:03.780 --> 1:10:10.540\n So if your goal is to create AIs that are more humanlike,\n\n1:10:10.540 --> 1:10:12.540\n then it would be super valuable, obviously,\n\n1:10:12.540 --> 1:10:18.500\n to have a test that's universal, that applies to both AIs\n\n1:10:18.500 --> 1:10:20.820\n and humans, so that you could establish\n\n1:10:20.820 --> 1:10:23.260\n a comparison between the two, that you\n\n1:10:23.260 --> 1:10:27.340\n could tell exactly how intelligent,\n\n1:10:27.340 --> 1:10:30.420\n in terms of human intelligence, a given system is.\n\n1:10:30.420 --> 1:10:34.260\n So that said, the constraints that\n\n1:10:34.260 --> 1:10:37.620\n apply to artificial intelligence and to human intelligence\n\n1:10:37.620 --> 1:10:39.340\n are very different.\n\n1:10:39.340 --> 1:10:44.860\n And your test should account for this difference.\n\n1:10:44.860 --> 1:10:47.140\n Because if you look at artificial systems,\n\n1:10:47.140 --> 1:10:50.420\n it's always possible for an experimenter\n\n1:10:50.420 --> 1:10:55.580\n to buy arbitrary levels of skill at arbitrary tasks,\n\n1:10:55.580 --> 1:11:01.100\n either by injecting hardcoded prior knowledge\n\n1:11:01.100 --> 1:11:05.660\n into the system via rules and so on that\n\n1:11:05.660 --> 1:11:08.660\n come from the human mind, from the minds of the programmers,\n\n1:11:08.660 --> 1:11:12.980\n and also buying higher levels of skill\n\n1:11:12.980 --> 1:11:15.620\n just by training on more data.\n\n1:11:15.620 --> 1:11:17.860\n For instance, you could generate an infinity\n\n1:11:17.860 --> 1:11:21.660\n of different Go games, and you could train a Go playing\n\n1:11:21.660 --> 1:11:26.820\n system that way, but you could not directly compare it\n\n1:11:26.820 --> 1:11:28.620\n to human Go playing skills.\n\n1:11:28.620 --> 1:11:31.100\n Because a human that plays Go had\n\n1:11:31.100 --> 1:11:34.660\n to develop that skill in a very constrained environment.\n\n1:11:34.660 --> 1:11:36.580\n They had a limited amount of time.\n\n1:11:36.580 --> 1:11:38.940\n They had a limited amount of energy.\n\n1:11:38.940 --> 1:11:42.620\n And of course, this started from a different set of priors.\n\n1:11:42.620 --> 1:11:48.540\n This started from innate human priors.\n\n1:11:48.540 --> 1:11:49.860\n So I think if you want to compare\n\n1:11:49.860 --> 1:11:53.260\n the intelligence of two systems, like the intelligence of an AI\n\n1:11:53.260 --> 1:11:59.780\n and the intelligence of a human, you have to control for priors.\n\n1:11:59.780 --> 1:12:04.500\n You have to start from the same set of knowledge priors\n\n1:12:04.500 --> 1:12:06.940\n about the task, and you have to control\n\n1:12:06.940 --> 1:12:11.140\n for experience, that is to say, for training data.\n\n1:12:11.140 --> 1:12:14.980\n So what's priors?\n\n1:12:14.980 --> 1:12:18.340\n So prior is whatever information you\n\n1:12:18.340 --> 1:12:21.020\n have about a given task before you\n\n1:12:21.020 --> 1:12:23.100\n start learning about this task.\n\n1:12:23.100 --> 1:12:25.780\n And how's that different from experience?\n\n1:12:25.780 --> 1:12:28.020\n Well, experience is acquired.\n\n1:12:28.020 --> 1:12:31.100\n So for instance, if you're trying to play Go,\n\n1:12:31.100 --> 1:12:33.900\n your experience with Go is all the Go games\n\n1:12:33.900 --> 1:12:37.060\n you've played, or you've seen, or you've simulated\n\n1:12:37.060 --> 1:12:38.500\n in your mind, let's say.\n\n1:12:38.500 --> 1:12:42.740\n And your priors are things like, well,\n\n1:12:42.740 --> 1:12:45.860\n Go is a game on the 2D grid.\n\n1:12:45.860 --> 1:12:48.780\n And we have lots of hardcoded priors\n\n1:12:48.780 --> 1:12:53.180\n about the organization of 2D space.\n\n1:12:53.180 --> 1:12:58.340\n And the rules of how the dynamics of the physics\n\n1:12:58.340 --> 1:12:59.980\n of this game in this 2D space?\n\n1:12:59.980 --> 1:13:00.580\n Yes.\n\n1:13:00.580 --> 1:13:04.300\n And the idea that you have what winning is.\n\n1:13:04.300 --> 1:13:05.580\n Yes, exactly.\n\n1:13:05.580 --> 1:13:09.660\n And other board games can also share some similarities with Go.\n\n1:13:09.660 --> 1:13:12.060\n And if you've played these board games, then,\n\n1:13:12.060 --> 1:13:13.860\n with respect to the game of Go, that\n\n1:13:13.860 --> 1:13:16.300\n would be part of your priors about the game.\n\n1:13:16.300 --> 1:13:18.500\n Well, it's interesting to think about the game of Go\n\n1:13:18.500 --> 1:13:22.620\n is how many priors are actually brought to the table.\n\n1:13:22.620 --> 1:13:27.500\n When you look at self play, reinforcement learning based\n\n1:13:27.500 --> 1:13:29.300\n mechanisms that do learning, it seems\n\n1:13:29.300 --> 1:13:31.020\n like the number of priors is pretty low.\n\n1:13:31.020 --> 1:13:31.380\n Yes.\n\n1:13:31.380 --> 1:13:32.980\n But you're saying you should be expec...\n\n1:13:32.980 --> 1:13:35.700\n There is a 2D special priors in the carbonate.\n\n1:13:35.700 --> 1:13:36.460\n Right.\n\n1:13:36.460 --> 1:13:39.020\n But you should be clear at making\n\n1:13:39.020 --> 1:13:40.460\n those priors explicit.\n\n1:13:40.460 --> 1:13:41.820\n Yes.\n\n1:13:41.820 --> 1:13:44.060\n So in particular, I think if your goal\n\n1:13:44.060 --> 1:13:47.700\n is to measure a humanlike form of intelligence,\n\n1:13:47.700 --> 1:13:49.700\n then you should clearly establish\n\n1:13:49.700 --> 1:13:52.820\n that you want the AI you're testing\n\n1:13:52.820 --> 1:13:57.500\n to start from the same set of priors that humans start with.\n\n1:13:57.500 --> 1:13:58.820\n Right.\n\n1:13:58.820 --> 1:14:02.740\n So I mean, to me personally, but I think to a lot of people,\n\n1:14:02.740 --> 1:14:05.300\n the human side of things is very interesting.\n\n1:14:05.300 --> 1:14:08.020\n So testing intelligence for humans.\n\n1:14:08.020 --> 1:14:14.420\n What do you think is a good test of human intelligence?\n\n1:14:14.420 --> 1:14:19.820\n Well, that's the question that psychometrics is interested in.\n\n1:14:19.820 --> 1:14:22.420\n There's an entire subfield of psychology\n\n1:14:22.420 --> 1:14:23.860\n that deals with this question.\n\n1:14:23.860 --> 1:14:25.180\n So what's psychometrics?\n\n1:14:25.180 --> 1:14:27.980\n The psychometrics is the subfield of psychology\n\n1:14:27.980 --> 1:14:33.940\n that tries to measure, quantify aspects of the human mind.\n\n1:14:33.940 --> 1:14:36.940\n So in particular, our cognitive abilities, intelligence,\n\n1:14:36.940 --> 1:14:39.660\n and personality traits as well.\n\n1:14:39.660 --> 1:14:43.620\n So what are, it might be a weird question,\n\n1:14:43.620 --> 1:14:49.700\n but what are the first principles of psychometrics\n\n1:14:49.700 --> 1:14:52.100\n this operates on?\n\n1:14:52.100 --> 1:14:55.340\n What are the priors it brings to the table?\n\n1:14:55.340 --> 1:14:58.500\n So it's a field with a fairly long history.\n\n1:15:01.940 --> 1:15:05.500\n So psychology sometimes gets a bad reputation\n\n1:15:05.500 --> 1:15:09.020\n for not having very reproducible results.\n\n1:15:09.020 --> 1:15:12.420\n And psychometrics has actually some fairly solidly\n\n1:15:12.420 --> 1:15:14.180\n reproducible results.\n\n1:15:14.180 --> 1:15:17.980\n So the ideal goals of the field is a test\n\n1:15:17.980 --> 1:15:23.060\n should be reliable, which is a notion tied to reproducibility.\n\n1:15:23.060 --> 1:15:26.540\n It should be valid, meaning that it should actually\n\n1:15:26.540 --> 1:15:30.860\n measure what you say it measures.\n\n1:15:30.860 --> 1:15:32.780\n So for instance, if you're saying\n\n1:15:32.780 --> 1:15:34.140\n that you're measuring intelligence,\n\n1:15:34.140 --> 1:15:36.620\n then your test results should be correlated\n\n1:15:36.620 --> 1:15:39.140\n with things that you expect to be correlated\n\n1:15:39.140 --> 1:15:41.500\n with intelligence like success in school\n\n1:15:41.500 --> 1:15:43.580\n or success in the workplace and so on.\n\n1:15:43.580 --> 1:15:46.540\n Should be standardized, meaning that you\n\n1:15:46.540 --> 1:15:48.980\n can administer your tests to many different people\n\n1:15:48.980 --> 1:15:50.780\n in some conditions.\n\n1:15:50.780 --> 1:15:52.860\n And it should be free from bias.\n\n1:15:52.860 --> 1:15:57.140\n Meaning that, for instance, if your test involves\n\n1:15:57.140 --> 1:15:59.100\n the English language, then you have\n\n1:15:59.100 --> 1:16:02.500\n to be aware that this creates a bias against people\n\n1:16:02.500 --> 1:16:04.340\n who have English as their second language\n\n1:16:04.340 --> 1:16:07.300\n or people who can't speak English at all.\n\n1:16:07.300 --> 1:16:10.100\n So of course, these principles for creating\n\n1:16:10.100 --> 1:16:13.420\n psychometric tests are very much an ideal.\n\n1:16:13.420 --> 1:16:17.540\n I don't think every psychometric test is really either\n\n1:16:17.540 --> 1:16:22.060\n reliable, valid, or free from bias.\n\n1:16:22.060 --> 1:16:25.740\n But at least the field is aware of these weaknesses\n\n1:16:25.740 --> 1:16:27.380\n and is trying to address them.\n\n1:16:27.380 --> 1:16:30.100\n So it's kind of interesting.\n\n1:16:30.100 --> 1:16:31.820\n Ultimately, you're only able to measure,\n\n1:16:31.820 --> 1:16:34.420\n like you said previously, the skill.\n\n1:16:34.420 --> 1:16:36.420\n But you're trying to do a bunch of measures\n\n1:16:36.420 --> 1:16:38.820\n of different skills that correlate,\n\n1:16:38.820 --> 1:16:41.780\n as you mentioned, strongly with some general concept\n\n1:16:41.780 --> 1:16:43.340\n of cognitive ability.\n\n1:16:43.340 --> 1:16:44.060\n Yes, yes.\n\n1:16:44.060 --> 1:16:46.620\n So what's the G factor?\n\n1:16:46.620 --> 1:16:48.140\n So right, there are many different kinds\n\n1:16:48.140 --> 1:16:50.620\n of tests of intelligence.\n\n1:16:50.620 --> 1:16:55.340\n And each of them is interesting in different aspects\n\n1:16:55.340 --> 1:16:56.060\n of intelligence.\n\n1:16:56.060 --> 1:16:57.580\n Some of them will deal with language.\n\n1:16:57.580 --> 1:17:00.940\n Some of them will deal with spatial vision,\n\n1:17:00.940 --> 1:17:04.420\n maybe mental rotations, numbers, and so on.\n\n1:17:04.420 --> 1:17:08.580\n When you run these very different tests at scale,\n\n1:17:08.580 --> 1:17:10.940\n what you start seeing is that there\n\n1:17:10.940 --> 1:17:14.220\n are clusters of correlations among test results.\n\n1:17:14.220 --> 1:17:19.300\n So for instance, if you look at homework at school,\n\n1:17:19.300 --> 1:17:21.780\n you will see that people who do well at math\n\n1:17:21.780 --> 1:17:25.500\n are also likely statistically to do well in physics.\n\n1:17:25.500 --> 1:17:30.060\n And what's more, people who do well at math and physics\n\n1:17:30.060 --> 1:17:32.620\n are also statistically likely to do well\n\n1:17:32.620 --> 1:17:35.580\n in things that sound completely unrelated,\n\n1:17:35.580 --> 1:17:38.420\n like writing an English essay, for instance.\n\n1:17:38.420 --> 1:17:42.700\n And so when you see clusters of correlations\n\n1:17:42.700 --> 1:17:46.140\n in statistical terms, you would explain them\n\n1:17:46.140 --> 1:17:47.540\n with the latent variable.\n\n1:17:47.540 --> 1:17:51.100\n And the latent variable that would, for instance, explain\n\n1:17:51.100 --> 1:17:53.020\n the relationship between being good at math\n\n1:17:53.020 --> 1:17:57.020\n and being good at physics would be cognitive ability.\n\n1:17:57.020 --> 1:18:00.780\n And the G factor is the latent variable\n\n1:18:00.780 --> 1:18:05.540\n that explains the fact that every test of intelligence\n\n1:18:05.540 --> 1:18:09.340\n that you can come up with results on this test\n\n1:18:09.340 --> 1:18:10.540\n end up being correlated.\n\n1:18:10.540 --> 1:18:16.180\n So there is some single unique variable\n\n1:18:16.180 --> 1:18:17.820\n that explains these correlations.\n\n1:18:17.820 --> 1:18:18.820\n That's the G factor.\n\n1:18:18.820 --> 1:18:20.380\n So it's a statistical construct.\n\n1:18:20.380 --> 1:18:23.060\n It's not really something you can directly measure,\n\n1:18:23.060 --> 1:18:25.540\n for instance, in a person.\n\n1:18:25.540 --> 1:18:26.540\n But it's there.\n\n1:18:26.540 --> 1:18:27.220\n But it's there.\n\n1:18:27.220 --> 1:18:27.740\n It's there.\n\n1:18:27.740 --> 1:18:28.740\n It's there at scale.\n\n1:18:28.740 --> 1:18:33.460\n And that's also one thing I want to mention about psychometrics.\n\n1:18:33.460 --> 1:18:36.620\n Like when you talk about measuring intelligence\n\n1:18:36.620 --> 1:18:38.660\n in humans, for instance, some people\n\n1:18:38.660 --> 1:18:40.060\n get a little bit worried.\n\n1:18:40.060 --> 1:18:41.940\n They will say, that sounds dangerous.\n\n1:18:41.940 --> 1:18:44.340\n Maybe that sounds potentially discriminatory, and so on.\n\n1:18:44.340 --> 1:18:46.460\n And they're not wrong.\n\n1:18:46.460 --> 1:18:48.220\n And the thing is, personally, I'm\n\n1:18:48.220 --> 1:18:51.100\n not interested in psychometrics as a way\n\n1:18:51.100 --> 1:18:54.740\n to characterize one individual person.\n\n1:18:54.740 --> 1:18:59.180\n Like if I get your psychometric personality\n\n1:18:59.180 --> 1:19:01.780\n assessments or your IQ, I don't think that actually\n\n1:19:01.780 --> 1:19:05.020\n tells me much about you as a person.\n\n1:19:05.020 --> 1:19:10.300\n I think psychometrics is most useful as a statistical tool.\n\n1:19:10.300 --> 1:19:12.500\n So it's most useful at scale.\n\n1:19:12.500 --> 1:19:15.420\n It's most useful when you start getting test results\n\n1:19:15.420 --> 1:19:17.420\n for a large number of people.\n\n1:19:17.420 --> 1:19:20.580\n And you start cross correlating these test results.\n\n1:19:20.580 --> 1:19:23.620\n Because that gives you information\n\n1:19:23.620 --> 1:19:26.420\n about the structure of the human mind,\n\n1:19:26.420 --> 1:19:28.300\n in particular about the structure\n\n1:19:28.300 --> 1:19:29.780\n of human cognitive abilities.\n\n1:19:29.780 --> 1:19:34.860\n So at scale, psychometrics paints a certain picture\n\n1:19:34.860 --> 1:19:35.620\n of the human mind.\n\n1:19:35.620 --> 1:19:37.220\n And that's interesting.\n\n1:19:37.220 --> 1:19:39.540\n And that's what's relevant to AI, the structure\n\n1:19:39.540 --> 1:19:41.060\n of human cognitive abilities.\n\n1:19:41.060 --> 1:19:42.860\n Yeah, it gives you an insight into it.\n\n1:19:42.860 --> 1:19:45.820\n I mean, to me, I remember when I learned about G factor,\n\n1:19:45.820 --> 1:19:52.820\n it seemed like it would be impossible for it\n\n1:19:52.820 --> 1:19:55.500\n to be real, even as a statistical variable.\n\n1:19:55.500 --> 1:19:59.020\n Like it felt kind of like astrology.\n\n1:19:59.020 --> 1:20:01.980\n Like it's like wishful thinking among psychologists.\n\n1:20:01.980 --> 1:20:05.420\n But the more I learned, I realized that there's some.\n\n1:20:05.420 --> 1:20:07.620\n I mean, I'm not sure what to make about human beings,\n\n1:20:07.620 --> 1:20:10.580\n the fact that the G factor is a thing.\n\n1:20:10.580 --> 1:20:13.260\n There's a commonality across all of human species,\n\n1:20:13.260 --> 1:20:15.340\n that there does seem to be a strong correlation\n\n1:20:15.340 --> 1:20:17.140\n between cognitive abilities.\n\n1:20:17.140 --> 1:20:19.140\n That's kind of fascinating, actually.\n\n1:20:19.140 --> 1:20:22.780\n So human cognitive abilities have a structure.\n\n1:20:22.780 --> 1:20:25.380\n Like the most mainstream theory of the structure\n\n1:20:25.380 --> 1:20:28.780\n of cognitive abilities is called CHC theory.\n\n1:20:28.780 --> 1:20:30.660\n It's Cattell, Horn, Carroll.\n\n1:20:30.660 --> 1:20:33.180\n It's named after the three psychologists who\n\n1:20:33.180 --> 1:20:35.340\n contributed key pieces of it.\n\n1:20:35.340 --> 1:20:38.620\n And it describes cognitive abilities\n\n1:20:38.620 --> 1:20:41.060\n as a hierarchy with three levels.\n\n1:20:41.060 --> 1:20:43.140\n And at the top, you have the G factor.\n\n1:20:43.140 --> 1:20:46.140\n Then you have broad cognitive abilities,\n\n1:20:46.140 --> 1:20:49.340\n for instance fluid intelligence, that\n\n1:20:49.340 --> 1:20:54.940\n encompass a broad set of possible kinds of tasks\n\n1:20:54.940 --> 1:20:57.100\n that are all related.\n\n1:20:57.100 --> 1:20:59.900\n And then you have narrow cognitive abilities\n\n1:20:59.900 --> 1:21:04.340\n at the last level, which is closer to task specific skill.\n\n1:21:04.340 --> 1:21:09.100\n And there are actually different theories of the structure\n\n1:21:09.100 --> 1:21:10.700\n of cognitive abilities that just emerge\n\n1:21:10.700 --> 1:21:14.500\n from different statistical analysis of IQ test results.\n\n1:21:14.500 --> 1:21:18.500\n But they all describe a hierarchy with a kind of G\n\n1:21:18.500 --> 1:21:21.140\n factor at the top.\n\n1:21:21.140 --> 1:21:23.740\n And you're right that the G factor,\n\n1:21:23.740 --> 1:21:27.620\n it's not quite real in the sense that it's not something\n\n1:21:27.620 --> 1:21:29.660\n you can observe and measure, like your height,\n\n1:21:29.660 --> 1:21:30.340\n for instance.\n\n1:21:30.340 --> 1:21:32.940\n But it's real in the sense that you\n\n1:21:32.940 --> 1:21:37.780\n see it in a statistical analysis of the data.\n\n1:21:37.780 --> 1:21:39.700\n One thing I want to mention is that the fact\n\n1:21:39.700 --> 1:21:41.540\n that there is a G factor does not really\n\n1:21:41.540 --> 1:21:45.740\n mean that human intelligence is general in a strong sense.\n\n1:21:45.740 --> 1:21:47.220\n It does not mean human intelligence\n\n1:21:47.220 --> 1:21:50.340\n can be applied to any problem at all,\n\n1:21:50.340 --> 1:21:52.140\n and that someone who has a high IQ\n\n1:21:52.140 --> 1:21:54.100\n is going to be able to solve any problem at all.\n\n1:21:54.100 --> 1:21:55.260\n That's not quite what it means.\n\n1:21:55.260 --> 1:22:00.420\n I think one popular analogy to understand it\n\n1:22:00.420 --> 1:22:03.340\n is the sports analogy.\n\n1:22:03.340 --> 1:22:06.660\n If you consider the concept of physical fitness,\n\n1:22:06.660 --> 1:22:09.220\n it's a concept that's very similar to intelligence\n\n1:22:09.220 --> 1:22:11.340\n because it's a useful concept.\n\n1:22:11.340 --> 1:22:14.460\n It's something you can intuitively understand.\n\n1:22:14.460 --> 1:22:17.620\n Some people are fit, maybe like you.\n\n1:22:17.620 --> 1:22:20.540\n Some people are not as fit, maybe like me.\n\n1:22:20.540 --> 1:22:22.980\n But none of us can fly.\n\n1:22:22.980 --> 1:22:23.700\n Absolutely.\n\n1:22:23.700 --> 1:22:25.460\n It's constrained to a specific set of skills.\n\n1:22:25.460 --> 1:22:27.060\n Even if you're very fit, that doesn't\n\n1:22:27.060 --> 1:22:31.020\n mean you can do anything at all in any environment.\n\n1:22:31.020 --> 1:22:32.420\n You obviously cannot fly.\n\n1:22:32.420 --> 1:22:36.020\n You cannot survive at the bottom of the ocean and so on.\n\n1:22:36.020 --> 1:22:38.540\n And if you were a scientist and you\n\n1:22:38.540 --> 1:22:42.820\n wanted to precisely define and measure physical fitness\n\n1:22:42.820 --> 1:22:47.500\n in humans, then you would come up with a battery of tests.\n\n1:22:47.500 --> 1:22:51.580\n You would have running 100 meter, playing soccer,\n\n1:22:51.580 --> 1:22:54.260\n playing table tennis, swimming, and so on.\n\n1:22:54.260 --> 1:22:58.420\n And if you ran these tests over many different people,\n\n1:22:58.420 --> 1:23:01.220\n you would start seeing correlations in test results.\n\n1:23:01.220 --> 1:23:03.020\n For instance, people who are good at soccer\n\n1:23:03.020 --> 1:23:05.620\n are also good at sprinting.\n\n1:23:05.620 --> 1:23:08.580\n And you would explain these correlations\n\n1:23:08.580 --> 1:23:11.660\n with physical abilities that are strictly\n\n1:23:11.660 --> 1:23:14.020\n analogous to cognitive abilities.\n\n1:23:14.020 --> 1:23:17.060\n And then you would start also observing correlations\n\n1:23:17.060 --> 1:23:21.220\n between biological characteristics,\n\n1:23:21.220 --> 1:23:24.900\n like maybe lung volume is correlated with being\n\n1:23:24.900 --> 1:23:27.820\n a fast runner, for instance, in the same way\n\n1:23:27.820 --> 1:23:32.500\n that there are neurophysical correlates of cognitive\n\n1:23:32.500 --> 1:23:33.940\n abilities.\n\n1:23:33.940 --> 1:23:38.620\n And at the top of the hierarchy of physical abilities\n\n1:23:38.620 --> 1:23:39.980\n that you would be able to observe,\n\n1:23:39.980 --> 1:23:43.340\n you would have a G factor, a physical G factor, which\n\n1:23:43.340 --> 1:23:45.740\n would map to physical fitness.\n\n1:23:45.740 --> 1:23:47.980\n And as you just said, that doesn't\n\n1:23:47.980 --> 1:23:51.340\n mean that people with high physical fitness can't fly.\n\n1:23:51.340 --> 1:23:54.500\n It doesn't mean human morphology and human physiology\n\n1:23:54.500 --> 1:23:55.660\n is universal.\n\n1:23:55.660 --> 1:23:57.860\n It's actually super specialized.\n\n1:23:57.860 --> 1:24:04.100\n We can only do the things that we were evolved to do.\n\n1:24:04.100 --> 1:24:08.340\n We are not appropriate to, you could not\n\n1:24:08.340 --> 1:24:11.100\n exist on Venus or Mars or in the void of space\n\n1:24:11.100 --> 1:24:12.460\n or the bottom of the ocean.\n\n1:24:12.460 --> 1:24:17.740\n So that said, one thing that's really striking and remarkable\n\n1:24:17.740 --> 1:24:23.060\n is that our morphology generalizes\n\n1:24:23.060 --> 1:24:27.260\n far beyond the environments that we evolved for.\n\n1:24:27.260 --> 1:24:31.180\n Like in a way, you could say we evolved to run after prey\n\n1:24:31.180 --> 1:24:32.900\n in the savanna, right?\n\n1:24:32.900 --> 1:24:36.820\n That's very much where our human morphology comes from.\n\n1:24:36.820 --> 1:24:40.220\n And that said, we can do a lot of things\n\n1:24:40.220 --> 1:24:42.980\n that are completely unrelated to that.\n\n1:24:42.980 --> 1:24:44.260\n We can climb mountains.\n\n1:24:44.260 --> 1:24:47.260\n We can swim across lakes.\n\n1:24:47.260 --> 1:24:48.980\n We can play table tennis.\n\n1:24:48.980 --> 1:24:51.060\n I mean, table tennis is very different from what\n\n1:24:51.060 --> 1:24:53.100\n we were evolved to do, right?\n\n1:24:53.100 --> 1:24:56.300\n So our morphology, our bodies, our sense and motor\n\n1:24:56.300 --> 1:24:59.500\n affordances have a degree of generality\n\n1:24:59.500 --> 1:25:02.180\n that is absolutely remarkable, right?\n\n1:25:02.180 --> 1:25:05.300\n And I think cognition is very similar to that.\n\n1:25:05.300 --> 1:25:08.260\n Our cognitive abilities have a degree of generality\n\n1:25:08.260 --> 1:25:11.180\n that goes far beyond what the mind was initially\n\n1:25:11.180 --> 1:25:14.540\n supposed to do, which is why we can play music and write\n\n1:25:14.540 --> 1:25:18.580\n novels and go to Mars and do all kinds of crazy things.\n\n1:25:18.580 --> 1:25:20.780\n But it's not universal in the same way\n\n1:25:20.780 --> 1:25:23.420\n that human morphology and our body\n\n1:25:23.420 --> 1:25:27.500\n is not appropriate for actually most of the universe by volume.\n\n1:25:27.500 --> 1:25:29.940\n In the same way, you could say that the human mind is not\n\n1:25:29.940 --> 1:25:32.620\n really appropriate for most of problem space,\n\n1:25:32.620 --> 1:25:35.460\n potential problem space by volume.\n\n1:25:35.460 --> 1:25:39.660\n So we have very strong cognitive biases, actually,\n\n1:25:39.660 --> 1:25:42.620\n that mean that there are certain types of problems\n\n1:25:42.620 --> 1:25:45.380\n that we handle very well and certain types of problems\n\n1:25:45.380 --> 1:25:48.260\n that we are completely in adapted for.\n\n1:25:48.260 --> 1:25:52.420\n So that's really how we'd interpret the G factor.\n\n1:25:52.420 --> 1:25:56.340\n It's not a sign of strong generality.\n\n1:25:56.340 --> 1:26:01.020\n It's really just the broadest cognitive ability.\n\n1:26:01.020 --> 1:26:03.020\n But our abilities, whether we are\n\n1:26:03.020 --> 1:26:05.820\n talking about sensory motor abilities or cognitive\n\n1:26:05.820 --> 1:26:09.460\n abilities, they still remain very specialized\n\n1:26:09.460 --> 1:26:12.420\n in the human condition, right?\n\n1:26:12.420 --> 1:26:16.300\n Within the constraints of the human cognition,\n\n1:26:16.300 --> 1:26:18.300\n they're general.\n\n1:26:18.300 --> 1:26:19.500\n Yes, absolutely.\n\n1:26:19.500 --> 1:26:22.140\n But the constraints, as you're saying, are very limited.\n\n1:26:22.140 --> 1:26:23.860\n I think what's limiting.\n\n1:26:23.860 --> 1:26:26.980\n So we evolved our cognition and our body\n\n1:26:26.980 --> 1:26:29.420\n evolved in very specific environments.\n\n1:26:29.420 --> 1:26:32.740\n Because our environment was so variable, fast changing,\n\n1:26:32.740 --> 1:26:35.740\n and so unpredictable, part of the constraints\n\n1:26:35.740 --> 1:26:39.540\n that drove our evolution is generality itself.\n\n1:26:39.540 --> 1:26:42.780\n So we were, in a way, evolved to be able to improvise\n\n1:26:42.780 --> 1:26:47.540\n in all kinds of physical or cognitive environments.\n\n1:26:47.540 --> 1:26:49.900\n And for this reason, it turns out\n\n1:26:49.900 --> 1:26:55.060\n that the minds and bodies that we ended up with\n\n1:26:55.060 --> 1:26:58.020\n can be applied to much, much broader scope\n\n1:26:58.020 --> 1:27:00.060\n than what they were evolved for.\n\n1:27:00.060 --> 1:27:01.740\n And that's truly remarkable.\n\n1:27:01.740 --> 1:27:03.940\n And that's a degree of generalization\n\n1:27:03.940 --> 1:27:07.540\n that is far beyond anything you can see in artificial systems\n\n1:27:07.540 --> 1:27:10.300\n today.\n\n1:27:10.300 --> 1:27:14.500\n That said, it does not mean that human intelligence\n\n1:27:14.500 --> 1:27:16.380\n is anywhere universal.\n\n1:27:16.380 --> 1:27:18.900\n Yeah, it's not general.\n\n1:27:18.900 --> 1:27:21.140\n It's a kind of exciting topic for people,\n\n1:27:21.140 --> 1:27:24.060\n even outside of artificial intelligence, is IQ tests.\n\n1:27:27.580 --> 1:27:29.220\n I think it's Mensa, whatever.\n\n1:27:29.220 --> 1:27:32.420\n There's different degrees of difficulty for questions.\n\n1:27:32.420 --> 1:27:34.700\n We talked about this offline a little bit, too,\n\n1:27:34.700 --> 1:27:37.500\n about difficult questions.\n\n1:27:37.500 --> 1:27:42.300\n What makes a question on an IQ test more difficult or less\n\n1:27:42.300 --> 1:27:43.700\n difficult, do you think?\n\n1:27:43.700 --> 1:27:46.500\n So the thing to keep in mind is that there's\n\n1:27:46.500 --> 1:27:51.540\n no such thing as a question that's intrinsically difficult.\n\n1:27:51.540 --> 1:27:54.580\n It has to be difficult to suspect to the things you\n\n1:27:54.580 --> 1:27:58.540\n already know and the things you can already do, right?\n\n1:27:58.540 --> 1:28:02.740\n So in terms of an IQ test question,\n\n1:28:02.740 --> 1:28:05.980\n typically it would be structured, for instance,\n\n1:28:05.980 --> 1:28:11.860\n as a set of demonstration input and output pairs, right?\n\n1:28:11.860 --> 1:28:15.420\n And then you would be given a test input, a prompt,\n\n1:28:15.420 --> 1:28:18.700\n and you would need to recognize or produce\n\n1:28:18.700 --> 1:28:20.300\n the corresponding output.\n\n1:28:20.300 --> 1:28:26.060\n And in that narrow context, you could say a difficult question\n\n1:28:26.060 --> 1:28:31.580\n is a question where the input prompt is\n\n1:28:31.580 --> 1:28:36.540\n very surprising and unexpected, given the training examples.\n\n1:28:36.540 --> 1:28:38.340\n Just even the nature of the patterns\n\n1:28:38.340 --> 1:28:40.180\n that you're observing in the input prompt.\n\n1:28:40.180 --> 1:28:43.260\n For instance, let's say you have a rotation problem.\n\n1:28:43.260 --> 1:28:46.660\n You must relate the shape by 90 degrees.\n\n1:28:46.660 --> 1:28:50.500\n If I give you two examples and then I give you one prompt,\n\n1:28:50.500 --> 1:28:53.020\n which is actually one of the two training examples,\n\n1:28:53.020 --> 1:28:55.700\n then there is zero generalization difficulty\n\n1:28:55.700 --> 1:28:56.380\n for the task.\n\n1:28:56.380 --> 1:28:57.500\n It's actually a trivial task.\n\n1:28:57.500 --> 1:29:00.780\n You just recognize that it's one of the training examples,\n\n1:29:00.780 --> 1:29:02.300\n and you produce the same answer.\n\n1:29:02.300 --> 1:29:05.580\n Now, if it's a more complex shape,\n\n1:29:05.580 --> 1:29:07.700\n there is a little bit more generalization,\n\n1:29:07.700 --> 1:29:09.860\n but it remains that you are still\n\n1:29:09.860 --> 1:29:12.060\n doing the same thing at this time,\n\n1:29:12.060 --> 1:29:15.060\n as you were being demonstrated at training time.\n\n1:29:15.060 --> 1:29:20.300\n A difficult task starts to require some amount of test\n\n1:29:20.300 --> 1:29:25.100\n time adaptation, some amount of improvisation, right?\n\n1:29:25.100 --> 1:29:29.260\n So consider, I don't know, you're\n\n1:29:29.260 --> 1:29:34.020\n teaching a class on quantum physics or something.\n\n1:29:34.020 --> 1:29:40.460\n If you wanted to test the understanding that students\n\n1:29:40.460 --> 1:29:42.220\n have of the material, you would come up\n\n1:29:42.220 --> 1:29:47.740\n with an exam that's very different from anything\n\n1:29:47.740 --> 1:29:51.940\n they've seen on the internet when they were cramming.\n\n1:29:51.940 --> 1:29:54.780\n On the other hand, if you wanted to make it easy,\n\n1:29:54.780 --> 1:29:56.340\n you would just give them something\n\n1:29:56.340 --> 1:30:00.420\n that's very similar to the mock exams\n\n1:30:00.420 --> 1:30:03.060\n that they've taken, something that's\n\n1:30:03.060 --> 1:30:05.220\n just a simple interpolation of questions\n\n1:30:05.220 --> 1:30:07.260\n that they've already seen.\n\n1:30:07.260 --> 1:30:09.220\n And so that would be an easy exam.\n\n1:30:09.220 --> 1:30:11.940\n It's very similar to what you've been trained on.\n\n1:30:11.940 --> 1:30:15.460\n And a difficult exam is one that really probes your understanding\n\n1:30:15.460 --> 1:30:18.980\n because it forces you to improvise.\n\n1:30:18.980 --> 1:30:22.180\n It forces you to do things that are\n\n1:30:22.180 --> 1:30:24.780\n different from what you were exposed to before.\n\n1:30:24.780 --> 1:30:29.100\n So that said, it doesn't mean that the exam that\n\n1:30:29.100 --> 1:30:32.700\n requires improvisation is intrinsically hard, right?\n\n1:30:32.700 --> 1:30:35.820\n Because maybe you're a quantum physics expert.\n\n1:30:35.820 --> 1:30:37.780\n So when you take the exam, this is actually\n\n1:30:37.780 --> 1:30:40.300\n stuff that, despite being new to the students,\n\n1:30:40.300 --> 1:30:42.900\n it's not new to you, right?\n\n1:30:42.900 --> 1:30:46.020\n So it can only be difficult with respect\n\n1:30:46.020 --> 1:30:49.380\n to what the test taker already knows\n\n1:30:49.380 --> 1:30:51.780\n and with respect to the information\n\n1:30:51.780 --> 1:30:54.700\n that the test taker has about the task.\n\n1:30:54.700 --> 1:30:57.860\n So that's what I mean by controlling for priors\n\n1:30:57.860 --> 1:30:59.900\n what the information you bring to the table.\n\n1:30:59.900 --> 1:31:00.660\n And the experience.\n\n1:31:00.660 --> 1:31:02.660\n And the experience, which is to train data.\n\n1:31:02.660 --> 1:31:05.580\n So in the case of the quantum physics exam,\n\n1:31:05.580 --> 1:31:09.740\n that would be all the course material itself\n\n1:31:09.740 --> 1:31:11.500\n and all the mock exams that students\n\n1:31:11.500 --> 1:31:12.820\n might have taken online.\n\n1:31:12.820 --> 1:31:17.700\n Yeah, it's interesting because I've also sent you an email.\n\n1:31:17.700 --> 1:31:21.820\n I asked you, I've been in just this curious question\n\n1:31:21.820 --> 1:31:26.820\n of what's a really hard IQ test question.\n\n1:31:27.300 --> 1:31:30.580\n And I've been talking to also people\n\n1:31:30.580 --> 1:31:32.540\n who have designed IQ tests.\n\n1:31:32.540 --> 1:31:34.420\n There's a few folks on the internet, it's like a thing.\n\n1:31:34.420 --> 1:31:36.180\n People are really curious about it.\n\n1:31:36.180 --> 1:31:39.460\n First of all, most of the IQ tests they designed,\n\n1:31:39.460 --> 1:31:44.460\n they like religiously protect against the correct answers.\n\n1:31:45.620 --> 1:31:48.380\n Like you can't find the correct answers anywhere.\n\n1:31:48.380 --> 1:31:50.620\n In fact, the question is ruined once you know,\n\n1:31:50.620 --> 1:31:53.700\n even like the approach you're supposed to take.\n\n1:31:53.700 --> 1:31:54.540\n So they're very...\n\n1:31:54.540 --> 1:31:58.420\n That said, the approach is implicit in the training examples.\n\n1:31:58.420 --> 1:32:00.860\n So if you release the training examples, it's over.\n\n1:32:02.740 --> 1:32:04.980\n Which is why in Arc, for instance,\n\n1:32:04.980 --> 1:32:07.940\n there is a test set that is private and no one has seen it.\n\n1:32:09.140 --> 1:32:13.580\n No, for really tough IQ questions, it's not obvious.\n\n1:32:13.580 --> 1:32:17.100\n It's not because the ambiguity.\n\n1:32:17.100 --> 1:32:20.780\n Like it's, I mean, we'll have to look through them,\n\n1:32:20.780 --> 1:32:22.860\n but like some number sequences and so on,\n\n1:32:22.860 --> 1:32:25.060\n it's not completely clear.\n\n1:32:25.060 --> 1:32:29.380\n So like you can get a sense, but there's like some,\n\n1:32:30.540 --> 1:32:33.540\n you know, when you look at a number sequence, I don't know,\n\n1:32:36.140 --> 1:32:37.620\n like your Fibonacci number sequence,\n\n1:32:37.620 --> 1:32:39.580\n if you look at the first few numbers,\n\n1:32:39.580 --> 1:32:42.980\n that sequence could be completed in a lot of different ways.\n\n1:32:42.980 --> 1:32:45.620\n And you know, some are, if you think deeply,\n\n1:32:45.620 --> 1:32:46.900\n are more correct than others.\n\n1:32:46.900 --> 1:32:51.300\n Like there's a kind of intuitive simplicity\n\n1:32:51.300 --> 1:32:53.020\n and elegance to the correct solution.\n\n1:32:53.020 --> 1:32:53.860\n Yes.\n\n1:32:53.860 --> 1:32:56.420\n I am personally not a fan of ambiguity\n\n1:32:56.420 --> 1:32:58.660\n in test questions actually,\n\n1:32:58.660 --> 1:33:01.140\n but I think you can have difficulty\n\n1:33:01.140 --> 1:33:05.620\n without requiring ambiguity simply by making the test\n\n1:33:05.620 --> 1:33:09.500\n require a lot of extrapolation over the training examples.\n\n1:33:09.500 --> 1:33:13.340\n But the beautiful question is difficult,\n\n1:33:13.340 --> 1:33:14.500\n but gives away everything\n\n1:33:14.500 --> 1:33:17.180\n when you give the training example.\n\n1:33:17.180 --> 1:33:18.460\n Basically, yes.\n\n1:33:18.460 --> 1:33:23.460\n Meaning that, so the tests I'm interested in creating\n\n1:33:24.020 --> 1:33:27.740\n are not necessarily difficult for humans\n\n1:33:27.740 --> 1:33:31.580\n because human intelligence is the benchmark.\n\n1:33:31.580 --> 1:33:34.380\n They're supposed to be difficult for machines\n\n1:33:34.380 --> 1:33:36.300\n in ways that are easy for humans.\n\n1:33:36.300 --> 1:33:40.820\n Like I think an ideal test of human and machine intelligence\n\n1:33:40.820 --> 1:33:44.380\n is a test that is actionable,\n\n1:33:44.380 --> 1:33:48.260\n that highlights the need for progress,\n\n1:33:48.260 --> 1:33:50.060\n and that highlights the direction\n\n1:33:50.060 --> 1:33:51.500\n in which you should be making progress.\n\n1:33:51.500 --> 1:33:54.340\n I think we'll talk about the ARC challenge\n\n1:33:54.340 --> 1:33:55.580\n and the test you've constructed\n\n1:33:55.580 --> 1:33:58.100\n and you have these elegant examples.\n\n1:33:58.100 --> 1:33:59.180\n I think that highlight,\n\n1:33:59.180 --> 1:34:01.820\n like this is really easy for us humans,\n\n1:34:01.820 --> 1:34:04.580\n but it's really hard for machines.\n\n1:34:04.580 --> 1:34:09.220\n But on the, you know, the designing an IQ test\n\n1:34:09.220 --> 1:34:13.380\n for IQs of like higher than 160 and so on,\n\n1:34:13.380 --> 1:34:15.220\n you have to say, you have to take that\n\n1:34:15.220 --> 1:34:16.500\n and put it on steroids, right?\n\n1:34:16.500 --> 1:34:19.540\n You have to think like, what is hard for humans?\n\n1:34:19.540 --> 1:34:23.900\n And that's a fascinating exercise in itself, I think.\n\n1:34:25.940 --> 1:34:27.740\n And it was an interesting question\n\n1:34:27.740 --> 1:34:32.300\n of what it takes to create a really hard question for humans\n\n1:34:32.300 --> 1:34:36.340\n because you again have to do the same process\n\n1:34:36.340 --> 1:34:39.900\n as you mentioned, which is, you know,\n\n1:34:39.900 --> 1:34:44.900\n something basically where the experience\n\n1:34:45.100 --> 1:34:46.900\n that you have likely to have encountered\n\n1:34:46.900 --> 1:34:48.740\n throughout your whole life,\n\n1:34:48.740 --> 1:34:51.780\n even if you've prepared for IQ tests,\n\n1:34:51.780 --> 1:34:53.380\n which is a big challenge,\n\n1:34:53.380 --> 1:34:55.820\n that this will still be novel for you.\n\n1:34:55.820 --> 1:34:57.900\n Yeah, I mean, novelty is a requirement.\n\n1:34:58.900 --> 1:35:02.100\n You should not be able to practice for the questions\n\n1:35:02.100 --> 1:35:03.780\n that you're gonna be tested on.\n\n1:35:03.780 --> 1:35:06.700\n That's important because otherwise what you're doing\n\n1:35:06.700 --> 1:35:08.180\n is not exhibiting intelligence.\n\n1:35:08.180 --> 1:35:10.900\n What you're doing is just retrieving\n\n1:35:10.900 --> 1:35:12.380\n what you've been exposed before.\n\n1:35:12.380 --> 1:35:14.500\n It's the same thing as deep learning model.\n\n1:35:14.500 --> 1:35:15.900\n If you train a deep learning model\n\n1:35:15.900 --> 1:35:20.100\n on all the possible answers, then it will ace your test\n\n1:35:20.100 --> 1:35:22.860\n in the same way that, you know,\n\n1:35:24.420 --> 1:35:28.100\n a stupid student can still ace the test\n\n1:35:28.100 --> 1:35:30.140\n if they cram for it.\n\n1:35:30.140 --> 1:35:32.500\n They memorize, you know,\n\n1:35:32.500 --> 1:35:34.980\n a hundred different possible mock exams.\n\n1:35:34.980 --> 1:35:37.180\n And then they hope that the actual exam\n\n1:35:37.180 --> 1:35:41.180\n will be a very simple interpolation of the mock exams.\n\n1:35:41.180 --> 1:35:43.180\n And that student could just be a deep learning model\n\n1:35:43.180 --> 1:35:44.020\n at that point.\n\n1:35:44.020 --> 1:35:45.900\n But you can actually do that\n\n1:35:45.900 --> 1:35:48.180\n without any understanding of the material.\n\n1:35:48.180 --> 1:35:50.540\n And in fact, many students pass their exams\n\n1:35:50.540 --> 1:35:51.940\n in exactly this way.\n\n1:35:51.940 --> 1:35:53.140\n And if you want to avoid that,\n\n1:35:53.140 --> 1:35:56.660\n you need an exam that's unlike anything they've seen\n\n1:35:56.660 --> 1:36:00.020\n that really probes their understanding.\n\n1:36:00.020 --> 1:36:05.020\n So how do we design an IQ test for machines,\n\n1:36:05.020 --> 1:36:07.860\n an intelligent test for machines?\n\n1:36:07.860 --> 1:36:10.300\n All right, so in the paper I outline\n\n1:36:10.300 --> 1:36:14.780\n a number of requirements that you expect of such a test.\n\n1:36:14.780 --> 1:36:19.620\n And in particular, we should start by acknowledging\n\n1:36:19.620 --> 1:36:23.300\n the priors that we expect to be required\n\n1:36:23.300 --> 1:36:25.260\n in order to perform the test.\n\n1:36:25.260 --> 1:36:28.100\n So we should be explicit about the priors, right?\n\n1:36:28.100 --> 1:36:31.780\n And if the goal is to compare machine intelligence\n\n1:36:31.780 --> 1:36:32.740\n and human intelligence,\n\n1:36:32.740 --> 1:36:36.980\n then we should assume human cognitive priors, right?\n\n1:36:36.980 --> 1:36:41.980\n And secondly, we should make sure that we are testing\n\n1:36:42.020 --> 1:36:44.820\n for skill acquisition ability,\n\n1:36:44.820 --> 1:36:46.740\n skill acquisition efficiency in particular,\n\n1:36:46.740 --> 1:36:48.580\n and not for skill itself.\n\n1:36:48.580 --> 1:36:51.860\n Meaning that every task featured in your test\n\n1:36:51.860 --> 1:36:54.420\n should be novel and should not be something\n\n1:36:54.420 --> 1:36:55.980\n that you can anticipate.\n\n1:36:55.980 --> 1:36:57.980\n So for instance, it should not be possible\n\n1:36:57.980 --> 1:37:02.860\n to brute force the space of possible questions, right?\n\n1:37:02.860 --> 1:37:05.900\n To pre generate every possible question and answer.\n\n1:37:06.940 --> 1:37:10.660\n So it should be tasks that cannot be anticipated,\n\n1:37:10.660 --> 1:37:12.460\n not just by the system itself,\n\n1:37:12.460 --> 1:37:15.940\n but by the creators of the system, right?\n\n1:37:15.940 --> 1:37:17.660\n Yeah, you know what's fascinating?\n\n1:37:17.660 --> 1:37:20.820\n I mean, one of my favorite aspects of the paper\n\n1:37:20.820 --> 1:37:22.860\n and the work you do with the ARC challenge\n\n1:37:22.860 --> 1:37:27.860\n is the process of making priors explicit.\n\n1:37:28.940 --> 1:37:33.420\n Just even that act alone is a really powerful one\n\n1:37:33.420 --> 1:37:38.420\n of like, what are, it's a really powerful question\n\n1:37:39.260 --> 1:37:40.500\n asked of us humans.\n\n1:37:40.500 --> 1:37:42.860\n What are the priors that we bring to the table?\n\n1:37:44.180 --> 1:37:46.900\n So the next step is like, once you have those priors,\n\n1:37:46.900 --> 1:37:50.060\n how do you use them to solve a novel task?\n\n1:37:50.060 --> 1:37:52.940\n But like, just even making the priors explicit\n\n1:37:52.940 --> 1:37:56.140\n is a really difficult and really powerful step.\n\n1:37:56.140 --> 1:37:58.940\n And that's like visually beautiful\n\n1:37:58.940 --> 1:38:01.340\n and conceptually philosophically beautiful part\n\n1:38:01.340 --> 1:38:06.020\n of the work you did with, and I guess continue to do\n\n1:38:06.020 --> 1:38:08.460\n probably with the paper and the ARC challenge.\n\n1:38:08.460 --> 1:38:10.740\n Can you talk about some of the priors\n\n1:38:10.740 --> 1:38:12.380\n that we're talking about here?\n\n1:38:12.380 --> 1:38:15.380\n Yes, so a researcher has done a lot of work\n\n1:38:15.380 --> 1:38:19.460\n on what exactly are the knowledge priors\n\n1:38:19.460 --> 1:38:24.460\n that are innate to humans is Elizabeth Spelke from Harvard.\n\n1:38:26.500 --> 1:38:30.580\n So she developed the core knowledge theory,\n\n1:38:30.580 --> 1:38:35.580\n which outlines four different core knowledge systems.\n\n1:38:36.500 --> 1:38:39.180\n So systems of knowledge that we are basically\n\n1:38:39.180 --> 1:38:43.660\n either born with or that we are hardwired\n\n1:38:43.660 --> 1:38:47.180\n to acquire very early on in our development.\n\n1:38:47.180 --> 1:38:52.060\n And there's no strong distinction between the two.\n\n1:38:52.060 --> 1:38:57.060\n Like if you are primed to acquire\n\n1:38:57.060 --> 1:39:01.220\n a certain type of knowledge in just a few weeks,\n\n1:39:01.220 --> 1:39:03.500\n you might as well just be born with it.\n\n1:39:03.500 --> 1:39:06.460\n It's just part of who you are.\n\n1:39:06.460 --> 1:39:09.500\n And so there are four different core knowledge systems.\n\n1:39:09.500 --> 1:39:13.460\n Like the first one is the notion of objectness\n\n1:39:13.460 --> 1:39:16.340\n and basic physics.\n\n1:39:16.340 --> 1:39:20.700\n Like you recognize that something that moves\n\n1:39:20.700 --> 1:39:23.220\n coherently, for instance, is an object.\n\n1:39:23.220 --> 1:39:28.220\n So we intuitively, naturally, innately divide the world\n\n1:39:28.260 --> 1:39:31.260\n into objects based on this notion of coherence,\n\n1:39:31.260 --> 1:39:32.740\n physical coherence.\n\n1:39:32.740 --> 1:39:34.700\n And in terms of elementary physics,\n\n1:39:34.700 --> 1:39:39.700\n there's the fact that objects can bump against each other\n\n1:39:41.620 --> 1:39:44.460\n and the fact that they can occlude each other.\n\n1:39:44.460 --> 1:39:48.300\n So these are things that we are essentially born with\n\n1:39:48.300 --> 1:39:52.500\n or at least that we are going to be acquiring extremely early\n\n1:39:52.500 --> 1:39:55.620\n because we're really hardwired to acquire them.\n\n1:39:55.620 --> 1:39:59.940\n So a bunch of points, pixels that move together\n\n1:39:59.940 --> 1:40:02.820\n on objects are partly the same object.\n\n1:40:02.820 --> 1:40:03.660\n Yes.\n\n1:40:07.660 --> 1:40:11.260\n I don't smoke weed, but if I did,\n\n1:40:11.260 --> 1:40:13.100\n that's something I could sit all night\n\n1:40:13.100 --> 1:40:15.700\n and just think about, remember what I wrote in your paper,\n\n1:40:15.700 --> 1:40:19.700\n just objectness, I wasn't self aware, I guess,\n\n1:40:19.700 --> 1:40:23.180\n of that particular prior.\n\n1:40:23.180 --> 1:40:28.180\n That's such a fascinating prior that like...\n\n1:40:28.500 --> 1:40:30.940\n That's the most basic one, but actually...\n\n1:40:30.940 --> 1:40:34.420\n Objectness, just identity, just objectness.\n\n1:40:34.420 --> 1:40:39.060\n It's very basic, I suppose, but it's so fundamental.\n\n1:40:39.060 --> 1:40:41.380\n It is fundamental to human cognition.\n\n1:40:41.380 --> 1:40:42.220\n Yeah.\n\n1:40:42.220 --> 1:40:46.660\n The second prior that's also fundamental is agentness,\n\n1:40:46.660 --> 1:40:50.740\n which is not a real world, a real world, so agentness.\n\n1:40:50.740 --> 1:40:53.340\n The fact that some of these objects\n\n1:40:53.340 --> 1:40:56.540\n that you segment your environment into,\n\n1:40:56.540 --> 1:40:58.940\n some of these objects are agents.\n\n1:40:58.940 --> 1:41:00.300\n So what's an agent?\n\n1:41:00.300 --> 1:41:04.460\n It's basically, it's an object that has goals.\n\n1:41:05.380 --> 1:41:06.340\n That has what?\n\n1:41:06.340 --> 1:41:09.420\n That has goals, that is capable of pursuing goals.\n\n1:41:09.420 --> 1:41:12.580\n So for instance, if you see two dots\n\n1:41:12.580 --> 1:41:16.300\n moving in roughly synchronized fashion,\n\n1:41:16.300 --> 1:41:19.820\n you will intuitively infer that one of the dots\n\n1:41:19.820 --> 1:41:21.620\n is pursuing the other.\n\n1:41:21.620 --> 1:41:24.980\n So that one of the dots is...\n\n1:41:24.980 --> 1:41:27.380\n And one of the dots is an agent\n\n1:41:27.380 --> 1:41:29.460\n and its goal is to avoid the other dot.\n\n1:41:29.460 --> 1:41:32.740\n And one of the dots, the other dot is also an agent\n\n1:41:32.740 --> 1:41:35.860\n and its goal is to catch the first dot.\n\n1:41:35.860 --> 1:41:40.540\n Belke has shown that babies as young as three months\n\n1:41:40.540 --> 1:41:45.220\n identify agentness and goal directedness\n\n1:41:45.220 --> 1:41:46.420\n in their environment.\n\n1:41:46.420 --> 1:41:51.420\n Another prior is basic geometry and topology,\n\n1:41:52.140 --> 1:41:53.660\n like the notion of distance,\n\n1:41:53.660 --> 1:41:57.620\n the ability to navigate in your environment and so on.\n\n1:41:57.620 --> 1:42:01.380\n This is something that is fundamentally hardwired\n\n1:42:01.380 --> 1:42:02.700\n into our brain.\n\n1:42:02.700 --> 1:42:07.100\n It's in fact backed by very specific neural mechanisms,\n\n1:42:07.100 --> 1:42:10.820\n like for instance, grid cells and place cells.\n\n1:42:10.820 --> 1:42:15.260\n So it's something that's literally hard coded\n\n1:42:15.260 --> 1:42:19.940\n at the neural level in our hippocampus.\n\n1:42:19.940 --> 1:42:23.580\n And the last prior would be the notion of numbers.\n\n1:42:23.580 --> 1:42:26.460\n Like numbers are not actually a cultural construct.\n\n1:42:26.460 --> 1:42:31.460\n We are intuitively, innately able to do some basic counting\n\n1:42:31.460 --> 1:42:34.100\n and to compare quantities.\n\n1:42:34.100 --> 1:42:36.660\n So it doesn't mean we can do arbitrary arithmetic.\n\n1:42:37.660 --> 1:42:39.020\n Counting, the actual counting.\n\n1:42:39.020 --> 1:42:41.500\n Counting, like counting one, two, three ish,\n\n1:42:41.500 --> 1:42:43.700\n then maybe more than three.\n\n1:42:43.700 --> 1:42:45.140\n You can also compare quantities.\n\n1:42:45.140 --> 1:42:48.580\n If I give you three dots and five dots,\n\n1:42:48.580 --> 1:42:52.500\n you can tell the side with five dots has more dots.\n\n1:42:52.500 --> 1:42:56.580\n So this is actually an innate prior.\n\n1:42:56.580 --> 1:43:00.020\n So that said, the list may not be exhaustive.\n\n1:43:00.020 --> 1:43:02.580\n So SpellKey is still, you know,\n\n1:43:02.580 --> 1:43:07.580\n passing the potential existence of new knowledge systems.\n\n1:43:08.500 --> 1:43:12.100\n For instance, knowledge systems that we deal\n\n1:43:12.100 --> 1:43:14.340\n with social relationships.\n\n1:43:15.940 --> 1:43:17.700\n Yeah, I mean, and there could be...\n\n1:43:17.700 --> 1:43:22.060\n Which is much less relevant to something like ARC\n\n1:43:22.060 --> 1:43:22.900\n or IQ test and so on.\n\n1:43:22.900 --> 1:43:23.740\n Right.\n\n1:43:23.740 --> 1:43:26.740\n There could be stuff that's like you said,\n\n1:43:26.740 --> 1:43:29.020\n rotation, symmetry, is there like...\n\n1:43:29.020 --> 1:43:31.060\n Symmetry is really interesting.\n\n1:43:31.060 --> 1:43:34.380\n It's very likely that there is, speaking about rotation,\n\n1:43:34.380 --> 1:43:38.900\n that there is in the brain, a hard coded system\n\n1:43:38.900 --> 1:43:40.940\n that is capable of performing rotations.\n\n1:43:42.060 --> 1:43:45.660\n One famous experiment that people did in the...\n\n1:43:45.660 --> 1:43:48.180\n I don't remember which was exactly,\n\n1:43:48.180 --> 1:43:53.180\n but in the 70s was that people found that\n\n1:43:53.180 --> 1:43:57.580\n if you asked people, if you give them two different shapes\n\n1:43:57.580 --> 1:44:01.420\n and one of the shapes is a rotated version\n\n1:44:01.420 --> 1:44:03.340\n of the first shape, and you ask them,\n\n1:44:03.340 --> 1:44:07.060\n is that shape a rotated version of the first shape or not?\n\n1:44:07.060 --> 1:44:11.140\n What you see is that the time it takes people to answer\n\n1:44:11.140 --> 1:44:16.140\n is linearly proportional, right, to the angle of rotation.\n\n1:44:16.140 --> 1:44:19.660\n So it's almost like you have somewhere in your brain\n\n1:44:19.660 --> 1:44:24.020\n like a turntable with a fixed speed.\n\n1:44:24.020 --> 1:44:28.620\n And if you want to know if two objects are a rotated version\n\n1:44:28.620 --> 1:44:31.700\n of each other, you put the object on the turntable,\n\n1:44:31.700 --> 1:44:34.740\n you let it move around a little bit,\n\n1:44:34.740 --> 1:44:37.580\n and then you stop when you have a match.\n\n1:44:37.580 --> 1:44:40.140\n And that's really interesting.\n\n1:44:40.140 --> 1:44:42.740\n So what's the ARC challenge?\n\n1:44:42.740 --> 1:44:47.380\n So in the paper, I outline all these principles\n\n1:44:47.380 --> 1:44:50.140\n that a good test of machine intelligence\n\n1:44:50.140 --> 1:44:51.940\n and human intelligence should follow.\n\n1:44:51.940 --> 1:44:55.300\n And the ARC challenge is one attempt\n\n1:44:55.300 --> 1:44:58.540\n to embody as many of these principles as possible.\n\n1:44:58.540 --> 1:45:03.780\n So I don't think it's anywhere near a perfect attempt, right?\n\n1:45:03.780 --> 1:45:06.060\n It does not actually follow every principle,\n\n1:45:06.060 --> 1:45:10.700\n but it is what I was able to do given the constraints.\n\n1:45:10.700 --> 1:45:15.540\n So the format of ARC is very similar to classic IQ tests,\n\n1:45:15.540 --> 1:45:18.020\n in particular Raven's Progressive Metrices.\n\n1:45:18.020 --> 1:45:18.980\n Raven's?\n\n1:45:18.980 --> 1:45:20.580\n Yeah, Raven's Progressive Metrices.\n\n1:45:20.580 --> 1:45:22.820\n I mean, if you've done IQ tests in the past,\n\n1:45:22.820 --> 1:45:24.220\n you know what that is, probably.\n\n1:45:24.220 --> 1:45:25.620\n Or at least you've seen it, even if you\n\n1:45:25.620 --> 1:45:26.980\n don't know what it's called.\n\n1:45:26.980 --> 1:45:32.300\n And so you have a set of tasks, that's what they're called.\n\n1:45:32.300 --> 1:45:37.180\n And for each task, you have training data,\n\n1:45:37.180 --> 1:45:40.260\n which is a set of input and output pairs.\n\n1:45:40.260 --> 1:45:45.540\n So an input or output pair is a grid of colors, basically.\n\n1:45:45.540 --> 1:45:48.500\n The grid, the size of the grid is variables.\n\n1:45:48.500 --> 1:45:51.380\n The size of the grid is variable.\n\n1:45:51.380 --> 1:45:56.100\n And you're given an input, and you must transform it\n\n1:45:56.100 --> 1:45:59.020\n into the proper output.\n\n1:45:59.020 --> 1:46:02.060\n And so you're shown a few demonstrations\n\n1:46:02.060 --> 1:46:05.100\n of a task in the form of existing input output pairs,\n\n1:46:05.100 --> 1:46:06.860\n and then you're given a new input.\n\n1:46:06.860 --> 1:46:12.620\n And you must provide, you must produce the correct output.\n\n1:46:12.620 --> 1:46:22.860\n And the assumptions in Arc is that every task should only\n\n1:46:22.860 --> 1:46:27.660\n require core knowledge priors, should not\n\n1:46:27.660 --> 1:46:30.460\n require any outside knowledge.\n\n1:46:30.460 --> 1:46:36.900\n So for instance, no language, no English, nothing like this.\n\n1:46:36.900 --> 1:46:41.540\n No concepts taken from our human experience,\n\n1:46:41.540 --> 1:46:44.340\n like trees, dogs, cats, and so on.\n\n1:46:44.340 --> 1:46:49.700\n So only reasoning tasks that are built on top\n\n1:46:49.700 --> 1:46:52.060\n of core knowledge priors.\n\n1:46:52.060 --> 1:46:56.260\n And some of the tasks are actually explicitly\n\n1:46:56.260 --> 1:47:02.220\n trying to probe specific forms of abstraction.\n\n1:47:02.220 --> 1:47:05.500\n Part of the reason why I wanted to create Arc\n\n1:47:05.500 --> 1:47:11.740\n is I'm a big believer in when you're\n\n1:47:11.740 --> 1:47:18.340\n faced with a problem as murky as understanding\n\n1:47:18.340 --> 1:47:22.380\n how to autonomously generate abstraction in a machine,\n\n1:47:22.380 --> 1:47:27.180\n you have to coevolve the solution and the problem.\n\n1:47:27.180 --> 1:47:29.380\n And so part of the reason why I designed Arc\n\n1:47:29.380 --> 1:47:34.660\n was to clarify my ideas about the nature of abstraction.\n\n1:47:34.660 --> 1:47:36.220\n And some of the tasks are actually\n\n1:47:36.220 --> 1:47:39.900\n designed to probe bits of that theory.\n\n1:47:39.900 --> 1:47:42.340\n And there are things that turn out\n\n1:47:42.340 --> 1:47:46.740\n to be very easy for humans to perform, including young kids,\n\n1:47:46.740 --> 1:47:50.500\n but turn out to be near impossible for machines.\n\n1:47:50.500 --> 1:47:53.780\n So what have you learned from the nature of abstraction\n\n1:47:53.780 --> 1:47:58.380\n from designing that?\n\n1:47:58.380 --> 1:47:59.620\n Can you clarify what you mean?\n\n1:47:59.620 --> 1:48:02.300\n One of the things you wanted to try to understand\n\n1:48:02.300 --> 1:48:06.020\n was this idea of abstraction.\n\n1:48:06.020 --> 1:48:10.380\n Yes, so clarifying my own ideas about abstraction\n\n1:48:10.380 --> 1:48:13.700\n by forcing myself to produce tasks that\n\n1:48:13.700 --> 1:48:17.020\n would require the ability to produce\n\n1:48:17.020 --> 1:48:19.900\n that form of abstraction in order to solve them.\n\n1:48:19.900 --> 1:48:20.860\n Got it.\n\n1:48:20.860 --> 1:48:24.060\n OK, so and by the way, just the people should check out.\n\n1:48:24.060 --> 1:48:26.380\n I'll probably overlay if you're watching the video part.\n\n1:48:26.380 --> 1:48:32.180\n But the grid input output with the different colors\n\n1:48:32.180 --> 1:48:34.340\n on the grid, that's it.\n\n1:48:34.340 --> 1:48:36.300\n I mean, it's a very simple world,\n\n1:48:36.300 --> 1:48:37.460\n but it's kind of beautiful.\n\n1:48:37.460 --> 1:48:39.740\n It's very similar to classic IQ tests.\n\n1:48:39.740 --> 1:48:41.620\n It's not very original in that sense.\n\n1:48:41.620 --> 1:48:43.260\n The main difference with IQ tests\n\n1:48:43.260 --> 1:48:46.860\n is that we make the priors explicit, which is not\n\n1:48:46.860 --> 1:48:48.580\n usually the case in IQ tests.\n\n1:48:48.580 --> 1:48:50.820\n So you make it explicit that everything should only\n\n1:48:50.820 --> 1:48:53.860\n be built on top of core knowledge priors.\n\n1:48:53.860 --> 1:48:58.620\n I also think it's generally more diverse than IQ tests\n\n1:48:58.620 --> 1:49:00.300\n in general.\n\n1:49:00.300 --> 1:49:03.820\n And it perhaps requires a bit more manual work\n\n1:49:03.820 --> 1:49:05.460\n to produce solutions, because you\n\n1:49:05.460 --> 1:49:08.500\n have to click around on a grid for a while.\n\n1:49:08.500 --> 1:49:12.020\n Sometimes the grids can be as large as 30 by 30 cells.\n\n1:49:12.020 --> 1:49:18.020\n So how did you come up, if you can reveal, with the questions?\n\n1:49:18.020 --> 1:49:19.580\n What's the process of the questions?\n\n1:49:19.580 --> 1:49:23.380\n Was it mostly you that came up with the questions?\n\n1:49:23.380 --> 1:49:25.780\n How difficult is it to come up with a question?\n\n1:49:25.780 --> 1:49:30.700\n Is this scalable to a much larger number?\n\n1:49:30.700 --> 1:49:33.740\n If we think, with IQ tests, you might not necessarily\n\n1:49:33.740 --> 1:49:36.460\n want it to or need it to be scalable.\n\n1:49:36.460 --> 1:49:39.580\n With machines, it's possible, you\n\n1:49:39.580 --> 1:49:41.620\n could argue, that it needs to be scalable.\n\n1:49:41.620 --> 1:49:46.500\n So there are 1,000 questions, 1,000 tasks,\n\n1:49:46.500 --> 1:49:49.140\n including the test set, the prior test set.\n\n1:49:49.140 --> 1:49:51.060\n I think it's fairly difficult in the sense\n\n1:49:51.060 --> 1:49:54.500\n that a big requirement is that every task should\n\n1:49:54.500 --> 1:50:00.140\n be novel and unique and unpredictable.\n\n1:50:00.140 --> 1:50:04.460\n You don't want to create your own little world that\n\n1:50:04.460 --> 1:50:08.860\n is simple enough that it would be possible for a human\n\n1:50:08.860 --> 1:50:12.580\n to reverse and generate and write down\n\n1:50:12.580 --> 1:50:15.940\n an algorithm that could generate every possible arc\n\n1:50:15.940 --> 1:50:17.060\n task and their solution.\n\n1:50:17.060 --> 1:50:19.340\n So that would completely invalidate the test.\n\n1:50:19.340 --> 1:50:21.700\n So you're constantly coming up with new stuff.\n\n1:50:21.700 --> 1:50:24.820\n Yeah, you need a source of novelty,\n\n1:50:24.820 --> 1:50:27.860\n of unfakeable novelty.\n\n1:50:27.860 --> 1:50:32.020\n And one thing I found is that, as a human,\n\n1:50:32.020 --> 1:50:36.460\n you are not a very good source of unfakeable novelty.\n\n1:50:36.460 --> 1:50:40.580\n And so you have to base the creation of these tasks\n\n1:50:40.580 --> 1:50:41.100\n quite a bit.\n\n1:50:41.100 --> 1:50:42.980\n There are only so many unique tasks\n\n1:50:42.980 --> 1:50:45.580\n that you can do in a given day.\n\n1:50:45.580 --> 1:50:49.860\n So that means coming up with truly original new ideas.\n\n1:50:49.860 --> 1:50:52.380\n Did psychedelics help you at all?\n\n1:50:52.380 --> 1:50:53.780\n No, I'm just kidding.\n\n1:50:53.780 --> 1:50:55.820\n But I mean, that's fascinating to think about.\n\n1:50:55.820 --> 1:50:58.780\n So you would be walking or something like that.\n\n1:50:58.780 --> 1:51:02.860\n Are you constantly thinking of something totally new?\n\n1:51:02.860 --> 1:51:03.380\n Yes.\n\n1:51:06.020 --> 1:51:06.980\n This is hard.\n\n1:51:06.980 --> 1:51:07.620\n This is hard.\n\n1:51:07.620 --> 1:51:10.980\n Yeah, I mean, I'm not saying you've done anywhere\n\n1:51:10.980 --> 1:51:12.380\n near a perfect job at it.\n\n1:51:12.380 --> 1:51:14.540\n There is some amount of redundancy,\n\n1:51:14.540 --> 1:51:16.740\n and there are many imperfections in ARC.\n\n1:51:16.740 --> 1:51:18.540\n So that said, you should consider\n\n1:51:18.540 --> 1:51:19.820\n ARC as a work in progress.\n\n1:51:19.820 --> 1:51:25.180\n It is not the definitive state.\n\n1:51:25.180 --> 1:51:29.300\n The ARC tasks today are not the definitive state of the test.\n\n1:51:29.300 --> 1:51:32.780\n I want to keep refining it in the future.\n\n1:51:32.780 --> 1:51:36.180\n I also think it should be possible to open up\n\n1:51:36.180 --> 1:51:38.660\n the creation of tasks to a broad audience\n\n1:51:38.660 --> 1:51:40.860\n to do crowdsourcing.\n\n1:51:40.860 --> 1:51:43.180\n That would involve several levels of filtering,\n\n1:51:43.180 --> 1:51:44.140\n obviously.\n\n1:51:44.140 --> 1:51:46.260\n But I think it's possible to apply crowdsourcing\n\n1:51:46.260 --> 1:51:51.140\n to develop a much bigger and much more diverse ARC data set.\n\n1:51:51.140 --> 1:51:54.020\n That would also be free of potentially some\n\n1:51:54.020 --> 1:51:56.700\n of my own personal biases.\n\n1:51:56.700 --> 1:51:59.220\n Is there always need to be a part of ARC\n\n1:51:59.220 --> 1:52:02.900\n that the test is hidden?\n\n1:52:02.900 --> 1:52:04.140\n Yes, absolutely.\n\n1:52:04.140 --> 1:52:08.900\n It is imperative that the tests that you're\n\n1:52:08.900 --> 1:52:11.900\n using to actually benchmark algorithms\n\n1:52:11.900 --> 1:52:15.220\n is not accessible to the people developing these algorithms.\n\n1:52:15.220 --> 1:52:16.860\n Because otherwise, what's going to happen\n\n1:52:16.860 --> 1:52:19.100\n is that the human engineers are just\n\n1:52:19.100 --> 1:52:21.820\n going to solve the tasks themselves\n\n1:52:21.820 --> 1:52:24.820\n and encode their solution in program form.\n\n1:52:24.820 --> 1:52:27.420\n But that, again, what you're seeing here\n\n1:52:27.420 --> 1:52:30.100\n is the process of intelligence happening\n\n1:52:30.100 --> 1:52:31.180\n in the mind of the human.\n\n1:52:31.180 --> 1:52:35.460\n And then you're just capturing its crystallized output.\n\n1:52:35.460 --> 1:52:38.260\n But that crystallized output is not the same thing\n\n1:52:38.260 --> 1:52:40.020\n as the process it generated.\n\n1:52:40.020 --> 1:52:41.340\n It's not intelligent in itself.\n\n1:52:41.340 --> 1:52:43.980\n So what, by the way, the idea of crowdsourcing it\n\n1:52:43.980 --> 1:52:45.860\n is fascinating.\n\n1:52:45.860 --> 1:52:49.860\n I think the creation of questions\n\n1:52:49.860 --> 1:52:51.460\n is really exciting for people.\n\n1:52:51.460 --> 1:52:53.980\n I think there's a lot of really brilliant people\n\n1:52:53.980 --> 1:52:56.220\n out there that love to create these kinds of stuff.\n\n1:52:56.220 --> 1:52:59.060\n Yeah, one thing that kind of surprised me\n\n1:52:59.060 --> 1:53:01.620\n that I wasn't expecting is that lots of people\n\n1:53:01.620 --> 1:53:05.980\n seem to actually enjoy ARC as a kind of game.\n\n1:53:05.980 --> 1:53:08.820\n And I was releasing it as a test,\n\n1:53:08.820 --> 1:53:14.100\n as a benchmark of fluid general intelligence.\n\n1:53:14.100 --> 1:53:17.100\n And lots of people just, including kids,\n\n1:53:17.100 --> 1:53:18.900\n just started enjoying it as a game.\n\n1:53:18.900 --> 1:53:20.980\n So I think that's encouraging.\n\n1:53:20.980 --> 1:53:22.300\n Yeah, I'm fascinated by it.\n\n1:53:22.300 --> 1:53:25.940\n There's a world of people who create IQ questions.\n\n1:53:25.940 --> 1:53:32.660\n I think that's a cool activity for machines and for humans.\n\n1:53:32.660 --> 1:53:35.420\n And humans are themselves fascinated\n\n1:53:35.420 --> 1:53:40.220\n by taking the questions, like measuring\n\n1:53:40.220 --> 1:53:42.300\n their own intelligence.\n\n1:53:42.300 --> 1:53:44.420\n I mean, that's just really compelling.\n\n1:53:44.420 --> 1:53:47.020\n It's really interesting to me, too.\n\n1:53:47.020 --> 1:53:48.740\n One of the cool things about ARC, you said,\n\n1:53:48.740 --> 1:53:51.620\n is kind of inspired by IQ tests or whatever\n\n1:53:51.620 --> 1:53:53.460\n follows a similar process.\n\n1:53:53.460 --> 1:53:56.060\n But because of its nature, because of the context\n\n1:53:56.060 --> 1:53:59.020\n in which it lives, it immediately\n\n1:53:59.020 --> 1:54:01.660\n forces you to think about the nature of intelligence\n\n1:54:01.660 --> 1:54:04.220\n as opposed to just the test of your own.\n\n1:54:04.220 --> 1:54:06.020\n It forces you to really think.\n\n1:54:06.020 --> 1:54:09.900\n I don't know if it's within the question,\n\n1:54:09.900 --> 1:54:11.860\n inherent in the question, or just the fact\n\n1:54:11.860 --> 1:54:13.780\n that it lives in the test that's supposed\n\n1:54:13.780 --> 1:54:15.340\n to be a test of machine intelligence.\n\n1:54:15.340 --> 1:54:15.900\n Absolutely.\n\n1:54:15.900 --> 1:54:20.660\n As you solve ARC tasks as a human,\n\n1:54:20.660 --> 1:54:24.700\n you will be forced to basically introspect\n\n1:54:24.700 --> 1:54:27.060\n how you come up with solutions.\n\n1:54:27.060 --> 1:54:32.660\n And that forces you to reflect on the human problem solving\n\n1:54:32.660 --> 1:54:33.820\n process.\n\n1:54:33.820 --> 1:54:38.780\n And the way your own mind generates\n\n1:54:38.780 --> 1:54:44.780\n abstract representations of the problems it's exposed to.\n\n1:54:44.780 --> 1:54:48.860\n I think it's due to the fact that the set of core knowledge\n\n1:54:48.860 --> 1:54:52.460\n priors that ARC is built upon is so small.\n\n1:54:52.460 --> 1:54:58.660\n It's all a recombination of a very, very small set\n\n1:54:58.660 --> 1:55:00.460\n of assumptions.\n\n1:55:00.460 --> 1:55:02.900\n OK, so what's the future of ARC?\n\n1:55:02.900 --> 1:55:05.420\n So you held ARC as a challenge, as part\n\n1:55:05.420 --> 1:55:06.700\n of like a Kaggle competition.\n\n1:55:06.700 --> 1:55:07.180\n Yes.\n\n1:55:07.180 --> 1:55:08.420\n Kaggle competition.\n\n1:55:08.420 --> 1:55:11.860\n And what do you think?\n\n1:55:11.860 --> 1:55:13.060\n Do you think that's something that\n\n1:55:13.060 --> 1:55:16.060\n continues for five years, 10 years,\n\n1:55:16.060 --> 1:55:17.820\n like just continues growing?\n\n1:55:17.820 --> 1:55:18.940\n Yes, absolutely.\n\n1:55:18.940 --> 1:55:21.340\n So ARC itself will keep evolving.\n\n1:55:21.340 --> 1:55:22.780\n So I've talked about crowdsourcing.\n\n1:55:22.780 --> 1:55:26.180\n I think that's a good avenue.\n\n1:55:26.180 --> 1:55:29.340\n Another thing I'm starting is I'll\n\n1:55:29.340 --> 1:55:32.700\n be collaborating with folks from the psychology department\n\n1:55:32.700 --> 1:55:36.660\n at NYU to do human testing on ARC.\n\n1:55:36.660 --> 1:55:38.940\n And I think there are lots of interesting questions\n\n1:55:38.940 --> 1:55:43.940\n you can start asking, especially as you start correlating\n\n1:55:43.940 --> 1:55:49.420\n machine solutions to ARC tasks and the human characteristics\n\n1:55:49.420 --> 1:55:50.060\n of solutions.\n\n1:55:50.060 --> 1:55:52.020\n Like for instance, you can try to see\n\n1:55:52.020 --> 1:55:55.660\n if there's a relationship between the human perceived\n\n1:55:55.660 --> 1:55:59.420\n difficulty of a task and the machine perceived.\n\n1:55:59.420 --> 1:56:01.940\n Yes, and exactly some measure of machine\n\n1:56:01.940 --> 1:56:02.780\n perceived difficulty.\n\n1:56:02.780 --> 1:56:04.900\n Yeah, it's a nice playground in which\n\n1:56:04.900 --> 1:56:06.340\n to explore this very difference.\n\n1:56:06.340 --> 1:56:09.260\n It's the same thing as we talked about the autonomous vehicles.\n\n1:56:09.260 --> 1:56:10.900\n The things that could be difficult for humans\n\n1:56:10.900 --> 1:56:13.100\n might be very different than the things that are difficult.\n\n1:56:13.100 --> 1:56:17.300\n And formalizing or making explicit that difference\n\n1:56:17.300 --> 1:56:21.020\n in difficulty may teach us something fundamental\n\n1:56:21.020 --> 1:56:22.340\n about intelligence.\n\n1:56:22.340 --> 1:56:26.420\n So one thing I think we did well with ARC\n\n1:56:26.420 --> 1:56:33.060\n is that it's proving to be a very actionable test in the sense\n\n1:56:33.060 --> 1:56:37.700\n that machine performance on ARC started at very much zero\n\n1:56:37.700 --> 1:56:43.340\n initially, while humans found actually the task very easy.\n\n1:56:43.340 --> 1:56:48.180\n And that alone was like a big red flashing light saying\n\n1:56:48.180 --> 1:56:52.380\n that something is going on and that we are missing something.\n\n1:56:52.380 --> 1:56:55.420\n And at the same time, machine performance\n\n1:56:55.420 --> 1:56:57.660\n did not stay at zero for very long.\n\n1:56:57.660 --> 1:57:00.260\n Actually, within two weeks of the Kaggle competition,\n\n1:57:00.260 --> 1:57:03.220\n we started having a nonzero number.\n\n1:57:03.220 --> 1:57:06.460\n And now the state of the art is around 20%\n\n1:57:06.460 --> 1:57:10.260\n of the test set solved.\n\n1:57:10.260 --> 1:57:12.500\n And so ARC is actually a challenge\n\n1:57:12.500 --> 1:57:16.860\n where our capabilities start at zero, which indicates\n\n1:57:16.860 --> 1:57:18.180\n the need for progress.\n\n1:57:18.180 --> 1:57:20.580\n But it's also not an impossible challenge.\n\n1:57:20.580 --> 1:57:21.500\n It's not accessible.\n\n1:57:21.500 --> 1:57:25.260\n You can start making progress basically right away.\n\n1:57:25.260 --> 1:57:28.380\n At the same time, we are still very far\n\n1:57:28.380 --> 1:57:29.420\n from having solved it.\n\n1:57:29.420 --> 1:57:32.820\n And that's actually a very positive outcome\n\n1:57:32.820 --> 1:57:35.900\n of the competition is that the competition has proven\n\n1:57:35.900 --> 1:57:41.740\n that there was no obvious shortcut to solve these tasks.\n\n1:57:41.740 --> 1:57:43.180\n Yeah, so the test held up.\n\n1:57:43.180 --> 1:57:44.340\n Yeah, exactly.\n\n1:57:44.340 --> 1:57:46.900\n That was the primary reason to use the Kaggle competition\n\n1:57:46.900 --> 1:57:51.540\n is to check if some clever person was\n\n1:57:51.540 --> 1:57:56.380\n going to hack the benchmark that did not happen.\n\n1:57:56.380 --> 1:58:01.060\n People who are solving the task are essentially doing it.\n\n1:58:01.060 --> 1:58:05.580\n Well, in a way, they're actually exploring some flaws of ARC\n\n1:58:05.580 --> 1:58:07.380\n that we will need to address in the future,\n\n1:58:07.380 --> 1:58:09.900\n especially they're essentially anticipating\n\n1:58:09.900 --> 1:58:13.780\n what sort of tasks may be contained in the test set.\n\n1:58:13.780 --> 1:58:18.460\n Right, which is kind of, yeah, that's the kind of hacking.\n\n1:58:18.460 --> 1:58:20.180\n It's human hacking of the test.\n\n1:58:20.180 --> 1:58:23.380\n Yes, that said, with the state of the art,\n\n1:58:23.380 --> 1:58:28.220\n it's like 20% we're still very, very far from human level,\n\n1:58:28.220 --> 1:58:30.940\n which is closer to 100%.\n\n1:58:30.940 --> 1:58:35.540\n And I do believe that it will take a while\n\n1:58:35.540 --> 1:58:40.500\n until we reach human parity on ARC.\n\n1:58:40.500 --> 1:58:43.540\n And that by the time we have human parity,\n\n1:58:43.540 --> 1:58:47.020\n we will have AI systems that are probably\n\n1:58:47.020 --> 1:58:50.740\n pretty close to human level in terms of general fluid\n\n1:58:50.740 --> 1:58:53.260\n intelligence, which is, I mean, they are not\n\n1:58:53.260 --> 1:58:54.940\n going to be necessarily human like.\n\n1:58:54.940 --> 1:58:58.780\n They're not necessarily, you would not necessarily\n\n1:58:58.780 --> 1:59:01.860\n recognize them as being an AGI.\n\n1:59:01.860 --> 1:59:06.860\n But they would be capable of a degree of generalization\n\n1:59:06.860 --> 1:59:09.820\n that matches the generalization performed\n\n1:59:09.820 --> 1:59:11.300\n by human fluid intelligence.\n\n1:59:11.300 --> 1:59:11.860\n Sure.\n\n1:59:11.860 --> 1:59:13.380\n I mean, this is a good point in terms\n\n1:59:13.380 --> 1:59:17.700\n of general fluid intelligence to mention in your paper.\n\n1:59:17.700 --> 1:59:21.060\n You describe different kinds of generalizations,\n\n1:59:21.060 --> 1:59:23.460\n local, broad, extreme.\n\n1:59:23.460 --> 1:59:25.660\n And there's a kind of a hierarchy that you form.\n\n1:59:25.660 --> 1:59:31.820\n So when we say generalizations, what are we talking about?\n\n1:59:31.820 --> 1:59:33.180\n What kinds are there?\n\n1:59:33.180 --> 1:59:37.020\n Right, so generalization is a very old idea.\n\n1:59:37.020 --> 1:59:39.420\n I mean, it's even older than machine learning.\n\n1:59:39.420 --> 1:59:40.980\n In the context of machine learning,\n\n1:59:40.980 --> 1:59:47.140\n you say a system generalizes if it can make sense of an input\n\n1:59:47.140 --> 1:59:49.580\n it has not yet seen.\n\n1:59:49.580 --> 1:59:54.940\n And that's what I would call system centric generalization,\n\n1:59:54.940 --> 2:00:00.380\n generalization with respect to novelty\n\n2:00:00.380 --> 2:00:02.980\n for the specific system you're considering.\n\n2:00:02.980 --> 2:00:05.060\n So I think a good test of intelligence\n\n2:00:05.060 --> 2:00:09.900\n should actually deal with developer aware generalization,\n\n2:00:09.900 --> 2:00:13.500\n which is slightly stronger than system centric generalization.\n\n2:00:13.500 --> 2:00:16.020\n So developer aware generalization\n\n2:00:16.020 --> 2:00:19.860\n would be the ability to generalize\n\n2:00:19.860 --> 2:00:24.220\n to novelty or uncertainty that not only the system itself has\n\n2:00:24.220 --> 2:00:26.660\n not access to, but the developer of the system\n\n2:00:26.660 --> 2:00:29.380\n could not have access to either.\n\n2:00:29.380 --> 2:00:32.380\n That's a fascinating meta definition.\n\n2:00:32.380 --> 2:00:37.700\n So the system is basically the edge case thing\n\n2:00:37.700 --> 2:00:39.780\n we're talking about with autonomous vehicles.\n\n2:00:39.780 --> 2:00:41.620\n Neither the developer nor the system\n\n2:00:41.620 --> 2:00:44.420\n know about the edge cases in my encounter.\n\n2:00:44.420 --> 2:00:47.020\n So it's up to the system should be\n\n2:00:47.020 --> 2:00:51.660\n able to generalize the thing that nobody expected,\n\n2:00:51.660 --> 2:00:54.860\n neither the designer of the training data,\n\n2:00:54.860 --> 2:00:59.060\n nor obviously the contents of the training data.\n\n2:00:59.060 --> 2:01:00.580\n That's a fascinating definition.\n\n2:01:00.580 --> 2:01:04.540\n So you can see degrees of generalization as a spectrum.\n\n2:01:04.540 --> 2:01:08.060\n And the lowest level is what machine learning\n\n2:01:08.060 --> 2:01:10.780\n is trying to do is the assumption\n\n2:01:10.780 --> 2:01:15.220\n that any new situation is going to be sampled\n\n2:01:15.220 --> 2:01:18.340\n from a static distribution of possible situations\n\n2:01:18.340 --> 2:01:21.500\n and that you already have a representative sample\n\n2:01:21.500 --> 2:01:22.420\n of the distribution.\n\n2:01:22.420 --> 2:01:23.860\n That's your training data.\n\n2:01:23.860 --> 2:01:26.700\n And so in machine learning, you generalize to a new sample\n\n2:01:26.700 --> 2:01:28.780\n from a known distribution.\n\n2:01:28.780 --> 2:01:34.020\n And the ways in which your new sample will be new or different\n\n2:01:34.020 --> 2:01:38.140\n are ways that are already understood by the developers\n\n2:01:38.140 --> 2:01:39.420\n of the system.\n\n2:01:39.420 --> 2:01:43.020\n So you are generalizing to known unknowns\n\n2:01:43.020 --> 2:01:45.100\n for one specific task.\n\n2:01:45.100 --> 2:01:47.500\n That's what you would call robustness.\n\n2:01:47.500 --> 2:01:50.180\n You are robust to things like noise, small variations,\n\n2:01:50.180 --> 2:01:56.620\n and so on for one fixed known distribution\n\n2:01:56.620 --> 2:01:59.300\n that you know through your training data.\n\n2:01:59.300 --> 2:02:05.060\n And the higher degree would be flexibility\n\n2:02:05.060 --> 2:02:06.380\n in machine intelligence.\n\n2:02:06.380 --> 2:02:08.620\n So flexibility would be something\n\n2:02:08.620 --> 2:02:12.500\n like an L5 cell driving car or maybe a robot that\n\n2:02:12.500 --> 2:02:16.820\n can pass the coffee cup test, which\n\n2:02:16.820 --> 2:02:21.460\n is the notion that you'd be given a random kitchen\n\n2:02:21.460 --> 2:02:22.460\n somewhere in the country.\n\n2:02:22.460 --> 2:02:28.460\n And you would have to go make a cup of coffee in that kitchen.\n\n2:02:28.460 --> 2:02:30.820\n So flexibility would be the ability\n\n2:02:30.820 --> 2:02:35.300\n to deal with unknown unknowns, so things that could not,\n\n2:02:35.300 --> 2:02:37.180\n dimensions of viability that could not\n\n2:02:37.180 --> 2:02:41.100\n have been possibly foreseen by the creators of the system\n\n2:02:41.100 --> 2:02:42.860\n within one specific task.\n\n2:02:42.860 --> 2:02:47.020\n So generalizing to the long tail of situations in self driving,\n\n2:02:47.020 --> 2:02:48.540\n for instance, would be flexibility.\n\n2:02:48.540 --> 2:02:51.700\n So you have robustness, flexibility, and finally,\n\n2:02:51.700 --> 2:02:53.700\n you would have extreme generalization,\n\n2:02:53.700 --> 2:02:57.740\n which is basically flexibility, but instead\n\n2:02:57.740 --> 2:03:01.180\n of just considering one specific domain,\n\n2:03:01.180 --> 2:03:03.340\n like driving or domestic robotics,\n\n2:03:03.340 --> 2:03:07.740\n you're considering an open ended range of possible domains.\n\n2:03:07.740 --> 2:03:12.620\n So a robot would be capable of extreme generalization\n\n2:03:12.620 --> 2:03:18.060\n if, let's say, it's designed and trained for cooking,\n\n2:03:18.060 --> 2:03:19.820\n for instance.\n\n2:03:19.820 --> 2:03:24.580\n And if I buy the robot and if it's\n\n2:03:24.580 --> 2:03:28.780\n able to teach itself gardening in a couple of weeks,\n\n2:03:28.780 --> 2:03:32.300\n it would be capable of extreme generalization, for instance.\n\n2:03:32.300 --> 2:03:34.300\n So the ultimate goal is extreme generalization.\n\n2:03:34.300 --> 2:03:34.820\n Yes.\n\n2:03:34.820 --> 2:03:40.020\n So creating a system that is so general that it could\n\n2:03:40.020 --> 2:03:46.140\n essentially achieve human skill parity over arbitrary tasks\n\n2:03:46.140 --> 2:03:50.820\n and arbitrary domains with the same level of improvisation\n\n2:03:50.820 --> 2:03:53.740\n and adaptation power as humans when\n\n2:03:53.740 --> 2:03:55.380\n it encounters new situations.\n\n2:03:55.380 --> 2:03:59.780\n And it would do so over basically the same range\n\n2:03:59.780 --> 2:04:02.780\n of possible domains and tasks as humans\n\n2:04:02.780 --> 2:04:05.500\n and using essentially the same amount of training\n\n2:04:05.500 --> 2:04:07.860\n experience of practice as humans would require.\n\n2:04:07.860 --> 2:04:10.900\n That would be human level extreme generalization.\n\n2:04:10.900 --> 2:04:14.620\n So I don't actually think humans are anywhere\n\n2:04:14.620 --> 2:04:19.580\n near the optimal intelligence bounds\n\n2:04:19.580 --> 2:04:21.300\n if there is such a thing.\n\n2:04:21.300 --> 2:04:23.820\n So I think for humans or in general?\n\n2:04:23.820 --> 2:04:25.140\n In general.\n\n2:04:25.140 --> 2:04:26.780\n I think it's quite likely that there\n\n2:04:26.780 --> 2:04:33.860\n is a hard limit to how intelligent any system can be.\n\n2:04:33.860 --> 2:04:35.980\n But at the same time, I don't think humans are anywhere\n\n2:04:35.980 --> 2:04:39.180\n near that limit.\n\n2:04:39.180 --> 2:04:40.780\n Yeah, last time I think we talked,\n\n2:04:40.780 --> 2:04:43.820\n I think you had this idea that we're only\n\n2:04:43.820 --> 2:04:46.580\n as intelligent as the problems we face.\n\n2:04:46.580 --> 2:04:51.300\n Sort of we are bounded by the problems.\n\n2:04:51.300 --> 2:04:51.940\n In a way, yes.\n\n2:04:51.940 --> 2:04:55.100\n We are bounded by our environments,\n\n2:04:55.100 --> 2:04:58.100\n and we are bounded by the problems we try to solve.\n\n2:04:58.100 --> 2:04:59.220\n Yeah.\n\n2:04:59.220 --> 2:04:59.700\n Yeah.\n\n2:04:59.700 --> 2:05:03.820\n What do you make of Neuralink and outsourcing\n\n2:05:03.820 --> 2:05:07.140\n some of the brain power, like brain computer interfaces?\n\n2:05:07.140 --> 2:05:13.460\n Do you think we can expand or augment our intelligence?\n\n2:05:13.460 --> 2:05:18.340\n I am fairly skeptical of neural interfaces\n\n2:05:18.340 --> 2:05:23.780\n because they are trying to fix one specific bottleneck\n\n2:05:23.780 --> 2:05:26.380\n in human machine cognition, which\n\n2:05:26.380 --> 2:05:29.700\n is the bandwidth bottleneck, input and output\n\n2:05:29.700 --> 2:05:31.820\n of information in the brain.\n\n2:05:31.820 --> 2:05:37.820\n And my perception of the problem is that bandwidth is not\n\n2:05:37.820 --> 2:05:41.140\n at this time a bottleneck at all.\n\n2:05:41.140 --> 2:05:43.580\n Meaning that we already have sensors\n\n2:05:43.580 --> 2:05:48.300\n that enable us to take in far more information than what\n\n2:05:48.300 --> 2:05:50.420\n we can actually process.\n\n2:05:50.420 --> 2:05:53.260\n Well, to push back on that a little bit,\n\n2:05:53.260 --> 2:05:55.420\n to sort of play devil's advocate a little bit,\n\n2:05:55.420 --> 2:05:58.980\n is if you look at the internet, Wikipedia, let's say Wikipedia,\n\n2:05:58.980 --> 2:06:03.300\n I would say that humans, after the advent of Wikipedia,\n\n2:06:03.300 --> 2:06:05.860\n are much more intelligent.\n\n2:06:05.860 --> 2:06:07.820\n Yes, I think that's a good one.\n\n2:06:07.820 --> 2:06:14.180\n But that's also not about, that's about externalizing\n\n2:06:14.180 --> 2:06:18.140\n our intelligence via information processing systems,\n\n2:06:18.140 --> 2:06:19.740\n external information processing systems,\n\n2:06:19.740 --> 2:06:23.780\n which is very different from brain computer interfaces.\n\n2:06:23.780 --> 2:06:27.980\n Right, but the question is whether if we have direct\n\n2:06:27.980 --> 2:06:31.940\n access, if our brain has direct access to Wikipedia without\n\n2:06:31.940 --> 2:06:34.540\n Your brain already has direct access to Wikipedia.\n\n2:06:34.540 --> 2:06:35.900\n It's on your phone.\n\n2:06:35.900 --> 2:06:39.380\n And you have your hands and your eyes and your ears\n\n2:06:39.380 --> 2:06:42.140\n and so on to access that information.\n\n2:06:42.140 --> 2:06:44.340\n And the speed at which you can access it\n\n2:06:44.340 --> 2:06:45.700\n Is bottlenecked by the cognition.\n\n2:06:45.700 --> 2:06:49.620\n I think it's already close, fairly close to optimal,\n\n2:06:49.620 --> 2:06:53.340\n which is why speed reading, for instance, does not work.\n\n2:06:53.340 --> 2:06:55.980\n The faster you read, the less you understand.\n\n2:06:55.980 --> 2:06:58.420\n But maybe it's because it uses the eyes.\n\n2:06:58.420 --> 2:07:00.540\n So maybe.\n\n2:07:00.540 --> 2:07:01.460\n So I don't believe so.\n\n2:07:01.460 --> 2:07:04.620\n I think the brain is very slow.\n\n2:07:04.620 --> 2:07:07.860\n It typically operates, you know, the fastest things\n\n2:07:07.860 --> 2:07:11.420\n that happen in the brain are at the level of 50 milliseconds.\n\n2:07:11.420 --> 2:07:14.580\n Forming a conscious thought can potentially\n\n2:07:14.580 --> 2:07:16.740\n take entire seconds, right?\n\n2:07:16.740 --> 2:07:19.220\n And you can already read pretty fast.\n\n2:07:19.220 --> 2:07:23.460\n So I think the speed at which you can take information in\n\n2:07:23.460 --> 2:07:26.460\n and even the speed at which you can output information\n\n2:07:26.460 --> 2:07:29.900\n can only be very incrementally improved.\n\n2:07:29.900 --> 2:07:31.100\n Maybe there's a question.\n\n2:07:31.100 --> 2:07:34.380\n If you're a very fast typer, if you're a very trained typer,\n\n2:07:34.380 --> 2:07:36.660\n the speed at which you can express your thoughts\n\n2:07:36.660 --> 2:07:40.500\n is already the speed at which you can form your thoughts.\n\n2:07:40.500 --> 2:07:44.540\n Right, so that's kind of an idea that there are\n\n2:07:44.540 --> 2:07:47.020\n fundamental bottlenecks to the human mind.\n\n2:07:47.020 --> 2:07:50.260\n But it's possible that everything we have\n\n2:07:50.260 --> 2:07:53.140\n in the human mind is just to be able to survive\n\n2:07:53.140 --> 2:07:54.420\n in the environment.\n\n2:07:54.420 --> 2:07:58.300\n And there's a lot more to expand.\n\n2:07:58.300 --> 2:08:02.420\n Maybe, you know, you said the speed of the thought.\n\n2:08:02.420 --> 2:08:06.780\n So I think augmenting human intelligence\n\n2:08:06.780 --> 2:08:09.900\n is a very valid and very powerful avenue, right?\n\n2:08:09.900 --> 2:08:12.260\n And that's what computers are about.\n\n2:08:12.260 --> 2:08:15.900\n In fact, that's what all of culture and civilization\n\n2:08:15.900 --> 2:08:16.740\n is about.\n\n2:08:16.740 --> 2:08:20.620\n Our culture is externalized cognition\n\n2:08:20.620 --> 2:08:23.740\n and we rely on culture to think constantly.\n\n2:08:23.740 --> 2:08:26.620\n Yeah, I mean, that's another, yeah.\n\n2:08:26.620 --> 2:08:29.140\n Not just computers, not just phones and the internet.\n\n2:08:29.140 --> 2:08:32.460\n I mean, all of culture, like language, for instance,\n\n2:08:32.460 --> 2:08:34.020\n is a form of externalized cognition.\n\n2:08:34.020 --> 2:08:37.460\n Books are obviously externalized cognition.\n\n2:08:37.460 --> 2:08:38.580\n Yeah, that's a good point.\n\n2:08:38.580 --> 2:08:42.060\n And you can scale that externalized cognition\n\n2:08:42.060 --> 2:08:45.180\n far beyond the capability of the human brain.\n\n2:08:45.180 --> 2:08:48.900\n And you could see civilization itself\n\n2:08:48.900 --> 2:08:54.260\n is it has capabilities that are far beyond any individual brain\n\n2:08:54.260 --> 2:08:55.940\n and will keep scaling it because it's not\n\n2:08:55.940 --> 2:08:59.140\n rebound by individual brains.\n\n2:08:59.140 --> 2:09:01.340\n It's a different kind of system.\n\n2:09:01.340 --> 2:09:06.260\n Yeah, and that system includes nonhuman, nonhumans.\n\n2:09:06.260 --> 2:09:08.700\n First of all, it includes all the other biological systems,\n\n2:09:08.700 --> 2:09:11.660\n which are probably contributing to the overall intelligence\n\n2:09:11.660 --> 2:09:12.900\n of the organism.\n\n2:09:12.900 --> 2:09:14.460\n And then computers are part of it.\n\n2:09:14.460 --> 2:09:16.860\n Nonhuman systems are probably not contributing much,\n\n2:09:16.860 --> 2:09:19.700\n but AIs are definitely contributing to that.\n\n2:09:19.700 --> 2:09:24.260\n Like Google search, for instance, is a big part of it.\n\n2:09:24.260 --> 2:09:29.660\n Yeah, yeah, a huge part, a part that we can't probably\n\n2:09:29.660 --> 2:09:31.060\n introspect.\n\n2:09:31.060 --> 2:09:33.780\n Like how the world has changed in the past 20 years,\n\n2:09:33.780 --> 2:09:35.220\n it's probably very difficult for us\n\n2:09:35.220 --> 2:09:38.620\n to be able to understand until, of course,\n\n2:09:38.620 --> 2:09:41.740\n whoever created the simulation we're in is probably\n\n2:09:41.740 --> 2:09:44.940\n doing metrics, measuring the progress.\n\n2:09:44.940 --> 2:09:48.340\n There was probably a big spike in performance.\n\n2:09:48.340 --> 2:09:51.580\n They're enjoying this.\n\n2:09:51.580 --> 2:09:56.020\n So what are your thoughts on the Turing test\n\n2:09:56.020 --> 2:10:00.340\n and the Lobner Prize, which is one\n\n2:10:00.340 --> 2:10:05.700\n of the most famous attempts at the test of artificial\n\n2:10:05.700 --> 2:10:11.740\n intelligence by doing a natural language open dialogue test\n\n2:10:11.740 --> 2:10:18.860\n that's judged by humans as far as how well the machine did?\n\n2:10:18.860 --> 2:10:21.460\n So I'm not a fan of the Turing test.\n\n2:10:21.460 --> 2:10:25.940\n Itself or any of its variants for two reasons.\n\n2:10:25.940 --> 2:10:34.140\n So first of all, it's really coping out\n\n2:10:34.140 --> 2:10:37.660\n of trying to define and measure intelligence\n\n2:10:37.660 --> 2:10:40.620\n because it's entirely outsourcing that\n\n2:10:40.620 --> 2:10:43.380\n to a panel of human judges.\n\n2:10:43.380 --> 2:10:47.420\n And these human judges, they may not themselves\n\n2:10:47.420 --> 2:10:49.700\n have any proper methodology.\n\n2:10:49.700 --> 2:10:52.660\n They may not themselves have any proper definition\n\n2:10:52.660 --> 2:10:53.620\n of intelligence.\n\n2:10:53.620 --> 2:10:54.780\n They may not be reliable.\n\n2:10:54.780 --> 2:10:57.260\n So the Turing test is already failing\n\n2:10:57.260 --> 2:10:59.620\n one of the core psychometrics principles, which\n\n2:10:59.620 --> 2:11:04.620\n is reliability because you have biased human judges.\n\n2:11:04.620 --> 2:11:07.900\n It's also violating the standardization requirement\n\n2:11:07.900 --> 2:11:10.140\n and the freedom from bias requirement.\n\n2:11:10.140 --> 2:11:13.900\n And so it's really a cope out because you are outsourcing\n\n2:11:13.900 --> 2:11:17.380\n everything that matters, which is precisely describing\n\n2:11:17.380 --> 2:11:22.180\n intelligence and finding a standalone test to measure it.\n\n2:11:22.180 --> 2:11:25.260\n You're outsourcing everything to people.\n\n2:11:25.260 --> 2:11:26.340\n So it's really a cope out.\n\n2:11:26.340 --> 2:11:28.860\n And by the way, we should keep in mind\n\n2:11:28.860 --> 2:11:33.940\n that when Turing proposed the imitation game,\n\n2:11:33.940 --> 2:11:36.780\n it was not meaning for the imitation game\n\n2:11:36.780 --> 2:11:40.700\n to be an actual goal for the field of AI\n\n2:11:40.700 --> 2:11:42.460\n and actual test of intelligence.\n\n2:11:42.460 --> 2:11:48.780\n It was using the imitation game as a thought experiment\n\n2:11:48.780 --> 2:11:53.580\n in a philosophical discussion in his 1950 paper.\n\n2:11:53.580 --> 2:11:58.820\n He was trying to argue that theoretically, it\n\n2:11:58.820 --> 2:12:04.220\n should be possible for something very much like the human mind,\n\n2:12:04.220 --> 2:12:06.100\n indistinguishable from the human mind,\n\n2:12:06.100 --> 2:12:08.060\n to be encoded in a Turing machine.\n\n2:12:08.060 --> 2:12:14.540\n And at the time, that was a very daring idea.\n\n2:12:14.540 --> 2:12:16.580\n It was stretching credulity.\n\n2:12:16.580 --> 2:12:20.140\n But nowadays, I think it's fairly well accepted\n\n2:12:20.140 --> 2:12:22.660\n that the mind is an information processing system\n\n2:12:22.660 --> 2:12:25.420\n and that you could probably encode it into a computer.\n\n2:12:25.420 --> 2:12:29.380\n So another reason why I'm not a fan of this type of test\n\n2:12:29.380 --> 2:12:34.220\n is that the incentives that it creates\n\n2:12:34.220 --> 2:12:39.740\n are incentives that are not conducive to proper scientific\n\n2:12:39.740 --> 2:12:40.780\n research.\n\n2:12:40.780 --> 2:12:45.700\n If your goal is to trick, to convince a panel of human\n\n2:12:45.700 --> 2:12:48.460\n judges that they are talking to a human,\n\n2:12:48.460 --> 2:12:53.420\n then you have an incentive to rely on tricks\n\n2:12:53.420 --> 2:12:56.500\n and prestidigitation.\n\n2:12:56.500 --> 2:12:59.180\n In the same way that, let's say, you're doing physics\n\n2:12:59.180 --> 2:13:01.500\n and you want to solve teleportation.\n\n2:13:01.500 --> 2:13:04.660\n And what if the test that you set out to pass\n\n2:13:04.660 --> 2:13:07.460\n is you need to convince a panel of judges\n\n2:13:07.460 --> 2:13:09.500\n that teleportation took place?\n\n2:13:09.500 --> 2:13:12.580\n And they're just sitting there and watching what you're doing.\n\n2:13:12.580 --> 2:13:17.540\n And that is something that you can achieve with David\n\n2:13:17.540 --> 2:13:22.780\n Copperfield could achieve it in his show at Vegas.\n\n2:13:22.780 --> 2:13:25.260\n And what he's doing is very elaborate.\n\n2:13:25.260 --> 2:13:29.180\n But it's not physics.\n\n2:13:29.180 --> 2:13:31.740\n It's not making any progress in our understanding\n\n2:13:31.740 --> 2:13:32.620\n of the universe.\n\n2:13:32.620 --> 2:13:34.780\n To push back on that is possible.\n\n2:13:34.780 --> 2:13:39.020\n That's the hope with these kinds of subjective evaluations\n\n2:13:39.020 --> 2:13:41.940\n is that it's easier to solve it generally\n\n2:13:41.940 --> 2:13:45.420\n than it is to come up with tricks that convince\n\n2:13:45.420 --> 2:13:46.620\n a large number of judges.\n\n2:13:46.620 --> 2:13:47.340\n That's the hope.\n\n2:13:47.340 --> 2:13:49.300\n In practice, it turns out that it's\n\n2:13:49.300 --> 2:13:51.500\n very easy to deceive people in the same way\n\n2:13:51.500 --> 2:13:54.380\n that you can do magic in Vegas.\n\n2:13:54.380 --> 2:13:57.300\n You can actually very easily convince people\n\n2:13:57.300 --> 2:13:59.500\n that they're talking to a human when they're actually\n\n2:13:59.500 --> 2:14:00.740\n talking to an algorithm.\n\n2:14:00.740 --> 2:14:01.740\n I just disagree.\n\n2:14:01.740 --> 2:14:02.660\n I disagree with that.\n\n2:14:02.660 --> 2:14:03.620\n I think it's easy.\n\n2:14:03.620 --> 2:14:05.100\n I would push.\n\n2:14:05.100 --> 2:14:07.340\n No, it's not easy.\n\n2:14:07.340 --> 2:14:08.300\n It's doable.\n\n2:14:08.300 --> 2:14:12.260\n It's very easy because we are biased.\n\n2:14:12.260 --> 2:14:13.860\n We have theory of mind.\n\n2:14:13.860 --> 2:14:21.020\n We are constantly projecting emotions, intentions, agentness.\n\n2:14:21.020 --> 2:14:24.260\n Agentness is one of our core innate priors.\n\n2:14:24.260 --> 2:14:26.820\n We are projecting these things on everything around us.\n\n2:14:26.820 --> 2:14:31.260\n Like if you paint a smiley on a rock,\n\n2:14:31.260 --> 2:14:33.420\n the rock becomes happy in our eyes.\n\n2:14:33.420 --> 2:14:36.540\n And because we have this extreme bias that\n\n2:14:36.540 --> 2:14:39.740\n permits everything we see around us,\n\n2:14:39.740 --> 2:14:41.780\n it's actually pretty easy to trick people.\n\n2:14:41.780 --> 2:14:44.300\n I just disagree with that.\n\n2:14:44.300 --> 2:14:45.820\n I so totally disagree with that.\n\n2:14:45.820 --> 2:14:50.500\n You brilliantly put as a huge, the anthropomorphization\n\n2:14:50.500 --> 2:14:53.140\n that we naturally do, the agentness of that word.\n\n2:14:53.140 --> 2:14:53.980\n Is that a real word?\n\n2:14:53.980 --> 2:14:55.500\n No, it's not a real word.\n\n2:14:55.500 --> 2:14:56.020\n I like it.\n\n2:14:56.020 --> 2:14:57.780\n But it's a useful word.\n\n2:14:57.780 --> 2:14:58.620\n It's a useful word.\n\n2:14:58.620 --> 2:14:59.660\n Let's make it real.\n\n2:14:59.660 --> 2:15:01.020\n It's a huge help.\n\n2:15:01.020 --> 2:15:04.900\n But I still think it's really difficult to convince.\n\n2:15:04.900 --> 2:15:07.940\n If you do like the Alexa Prize formulation,\n\n2:15:07.940 --> 2:15:10.420\n where you talk for an hour, there's\n\n2:15:10.420 --> 2:15:12.460\n formulations of the test you can create,\n\n2:15:12.460 --> 2:15:13.780\n where it's very difficult.\n\n2:15:13.780 --> 2:15:18.100\n So I like the Alexa Prize better because it's more pragmatic.\n\n2:15:18.100 --> 2:15:19.540\n It's more practical.\n\n2:15:19.540 --> 2:15:22.100\n It's actually incentivizing developers\n\n2:15:22.100 --> 2:15:27.860\n to create something that's useful as a human machine\n\n2:15:27.860 --> 2:15:29.300\n interface.\n\n2:15:29.300 --> 2:15:31.780\n So that's slightly better than just the imitation.\n\n2:15:31.780 --> 2:15:34.100\n So I like it.\n\n2:15:34.100 --> 2:15:36.980\n Your idea is like a test which hopefully\n\n2:15:36.980 --> 2:15:39.620\n help us in creating intelligent systems as a result.\n\n2:15:39.620 --> 2:15:41.700\n Like if you create a system that passes it,\n\n2:15:41.700 --> 2:15:44.740\n it'll be useful for creating further intelligent systems.\n\n2:15:44.740 --> 2:15:46.100\n Yes, at least.\n\n2:15:46.100 --> 2:15:47.620\n Yeah.\n\n2:15:47.620 --> 2:15:51.740\n Just to kind of comment, I'm a little bit surprised\n\n2:15:51.740 --> 2:15:55.660\n how little inspiration people draw from the Turing test\n\n2:15:55.660 --> 2:15:57.180\n today.\n\n2:15:57.180 --> 2:15:59.420\n The media and the popular press might write about it\n\n2:15:59.420 --> 2:16:00.900\n every once in a while.\n\n2:16:00.900 --> 2:16:03.500\n The philosophers might talk about it.\n\n2:16:03.500 --> 2:16:07.020\n But most engineers are not really inspired by it.\n\n2:16:07.020 --> 2:16:11.340\n And I know you don't like the Turing test,\n\n2:16:11.340 --> 2:16:15.060\n but we'll have this argument another time.\n\n2:16:15.060 --> 2:16:18.620\n There's something inspiring about it, I think.\n\n2:16:18.620 --> 2:16:21.740\n As a philosophical device in a physical discussion,\n\n2:16:21.740 --> 2:16:23.780\n I think there is something very interesting about it.\n\n2:16:23.780 --> 2:16:26.220\n I don't think it is in practical terms.\n\n2:16:26.220 --> 2:16:29.060\n I don't think it's conducive to progress.\n\n2:16:29.060 --> 2:16:32.540\n And one of the reasons why is that I\n\n2:16:32.540 --> 2:16:35.300\n think being very human like, being\n\n2:16:35.300 --> 2:16:37.540\n indistinguishable from a human is actually\n\n2:16:37.540 --> 2:16:40.460\n the very last step in the creation of machine\n\n2:16:40.460 --> 2:16:41.020\n intelligence.\n\n2:16:41.020 --> 2:16:46.820\n That the first ARs that will show strong generalization\n\n2:16:46.820 --> 2:16:52.500\n that will actually implement human like broad cognitive\n\n2:16:52.500 --> 2:16:54.980\n abilities, they will not actually behave or look\n\n2:16:54.980 --> 2:16:58.500\n anything like humans.\n\n2:16:58.500 --> 2:17:01.700\n Human likeness is the very last step in that process.\n\n2:17:01.700 --> 2:17:03.780\n And so a good test is a test that\n\n2:17:03.780 --> 2:17:07.060\n points you towards the first step on the ladder,\n\n2:17:07.060 --> 2:17:08.900\n not towards the top of the ladder.\n\n2:17:08.900 --> 2:17:11.980\n So to push back on that, I usually\n\n2:17:11.980 --> 2:17:13.460\n agree with you on most things.\n\n2:17:13.460 --> 2:17:15.060\n I remember you, I think at some point,\n\n2:17:15.060 --> 2:17:17.100\n tweeting something about the Turing test\n\n2:17:17.100 --> 2:17:19.020\n not being being counterproductive\n\n2:17:19.020 --> 2:17:20.340\n or something like that.\n\n2:17:20.340 --> 2:17:23.220\n And I think a lot of very smart people agree with that.\n\n2:17:23.220 --> 2:17:31.460\n I, a computation speaking, not very smart person,\n\n2:17:31.460 --> 2:17:32.300\n disagree with that.\n\n2:17:32.300 --> 2:17:33.820\n Because I think there's some magic\n\n2:17:33.820 --> 2:17:36.900\n to the interactivity with other humans.\n\n2:17:36.900 --> 2:17:39.620\n So to play devil's advocate on your statement,\n\n2:17:39.620 --> 2:17:42.780\n it's possible that in order to demonstrate\n\n2:17:42.780 --> 2:17:45.540\n the generalization abilities of a system,\n\n2:17:45.540 --> 2:17:49.940\n you have to show your ability, in conversation,\n\n2:17:49.940 --> 2:17:55.380\n show your ability to adjust, adapt to the conversation\n\n2:17:55.380 --> 2:17:58.380\n through not just like as a standalone system,\n\n2:17:58.380 --> 2:18:01.380\n but through the process of like the interaction,\n\n2:18:01.380 --> 2:18:05.700\n the game theoretic, where you really\n\n2:18:05.700 --> 2:18:09.180\n are changing the environment by your actions.\n\n2:18:09.180 --> 2:18:11.660\n So in the ARC challenge, for example,\n\n2:18:11.660 --> 2:18:12.820\n you're an observer.\n\n2:18:12.820 --> 2:18:17.460\n You can't scare the test into changing.\n\n2:18:17.460 --> 2:18:19.380\n You can't talk to the test.\n\n2:18:19.380 --> 2:18:21.260\n You can't play with it.\n\n2:18:21.260 --> 2:18:24.300\n So there's some aspect of that interactivity\n\n2:18:24.300 --> 2:18:26.140\n that becomes highly subjective, but it\n\n2:18:26.140 --> 2:18:29.620\n feels like it could be conducive to generalizability.\n\n2:18:29.620 --> 2:18:31.060\n I think you make a great point.\n\n2:18:31.060 --> 2:18:33.580\n The interactivity is a very good setting\n\n2:18:33.580 --> 2:18:36.060\n to force a system to show adaptation,\n\n2:18:36.060 --> 2:18:39.300\n to show generalization.\n\n2:18:39.300 --> 2:18:42.620\n That said, at the same time, it's\n\n2:18:42.620 --> 2:18:44.860\n not something very scalable, because you\n\n2:18:44.860 --> 2:18:46.100\n rely on human judges.\n\n2:18:46.100 --> 2:18:48.700\n It's not something reliable, because the human judges may\n\n2:18:48.700 --> 2:18:49.420\n not, may not.\n\n2:18:49.420 --> 2:18:50.940\n So you don't like human judges.\n\n2:18:50.940 --> 2:18:51.860\n Basically, yes.\n\n2:18:51.860 --> 2:18:52.540\n And I think so.\n\n2:18:52.540 --> 2:18:56.140\n I love the idea of interactivity.\n\n2:18:56.140 --> 2:18:59.620\n I initially wanted an ARC test that\n\n2:18:59.620 --> 2:19:02.820\n had some amount of interactivity where your score on a task\n\n2:19:02.820 --> 2:19:05.380\n would not be 1 or 0, if you can solve it or not,\n\n2:19:05.380 --> 2:19:11.580\n but would be the number of attempts\n\n2:19:11.580 --> 2:19:14.740\n that you can make before you hit the right solution, which\n\n2:19:14.740 --> 2:19:16.900\n means that now you can start applying\n\n2:19:16.900 --> 2:19:19.860\n the scientific method as you solve ARC tasks,\n\n2:19:19.860 --> 2:19:23.780\n that you can start formulating hypotheses and probing\n\n2:19:23.780 --> 2:19:27.300\n the system to see whether the observation will\n\n2:19:27.300 --> 2:19:28.660\n match the hypothesis or not.\n\n2:19:28.660 --> 2:19:30.700\n It would be amazing if you could also,\n\n2:19:30.700 --> 2:19:35.500\n even higher level than that, measure the quality of your attempts,\n\n2:19:35.500 --> 2:19:36.780\n which, of course, is impossible.\n\n2:19:36.780 --> 2:19:38.540\n But again, that gets subjective.\n\n2:19:38.540 --> 2:19:41.620\n How good was your thinking?\n\n2:19:41.620 --> 2:19:43.900\n How efficient was?\n\n2:19:43.900 --> 2:19:48.380\n So one thing that's interesting about this notion of scoring you\n\n2:19:48.380 --> 2:19:50.500\n as how many attempts you need is that you\n\n2:19:50.500 --> 2:19:55.220\n can start producing tasks that are way more ambiguous, right?\n\n2:19:55.220 --> 2:19:56.500\n Right.\n\n2:19:56.500 --> 2:19:59.700\n Because with the different attempts,\n\n2:19:59.700 --> 2:20:03.300\n you can actually probe that ambiguity, right?\n\n2:20:03.300 --> 2:20:04.140\n Right.\n\n2:20:04.140 --> 2:20:08.220\n So that's, in a sense, which is how good can\n\n2:20:08.220 --> 2:20:15.700\n you adapt to the uncertainty and reduce the uncertainty?\n\n2:20:15.700 --> 2:20:18.260\n Yes, it's half fast.\n\n2:20:18.260 --> 2:20:21.180\n It's the efficiency with which you reduce uncertainty\n\n2:20:21.180 --> 2:20:22.940\n in program space, exactly.\n\n2:20:22.940 --> 2:20:24.940\n Very difficult to come up with that kind of test, though.\n\n2:20:24.940 --> 2:20:28.340\n Yeah, so I would love to be able to create something like this.\n\n2:20:28.340 --> 2:20:33.140\n In practice, it would be very, very difficult, but yes.\n\n2:20:33.140 --> 2:20:36.140\n I mean, what you're doing, what you've done with the ARC challenge\n\n2:20:36.140 --> 2:20:37.620\n is brilliant.\n\n2:20:37.620 --> 2:20:40.940\n I'm also not surprised that it's not more popular,\n\n2:20:40.940 --> 2:20:42.140\n but I think it's picking up.\n\n2:20:42.140 --> 2:20:42.860\n It does its niche.\n\n2:20:42.860 --> 2:20:44.100\n It does its niche, yeah.\n\n2:20:44.100 --> 2:20:44.900\n Yeah.\n\n2:20:44.900 --> 2:20:47.100\n What are your thoughts about another test?\n\n2:20:47.100 --> 2:20:48.940\n I talked with Marcus Hutter.\n\n2:20:48.940 --> 2:20:51.660\n He has the Hutter Prize for compression of human knowledge.\n\n2:20:51.660 --> 2:20:55.620\n And the idea is really sort of quantify and reduce\n\n2:20:55.620 --> 2:20:58.260\n the test of intelligence purely to just the ability\n\n2:20:58.260 --> 2:20:59.580\n to compress.\n\n2:20:59.580 --> 2:21:04.660\n What's your thoughts about this intelligence as compression?\n\n2:21:04.660 --> 2:21:07.980\n I mean, it's a very fun test because it's\n\n2:21:07.980 --> 2:21:12.220\n such a simple idea, like you're given Wikipedia,\n\n2:21:12.220 --> 2:21:15.500\n basic English Wikipedia, and you must compress it.\n\n2:21:15.500 --> 2:21:21.140\n And so it stems from the idea that cognition is compression,\n\n2:21:21.140 --> 2:21:24.020\n that the brain is basically a compression algorithm.\n\n2:21:24.020 --> 2:21:25.620\n This is a very old idea.\n\n2:21:25.620 --> 2:21:30.540\n It's a very, I think, striking and beautiful idea.\n\n2:21:30.540 --> 2:21:32.740\n I used to believe it.\n\n2:21:32.740 --> 2:21:36.140\n I eventually had to realize that it was very much\n\n2:21:36.140 --> 2:21:36.900\n a flawed idea.\n\n2:21:36.900 --> 2:21:41.420\n So I no longer believe that cognition is compression.\n\n2:21:41.420 --> 2:21:44.620\n But I can tell you what's the difference.\n\n2:21:44.620 --> 2:21:48.820\n So it's very easy to believe that cognition and compression\n\n2:21:48.820 --> 2:21:51.660\n are the same thing.\n\n2:21:51.660 --> 2:21:53.220\n So Jeff Hawkins, for instance, says\n\n2:21:53.220 --> 2:21:54.780\n that cognition is prediction.\n\n2:21:54.780 --> 2:21:57.740\n And of course, prediction is basically the same thing\n\n2:21:57.740 --> 2:21:58.700\n as compression.\n\n2:21:58.700 --> 2:22:03.580\n It's just including the temporal axis.\n\n2:22:03.580 --> 2:22:05.060\n And it's very easy to believe this\n\n2:22:05.060 --> 2:22:06.900\n because compression is something that we\n\n2:22:06.900 --> 2:22:09.020\n do all the time very naturally.\n\n2:22:09.020 --> 2:22:12.020\n We are constantly compressing information.\n\n2:22:12.020 --> 2:22:15.660\n We are constantly trying.\n\n2:22:15.660 --> 2:22:17.940\n We have this bias towards simplicity.\n\n2:22:17.940 --> 2:22:21.060\n We are constantly trying to organize things in our mind\n\n2:22:21.060 --> 2:22:24.460\n and around us to be more regular.\n\n2:22:24.460 --> 2:22:26.860\n So it's a beautiful idea.\n\n2:22:26.860 --> 2:22:28.620\n It's very easy to believe.\n\n2:22:28.620 --> 2:22:31.580\n There is a big difference between what\n\n2:22:31.580 --> 2:22:33.980\n we do with our brains and compression.\n\n2:22:33.980 --> 2:22:38.220\n So compression is actually kind of a tool\n\n2:22:38.220 --> 2:22:42.060\n in the human cognitive toolkit that is used in many ways.\n\n2:22:42.060 --> 2:22:44.540\n But it's just a tool.\n\n2:22:44.540 --> 2:22:45.940\n It is a tool for cognition.\n\n2:22:45.940 --> 2:22:47.620\n It is not cognition itself.\n\n2:22:47.620 --> 2:22:50.020\n And the big fundamental difference\n\n2:22:50.020 --> 2:22:55.340\n is that cognition is about being able to operate\n\n2:22:55.340 --> 2:23:00.740\n in future situations that include fundamental uncertainty\n\n2:23:00.740 --> 2:23:02.140\n and novelty.\n\n2:23:02.140 --> 2:23:06.860\n So for instance, consider a child at age 10.\n\n2:23:06.860 --> 2:23:10.100\n And so they have 10 years of life experience.\n\n2:23:10.100 --> 2:23:14.260\n They've gotten pain, pleasure, rewards, and punishment\n\n2:23:14.260 --> 2:23:16.500\n in a period of time.\n\n2:23:16.500 --> 2:23:21.980\n If you were to generate the shortest behavioral program\n\n2:23:21.980 --> 2:23:26.740\n that would have basically run that child over these 10 years\n\n2:23:26.740 --> 2:23:32.220\n in an optimal way, the shortest optimal behavioral program\n\n2:23:32.220 --> 2:23:34.820\n given the experience of that child so far,\n\n2:23:34.820 --> 2:23:37.540\n well, that program, that compressed program,\n\n2:23:37.540 --> 2:23:39.940\n this is what you would get if the mind of the child\n\n2:23:39.940 --> 2:23:42.740\n was a compression algorithm essentially,\n\n2:23:42.740 --> 2:23:48.100\n would be utterly unable, inappropriate,\n\n2:23:48.100 --> 2:23:54.380\n to process the next 70 years in the life of that child.\n\n2:23:54.380 --> 2:23:59.020\n So in the models we build of the world,\n\n2:23:59.020 --> 2:24:03.220\n we are not trying to make them actually optimally compressed.\n\n2:24:03.220 --> 2:24:06.660\n We are using compression as a tool\n\n2:24:06.660 --> 2:24:10.060\n to promote simplicity and efficiency in our models.\n\n2:24:10.060 --> 2:24:12.060\n But they are not perfectly compressed\n\n2:24:12.060 --> 2:24:15.300\n because they need to include things\n\n2:24:15.300 --> 2:24:18.540\n that are seemingly useless today, that have seemingly\n\n2:24:18.540 --> 2:24:20.140\n been useless so far.\n\n2:24:20.140 --> 2:24:24.140\n But that may turn out to be useful in the future\n\n2:24:24.140 --> 2:24:25.900\n because you just don't know the future.\n\n2:24:25.900 --> 2:24:28.740\n And that's the fundamental principle\n\n2:24:28.740 --> 2:24:31.260\n that cognition, that intelligence arises from\n\n2:24:31.260 --> 2:24:33.780\n is that you need to be able to run\n\n2:24:33.780 --> 2:24:36.660\n appropriate behavioral programs except you have absolutely\n\n2:24:36.660 --> 2:24:40.940\n no idea what sort of context, environment, situation\n\n2:24:40.940 --> 2:24:42.260\n they are going to be running in.\n\n2:24:42.260 --> 2:24:45.020\n And you have to deal with that uncertainty,\n\n2:24:45.020 --> 2:24:46.580\n with that future anomaly.\n\n2:24:46.580 --> 2:24:52.500\n So an analogy that you can make is with investing,\n\n2:24:52.500 --> 2:24:54.460\n for instance.\n\n2:24:54.460 --> 2:24:59.540\n If I look at the past 20 years of stock market data,\n\n2:24:59.540 --> 2:25:01.860\n and I use a compression algorithm\n\n2:25:01.860 --> 2:25:04.420\n to figure out the best trading strategy,\n\n2:25:04.420 --> 2:25:06.660\n it's going to be you buy Apple stock, then\n\n2:25:06.660 --> 2:25:10.420\n maybe the past few years you buy Tesla stock or something.\n\n2:25:10.420 --> 2:25:13.300\n But is that strategy still going to be\n\n2:25:13.300 --> 2:25:14.660\n true for the next 20 years?\n\n2:25:14.660 --> 2:25:17.980\n Well, actually, probably not, which\n\n2:25:17.980 --> 2:25:21.060\n is why if you're a smart investor,\n\n2:25:21.060 --> 2:25:26.340\n you're not just going to be following the strategy that\n\n2:25:26.340 --> 2:25:28.980\n corresponds to compression of the past.\n\n2:25:28.980 --> 2:25:31.660\n You're going to be following, you're\n\n2:25:31.660 --> 2:25:34.860\n going to have a balanced portfolio, right?\n\n2:25:34.860 --> 2:25:38.180\n Because you just don't know what's going to happen.\n\n2:25:38.180 --> 2:25:40.460\n I mean, I guess in that same sense,\n\n2:25:40.460 --> 2:25:42.540\n the compression is analogous to what\n\n2:25:42.540 --> 2:25:45.900\n you talked about, which is local or robust generalization\n\n2:25:45.900 --> 2:25:47.820\n versus extreme generalization.\n\n2:25:47.820 --> 2:25:52.420\n It's much closer to that side of being able to generalize\n\n2:25:52.420 --> 2:25:53.420\n in the local sense.\n\n2:25:53.420 --> 2:25:59.980\n That's why as humans, when we are children, in our education,\n\n2:25:59.980 --> 2:26:04.180\n so a lot of it is driven by play, driven by curiosity.\n\n2:26:04.180 --> 2:26:07.900\n We are not efficiently compressing things.\n\n2:26:07.900 --> 2:26:09.620\n We're actually exploring.\n\n2:26:09.620 --> 2:26:16.620\n We are retaining all kinds of things\n\n2:26:16.620 --> 2:26:19.660\n from our environment that seem to be completely useless.\n\n2:26:19.660 --> 2:26:24.380\n Because they might turn out to be eventually useful, right?\n\n2:26:24.380 --> 2:26:26.940\n And that's what cognition is really about.\n\n2:26:26.940 --> 2:26:29.300\n And what makes it antagonistic to compression\n\n2:26:29.300 --> 2:26:33.980\n is that it is about hedging for future uncertainty.\n\n2:26:33.980 --> 2:26:35.860\n And that's antagonistic to compression.\n\n2:26:35.860 --> 2:26:36.580\n Yes.\n\n2:26:36.580 --> 2:26:38.500\n Officially hedging.\n\n2:26:38.500 --> 2:26:41.660\n Cognition leverages compression as a tool\n\n2:26:41.660 --> 2:26:47.420\n to promote efficiency and simplicity in our models.\n\n2:26:47.420 --> 2:26:52.260\n It's like Einstein said, make it simpler, but not,\n\n2:26:52.260 --> 2:26:54.940\n however that quote goes, but not too simple.\n\n2:26:54.940 --> 2:26:57.700\n So compression simplifies things,\n\n2:26:57.700 --> 2:27:00.100\n but you don't want to make it too simple.\n\n2:27:00.100 --> 2:27:00.740\n Yes.\n\n2:27:00.740 --> 2:27:03.100\n So a good model of the world is going\n\n2:27:03.100 --> 2:27:06.100\n to include all kinds of things that are completely useless,\n\n2:27:06.100 --> 2:27:08.500\n actually, just in case.\n\n2:27:08.500 --> 2:27:10.020\n Because you need diversity in the same way\n\n2:27:10.020 --> 2:27:11.140\n that in your portfolio.\n\n2:27:11.140 --> 2:27:13.340\n You need all kinds of stocks that may not\n\n2:27:13.340 --> 2:27:15.580\n have performed well so far, but you need diversity.\n\n2:27:15.580 --> 2:27:16.980\n And the reason you need diversity\n\n2:27:16.980 --> 2:27:19.660\n is because fundamentally you don't know what you're doing.\n\n2:27:19.660 --> 2:27:22.020\n And the same is true of the human mind,\n\n2:27:22.020 --> 2:27:26.860\n is that it needs to behave appropriately in the future.\n\n2:27:26.860 --> 2:27:29.860\n And it has no idea what the future is going to be like.\n\n2:27:29.860 --> 2:27:31.460\n But it's not going to be like the past.\n\n2:27:31.460 --> 2:27:33.620\n So compressing the past is not appropriate,\n\n2:27:33.620 --> 2:27:40.500\n because the past is not, it's not predictive of the future.\n\n2:27:40.500 --> 2:27:44.740\n Yeah, history repeats itself, but not perfectly.\n\n2:27:44.740 --> 2:27:48.980\n I don't think I asked you last time the most inappropriately\n\n2:27:48.980 --> 2:27:51.180\n absurd question.\n\n2:27:51.180 --> 2:27:54.420\n We've talked a lot about intelligence,\n\n2:27:54.420 --> 2:28:00.860\n but the bigger question from intelligence is of meaning.\n\n2:28:00.860 --> 2:28:02.980\n Intelligence systems are kind of goal oriented.\n\n2:28:02.980 --> 2:28:05.380\n They're always optimizing for a goal.\n\n2:28:05.380 --> 2:28:07.620\n If you look at the Hutter Prize, actually,\n\n2:28:07.620 --> 2:28:10.860\n I mean, there's always a clean formulation of a goal.\n\n2:28:10.860 --> 2:28:14.220\n But the natural question for us humans,\n\n2:28:14.220 --> 2:28:16.020\n since we don't know our objective function,\n\n2:28:16.020 --> 2:28:18.460\n is what is the meaning of it all?\n\n2:28:18.460 --> 2:28:22.980\n So the absurd question is, what, Francois,\n\n2:28:22.980 --> 2:28:25.660\n do you think is the meaning of life?\n\n2:28:25.660 --> 2:28:26.820\n What's the meaning of life?\n\n2:28:26.820 --> 2:28:28.180\n Yeah, that's a big question.\n\n2:28:28.180 --> 2:28:33.220\n And I think I can give you my answer, at least one\n\n2:28:33.220 --> 2:28:34.540\n of my answers.\n\n2:28:34.540 --> 2:28:42.220\n And so one thing that's very important in understanding who\n\n2:28:42.220 --> 2:28:48.380\n we are is that everything that makes up ourselves,\n\n2:28:48.380 --> 2:28:53.740\n that makes up who we are, even your most personal thoughts,\n\n2:28:53.740 --> 2:28:55.700\n is not actually your own.\n\n2:28:55.700 --> 2:29:00.060\n Even your most personal thoughts are expressed in words\n\n2:29:00.060 --> 2:29:04.940\n that you did not invent and are built on concepts and images\n\n2:29:04.940 --> 2:29:06.900\n that you did not invent.\n\n2:29:06.900 --> 2:29:10.940\n We are very much cultural beings.\n\n2:29:10.940 --> 2:29:12.860\n We are made of culture.\n\n2:29:12.860 --> 2:29:16.660\n What makes us different from animals, for instance?\n\n2:29:16.660 --> 2:29:22.860\n So everything about ourselves is an echo of the past.\n\n2:29:22.860 --> 2:29:29.900\n Is an echo of the past, an echo of people who lived before us.\n\n2:29:29.900 --> 2:29:31.420\n That's who we are.\n\n2:29:31.420 --> 2:29:35.300\n And in the same way, if we manage\n\n2:29:35.300 --> 2:29:41.780\n to contribute something to the collective edifice of culture,\n\n2:29:41.780 --> 2:29:44.580\n a new idea, maybe a beautiful piece of music,\n\n2:29:44.580 --> 2:29:51.260\n a work of art, a grand theory, a new world, maybe,\n\n2:29:51.260 --> 2:29:54.380\n that something is going to become\n\n2:29:54.380 --> 2:30:00.300\n a part of the minds of future humans, essentially, forever.\n\n2:30:00.300 --> 2:30:03.980\n So everything we do creates ripples\n\n2:30:03.980 --> 2:30:06.020\n that propagate into the future.\n\n2:30:06.020 --> 2:30:11.900\n And in a way, this is our path to immortality,\n\n2:30:11.900 --> 2:30:17.580\n is that as we contribute things to culture,\n\n2:30:17.580 --> 2:30:21.420\n culture in turn becomes future humans.\n\n2:30:21.420 --> 2:30:27.660\n And we keep influencing people thousands of years from now.\n\n2:30:27.660 --> 2:30:30.740\n So our actions today create ripples.\n\n2:30:30.740 --> 2:30:35.140\n And these ripples, I think, basically\n\n2:30:35.140 --> 2:30:37.620\n sum up the meaning of life.\n\n2:30:37.620 --> 2:30:42.540\n In the same way that we are the sum\n\n2:30:42.540 --> 2:30:45.500\n of the interactions between many different ripples that\n\n2:30:45.500 --> 2:30:48.100\n came from our past, we are ourselves\n\n2:30:48.100 --> 2:30:50.700\n creating ripples that will propagate into the future.\n\n2:30:50.700 --> 2:30:53.460\n And that's why we should be, this\n\n2:30:53.460 --> 2:30:56.060\n seems like perhaps an eighth thing to say,\n\n2:30:56.060 --> 2:31:02.060\n but we should be kind to others during our time on Earth\n\n2:31:02.060 --> 2:31:05.660\n because every act of kindness creates ripples.\n\n2:31:05.660 --> 2:31:09.380\n And in reverse, every act of violence also creates ripples.\n\n2:31:09.380 --> 2:31:13.260\n And you want to carefully choose which kind of ripples\n\n2:31:13.260 --> 2:31:16.460\n you want to create, and you want to propagate into the future.\n\n2:31:16.460 --> 2:31:19.020\n And in your case, first of all, beautifully put,\n\n2:31:19.020 --> 2:31:21.380\n but in your case, creating ripples\n\n2:31:21.380 --> 2:31:27.780\n into the future human and future AGI systems.\n\n2:31:27.780 --> 2:31:28.500\n Yes.\n\n2:31:28.500 --> 2:31:29.500\n It's fascinating.\n\n2:31:29.500 --> 2:31:30.420\n Our successors.\n\n2:31:30.420 --> 2:31:34.500\n I don't think there's a better way to end it,\n\n2:31:34.500 --> 2:31:37.180\n Francois, as always, for a second time.\n\n2:31:37.180 --> 2:31:39.340\n And I'm sure many times in the future,\n\n2:31:39.340 --> 2:31:40.820\n it's been a huge honor.\n\n2:31:40.820 --> 2:31:43.380\n You're one of the most brilliant people\n\n2:31:43.380 --> 2:31:47.500\n in the machine learning, computer science world.\n\n2:31:47.500 --> 2:31:48.700\n Again, it's a huge honor.\n\n2:31:48.700 --> 2:31:49.460\n Thanks for talking to me.\n\n2:31:49.460 --> 2:31:50.540\n It's been a pleasure.\n\n2:31:50.540 --> 2:31:51.980\n Thanks a lot for having me.\n\n2:31:51.980 --> 2:31:53.900\n We appreciate it.\n\n2:31:53.900 --> 2:31:56.220\n Thanks for listening to this conversation with Francois\n\n2:31:56.220 --> 2:32:00.340\n Chollet, and thank you to our sponsors, Babbel, Masterclass,\n\n2:32:00.340 --> 2:32:01.660\n and Cash App.\n\n2:32:01.660 --> 2:32:03.900\n Click the sponsor links in the description\n\n2:32:03.900 --> 2:32:06.820\n to get a discount and to support this podcast.\n\n2:32:06.820 --> 2:32:09.060\n If you enjoy this thing, subscribe on YouTube,\n\n2:32:09.060 --> 2:32:11.340\n review it with five stars on Apple Podcast,\n\n2:32:11.340 --> 2:32:14.060\n follow on Spotify, support on Patreon,\n\n2:32:14.060 --> 2:32:17.780\n or connect with me on Twitter at Lex Friedman.\n\n2:32:17.780 --> 2:32:19.420\n And now let me leave you with some words\n\n2:32:19.420 --> 2:32:24.380\n from Ren\u00e9 Descartes in 1668, an excerpt of which Francois\n\n2:32:24.380 --> 2:32:27.780\n includes and is on the measure of intelligence paper.\n\n2:32:27.780 --> 2:32:30.300\n If there were machines which bore a resemblance\n\n2:32:30.300 --> 2:32:34.420\n to our bodies and imitated our actions as closely as possible\n\n2:32:34.420 --> 2:32:36.980\n for all practical purposes, we should still\n\n2:32:36.980 --> 2:32:40.020\n have two very certain means of recognizing\n\n2:32:40.020 --> 2:32:42.220\n that they were not real men.\n\n2:32:42.220 --> 2:32:45.300\n The first is that they could never use words or put together\n\n2:32:45.300 --> 2:32:49.820\n signs, as we do in order to declare our thoughts to others.\n\n2:32:49.820 --> 2:32:53.420\n For we can certainly conceive of a machine so constructed\n\n2:32:53.420 --> 2:32:55.540\n that it utters words and even utters\n\n2:32:55.540 --> 2:32:57.940\n words that correspond to bodily actions causing\n\n2:32:57.940 --> 2:32:59.580\n a change in its organs.\n\n2:32:59.580 --> 2:33:03.380\n But it is not conceivable that such a machine should produce\n\n2:33:03.380 --> 2:33:05.420\n different arrangements of words so as\n\n2:33:05.420 --> 2:33:08.620\n to give an appropriately meaningful answer to whatever\n\n2:33:08.620 --> 2:33:12.780\n is said in its presence as the dullest of men can do.\n\n2:33:12.780 --> 2:33:15.460\n Here, Descartes is anticipating the Turing test,\n\n2:33:15.460 --> 2:33:18.780\n and the argument still continues to this day.\n\n2:33:18.780 --> 2:33:22.140\n Secondly, he continues, even though some machines might\n\n2:33:22.140 --> 2:33:26.580\n do some things as well as we do them, or perhaps even better,\n\n2:33:26.580 --> 2:33:29.100\n they would inevitably fail in others,\n\n2:33:29.100 --> 2:33:32.420\n which would reveal that they are acting not from understanding\n\n2:33:32.420 --> 2:33:36.780\n but only from the disposition of their organs.\n\n2:33:36.780 --> 2:33:39.860\n This is an incredible quote.\n\n2:33:39.860 --> 2:33:43.220\n Whereas reason is a universal instrument\n\n2:33:43.220 --> 2:33:46.580\n which can be used in all kinds of situations,\n\n2:33:46.580 --> 2:33:49.060\n these organs need some particular action.\n\n2:33:49.060 --> 2:33:51.220\n Hence, it is for all practical purposes\n\n2:33:51.220 --> 2:33:54.300\n impossible for a machine to have enough different organs\n\n2:33:54.300 --> 2:33:57.780\n to make it act in all the contingencies of life\n\n2:33:57.780 --> 2:34:01.340\n and the way in which our reason makes us act.\n\n2:34:01.340 --> 2:34:05.060\n That's the debate between mimicry and memorization\n\n2:34:05.060 --> 2:34:07.220\n versus understanding.\n\n2:34:07.220 --> 2:34:32.460\n So thank you for listening and hope to see you next time.\n\n"
}
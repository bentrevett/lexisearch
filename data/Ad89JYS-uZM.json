{
  "title": "Rohit Prasad: Amazon Alexa and Conversational AI | Lex Fridman Podcast #57",
  "id": "Ad89JYS-uZM",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:02.960\n The following is a conversation with Rohit Prasad.\n\n00:02.960 --> 00:06.360\n He's the vice president and head scientist of Amazon Alexa\n\n00:06.360 --> 00:08.880\n and one of its original creators.\n\n00:08.880 --> 00:12.120\n The Alexa team embodies some of the most challenging,\n\n00:12.120 --> 00:14.960\n incredible, impactful, and inspiring work\n\n00:14.960 --> 00:17.040\n that is done in AI today.\n\n00:17.040 --> 00:19.120\n The team has to both solve problems\n\n00:19.120 --> 00:21.720\n at the cutting edge of natural language processing\n\n00:21.720 --> 00:25.320\n and provide a trustworthy, secure, and enjoyable experience\n\n00:25.320 --> 00:27.440\n to millions of people.\n\n00:27.440 --> 00:29.400\n This is where state of the art methods\n\n00:29.400 --> 00:31.840\n in computer science meet the challenges\n\n00:31.840 --> 00:33.720\n of real world engineering.\n\n00:33.720 --> 00:37.280\n In many ways, Alexa and the other voice assistants\n\n00:37.280 --> 00:39.520\n are the voices of artificial intelligence\n\n00:39.520 --> 00:43.160\n to millions of people and an introduction to AI\n\n00:43.160 --> 00:46.940\n for people who have only encountered it in science fiction.\n\n00:46.940 --> 00:49.960\n This is an important and exciting opportunity.\n\n00:49.960 --> 00:52.920\n So the work that Rohit and the Alexa team are doing\n\n00:52.920 --> 00:55.960\n is an inspiration to me and to many researchers\n\n00:55.960 --> 00:58.840\n and engineers in the AI community.\n\n00:58.840 --> 01:01.940\n This is the Artificial Intelligence Podcast.\n\n01:01.940 --> 01:04.400\n If you enjoy it, subscribe on YouTube,\n\n01:04.400 --> 01:07.720\n give it five stars on Apple Podcast, support it on Patreon,\n\n01:07.720 --> 01:09.820\n or simply connect with me on Twitter,\n\n01:09.820 --> 01:13.680\n at Lex Friedman, spelled F R I D M A N.\n\n01:13.680 --> 01:16.960\n If you leave a review on Apple Podcasts especially,\n\n01:16.960 --> 01:20.040\n but also cast box or comment on YouTube,\n\n01:20.040 --> 01:22.920\n consider mentioning topics, people, ideas, questions,\n\n01:22.920 --> 01:25.160\n quotes in science, tech, or philosophy\n\n01:25.160 --> 01:26.320\n that you find interesting,\n\n01:26.320 --> 01:28.800\n and I'll read them on this podcast.\n\n01:28.800 --> 01:31.640\n I won't call out names, but I love comments\n\n01:31.640 --> 01:33.240\n with kindness and thoughtfulness in them,\n\n01:33.240 --> 01:35.720\n so I thought I'd share them.\n\n01:35.720 --> 01:37.480\n Someone on YouTube highlighted a quote\n\n01:37.480 --> 01:40.280\n from the conversation with Ray Dalio,\n\n01:40.280 --> 01:41.960\n where he said that you have to appreciate\n\n01:41.960 --> 01:45.300\n all the different ways that people can be A players.\n\n01:45.300 --> 01:48.560\n This connected me to, on teams of engineers,\n\n01:48.560 --> 01:50.360\n it's easy to think that raw productivity\n\n01:50.360 --> 01:53.480\n is the measure of excellence, but there are others.\n\n01:53.480 --> 01:55.760\n I've worked with people who brought a smile to my face\n\n01:55.760 --> 01:57.920\n every time I got to work in the morning.\n\n01:57.920 --> 02:01.240\n Their contribution to the team is immeasurable.\n\n02:01.240 --> 02:03.040\n I recently started doing podcast ads\n\n02:03.040 --> 02:04.660\n at the end of the introduction.\n\n02:04.660 --> 02:07.640\n I'll do one or two minutes after introducing the episode,\n\n02:07.640 --> 02:09.160\n and never any ads in the middle\n\n02:09.160 --> 02:11.540\n that break the flow of the conversation.\n\n02:11.540 --> 02:13.000\n I hope that works for you.\n\n02:13.000 --> 02:15.680\n It doesn't hurt the listening experience.\n\n02:15.680 --> 02:17.840\n This show is presented by Cash App,\n\n02:17.840 --> 02:20.340\n the number one finance app in the App Store.\n\n02:20.340 --> 02:23.000\n I personally use Cash App to send money to friends,\n\n02:23.000 --> 02:24.720\n but you can also use it to buy, sell,\n\n02:24.720 --> 02:27.140\n and deposit Bitcoin in just seconds.\n\n02:27.140 --> 02:30.360\n Cash App also has a new investing feature.\n\n02:30.360 --> 02:33.640\n You can buy fractions of a stock, say $1 worth,\n\n02:33.640 --> 02:35.800\n no matter what the stock price is.\n\n02:35.800 --> 02:38.660\n Brokerage services are provided by Cash App Investing,\n\n02:38.660 --> 02:42.420\n a subsidiary of Square and member SIPC.\n\n02:42.420 --> 02:44.440\n I'm excited to be working with Cash App\n\n02:44.440 --> 02:47.560\n to support one of my favorite organizations called First,\n\n02:47.560 --> 02:50.920\n best known for their FIRST Robotics and Lego competitions.\n\n02:50.920 --> 02:54.360\n They educate and inspire hundreds of thousands of students\n\n02:54.360 --> 02:57.360\n in over 110 countries, and have a perfect rating\n\n02:57.360 --> 03:00.100\n on Charity Navigator, which means that donated money\n\n03:00.100 --> 03:03.480\n is used to maximum effectiveness.\n\n03:03.480 --> 03:06.380\n When you get Cash App from the App Store, Google Play,\n\n03:06.380 --> 03:10.260\n and use code LexPodcast, you'll get $10,\n\n03:10.260 --> 03:13.240\n and Cash App will also donate $10 to FIRST,\n\n03:13.240 --> 03:16.140\n which again, is an organization that I've personally seen\n\n03:16.140 --> 03:19.100\n inspire girls and boys to dream\n\n03:19.100 --> 03:20.740\n of engineering a better world.\n\n03:20.740 --> 03:24.240\n This podcast is also supported by ZipRecruiter.\n\n03:24.240 --> 03:26.880\n Hiring great people is hard, and to me,\n\n03:26.880 --> 03:28.960\n is one of the most important elements\n\n03:28.960 --> 03:31.400\n of a successful mission driven team.\n\n03:31.400 --> 03:33.280\n I've been fortunate to be a part of,\n\n03:33.280 --> 03:35.920\n and lead several great engineering teams.\n\n03:35.920 --> 03:38.840\n The hiring I've done in the past was mostly through tools\n\n03:38.840 --> 03:42.720\n we built ourselves, but reinventing the wheel was painful.\n\n03:42.720 --> 03:45.880\n ZipRecruiter is a tool that's already available for you.\n\n03:45.880 --> 03:49.400\n It seeks to make hiring simple, fast, and smart.\n\n03:49.400 --> 03:52.800\n For example, Codable cofounder, Gretchen Huebner,\n\n03:52.800 --> 03:55.160\n used ZipRecruiter to find a new game artist\n\n03:55.160 --> 03:57.320\n to join our education tech company.\n\n03:57.320 --> 03:59.440\n By using ZipRecruiter's screening questions\n\n03:59.440 --> 04:02.080\n to filter candidates, Gretchen found it easier\n\n04:02.080 --> 04:03.760\n to focus on the best candidates,\n\n04:03.760 --> 04:06.840\n and finally, hiring the perfect person for the role,\n\n04:06.840 --> 04:10.160\n in less than two weeks, from start to finish.\n\n04:10.160 --> 04:12.640\n ZipRecruiter, the smartest way to hire.\n\n04:13.600 --> 04:15.920\n See why ZipRecruiter is effective for businesses\n\n04:15.920 --> 04:17.920\n of all sizes by signing up,\n\n04:17.920 --> 04:22.920\n as I did, for free, at ziprecruiter.com slash lexpod.\n\n04:23.160 --> 04:27.160\n That's ziprecruiter.com slash lexpod.\n\n04:27.160 --> 04:32.160\n And now, here's my conversation with Rohit Prasad.\n\n04:33.000 --> 04:36.120\n In the movie Her, I'm not sure if you've ever seen it.\n\n04:36.120 --> 04:39.720\n Human falls in love with the voice of an AI system.\n\n04:39.720 --> 04:42.000\n Let's start at the highest philosophical level\n\n04:42.000 --> 04:45.080\n before we get to deep learning and some of the fun things.\n\n04:45.080 --> 04:48.200\n Do you think this, what the movie Her shows,\n\n04:48.200 --> 04:49.360\n is within our reach?\n\n04:51.160 --> 04:54.480\n I think not specifically about Her,\n\n04:54.480 --> 04:59.000\n but I think what we are seeing is a massive increase\n\n04:59.000 --> 05:02.240\n in adoption of AI assistance, or AI,\n\n05:02.240 --> 05:05.320\n in all parts of our social fabric.\n\n05:05.320 --> 05:08.880\n And I think it's, what I do believe,\n\n05:08.880 --> 05:11.680\n is that the utility these AIs provide,\n\n05:11.680 --> 05:14.680\n some of the functionalities that are shown\n\n05:14.680 --> 05:16.520\n are absolutely within reach.\n\n05:18.240 --> 05:19.600\n So some of the functionality\n\n05:19.600 --> 05:21.640\n in terms of the interactive elements,\n\n05:21.640 --> 05:24.680\n but in terms of the deep connection,\n\n05:24.680 --> 05:26.840\n that's purely voice based.\n\n05:26.840 --> 05:29.160\n Do you think such a close connection is possible\n\n05:29.160 --> 05:30.600\n with voice alone?\n\n05:30.600 --> 05:32.240\n It's been a while since I saw Her,\n\n05:32.240 --> 05:36.760\n but I would say in terms of interactions\n\n05:36.760 --> 05:40.240\n which are both human like and in these AI systems,\n\n05:40.240 --> 05:43.840\n you have to value what is also superhuman.\n\n05:44.800 --> 05:47.760\n We as humans can be in only one place.\n\n05:47.760 --> 05:51.240\n AI assistance can be in multiple places at the same time.\n\n05:51.240 --> 05:53.720\n One with you on your mobile device,\n\n05:53.720 --> 05:56.360\n one at your home, one at work.\n\n05:56.360 --> 05:59.160\n So you have to respect these superhuman capabilities too.\n\n06:00.280 --> 06:03.080\n Plus as humans, we have certain attributes\n\n06:03.080 --> 06:05.120\n we are very good at, very good at reasoning.\n\n06:05.120 --> 06:07.360\n AI assistance not yet there,\n\n06:07.360 --> 06:10.360\n but in the realm of AI assistance,\n\n06:10.360 --> 06:12.680\n what they're great at is computation, memory,\n\n06:12.680 --> 06:14.600\n it's infinite and pure.\n\n06:14.600 --> 06:16.440\n These are the attributes you have to start respecting.\n\n06:16.440 --> 06:18.360\n So I think the comparison with human like\n\n06:18.360 --> 06:21.480\n versus the other aspect, which is also superhuman,\n\n06:21.480 --> 06:22.920\n has to be taken into consideration.\n\n06:22.920 --> 06:25.440\n So I think we need to elevate the discussion\n\n06:25.440 --> 06:27.240\n to not just human like.\n\n06:27.240 --> 06:28.800\n So there's certainly elements,\n\n06:28.800 --> 06:32.680\n we just mentioned, Alexa is everywhere,\n\n06:32.680 --> 06:33.960\n computation speaking.\n\n06:33.960 --> 06:35.600\n So this is a much bigger infrastructure\n\n06:35.600 --> 06:38.440\n than just the thing that sits there in the room with you.\n\n06:38.440 --> 06:43.120\n But it certainly feels to us mere humans\n\n06:43.120 --> 06:47.320\n that there's just another little creature there\n\n06:47.320 --> 06:48.400\n when you're interacting with it.\n\n06:48.400 --> 06:49.880\n You're not interacting with the entirety\n\n06:49.880 --> 06:52.360\n of the infrastructure, you're interacting with the device.\n\n06:52.360 --> 06:56.560\n The feeling is, okay, sure, we anthropomorphize things,\n\n06:56.560 --> 06:58.640\n but that feeling is still there.\n\n06:58.640 --> 07:02.240\n So what do you think we as humans,\n\n07:02.240 --> 07:04.760\n the purity of the interaction with a smart device,\n\n07:04.760 --> 07:06.920\n interaction with a smart assistant,\n\n07:06.920 --> 07:10.200\n what do you think we look for in that interaction?\n\n07:10.200 --> 07:12.240\n I think in the certain interactions\n\n07:12.240 --> 07:15.920\n I think will be very much where it does feel like a human\n\n07:15.920 --> 07:18.160\n because it has a persona of its own.\n\n07:19.080 --> 07:20.680\n And in certain ones it wouldn't be.\n\n07:20.680 --> 07:23.080\n So I think a simple example to think of it\n\n07:23.080 --> 07:25.200\n is if you're walking through the house\n\n07:25.200 --> 07:27.960\n and you just wanna turn on your lights on and off\n\n07:27.960 --> 07:29.840\n and you're issuing a command,\n\n07:29.840 --> 07:32.040\n that's not very much like a human like interaction\n\n07:32.040 --> 07:33.840\n and that's where the AI shouldn't come back\n\n07:33.840 --> 07:35.240\n and have a conversation with you,\n\n07:35.240 --> 07:38.480\n just it should simply complete that command.\n\n07:38.480 --> 07:40.200\n So those, I think the blend of,\n\n07:40.200 --> 07:43.360\n we have to think about this is not human, human alone.\n\n07:43.360 --> 07:45.080\n It is a human machine interaction\n\n07:45.080 --> 07:48.160\n and certain aspects of humans are needed\n\n07:48.160 --> 07:49.920\n and certain aspects are in situations\n\n07:49.920 --> 07:51.640\n demand it to be like a machine.\n\n07:51.640 --> 07:55.040\n So I told you, it's gonna be philosophical in parts.\n\n07:55.040 --> 07:57.480\n What's the difference between human and machine\n\n07:57.480 --> 07:58.640\n in that interaction?\n\n07:58.640 --> 08:00.760\n When we interact to humans,\n\n08:00.760 --> 08:04.000\n especially those are friends and loved ones\n\n08:04.000 --> 08:09.000\n versus you and a machine that you also are close with.\n\n08:10.400 --> 08:12.640\n I think the, you have to think about the roles\n\n08:12.640 --> 08:13.800\n the AI plays, right?\n\n08:13.800 --> 08:16.320\n So, and it differs from different customer to customer,\n\n08:16.320 --> 08:18.040\n different situation to situation,\n\n08:18.840 --> 08:21.560\n especially I can speak from Alexa's perspective.\n\n08:21.560 --> 08:25.000\n It is a companion, a friend at times,\n\n08:25.000 --> 08:27.520\n an assistant, an advisor down the line.\n\n08:27.520 --> 08:31.240\n So I think most AIs will have this kind of attributes\n\n08:31.240 --> 08:33.040\n and it will be very situational in nature.\n\n08:33.040 --> 08:34.680\n So where is the boundary?\n\n08:34.680 --> 08:37.080\n I think the boundary depends on exact context\n\n08:37.080 --> 08:39.320\n in which you're interacting with the AI.\n\n08:39.320 --> 08:41.240\n So the depth and the richness\n\n08:41.240 --> 08:42.920\n of natural language conversation\n\n08:42.920 --> 08:47.920\n is been by Alan Turing been used to try to define\n\n08:48.160 --> 08:50.480\n what it means to be intelligent.\n\n08:50.480 --> 08:52.280\n There's a lot of criticism of that kind of test,\n\n08:52.280 --> 08:55.840\n but what do you think is a good test of intelligence\n\n08:55.840 --> 08:58.360\n in your view, in the context of the Turing test\n\n08:58.360 --> 09:03.240\n and Alexa or the Alexa prize, this whole realm,\n\n09:03.240 --> 09:07.160\n do you think about this human intelligence,\n\n09:07.160 --> 09:08.000\n what it means to define it,\n\n09:08.000 --> 09:10.080\n what it means to reach that level?\n\n09:10.080 --> 09:12.480\n I do think the ability to converse\n\n09:12.480 --> 09:15.160\n is a sign of an ultimate intelligence.\n\n09:15.160 --> 09:17.440\n I think that there's no question about it.\n\n09:18.320 --> 09:20.560\n So if you think about all aspects of humans,\n\n09:20.560 --> 09:22.840\n there are sensors we have,\n\n09:22.840 --> 09:26.400\n and those are basically a data collection mechanism.\n\n09:26.400 --> 09:27.240\n And based on that,\n\n09:27.240 --> 09:30.560\n we make some decisions with our sensory brains, right?\n\n09:30.560 --> 09:32.720\n And from that perspective,\n\n09:32.720 --> 09:35.240\n I think there are elements we have to talk about\n\n09:35.240 --> 09:37.080\n how we sense the world\n\n09:37.080 --> 09:40.360\n and then how we act based on what we sense.\n\n09:40.360 --> 09:43.640\n Those elements clearly machines have,\n\n09:43.640 --> 09:46.800\n but then there's the other aspects of computation\n\n09:46.800 --> 09:48.360\n that is way better.\n\n09:48.360 --> 09:50.040\n I also mentioned about memory again,\n\n09:50.040 --> 09:51.880\n in terms of being near infinite,\n\n09:51.880 --> 09:54.200\n depending on the storage capacity you have,\n\n09:54.200 --> 09:58.200\n and the retrieval can be extremely fast and pure\n\n09:58.200 --> 09:59.600\n in terms of like, there's no ambiguity\n\n09:59.600 --> 10:02.080\n of who did I see when, right?\n\n10:02.080 --> 10:04.440\n I mean, machines can remember that quite well.\n\n10:04.440 --> 10:06.840\n So again, on a philosophical level,\n\n10:06.840 --> 10:10.840\n I do subscribe to the fact that to be able to converse\n\n10:10.840 --> 10:13.400\n and as part of that, to be able to reason\n\n10:13.400 --> 10:15.240\n based on the world knowledge you've acquired\n\n10:15.240 --> 10:18.320\n and the sensory knowledge that is there\n\n10:18.320 --> 10:22.080\n is definitely very much the essence of intelligence.\n\n10:23.160 --> 10:26.960\n But intelligence can go beyond human level intelligence\n\n10:26.960 --> 10:29.800\n based on what machines are getting capable of.\n\n10:29.800 --> 10:33.440\n So what do you think maybe stepping outside of Alexa\n\n10:33.440 --> 10:35.760\n broadly as an AI field,\n\n10:35.760 --> 10:38.720\n what do you think is a good test of intelligence?\n\n10:38.720 --> 10:41.200\n Put it another way outside of Alexa,\n\n10:41.200 --> 10:43.040\n because so much of Alexa is a product,\n\n10:43.040 --> 10:44.920\n is an experience for the customer.\n\n10:44.920 --> 10:46.400\n On the research side,\n\n10:46.400 --> 10:49.240\n what would impress the heck out of you if you saw,\n\n10:49.240 --> 10:50.800\n you know, what is the test where you said,\n\n10:50.800 --> 10:55.800\n wow, this thing is now starting to encroach\n\n10:57.000 --> 10:59.040\n into the realm of what we loosely think\n\n10:59.040 --> 11:00.360\n of as human intelligence?\n\n11:00.360 --> 11:02.400\n So, well, we think of it as AGI\n\n11:02.400 --> 11:04.320\n and human intelligence altogether, right?\n\n11:04.320 --> 11:08.000\n So in some sense, and I think we are quite far from that.\n\n11:08.000 --> 11:11.480\n I think an unbiased view I have\n\n11:11.480 --> 11:16.480\n is that the Alexa's intelligence capability is a great test.\n\n11:17.760 --> 11:20.600\n I think of it as there are many other true points\n\n11:20.600 --> 11:25.320\n like self driving cars, game playing like go or chess.\n\n11:26.320 --> 11:28.680\n Let's take those two for as an example,\n\n11:28.680 --> 11:31.760\n clearly requires a lot of data driven learning\n\n11:31.760 --> 11:35.080\n and intelligence, but it's not as hard a problem\n\n11:35.080 --> 11:39.760\n as conversing with, as an AI is with humans\n\n11:39.760 --> 11:42.320\n to accomplish certain tasks or open domain chat,\n\n11:42.320 --> 11:44.000\n as you mentioned, Alexa prize.\n\n11:44.880 --> 11:47.760\n In those settings, the key differences\n\n11:47.760 --> 11:51.920\n that the end goal is not defined unlike game playing.\n\n11:51.920 --> 11:55.720\n You also do not know exactly what state you are in\n\n11:55.720 --> 11:58.960\n in a particular goal completion scenario.\n\n11:58.960 --> 12:00.760\n In certain sense, sometimes you can,\n\n12:00.760 --> 12:04.440\n if it's a simple goal, but if you're even certain examples\n\n12:04.440 --> 12:07.120\n like planning a weekend or you can imagine\n\n12:07.120 --> 12:09.920\n how many things change along the way,\n\n12:09.920 --> 12:11.920\n you look for whether you may change your mind\n\n12:11.920 --> 12:14.840\n and you change the destination,\n\n12:14.840 --> 12:17.040\n or you want to catch a particular event\n\n12:17.040 --> 12:19.400\n and then you decide, no, I want this other event\n\n12:19.400 --> 12:20.520\n I want to go to.\n\n12:20.520 --> 12:24.000\n So these dimensions of how many different steps\n\n12:24.000 --> 12:26.360\n are possible when you're conversing as a human\n\n12:26.360 --> 12:29.120\n with a machine makes it an extremely daunting problem.\n\n12:29.120 --> 12:32.360\n And I think it is the ultimate test for intelligence.\n\n12:32.360 --> 12:37.360\n And don't you think that natural language is enough to prove\n\n12:37.440 --> 12:40.360\n that conversation, just pure conversation?\n\n12:40.360 --> 12:42.280\n From a scientific standpoint,\n\n12:42.280 --> 12:45.000\n natural language is a great test,\n\n12:45.000 --> 12:47.800\n but I would go beyond, I don't want to limit it\n\n12:47.800 --> 12:51.040\n to as natural language as simply understanding an intent\n\n12:51.040 --> 12:52.760\n or parsing for entities and so forth.\n\n12:52.760 --> 12:54.880\n We are really talking about dialogue.\n\n12:54.880 --> 12:55.720\n Dialogue, yeah.\n\n12:55.720 --> 12:58.480\n So I would say human machine dialogue\n\n12:58.480 --> 13:02.960\n is definitely one of the best tests of intelligence.\n\n13:02.960 --> 13:06.680\n So can you briefly speak to the Alexa Prize\n\n13:06.680 --> 13:08.640\n for people who are not familiar with it,\n\n13:08.640 --> 13:12.640\n and also just maybe where things stand\n\n13:12.640 --> 13:15.440\n and what have you learned and what's surprising?\n\n13:15.440 --> 13:16.920\n What have you seen that's surprising\n\n13:16.920 --> 13:18.440\n from this incredible competition?\n\n13:18.440 --> 13:20.960\n Absolutely, it's a very exciting competition.\n\n13:20.960 --> 13:24.040\n Alexa Prize is essentially a grand challenge\n\n13:24.040 --> 13:26.880\n in conversational artificial intelligence,\n\n13:26.880 --> 13:29.440\n where we threw the gauntlet to the universities\n\n13:29.440 --> 13:31.960\n who do active research in the field,\n\n13:31.960 --> 13:35.360\n to say, can you build what we call a social bot\n\n13:35.360 --> 13:37.320\n that can converse with you coherently\n\n13:37.320 --> 13:39.800\n and engagingly for 20 minutes?\n\n13:39.800 --> 13:42.480\n That is an extremely hard challenge,\n\n13:42.480 --> 13:46.480\n talking to someone who you're meeting for the first time,\n\n13:46.480 --> 13:49.640\n or even if you've met them quite often,\n\n13:49.640 --> 13:53.560\n to speak at 20 minutes on any topic,\n\n13:53.560 --> 13:57.760\n an evolving nature of topics is super hard.\n\n13:57.760 --> 14:01.600\n We have completed two successful years of the competition.\n\n14:01.600 --> 14:03.400\n The first was won with the University of Washington,\n\n14:03.400 --> 14:05.560\n second, the University of California.\n\n14:05.560 --> 14:06.880\n We are in our third instance.\n\n14:06.880 --> 14:09.640\n We have an extremely strong team of 10 cohorts,\n\n14:09.640 --> 14:13.960\n and the third instance of the Alexa Prize is underway now.\n\n14:14.840 --> 14:17.480\n And we are seeing a constant evolution.\n\n14:17.480 --> 14:18.920\n First year was definitely a learning.\n\n14:18.920 --> 14:21.200\n It was a lot of things to be put together.\n\n14:21.200 --> 14:23.640\n We had to build a lot of infrastructure\n\n14:23.640 --> 14:25.960\n to enable these universities\n\n14:25.960 --> 14:28.280\n to be able to build magical experiences\n\n14:28.280 --> 14:31.560\n and do high quality research.\n\n14:31.560 --> 14:33.880\n Just a few quick questions, sorry for the interruption.\n\n14:33.880 --> 14:37.240\n What does failure look like in the 20 minute session?\n\n14:37.240 --> 14:38.720\n So what does it mean to fail,\n\n14:38.720 --> 14:39.960\n not to reach the 20 minute mark?\n\n14:39.960 --> 14:41.200\n Oh, awesome question.\n\n14:41.200 --> 14:43.360\n So there are one, first of all,\n\n14:43.360 --> 14:45.360\n I forgot to mention one more detail.\n\n14:45.360 --> 14:46.560\n It's not just 20 minutes,\n\n14:46.560 --> 14:49.320\n but the quality of the conversation too that matters.\n\n14:49.320 --> 14:51.480\n And the beauty of this competition\n\n14:51.480 --> 14:53.800\n before I answer that question on what failure means\n\n14:53.800 --> 14:56.600\n is first that you actually converse\n\n14:56.600 --> 14:59.000\n with millions and millions of customers\n\n14:59.000 --> 15:00.840\n as the social bots.\n\n15:00.840 --> 15:05.000\n So during the judging phases, there are multiple phases,\n\n15:05.000 --> 15:06.320\n before we get to the finals,\n\n15:06.320 --> 15:08.640\n which is a very controlled judging in a situation\n\n15:08.640 --> 15:10.400\n where we bring in judges\n\n15:10.400 --> 15:14.400\n and we have interactors who interact with these social bots,\n\n15:14.400 --> 15:15.920\n that is a much more controlled setting.\n\n15:15.920 --> 15:18.960\n But till the point we get to the finals,\n\n15:18.960 --> 15:22.680\n all the judging is essentially by the customers of Alexa.\n\n15:22.680 --> 15:26.160\n And there you basically rate on a simple question,\n\n15:26.160 --> 15:28.400\n how good your experience was.\n\n15:28.400 --> 15:29.840\n So that's where we are not testing\n\n15:29.840 --> 15:32.760\n for a 20 minute boundary being crossed,\n\n15:32.760 --> 15:36.600\n because you do want it to be very much like a clear cut,\n\n15:36.600 --> 15:40.040\n winner, be chosen, and it's an absolute bar.\n\n15:40.040 --> 15:42.760\n So did you really break that 20 minute barrier\n\n15:42.760 --> 15:45.880\n is why we have to test it in a more controlled setting\n\n15:45.880 --> 15:48.640\n with actors, essentially interactors.\n\n15:48.640 --> 15:50.800\n And see how the conversation goes.\n\n15:50.800 --> 15:54.160\n So this is why it's a subtle difference\n\n15:54.160 --> 15:57.000\n between how it's being tested in the field\n\n15:57.000 --> 16:00.480\n with real customers versus in the lab to award the prize.\n\n16:00.480 --> 16:03.520\n So on the latter one, what it means is that\n\n16:03.520 --> 16:08.000\n essentially there are three judges\n\n16:08.000 --> 16:09.520\n and two of them have to say\n\n16:09.520 --> 16:11.720\n this conversation has stalled, essentially.\n\n16:13.080 --> 16:13.920\n Got it.\n\n16:13.920 --> 16:15.720\n And the judges are human experts.\n\n16:15.720 --> 16:16.920\n Judges are human experts.\n\n16:16.920 --> 16:17.760\n Okay, great.\n\n16:17.760 --> 16:19.120\n So this is in the third year.\n\n16:19.120 --> 16:20.920\n So what's been the evolution?\n\n16:20.920 --> 16:24.640\n How far, so the DARPA challenge in the first year,\n\n16:24.640 --> 16:26.560\n the autonomous vehicles, nobody finished.\n\n16:26.560 --> 16:29.680\n In the second year, a few more finished in the desert.\n\n16:30.640 --> 16:33.280\n So how far along in this,\n\n16:33.280 --> 16:36.360\n I would say much harder challenge are we?\n\n16:36.360 --> 16:37.720\n This challenge has come a long way\n\n16:37.720 --> 16:40.480\n to the extent that we're definitely not close\n\n16:40.480 --> 16:42.760\n to the 20 minute barrier being with coherence\n\n16:42.760 --> 16:44.760\n and engaging conversation.\n\n16:44.760 --> 16:46.880\n I think we are still five to 10 years away\n\n16:46.880 --> 16:49.480\n in that horizon to complete that.\n\n16:49.480 --> 16:51.360\n But the progress is immense.\n\n16:51.360 --> 16:54.080\n Like what you're finding is the accuracy\n\n16:54.080 --> 16:57.360\n and what kind of responses these social bots generate\n\n16:57.360 --> 16:59.520\n is getting better and better.\n\n16:59.520 --> 17:03.360\n What's even amazing to see that now there's humor coming in.\n\n17:03.360 --> 17:04.880\n The bots are quite...\n\n17:04.880 --> 17:05.720\n Awesome.\n\n17:05.720 --> 17:07.360\n You know, you're talking about\n\n17:07.360 --> 17:09.440\n ultimate science of intelligence.\n\n17:09.440 --> 17:11.840\n I think humor is a very high bar\n\n17:11.840 --> 17:14.880\n in terms of what it takes to create humor.\n\n17:14.880 --> 17:16.520\n And I don't mean just being goofy.\n\n17:16.520 --> 17:19.480\n I really mean good sense of humor\n\n17:19.480 --> 17:21.600\n is also a sign of intelligence in my mind\n\n17:21.600 --> 17:23.120\n and something very hard to do.\n\n17:23.120 --> 17:25.040\n So these social bots are now exploring\n\n17:25.040 --> 17:28.560\n not only what we think of natural language abilities,\n\n17:28.560 --> 17:30.400\n but also personality attributes\n\n17:30.400 --> 17:34.120\n and aspects of when to inject an appropriate joke,\n\n17:34.120 --> 17:38.440\n when you don't know the domain,\n\n17:38.440 --> 17:41.400\n how you come back with something more intelligible\n\n17:41.400 --> 17:43.200\n so that you can continue the conversation.\n\n17:43.200 --> 17:45.200\n If you and I are talking about AI\n\n17:45.200 --> 17:47.480\n and we are domain experts, we can speak to it.\n\n17:47.480 --> 17:50.480\n But if you suddenly switch a topic to that I don't know of,\n\n17:50.480 --> 17:52.160\n how do I change the conversation?\n\n17:52.160 --> 17:55.240\n So you're starting to notice these elements as well.\n\n17:55.240 --> 17:58.560\n And that's coming from partly by the nature\n\n17:58.560 --> 18:00.120\n of the 20 minute challenge\n\n18:00.120 --> 18:02.520\n that people are getting quite clever\n\n18:02.520 --> 18:05.600\n on how to really converse\n\n18:05.600 --> 18:08.600\n and essentially mask some of the understanding defects\n\n18:08.600 --> 18:09.840\n if they exist.\n\n18:09.840 --> 18:12.680\n So some of this, this is not Alexa, the product.\n\n18:12.680 --> 18:16.240\n This is somewhat for fun, for research,\n\n18:16.240 --> 18:17.800\n for innovation and so on.\n\n18:17.800 --> 18:20.280\n I have a question sort of in this modern era,\n\n18:20.280 --> 18:24.280\n there's a lot of, if you look at Twitter and Facebook\n\n18:24.280 --> 18:27.160\n and so on, there's discourse, public discourse going on\n\n18:27.160 --> 18:28.800\n and some things that are a little bit too edgy,\n\n18:28.800 --> 18:30.640\n people get blocked and so on.\n\n18:30.640 --> 18:32.280\n I'm just out of curiosity,\n\n18:32.280 --> 18:35.960\n are people in this context pushing the limits?\n\n18:35.960 --> 18:37.760\n Is anyone using the F word?\n\n18:37.760 --> 18:41.440\n Is anyone sort of pushing back\n\n18:41.440 --> 18:45.960\n sort of arguing, I guess I should say,\n\n18:45.960 --> 18:48.280\n as part of the dialogue to really draw people in?\n\n18:48.280 --> 18:50.320\n First of all, let me just back up a bit\n\n18:50.320 --> 18:52.120\n in terms of why we are doing this, right?\n\n18:52.120 --> 18:54.280\n So you said it's fun.\n\n18:54.280 --> 18:59.280\n I think fun is more part of the engaging part for customers.\n\n18:59.920 --> 19:02.480\n It is one of the most used skills as well\n\n19:02.480 --> 19:04.360\n in our skill store.\n\n19:04.360 --> 19:07.200\n But up that apart, the real goal was essentially\n\n19:07.200 --> 19:10.400\n what was happening is with a lot of AI research\n\n19:10.400 --> 19:14.200\n moving to industry, we felt that academia has the risk\n\n19:14.200 --> 19:16.800\n of not being able to have the same resources\n\n19:16.800 --> 19:20.480\n at disposal that we have, which is lots of data,\n\n19:20.480 --> 19:24.640\n massive computing power, and a clear ways\n\n19:24.640 --> 19:28.520\n to test these AI advances with real customer benefits.\n\n19:28.520 --> 19:30.880\n So we brought all these three together in the Alexa price.\n\n19:30.880 --> 19:33.880\n That's why it's one of my favorite projects in Amazon.\n\n19:33.880 --> 19:37.800\n And with that, the secondary effect is yes,\n\n19:37.800 --> 19:40.920\n it has become engaging for our customers as well.\n\n19:40.920 --> 19:43.880\n We're not there in terms of where we want it to be, right?\n\n19:43.880 --> 19:45.040\n But it's a huge progress.\n\n19:45.040 --> 19:47.080\n But coming back to your question on\n\n19:47.080 --> 19:48.800\n how do the conversations evolve?\n\n19:48.800 --> 19:51.880\n Yes, there is some natural attributes of what you said\n\n19:51.880 --> 19:54.160\n in terms of argument and some amount of swearing.\n\n19:54.160 --> 19:57.160\n The way we take care of that is that there is\n\n19:57.160 --> 20:00.400\n a sensitive filter we have built that sees keywords.\n\n20:00.400 --> 20:03.480\n It's more than keywords, a little more in terms of,\n\n20:03.480 --> 20:04.880\n of course, there's keyword based too,\n\n20:04.880 --> 20:07.920\n but there's more in terms of these words can be\n\n20:07.920 --> 20:09.440\n very contextual, as you can see,\n\n20:09.440 --> 20:12.600\n and also the topic can be something\n\n20:12.600 --> 20:15.400\n that you don't want a conversation to happen\n\n20:15.400 --> 20:17.320\n because this is a communal device as well.\n\n20:17.320 --> 20:19.240\n A lot of people use these devices.\n\n20:19.240 --> 20:22.600\n So we have put a lot of guardrails for the conversation\n\n20:22.600 --> 20:25.920\n to be more useful for advancing AI\n\n20:25.920 --> 20:30.920\n and not so much of these other issues you attributed\n\n20:31.080 --> 20:32.880\n what's happening in the AI field as well.\n\n20:32.880 --> 20:35.280\n Right, so this is actually a serious opportunity.\n\n20:35.280 --> 20:36.880\n I didn't use the right word, fun.\n\n20:36.880 --> 20:39.960\n I think it's an open opportunity to do\n\n20:39.960 --> 20:42.000\n some of the best innovation\n\n20:42.000 --> 20:44.760\n in conversational agents in the world.\n\n20:44.760 --> 20:45.920\n Absolutely.\n\n20:45.920 --> 20:49.000\n Why just universities?\n\n20:49.000 --> 20:49.880\n Why just universities?\n\n20:49.880 --> 20:51.560\n Because as I said, I really felt\n\n20:51.560 --> 20:52.400\n Young minds.\n\n20:52.400 --> 20:55.080\n Young minds, it's also to,\n\n20:55.080 --> 20:57.920\n if you think about the other aspect\n\n20:57.920 --> 21:01.400\n of where the whole industry is moving with AI,\n\n21:01.400 --> 21:04.880\n there's a dearth of talent given the demands.\n\n21:04.880 --> 21:09.880\n So you do want universities to have a clear place\n\n21:09.880 --> 21:11.440\n where they can invent and research\n\n21:11.440 --> 21:13.920\n and not fall behind that they can't motivate students.\n\n21:13.920 --> 21:18.920\n Imagine all grad students left to industry like us\n\n21:19.600 --> 21:22.880\n or faculty members, which has happened too.\n\n21:22.880 --> 21:25.200\n So this is a way that if you're so passionate\n\n21:25.200 --> 21:28.640\n about the field where you feel industry and academia\n\n21:28.640 --> 21:31.360\n need to work well, this is a great example\n\n21:31.360 --> 21:34.440\n and a great way for universities to participate.\n\n21:35.360 --> 21:37.280\n So what do you think it takes to build a system\n\n21:37.280 --> 21:39.600\n that wins the Alexa Prize?\n\n21:39.600 --> 21:44.600\n I think you have to start focusing on aspects of reasoning\n\n21:46.200 --> 21:50.760\n that it is, there are still more lookups\n\n21:50.760 --> 21:54.160\n of what intents customers asking for\n\n21:54.160 --> 21:58.920\n and responding to those rather than really reasoning\n\n21:58.920 --> 22:02.480\n about the elements of the conversation.\n\n22:02.480 --> 22:06.240\n For instance, if you're playing,\n\n22:06.240 --> 22:08.120\n if the conversation is about games\n\n22:08.120 --> 22:11.240\n and it's about a recent sports event,\n\n22:11.240 --> 22:13.320\n there's so much context involved\n\n22:13.320 --> 22:15.800\n and you have to understand the entities\n\n22:15.800 --> 22:17.320\n that are being mentioned\n\n22:17.320 --> 22:19.640\n so that the conversation is coherent\n\n22:19.640 --> 22:23.200\n rather than you suddenly just switch to knowing some fact\n\n22:23.200 --> 22:26.280\n about a sports entity and you're just relaying that\n\n22:26.280 --> 22:28.680\n rather than understanding the true context of the game.\n\n22:28.680 --> 22:32.280\n Like if you just said, I learned this fun fact\n\n22:32.280 --> 22:36.000\n about Tom Brady rather than really say\n\n22:36.000 --> 22:39.280\n how he played the game the previous night,\n\n22:39.280 --> 22:42.800\n then the conversation is not really that intelligent.\n\n22:42.800 --> 22:46.200\n So you have to go to more reasoning elements\n\n22:46.200 --> 22:49.120\n of understanding the context of the dialogue\n\n22:49.120 --> 22:51.240\n and giving more appropriate responses,\n\n22:51.240 --> 22:53.680\n which tells you that we are still quite far\n\n22:53.680 --> 22:57.400\n because a lot of times it's more facts being looked up\n\n22:57.400 --> 22:59.920\n and something that's close enough as an answer,\n\n22:59.920 --> 23:02.080\n but not really the answer.\n\n23:02.080 --> 23:05.040\n So that is where the research needs to go more\n\n23:05.040 --> 23:08.360\n and actual true understanding and reasoning.\n\n23:08.360 --> 23:10.440\n And that's why I feel it's a great way to do it\n\n23:10.440 --> 23:13.520\n because you have an engaged set of users\n\n23:13.520 --> 23:18.200\n working to help these AI advances happen in this case.\n\n23:18.200 --> 23:20.640\n You mentioned customers, they're quite a bit,\n\n23:20.640 --> 23:22.120\n and there's a skill.\n\n23:22.120 --> 23:26.520\n What is the experience for the user that's helping?\n\n23:26.520 --> 23:30.120\n So just to clarify, this isn't, as far as I understand,\n\n23:30.120 --> 23:32.560\n the Alexa, so this skill is a standalone\n\n23:32.560 --> 23:33.560\n for the Alexa Prize.\n\n23:33.560 --> 23:35.360\n I mean, it's focused on the Alexa Prize.\n\n23:35.360 --> 23:37.720\n It's not you ordering certain things on Amazon.\n\n23:37.720 --> 23:39.200\n Like, oh, we're checking the weather\n\n23:39.200 --> 23:40.720\n or playing Spotify, right?\n\n23:40.720 --> 23:42.520\n This is a separate skill.\n\n23:42.520 --> 23:45.600\n And so you're focused on helping that,\n\n23:45.600 --> 23:48.520\n I don't know, how do people, how do customers think of it?\n\n23:48.520 --> 23:49.800\n Are they having fun?\n\n23:49.800 --> 23:52.040\n Are they helping teach the system?\n\n23:52.040 --> 23:53.040\n What's the experience like?\n\n23:53.040 --> 23:54.640\n I think it's both actually.\n\n23:54.640 --> 23:57.800\n And let me tell you how you invoke this skill.\n\n23:57.800 --> 24:00.200\n So all you have to say, Alexa, let's chat.\n\n24:00.200 --> 24:03.320\n And then the first time you say, Alexa, let's chat,\n\n24:03.320 --> 24:04.720\n it comes back with a clear message\n\n24:04.720 --> 24:06.240\n that you're interacting with one of those\n\n24:06.240 --> 24:08.000\n university social bots.\n\n24:08.000 --> 24:09.320\n And there's a clear,\n\n24:09.320 --> 24:11.800\n so you know exactly how you interact, right?\n\n24:11.800 --> 24:14.080\n And that is why it's very transparent.\n\n24:14.080 --> 24:16.240\n You are being asked to help, right?\n\n24:16.240 --> 24:18.800\n And we have a lot of mechanisms\n\n24:18.800 --> 24:23.680\n where as we are in the first phase of feedback phase,\n\n24:23.680 --> 24:26.720\n then you send a lot of emails to our customers\n\n24:26.720 --> 24:31.720\n and then they know that the team needs a lot of interactions\n\n24:31.760 --> 24:33.920\n to improve the accuracy of the system.\n\n24:33.920 --> 24:35.880\n So we know we have a lot of customers\n\n24:35.880 --> 24:38.920\n who really want to help these university bots\n\n24:38.920 --> 24:40.400\n and they're conversing with that.\n\n24:40.400 --> 24:42.680\n And some are just having fun with just saying,\n\n24:42.680 --> 24:44.000\n Alexa, let's chat.\n\n24:44.000 --> 24:47.320\n And also some adversarial behavior to see whether,\n\n24:47.320 --> 24:50.240\n how much do you understand as a social bot?\n\n24:50.240 --> 24:51.480\n So I think we have a good,\n\n24:51.480 --> 24:53.920\n healthy mix of all three situations.\n\n24:53.920 --> 24:55.280\n So what is the,\n\n24:55.280 --> 24:58.040\n if we talk about solving the Alexa challenge,\n\n24:58.040 --> 24:59.080\n the Alexa prize,\n\n25:00.720 --> 25:05.480\n what's the data set of really engaging,\n\n25:05.480 --> 25:07.520\n pleasant conversations look like?\n\n25:07.520 --> 25:08.360\n Because if we think of this\n\n25:08.360 --> 25:10.600\n as a supervised learning problem,\n\n25:10.600 --> 25:12.200\n I don't know if it has to be,\n\n25:12.200 --> 25:15.400\n but if it does, maybe you can comment on that.\n\n25:15.400 --> 25:17.480\n Do you think there needs to be a data set\n\n25:17.480 --> 25:21.880\n of what it means to be an engaging, successful,\n\n25:21.880 --> 25:22.720\n fulfilling conversation?\n\n25:22.720 --> 25:24.760\n I think that's part of the research question here.\n\n25:24.760 --> 25:29.200\n This was, I think, we at least got the first part right,\n\n25:29.200 --> 25:33.360\n which is have a way for universities to build\n\n25:33.360 --> 25:35.680\n and test in a real world setting.\n\n25:35.680 --> 25:38.640\n Now you're asking in terms of the next phase of questions,\n\n25:38.640 --> 25:41.120\n which we are still, we're also asking, by the way,\n\n25:41.120 --> 25:45.400\n what does success look like from a optimization function?\n\n25:45.400 --> 25:47.200\n That's what you're asking in terms of,\n\n25:47.200 --> 25:49.560\n we as researchers are used to having a great corpus\n\n25:49.560 --> 25:53.480\n of annotated data and then making,\n\n25:53.480 --> 25:57.600\n then sort of tune our algorithms on those, right?\n\n25:57.600 --> 26:00.640\n And fortunately and unfortunately,\n\n26:00.640 --> 26:02.920\n in this world of Alexa prize,\n\n26:02.920 --> 26:05.400\n that is not the way we are going after it.\n\n26:05.400 --> 26:07.720\n So you have to focus more on learning\n\n26:07.720 --> 26:10.920\n based on life feedback.\n\n26:10.920 --> 26:12.960\n That is another element that's unique,\n\n26:12.960 --> 26:15.080\n where just not to,\n\n26:15.080 --> 26:17.280\n I started with giving you how you ingress\n\n26:17.280 --> 26:21.520\n and experience this capability as a customer.\n\n26:21.520 --> 26:23.600\n What happens when you're done?\n\n26:23.600 --> 26:27.560\n So they ask you a simple question on a scale of one to five,\n\n26:27.560 --> 26:31.880\n how likely are you to interact with this social bot again?\n\n26:31.880 --> 26:33.840\n That is a good feedback\n\n26:33.840 --> 26:37.440\n and customers can also leave more open ended feedback.\n\n26:37.440 --> 26:40.840\n And I think partly that to me\n\n26:40.840 --> 26:42.640\n is one part of the question you're asking,\n\n26:42.640 --> 26:44.600\n which I'm saying is a mental model shift\n\n26:44.600 --> 26:47.120\n that as researchers also,\n\n26:47.120 --> 26:48.560\n you have to change your mindset\n\n26:48.560 --> 26:52.680\n that this is not a DARPA evaluation or NSF funded study\n\n26:52.680 --> 26:54.960\n and you have a nice corpus.\n\n26:54.960 --> 26:56.960\n This is where it's real world.\n\n26:56.960 --> 26:58.720\n You have real data.\n\n26:58.720 --> 27:01.560\n The scale is amazing and that's a beautiful thing.\n\n27:01.560 --> 27:02.960\n And then the customer,\n\n27:02.960 --> 27:06.160\n the user can quit the conversation at any time.\n\n27:06.160 --> 27:07.200\n Exactly, the user can,\n\n27:07.200 --> 27:11.720\n that is also a signal for how good you were at that point.\n\n27:11.720 --> 27:15.000\n So, and then on a scale one to five, one to three,\n\n27:15.000 --> 27:16.360\n do they say how likely are you\n\n27:16.360 --> 27:18.040\n or is it just a binary?\n\n27:18.040 --> 27:18.880\n One to five.\n\n27:18.880 --> 27:20.040\n One to five.\n\n27:20.040 --> 27:22.680\n Wow, okay, that's such a beautifully constructed challenge.\n\n27:22.680 --> 27:23.520\n Okay.\n\n27:24.720 --> 27:29.720\n You said the only way to make a smart assistant really smart\n\n27:30.040 --> 27:32.480\n is to give it eyes and let it explore the world.\n\n27:34.560 --> 27:36.840\n I'm not sure it might've been taken out of context,\n\n27:36.840 --> 27:38.240\n but can you comment on that?\n\n27:38.240 --> 27:40.080\n Can you elaborate on that idea?\n\n27:40.080 --> 27:43.120\n Is that I personally also find that idea super exciting\n\n27:43.120 --> 27:46.240\n from a social robotics, personal robotics perspective.\n\n27:46.240 --> 27:48.840\n Yeah, a lot of things do get taken out of context.\n\n27:48.840 --> 27:50.600\n This particular one was just\n\n27:50.600 --> 27:53.000\n as philosophical discussion we were having\n\n27:53.000 --> 27:55.520\n on terms of what does intelligence look like?\n\n27:55.520 --> 27:59.200\n And the context was in terms of learning,\n\n27:59.200 --> 28:03.040\n I think just we said we as humans are empowered\n\n28:03.040 --> 28:05.480\n with many different sensory abilities.\n\n28:05.480 --> 28:09.560\n I do believe that eyes are an important aspect of it\n\n28:09.560 --> 28:13.680\n in terms of if you think about how we as humans learn,\n\n28:14.640 --> 28:18.320\n it is quite complex and it's also not unimodal\n\n28:18.320 --> 28:22.040\n that you are fed a ton of text or audio\n\n28:22.040 --> 28:23.360\n and you just learn that way.\n\n28:23.360 --> 28:27.240\n No, you learn by experience, you learn by seeing,\n\n28:27.240 --> 28:30.320\n you're taught by humans\n\n28:30.320 --> 28:33.240\n and we are very efficient in how we learn.\n\n28:33.240 --> 28:35.320\n Machines on the contrary are very inefficient\n\n28:35.320 --> 28:38.480\n on how they learn, especially these AIs.\n\n28:38.480 --> 28:42.640\n I think the next wave of research is going to be\n\n28:42.640 --> 28:46.000\n with less data, not just less human,\n\n28:46.000 --> 28:48.240\n not just with less labeled data,\n\n28:48.240 --> 28:51.080\n but also with a lot of weak supervision\n\n28:51.080 --> 28:55.160\n and where you can increase the learning rate.\n\n28:55.160 --> 28:56.120\n I don't mean less data\n\n28:56.120 --> 28:58.640\n in terms of not having a lot of data to learn from\n\n28:58.640 --> 29:00.360\n that we are generating so much data,\n\n29:00.360 --> 29:02.640\n but it is more about from a aspect\n\n29:02.640 --> 29:04.880\n of how fast can you learn?\n\n29:04.880 --> 29:07.880\n So improving the quality of the data,\n\n29:07.880 --> 29:09.920\n the quality of data and the learning process.\n\n29:09.920 --> 29:11.440\n I think more on the learning process.\n\n29:11.440 --> 29:13.560\n I think we have to, we as humans learn\n\n29:13.560 --> 29:15.720\n with a lot of noisy data, right?\n\n29:15.720 --> 29:18.480\n And I think that's the part\n\n29:18.480 --> 29:21.440\n that I don't think should change.\n\n29:21.440 --> 29:23.880\n What should change is how we learn, right?\n\n29:23.880 --> 29:26.080\n So if you look at, you mentioned supervised learning,\n\n29:26.080 --> 29:27.960\n we have making transformative shifts\n\n29:27.960 --> 29:31.160\n from moving to more unsupervised, more weak supervision.\n\n29:31.160 --> 29:34.840\n Those are the key aspects of how to learn.\n\n29:34.840 --> 29:37.760\n And I think in that setting, I hope you agree with me\n\n29:37.760 --> 29:41.680\n that having other senses is very crucial\n\n29:41.680 --> 29:43.480\n in terms of how you learn.\n\n29:43.480 --> 29:44.640\n So absolutely.\n\n29:44.640 --> 29:46.680\n And from a machine learning perspective,\n\n29:46.680 --> 29:49.680\n which I hope we get a chance to talk to a few aspects\n\n29:49.680 --> 29:51.080\n that are fascinating there,\n\n29:51.080 --> 29:55.600\n but to stick on the point of sort of a body,\n\n29:55.600 --> 29:56.440\n an embodiment.\n\n29:56.440 --> 29:57.520\n So Alexa has a body.\n\n29:57.520 --> 30:01.600\n It has a very minimalistic, beautiful interface\n\n30:01.600 --> 30:02.840\n where there's a ring and so on.\n\n30:02.840 --> 30:04.480\n I mean, I'm not sure of all the flavors\n\n30:04.480 --> 30:07.560\n of the devices that Alexa lives on,\n\n30:07.560 --> 30:11.000\n but there's a minimalistic basic interface.\n\n30:13.280 --> 30:15.640\n And nevertheless, we humans, so I have a Roomba,\n\n30:15.640 --> 30:18.240\n I have all kinds of robots all over everywhere.\n\n30:18.240 --> 30:23.240\n So what do you think the Alexa of the future looks like\n\n30:24.680 --> 30:29.240\n if it begins to shift what his body looks like?\n\n30:29.240 --> 30:30.640\n Maybe beyond the Alexa,\n\n30:30.640 --> 30:33.720\n what do you think are the different devices in the home\n\n30:33.720 --> 30:36.880\n as they start to embody their intelligence more and more?\n\n30:36.880 --> 30:38.080\n What do you think that looks like?\n\n30:38.080 --> 30:41.200\n Philosophically, a future, what do you think that looks like?\n\n30:41.200 --> 30:43.600\n I think let's look at what's happening today.\n\n30:43.600 --> 30:46.840\n You mentioned, I think our devices as an Amazon devices,\n\n30:46.840 --> 30:49.840\n but I also wanted to point out Alexa is already integrated\n\n30:49.840 --> 30:51.360\n a lot of third party devices,\n\n30:51.360 --> 30:54.840\n which also come in lots of forms and shapes,\n\n30:54.840 --> 30:58.960\n some in robots, some in microwaves,\n\n30:58.960 --> 31:02.600\n some in appliances that you use in everyday life.\n\n31:02.600 --> 31:07.600\n So I think it's not just the shape Alexa takes\n\n31:07.720 --> 31:09.200\n in terms of form factors,\n\n31:09.200 --> 31:13.000\n but it's also where all it's available.\n\n31:13.000 --> 31:14.240\n And it's getting in cars,\n\n31:14.240 --> 31:16.760\n it's getting in different appliances in homes,\n\n31:16.760 --> 31:18.720\n even toothbrushes, right?\n\n31:18.720 --> 31:20.760\n So I think you have to think about it\n\n31:20.760 --> 31:25.440\n as not a physical assistant.\n\n31:25.440 --> 31:28.480\n It will be in some embodiment, as you said,\n\n31:28.480 --> 31:31.120\n we already have these nice devices,\n\n31:31.120 --> 31:33.800\n but I think it's also important to think of it,\n\n31:33.800 --> 31:35.640\n it is a virtual assistant.\n\n31:35.640 --> 31:38.520\n It is superhuman in the sense that it is in multiple places\n\n31:38.520 --> 31:40.280\n at the same time.\n\n31:40.280 --> 31:45.200\n So I think the actual embodiment in some sense,\n\n31:45.200 --> 31:46.680\n to me doesn't matter.\n\n31:47.600 --> 31:52.600\n I think you have to think of it as not as human like\n\n31:52.800 --> 31:56.080\n and more of what its capabilities are\n\n31:56.080 --> 31:58.840\n that derive a lot of benefit for customers\n\n31:58.840 --> 32:00.680\n and how there are different ways to delight it\n\n32:00.680 --> 32:03.960\n and delight customers and different experiences.\n\n32:03.960 --> 32:08.960\n And I think I'm a big fan of it not being just human like,\n\n32:09.240 --> 32:11.120\n it should be human like in certain situations.\n\n32:11.120 --> 32:13.360\n Alexa price social bot in terms of conversation\n\n32:13.360 --> 32:14.920\n is a great way to look at it,\n\n32:14.920 --> 32:18.800\n but there are other scenarios where human like,\n\n32:18.800 --> 32:22.080\n I think is underselling the abilities of this AI.\n\n32:22.080 --> 32:26.120\n So if I could trivialize what we're talking about.\n\n32:26.120 --> 32:29.400\n So if you look at the way Steve Jobs thought\n\n32:29.400 --> 32:33.440\n about the interaction with the device that Apple produced,\n\n32:33.440 --> 32:36.760\n there was a extreme focus on controlling the experience\n\n32:36.760 --> 32:40.200\n by making sure there's only this Apple produced devices.\n\n32:40.200 --> 32:45.200\n You see the voice of Alexa being taking all kinds of forms\n\n32:45.600 --> 32:47.080\n depending on what the customers want.\n\n32:47.080 --> 32:49.920\n And that means it could be anywhere\n\n32:49.920 --> 32:53.760\n from the microwave to a vacuum cleaner to the home\n\n32:53.760 --> 32:56.960\n and so on the voice is the essential element\n\n32:56.960 --> 32:57.800\n of the interaction.\n\n32:57.800 --> 33:01.160\n I think voice is an essence, it's not all,\n\n33:01.160 --> 33:02.240\n but it's a key aspect.\n\n33:02.240 --> 33:05.720\n I think to your question in terms of,\n\n33:05.720 --> 33:08.280\n you should be able to recognize Alexa\n\n33:08.280 --> 33:10.000\n and that's a huge problem.\n\n33:10.000 --> 33:12.080\n I think in terms of a huge scientific problem,\n\n33:12.080 --> 33:13.800\n I should say like, what are the traits?\n\n33:13.800 --> 33:16.200\n What makes it look like Alexa,\n\n33:16.200 --> 33:17.600\n especially in different settings\n\n33:17.600 --> 33:20.440\n and especially if it's primarily voice, what it is,\n\n33:20.440 --> 33:22.320\n but Alexa is not just voice either, right?\n\n33:22.320 --> 33:25.080\n I mean, we have devices with a screen.\n\n33:25.080 --> 33:28.520\n Now you're seeing just other behaviors of Alexa.\n\n33:28.520 --> 33:31.400\n So I think we're in very early stages of what that means\n\n33:31.400 --> 33:34.960\n and this will be an important topic for the following years.\n\n33:34.960 --> 33:38.240\n But I do believe that being able to recognize\n\n33:38.240 --> 33:40.520\n and tell when it's Alexa versus it's not\n\n33:40.520 --> 33:43.400\n is going to be important from an Alexa perspective.\n\n33:43.400 --> 33:46.040\n I'm not speaking for the entire AI community,\n\n33:46.040 --> 33:51.040\n but I think attribution and as we go into more\n\n33:51.040 --> 33:54.400\n of understanding who did what,\n\n33:54.400 --> 33:58.000\n that identity of the AI is crucial in the coming world.\n\n33:58.000 --> 34:00.320\n I think from the broad AI community perspective,\n\n34:00.320 --> 34:02.120\n that's also a fascinating problem.\n\n34:02.120 --> 34:05.480\n So basically if I close my eyes and listen to the voice,\n\n34:05.480 --> 34:08.040\n what would it take for me to recognize that this is Alexa?\n\n34:08.040 --> 34:08.880\n Exactly.\n\n34:08.880 --> 34:10.600\n Or at least the Alexa that I've come to know\n\n34:10.600 --> 34:13.000\n from my personal experience in my home\n\n34:13.000 --> 34:14.400\n through my interactions that come through.\n\n34:14.400 --> 34:16.920\n Yeah, and the Alexa here in the US is very different\n\n34:16.920 --> 34:19.440\n than Alexa in UK and the Alexa in India,\n\n34:19.440 --> 34:21.640\n even though they are all speaking English\n\n34:21.640 --> 34:23.280\n or the Australian version.\n\n34:23.280 --> 34:26.680\n So again, so now think about when you go\n\n34:26.680 --> 34:28.400\n into a different culture, a different community,\n\n34:28.400 --> 34:31.800\n but you travel there, what do you recognize Alexa?\n\n34:31.800 --> 34:34.160\n I think these are super hard questions actually.\n\n34:34.160 --> 34:36.840\n So there's a team that works on personality.\n\n34:36.840 --> 34:39.360\n So if we talk about those different flavors\n\n34:39.360 --> 34:41.040\n of what it means culturally speaking,\n\n34:41.040 --> 34:44.680\n India, UK, US, what does it mean to add?\n\n34:44.680 --> 34:46.440\n So the problem that we just stated,\n\n34:46.440 --> 34:51.080\n it's just fascinating, how do we make it purely recognizable\n\n34:51.080 --> 34:55.000\n that it's Alexa, assuming that the qualities\n\n34:55.000 --> 34:56.720\n of the voice are not sufficient?\n\n34:58.040 --> 35:01.000\n It's also the content of what is being said.\n\n35:01.000 --> 35:02.160\n How do we do that?\n\n35:02.160 --> 35:04.320\n How does the personality come into play?\n\n35:04.320 --> 35:06.800\n What's that research gonna look like?\n\n35:06.800 --> 35:08.120\n I mean, it's such a fascinating subject.\n\n35:08.120 --> 35:11.080\n We have some very fascinating folks\n\n35:11.080 --> 35:13.560\n who from both the UX background and human factors\n\n35:13.560 --> 35:16.360\n are looking at these aspects and these exact questions.\n\n35:16.360 --> 35:21.360\n But I'll definitely say it's not just how it sounds,\n\n35:21.600 --> 35:25.320\n the choice of words, the tone, not just, I mean,\n\n35:25.320 --> 35:28.040\n the voice identity of it, but the tone matters,\n\n35:28.040 --> 35:30.720\n the speed matters, how you speak,\n\n35:30.720 --> 35:34.880\n how you enunciate words, what choice of words\n\n35:34.880 --> 35:37.320\n are you using, how terse are you,\n\n35:37.320 --> 35:40.720\n or how lengthy in your explanations you are.\n\n35:40.720 --> 35:42.920\n All of these are factors.\n\n35:42.920 --> 35:45.440\n And you also, you mentioned something crucial\n\n35:45.440 --> 35:49.160\n that you may have personalized it, Alexa,\n\n35:49.160 --> 35:51.400\n to some extent in your homes\n\n35:51.400 --> 35:53.440\n or in the devices you are interacting with.\n\n35:53.440 --> 35:58.440\n So you, as your individual, how you prefer Alexa sounds\n\n35:59.240 --> 36:01.240\n can be different than how I prefer.\n\n36:01.240 --> 36:04.440\n And the amount of customizability you want to give\n\n36:04.440 --> 36:07.640\n is also a key debate we always have.\n\n36:07.640 --> 36:10.720\n But I do want to point out it's more than the voice actor\n\n36:10.720 --> 36:14.000\n that recorded and it sounds like that actor.\n\n36:14.000 --> 36:16.920\n It is more about the choices of words,\n\n36:16.920 --> 36:19.800\n the attributes of tonality, the volume\n\n36:19.800 --> 36:22.600\n in terms of how you raise your pitch and so forth.\n\n36:22.600 --> 36:23.880\n All of that matters.\n\n36:23.880 --> 36:25.440\n This is such a fascinating problem\n\n36:25.440 --> 36:27.600\n from a product perspective.\n\n36:27.600 --> 36:29.480\n I could see those debates just happening\n\n36:29.480 --> 36:32.440\n inside of the Alexa team of how much personalization\n\n36:32.440 --> 36:34.440\n do you do for the specific customer?\n\n36:34.440 --> 36:37.360\n Because you're taking a risk if you over personalize.\n\n36:38.240 --> 36:42.080\n Because you don't, if you create a personality\n\n36:42.080 --> 36:46.040\n for a million people, you can test that better.\n\n36:46.040 --> 36:48.640\n You can create a rich, fulfilling experience\n\n36:48.640 --> 36:50.040\n that will do well.\n\n36:50.040 --> 36:53.480\n But the more you personalize it, the less you can test it,\n\n36:53.480 --> 36:56.320\n the less you can know that it's a great experience.\n\n36:56.320 --> 36:59.720\n So how much personalization, what's the right balance?\n\n36:59.720 --> 37:01.600\n I think the right balance depends on the customer.\n\n37:01.600 --> 37:02.800\n Give them the control.\n\n37:02.800 --> 37:07.400\n So I'll say, I think the more control you give customers,\n\n37:07.400 --> 37:09.600\n the better it is for everyone.\n\n37:09.600 --> 37:13.880\n And I'll give you some key personalization features.\n\n37:13.880 --> 37:15.840\n I think we have a feature called Remember This,\n\n37:15.840 --> 37:19.440\n which is where you can tell Alexa to remember something.\n\n37:19.440 --> 37:23.080\n There you have an explicit sort of control\n\n37:23.080 --> 37:24.600\n in customer's hand because they have to say,\n\n37:24.600 --> 37:26.520\n Alexa, remember X, Y, Z.\n\n37:26.520 --> 37:28.000\n What kind of things would that be used for?\n\n37:28.000 --> 37:32.200\n So you can like you, I have stored my tire specs\n\n37:32.200 --> 37:34.800\n for my car because it's so hard to go and find\n\n37:34.800 --> 37:36.760\n and see what it is, right?\n\n37:36.760 --> 37:38.320\n When you're having some issues.\n\n37:38.320 --> 37:41.440\n I store my mileage plan numbers\n\n37:41.440 --> 37:43.120\n for all the frequent flyer ones\n\n37:43.120 --> 37:46.520\n where I'm sometimes just looking at it and it's not handy.\n\n37:46.520 --> 37:49.960\n So those are my own personal choices I've made\n\n37:49.960 --> 37:52.320\n for Alexa to remember something on my behalf, right?\n\n37:52.320 --> 37:56.000\n So again, I think the choice was be explicit\n\n37:56.000 --> 38:00.000\n about how you provide that to a customer as a control.\n\n38:00.000 --> 38:03.440\n So I think these are the aspects of what you do.\n\n38:03.440 --> 38:07.360\n Like think about where we can use speaker recognition\n\n38:07.360 --> 38:11.000\n capabilities that it's, if you taught Alexa\n\n38:11.000 --> 38:14.440\n that you are Lex and this person in your household\n\n38:14.440 --> 38:17.920\n is person two, then you can personalize the experiences.\n\n38:17.920 --> 38:22.840\n Again, these are very in the CX customer experience patterns\n\n38:22.840 --> 38:26.520\n are very clear about and transparent\n\n38:26.520 --> 38:29.200\n when a personalization action is happening.\n\n38:30.040 --> 38:32.240\n And then you have other ways like you go\n\n38:32.240 --> 38:34.640\n through explicit control right now through your app\n\n38:34.640 --> 38:36.920\n that your multiple service providers,\n\n38:36.920 --> 38:39.480\n let's say for music, which one is your preferred one.\n\n38:39.480 --> 38:42.000\n So when you say play sting, depend on your\n\n38:42.000 --> 38:44.880\n whether you have preferred Spotify or Amazon music\n\n38:44.880 --> 38:47.240\n or Apple music, that the decision is made\n\n38:47.240 --> 38:48.320\n where to play it from.\n\n38:49.480 --> 38:52.720\n So what's Alexa's backstory from her perspective?\n\n38:52.720 --> 38:57.720\n Is there, I remember just asking as probably a lot\n\n38:58.120 --> 39:00.600\n of us are just the basic questions about love\n\n39:00.600 --> 39:03.800\n and so on of Alexa, just to see what the answer would be.\n\n39:03.800 --> 39:08.800\n It feels like there's a little bit of a personality\n\n39:10.280 --> 39:12.840\n but not too much.\n\n39:12.840 --> 39:17.840\n Is Alexa have a metaphysical presence\n\n39:18.360 --> 39:21.880\n in this human universe we live in\n\n39:21.880 --> 39:23.720\n or is it something more ambiguous?\n\n39:23.720 --> 39:25.080\n Is there a past?\n\n39:25.080 --> 39:26.240\n Is there a birth?\n\n39:26.240 --> 39:28.920\n Is there a family kind of idea\n\n39:28.920 --> 39:31.120\n even for joking purposes and so on?\n\n39:31.120 --> 39:34.800\n I think, well, it does tell you if I think you,\n\n39:34.800 --> 39:36.320\n I should double check this but if you said\n\n39:36.320 --> 39:39.000\n when were you born, I think we do respond.\n\n39:39.000 --> 39:40.120\n I need to double check that\n\n39:40.120 --> 39:41.480\n but I'm pretty positive about it.\n\n39:41.480 --> 39:44.000\n I think you do actually because I think I've tested that.\n\n39:44.000 --> 39:49.000\n But that's like how I was born in your brand of champagne\n\n39:49.120 --> 39:51.240\n and whatever the year kind of thing, yeah.\n\n39:51.240 --> 39:55.720\n So in terms of the metaphysical, I think it's early.\n\n39:55.720 --> 40:00.360\n Does it have the historic knowledge about herself\n\n40:00.360 --> 40:01.440\n to be able to do that?\n\n40:01.440 --> 40:03.720\n Maybe, have we crossed that boundary?\n\n40:03.720 --> 40:04.560\n Not yet, right?\n\n40:04.560 --> 40:06.520\n In terms of being, thank you.\n\n40:06.520 --> 40:08.600\n Have we thought about it quite a bit\n\n40:08.600 --> 40:11.480\n but I wouldn't say that we have come to a clear decision\n\n40:11.480 --> 40:13.000\n in terms of what it should look like.\n\n40:13.000 --> 40:16.920\n But you can imagine though, and I bring this back\n\n40:16.920 --> 40:19.200\n to the Alexa Prize social bot one,\n\n40:19.200 --> 40:21.200\n there you will start seeing some of that.\n\n40:21.200 --> 40:23.440\n Like these bots have their identity\n\n40:23.440 --> 40:25.720\n and in terms of that, you may find,\n\n40:26.800 --> 40:28.400\n this is such a great research topic\n\n40:28.400 --> 40:32.120\n that some academia team may think of these problems\n\n40:32.120 --> 40:34.080\n and start solving them too.\n\n40:35.080 --> 40:38.840\n So let me ask a question.\n\n40:38.840 --> 40:41.160\n It's kind of difficult, I think,\n\n40:41.160 --> 40:43.280\n but it feels, and fascinating to me\n\n40:43.280 --> 40:45.320\n because I'm fascinated with psychology.\n\n40:45.320 --> 40:48.200\n It feels that the more personality you have,\n\n40:48.200 --> 40:50.400\n the more dangerous it is\n\n40:50.400 --> 40:54.480\n in terms of a customer perspective of product.\n\n40:54.480 --> 40:57.080\n If you want to create a product that's useful.\n\n40:57.080 --> 41:01.360\n By dangerous, I mean creating an experience that upsets me.\n\n41:02.360 --> 41:06.680\n And so how do you get that right?\n\n41:06.680 --> 41:10.040\n Because if you look at the relationships,\n\n41:10.040 --> 41:11.800\n maybe I'm just a screwed up Russian,\n\n41:11.800 --> 41:15.040\n but if you look at the human to human relationship,\n\n41:15.040 --> 41:18.120\n some of our deepest relationships have fights,\n\n41:18.120 --> 41:21.200\n have tension, have the push and pull,\n\n41:21.200 --> 41:22.800\n have a little flavor in them.\n\n41:22.800 --> 41:26.800\n Do you want to have such flavor in an interaction with Alexa?\n\n41:26.800 --> 41:28.200\n How do you think about that?\n\n41:28.200 --> 41:31.280\n So there's one other common thing that you didn't say,\n\n41:31.280 --> 41:35.000\n but we think of it as paramount for any deep relationship.\n\n41:35.000 --> 41:36.680\n That's trust.\n\n41:36.680 --> 41:37.520\n Trust, yeah.\n\n41:37.520 --> 41:40.960\n So I think if you trust every attribute you said,\n\n41:40.960 --> 41:44.880\n a fight, some tension, is all healthy.\n\n41:44.880 --> 41:49.880\n But what is sort of unnegotiable in this instance is trust.\n\n41:49.880 --> 41:52.920\n And I think the bar to earn customer trust for AI\n\n41:52.920 --> 41:56.880\n is very high, in some sense, more than a human.\n\n41:56.880 --> 42:01.880\n It's not just about personal information or your data.\n\n42:02.040 --> 42:05.120\n It's also about your actions on a daily basis.\n\n42:05.120 --> 42:07.920\n How trustworthy are you in terms of consistency,\n\n42:07.920 --> 42:11.200\n in terms of how accurate are you in understanding me?\n\n42:11.200 --> 42:13.680\n Like if you're talking to a person on the phone,\n\n42:13.680 --> 42:14.880\n if you have a problem with your,\n\n42:14.880 --> 42:16.360\n let's say your internet or something,\n\n42:16.360 --> 42:17.720\n if the person's not understanding,\n\n42:17.720 --> 42:19.040\n you lose trust right away.\n\n42:19.040 --> 42:20.960\n You don't want to talk to that person.\n\n42:20.960 --> 42:24.360\n That whole example gets amplified by a factor of 10,\n\n42:24.360 --> 42:28.200\n because when you're a human interacting with an AI,\n\n42:28.200 --> 42:29.720\n you have a certain expectation.\n\n42:29.720 --> 42:31.960\n Either you expect it to be very intelligent\n\n42:31.960 --> 42:34.400\n and then you get upset, why is it behaving this way?\n\n42:34.400 --> 42:37.640\n Or you expect it to be not so intelligent\n\n42:37.640 --> 42:38.800\n and when it surprises you, you're like,\n\n42:38.800 --> 42:40.960\n really, you're trying to be too smart?\n\n42:40.960 --> 42:43.680\n So I think we grapple with these hard questions as well.\n\n42:43.680 --> 42:47.720\n But I think the key is actions need to be trustworthy.\n\n42:47.720 --> 42:50.840\n From these AIs, not just about data protection,\n\n42:50.840 --> 42:53.400\n your personal information protection,\n\n42:53.400 --> 42:57.200\n but also from how accurately it accomplishes\n\n42:57.200 --> 42:59.760\n all commands or all interactions.\n\n42:59.760 --> 43:02.200\n Well, it's tough to hear because trust,\n\n43:02.200 --> 43:03.080\n you're absolutely right,\n\n43:03.080 --> 43:05.560\n but trust is such a high bar with AI systems\n\n43:05.560 --> 43:07.400\n because people, and I see this\n\n43:07.400 --> 43:08.880\n because I work with autonomous vehicles.\n\n43:08.880 --> 43:11.720\n I mean, the bar that's placed on AI system\n\n43:11.720 --> 43:13.440\n is unreasonably high.\n\n43:13.440 --> 43:16.120\n Yeah, that is going to be, I agree with you.\n\n43:16.120 --> 43:19.920\n And I think of it as it's a challenge\n\n43:19.920 --> 43:23.120\n and it's also keeps my job, right?\n\n43:23.120 --> 43:26.360\n So from that perspective, I totally,\n\n43:26.360 --> 43:28.720\n I think of it at both sides as a customer\n\n43:28.720 --> 43:30.240\n and as a researcher.\n\n43:30.240 --> 43:33.400\n I think as a researcher, yes, occasionally it will frustrate\n\n43:33.400 --> 43:36.920\n me that why is the bar so high for these AIs?\n\n43:36.920 --> 43:38.640\n And as a customer, then I say,\n\n43:38.640 --> 43:40.920\n absolutely, it has to be that high, right?\n\n43:40.920 --> 43:44.120\n So I think that's the trade off we have to balance,\n\n43:44.120 --> 43:46.760\n but it doesn't change the fundamentals.\n\n43:46.760 --> 43:50.520\n That trust has to be earned and the question then becomes\n\n43:50.520 --> 43:53.520\n is are we holding the AIs to a different bar\n\n43:53.520 --> 43:56.320\n in accuracy and mistakes than we hold humans?\n\n43:56.320 --> 43:58.280\n That's going to be a great societal questions\n\n43:58.280 --> 44:00.320\n for years to come, I think for us.\n\n44:00.320 --> 44:04.000\n Well, one of the questions that we grapple as a society now\n\n44:04.000 --> 44:05.480\n that I think about a lot,\n\n44:05.480 --> 44:07.840\n I think a lot of people in the AI think about a lot\n\n44:07.840 --> 44:11.640\n and Alexis taking on head on is privacy.\n\n44:11.640 --> 44:16.640\n The reality is us giving over data to any AI system\n\n44:20.760 --> 44:25.760\n can be used to enrich our lives in profound ways.\n\n44:25.800 --> 44:28.520\n So if basically any product that does anything awesome\n\n44:28.520 --> 44:31.680\n for you, the more data it has,\n\n44:31.680 --> 44:34.040\n the more awesome things it can do.\n\n44:34.040 --> 44:37.040\n And yet on the other side,\n\n44:37.040 --> 44:39.400\n people imagine the worst case possible scenario\n\n44:39.400 --> 44:42.240\n of what can you possibly do with that data?\n\n44:42.240 --> 44:45.680\n People, it's goes down to trust, as you said before.\n\n44:45.680 --> 44:48.200\n There's a fundamental distrust of,\n\n44:48.200 --> 44:50.440\n in certain groups of governments and so on.\n\n44:50.440 --> 44:51.560\n And depending on the government,\n\n44:51.560 --> 44:52.880\n depending on who's in power,\n\n44:52.880 --> 44:55.400\n depending on all these kinds of factors.\n\n44:55.400 --> 44:59.600\n And so here's Alexa in the middle of all of it in the home,\n\n44:59.600 --> 45:02.320\n trying to do good things for the customers.\n\n45:02.320 --> 45:05.040\n So how do you think about privacy in this context,\n\n45:05.040 --> 45:06.720\n the smart assistance in the home?\n\n45:06.720 --> 45:08.680\n How do you maintain, how do you earn trust?\n\n45:08.680 --> 45:09.520\n Absolutely.\n\n45:09.520 --> 45:12.400\n So as you said, trust is the key here.\n\n45:12.400 --> 45:13.560\n So you start with trust\n\n45:13.560 --> 45:16.760\n and then privacy is a key aspect of it.\n\n45:16.760 --> 45:20.240\n It has to be designed from very beginning about that.\n\n45:20.240 --> 45:23.920\n And we believe in two fundamental principles.\n\n45:23.920 --> 45:26.840\n One is transparency and second is control.\n\n45:26.840 --> 45:28.920\n So by transparency, I mean,\n\n45:28.920 --> 45:32.120\n when we build what is now called smart speaker\n\n45:32.120 --> 45:33.360\n or the first echo,\n\n45:34.320 --> 45:38.400\n we were quite judicious about making these right trade offs\n\n45:38.400 --> 45:40.160\n on customer's behalf,\n\n45:40.160 --> 45:41.920\n that it is pretty clear\n\n45:41.920 --> 45:44.200\n when the audio is being sent to cloud,\n\n45:44.200 --> 45:45.280\n the light ring comes on\n\n45:45.280 --> 45:48.280\n when it has heard you say the word wake word,\n\n45:48.280 --> 45:49.760\n and then the streaming happens, right?\n\n45:49.760 --> 45:51.360\n So when the light ring comes up,\n\n45:51.360 --> 45:55.520\n we also had, we put a physical mute button on it,\n\n45:55.520 --> 45:57.920\n just so if you didn't want it to be listening,\n\n45:57.920 --> 45:58.760\n even for the wake word,\n\n45:58.760 --> 46:01.800\n then you turn the power button or the mute button on,\n\n46:01.800 --> 46:04.960\n and that disables the microphones.\n\n46:04.960 --> 46:08.040\n That's just the first decision on essentially transparency\n\n46:08.040 --> 46:09.720\n and control.\n\n46:09.720 --> 46:11.720\n Oh, then even when we launched,\n\n46:11.720 --> 46:13.840\n we gave the control in the hands of the customers\n\n46:13.840 --> 46:16.400\n that you can go and look at any of your individual utterances\n\n46:16.400 --> 46:19.560\n that is recorded and delete them anytime.\n\n46:19.560 --> 46:22.520\n And we've got to true to that promise, right?\n\n46:22.520 --> 46:25.000\n So, and that is super, again,\n\n46:25.000 --> 46:29.080\n a great instance of showing how you have the control.\n\n46:29.080 --> 46:30.440\n Then we made it even easier.\n\n46:30.440 --> 46:33.080\n You can say, like I said, delete what I said today.\n\n46:33.080 --> 46:36.880\n So that is now making it even just more control\n\n46:36.880 --> 46:39.360\n in your hands with what's most convenient\n\n46:39.360 --> 46:42.000\n about this technology is voice.\n\n46:42.000 --> 46:44.400\n You delete it with your voice now.\n\n46:44.400 --> 46:48.080\n So these are the types of decisions we continually make.\n\n46:48.080 --> 46:51.240\n We just recently launched this feature called,\n\n46:51.240 --> 46:52.360\n what we think of it as,\n\n46:52.360 --> 46:55.760\n if you wanted humans not to review your data,\n\n46:56.680 --> 46:59.160\n because you've mentioned supervised learning, right?\n\n46:59.160 --> 47:01.160\n So in supervised learning,\n\n47:01.160 --> 47:03.760\n humans have to give some annotation.\n\n47:03.760 --> 47:06.200\n And that also is now a feature\n\n47:06.200 --> 47:09.320\n where you can essentially, if you've selected that flag,\n\n47:09.320 --> 47:11.320\n your data will not be reviewed by a human.\n\n47:11.320 --> 47:13.640\n So these are the types of controls\n\n47:13.640 --> 47:17.480\n that we have to constantly offer with customers.\n\n47:18.440 --> 47:23.440\n So why do you think it bothers people so much that,\n\n47:23.840 --> 47:26.920\n so everything you just said is really powerful.\n\n47:26.920 --> 47:28.400\n So the control, the ability to delete,\n\n47:28.400 --> 47:31.120\n cause we collect, we have studies here running at MIT\n\n47:31.120 --> 47:32.760\n that collects huge amounts of data\n\n47:32.760 --> 47:34.880\n and people consent and so on.\n\n47:34.880 --> 47:38.040\n The ability to delete that data is really empowering\n\n47:38.040 --> 47:40.000\n and almost nobody ever asked to delete it,\n\n47:40.000 --> 47:44.200\n but the ability to have that control is really powerful.\n\n47:44.200 --> 47:47.040\n But still, there's these popular anecdote,\n\n47:47.040 --> 47:49.280\n anecdotal evidence that people say,\n\n47:49.280 --> 47:51.000\n they like to tell that,\n\n47:51.000 --> 47:53.160\n them and a friend were talking about something,\n\n47:53.160 --> 47:56.120\n I don't know, sweaters for cats.\n\n47:56.120 --> 47:58.200\n And all of a sudden they'll have advertisements\n\n47:58.200 --> 48:01.400\n for cat sweaters on Amazon.\n\n48:01.400 --> 48:02.680\n That's a popular anecdote\n\n48:02.680 --> 48:05.040\n as if something is always listening.\n\n48:05.040 --> 48:07.800\n What, can you explain that anecdote,\n\n48:07.800 --> 48:09.120\n that experience that people have?\n\n48:09.120 --> 48:11.000\n What's the psychology of that?\n\n48:11.000 --> 48:13.080\n What's that experience?\n\n48:13.080 --> 48:15.080\n And can you, you've answered it,\n\n48:15.080 --> 48:17.440\n but let me just ask, is Alexa listening?\n\n48:18.280 --> 48:22.560\n No, Alexa listens only for the wake word on the device.\n\n48:22.560 --> 48:23.920\n And the wake word is?\n\n48:23.920 --> 48:28.080\n The words like Alexa, Amazon, Echo,\n\n48:28.080 --> 48:29.640\n but you only choose one at a time.\n\n48:29.640 --> 48:31.640\n So you choose one and it listens only\n\n48:31.640 --> 48:33.000\n for that on our devices.\n\n48:34.040 --> 48:35.160\n So that's first.\n\n48:35.160 --> 48:36.480\n From a listening perspective,\n\n48:36.480 --> 48:38.360\n we have to be very clear that it's just the wake word.\n\n48:38.360 --> 48:41.280\n So you said, why is there this anxiety, if you may?\n\n48:41.280 --> 48:42.120\n Yeah, exactly.\n\n48:42.120 --> 48:43.560\n It's because there's a lot of confusion,\n\n48:43.560 --> 48:45.360\n what it really listens to, right?\n\n48:45.360 --> 48:48.760\n And I think it's partly on us to keep educating\n\n48:49.680 --> 48:52.240\n our customers and the general media more\n\n48:52.240 --> 48:54.080\n in terms of like how, what really happens.\n\n48:54.080 --> 48:56.560\n And we've done a lot of it.\n\n48:56.560 --> 49:00.840\n And our pages on information are clear,\n\n49:00.840 --> 49:04.040\n but still people have to have more,\n\n49:04.040 --> 49:06.680\n there's always a hunger for information and clarity.\n\n49:06.680 --> 49:09.120\n And we'll constantly look at how best to communicate.\n\n49:09.120 --> 49:10.560\n If you go back and read everything,\n\n49:10.560 --> 49:12.280\n yes, it states exactly that.\n\n49:13.120 --> 49:15.360\n And then people could still question it.\n\n49:15.360 --> 49:17.760\n And I think that's absolutely okay to question.\n\n49:17.760 --> 49:21.760\n What we have to make sure is that we are,\n\n49:21.760 --> 49:24.880\n because our fundamental philosophy is customer first,\n\n49:24.880 --> 49:27.280\n customer obsession is our leadership principle.\n\n49:27.280 --> 49:31.040\n If you put, as researchers, I put myself\n\n49:31.040 --> 49:33.200\n in the shoes of the customer,\n\n49:33.200 --> 49:35.880\n and all decisions in Amazon are made with that.\n\n49:35.880 --> 49:38.040\n And trust has to be earned,\n\n49:38.040 --> 49:39.440\n and we have to keep earning the trust\n\n49:39.440 --> 49:41.800\n of our customers in this setting.\n\n49:41.800 --> 49:44.080\n And to your other point on like,\n\n49:44.080 --> 49:45.560\n is there something showing up\n\n49:45.560 --> 49:46.680\n based on your conversations?\n\n49:46.680 --> 49:49.640\n No, I think the answer is like,\n\n49:49.640 --> 49:51.400\n a lot of times when those experiences happen,\n\n49:51.400 --> 49:52.840\n you have to also know that, okay,\n\n49:52.840 --> 49:54.600\n it may be a winter season,\n\n49:54.600 --> 49:56.480\n people are looking for sweaters, right?\n\n49:56.480 --> 49:59.640\n And it shows up on your amazon.com because it is popular.\n\n49:59.640 --> 50:01.440\n So there are many of these,\n\n50:02.720 --> 50:06.320\n you mentioned that personality or personalization,\n\n50:06.320 --> 50:09.120\n turns out we are not that unique either, right?\n\n50:09.120 --> 50:12.080\n So those things we as humans start thinking,\n\n50:12.080 --> 50:14.120\n oh, must be because something was heard,\n\n50:14.120 --> 50:16.720\n and that's why this other thing showed up.\n\n50:16.720 --> 50:17.760\n The answer is no,\n\n50:17.760 --> 50:21.520\n probably it is just the season for sweaters.\n\n50:21.520 --> 50:23.800\n I'm not gonna ask you this question\n\n50:23.800 --> 50:27.160\n because people have so much paranoia.\n\n50:27.160 --> 50:29.200\n But let me just say from my perspective,\n\n50:29.200 --> 50:33.160\n I hope there's a day when customer can ask Alexa\n\n50:33.160 --> 50:34.320\n to listen all the time,\n\n50:35.200 --> 50:36.640\n to improve the experience,\n\n50:36.640 --> 50:39.800\n to improve because I personally don't see the negative\n\n50:40.760 --> 50:43.920\n because if you have the control and if you have the trust,\n\n50:43.920 --> 50:45.640\n there's no reason why I shouldn't be listening\n\n50:45.640 --> 50:48.280\n all the time to the conversations to learn more about you.\n\n50:48.280 --> 50:49.640\n Because ultimately,\n\n50:49.640 --> 50:52.560\n as long as you have control and trust,\n\n50:52.560 --> 50:55.680\n every data you provide to the device,\n\n50:55.680 --> 51:00.200\n that the device wants is going to be useful.\n\n51:00.200 --> 51:03.880\n And so to me, as a machine learning person,\n\n51:03.880 --> 51:08.200\n I think it worries me how sensitive people are\n\n51:08.200 --> 51:13.200\n about their data relative to how empowering it could be\n\n51:13.200 --> 51:18.200\n relative to how empowering it could be\n\n51:19.320 --> 51:21.160\n for the devices around them,\n\n51:21.160 --> 51:23.720\n how enriching it could be for their own life\n\n51:23.720 --> 51:25.440\n to improve the product.\n\n51:25.440 --> 51:28.320\n So I just, it's something I think about sort of a lot,\n\n51:28.320 --> 51:29.520\n how do we make that devices,\n\n51:29.520 --> 51:32.200\n obviously Alexa thinks about a lot as well.\n\n51:32.200 --> 51:34.200\n I don't know if you wanna comment on that,\n\n51:34.200 --> 51:35.360\n sort of, okay, have you seen,\n\n51:35.360 --> 51:37.560\n let me ask it in the form of a question, okay.\n\n51:38.680 --> 51:42.240\n Have you seen an evolution in the way people think about\n\n51:42.240 --> 51:46.400\n their private data in the previous several years?\n\n51:46.400 --> 51:48.680\n So as we as a society get more and more comfortable\n\n51:48.680 --> 51:52.600\n to the benefits we get by sharing more data.\n\n51:53.520 --> 51:55.040\n First, let me answer that part\n\n51:55.040 --> 51:55.960\n and then I'll wanna go back\n\n51:55.960 --> 51:58.440\n to the other aspect you were mentioning.\n\n51:58.440 --> 52:01.160\n So as a society, on a general,\n\n52:01.160 --> 52:03.120\n we are getting more comfortable as a society.\n\n52:03.120 --> 52:05.840\n Doesn't mean that everyone is,\n\n52:05.840 --> 52:07.600\n and I think we have to respect that.\n\n52:07.600 --> 52:10.320\n I don't think one size fits all\n\n52:10.320 --> 52:13.520\n is always gonna be the answer for all, right?\n\n52:13.520 --> 52:14.360\n By definition.\n\n52:14.360 --> 52:17.160\n So I think that's something to keep in mind in these.\n\n52:17.160 --> 52:19.600\n Going back to your, on what more\n\n52:21.400 --> 52:23.640\n magical experiences can be launched\n\n52:23.640 --> 52:26.040\n in these kinds of AI settings.\n\n52:26.040 --> 52:29.200\n I think again, if you give the control,\n\n52:29.200 --> 52:32.080\n we, it's possible certain parts of it.\n\n52:32.080 --> 52:33.960\n So we have a feature called follow up mode\n\n52:33.960 --> 52:37.000\n where you, if you turn it on\n\n52:37.000 --> 52:40.400\n and Alexa, after you've spoken to it,\n\n52:40.400 --> 52:42.000\n will open the mics again,\n\n52:42.000 --> 52:44.680\n thinking you will answer something again.\n\n52:44.680 --> 52:47.880\n Like if you're adding lists to your shopping item,\n\n52:47.880 --> 52:50.360\n so right, or a shopping list or to do list,\n\n52:50.360 --> 52:51.440\n you're not done.\n\n52:51.440 --> 52:53.000\n You want to keep, so in that setting,\n\n52:53.000 --> 52:54.520\n it's awesome that it opens the mic\n\n52:54.520 --> 52:57.160\n for you to say eggs and milk and then bread, right?\n\n52:57.160 --> 52:59.920\n So these are the kinds of things which you can empower.\n\n52:59.920 --> 53:02.320\n So, and then another feature we have,\n\n53:02.320 --> 53:04.960\n which is called Alexa Guard.\n\n53:04.960 --> 53:07.800\n I said it only listens for the wake word, right?\n\n53:07.800 --> 53:10.480\n But if you have, let's say you're going to say,\n\n53:10.480 --> 53:13.440\n like you leave your home and you want Alexa to listen\n\n53:13.440 --> 53:17.200\n for a couple of sound events like smoke alarm going off\n\n53:17.200 --> 53:19.280\n or someone breaking your glass, right?\n\n53:19.280 --> 53:22.160\n So it's like just to keep your peace of mind.\n\n53:22.160 --> 53:26.480\n So you can say Alexa on guard or I'm away\n\n53:26.480 --> 53:29.200\n and then it can be listening for these sound events.\n\n53:29.200 --> 53:33.040\n And when you're home, you come out of that mode, right?\n\n53:33.040 --> 53:35.560\n So this is another one where you again gave controls\n\n53:35.560 --> 53:38.040\n in the hands of the user or the customer\n\n53:38.040 --> 53:42.440\n and to enable some experience that is high utility\n\n53:42.440 --> 53:44.600\n and maybe even more delightful in the certain settings\n\n53:44.600 --> 53:46.480\n like follow up mode and so forth.\n\n53:46.480 --> 53:48.880\n And again, this general principle is the same,\n\n53:48.880 --> 53:50.760\n control in the hands of the customer.\n\n53:52.640 --> 53:55.480\n So I know we kind of started with a lot of philosophy\n\n53:55.480 --> 53:56.840\n and a lot of interesting topics\n\n53:56.840 --> 53:58.280\n and we're just jumping all over the place,\n\n53:58.280 --> 54:00.280\n but really some of the fascinating things\n\n54:00.280 --> 54:03.040\n that the Alexa team and Amazon is doing\n\n54:03.040 --> 54:05.480\n is in the algorithm side, the data side,\n\n54:05.480 --> 54:07.520\n the technology, the deep learning, machine learning\n\n54:07.520 --> 54:08.880\n and so on.\n\n54:08.880 --> 54:13.040\n So can you give a brief history of Alexa\n\n54:13.040 --> 54:15.440\n from the perspective of just innovation,\n\n54:15.440 --> 54:18.640\n the algorithms, the data of how it was born,\n\n54:18.640 --> 54:22.280\n how it came to be, how it's grown, where it is today?\n\n54:22.280 --> 54:24.360\n Yeah, it start with in Amazon,\n\n54:24.360 --> 54:27.000\n everything starts with the customer\n\n54:27.000 --> 54:30.320\n and we have a process called working backwards.\n\n54:30.320 --> 54:35.040\n Alexa and more specifically than the product Echo,\n\n54:35.040 --> 54:37.320\n there was a working backwards document essentially\n\n54:37.320 --> 54:38.880\n that reflected what it would be,\n\n54:38.880 --> 54:43.880\n started with a very simple vision statement for instance\n\n54:44.320 --> 54:47.160\n that morphed into a full fledged document\n\n54:47.160 --> 54:51.720\n along the way changed into what all it can do, right?\n\n54:51.720 --> 54:54.160\n But the inspiration was the Star Trek computer.\n\n54:54.160 --> 54:56.240\n So when you think of it that way,\n\n54:56.240 --> 54:58.360\n everything is possible, but when you launch a product,\n\n54:58.360 --> 55:01.040\n you have to start with some place.\n\n55:01.040 --> 55:05.520\n And when I joined, the product was already in conception\n\n55:05.520 --> 55:08.960\n and we started working on the far field speech recognition\n\n55:08.960 --> 55:10.960\n because that was the first thing to solve.\n\n55:10.960 --> 55:12.880\n By that we mean that you should be able to speak\n\n55:12.880 --> 55:15.280\n to the device from a distance.\n\n55:15.280 --> 55:18.840\n And in those days, that wasn't a common practice.\n\n55:18.840 --> 55:22.360\n And even in the previous research world I was in\n\n55:22.360 --> 55:24.640\n was considered to an unsolvable problem then\n\n55:24.640 --> 55:28.320\n in terms of whether you can converse from a length.\n\n55:28.320 --> 55:30.360\n And here I'm still talking about the first part\n\n55:30.360 --> 55:32.440\n of the problem where you say,\n\n55:32.440 --> 55:34.080\n get the attention of the device\n\n55:34.080 --> 55:37.120\n as in by saying what we call the wake word,\n\n55:37.120 --> 55:40.400\n which means the word Alexa has to be detected\n\n55:40.400 --> 55:44.880\n with a very high accuracy because it is a very common word.\n\n55:44.880 --> 55:48.240\n It has sound units that map with words like I like you\n\n55:48.240 --> 55:51.160\n or Alec, Alex, right?\n\n55:51.160 --> 55:56.160\n So it's a undoubtedly hard problem to detect\n\n55:56.160 --> 56:00.520\n the right mentions of Alexa's address to the device\n\n56:00.520 --> 56:02.800\n versus I like Alexa.\n\n56:02.800 --> 56:04.240\n So you have to pick up that signal\n\n56:04.240 --> 56:06.040\n when there's a lot of noise.\n\n56:06.040 --> 56:09.120\n Not only noise but a lot of conversation in the house,\n\n56:09.120 --> 56:09.960\n right?\n\n56:09.960 --> 56:10.800\n You remember on the device,\n\n56:10.800 --> 56:13.160\n you're simply listening for the wake word, Alexa.\n\n56:13.160 --> 56:15.760\n And there's a lot of words being spoken in the house.\n\n56:15.760 --> 56:20.760\n How do you know it's Alexa and directed at Alexa?\n\n56:21.720 --> 56:25.320\n Because I could say, I love my Alexa, I hate my Alexa.\n\n56:25.320 --> 56:27.000\n I want Alexa to do this.\n\n56:27.000 --> 56:29.280\n And in all these three sentences, I said, Alexa,\n\n56:29.280 --> 56:30.600\n I didn't want it to wake up.\n\n56:32.120 --> 56:33.720\n Can I just pause on that second?\n\n56:33.720 --> 56:36.680\n What would be your device that I should probably\n\n56:36.680 --> 56:39.920\n in the introduction of this conversation give to people\n\n56:39.920 --> 56:43.440\n in terms of them turning off their Alexa device\n\n56:43.440 --> 56:48.440\n if they're listening to this podcast conversation out loud?\n\n56:49.240 --> 56:51.640\n Like what's the probability that an Alexa device\n\n56:51.640 --> 56:55.160\n will go off because we mentioned Alexa like a million times.\n\n56:55.160 --> 56:58.120\n So it will, we have done a lot of different things\n\n56:58.120 --> 57:03.120\n where we can figure out that there is the device,\n\n57:03.720 --> 57:08.200\n the speech is coming from a human versus over the air.\n\n57:08.200 --> 57:11.720\n Also, I mean, in terms of like, also it is think about ads\n\n57:11.720 --> 57:14.240\n or so we have also launched a technology\n\n57:14.240 --> 57:16.280\n for watermarking kind of approaches\n\n57:16.280 --> 57:18.800\n in terms of filtering it out.\n\n57:18.800 --> 57:21.600\n But yes, if this kind of a podcast is happening,\n\n57:21.600 --> 57:24.360\n it's possible your device will wake up a few times.\n\n57:24.360 --> 57:25.440\n It's an unsolved problem,\n\n57:25.440 --> 57:30.440\n but it is definitely something we care very much about.\n\n57:31.040 --> 57:33.880\n But the idea is you wanna detect Alexa.\n\n57:33.880 --> 57:36.080\n Meant for the device.\n\n57:36.080 --> 57:40.040\n First of all, just even hearing Alexa versus I like something.\n\n57:40.040 --> 57:41.040\n I mean, that's a fascinating part.\n\n57:41.040 --> 57:43.040\n So that was the first relief.\n\n57:43.040 --> 57:43.880\n That's the first.\n\n57:43.880 --> 57:45.960\n The world's best detector of Alexa.\n\n57:45.960 --> 57:48.720\n Yeah, the world's best wake word detector\n\n57:48.720 --> 57:49.920\n in a far field setting,\n\n57:49.920 --> 57:52.960\n not like something where the phone is sitting on the table.\n\n57:53.840 --> 57:56.680\n This is like people have devices 40 feet away\n\n57:56.680 --> 58:00.640\n like in my house or 20 feet away and you still get an answer.\n\n58:00.640 --> 58:02.480\n So that was the first part.\n\n58:02.480 --> 58:05.880\n The next is, okay, you're speaking to the device.\n\n58:05.880 --> 58:09.000\n Of course, you're gonna issue many different requests.\n\n58:09.000 --> 58:11.560\n Some may be simple, some may be extremely hard,\n\n58:11.560 --> 58:13.720\n but it's a large vocabulary speech recognition problem\n\n58:13.720 --> 58:17.600\n essentially, where the audio is now not coming\n\n58:17.600 --> 58:20.360\n onto your phone or a handheld mic like this\n\n58:20.360 --> 58:23.880\n or a close talking mic, but it's from 20 feet away\n\n58:23.880 --> 58:26.240\n where if you're in a busy household,\n\n58:26.240 --> 58:28.840\n your son may be listening to music,\n\n58:28.840 --> 58:31.600\n your daughter may be running around with something\n\n58:31.600 --> 58:33.800\n and asking your mom something and so forth, right?\n\n58:33.800 --> 58:36.360\n So this is like a common household setting\n\n58:36.360 --> 58:40.160\n where the words you're speaking to Alexa\n\n58:40.160 --> 58:43.400\n need to be recognized with very high accuracy, right?\n\n58:43.400 --> 58:45.800\n Now we are still just in the recognition problem.\n\n58:45.800 --> 58:48.160\n We haven't yet come to the understanding one, right?\n\n58:48.160 --> 58:50.160\n And if I pause them, sorry, once again,\n\n58:50.160 --> 58:51.160\n what year was this?\n\n58:51.160 --> 58:55.520\n Is this before neural networks began to start\n\n58:56.440 --> 59:00.480\n to seriously prove themselves in the audio space?\n\n59:00.480 --> 59:05.480\n Yeah, this is around, so I joined in 2013 in April, right?\n\n59:05.480 --> 59:08.800\n So the early research and neural networks coming back\n\n59:08.800 --> 59:11.240\n and showing some promising results\n\n59:11.240 --> 59:13.560\n in speech recognition space had started happening,\n\n59:13.560 --> 59:15.360\n but it was very early.\n\n59:15.360 --> 59:17.800\n But we just now build on that\n\n59:17.800 --> 59:22.800\n on the very first thing we did when I joined with the team.\n\n59:23.240 --> 59:25.960\n And remember, it was a very much of a startup environment,\n\n59:25.960 --> 59:28.080\n which is great about Amazon.\n\n59:28.080 --> 59:31.240\n And we doubled down on deep learning right away.\n\n59:31.240 --> 59:36.240\n And we knew we'll have to improve accuracy fast.\n\n59:36.600 --> 59:38.960\n And because of that, we worked on,\n\n59:38.960 --> 59:41.640\n and the scale of data, once you have a device like this,\n\n59:41.640 --> 59:44.920\n if it is successful, will improve big time.\n\n59:44.920 --> 59:48.040\n Like you'll suddenly have large volumes of data\n\n59:48.040 --> 59:51.080\n to learn from to make the customer experience better.\n\n59:51.080 --> 59:52.480\n So how do you scale deep learning?\n\n59:52.480 --> 59:54.560\n So we did one of the first works\n\n59:54.560 --> 59:57.600\n in training with distributed GPUs\n\n59:57.600 --> 1:00:01.400\n and where the training time was linear\n\n1:00:01.400 --> 1:00:03.960\n in terms of the amount of data.\n\n1:00:03.960 --> 1:00:06.200\n So that was quite important work\n\n1:00:06.200 --> 1:00:07.840\n where it was algorithmic improvements\n\n1:00:07.840 --> 1:00:09.920\n as well as a lot of engineering improvements\n\n1:00:09.920 --> 1:00:14.000\n to be able to train on thousands and thousands of speech.\n\n1:00:14.000 --> 1:00:15.600\n And that was an important factor.\n\n1:00:15.600 --> 1:00:19.320\n So if you ask me like back in 2013 and 2014,\n\n1:00:19.320 --> 1:00:22.440\n when we launched Echo,\n\n1:00:22.440 --> 1:00:25.680\n the combination of large scale data,\n\n1:00:25.680 --> 1:00:29.680\n deep learning progress, near infinite GPUs\n\n1:00:29.680 --> 1:00:33.120\n we had available on AWS even then,\n\n1:00:33.120 --> 1:00:35.320\n was all came together for us to be able\n\n1:00:35.320 --> 1:00:38.400\n to solve the far field speech recognition\n\n1:00:38.400 --> 1:00:40.640\n to the extent it could be useful to the customers.\n\n1:00:40.640 --> 1:00:41.480\n It's still not solved.\n\n1:00:41.480 --> 1:00:43.000\n Like, I mean, it's not that we are perfect\n\n1:00:43.000 --> 1:00:45.520\n at recognizing speech, but we are great at it\n\n1:00:45.520 --> 1:00:48.360\n in terms of the settings that are in homes, right?\n\n1:00:48.360 --> 1:00:50.920\n So, and that was important even in the early stages.\n\n1:00:50.920 --> 1:00:51.960\n So first of all, just even,\n\n1:00:51.960 --> 1:00:54.240\n I'm trying to look back at that time.\n\n1:00:54.240 --> 1:00:57.120\n If I remember correctly,\n\n1:00:57.120 --> 1:01:01.160\n it was, it seems like the task would be pretty daunting.\n\n1:01:01.160 --> 1:01:04.480\n So like, so we kind of take it for granted\n\n1:01:04.480 --> 1:01:06.400\n that it works now.\n\n1:01:06.400 --> 1:01:07.720\n Yes, you're right.\n\n1:01:07.720 --> 1:01:10.880\n So let me, like how, first of all, you mentioned startup.\n\n1:01:10.880 --> 1:01:12.880\n I wasn't familiar how big the team was.\n\n1:01:12.880 --> 1:01:14.200\n I kind of, cause I know there's a lot\n\n1:01:14.200 --> 1:01:16.040\n of really smart people working on it.\n\n1:01:16.040 --> 1:01:17.880\n So now it's a very, very large team.\n\n1:01:19.120 --> 1:01:20.840\n How big was the team?\n\n1:01:20.840 --> 1:01:24.120\n How likely were you to fail in the eyes of everyone else?\n\n1:01:24.120 --> 1:01:26.120\n And ourselves?\n\n1:01:26.120 --> 1:01:27.760\n And yourself?\n\n1:01:27.760 --> 1:01:28.600\n So like what?\n\n1:01:28.600 --> 1:01:31.600\n I'll give you a very interesting anecdote on that.\n\n1:01:31.600 --> 1:01:33.880\n When I joined the team,\n\n1:01:33.880 --> 1:01:37.680\n the speech recognition team was six people.\n\n1:01:37.680 --> 1:01:40.520\n My first meeting, and we had hired a few more people,\n\n1:01:40.520 --> 1:01:41.680\n it was 10 people.\n\n1:01:42.960 --> 1:01:45.560\n Nine out of 10 people thought it can't be done.\n\n1:01:48.040 --> 1:01:48.880\n Who was the one?\n\n1:01:50.080 --> 1:01:52.960\n The one was me, say, actually I should say,\n\n1:01:52.960 --> 1:01:56.000\n and one was semi optimistic.\n\n1:01:56.000 --> 1:01:59.120\n And eight were trying to convince,\n\n1:01:59.120 --> 1:02:01.720\n let's go to the management and say,\n\n1:02:01.720 --> 1:02:03.600\n let's not work on this problem.\n\n1:02:03.600 --> 1:02:05.240\n Let's work on some other problem,\n\n1:02:05.240 --> 1:02:09.000\n like either telephony speech for customer service calls\n\n1:02:09.000 --> 1:02:10.160\n and so forth.\n\n1:02:10.160 --> 1:02:12.040\n But this was the kind of belief you must have.\n\n1:02:12.040 --> 1:02:14.360\n And I had experience with far field speech recognition\n\n1:02:14.360 --> 1:02:17.720\n and my eyes lit up when I saw a problem like that saying,\n\n1:02:17.720 --> 1:02:20.840\n okay, we have been in speech recognition,\n\n1:02:20.840 --> 1:02:23.400\n always looking for that killer app.\n\n1:02:23.400 --> 1:02:25.840\n And this was a killer use case\n\n1:02:25.840 --> 1:02:28.840\n to bring something delightful in the hands of customers.\n\n1:02:28.840 --> 1:02:31.200\n So you mentioned the way you kind of think of it\n\n1:02:31.200 --> 1:02:32.680\n in the product way in the future,\n\n1:02:32.680 --> 1:02:35.760\n have a press release and an FAQ and you think backwards.\n\n1:02:35.760 --> 1:02:39.880\n Did you have, did the team have the echo in mind?\n\n1:02:41.000 --> 1:02:43.040\n So this far field speech recognition,\n\n1:02:43.040 --> 1:02:45.360\n actually putting a thing in the home that works,\n\n1:02:45.360 --> 1:02:46.640\n that it's able to interact with,\n\n1:02:46.640 --> 1:02:48.160\n was that the press release?\n\n1:02:48.160 --> 1:02:49.000\n What was the?\n\n1:02:49.000 --> 1:02:51.440\n The way close, I would say, in terms of the,\n\n1:02:51.440 --> 1:02:55.520\n as I said, the vision was start a computer, right?\n\n1:02:55.520 --> 1:02:56.880\n Or the inspiration.\n\n1:02:56.880 --> 1:02:59.120\n And from there, I can't divulge\n\n1:02:59.120 --> 1:03:00.600\n all the exact specifications,\n\n1:03:00.600 --> 1:03:05.600\n but one of the first things that was magical on Alexa\n\n1:03:07.200 --> 1:03:08.800\n was music.\n\n1:03:08.800 --> 1:03:11.160\n It brought me to back to music\n\n1:03:11.160 --> 1:03:14.200\n because my taste was still in when I was an undergrad.\n\n1:03:14.200 --> 1:03:17.400\n So I still listened to those songs and I,\n\n1:03:17.400 --> 1:03:21.400\n it was too hard for me to be a music fan with a phone, right?\n\n1:03:21.400 --> 1:03:24.200\n So I, and I don't, I hate things in my ears.\n\n1:03:24.200 --> 1:03:28.120\n So from that perspective, it was quite hard\n\n1:03:28.120 --> 1:03:30.560\n and music was part of the,\n\n1:03:32.040 --> 1:03:33.640\n at least the documents I have seen, right?\n\n1:03:33.640 --> 1:03:36.120\n So from that perspective, I think, yes,\n\n1:03:36.120 --> 1:03:40.920\n in terms of how far are we from the original vision?\n\n1:03:40.920 --> 1:03:42.400\n I can't reveal that, but it's,\n\n1:03:42.400 --> 1:03:44.520\n that's why I have done a fun at work\n\n1:03:44.520 --> 1:03:47.200\n because every day we go in and thinking like,\n\n1:03:47.200 --> 1:03:49.080\n these are the new set of challenges to solve.\n\n1:03:49.080 --> 1:03:51.920\n Yeah, that's a great way to do great engineering\n\n1:03:51.920 --> 1:03:53.640\n as you think of the press release.\n\n1:03:53.640 --> 1:03:55.040\n I like that idea actually.\n\n1:03:55.040 --> 1:03:56.840\n Maybe we'll talk about it a bit later,\n\n1:03:56.840 --> 1:03:59.280\n but it's just a super nice way to have a focus.\n\n1:03:59.280 --> 1:04:01.400\n I'll tell you this, you're a scientist\n\n1:04:01.400 --> 1:04:03.760\n and a lot of my scientists have adopted that.\n\n1:04:03.760 --> 1:04:07.000\n They have now, they love it as a process\n\n1:04:07.000 --> 1:04:09.000\n because it was very, as scientists,\n\n1:04:09.000 --> 1:04:10.960\n you're trained to write great papers,\n\n1:04:10.960 --> 1:04:13.520\n but they are all after you've done the research\n\n1:04:13.520 --> 1:04:16.640\n or you've proven that and your PhD dissertation proposal\n\n1:04:16.640 --> 1:04:18.480\n is something that comes closest\n\n1:04:18.480 --> 1:04:21.200\n or a DARPA proposal or a NSF proposal\n\n1:04:21.200 --> 1:04:23.640\n is the closest that comes to a press release.\n\n1:04:23.640 --> 1:04:27.040\n But that process is now ingrained in our scientists,\n\n1:04:27.040 --> 1:04:29.840\n which is like delightful for me to see.\n\n1:04:30.960 --> 1:04:33.080\n You write the paper first and then make it happen.\n\n1:04:33.080 --> 1:04:33.920\n That's right.\n\n1:04:33.920 --> 1:04:34.760\n In fact, it's not.\n\n1:04:34.760 --> 1:04:36.320\n State of the art results.\n\n1:04:36.320 --> 1:04:38.480\n Or you leave the results section open\n\n1:04:38.480 --> 1:04:41.680\n where you have a thesis about here's what I expect, right?\n\n1:04:41.680 --> 1:04:44.960\n And here's what it will change, right?\n\n1:04:44.960 --> 1:04:46.560\n So I think it is a great thing.\n\n1:04:46.560 --> 1:04:48.280\n It works for researchers as well.\n\n1:04:48.280 --> 1:04:49.120\n Yeah.\n\n1:04:49.120 --> 1:04:50.760\n So far field recognition.\n\n1:04:50.760 --> 1:04:52.400\n Yeah.\n\n1:04:52.400 --> 1:04:53.920\n What was the big leap?\n\n1:04:53.920 --> 1:04:55.520\n What were the breakthroughs\n\n1:04:55.520 --> 1:04:58.440\n and what was that journey like to today?\n\n1:04:58.440 --> 1:05:00.240\n Yeah, I think the, as you said first,\n\n1:05:00.240 --> 1:05:01.640\n there was a lot of skepticism\n\n1:05:01.640 --> 1:05:03.400\n on whether far field speech recognition\n\n1:05:03.400 --> 1:05:06.560\n will ever work to be good enough, right?\n\n1:05:06.560 --> 1:05:10.040\n And what we first did was got a lot of training data\n\n1:05:10.040 --> 1:05:11.520\n in a far field setting.\n\n1:05:11.520 --> 1:05:14.080\n And that was extremely hard to get\n\n1:05:14.080 --> 1:05:16.240\n because none of it existed.\n\n1:05:16.240 --> 1:05:20.120\n So how do you collect data in far field setup, right?\n\n1:05:20.120 --> 1:05:21.400\n With no customer base at this time.\n\n1:05:21.400 --> 1:05:22.720\n With no customer base, right?\n\n1:05:22.720 --> 1:05:24.840\n So that was first innovation.\n\n1:05:24.840 --> 1:05:27.040\n And once we had that, the next thing was,\n\n1:05:27.040 --> 1:05:29.760\n okay, if you have the data,\n\n1:05:29.760 --> 1:05:31.920\n first of all, we didn't talk about like,\n\n1:05:31.920 --> 1:05:35.320\n what would magical mean in this kind of a setting?\n\n1:05:35.320 --> 1:05:37.520\n What is good enough for customers, right?\n\n1:05:37.520 --> 1:05:40.480\n That's always, since you've never done this before,\n\n1:05:40.480 --> 1:05:41.680\n what would be magical?\n\n1:05:41.680 --> 1:05:44.280\n So it wasn't just a research problem.\n\n1:05:44.280 --> 1:05:47.720\n You had to put some in terms of accuracy\n\n1:05:47.720 --> 1:05:49.960\n and customer experience features,\n\n1:05:49.960 --> 1:05:51.560\n some stakes on the ground saying,\n\n1:05:51.560 --> 1:05:55.000\n here's where I think it should get to.\n\n1:05:55.000 --> 1:05:56.120\n So you established a bar\n\n1:05:56.120 --> 1:05:57.520\n and then how do you measure progress\n\n1:05:57.520 --> 1:06:01.800\n towards given you have no customer right now.\n\n1:06:01.800 --> 1:06:04.240\n So from that perspective, we went,\n\n1:06:04.240 --> 1:06:07.600\n so first was the data without customers.\n\n1:06:07.600 --> 1:06:10.600\n Second was doubling down on deep learning\n\n1:06:10.600 --> 1:06:11.960\n as a way to learn.\n\n1:06:11.960 --> 1:06:16.200\n And I can just tell you that the combination of the two\n\n1:06:16.200 --> 1:06:19.240\n got our error rates by a factor of five.\n\n1:06:19.240 --> 1:06:21.440\n From where we were when I started\n\n1:06:21.440 --> 1:06:24.360\n to within six months of having that data,\n\n1:06:24.360 --> 1:06:28.440\n we, at that point, I got the conviction\n\n1:06:28.440 --> 1:06:29.960\n that this will work, right?\n\n1:06:29.960 --> 1:06:31.680\n So, because that was magical\n\n1:06:31.680 --> 1:06:34.760\n in terms of when it started working and.\n\n1:06:34.760 --> 1:06:36.280\n That reached the magical bar.\n\n1:06:36.280 --> 1:06:38.000\n That came close to the magical bar.\n\n1:06:38.000 --> 1:06:39.560\n To the bar, right?\n\n1:06:39.560 --> 1:06:44.280\n That we felt would be where people will use it.\n\n1:06:44.280 --> 1:06:45.360\n That was critical.\n\n1:06:45.360 --> 1:06:48.880\n Because you really have one chance at this.\n\n1:06:48.880 --> 1:06:51.920\n If we had launched in November 2014 is when we launched,\n\n1:06:51.920 --> 1:06:53.160\n if it was below the bar,\n\n1:06:53.160 --> 1:06:56.520\n I don't think this category exists\n\n1:06:56.520 --> 1:06:58.120\n if you don't meet the bar.\n\n1:06:58.120 --> 1:07:02.080\n Yeah, and just having looked at voice based interactions\n\n1:07:02.080 --> 1:07:06.120\n like in the car or earlier systems,\n\n1:07:06.120 --> 1:07:08.320\n it's a source of huge frustration for people.\n\n1:07:08.320 --> 1:07:10.280\n In fact, we use voice based interaction\n\n1:07:10.280 --> 1:07:14.600\n for collecting data on subjects to measure frustration.\n\n1:07:14.600 --> 1:07:16.560\n So, as a training set for computer vision,\n\n1:07:16.560 --> 1:07:19.360\n for face data, so we can get a data set\n\n1:07:19.360 --> 1:07:20.600\n of frustrated people.\n\n1:07:20.600 --> 1:07:22.240\n That's the best way to get frustrated people\n\n1:07:22.240 --> 1:07:24.840\n is having them interact with a voice based system\n\n1:07:24.840 --> 1:07:25.680\n in the car.\n\n1:07:25.680 --> 1:07:28.520\n So, that bar I imagine is pretty high.\n\n1:07:28.520 --> 1:07:29.480\n It was very high.\n\n1:07:29.480 --> 1:07:32.720\n And we talked about how also errors are perceived\n\n1:07:32.720 --> 1:07:35.400\n from AIs versus errors by humans.\n\n1:07:35.400 --> 1:07:38.320\n But we are not done with the problems that ended up,\n\n1:07:38.320 --> 1:07:39.800\n we had to solve to get it to launch.\n\n1:07:39.800 --> 1:07:41.280\n So, do you want the next one?\n\n1:07:41.280 --> 1:07:42.680\n Yeah, the next one.\n\n1:07:42.680 --> 1:07:47.680\n So, the next one was what I think of as\n\n1:07:47.680 --> 1:07:50.960\n multi domain natural language understanding.\n\n1:07:50.960 --> 1:07:53.200\n It's very, I wouldn't say easy,\n\n1:07:53.200 --> 1:07:56.160\n but it is during those days,\n\n1:07:56.160 --> 1:07:59.720\n solving it, understanding in one domain,\n\n1:07:59.720 --> 1:08:02.880\n a narrow domain was doable,\n\n1:08:02.880 --> 1:08:06.880\n but for these multiple domains like music,\n\n1:08:06.880 --> 1:08:10.680\n like information, other kinds of household productivity,\n\n1:08:10.680 --> 1:08:14.160\n alarms, timers, even though it wasn't as big as it is\n\n1:08:14.160 --> 1:08:15.640\n in terms of the number of skills Alexa has\n\n1:08:15.640 --> 1:08:17.480\n and the confusion space has like grown\n\n1:08:17.480 --> 1:08:20.680\n by three orders of magnitude,\n\n1:08:20.680 --> 1:08:22.680\n it was still daunting even those days.\n\n1:08:22.680 --> 1:08:24.640\n And again, no customer base yet.\n\n1:08:24.640 --> 1:08:26.200\n Again, no customer base.\n\n1:08:26.200 --> 1:08:28.200\n So, now you're looking at meaning understanding\n\n1:08:28.200 --> 1:08:30.120\n and intent understanding and taking actions\n\n1:08:30.120 --> 1:08:31.640\n on behalf of customers.\n\n1:08:31.640 --> 1:08:33.440\n Based on their requests.\n\n1:08:33.440 --> 1:08:36.440\n And that is the next hard problem.\n\n1:08:36.440 --> 1:08:39.960\n Even if you have gotten the words recognized,\n\n1:08:39.960 --> 1:08:41.640\n how do you make sense of them?\n\n1:08:42.520 --> 1:08:47.520\n In those days, there was still a lot of emphasis\n\n1:08:47.520 --> 1:08:50.760\n on rule based systems for writing grammar patterns\n\n1:08:50.760 --> 1:08:52.360\n to understand the intent.\n\n1:08:52.360 --> 1:08:55.560\n But we had a statistical first approach even then,\n\n1:08:55.560 --> 1:08:58.240\n where for our language understanding we had,\n\n1:08:58.240 --> 1:09:00.200\n and even those starting days,\n\n1:09:00.200 --> 1:09:03.520\n an entity recognizer and an intent classifier,\n\n1:09:03.520 --> 1:09:06.080\n which was all trained statistically.\n\n1:09:06.080 --> 1:09:09.400\n In fact, we had to build the deterministic matching\n\n1:09:09.400 --> 1:09:14.400\n as a follow up to fix bugs that statistical models have.\n\n1:09:14.400 --> 1:09:16.320\n So, it was just a different mindset\n\n1:09:16.320 --> 1:09:20.080\n where we focused on data driven statistical understanding.\n\n1:09:20.080 --> 1:09:22.720\n It wins in the end if you have a huge data set.\n\n1:09:22.720 --> 1:09:24.520\n Yes, it is contingent on that.\n\n1:09:24.520 --> 1:09:27.120\n And that's why it came back to how do you get the data.\n\n1:09:27.120 --> 1:09:30.360\n Before customers, the fact that this is why data\n\n1:09:30.360 --> 1:09:33.280\n becomes crucial to get to the point\n\n1:09:33.280 --> 1:09:37.840\n that you have the understanding system built up.\n\n1:09:37.840 --> 1:09:40.680\n And notice that for you,\n\n1:09:40.680 --> 1:09:42.480\n we were talking about human machine dialogue,\n\n1:09:42.480 --> 1:09:44.800\n and even those early days,\n\n1:09:44.800 --> 1:09:47.120\n even it was very much transactional,\n\n1:09:47.120 --> 1:09:50.560\n do one thing, one shot utterances in great way.\n\n1:09:50.560 --> 1:09:52.840\n There was a lot of debate on how much should Alexa talk back\n\n1:09:52.840 --> 1:09:55.680\n in terms of if you misunderstood it.\n\n1:09:55.680 --> 1:10:01.440\n If you misunderstood you or you said play songs by the stones,\n\n1:10:01.440 --> 1:10:04.760\n and let's say it doesn't know early days,\n\n1:10:04.760 --> 1:10:09.240\n knowledge can be sparse, who are the stones?\n\n1:10:09.240 --> 1:10:12.760\n It's the Rolling Stones.\n\n1:10:12.760 --> 1:10:16.280\n And you don't want the match to be Stone Temple Pilots\n\n1:10:16.280 --> 1:10:17.200\n or Rolling Stones.\n\n1:10:17.200 --> 1:10:18.840\n So, you don't know which one it is.\n\n1:10:18.840 --> 1:10:22.480\n So, these kind of other signals,\n\n1:10:22.480 --> 1:10:27.040\n now there we had great assets from Amazon in terms of...\n\n1:10:27.040 --> 1:10:29.560\n UX, like what is it, what kind of...\n\n1:10:29.560 --> 1:10:31.200\n Yeah, how do you solve that problem?\n\n1:10:31.200 --> 1:10:32.280\n In terms of what we think of it\n\n1:10:32.280 --> 1:10:34.000\n as an entity resolution problem, right?\n\n1:10:34.000 --> 1:10:36.200\n So, because which one is it, right?\n\n1:10:36.200 --> 1:10:40.160\n I mean, even if you figured out the stones as an entity,\n\n1:10:40.160 --> 1:10:42.200\n you have to resolve it to whether it's the stones\n\n1:10:42.200 --> 1:10:44.840\n or the Stone Temple Pilots or some other stones.\n\n1:10:44.840 --> 1:10:47.080\n Maybe I misunderstood, is the resolution\n\n1:10:47.080 --> 1:10:50.520\n the job of the algorithm or is the job of UX\n\n1:10:50.520 --> 1:10:52.320\n communicating with the human to help the resolution?\n\n1:10:52.320 --> 1:10:54.240\n Well, there is both, right?\n\n1:10:54.240 --> 1:10:58.760\n It is, you want 90% or high 90s to be done\n\n1:10:58.760 --> 1:11:01.200\n without any further questioning or UX, right?\n\n1:11:01.200 --> 1:11:05.560\n So, but it's absolutely okay, just like as humans,\n\n1:11:05.560 --> 1:11:09.000\n we ask the question, I didn't understand you, Lex.\n\n1:11:09.000 --> 1:11:10.640\n It's fine for Alexa to occasionally say,\n\n1:11:10.640 --> 1:11:12.080\n I did not understand you, right?\n\n1:11:12.080 --> 1:11:14.640\n And that's an important way to learn.\n\n1:11:14.640 --> 1:11:16.240\n And I'll talk about where we have come\n\n1:11:16.240 --> 1:11:20.080\n with more self learning with these kind of feedback signals.\n\n1:11:20.080 --> 1:11:23.240\n But in those days, just solving the ability\n\n1:11:23.240 --> 1:11:26.480\n of understanding the intent and resolving to an action\n\n1:11:26.480 --> 1:11:28.760\n where action could be play a particular artist\n\n1:11:28.760 --> 1:11:31.960\n or a particular song was super hard.\n\n1:11:31.960 --> 1:11:35.400\n Again, the bar was high as we were talking about, right?\n\n1:11:35.400 --> 1:11:40.240\n So, while we launched it in sort of 13 big domains,\n\n1:11:40.240 --> 1:11:42.360\n I would say in terms of,\n\n1:11:42.360 --> 1:11:44.760\n we think of it as 13, the big skills we had,\n\n1:11:44.760 --> 1:11:47.720\n like music is a massive one when we launched it.\n\n1:11:47.720 --> 1:11:51.480\n And now we have 90,000 plus skills on Alexa.\n\n1:11:51.480 --> 1:11:52.640\n So, what are the big skills?\n\n1:11:52.640 --> 1:11:53.480\n Can you just go over them?\n\n1:11:53.480 --> 1:11:55.480\n Because the only thing I use it for\n\n1:11:55.480 --> 1:11:57.640\n is music, weather and shopping.\n\n1:11:58.840 --> 1:12:02.520\n So, we think of it as music information, right?\n\n1:12:02.520 --> 1:12:05.360\n So, weather is a part of information, right?\n\n1:12:05.360 --> 1:12:08.000\n So, when we launched, we didn't have smart home,\n\n1:12:08.000 --> 1:12:10.360\n but within, by smart home I mean,\n\n1:12:10.360 --> 1:12:12.040\n you connect your smart devices,\n\n1:12:12.040 --> 1:12:13.080\n you control them with voice.\n\n1:12:13.080 --> 1:12:15.000\n If you haven't done it, it's worth,\n\n1:12:15.000 --> 1:12:15.840\n it will change your life.\n\n1:12:15.840 --> 1:12:16.680\n Like turning on the lights and so on.\n\n1:12:16.680 --> 1:12:20.200\n Turning on your light to anything that's connected\n\n1:12:20.200 --> 1:12:21.480\n and has a, it's just that.\n\n1:12:21.480 --> 1:12:23.160\n What's your favorite smart device for you?\n\n1:12:23.160 --> 1:12:24.000\n My light.\n\n1:12:24.000 --> 1:12:24.840\n Light.\n\n1:12:24.840 --> 1:12:26.320\n And now you have the smart plug with,\n\n1:12:26.320 --> 1:12:29.880\n and you don't, we also have this echo plug, which is.\n\n1:12:29.880 --> 1:12:30.720\n Oh yeah, you can plug in anything.\n\n1:12:30.720 --> 1:12:31.560\n You can plug in anything\n\n1:12:31.560 --> 1:12:33.560\n and now you can turn that one on and off.\n\n1:12:33.560 --> 1:12:35.680\n I use this conversation motivation to get one.\n\n1:12:35.680 --> 1:12:39.560\n Garage door, you can check your status of the garage door\n\n1:12:39.560 --> 1:12:41.200\n and things like, and we have gone,\n\n1:12:41.200 --> 1:12:43.200\n make Alexa more and more proactive,\n\n1:12:43.200 --> 1:12:45.120\n where it even has hunches now,\n\n1:12:45.120 --> 1:12:49.160\n that, oh, looks, hunches, like you left your light on.\n\n1:12:50.520 --> 1:12:51.640\n Let's say you've gone to your bed\n\n1:12:51.640 --> 1:12:52.880\n and you left the garage light on.\n\n1:12:52.880 --> 1:12:56.600\n So it will help you out in these settings, right?\n\n1:12:56.600 --> 1:13:00.160\n That's smart devices, information, smart devices.\n\n1:13:00.160 --> 1:13:01.120\n You said music.\n\n1:13:01.120 --> 1:13:02.960\n Yeah, so I don't remember everything we had,\n\n1:13:02.960 --> 1:13:05.040\n but alarms, timers were the big ones.\n\n1:13:05.040 --> 1:13:06.680\n Like that was, you know,\n\n1:13:06.680 --> 1:13:09.520\n the timers were very popular right away.\n\n1:13:09.520 --> 1:13:13.440\n Music also, like you could play song, artist, album,\n\n1:13:13.440 --> 1:13:17.000\n everything, and so that was like a clear win\n\n1:13:17.000 --> 1:13:19.440\n in terms of the customer experience.\n\n1:13:19.440 --> 1:13:22.760\n So that's, again, this is language understanding.\n\n1:13:22.760 --> 1:13:24.080\n Now things have evolved, right?\n\n1:13:24.080 --> 1:13:28.360\n So where we want Alexa definitely to be more accurate,\n\n1:13:28.360 --> 1:13:29.800\n competent, trustworthy,\n\n1:13:29.800 --> 1:13:33.080\n based on how well it does these core things,\n\n1:13:33.080 --> 1:13:35.240\n but we have evolved in many different dimensions.\n\n1:13:35.240 --> 1:13:38.360\n First is what I think of are doing more conversational\n\n1:13:38.360 --> 1:13:40.920\n for high utility, not just for chat, right?\n\n1:13:40.920 --> 1:13:44.920\n And there at Remars this year, which is our AI conference,\n\n1:13:44.920 --> 1:13:48.560\n we launched what is called Alexa Conversations.\n\n1:13:48.560 --> 1:13:51.800\n That is providing the ability for developers\n\n1:13:51.800 --> 1:13:55.040\n to author multi turn experiences on Alexa\n\n1:13:55.040 --> 1:13:57.080\n with no code, essentially,\n\n1:13:57.080 --> 1:13:58.880\n in terms of the dialogue code.\n\n1:13:58.880 --> 1:14:02.600\n Initially it was like, you know, all these IVR systems,\n\n1:14:02.600 --> 1:14:06.560\n you have to fully author if the customer says this,\n\n1:14:06.560 --> 1:14:07.560\n do that, right?\n\n1:14:07.560 --> 1:14:11.440\n So the whole dialogue flow is hand authored.\n\n1:14:11.440 --> 1:14:13.640\n And with Alexa Conversations,\n\n1:14:13.640 --> 1:14:15.440\n the way it is that you just provide\n\n1:14:15.440 --> 1:14:18.040\n a sample interaction data with your service or your API,\n\n1:14:18.040 --> 1:14:21.400\n let's say your Atom tickets that provides a service\n\n1:14:21.400 --> 1:14:23.400\n for buying movie tickets.\n\n1:14:23.400 --> 1:14:25.840\n You provide a few examples of how your customers\n\n1:14:25.840 --> 1:14:27.840\n will interact with your APIs.\n\n1:14:27.840 --> 1:14:29.960\n And then the dialogue flow is automatically constructed\n\n1:14:29.960 --> 1:14:33.360\n using a record neural network trained on that data.\n\n1:14:33.360 --> 1:14:35.920\n So that simplifies the developer experience.\n\n1:14:35.920 --> 1:14:38.440\n We just launched our preview for the developers\n\n1:14:38.440 --> 1:14:40.600\n to try this capability out.\n\n1:14:40.600 --> 1:14:42.120\n And then the second part of it,\n\n1:14:42.120 --> 1:14:45.680\n which shows even increased utility for customers\n\n1:14:45.680 --> 1:14:49.960\n is you and I, when we interact with Alexa or any customer,\n\n1:14:50.920 --> 1:14:53.160\n as I'm coming back to our initial part of the conversation,\n\n1:14:53.160 --> 1:14:58.160\n the goal is often unclear or unknown to the AI.\n\n1:14:58.960 --> 1:15:02.680\n If I say, Alexa, what movies are playing nearby?\n\n1:15:02.680 --> 1:15:07.080\n Am I trying to just buy movie tickets?\n\n1:15:07.080 --> 1:15:09.120\n Am I actually even,\n\n1:15:09.120 --> 1:15:12.040\n do you think I'm looking for just movies for curiosity,\n\n1:15:12.040 --> 1:15:15.120\n whether the Avengers is still in theater or when is it?\n\n1:15:15.120 --> 1:15:17.640\n Maybe it's gone and maybe it will come on my missed it.\n\n1:15:17.640 --> 1:15:20.680\n So I may watch it on Prime, right?\n\n1:15:20.680 --> 1:15:21.920\n Which happened to me.\n\n1:15:21.920 --> 1:15:24.680\n So from that perspective now,\n\n1:15:24.680 --> 1:15:27.680\n you're looking into what is my goal?\n\n1:15:27.680 --> 1:15:31.480\n And let's say I now complete the movie ticket purchase.\n\n1:15:31.480 --> 1:15:34.080\n Maybe I would like to get dinner nearby.\n\n1:15:35.760 --> 1:15:38.680\n So what is really the goal here?\n\n1:15:38.680 --> 1:15:41.920\n Is it night out or is it movies?\n\n1:15:41.920 --> 1:15:44.040\n As in just go watch a movie?\n\n1:15:44.040 --> 1:15:46.240\n The answer is, we don't know.\n\n1:15:46.240 --> 1:15:50.720\n So can Alexa now figuratively have the intelligence\n\n1:15:50.720 --> 1:15:53.760\n that I think this meta goal is really night out\n\n1:15:53.760 --> 1:15:55.800\n or at least say to the customer\n\n1:15:55.800 --> 1:15:58.200\n when you've completed the purchase of movie tickets\n\n1:15:58.200 --> 1:16:00.320\n from Atom tickets or Fandango,\n\n1:16:00.320 --> 1:16:01.840\n or pick your anyone.\n\n1:16:01.840 --> 1:16:02.880\n Then the next thing is,\n\n1:16:02.880 --> 1:16:07.880\n do you want to get an Uber to the theater, right?\n\n1:16:09.360 --> 1:16:12.880\n Or do you want to book a restaurant next to it?\n\n1:16:12.880 --> 1:16:17.560\n And then not ask the same information over and over again,\n\n1:16:17.560 --> 1:16:22.560\n what time, how many people in your party, right?\n\n1:16:22.560 --> 1:16:26.560\n So this is where you shift the cognitive burden\n\n1:16:26.560 --> 1:16:29.000\n from the customer to the AI.\n\n1:16:29.000 --> 1:16:32.120\n Where it's thinking of what is your,\n\n1:16:32.120 --> 1:16:34.200\n it anticipates your goal\n\n1:16:34.200 --> 1:16:37.480\n and takes the next best action to complete it.\n\n1:16:37.480 --> 1:16:39.760\n Now that's the machine learning problem.\n\n1:16:40.760 --> 1:16:43.760\n But essentially the way we solve this first instance,\n\n1:16:43.760 --> 1:16:46.800\n and we have a long way to go to make it scale\n\n1:16:46.800 --> 1:16:48.720\n to everything possible in the world.\n\n1:16:48.720 --> 1:16:50.160\n But at least for this situation,\n\n1:16:50.160 --> 1:16:53.000\n it is from at every instance,\n\n1:16:53.000 --> 1:16:54.600\n Alexa is making the determination,\n\n1:16:54.600 --> 1:16:56.240\n whether it should stick with the experience\n\n1:16:56.240 --> 1:16:58.600\n with Atom tickets or not.\n\n1:16:58.600 --> 1:17:03.600\n Or offer you based on what you say,\n\n1:17:03.800 --> 1:17:06.280\n whether either you have completed the interaction,\n\n1:17:06.280 --> 1:17:07.760\n or you said, no, get me an Uber now.\n\n1:17:07.760 --> 1:17:12.080\n So it will shift context into another experience or skill\n\n1:17:12.080 --> 1:17:12.920\n or another service.\n\n1:17:12.920 --> 1:17:15.360\n So that's a dynamic decision making.\n\n1:17:15.360 --> 1:17:18.160\n That's making Alexa, you can say more conversational\n\n1:17:18.160 --> 1:17:20.200\n for the benefit of the customer,\n\n1:17:20.200 --> 1:17:22.520\n rather than simply complete transactions,\n\n1:17:22.520 --> 1:17:24.360\n which are well thought through.\n\n1:17:24.360 --> 1:17:27.840\n You as a customer has fully specified\n\n1:17:27.840 --> 1:17:29.680\n what you want to be accomplished.\n\n1:17:29.680 --> 1:17:30.840\n It's accomplishing that.\n\n1:17:30.840 --> 1:17:34.080\n So it's kind of as we do this with pedestrians,\n\n1:17:34.080 --> 1:17:36.840\n like intent modeling is predicting\n\n1:17:36.840 --> 1:17:40.040\n what your possible goals are and what's the most likely goal\n\n1:17:40.040 --> 1:17:42.440\n and switching that depending on the things you say.\n\n1:17:42.440 --> 1:17:44.440\n So my question is there,\n\n1:17:44.440 --> 1:17:46.520\n it seems maybe it's a dumb question,\n\n1:17:46.520 --> 1:17:51.400\n but it would help a lot if Alexa remembered me,\n\n1:17:51.400 --> 1:17:53.040\n what I said previously.\n\n1:17:53.040 --> 1:17:53.880\n Right.\n\n1:17:53.880 --> 1:17:58.360\n Is it trying to use some memories for the customer?\n\n1:17:58.360 --> 1:18:00.680\n Yeah, it is using a lot of memory within that.\n\n1:18:00.680 --> 1:18:02.560\n So right now, not so much in terms of,\n\n1:18:02.560 --> 1:18:05.280\n okay, which restaurant do you prefer, right?\n\n1:18:05.280 --> 1:18:06.680\n That is a more longterm memory,\n\n1:18:06.680 --> 1:18:09.720\n but within the short term memory, within the session,\n\n1:18:09.720 --> 1:18:11.720\n it is remembering how many people did you,\n\n1:18:11.720 --> 1:18:13.720\n so if you said buy four tickets,\n\n1:18:13.720 --> 1:18:15.560\n now it has made an implicit assumption\n\n1:18:15.560 --> 1:18:18.200\n that you were gonna have,\n\n1:18:18.200 --> 1:18:21.640\n you need at least four seats at a restaurant, right?\n\n1:18:21.640 --> 1:18:24.200\n So these are the kind of context it's preserving\n\n1:18:24.200 --> 1:18:26.720\n between these skills, but within that session.\n\n1:18:26.720 --> 1:18:28.000\n But you're asking the right question\n\n1:18:28.000 --> 1:18:32.040\n in terms of for it to be more and more useful,\n\n1:18:32.040 --> 1:18:33.680\n it has to have more longterm memory\n\n1:18:33.680 --> 1:18:35.120\n and that's also an open question\n\n1:18:35.120 --> 1:18:37.400\n and again, these are still early days.\n\n1:18:37.400 --> 1:18:40.240\n So for me, I mean, everybody's different,\n\n1:18:40.240 --> 1:18:43.920\n but yeah, I'm definitely not representative\n\n1:18:43.920 --> 1:18:45.240\n of the general population in the sense\n\n1:18:45.240 --> 1:18:47.800\n that I do the same thing every day.\n\n1:18:47.800 --> 1:18:48.640\n Like I eat the same,\n\n1:18:48.640 --> 1:18:51.760\n I do everything the same, the same thing,\n\n1:18:51.760 --> 1:18:55.360\n wear the same thing clearly, this or the black shirt.\n\n1:18:55.360 --> 1:18:59.000\n So it's frustrating when Alexa doesn't get what I'm saying\n\n1:18:59.000 --> 1:19:01.920\n because I have to correct her every time\n\n1:19:01.920 --> 1:19:02.800\n in the exact same way.\n\n1:19:02.800 --> 1:19:05.480\n This has to do with certain songs,\n\n1:19:05.480 --> 1:19:08.240\n like she doesn't know certain weird songs I like\n\n1:19:08.240 --> 1:19:11.240\n and doesn't know, I've complained to Spotify about this,\n\n1:19:11.240 --> 1:19:13.840\n talked to the RD, head of RD at Spotify,\n\n1:19:13.840 --> 1:19:15.040\n it's their way to heaven.\n\n1:19:15.040 --> 1:19:16.280\n I have to correct it every time.\n\n1:19:16.280 --> 1:19:18.720\n It doesn't play Led Zeppelin correctly.\n\n1:19:18.720 --> 1:19:22.080\n It plays cover of Led's of Stairway to Heaven.\n\n1:19:22.080 --> 1:19:22.920\n So I'm.\n\n1:19:22.920 --> 1:19:24.920\n You should figure, you should send me your,\n\n1:19:24.920 --> 1:19:27.480\n next time it fails, feel free to send it to me,\n\n1:19:27.480 --> 1:19:28.400\n we'll take care of it.\n\n1:19:28.400 --> 1:19:29.240\n Okay, well.\n\n1:19:29.240 --> 1:19:31.720\n Because Led Zeppelin is one of my favorite brands,\n\n1:19:31.720 --> 1:19:34.120\n it works for me, so I'm like shocked it doesn't work for you.\n\n1:19:34.120 --> 1:19:35.440\n This is an official bug report.\n\n1:19:35.440 --> 1:19:37.480\n I'll put it, I'll make it public,\n\n1:19:37.480 --> 1:19:39.000\n I'll make everybody retweet it.\n\n1:19:39.000 --> 1:19:40.960\n We're gonna fix the Stairway to Heaven problem.\n\n1:19:40.960 --> 1:19:43.200\n Anyway, but the point is,\n\n1:19:43.200 --> 1:19:45.120\n you know, I'm pretty boring and do the same things,\n\n1:19:45.120 --> 1:19:48.320\n but I'm sure most people do the same set of things.\n\n1:19:48.320 --> 1:19:51.360\n Do you see Alexa sort of utilizing that in the future\n\n1:19:51.360 --> 1:19:52.760\n for improving the experience?\n\n1:19:52.760 --> 1:19:54.680\n Yes, and not only utilizing,\n\n1:19:54.680 --> 1:19:56.200\n it's already doing some of it.\n\n1:19:56.200 --> 1:19:59.520\n We call it, where Alexa is becoming more self learning.\n\n1:19:59.520 --> 1:20:04.360\n So, Alexa is now auto correcting millions and millions\n\n1:20:04.360 --> 1:20:06.360\n of utterances in the US\n\n1:20:06.360 --> 1:20:08.720\n without any human supervision involved.\n\n1:20:08.720 --> 1:20:10.840\n The way it does it is,\n\n1:20:10.840 --> 1:20:13.320\n let's take an example of a particular song\n\n1:20:13.320 --> 1:20:14.720\n didn't work for you.\n\n1:20:14.720 --> 1:20:15.680\n What do you do next?\n\n1:20:15.680 --> 1:20:17.840\n You either it played the wrong song\n\n1:20:17.840 --> 1:20:20.720\n and you said, Alexa, no, that's not the song I want.\n\n1:20:20.720 --> 1:20:25.160\n Or you say, Alexa play that, you try it again.\n\n1:20:25.160 --> 1:20:27.440\n And that is a signal to Alexa\n\n1:20:27.440 --> 1:20:30.080\n that she may have done something wrong.\n\n1:20:30.080 --> 1:20:31.840\n And from that perspective,\n\n1:20:31.840 --> 1:20:35.200\n we can learn if there's that failure pattern\n\n1:20:35.200 --> 1:20:38.480\n or that action of song A was played\n\n1:20:38.480 --> 1:20:41.000\n when song B was requested.\n\n1:20:41.000 --> 1:20:43.040\n And it's very common with station names\n\n1:20:43.040 --> 1:20:47.160\n because play NPR, you can have N be confused as an M.\n\n1:20:47.160 --> 1:20:50.920\n And then you, for a certain accent like mine,\n\n1:20:51.840 --> 1:20:54.720\n people confuse my N and M all the time.\n\n1:20:54.720 --> 1:20:57.640\n And because I have a Indian accent,\n\n1:20:57.640 --> 1:20:59.600\n they're confusable to humans.\n\n1:20:59.600 --> 1:21:01.600\n It is for Alexa too.\n\n1:21:01.600 --> 1:21:05.080\n And in that part, but it starts auto correcting\n\n1:21:05.080 --> 1:21:09.680\n and we collect, we correct a lot of these automatically\n\n1:21:09.680 --> 1:21:12.680\n without a human looking at the failures.\n\n1:21:12.680 --> 1:21:17.360\n So one of the things that's for me missing in Alexa,\n\n1:21:17.360 --> 1:21:19.720\n I don't know if I'm a representative customer,\n\n1:21:19.720 --> 1:21:22.920\n but every time I correct it,\n\n1:21:22.920 --> 1:21:26.120\n it would be nice to know that that made a difference.\n\n1:21:26.120 --> 1:21:26.960\n Yes.\n\n1:21:26.960 --> 1:21:27.800\n You know what I mean?\n\n1:21:27.800 --> 1:21:31.880\n Like the sort of like, I heard you like a sort of.\n\n1:21:31.880 --> 1:21:33.840\n Some acknowledgement of that.\n\n1:21:33.840 --> 1:21:37.440\n We work a lot with Tesla, we study autopilot and so on.\n\n1:21:37.440 --> 1:21:39.240\n And a large amount of the customers\n\n1:21:39.240 --> 1:21:40.720\n that use Tesla autopilot,\n\n1:21:40.720 --> 1:21:43.000\n they feel like they're always teaching the system.\n\n1:21:43.000 --> 1:21:43.840\n They're almost excited\n\n1:21:43.840 --> 1:21:45.080\n by the possibility that they're teaching.\n\n1:21:45.080 --> 1:21:48.440\n I don't know if Alexa customers generally think of it\n\n1:21:48.440 --> 1:21:51.160\n as they're teaching to improve the system.\n\n1:21:51.160 --> 1:21:52.680\n And that's a really powerful thing.\n\n1:21:52.680 --> 1:21:55.200\n Again, I would say it's a spectrum.\n\n1:21:55.200 --> 1:21:57.320\n Some customers do think that way\n\n1:21:57.320 --> 1:22:01.320\n and some would be annoyed by Alexa acknowledging that.\n\n1:22:02.320 --> 1:22:04.360\n So there's, again, no one,\n\n1:22:04.360 --> 1:22:05.760\n while there are certain patterns,\n\n1:22:05.760 --> 1:22:08.280\n not everyone is the same in this way.\n\n1:22:08.280 --> 1:22:13.280\n But we believe that, again, customers helping Alexa\n\n1:22:13.680 --> 1:22:15.720\n is a tenet for us in terms of improving it.\n\n1:22:15.720 --> 1:22:18.280\n And some more self learning is by, again,\n\n1:22:18.280 --> 1:22:20.120\n this is like fully unsupervised, right?\n\n1:22:20.120 --> 1:22:23.600\n There is no human in the loop and no labeling happening.\n\n1:22:23.600 --> 1:22:27.120\n And based on your actions as a customer,\n\n1:22:27.120 --> 1:22:29.080\n Alexa becomes smarter.\n\n1:22:29.080 --> 1:22:31.160\n Again, it's early days,\n\n1:22:31.160 --> 1:22:35.840\n but I think this whole area of teachable AI\n\n1:22:35.840 --> 1:22:38.680\n is gonna get bigger and bigger in the whole space,\n\n1:22:38.680 --> 1:22:40.760\n especially in the AI assistant space.\n\n1:22:40.760 --> 1:22:41.920\n So that's the second part\n\n1:22:41.920 --> 1:22:44.800\n where I mentioned more conversational.\n\n1:22:44.800 --> 1:22:46.520\n This is more self learning.\n\n1:22:46.520 --> 1:22:48.320\n The third is more natural.\n\n1:22:48.320 --> 1:22:50.240\n And the way I think of more natural\n\n1:22:50.240 --> 1:22:53.240\n is we talked about how Alexa sounds.\n\n1:22:53.240 --> 1:22:58.080\n And we have done a lot of advances in our text to speech\n\n1:22:58.080 --> 1:23:00.480\n by using, again, neural network technology\n\n1:23:00.480 --> 1:23:03.520\n for it to sound very humanlike.\n\n1:23:03.520 --> 1:23:07.520\n From the individual texture of the sound to the timing,\n\n1:23:07.520 --> 1:23:09.240\n the tonality, the tone, everything, the whole thing.\n\n1:23:09.240 --> 1:23:11.000\n I would think in terms of,\n\n1:23:11.000 --> 1:23:13.360\n there's a lot of controls in each of the places\n\n1:23:13.360 --> 1:23:16.640\n for how, I mean, the speed of the voice,\n\n1:23:16.640 --> 1:23:18.200\n the prosthetic patterns,\n\n1:23:19.520 --> 1:23:23.360\n the actual smoothness of how it sounds,\n\n1:23:23.360 --> 1:23:24.360\n all of those are factored\n\n1:23:24.360 --> 1:23:27.120\n and we do a ton of listening tests to make sure.\n\n1:23:27.120 --> 1:23:30.720\n But naturalness, how it sounds should be very natural.\n\n1:23:30.720 --> 1:23:33.920\n How it understands requests is also very important.\n\n1:23:33.920 --> 1:23:37.120\n And in terms of, we have 95,000 skills.\n\n1:23:37.120 --> 1:23:41.440\n And if we have, imagine that in many of these skills,\n\n1:23:41.440 --> 1:23:43.440\n you have to remember the skill name\n\n1:23:43.440 --> 1:23:48.440\n and say, Alexa, ask the tide skill to tell me X.\n\n1:23:51.120 --> 1:23:52.960\n Now, if you have to remember the skill name,\n\n1:23:52.960 --> 1:23:56.640\n that means the discovery and the interaction is unnatural.\n\n1:23:56.640 --> 1:23:58.120\n And we are trying to solve that\n\n1:23:58.120 --> 1:24:01.680\n by what we think of as, again,\n\n1:24:03.960 --> 1:24:05.680\n you don't have to have the app metaphor here.\n\n1:24:05.680 --> 1:24:07.400\n These are not individual apps, right?\n\n1:24:07.400 --> 1:24:08.360\n Even though they're,\n\n1:24:08.360 --> 1:24:11.400\n so you're not sort of opening one at a time and interacting.\n\n1:24:11.400 --> 1:24:14.000\n So it should be seamless because it's voice.\n\n1:24:14.000 --> 1:24:15.160\n And when it's voice,\n\n1:24:15.160 --> 1:24:17.560\n you have to be able to understand these requests\n\n1:24:17.560 --> 1:24:20.600\n independent of the specificity, like a skill name.\n\n1:24:20.600 --> 1:24:21.640\n And to do that,\n\n1:24:21.640 --> 1:24:22.840\n what we have done is again,\n\n1:24:22.840 --> 1:24:24.440\n built a deep learning based capability\n\n1:24:24.440 --> 1:24:27.040\n where we shortlist a bunch of skills\n\n1:24:27.040 --> 1:24:28.880\n when you say, Alexa, get me a car.\n\n1:24:28.880 --> 1:24:30.080\n And then we figure it out, okay,\n\n1:24:30.080 --> 1:24:33.320\n it's meant for an Uber skill versus a Lyft\n\n1:24:33.320 --> 1:24:34.880\n or based on your preferences.\n\n1:24:34.880 --> 1:24:38.320\n And then you can rank the responses from the skill\n\n1:24:38.320 --> 1:24:41.280\n and then choose the best response for the customer.\n\n1:24:41.280 --> 1:24:43.240\n So that's on the more natural,\n\n1:24:43.240 --> 1:24:46.360\n other examples of more natural is like,\n\n1:24:46.360 --> 1:24:49.120\n we were talking about lists, for instance,\n\n1:24:49.120 --> 1:24:51.720\n and you don't wanna say, Alexa, add milk,\n\n1:24:51.720 --> 1:24:55.160\n Alexa, add eggs, Alexa, add cookies.\n\n1:24:55.160 --> 1:24:57.280\n No, Alexa, add cookies, milk, and eggs\n\n1:24:57.280 --> 1:24:59.240\n and that in one shot, right?\n\n1:24:59.240 --> 1:25:01.760\n So that works, that helps with the naturalness.\n\n1:25:01.760 --> 1:25:05.400\n We talked about memory, like if you said,\n\n1:25:05.400 --> 1:25:09.040\n you can say, Alexa, remember I have to go to mom's house,\n\n1:25:09.040 --> 1:25:11.160\n or you may have entered a calendar event\n\n1:25:11.160 --> 1:25:13.520\n through your calendar that's linked to Alexa.\n\n1:25:13.520 --> 1:25:15.800\n You don't wanna remember whether it's in my calendar\n\n1:25:15.800 --> 1:25:18.360\n or did I tell you to remember something\n\n1:25:18.360 --> 1:25:20.960\n or some other reminder, right?\n\n1:25:20.960 --> 1:25:25.320\n So you have to now, independent of how customers\n\n1:25:25.320 --> 1:25:28.120\n create these events, it should just say,\n\n1:25:28.120 --> 1:25:29.840\n Alexa, when do I have to go to mom's house?\n\n1:25:29.840 --> 1:25:32.320\n And it tells you when you have to go to mom's house.\n\n1:25:32.320 --> 1:25:33.720\n Now that's a fascinating problem.\n\n1:25:33.720 --> 1:25:35.280\n Who's that problem on?\n\n1:25:35.280 --> 1:25:37.480\n So there's people who create skills.\n\n1:25:38.520 --> 1:25:42.840\n Who's tasked with integrating all of that knowledge together\n\n1:25:42.840 --> 1:25:44.640\n so the skills become seamless?\n\n1:25:44.640 --> 1:25:46.840\n Is it the creators of the skills\n\n1:25:46.840 --> 1:25:51.280\n or is it an infrastructure that Alexa provides problem?\n\n1:25:51.280 --> 1:25:52.120\n It's both.\n\n1:25:52.120 --> 1:25:54.960\n I think the large problem in terms of making sure\n\n1:25:54.960 --> 1:25:56.720\n your skill quality is high,\n\n1:25:58.560 --> 1:26:01.240\n that has to be done by our tools,\n\n1:26:01.240 --> 1:26:03.160\n because it's just, so these skills,\n\n1:26:03.160 --> 1:26:04.720\n just to put the context,\n\n1:26:04.720 --> 1:26:06.360\n they are built through Alexa Skills Kit,\n\n1:26:06.360 --> 1:26:09.160\n which is a self serve way of building\n\n1:26:09.160 --> 1:26:11.320\n an experience on Alexa.\n\n1:26:11.320 --> 1:26:13.000\n This is like any developer in the world\n\n1:26:13.000 --> 1:26:14.880\n could go to Alexa Skills Kit\n\n1:26:14.880 --> 1:26:16.840\n and build an experience on Alexa.\n\n1:26:16.840 --> 1:26:20.160\n Like if you're a Domino's, you can build a Domino's Skills.\n\n1:26:20.160 --> 1:26:22.560\n For instance, that does pizza ordering.\n\n1:26:22.560 --> 1:26:24.440\n When you have authored that,\n\n1:26:25.320 --> 1:26:28.280\n you do want to now,\n\n1:26:28.280 --> 1:26:30.120\n if people say, Alexa, open Domino's\n\n1:26:30.120 --> 1:26:35.120\n or Alexa, ask Domino's to get a particular type of pizza,\n\n1:26:35.360 --> 1:26:37.800\n that will work, but the discovery is hard.\n\n1:26:37.800 --> 1:26:39.360\n You can't just say, Alexa, get me a pizza.\n\n1:26:39.360 --> 1:26:42.440\n And then Alexa figures out what to do.\n\n1:26:42.440 --> 1:26:45.000\n That latter part is definitely our responsibility\n\n1:26:45.000 --> 1:26:48.960\n in terms of when the request is not fully specific,\n\n1:26:48.960 --> 1:26:51.560\n how do you figure out what's the best skill\n\n1:26:51.560 --> 1:26:56.120\n or a service that can fulfill the customer's request?\n\n1:26:56.120 --> 1:26:57.280\n And it can keep evolving.\n\n1:26:57.280 --> 1:26:59.280\n Imagine going to the situation I said,\n\n1:26:59.280 --> 1:27:00.360\n which was the night out planning,\n\n1:27:00.360 --> 1:27:03.520\n that the goal could be more than that individual request\n\n1:27:03.520 --> 1:27:05.600\n that came up.\n\n1:27:05.600 --> 1:27:08.600\n A pizza ordering could mean a night in,\n\n1:27:08.600 --> 1:27:10.520\n where you're having an event with your kids\n\n1:27:10.520 --> 1:27:12.920\n in their house, and you're, so this is,\n\n1:27:12.920 --> 1:27:15.160\n welcome to the world of conversational AI.\n\n1:27:16.720 --> 1:27:18.920\n This is super exciting because it's not\n\n1:27:18.920 --> 1:27:20.760\n the academic problem of NLP,\n\n1:27:20.760 --> 1:27:23.080\n of natural language processing, understanding, dialogue.\n\n1:27:23.080 --> 1:27:24.640\n This is like real world.\n\n1:27:24.640 --> 1:27:27.120\n And the stakes are high in the sense\n\n1:27:27.120 --> 1:27:30.000\n that customers get frustrated quickly,\n\n1:27:30.000 --> 1:27:31.800\n people get frustrated quickly.\n\n1:27:31.800 --> 1:27:33.120\n So you have to get it right,\n\n1:27:33.120 --> 1:27:35.280\n you have to get that interaction right.\n\n1:27:35.280 --> 1:27:36.880\n So it's, I love it.\n\n1:27:36.880 --> 1:27:39.200\n But so from that perspective,\n\n1:27:39.200 --> 1:27:41.920\n what are the challenges today?\n\n1:27:41.920 --> 1:27:45.040\n What are the problems that really need to be solved\n\n1:27:45.040 --> 1:27:45.880\n in the next few years?\n\n1:27:45.880 --> 1:27:46.840\n What's the focus?\n\n1:27:46.840 --> 1:27:48.720\n First and foremost, as I mentioned,\n\n1:27:48.720 --> 1:27:53.080\n that get the basics right is still true.\n\n1:27:53.080 --> 1:27:57.000\n Basically, even the one shot requests,\n\n1:27:57.000 --> 1:27:58.840\n which we think of as transactional requests,\n\n1:27:58.840 --> 1:28:01.680\n needs to work magically, no question about that.\n\n1:28:01.680 --> 1:28:03.600\n If it doesn't turn your light on and off,\n\n1:28:03.600 --> 1:28:05.200\n you'll be super frustrated.\n\n1:28:05.200 --> 1:28:07.080\n Even if I can complete the night out for you\n\n1:28:07.080 --> 1:28:10.720\n and not do that, that is unacceptable as a customer, right?\n\n1:28:10.720 --> 1:28:14.120\n So that you have to get the foundational understanding\n\n1:28:14.120 --> 1:28:15.440\n going very well.\n\n1:28:15.440 --> 1:28:17.760\n The second aspect when I said more conversational\n\n1:28:17.760 --> 1:28:20.120\n is as you imagine is more about reasoning.\n\n1:28:20.120 --> 1:28:24.360\n It is really about figuring out what the latent goal is\n\n1:28:24.360 --> 1:28:28.520\n of the customer based on what I have the information now\n\n1:28:28.520 --> 1:28:31.360\n and the history, what's the next best thing to do.\n\n1:28:31.360 --> 1:28:35.400\n So that's a complete reasoning and decision making problem.\n\n1:28:35.400 --> 1:28:37.040\n Just like your self driving car,\n\n1:28:37.040 --> 1:28:38.680\n but the goal is still more finite.\n\n1:28:38.680 --> 1:28:41.960\n Here it evolves, your environment is super hard\n\n1:28:41.960 --> 1:28:46.880\n and self driving and the cost of a mistake is huge here,\n\n1:28:46.880 --> 1:28:48.520\n but there are certain similarities.\n\n1:28:48.520 --> 1:28:52.640\n But if you think about how many decisions Alexa is making\n\n1:28:52.640 --> 1:28:54.280\n or evaluating at any given time,\n\n1:28:54.280 --> 1:28:56.480\n it's a huge hypothesis space.\n\n1:28:56.480 --> 1:28:59.760\n And we're only talked about so far\n\n1:28:59.760 --> 1:29:02.080\n about what I think of reactive decision\n\n1:29:02.080 --> 1:29:03.640\n in terms of you asked for something\n\n1:29:03.640 --> 1:29:05.920\n and Alexa is reacting to it.\n\n1:29:05.920 --> 1:29:07.760\n If you bring the proactive part,\n\n1:29:07.760 --> 1:29:10.040\n which is Alexa having hunches.\n\n1:29:10.040 --> 1:29:14.440\n So any given instance then it's really a decision\n\n1:29:14.440 --> 1:29:17.240\n at any given point based on the information.\n\n1:29:17.240 --> 1:29:20.120\n Alexa has to determine what's the best thing it needs to do.\n\n1:29:20.120 --> 1:29:22.520\n So these are the ultimate AI problem\n\n1:29:22.520 --> 1:29:25.080\n about decisions based on the information you have.\n\n1:29:25.080 --> 1:29:27.880\n Do you think, just from my perspective,\n\n1:29:27.880 --> 1:29:31.120\n I work a lot with sensing of the human face.\n\n1:29:31.120 --> 1:29:33.680\n Do you think they'll, and we touched this topic\n\n1:29:33.680 --> 1:29:36.560\n a little bit earlier, but do you think it'll be a day soon\n\n1:29:36.560 --> 1:29:41.360\n when Alexa can also look at you to help improve the quality\n\n1:29:41.360 --> 1:29:46.360\n of the hunch it has, or at least detect frustration\n\n1:29:46.360 --> 1:29:51.360\n or detect, improve the quality of its perception\n\n1:29:51.600 --> 1:29:54.360\n of what you're trying to do?\n\n1:29:54.360 --> 1:29:57.160\n I mean, let me again bring back to what it already does.\n\n1:29:57.160 --> 1:30:01.800\n We talked about how based on you barge in over Alexa,\n\n1:30:01.800 --> 1:30:04.960\n clearly it's a very high probability\n\n1:30:04.960 --> 1:30:06.560\n it must have done something wrong.\n\n1:30:06.560 --> 1:30:08.520\n That's why you barged in.\n\n1:30:08.520 --> 1:30:13.240\n The next extension of whether frustration is a signal or not,\n\n1:30:13.240 --> 1:30:15.320\n of course, is a natural thought\n\n1:30:15.320 --> 1:30:18.200\n in terms of how that should be in a signal to it.\n\n1:30:18.200 --> 1:30:19.520\n You can get that from voice.\n\n1:30:19.520 --> 1:30:21.280\n You can get from voice, but it's very hard.\n\n1:30:21.280 --> 1:30:25.920\n Like, I mean, frustration as a signal historically,\n\n1:30:25.920 --> 1:30:28.440\n if you think about emotions of different kinds,\n\n1:30:29.640 --> 1:30:31.440\n there's a whole field of affective computing,\n\n1:30:31.440 --> 1:30:34.520\n something that MIT has also done a lot of research in,\n\n1:30:34.520 --> 1:30:35.600\n is super hard.\n\n1:30:35.600 --> 1:30:39.040\n And you are now talking about a far field device,\n\n1:30:39.040 --> 1:30:41.920\n as in you're talking to a distance noisy environment.\n\n1:30:41.920 --> 1:30:44.080\n And in that environment,\n\n1:30:44.080 --> 1:30:47.520\n it needs to have a good sense for your emotions.\n\n1:30:47.520 --> 1:30:49.440\n This is a very, very hard problem.\n\n1:30:49.440 --> 1:30:50.960\n Very hard problem, but you haven't shied away\n\n1:30:50.960 --> 1:30:51.800\n from hard problems.\n\n1:30:51.800 --> 1:30:55.240\n So, Deep Learning has been at the core\n\n1:30:55.240 --> 1:30:57.360\n of a lot of this technology.\n\n1:30:57.360 --> 1:30:58.200\n Are you optimistic\n\n1:30:58.200 --> 1:30:59.680\n about the current Deep Learning approaches\n\n1:30:59.680 --> 1:31:03.200\n to solving the hardest aspects of what we're talking about?\n\n1:31:03.200 --> 1:31:05.320\n Or do you think there will come a time\n\n1:31:05.320 --> 1:31:07.960\n where new ideas need to further,\n\n1:31:07.960 --> 1:31:09.320\n if we look at reasoning,\n\n1:31:09.320 --> 1:31:10.640\n so OpenAI, DeepMind,\n\n1:31:10.640 --> 1:31:13.840\n a lot of folks are now starting to work in reasoning,\n\n1:31:13.840 --> 1:31:16.560\n trying to see how we can make neural networks reason.\n\n1:31:16.560 --> 1:31:20.480\n Do you see that new approaches need to be invented\n\n1:31:20.480 --> 1:31:23.280\n to take the next big leap?\n\n1:31:23.280 --> 1:31:27.160\n Absolutely, I think there has to be a lot more investment.\n\n1:31:27.160 --> 1:31:29.360\n And I think in many different ways,\n\n1:31:29.360 --> 1:31:31.160\n and there are these, I would say,\n\n1:31:31.160 --> 1:31:33.520\n nuggets of research forming in a good way,\n\n1:31:33.520 --> 1:31:36.040\n like learning with less data\n\n1:31:36.040 --> 1:31:39.640\n or like zero short learning, one short learning.\n\n1:31:39.640 --> 1:31:41.360\n And the active learning stuff you've talked about\n\n1:31:41.360 --> 1:31:43.200\n is incredible stuff.\n\n1:31:43.200 --> 1:31:45.640\n So, transfer learning is also super critical,\n\n1:31:45.640 --> 1:31:48.560\n especially when you're thinking about applying knowledge\n\n1:31:48.560 --> 1:31:49.840\n from one task to another,\n\n1:31:49.840 --> 1:31:52.000\n or one language to another, right?\n\n1:31:52.000 --> 1:31:52.960\n It's really ripe.\n\n1:31:52.960 --> 1:31:55.280\n So, these are great pieces.\n\n1:31:55.280 --> 1:31:56.760\n Deep learning has been useful too.\n\n1:31:56.760 --> 1:31:58.840\n And now we are sort of marrying deep learning\n\n1:31:58.840 --> 1:32:02.440\n with transfer learning and active learning.\n\n1:32:02.440 --> 1:32:04.480\n Of course, that's more straightforward\n\n1:32:04.480 --> 1:32:05.840\n in terms of applying deep learning\n\n1:32:05.840 --> 1:32:06.960\n and an active learning setup.\n\n1:32:06.960 --> 1:32:11.960\n But I do think in terms of now looking\n\n1:32:12.120 --> 1:32:14.200\n into more reasoning based approaches\n\n1:32:14.200 --> 1:32:19.200\n is going to be key for our next wave of the technology.\n\n1:32:19.440 --> 1:32:20.840\n But there is a good news.\n\n1:32:20.840 --> 1:32:23.280\n The good news is that I think for keeping on\n\n1:32:23.280 --> 1:32:25.200\n to delight customers, that a lot of it\n\n1:32:25.200 --> 1:32:27.880\n can be done by prediction tasks.\n\n1:32:27.880 --> 1:32:30.640\n So, we haven't exhausted that.\n\n1:32:30.640 --> 1:32:34.440\n So, we don't need to give up\n\n1:32:34.440 --> 1:32:37.280\n on the deep learning approaches for that.\n\n1:32:37.280 --> 1:32:39.520\n So, that's just I wanted to sort of point that out.\n\n1:32:39.520 --> 1:32:42.560\n Creating a rich, fulfilling, amazing experience\n\n1:32:42.560 --> 1:32:44.200\n that makes Amazon a lot of money\n\n1:32:44.200 --> 1:32:46.360\n and a lot of everybody a lot of money\n\n1:32:46.360 --> 1:32:49.840\n because it does awesome things, deep learning is enough.\n\n1:32:49.840 --> 1:32:51.080\n The point.\n\n1:32:51.080 --> 1:32:54.160\n I don't think, I wouldn't say deep learning is enough.\n\n1:32:54.160 --> 1:32:56.680\n I think for the purposes of Alexa\n\n1:32:56.680 --> 1:32:58.400\n accomplished the task for customers.\n\n1:32:58.400 --> 1:33:02.160\n I'm saying there are still a lot of things we can do\n\n1:33:02.160 --> 1:33:05.280\n with prediction based approaches that do not reason.\n\n1:33:05.280 --> 1:33:08.600\n I'm not saying that and we haven't exhausted those.\n\n1:33:08.600 --> 1:33:12.440\n But for the kind of high utility experiences\n\n1:33:12.440 --> 1:33:14.240\n that I'm personally passionate about\n\n1:33:14.240 --> 1:33:18.760\n of what Alexa needs to do, reasoning has to be solved\n\n1:33:18.760 --> 1:33:21.000\n to the same extent as you can think\n\n1:33:21.000 --> 1:33:24.720\n of natural language understanding and speech recognition\n\n1:33:24.720 --> 1:33:27.600\n to the extent of understanding intents\n\n1:33:27.600 --> 1:33:30.120\n has been how accurate it has become.\n\n1:33:30.120 --> 1:33:32.760\n But reasoning, we have very, very early days.\n\n1:33:32.760 --> 1:33:34.000\n Let me ask it another way.\n\n1:33:34.000 --> 1:33:36.760\n How hard of a problem do you think that is?\n\n1:33:36.760 --> 1:33:37.800\n Hardest of them.\n\n1:33:39.160 --> 1:33:41.680\n I would say hardest of them because again,\n\n1:33:42.560 --> 1:33:47.560\n the hypothesis space is really, really large.\n\n1:33:47.560 --> 1:33:50.000\n And when you go back in time, like you were saying,\n\n1:33:50.000 --> 1:33:53.000\n I wanna, I want Alexa to remember more things\n\n1:33:53.000 --> 1:33:56.280\n that once you go beyond a session of interaction,\n\n1:33:56.280 --> 1:33:59.200\n which is by session, I mean a time span,\n\n1:33:59.200 --> 1:34:03.120\n which is today to versus remembering which restaurant I like.\n\n1:34:03.120 --> 1:34:05.440\n And then when I'm planning a night out to say,\n\n1:34:05.440 --> 1:34:07.480\n do you wanna go to the same restaurant?\n\n1:34:07.480 --> 1:34:09.720\n Now you're up the stakes big time.\n\n1:34:09.720 --> 1:34:12.800\n And this is where the reasoning dimension\n\n1:34:12.800 --> 1:34:14.680\n also goes way, way bigger.\n\n1:34:14.680 --> 1:34:17.760\n So you think the space, we'll be elaborating that\n\n1:34:17.760 --> 1:34:20.480\n a little bit, just philosophically speaking,\n\n1:34:20.480 --> 1:34:24.480\n do you think when you reason about trying to model\n\n1:34:24.480 --> 1:34:28.040\n what the goal of a person is in the context\n\n1:34:28.040 --> 1:34:31.080\n of interacting with Alexa, you think that space is huge?\n\n1:34:31.080 --> 1:34:32.840\n It's huge, absolutely huge.\n\n1:34:32.840 --> 1:34:35.840\n Do you think, so like another sort of devil's advocate\n\n1:34:35.840 --> 1:34:38.520\n would be that we human beings are really simple\n\n1:34:38.520 --> 1:34:41.360\n and we all want like just a small set of things.\n\n1:34:41.360 --> 1:34:44.720\n And so do you think it's possible?\n\n1:34:44.720 --> 1:34:47.000\n Cause we're not talking about\n\n1:34:47.000 --> 1:34:49.240\n a fulfilling general conversation.\n\n1:34:49.240 --> 1:34:53.320\n Perhaps actually the Alexa prize is a little bit after that.\n\n1:34:53.320 --> 1:34:56.080\n Creating a customer, like there's so many\n\n1:34:56.080 --> 1:35:01.040\n of the interactions, it feels like are clustered\n\n1:35:01.040 --> 1:35:06.040\n in groups that are, don't require general reasoning.\n\n1:35:06.520 --> 1:35:09.320\n I think you're right in terms of the head\n\n1:35:09.320 --> 1:35:11.800\n of the distribution of all the possible things\n\n1:35:11.800 --> 1:35:13.720\n customers may wanna accomplish.\n\n1:35:13.720 --> 1:35:18.200\n But the tail is long and it's diverse, right?\n\n1:35:18.200 --> 1:35:19.040\n So from that.\n\n1:35:19.040 --> 1:35:21.280\n There's many, many long tails.\n\n1:35:21.280 --> 1:35:24.880\n So from that perspective, I think you have\n\n1:35:24.880 --> 1:35:26.720\n to solve that problem otherwise,\n\n1:35:27.640 --> 1:35:28.800\n and everyone's very different.\n\n1:35:28.800 --> 1:35:30.440\n Like, I mean, we see this already\n\n1:35:30.440 --> 1:35:32.320\n in terms of the skills, right?\n\n1:35:32.320 --> 1:35:36.960\n I mean, if you're an average surfer, which I am not, right?\n\n1:35:36.960 --> 1:35:41.640\n But somebody is asking Alexa about surfing conditions, right?\n\n1:35:41.640 --> 1:35:45.480\n And there's a skill that is there for them to get to, right?\n\n1:35:45.480 --> 1:35:47.840\n That tells you that the tail is massive.\n\n1:35:47.840 --> 1:35:50.720\n Like in terms of like what kind of skills\n\n1:35:50.720 --> 1:35:54.200\n people have created, it's humongous in terms of it.\n\n1:35:54.200 --> 1:35:56.960\n And which means there are these diverse needs.\n\n1:35:56.960 --> 1:36:00.040\n And when you start looking at the combinations\n\n1:36:00.040 --> 1:36:00.960\n of these, right?\n\n1:36:00.960 --> 1:36:05.400\n Even if you had pairs of skills and 90,000 choose two,\n\n1:36:05.400 --> 1:36:07.920\n it's still a big set of combinations.\n\n1:36:07.920 --> 1:36:11.720\n So I'm saying there's a huge to do here now.\n\n1:36:11.720 --> 1:36:14.760\n And I think customers are, you know,\n\n1:36:14.760 --> 1:36:18.080\n wonderfully frustrated with things.\n\n1:36:18.080 --> 1:36:20.880\n And they have to keep getting to do better things for them.\n\n1:36:20.880 --> 1:36:21.720\n So.\n\n1:36:21.720 --> 1:36:23.920\n And they're not known to be super patient.\n\n1:36:23.920 --> 1:36:24.760\n So you have to.\n\n1:36:24.760 --> 1:36:25.600\n Do it fast.\n\n1:36:25.600 --> 1:36:26.960\n You have to do it fast.\n\n1:36:26.960 --> 1:36:29.840\n So you've mentioned the idea of a press release,\n\n1:36:29.840 --> 1:36:33.880\n the research and development, Amazon Alexa\n\n1:36:33.880 --> 1:36:35.960\n and Amazon general, you kind of think of what\n\n1:36:35.960 --> 1:36:37.240\n the future product will look like.\n\n1:36:37.240 --> 1:36:38.360\n And you kind of make it happen.\n\n1:36:38.360 --> 1:36:40.040\n You work backwards.\n\n1:36:40.040 --> 1:36:43.920\n So can you draft for me, you probably already have one,\n\n1:36:43.920 --> 1:36:48.880\n but can you make up one for 10, 20, 30, 40 years out\n\n1:36:48.880 --> 1:36:52.800\n that you see the Alexa team putting out\n\n1:36:52.800 --> 1:36:56.520\n just in broad strokes, something that you dream about?\n\n1:36:56.520 --> 1:37:00.920\n I think let's start with the five years first, right?\n\n1:37:00.920 --> 1:37:03.600\n So, and I'll get to the 40 years too.\n\n1:37:03.600 --> 1:37:06.000\n Cause I'm pretty sure you have a real five year one.\n\n1:37:06.000 --> 1:37:08.720\n That's why I didn't want to, but yeah,\n\n1:37:08.720 --> 1:37:10.120\n in broad strokes, let's start with five years.\n\n1:37:10.120 --> 1:37:11.800\n I think the five year is where, I mean,\n\n1:37:11.800 --> 1:37:14.800\n I think of in these spaces, it's hard,\n\n1:37:14.800 --> 1:37:16.160\n especially if you're in the thick of things\n\n1:37:16.160 --> 1:37:17.960\n to think beyond the five year space,\n\n1:37:17.960 --> 1:37:20.280\n because a lot of things change, right?\n\n1:37:20.280 --> 1:37:22.200\n I mean, if you ask me five years back,\n\n1:37:22.200 --> 1:37:24.200\n will Alexa will be here?\n\n1:37:24.200 --> 1:37:26.360\n I wouldn't have, I think it has surpassed\n\n1:37:26.360 --> 1:37:29.040\n my imagination of that time, right?\n\n1:37:29.040 --> 1:37:33.160\n So I think from the next five years perspective,\n\n1:37:33.160 --> 1:37:37.120\n from a AI perspective, what we're gonna see\n\n1:37:37.120 --> 1:37:40.400\n is that notion, which you said goal oriented dialogues\n\n1:37:40.400 --> 1:37:42.400\n and open domain like Alexa prize.\n\n1:37:42.400 --> 1:37:45.200\n I think that bridge is gonna get closed.\n\n1:37:45.200 --> 1:37:46.400\n They won't be different.\n\n1:37:46.400 --> 1:37:48.520\n And I'll give you why that's the case.\n\n1:37:48.520 --> 1:37:50.200\n You mentioned shopping.\n\n1:37:50.200 --> 1:37:52.240\n How do you shop?\n\n1:37:52.240 --> 1:37:55.680\n Do you shop in one shot?\n\n1:37:55.680 --> 1:37:59.400\n Sure, your double A batteries, paper towels.\n\n1:37:59.400 --> 1:38:04.160\n Yes, how long does it take for you to buy a camera?\n\n1:38:04.160 --> 1:38:07.480\n You do ton of research, then you make a decision.\n\n1:38:07.480 --> 1:38:11.440\n So is that a goal oriented dialogue\n\n1:38:11.440 --> 1:38:15.480\n when somebody says, Alexa, find me a camera?\n\n1:38:15.480 --> 1:38:18.640\n Is it simply inquisitiveness, right?\n\n1:38:18.640 --> 1:38:20.880\n So even in the something that you think of it as shopping,\n\n1:38:20.880 --> 1:38:23.960\n which you said you yourself use a lot of,\n\n1:38:23.960 --> 1:38:27.360\n if you go beyond where it's reorders\n\n1:38:27.360 --> 1:38:32.360\n or items where you sort of are not brand conscious\n\n1:38:32.440 --> 1:38:33.520\n and so forth.\n\n1:38:33.520 --> 1:38:35.040\n So that was just in shopping.\n\n1:38:35.040 --> 1:38:36.120\n Just to comment quickly,\n\n1:38:36.120 --> 1:38:38.040\n I've never bought anything through Alexa\n\n1:38:38.040 --> 1:38:41.160\n that I haven't bought before on Amazon on the desktop\n\n1:38:41.160 --> 1:38:44.000\n after I clicked in a bunch of read a bunch of reviews,\n\n1:38:44.000 --> 1:38:44.840\n that kind of stuff.\n\n1:38:44.840 --> 1:38:45.800\n So it's repurchase.\n\n1:38:45.800 --> 1:38:47.480\n So now you think in,\n\n1:38:47.480 --> 1:38:51.280\n even for something that you felt like is a finite goal,\n\n1:38:51.280 --> 1:38:54.680\n I think the space is huge because even products,\n\n1:38:54.680 --> 1:38:56.640\n the attributes are many,\n\n1:38:56.640 --> 1:38:58.240\n and you wanna look at reviews,\n\n1:38:58.240 --> 1:39:00.000\n some on Amazon, some outside,\n\n1:39:00.000 --> 1:39:01.960\n some you wanna look at what CNET is saying\n\n1:39:01.960 --> 1:39:05.200\n or another consumer forum is saying\n\n1:39:05.200 --> 1:39:06.880\n about even a product for instance, right?\n\n1:39:06.880 --> 1:39:11.640\n So that's just shopping where you could argue\n\n1:39:11.640 --> 1:39:13.960\n the ultimate goal is sort of known.\n\n1:39:13.960 --> 1:39:15.680\n And we haven't talked about Alexa,\n\n1:39:15.680 --> 1:39:18.880\n what's the weather in Cape Cod this weekend, right?\n\n1:39:18.880 --> 1:39:22.480\n So why am I asking that weather question, right?\n\n1:39:22.480 --> 1:39:27.480\n So I think of it as how do you complete goals\n\n1:39:27.480 --> 1:39:30.040\n with minimum steps for our customers, right?\n\n1:39:30.040 --> 1:39:32.400\n And when you think of it that way,\n\n1:39:32.400 --> 1:39:35.960\n the distinction between goal oriented and conversations\n\n1:39:35.960 --> 1:39:38.640\n for open domain say goes away.\n\n1:39:38.640 --> 1:39:41.680\n I may wanna know what happened\n\n1:39:41.680 --> 1:39:43.520\n in the presidential debate, right?\n\n1:39:43.520 --> 1:39:45.800\n And is it I'm seeking just information\n\n1:39:45.800 --> 1:39:49.560\n or I'm looking at who's winning the debates, right?\n\n1:39:49.560 --> 1:39:53.360\n So these are all quite hard problems.\n\n1:39:53.360 --> 1:39:55.560\n So even the five year horizon problem,\n\n1:39:55.560 --> 1:39:59.840\n I'm like, I sure hope we'll solve these.\n\n1:39:59.840 --> 1:40:03.440\n And you're optimistic because that's a hard problem.\n\n1:40:03.440 --> 1:40:04.280\n Which part?\n\n1:40:04.280 --> 1:40:09.280\n The reasoning enough to be able to help explore\n\n1:40:09.600 --> 1:40:12.400\n complex goals that are beyond something simplistic.\n\n1:40:12.400 --> 1:40:16.560\n That feels like it could be, well, five years is a nice.\n\n1:40:16.560 --> 1:40:18.280\n Is a nice bar for it, right?\n\n1:40:18.280 --> 1:40:21.240\n I think you will, it's a nice ambition\n\n1:40:21.240 --> 1:40:23.760\n and do we have press releases for that?\n\n1:40:23.760 --> 1:40:25.880\n Absolutely, can I tell you what specifically\n\n1:40:25.880 --> 1:40:26.720\n the roadmap will be?\n\n1:40:26.720 --> 1:40:28.080\n No, right?\n\n1:40:28.080 --> 1:40:30.760\n And what, and will we solve all of it\n\n1:40:30.760 --> 1:40:31.760\n in the five year space?\n\n1:40:31.760 --> 1:40:35.560\n No, this is, we'll work on this forever actually.\n\n1:40:35.560 --> 1:40:37.960\n This is the hardest of the AI problems\n\n1:40:37.960 --> 1:40:42.240\n and I don't see that being solved even in a 40 year horizon\n\n1:40:42.240 --> 1:40:45.200\n because even if you limit to the human intelligence,\n\n1:40:45.200 --> 1:40:47.640\n we know we are quite far from that.\n\n1:40:47.640 --> 1:40:52.640\n In fact, every aspects of our sensing to neural processing,\n\n1:40:52.640 --> 1:40:56.320\n to how brain stores information and how it processes it,\n\n1:40:56.320 --> 1:40:59.000\n we don't yet know how to represent knowledge, right?\n\n1:40:59.000 --> 1:41:02.920\n So we are still in those early stages.\n\n1:41:02.920 --> 1:41:06.360\n So I wanted to start, that's why at the five year,\n\n1:41:06.360 --> 1:41:09.120\n because the five year success would look like that\n\n1:41:09.120 --> 1:41:11.240\n in solving these complex goals.\n\n1:41:11.240 --> 1:41:14.560\n And the 40 year would be where it's just natural\n\n1:41:14.560 --> 1:41:18.720\n to talk to these in terms of more of these complex goals.\n\n1:41:18.720 --> 1:41:20.000\n Right now, we've already come to the point\n\n1:41:20.000 --> 1:41:22.840\n where these transactions you mentioned\n\n1:41:22.840 --> 1:41:25.720\n of asking for weather or reordering something\n\n1:41:25.720 --> 1:41:28.560\n or listening to your favorite tune,\n\n1:41:28.560 --> 1:41:30.840\n it's natural for you to ask Alexa.\n\n1:41:30.840 --> 1:41:33.880\n It's now unnatural to pick up your phone, right?\n\n1:41:33.880 --> 1:41:36.600\n And that I think is the first five year transformation.\n\n1:41:36.600 --> 1:41:38.800\n The next five year transformation would be,\n\n1:41:38.800 --> 1:41:40.960\n okay, I can plan my weekend with Alexa\n\n1:41:40.960 --> 1:41:43.640\n or I can plan my next meal with Alexa\n\n1:41:43.640 --> 1:41:47.840\n or my next night out with seamless effort.\n\n1:41:47.840 --> 1:41:51.200\n So just to pause and look back at the big picture of it all.\n\n1:41:51.200 --> 1:41:55.560\n It's a, you're a part of a large team\n\n1:41:55.560 --> 1:41:58.680\n that's creating a system that's in the home\n\n1:41:58.680 --> 1:42:02.760\n that's not human, that gets to interact with human beings.\n\n1:42:02.760 --> 1:42:06.120\n So we human beings, we these descendants of apes\n\n1:42:06.120 --> 1:42:09.000\n have created an artificial intelligence system\n\n1:42:09.000 --> 1:42:10.960\n that's able to have conversations.\n\n1:42:10.960 --> 1:42:15.960\n I mean, that to me, the two most transformative robots\n\n1:42:18.800 --> 1:42:22.000\n of this century, I think will be autonomous vehicles,\n\n1:42:23.200 --> 1:42:24.760\n but they're a little bit transformative\n\n1:42:24.760 --> 1:42:26.360\n in a more boring way.\n\n1:42:26.360 --> 1:42:28.120\n It's like a tool.\n\n1:42:28.120 --> 1:42:32.840\n I think conversational agents in the home\n\n1:42:32.840 --> 1:42:34.640\n is like an experience.\n\n1:42:34.640 --> 1:42:36.120\n How does that make you feel?\n\n1:42:36.120 --> 1:42:38.560\n That you're at the center of creating that?\n\n1:42:38.560 --> 1:42:42.800\n Do you sit back in awe sometimes?\n\n1:42:42.800 --> 1:42:47.320\n What is your feeling about the whole mess of it?\n\n1:42:47.320 --> 1:42:49.000\n Can you even believe that we're able\n\n1:42:49.000 --> 1:42:50.840\n to create something like this?\n\n1:42:50.840 --> 1:42:52.440\n I think it's a privilege.\n\n1:42:52.440 --> 1:42:57.440\n I'm so fortunate like where I ended up, right?\n\n1:42:57.640 --> 1:43:00.800\n And it's been a long journey.\n\n1:43:00.800 --> 1:43:03.480\n Like I've been in this space for a long time in Cambridge,\n\n1:43:03.480 --> 1:43:07.080\n right, and it's so heartwarming to see\n\n1:43:07.080 --> 1:43:11.440\n the kind of adoption conversational agents are having now.\n\n1:43:12.440 --> 1:43:14.480\n Five years back, it was almost like,\n\n1:43:14.480 --> 1:43:17.120\n should I move out of this because we are unable\n\n1:43:17.120 --> 1:43:21.360\n to find this killer application that customers would love\n\n1:43:21.360 --> 1:43:24.440\n that would not simply be a good to have thing\n\n1:43:24.440 --> 1:43:26.080\n in research labs.\n\n1:43:26.080 --> 1:43:29.160\n And it's so fulfilling to see it make a difference\n\n1:43:29.160 --> 1:43:32.240\n to millions and billions of people worldwide.\n\n1:43:32.240 --> 1:43:34.400\n The good thing is that it's still very early.\n\n1:43:34.400 --> 1:43:37.360\n So I have another 20 years of job security\n\n1:43:37.360 --> 1:43:38.200\n doing what I love.\n\n1:43:38.200 --> 1:43:40.560\n Like, so I think from that perspective,\n\n1:43:42.000 --> 1:43:44.280\n I tell every researcher that joins\n\n1:43:44.280 --> 1:43:46.240\n or every member of my team,\n\n1:43:46.240 --> 1:43:47.640\n that this is a unique privilege.\n\n1:43:47.640 --> 1:43:49.560\n Like I think, and we have,\n\n1:43:49.560 --> 1:43:52.760\n and I would say not just launching Alexa in 2014,\n\n1:43:52.760 --> 1:43:54.360\n which was first of its kind.\n\n1:43:54.360 --> 1:43:57.360\n Along the way we have, when we launched Alexa Skills Kit,\n\n1:43:57.360 --> 1:43:59.680\n it became democratizing AI.\n\n1:43:59.680 --> 1:44:02.440\n When before that there was no good evidence\n\n1:44:02.440 --> 1:44:04.960\n of an SDK for speech and language.\n\n1:44:04.960 --> 1:44:06.640\n Now we are coming to this where you and I\n\n1:44:06.640 --> 1:44:09.440\n are having this conversation where I'm not saying,\n\n1:44:10.320 --> 1:44:14.560\n oh, Lex, planning a night out with an AI agent, impossible.\n\n1:44:14.560 --> 1:44:17.120\n I'm saying it's in the realm of possibility\n\n1:44:17.120 --> 1:44:19.480\n and not only possibility, we'll be launching this, right?\n\n1:44:19.480 --> 1:44:23.800\n So some elements of that, it will keep getting better.\n\n1:44:23.800 --> 1:44:25.640\n We know that is a universal truth.\n\n1:44:25.640 --> 1:44:30.160\n Once you have these kinds of agents out there being used,\n\n1:44:30.160 --> 1:44:32.080\n they get better for your customers.\n\n1:44:32.080 --> 1:44:34.240\n And I think that's where,\n\n1:44:34.240 --> 1:44:36.560\n I think the amount of research topics\n\n1:44:36.560 --> 1:44:39.480\n we are throwing out at our budding researchers\n\n1:44:39.480 --> 1:44:41.840\n is just gonna be exponentially hard.\n\n1:44:41.840 --> 1:44:45.600\n And the great thing is you can now get immense satisfaction\n\n1:44:45.600 --> 1:44:47.280\n by having customers use it,\n\n1:44:47.280 --> 1:44:51.120\n not just a paper in NeurIPS or another conference.\n\n1:44:51.120 --> 1:44:53.120\n I think everyone, myself included,\n\n1:44:53.120 --> 1:44:54.840\n are deeply excited about that future.\n\n1:44:54.840 --> 1:44:58.040\n So I don't think there's a better place to end, Rohit.\n\n1:44:58.040 --> 1:44:58.880\n Thank you so much for talking to us.\n\n1:44:58.880 --> 1:44:59.720\n Thank you so much.\n\n1:44:59.720 --> 1:45:00.560\n This was fun.\n\n1:45:00.560 --> 1:45:02.240\n Thank you, same here.\n\n1:45:02.240 --> 1:45:04.240\n Thanks for listening to this conversation\n\n1:45:04.240 --> 1:45:05.760\n with Rohit Prasad.\n\n1:45:05.760 --> 1:45:08.880\n And thank you to our presenting sponsor, Cash App.\n\n1:45:08.880 --> 1:45:11.600\n Download it, use code LEGSPodcast,\n\n1:45:11.600 --> 1:45:14.720\n you'll get $10 and $10 will go to FIRST,\n\n1:45:14.720 --> 1:45:16.520\n a STEM education nonprofit\n\n1:45:16.520 --> 1:45:19.760\n that inspires hundreds of thousands of young minds\n\n1:45:19.760 --> 1:45:23.320\n to learn and to dream of engineering our future.\n\n1:45:23.320 --> 1:45:26.220\n If you enjoy this podcast, subscribe on YouTube,\n\n1:45:26.220 --> 1:45:28.200\n give it five stars on Apple Podcast,\n\n1:45:28.200 --> 1:45:31.720\n support it on Patreon, or connect with me on Twitter.\n\n1:45:31.720 --> 1:45:34.960\n And now let me leave you with some words of wisdom\n\n1:45:34.960 --> 1:45:37.500\n from the great Alan Turing.\n\n1:45:37.500 --> 1:45:41.680\n Sometimes it is the people no one can imagine anything of\n\n1:45:41.680 --> 1:45:44.180\n who do the things no one can imagine.\n\n1:45:44.180 --> 1:45:57.180\n Thank you for listening and hope to see you next time.\n\n"
}
{
  "title": "Kyle Vogt: Cruise Automation | Lex Fridman Podcast #14",
  "id": "YUYagvESisE",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:02.240\n The following is a conversation with Kyle Vogt.\n\n00:02.240 --> 00:05.040\n He's the president and the CTO of Cruise Automation,\n\n00:05.040 --> 00:09.680\n leading an effort to solve one of the biggest robotics challenges of our time,\n\n00:09.680 --> 00:13.600\n vehicle automation. He's a cofounder of two successful companies, Twitch\n\n00:13.600 --> 00:16.960\n and Cruise, that have each sold for a billion dollars.\n\n00:16.960 --> 00:20.640\n And he's a great example of the innovative spirit that flourishes\n\n00:20.640 --> 00:26.240\n in Silicon Valley, and now is facing an interesting and exciting challenge of\n\n00:26.240 --> 00:31.040\n matching that spirit with the mass production and the safety centric\n\n00:31.040 --> 00:35.520\n culture of a major automaker like General Motors. This conversation is\n\n00:35.520 --> 00:38.560\n part of the MIT Artificial General Intelligence series\n\n00:38.560 --> 00:42.000\n and the Artificial Intelligence podcast. If you enjoy it,\n\n00:42.000 --> 00:46.480\n please subscribe on YouTube, iTunes, or simply connect with me on Twitter\n\n00:46.480 --> 00:54.480\n at Lex Friedman, spelled F R I D. And now here's my conversation with Kyle Vogt.\n\n00:54.480 --> 00:57.920\n You grew up in Kansas, right? Yeah, and I just saw that picture you had hidden\n\n00:57.920 --> 01:00.560\n over there, so I'm a little bit a little bit worried about that now.\n\n01:00.560 --> 01:04.880\n Yeah, so in high school in Kansas City, you joined Shawnee Mission\n\n01:04.880 --> 01:09.280\n North high school robotics team. Yeah. Now that wasn't your high school.\n\n01:09.280 --> 01:13.040\n That's right, that was that was the only high school in the area that had a\n\n01:13.040 --> 01:16.480\n like a teacher who was willing to sponsor our first robotics team.\n\n01:16.480 --> 01:19.680\n I was gonna troll you a little bit. Jog your memory a little bit.\n\n01:19.680 --> 01:23.520\n Yeah, I was trying to look super cool and intense, because you know this\n\n01:23.520 --> 01:28.080\n was BattleBots. This is serious business. So we're standing there with a welded\n\n01:28.080 --> 01:32.560\n steel frame and looking tough. So go back there. What is that drew you\n\n01:32.560 --> 01:36.160\n to robotics? Well, I think I've been trying to figure\n\n01:36.160 --> 01:38.400\n this out for a while, but I've always liked building things with Legos. And\n\n01:38.400 --> 01:41.680\n when I was really, really young, I wanted the Legos that had motors and\n\n01:41.680 --> 01:45.040\n other things. And then, you know, Lego Mindstorms came out, and for the\n\n01:45.040 --> 01:49.680\n first time you could program Lego contraptions. And I think things\n\n01:49.680 --> 01:54.160\n just sort of snowballed from that. But I remember\n\n01:54.160 --> 01:58.240\n seeing, you know, the BattleBots TV show on Comedy Central and thinking that is\n\n01:58.240 --> 02:01.120\n the coolest thing in the world. I want to be a part of that.\n\n02:01.120 --> 02:04.240\n And not knowing a whole lot about how to build these\n\n02:04.240 --> 02:09.280\n 200 pound fighting robots. So I sort of obsessively poured over\n\n02:09.280 --> 02:12.960\n the internet forums where all the creators for BattleBots would sort of\n\n02:12.960 --> 02:16.160\n hang out and talk about, you know, document their build progress and\n\n02:16.160 --> 02:20.080\n everything. And I think I read, I must have read like,\n\n02:20.080 --> 02:23.760\n you know, tens of thousands of forum posts from basically\n\n02:23.760 --> 02:26.960\n everything that was out there on what these people were doing. And eventually\n\n02:26.960 --> 02:30.400\n like sort of triangulated how to put some of these things together.\n\n02:30.400 --> 02:34.880\n And I ended up doing BattleBots, which was, you know, I was like 13 or 14, which\n\n02:34.880 --> 02:37.280\n was pretty awesome. I'm not sure if the show is still\n\n02:37.280 --> 02:41.520\n running, but so BattleBots is, there's not an artificial\n\n02:41.520 --> 02:44.800\n intelligence component. It's remotely controlled. And it's\n\n02:44.800 --> 02:47.840\n almost like a mechanical engineering challenge of building things\n\n02:47.840 --> 02:50.960\n that can be broken. They're radio controlled. So,\n\n02:50.960 --> 02:54.720\n and I think that they allowed some limited form of autonomy.\n\n02:54.720 --> 02:58.640\n But, you know, in a two minute match, you're, in the way these things ran,\n\n02:58.640 --> 03:01.120\n you're really doing yourself a disservice by trying to automate it\n\n03:01.120 --> 03:04.560\n versus just, you know, do the practical thing, which is drive it yourself.\n\n03:04.560 --> 03:08.800\n And there's an entertainment aspect, just going on YouTube, there's like an,\n\n03:08.800 --> 03:12.080\n some of them wield an axe, some of them, I mean, there's that fun.\n\n03:12.080 --> 03:15.280\n So what drew you to that aspect? Was it the mechanical engineering?\n\n03:15.280 --> 03:19.760\n Was it the dream to create like Frankenstein and\n\n03:19.760 --> 03:22.720\n sentient being? Or was it just like the Lego,\n\n03:22.720 --> 03:25.920\n you like tinkering with stuff? I mean, that was just building something.\n\n03:25.920 --> 03:29.760\n I think the idea of, you know, this radio controlled machine that\n\n03:29.760 --> 03:32.320\n can do various things, if it has like a weapon or something was pretty\n\n03:32.320 --> 03:34.880\n interesting. I agree it doesn't have the same\n\n03:34.880 --> 03:37.600\n appeal as, you know, autonomous robots, which I,\n\n03:37.600 --> 03:40.720\n which I, you know, sort of gravitated towards later on. But it was definitely\n\n03:40.720 --> 03:44.880\n an engineering challenge because everything you did in that\n\n03:44.880 --> 03:49.200\n competition was pushing components to their limits. So we would\n\n03:49.200 --> 03:54.400\n buy like these $40 DC motors that came out of a\n\n03:54.400 --> 03:57.760\n winch, like on the front of a pickup truck or something, and we'd\n\n03:57.760 --> 04:01.200\n power the car with those and we'd run them at like double or triple their\n\n04:01.200 --> 04:04.000\n rated voltage. So they immediately start overheating,\n\n04:04.000 --> 04:06.000\n but for that two minute match you can get,\n\n04:06.000 --> 04:09.520\n you know, a significant increase in the power output of those motors\n\n04:09.520 --> 04:12.720\n before they burn out. And so you're doing the same thing for your battery packs,\n\n04:12.720 --> 04:16.800\n all the materials in the system. And I think there's something, something\n\n04:16.800 --> 04:20.240\n intrinsically interesting about just seeing like where things break.\n\n04:20.240 --> 04:23.760\n And did you offline see where they break? Did you\n\n04:23.760 --> 04:26.640\n take it to the testing point? Like how did you know two minutes? Or was there a\n\n04:26.640 --> 04:30.720\n reckless let's just go with it and see? We weren't very good at\n\n04:30.720 --> 04:34.240\n BattleBots. We lost all of our matches the first round.\n\n04:34.240 --> 04:38.240\n The one I built first, both of them were these wedge shaped robots because\n\n04:38.240 --> 04:40.000\n wedge, even though it's sort of boring to look\n\n04:40.000 --> 04:43.200\n at, is extremely effective. You drive towards another robot and\n\n04:43.200 --> 04:46.640\n the front edge of it gets under them and then they sort of flip over,\n\n04:46.640 --> 04:49.840\n kind of like a door stopper. And the first one had a\n\n04:49.840 --> 04:53.360\n pneumatic polished stainless steel spike on the front that would shoot out about\n\n04:53.360 --> 04:56.400\n eight inches. The purpose of which is what? Pretty,\n\n04:56.400 --> 04:58.720\n pretty ineffective actually, but it looks cool.\n\n04:58.720 --> 05:02.960\n And was it to help with the lift? No, it was, it was just to try to poke holes\n\n05:02.960 --> 05:07.040\n in the other robot. And then the second time I did it, which is the following,\n\n05:07.040 --> 05:12.640\n I think maybe 18 months later, we had a, well a titanium axe with a, with a\n\n05:12.640 --> 05:16.640\n hardened steel tip on it that was powered by a hydraulic\n\n05:16.640 --> 05:21.920\n cylinder which we were activating with liquid CO2, which was,\n\n05:21.920 --> 05:26.160\n had its own set of problems. So great, so that's kind of on the hardware side.\n\n05:26.160 --> 05:31.200\n I mean at a certain point there must have been born a fascination\n\n05:31.200 --> 05:35.360\n on the software side. So what was the first piece of code you've written?\n\n05:35.360 --> 05:38.480\n Go back there, see what language was it?\n\n05:38.480 --> 05:41.760\n What, what was that? Was it Emacs? Vim? Was it a more\n\n05:41.760 --> 05:45.760\n respectable modern IDE? Do you, do you remember any of this?\n\n05:45.760 --> 05:49.680\n Yeah, well I remember, I think maybe when I was in\n\n05:49.680 --> 05:52.880\n third or fourth grade, the school I was at, elementary school, had a bunch of\n\n05:52.880 --> 05:56.800\n Apple II computers and we'd play games on those. And I\n\n05:56.800 --> 05:58.640\n remember every once in a while something would,\n\n05:58.640 --> 06:02.560\n would, would crash or wouldn't start up correctly and it would dump you out to\n\n06:02.560 --> 06:05.680\n what I later learned was like sort of a command prompt.\n\n06:05.680 --> 06:08.640\n And my teacher would come over and type, I actually remember this to this day for\n\n06:08.640 --> 06:12.400\n some reason, like PR number six or PR pound six, which is\n\n06:12.400 --> 06:15.120\n peripheral six, which is the disk drive, which would fire up the disk and load the\n\n06:15.120 --> 06:17.200\n program. And I just remember thinking wow, she's\n\n06:17.200 --> 06:21.040\n like a hacker, like teach me these, these codes, these error codes, that is what\n\n06:21.040 --> 06:23.840\n I called them at the time. But she had no interest in that, so it\n\n06:23.840 --> 06:28.400\n wasn't until I think about fifth grade that I had a school where you could\n\n06:28.400 --> 06:31.520\n actually go on these Apple IIs and learn to program. And so it was all in basic,\n\n06:31.520 --> 06:34.720\n you know, where every line, you know, the line numbers are all number, that every\n\n06:34.720 --> 06:37.920\n line is numbered and you have to like leave enough space\n\n06:37.920 --> 06:41.600\n between the numbers so that if you want to tweak your code you go back and\n\n06:41.600 --> 06:44.720\n the first line was 10 and the second line is 20. Now you have to go back and\n\n06:44.720 --> 06:47.360\n insert 15 and if you need to add code in front of\n\n06:47.360 --> 06:50.240\n that, you know, 11 or 12 and you hope you don't run out of line numbers and have\n\n06:50.240 --> 06:54.160\n to redo the whole thing. And there's go to statements? Yeah, go to\n\n06:54.160 --> 06:58.080\n and it's very basic, maybe hence the name, but a lot of fun.\n\n06:58.080 --> 07:01.760\n And that was like, that was, you know, that's when, you know,\n\n07:01.760 --> 07:03.520\n when you first program you see the magic of it.\n\n07:03.520 --> 07:07.040\n It's like, it just, just like this world opens up with, you know, endless\n\n07:07.040 --> 07:09.040\n possibilities for the things you could build or\n\n07:09.040 --> 07:12.160\n or accomplish with that computer. So you got the bug then, so\n\n07:12.160 --> 07:15.920\n even starting with basic and then what C++ throughout,\n\n07:15.920 --> 07:19.200\n what did you, was there computer programming, computer science classes in\n\n07:19.200 --> 07:22.320\n high school? Not, not where I went, so it was self\n\n07:22.320 --> 07:27.760\n taught, but I did a lot of programming. The thing that, you know, sort of\n\n07:27.760 --> 07:31.280\n pushed me in the path of eventually working on self driving cars is actually\n\n07:31.280 --> 07:34.240\n one of these really long trips driving from my\n\n07:34.240 --> 07:39.440\n house in Kansas to, to I think Las Vegas where we did the BattleBots competition\n\n07:39.440 --> 07:43.680\n and I had just gotten my, I think my learner's permit or\n\n07:43.680 --> 07:47.040\n early driver's permit and so I was driving this,\n\n07:47.040 --> 07:50.480\n you know, 10 hour stretch across western Kansas where it's just,\n\n07:50.480 --> 07:53.760\n you're going straight on a highway and it is mind numbingly boring. And I\n\n07:53.760 --> 07:57.440\n remember thinking even then with my sort of mediocre programming\n\n07:57.440 --> 08:00.480\n background that this is something that a computer can do, right? Let's take a\n\n08:00.480 --> 08:03.440\n picture of the road, let's find the yellow lane markers and,\n\n08:03.440 --> 08:06.880\n you know, steer the wheel. And, you know, later I'd come to realize this had been\n\n08:06.880 --> 08:10.640\n done, you know, since, since the 80s or the 70s or even\n\n08:10.640 --> 08:13.520\n earlier, but I still wanted to do it and sort of\n\n08:13.520 --> 08:16.560\n immediately after that trip switched from sort of BattleBots, which is more\n\n08:16.560 --> 08:21.440\n radio controlled machines, to thinking about building,\n\n08:21.440 --> 08:24.320\n you know, autonomous vehicles of some scale. Start off with really small\n\n08:24.320 --> 08:27.680\n electric ones and then, you know, progress to what we're\n\n08:27.680 --> 08:30.640\n doing now. So what was your view of artificial intelligence at that point?\n\n08:30.640 --> 08:35.520\n What did you think? So this is before, there's been waves in artificial\n\n08:35.520 --> 08:39.440\n intelligence, right? The current wave with deep learning\n\n08:39.440 --> 08:44.000\n makes people believe that you can solve in a really rich deep way the computer\n\n08:44.000 --> 08:48.400\n vision perception problem, but like in\n\n08:48.400 --> 08:52.720\n before the deep learning craze, you know, how do you think about,\n\n08:52.720 --> 08:56.560\n how would you even go about building a thing that perceives itself in the\n\n08:56.560 --> 08:59.040\n world, localizes itself in the world, moves around the world?\n\n08:59.040 --> 09:02.320\n Like when you were younger, I mean, what was your thinking about it? Well,\n\n09:02.320 --> 09:05.040\n prior to deep neural networks or convolutional neural\n\n09:05.040 --> 09:06.960\n analysis, these modern techniques we have, or at least\n\n09:06.960 --> 09:11.680\n ones that are in use today, it was all a heuristic space and so like old school\n\n09:11.680 --> 09:16.800\n image processing and I think extracting, you know, yellow lane markers out of an\n\n09:16.800 --> 09:21.200\n image of a road is one of the problems that lends itself\n\n09:21.200 --> 09:24.240\n reasonably well to those heuristic based methods, you know, like\n\n09:24.240 --> 09:27.440\n just do a threshold on the color yellow and then try to\n\n09:27.440 --> 09:31.040\n fit some lines to that using a Huff transform or something and then\n\n09:31.040 --> 09:35.840\n go from there. Traffic light detection and stop sign detection, red, yellow, green.\n\n09:35.840 --> 09:39.760\n And I think you could, I mean, if you wanted to do a full,\n\n09:39.760 --> 09:43.120\n I was just trying to make something that would stay in between the lanes on a\n\n09:43.120 --> 09:46.560\n highway, but if you wanted to do the full,\n\n09:46.880 --> 09:50.400\n the full, you know, set of capabilities needed for a driverless car,\n\n09:50.400 --> 09:54.320\n I think you could, and we'd done this at cruise, you know, in the very first days,\n\n09:54.320 --> 09:58.160\n you can start off with a really simple, you know, human written heuristic just to\n\n09:58.160 --> 10:01.680\n get the scaffolding in place for your system. Traffic light detection,\n\n10:01.680 --> 10:04.960\n probably a really simple, you know, color thresholding on day one just to\n\n10:04.960 --> 10:08.800\n get the system up and running before you migrate to, you know, a deep\n\n10:08.800 --> 10:10.960\n learning based technique or something else.\n\n10:10.960 --> 10:14.000\n And, you know, back in when I was doing this, my first one, it was on a Pentium\n\n10:14.000 --> 10:19.520\n 203, 233 megahertz computer in it and I think I wrote the first version in\n\n10:19.520 --> 10:21.680\n basic, which is like an interpreted language. It's\n\n10:21.680 --> 10:24.720\n extremely slow because that's the thing I knew at the time.\n\n10:24.720 --> 10:27.760\n And so there was no, no chance at all of using,\n\n10:27.760 --> 10:32.480\n there was no, no computational power to do any sort of reasonable\n\n10:32.480 --> 10:35.360\n deep nets like you have today. So I don't know what kids these days are doing. Are\n\n10:35.360 --> 10:38.720\n kids these days, you know, at age 13 using neural networks in\n\n10:38.720 --> 10:40.640\n their garage? I mean, that would be awesome.\n\n10:40.640 --> 10:44.640\n I get emails all the time from, you know, like 11, 12 year olds\n\n10:44.640 --> 10:48.640\n saying I'm having, you know, I'm trying to follow this TensorFlow tutorial\n\n10:48.640 --> 10:53.200\n and I'm having this problem. And the general approach\n\n10:53.200 --> 11:00.000\n in the deep learning community is of extreme optimism of, as opposed to,\n\n11:00.000 --> 11:03.040\n you mentioned like heuristics, you can, you can, you can\n\n11:03.040 --> 11:06.560\n separate the autonomous driving problem into modules and try to solve it sort of\n\n11:06.560 --> 11:08.960\n rigorously, or you can just do it end to end.\n\n11:08.960 --> 11:12.960\n And most people just kind of love the idea that, you know, us humans do it end\n\n11:12.960 --> 11:17.280\n to end. We just perceive and act. We should be able to use that, do the\n\n11:17.280 --> 11:19.360\n same kind of thing when you're on nets. And that,\n\n11:19.360 --> 11:23.120\n that kind of thinking, you don't want to criticize that kind of thinking because\n\n11:23.120 --> 11:26.800\n eventually they will be right. Yeah. And so it's exciting and especially\n\n11:26.800 --> 11:30.960\n when they're younger to explore that as a really exciting approach. But yeah,\n\n11:30.960 --> 11:35.360\n it's, it's changed the, the language,\n\n11:35.360 --> 11:38.960\n the kind of stuff you're tinkering with. It's kind of exciting to see when these\n\n11:38.960 --> 11:42.240\n teenagers grow up. Yeah. I can only imagine if you,\n\n11:42.240 --> 11:46.640\n if your starting point is, you know, Python and TensorFlow at age 13\n\n11:46.640 --> 11:49.760\n where you end up, you know, after 10 or 15 years of that,\n\n11:49.760 --> 11:53.840\n that's, that's pretty cool. Because of GitHub, because the state tools for\n\n11:53.840 --> 11:56.880\n solving most of the major problems in artificial intelligence\n\n11:56.880 --> 12:00.160\n are within a few lines of code for most kids.\n\n12:00.160 --> 12:04.160\n And that's incredible to think about also on the entrepreneurial side.\n\n12:04.160 --> 12:10.560\n And, and on that point, was there any thought about entrepreneurship before\n\n12:10.560 --> 12:14.560\n you came to college? Is sort of doing, you're building this\n\n12:14.560 --> 12:18.480\n into a thing that impacts the world on a large scale? Yeah. I've always\n\n12:18.480 --> 12:22.720\n wanted to start a company. I think that's, you know, just a cool concept of\n\n12:22.720 --> 12:28.240\n creating something and exchanging it for value or creating value, I guess.\n\n12:28.240 --> 12:32.240\n So in high school, I was, I was trying to build like, you know, servo motor\n\n12:32.240 --> 12:35.280\n drivers, little circuit boards and sell them online\n\n12:35.280 --> 12:39.520\n or other, other things like that. And certainly knew at some point I wanted to\n\n12:39.520 --> 12:42.720\n do a startup, but it wasn't really, I'd say until college, until I felt\n\n12:42.720 --> 12:45.360\n like I had the,\n\n12:45.600 --> 12:48.960\n I guess the right combination of the environment, the smart people around you\n\n12:48.960 --> 12:52.240\n and some free time and a lot of free time at MIT.\n\n12:52.240 --> 12:58.000\n So you came to MIT as an undergrad 2004. That's right. And that's when the first\n\n12:58.000 --> 13:02.080\n DARPA Grand Challenge was happening. Yeah. The, the timing of that is\n\n13:02.080 --> 13:05.600\n beautifully poetic. So how did you get yourself involved in that one?\n\n13:05.600 --> 13:09.840\n Originally there wasn't a official entry. Yeah, faculty sponsored thing. And so a\n\n13:09.840 --> 13:14.720\n bunch of undergrads, myself included, started meeting and got together and\n\n13:14.720 --> 13:18.720\n tried to haggle together some sponsorships. We got a vehicle donated,\n\n13:18.720 --> 13:22.480\n a bunch of sensors and tried to put something together. And so we had,\n\n13:22.480 --> 13:26.320\n our team was probably mostly freshmen and sophomores, you know, which, which was\n\n13:26.320 --> 13:30.080\n not really a fair, fair fight against maybe the,\n\n13:30.080 --> 13:33.280\n you know, postdoc and faculty led teams from other schools. But\n\n13:33.280 --> 13:36.960\n we, we got something up and running. We had our vehicle drive by wire and\n\n13:36.960 --> 13:41.840\n you know, very, very basic control and things. But\n\n13:41.840 --> 13:47.520\n on the day of the qualifying, sort of pre qualifying round, the one and\n\n13:47.520 --> 13:50.720\n only steering motor that we had purchased,\n\n13:50.720 --> 13:55.200\n the thing that we had retrofitted to turn the steering wheel on the truck\n\n13:55.200 --> 13:58.480\n died. And so our vehicle was just dead in the water, couldn't steer.\n\n13:58.480 --> 14:02.400\n So we didn't make it very far. On the hardware side. So was there a software\n\n14:02.400 --> 14:05.760\n component? Was there, like, how did your view of autonomous\n\n14:05.760 --> 14:09.520\n vehicles in terms of artificial intelligence\n\n14:09.520 --> 14:13.120\n evolve in this moment? I mean, you know, like you said from the 80s has been\n\n14:13.120 --> 14:16.720\n autonomous vehicles, but really that was the birth of the modern wave.\n\n14:16.720 --> 14:21.440\n The, the thing that captivated everyone's imagination that we can actually do this.\n\n14:21.440 --> 14:25.600\n So what, how were you captivated in that way?\n\n14:25.600 --> 14:28.880\n So how did your view of autonomous vehicles change at that point?\n\n14:28.880 --> 14:32.640\n I'd say at that point in time it was, it was a\n\n14:32.640 --> 14:35.760\n curiosity as in, like, is this really possible?\n\n14:35.760 --> 14:39.120\n And I think that was generally the spirit and\n\n14:39.120 --> 14:44.800\n the purpose of that original DARPA Grand Challenge, which was to just get\n\n14:44.800 --> 14:49.200\n a whole bunch of really brilliant people exploring the space and pushing the\n\n14:49.200 --> 14:52.240\n limits. And I think, like, to this day that\n\n14:52.240 --> 14:56.080\n DARPA Challenge with its, you know, million dollar prize pool\n\n14:56.080 --> 15:00.320\n was probably one of the most effective, you know, uses of taxpayer\n\n15:00.320 --> 15:04.240\n money dollar for dollar that I've seen, you know, because that,\n\n15:04.240 --> 15:07.760\n that small sort of initiative that DARPA put,\n\n15:07.760 --> 15:12.640\n put out sort of, in my view, was the catalyst or the tipping point\n\n15:12.640 --> 15:16.400\n for this, this whole next wave of autonomous vehicle development. So that\n\n15:16.400 --> 15:20.160\n was pretty cool. So let me jump around a little bit on that point.\n\n15:20.160 --> 15:23.680\n They also did the Urban Challenge where it was in the city, but it was very\n\n15:23.680 --> 15:27.040\n artificial and there's no pedestrians and there's very little human\n\n15:27.040 --> 15:31.600\n involvement except a few professional drivers. Yeah.\n\n15:31.600 --> 15:34.400\n Do you think there's room, and then there was the Robotics Challenge with\n\n15:34.400 --> 15:38.560\n humanoid robots. Right. So in your now role is looking at this,\n\n15:38.560 --> 15:42.640\n you're trying to solve one of the, you know, autonomous driving, one of the\n\n15:42.640 --> 15:45.360\n harder, more difficult places in San Francisco.\n\n15:45.360 --> 15:49.280\n Is there a role for DARPA to step in to also kind of help out,\n\n15:49.280 --> 15:54.480\n like, challenge with new ideas, specifically pedestrians and so on, all\n\n15:54.480 --> 15:56.880\n these kinds of interesting things? Well, I haven't, I haven't thought about it\n\n15:56.880 --> 15:59.760\n from that perspective. Is there anything DARPA could do today to further\n\n15:59.760 --> 16:04.880\n accelerate things? And I would say, my instinct is that that's maybe not the\n\n16:04.880 --> 16:07.040\n highest and best use of their resources and time,\n\n16:07.040 --> 16:11.360\n because, like, kick starting and spinning up the flywheel is, I think, what\n\n16:11.360 --> 16:16.720\n what they did in this case for very, very little money. But today this has become,\n\n16:16.720 --> 16:19.920\n this has become, like, commercially interesting to very large companies and\n\n16:19.920 --> 16:22.320\n the amount of money going into it and the amount of\n\n16:22.320 --> 16:25.680\n people, like, going through your class and learning about these things and\n\n16:25.680 --> 16:29.040\n developing these skills is just, you know, orders of magnitude\n\n16:29.040 --> 16:33.040\n more than it was back then. And so there's enough momentum and inertia\n\n16:33.040 --> 16:37.440\n and energy and investment dollars into this space right now that\n\n16:37.440 --> 16:41.600\n I don't, I don't, I think they're, I think they're, they can just say mission\n\n16:41.600 --> 16:46.160\n accomplished and move on to the next area of technology that needs help.\n\n16:46.160 --> 16:50.720\n So then stepping back to MIT, you left MIT during your junior year.\n\n16:50.720 --> 16:54.400\n What was that decision like? As I said, I always wanted to do\n\n16:54.400 --> 16:59.120\n a company in, or start a company, and this opportunity landed in my lap, which\n\n16:59.120 --> 17:02.240\n was a couple guys from Yale were starting a\n\n17:02.240 --> 17:05.200\n new company, and I googled them and found that they had\n\n17:05.200 --> 17:09.360\n started a company previously and sold it actually on eBay for\n\n17:09.360 --> 17:13.280\n about a quarter million bucks, which was a pretty interesting story, but\n\n17:13.280 --> 17:17.040\n so I thought to myself, these guys are, you know, rock star entrepreneurs, they've\n\n17:17.040 --> 17:20.560\n done this before, they must be driving around in Ferraris\n\n17:20.560 --> 17:25.280\n because they sold their company, and, you know, I thought I could learn\n\n17:25.280 --> 17:27.920\n a lot from them, so I teamed up with those guys and,\n\n17:27.920 --> 17:33.520\n you know, went out during, went out to California during IAP, which is MIT's\n\n17:33.520 --> 17:37.840\n month off, on a one way ticket and basically never went back.\n\n17:37.840 --> 17:40.800\n We were having so much fun, we felt like we were building something and creating\n\n17:40.800 --> 17:42.960\n something, and it was going to be interesting\n\n17:42.960 --> 17:47.120\n that, you know, I was just all in and got completely hooked, and that\n\n17:47.120 --> 17:51.600\n that business was Justin TV, which is originally a reality show about a guy\n\n17:51.600 --> 17:56.000\n named Justin, which morphed into a live video\n\n17:56.000 --> 17:59.760\n streaming platform, which then morphed into what is Twitch\n\n17:59.760 --> 18:04.960\n today, so that was, that was quite an unexpected journey.\n\n18:04.960 --> 18:09.520\n So no regrets? No. Looking back, it was just an obvious, I mean,\n\n18:09.520 --> 18:12.640\n one way ticket. I mean, if we just pause on that for a second,\n\n18:12.640 --> 18:17.920\n there was no, how did you know these are the right guys, this is the\n\n18:17.920 --> 18:21.600\n right decision, you didn't think it was just follow the\n\n18:21.600 --> 18:25.360\n heart kind of thing? Well, I didn't know, but, you know, just trying something for a\n\n18:25.360 --> 18:28.080\n month during IAP seems pretty low risk, right?\n\n18:28.080 --> 18:31.680\n And then, you know, well, maybe I'll take a semester off, MIT's pretty flexible\n\n18:31.680 --> 18:35.280\n about that, you can always go back, right? And then after two or three cycles of\n\n18:35.280 --> 18:40.880\n that, I eventually threw in the towel, but, you know, I think it's,\n\n18:40.880 --> 18:44.720\n I guess in that case I felt like I could always hit the undo button if I had to.\n\n18:44.720 --> 18:48.640\n Right. But nevertheless, from when you look\n\n18:48.640 --> 18:51.600\n in retrospect, I mean, it seems like a brave decision,\n\n18:51.600 --> 18:54.960\n you know, it would be difficult for a lot of people to make. It wasn't as\n\n18:54.960 --> 18:59.520\n popular, I'd say that the general, you know, flux of people\n\n18:59.520 --> 19:04.080\n out of MIT at the time was mostly into, you know, finance or consulting jobs in\n\n19:04.080 --> 19:07.200\n Boston or New York, and very few people were going to\n\n19:07.200 --> 19:10.080\n California to start companies, but today I'd say that's,\n\n19:10.080 --> 19:14.080\n it's probably inverted, which is just a sign of,\n\n19:14.080 --> 19:18.320\n a sign of the times, I guess. Yeah. So there's a story about\n\n19:18.320 --> 19:24.000\n midnight of March 18, 2007, where TechCrunch, I guess, announced\n\n19:24.000 --> 19:28.880\n Justin.TV earlier than it was supposed to, a few hours.\n\n19:28.880 --> 19:32.400\n The site didn't work. I don't know if any of this is true, you can tell me.\n\n19:32.400 --> 19:36.080\n And you and one of the folks at Justin.TV,\n\n19:36.080 --> 19:41.280\n Emmett Shearer, coded through the night. Can you take me through that experience?\n\n19:41.280 --> 19:45.360\n So let me, let me say a few nice things that,\n\n19:45.360 --> 19:49.120\n the article I read quoted Justin Kahn said that you were known for bureau\n\n19:49.120 --> 19:52.400\n coding through problems and being a creative, quote, creative\n\n19:52.400 --> 19:56.640\n genius. So on that night,\n\n19:56.640 --> 20:00.720\n what, what was going through your head, or maybe I'd put another way,\n\n20:00.720 --> 20:04.960\n how do you solve these problems? What's your approach to solving these kinds of\n\n20:04.960 --> 20:08.560\n problems where the line between success and failure seems to be pretty\n\n20:08.560 --> 20:12.000\n thin? That's a good question. Well, first of all, that's, that's a\n\n20:12.000 --> 20:15.520\n nice of Justin to say that. I think, you know, I would have been\n\n20:15.520 --> 20:18.720\n maybe 21 years old then and not very experienced at programming,\n\n20:18.720 --> 20:23.920\n but as with, with everything in a startup, you're sort of racing against\n\n20:23.920 --> 20:28.080\n the clock. And so our plan was the second we had\n\n20:28.080 --> 20:33.520\n this live streaming camera backpack up and running, where Justin could wear it\n\n20:33.520 --> 20:35.280\n and no matter where he went in a city, it\n\n20:35.280 --> 20:36.800\n would be streaming live video. And this is\n\n20:36.800 --> 20:40.800\n even before the iPhones. This is like hard to do back then.\n\n20:40.800 --> 20:45.120\n We would launch. And so we thought we were there and the backpack was working\n\n20:45.120 --> 20:47.920\n and then we sent out all the emails to launch the,\n\n20:47.920 --> 20:51.120\n launch the company and do the press thing. And then, you know,\n\n20:51.120 --> 20:54.640\n we weren't quite actually there. And then\n\n20:54.640 --> 20:58.640\n we thought, oh, well, you know, they're not going to announce it until\n\n20:58.640 --> 21:02.320\n maybe 10 a.m. the next morning. And it's, I don't know, it's 5 p.m. now. So\n\n21:02.320 --> 21:06.080\n how many hours do we have left? What is that? Like, you know, 17 hours to go.\n\n21:06.080 --> 21:10.320\n And, and that was, that was going to be fine.\n\n21:10.320 --> 21:12.240\n Was the problem obvious? Did you understand\n\n21:12.240 --> 21:16.400\n what could possibly, like, how complicated was the system at that point?\n\n21:16.400 --> 21:22.320\n It was, it was pretty messy. So to get a live video feed that looked decent\n\n21:22.320 --> 21:27.040\n working from anywhere in San Francisco, I put together this system where we had\n\n21:27.040 --> 21:29.920\n like three or four cell phone data modems and\n\n21:29.920 --> 21:32.720\n they were, like, we take the video stream and,\n\n21:32.720 --> 21:36.000\n you know, sort of spray it across these three or four modems and then try to\n\n21:36.000 --> 21:39.040\n catch all the packets on the other side, you know, with unreliable cell phone\n\n21:39.040 --> 21:41.040\n networks. It's pretty low level networking.\n\n21:41.040 --> 21:44.160\n Yeah, and putting these, like, you know, sort of\n\n21:44.160 --> 21:47.520\n protocols on top of all that to, to reassemble and reorder the packets and\n\n21:47.520 --> 21:50.880\n have time buffers and error correction and all that kind of stuff.\n\n21:50.880 --> 21:55.600\n And the night before it was just staticky. Every once in a while the image\n\n21:55.600 --> 21:58.560\n would, would go to staticky and there would be this horrible,\n\n21:58.560 --> 22:01.920\n like, screeching audio noise because the audio was also corrupted.\n\n22:01.920 --> 22:05.280\n And this would happen, like, every five to ten minutes or so and it was\n\n22:05.280 --> 22:08.720\n a really, you know, off putting to the viewers.\n\n22:08.720 --> 22:12.720\n How do you tackle that problem? What was the, uh, you're just freaking out behind a\n\n22:12.720 --> 22:16.160\n computer. There's, are there other, other folks working\n\n22:16.160 --> 22:19.360\n on this problem? Like, were you behind a whiteboard? Were you doing, uh,\n\n22:19.360 --> 22:23.680\n Yeah, it was a little, it was a little, yeah, it's a little lonely because there's four of us\n\n22:23.680 --> 22:26.720\n working on the company and only two people really wrote code.\n\n22:26.720 --> 22:30.080\n And Emmett wrote the website and the chat system and I wrote the\n\n22:30.080 --> 22:34.080\n software for this video streaming device and video server.\n\n22:34.080 --> 22:37.200\n And so, you know, it's my sole responsibility to figure that out.\n\n22:37.200 --> 22:40.320\n And I think, I think it's those, you know, setting,\n\n22:40.320 --> 22:42.960\n setting deadlines, trying to move quickly and everything where you're in that\n\n22:42.960 --> 22:45.520\n moment of intense pressure that sometimes people do their\n\n22:45.520 --> 22:48.720\n best and most interesting work. And so even though that was a terrible moment,\n\n22:48.720 --> 22:51.360\n I look back on it fondly because that's like, you know, that's one of those\n\n22:51.360 --> 22:58.320\n character defining moments, I think. So in 2013, October, you founded\n\n22:58.320 --> 23:02.720\n Cruise Automation. Yeah. So progressing forward, another\n\n23:02.720 --> 23:06.800\n exceptionally successful company was acquired by GM in 16\n\n23:06.800 --> 23:14.000\n for $1 billion. But in October 2013, what was on your mind?\n\n23:14.000 --> 23:19.760\n What was the plan? How does one seriously start to tackle\n\n23:19.760 --> 23:23.200\n one of the hardest robotics, most important impact for robotics\n\n23:23.200 --> 23:27.760\n problems of our age? After going through Twitch, Twitch was,\n\n23:27.760 --> 23:35.120\n was, and is today, pretty successful. But the, the work was,\n\n23:35.120 --> 23:38.560\n the result was entertainment, mostly. Like, the better the product was,\n\n23:38.560 --> 23:42.320\n the more we would entertain people and then, you know, make money on the ad\n\n23:42.320 --> 23:44.960\n revenues and other things. And that was, that was a good thing. It\n\n23:44.960 --> 23:48.400\n felt, felt good to entertain people. But I figured like, you know, what is really\n\n23:48.400 --> 23:51.120\n the point of becoming a really good engineer and\n\n23:51.120 --> 23:54.320\n developing these skills other than, you know, my own enjoyment? And I\n\n23:54.320 --> 23:56.720\n realized I wanted something that scratched more of an existential\n\n23:56.720 --> 23:59.920\n itch, like something that, that truly matters. And so I\n\n23:59.920 --> 24:05.120\n basically made this list of requirements for a new, if I was going to\n\n24:05.120 --> 24:07.600\n do another company, and the one thing I knew in the back of\n\n24:07.600 --> 24:12.160\n my head that Twitch took like eight years to become successful.\n\n24:12.160 --> 24:16.160\n And so whatever I do, I better be willing to commit, you know, at least 10 years\n\n24:16.160 --> 24:20.240\n to something. And when you think about things from that perspective,\n\n24:20.240 --> 24:23.520\n you certainly, I think, raise the bar on what you choose to work on. So for me,\n\n24:23.520 --> 24:26.720\n the three things were it had to be something where the technology\n\n24:26.720 --> 24:28.880\n itself determines the success of the product,\n\n24:28.880 --> 24:32.400\n like hard, really juicy technology problems, because that's what\n\n24:32.400 --> 24:37.040\n motivates me. And then it had to have a direct and positive impact on society in\n\n24:37.040 --> 24:39.120\n some way. So an example would be like, you know,\n\n24:39.120 --> 24:42.000\n health care, self driving cars, because they save lives, other things where\n\n24:42.000 --> 24:45.040\n there's a clear connection to somehow improving other people's lives.\n\n24:45.040 --> 24:48.240\n And the last one is it had to be a big business, because\n\n24:48.240 --> 24:51.200\n for the positive impact to matter, it's got to be a large scale.\n\n24:51.200 --> 24:54.640\n And I was thinking about that for a while, and I made like, I tried\n\n24:54.640 --> 24:57.520\n writing a Gmail clone and looked at some other ideas.\n\n24:57.520 --> 25:00.720\n And then it just sort of light bulb went off, like self driving cars, like that\n\n25:00.720 --> 25:03.920\n was the most fun I had ever had in college working on that.\n\n25:03.920 --> 25:07.280\n And like, well, what's the state of the technology? It's been 10 years.\n\n25:07.280 --> 25:10.640\n Maybe times have changed, and maybe now is the time to make this work.\n\n25:10.640 --> 25:14.000\n And I poked around and looked at, the only other thing out there really at the\n\n25:14.000 --> 25:16.560\n time was the Google self driving car project.\n\n25:16.560 --> 25:20.720\n And I thought, surely there's a way to, you know, have an entrepreneur mindset\n\n25:20.720 --> 25:23.440\n and sort of solve the minimum viable product here.\n\n25:23.440 --> 25:26.400\n And so I just took the plunge right then and there and said, this is something I\n\n25:26.400 --> 25:29.600\n know I can commit 10 years to. It's the probably the greatest\n\n25:29.600 --> 25:33.440\n applied AI problem of our generation. And if it works, it's going to be both a\n\n25:33.440 --> 25:37.120\n huge business and therefore like, probably the most positive impact I can\n\n25:37.120 --> 25:41.680\n possibly have on the world. So after that light bulb went off, I went\n\n25:41.680 --> 25:45.520\n all in on cruise immediately and got to work.\n\n25:45.520 --> 25:48.320\n Did you have an idea how to solve this problem? Which aspect of the problem to\n\n25:48.320 --> 25:52.560\n solve? You know, slow, like we just had Oliver\n\n25:52.560 --> 25:56.400\n from Voyage here, slow moving retirement communities,\n\n25:56.400 --> 26:00.720\n urban driving, highway driving. Did you have, like, did you have a vision of the\n\n26:00.720 --> 26:05.200\n city of the future where, you know, the transportation is\n\n26:05.200 --> 26:09.760\n largely automated, that kind of thing? Or was it sort of\n\n26:09.760 --> 26:15.680\n more fuzzy and gray area than that? My analysis of the situation is that\n\n26:15.680 --> 26:19.200\n Google is putting a lot, had been putting a lot of money into that project. They\n\n26:19.200 --> 26:23.680\n had a lot more resources. And so, and they still hadn't cracked\n\n26:23.680 --> 26:29.520\n the fully driverless car. You know, this is 2013, I guess.\n\n26:29.520 --> 26:34.320\n So I thought, what can I do to sort of go from zero to,\n\n26:34.320 --> 26:37.520\n you know, significant scale so I can actually solve the real problem, which is\n\n26:37.520 --> 26:40.720\n the driverless cars. And I thought, here's the strategy. We'll\n\n26:40.720 --> 26:44.480\n start by doing a really simple problem or solving a\n\n26:44.480 --> 26:49.040\n really simple problem that creates value for people. So,\n\n26:49.040 --> 26:51.760\n eventually ended up deciding on automating highway driving,\n\n26:51.760 --> 26:55.120\n which is relatively more straightforward as long as there's a\n\n26:55.120 --> 26:59.200\n backup driver there. And, you know, the go to market will be able to retrofit\n\n26:59.200 --> 27:02.400\n people's cars and just sell these products directly. And\n\n27:02.400 --> 27:06.640\n the idea was, we'll take all the revenue and profits from that and use it\n\n27:06.640 --> 27:10.640\n to do the, so sort of reinvest that in research for\n\n27:10.640 --> 27:13.920\n doing fully driverless cars. And that was the plan.\n\n27:13.920 --> 27:17.280\n The only thing that really changed along the way between then and now is\n\n27:17.280 --> 27:21.040\n we never really launched the first product. We had enough interest from\n\n27:21.040 --> 27:23.760\n investors and enough of a signal that this was\n\n27:23.760 --> 27:26.880\n something that we should be working on, that after about a year of working on\n\n27:26.880 --> 27:29.840\n the highway autopilot, we had it working, you know, on a\n\n27:29.840 --> 27:33.040\n prototype stage. But we just completely abandoned that\n\n27:33.040 --> 27:36.480\n and said, we're going to go all in on driverless cars now is the time.\n\n27:36.480 --> 27:39.680\n Can't think of anything that's more exciting and if it works more impactful,\n\n27:39.680 --> 27:42.720\n so we're just going to go for it. The idea of retrofit is kind of\n\n27:42.720 --> 27:46.720\n interesting. Yeah. Being able to, it's how you achieve scale.\n\n27:46.720 --> 27:49.600\n It's a really interesting idea. Is it something that's still in the\n\n27:49.600 --> 27:52.800\n in the back of your mind as a possibility?\n\n27:52.800 --> 27:56.720\n Not at all. I've come full circle on that one. After\n\n27:56.720 --> 28:00.640\n trying to build a retrofit product, and I'll touch on some of the complexities\n\n28:00.640 --> 28:04.240\n of that, and then also having been inside an OEM\n\n28:04.240 --> 28:06.880\n and seeing how things work and how a vehicle is developed and\n\n28:06.880 --> 28:09.840\n validated. When it comes to something that has\n\n28:09.840 --> 28:13.200\n safety critical implications like controlling the steering and\n\n28:13.200 --> 28:16.560\n other control inputs on your car, it's pretty hard to get there\n\n28:16.560 --> 28:21.280\n with a retrofit. Or if you did, even if you did, it creates a whole bunch\n\n28:21.280 --> 28:25.040\n of new complications around liability or how did you truly validate\n\n28:25.040 --> 28:28.320\n that. Or you know, something in the base vehicle fails and causes your system to\n\n28:28.320 --> 28:31.280\n fail, whose fault is it?\n\n28:31.280 --> 28:35.040\n Or if the car's anti lock brake systems or other things kick in\n\n28:35.040 --> 28:38.640\n or the software has been, it's different in one version of the car you retrofit\n\n28:38.640 --> 28:40.480\n versus another and you don't know because\n\n28:40.480 --> 28:43.600\n the manufacturer has updated it behind the scenes. There's basically an\n\n28:43.600 --> 28:46.160\n infinite list of long tail issues that can get you.\n\n28:46.160 --> 28:48.160\n And if you're dealing with a safety critical product, that's not really\n\n28:48.160 --> 28:52.000\n acceptable. That's a really convincing summary of why\n\n28:52.000 --> 28:54.880\n that's really challenging. But I didn't know all that at the time, so we tried it\n\n28:54.880 --> 28:57.280\n anyway. But as a pitch also at the time, it's a\n\n28:57.280 --> 29:00.640\n really strong one. Because that's how you achieve scale and that's how you beat\n\n29:00.640 --> 29:04.640\n the current, the leader at the time of Google or the only one in the market.\n\n29:04.640 --> 29:08.560\n The other big problem we ran into, which is perhaps the biggest problem from a\n\n29:08.560 --> 29:13.200\n business model perspective, is we had kind of assumed that we\n\n29:13.200 --> 29:16.160\n started with an Audi S4 as the vehicle we\n\n29:16.160 --> 29:18.720\n retrofitted with this highway driving capability.\n\n29:18.720 --> 29:22.000\n And we had kind of assumed that if we just knock out like three\n\n29:22.000 --> 29:25.360\n make and models of vehicles, that'll cover like 80% of the San Francisco\n\n29:25.360 --> 29:28.800\n market. Doesn't everyone there drive, I don't know, a BMW or a Honda Civic or\n\n29:28.800 --> 29:32.080\n one of these three cars? And then we surveyed our users and we found out that\n\n29:32.080 --> 29:35.680\n it's all over the place. We would, to get even a decent number of\n\n29:35.680 --> 29:39.760\n units sold, we'd have to support like, you know, 20 or 50 different models.\n\n29:39.760 --> 29:43.120\n And each one is a little butterfly that takes time and effort to maintain,\n\n29:43.120 --> 29:47.040\n you know, that retrofit integration and custom hardware and all this.\n\n29:47.040 --> 29:52.720\n So it was a tough business. So GM manufactures and sells over 9 million\n\n29:52.720 --> 29:58.560\n cars a year. And what you with Cruise are trying to do\n\n29:58.560 --> 30:03.120\n some of the most cutting edge innovation in terms of applying AI.\n\n30:03.120 --> 30:06.960\n And so how do those, you've talked about a little bit before, but it's also just\n\n30:06.960 --> 30:09.840\n fascinating to me. We work a lot of automakers,\n\n30:09.840 --> 30:12.880\n you know, the difference between the gap between Detroit\n\n30:12.880 --> 30:17.200\n and Silicon Valley, let's say, just to be sort of poetic about it, I guess.\n\n30:17.200 --> 30:21.360\n How do you close that gap? How do you take GM into the future\n\n30:21.360 --> 30:24.720\n where a large part of the fleet will be autonomous, perhaps?\n\n30:24.720 --> 30:28.160\n I want to start by acknowledging that GM is made up of,\n\n30:28.160 --> 30:31.200\n you know, tens of thousands of really brilliant, motivated people who want to\n\n30:31.200 --> 30:34.800\n be a part of the future. And so it's pretty fun to work\n\n30:34.800 --> 30:37.840\n within the attitude inside a car company like that is, you\n\n30:37.840 --> 30:41.120\n know, embracing this transformation and change\n\n30:41.120 --> 30:44.400\n rather than fearing it. And I think that's a testament to\n\n30:44.400 --> 30:47.680\n the leadership at GM and that's flown all the way through to everyone you\n\n30:47.680 --> 30:51.040\n talk to, even the people in the assembly plants working on these cars.\n\n30:51.040 --> 30:55.120\n So that's really great. So starting from that position makes it a lot easier\n\n30:55.120 --> 30:59.920\n so then when the people in San Francisco at Cruise\n\n30:59.920 --> 31:02.960\n interact with the people at GM, at least we have this common set of values, which\n\n31:02.960 --> 31:04.800\n is that we really want this stuff to work\n\n31:04.800 --> 31:08.160\n because we think it's important and we think it's the future.\n\n31:08.160 --> 31:12.320\n That's not to say, you know, those two cultures don't clash. They absolutely do.\n\n31:12.320 --> 31:15.360\n There's different sort of value systems. Like in a\n\n31:15.360 --> 31:19.360\n car company, the thing that gets you promoted and sort of the reward\n\n31:19.360 --> 31:23.040\n system is following the processes, delivering\n\n31:23.040 --> 31:28.000\n the program on time and on budget. So any sort of risk taking\n\n31:28.000 --> 31:34.560\n is discouraged in many ways because if a program is late or if you shut down\n\n31:34.560 --> 31:38.000\n the plant for a day, it's, you know, you can count the millions of dollars that\n\n31:38.000 --> 31:42.880\n burn by pretty quickly. Whereas I think, you know, most Silicon\n\n31:42.880 --> 31:47.040\n Valley companies and in Cruise and the methodology\n\n31:47.040 --> 31:50.000\n we were employing, especially around the time of the acquisition,\n\n31:50.000 --> 31:53.680\n the reward structure is about trying to solve\n\n31:53.680 --> 31:57.360\n these complex problems in any way shape or form or coming up with crazy ideas\n\n31:57.360 --> 32:02.720\n that, you know, 90% of them won't work. And so meshing that culture\n\n32:02.720 --> 32:05.360\n of sort of continuous improvement and experimentation\n\n32:05.360 --> 32:08.960\n with one where everything needs to be rigorously defined up front so that\n\n32:08.960 --> 32:12.560\n you never slip a deadline or miss a budget\n\n32:12.560 --> 32:16.880\n was a pretty big challenge. And that we're over three years in now\n\n32:16.880 --> 32:20.560\n after the acquisition and I'd say like, you know, the investment we made in\n\n32:20.560 --> 32:23.520\n figuring out how to work together successfully and\n\n32:23.520 --> 32:26.560\n who should do what and how we bridge the gaps between these\n\n32:26.560 --> 32:29.440\n very different systems and way of doing engineering work\n\n32:29.440 --> 32:31.600\n is now one of our greatest assets because I think we have this really\n\n32:31.600 --> 32:36.000\n powerful thing. But for a while it was both GM and Cruise were very\n\n32:36.000 --> 32:38.800\n steep on the learning curve. Yeah, so I'm sure it was very stressful.\n\n32:38.800 --> 32:41.840\n It's really important work because that's how\n\n32:41.840 --> 32:44.880\n to revolutionize the transportation, really to revolutionize\n\n32:44.880 --> 32:48.880\n any system. You know, you look at the health care system or you look at the\n\n32:48.880 --> 32:52.560\n legal system. I have people like Loris come up to me all the time like\n\n32:52.560 --> 32:55.920\n everything they're working on can easily be automated.\n\n32:55.920 --> 32:59.760\n But then that's not a good feeling. Yeah, well it's not a good feeling but also\n\n32:59.760 --> 33:05.120\n there's no way to automate because the entire infrastructure is really,\n\n33:05.120 --> 33:08.880\n you know, based is older and it moves very slowly. And so\n\n33:08.880 --> 33:12.320\n how do you close the gap between I have an\n\n33:12.320 --> 33:15.920\n how can I replace, of course, Loris don't want to be replaced with an app, but you\n\n33:15.920 --> 33:20.000\n could replace a lot of aspect when most of the data is still on paper.\n\n33:20.000 --> 33:23.280\n And so the same thing was with automotive.\n\n33:23.280 --> 33:27.920\n I mean, it's fundamentally software. It's basically hiring software\n\n33:27.920 --> 33:30.160\n engineers. It's thinking in a software world.\n\n33:30.160 --> 33:34.560\n I mean, I'm pretty sure nobody in Silicon Valley has ever hit a deadline.\n\n33:34.560 --> 33:38.560\n So and then on GM. That's probably true, yeah. And GM side is probably the\n\n33:38.560 --> 33:42.640\n opposite. Yeah. So that's that culture gap is really fascinating.\n\n33:42.640 --> 33:45.120\n So you're optimistic about the future of that?\n\n33:45.120 --> 33:48.320\n Yeah, I mean, from what I've seen, it's impressive. And I think like\n\n33:48.320 --> 33:51.760\n especially in Silicon Valley, it's easy to write off building cars because,\n\n33:51.760 --> 33:55.280\n you know, people have been doing that for over 100 years now in this country. And\n\n33:55.280 --> 33:58.080\n so it seems like that's a solved problem, but that doesn't mean it's an easy\n\n33:58.080 --> 34:01.120\n problem. And I think it would be easy to sort of\n\n34:01.120 --> 34:04.960\n overlook that and think that, you know, we're\n\n34:04.960 --> 34:08.880\n Silicon Valley engineers. We can solve any problem, you know, building a car.\n\n34:08.880 --> 34:12.640\n It's been done. Therefore, it's, you know, it's not a real\n\n34:12.640 --> 34:16.960\n engineering challenge. But after having seen just the sheer\n\n34:16.960 --> 34:20.720\n scale and magnitude and industrialization\n\n34:20.720 --> 34:24.320\n that occurs inside of an automotive assembly plant, that is a lot of work\n\n34:24.320 --> 34:28.000\n that I am very glad that we don't have to reinvent\n\n34:28.000 --> 34:31.120\n to make self driving cars work. And so to have, you know, partners who have done\n\n34:31.120 --> 34:33.920\n that for 100 years now, these great processes and this huge infrastructure\n\n34:33.920 --> 34:38.640\n and supply base that we can tap into is just remarkable\n\n34:38.640 --> 34:43.840\n because the scope and surface area of\n\n34:43.840 --> 34:47.200\n the problem of deploying fleets of self driving cars is so large\n\n34:47.200 --> 34:50.240\n that we're constantly looking for ways to do less\n\n34:50.240 --> 34:53.760\n so we can focus on the things that really matter more. And if we had to\n\n34:53.760 --> 34:57.360\n figure out how to build and assemble and\n\n34:57.360 --> 35:01.360\n you know, build the cars themselves. I mean, we work closely with GM on\n\n35:01.360 --> 35:05.040\n that. But if we had to develop all that capability in house as well,\n\n35:05.040 --> 35:10.080\n you know, that would just make the problem really intractable, I think.\n\n35:10.080 --> 35:15.520\n So yeah, just like your first entry at the MIT DARPA challenge when\n\n35:15.520 --> 35:18.640\n there was what the motor that failed, somebody that knows what they're\n\n35:18.640 --> 35:20.960\n doing with the motor did it. That would have been nice if we could\n\n35:20.960 --> 35:23.760\n focus on the software, not the hardware platform.\n\n35:23.760 --> 35:27.760\n Yeah. Right. So from your perspective now,\n\n35:27.760 --> 35:30.480\n you know, there's so many ways that autonomous vehicles can impact\n\n35:30.480 --> 35:34.080\n society in the next year, five years, ten years.\n\n35:34.080 --> 35:37.600\n What do you think is the biggest opportunity to make\n\n35:37.600 --> 35:41.520\n money in autonomous driving, sort of make it a\n\n35:41.520 --> 35:44.560\n financially viable thing in the near term?\n\n35:44.560 --> 35:49.040\n What do you think will be the biggest impact there?\n\n35:49.040 --> 35:53.200\n Well, the things that drive the economics for fleets of self driving\n\n35:53.200 --> 35:57.760\n cars are, there's sort of a handful of variables. One is,\n\n35:57.760 --> 36:02.080\n you know, the cost to build the vehicle itself. So the material cost, how many,\n\n36:02.080 --> 36:05.200\n you know, what's the cost of all your sensors plus the cost of the vehicle and\n\n36:05.200 --> 36:08.720\n every all the other components on it. Another one is the lifetime of the\n\n36:08.720 --> 36:11.120\n vehicle. It's very different if your vehicle\n\n36:11.120 --> 36:13.680\n drives 100,000 miles and then it falls apart versus,\n\n36:13.680 --> 36:18.880\n you know, two million. And then, you know, if you have a fleet, it's\n\n36:18.880 --> 36:23.440\n kind of like an airplane or an airline where\n\n36:23.440 --> 36:26.720\n once you produce the vehicle, you want it to be in\n\n36:26.720 --> 36:30.640\n operation as many hours a day as possible producing revenue.\n\n36:30.640 --> 36:34.000\n And then, you know, the other piece of that is\n\n36:34.000 --> 36:36.800\n how are you generating revenue? I think that's kind of what you're asking. And I\n\n36:36.800 --> 36:40.000\n think the obvious things today are, you know, the ride sharing business\n\n36:40.000 --> 36:42.560\n because that's pretty clear that there's demand for that,\n\n36:42.560 --> 36:46.160\n there's existing markets you can tap into and\n\n36:46.160 --> 36:50.000\n large urban areas, that kind of thing. Yeah, yeah. And I think that there are\n\n36:50.000 --> 36:53.680\n some real benefits to having cars without\n\n36:53.680 --> 36:56.080\n drivers compared to sort of the status quo for\n\n36:56.080 --> 36:58.320\n people who use ride share services today.\n\n36:58.320 --> 37:02.320\n You know, you get privacy, consistency, hopefully significantly improve safety,\n\n37:02.320 --> 37:04.960\n all these benefits versus the current product.\n\n37:04.960 --> 37:08.160\n But it's a crowded market. And then other opportunities, which you've\n\n37:08.160 --> 37:10.960\n seen a lot of activity in the last, really in the last six or twelve months,\n\n37:10.960 --> 37:14.880\n is, you know, delivery, whether that's parcels and packages,\n\n37:14.880 --> 37:20.880\n food or groceries. Those are all sort of, I think, opportunities that are\n\n37:20.880 --> 37:25.120\n pretty ripe for these, you know, once you have this\n\n37:25.120 --> 37:28.640\n core technology, which is the fleet of autonomous vehicles, there's all sorts of\n\n37:28.640 --> 37:31.440\n different business opportunities you can build on\n\n37:31.440 --> 37:34.720\n top of that. But I think the important thing, of course, is that\n\n37:34.720 --> 37:37.760\n there's zero monetization opportunity until you actually have that fleet of\n\n37:37.760 --> 37:40.960\n very capable driverless cars that are that are as good or better than humans.\n\n37:40.960 --> 37:44.160\n And that's sort of where the entire industry is\n\n37:44.160 --> 37:45.840\n sort of in this holding pattern right now.\n\n37:45.840 --> 37:49.200\n Yeah, they're trying to achieve that baseline. So, but you said sort of\n\n37:49.200 --> 37:53.200\n not reliability, consistency. It's kind of interesting, I think I heard you say\n\n37:53.200 --> 37:56.400\n somewhere, I'm not sure if that's what you meant, but\n\n37:56.400 --> 38:01.200\n you know, I can imagine a situation where you would get an autonomous vehicle\n\n38:01.200 --> 38:04.480\n and, you know, when you get into an Uber or Lyft,\n\n38:04.480 --> 38:07.360\n you don't get to choose the driver in a sense that you don't get to choose the\n\n38:07.360 --> 38:12.000\n personality of the driving. Do you think there's a, there's room\n\n38:12.000 --> 38:15.440\n to define the personality of the car the way it drives you in terms of\n\n38:15.440 --> 38:19.680\n aggressiveness, for example, in terms of sort of pushing the\n\n38:19.680 --> 38:23.280\n bound? One of the biggest challenges of autonomous driving is the\n\n38:23.280 --> 38:26.880\n is the trade off between sort of safety and\n\n38:26.880 --> 38:30.880\n assertiveness. And do you think there's any room\n\n38:30.880 --> 38:36.800\n for the human to take a role in that decision? Sort of accept some of the\n\n38:36.800 --> 38:39.920\n liability, I guess. I wouldn't, no, I'd say within\n\n38:39.920 --> 38:43.600\n reasonable bounds, as in we're not gonna, I think it'd be\n\n38:43.600 --> 38:48.000\n highly unlikely we'd expose any knob that would let you, you know, significantly\n\n38:48.000 --> 38:51.280\n increase safety risk. I think that's just not\n\n38:51.280 --> 38:56.400\n something we'd be willing to do. But I think driving style or like, you\n\n38:56.400 --> 39:00.000\n know, are you going to relax the comfort constraints slightly or things like that,\n\n39:00.000 --> 39:03.280\n all of those things make sense and are plausible. I see all those as, you know,\n\n39:03.280 --> 39:07.200\n nice optimizations. Once again, we get the core problem solved in these fleets\n\n39:07.200 --> 39:09.840\n out there. But the other thing we've sort of\n\n39:09.840 --> 39:13.520\n observed is that you have this intuition that if you\n\n39:13.520 --> 39:16.640\n sort of slam your foot on the gas right after the light turns green and\n\n39:16.640 --> 39:19.840\n aggressively accelerate, you're going to get there faster. But the\n\n39:19.840 --> 39:22.000\n actual impact of doing that is pretty small.\n\n39:22.000 --> 39:25.680\n You feel like you're getting there faster, but so the same would be\n\n39:25.680 --> 39:29.440\n true for AVs. Even if they don't slam their, you know, the pedal to the floor\n\n39:29.440 --> 39:32.240\n when the light turns green, they're going to get you there within, you\n\n39:32.240 --> 39:35.200\n know, if it's a 15 minute trip, within 30 seconds of what you would have done\n\n39:35.200 --> 39:37.680\n otherwise if you were going really aggressively.\n\n39:37.680 --> 39:42.560\n So I think there's this sort of self deception that my aggressive\n\n39:42.560 --> 39:44.240\n driving style is getting me there faster.\n\n39:44.240 --> 39:46.960\n Well, so that's, you know, some of the things I've studied, some of the things\n\n39:46.960 --> 39:50.560\n I'm fascinated by the psychology of that. I don't think it matters\n\n39:50.560 --> 39:55.440\n that it doesn't get you there faster. It's the emotional release.\n\n39:55.440 --> 39:58.960\n Driving is a place, being inside of a car,\n\n39:58.960 --> 40:02.800\n somebody said it's like the real world version of being a troll.\n\n40:02.800 --> 40:05.920\n So you have this protection, this mental protection, you're able to sort of yell\n\n40:05.920 --> 40:08.320\n at the world, like release your anger, whatever.\n\n40:08.320 --> 40:12.240\n So there's an element of that that I think autonomous vehicles would also\n\n40:12.240 --> 40:16.320\n have to, you know, giving an outlet to people, but it doesn't have to be\n\n40:16.320 --> 40:19.520\n through, through, through driving or honking or so on.\n\n40:19.520 --> 40:23.840\n There might be other outlets, but I think to just sort of even just put that aside,\n\n40:23.840 --> 40:26.720\n the baseline is really, you know, that's the focus.\n\n40:26.720 --> 40:28.000\n That's the thing you need to solve.\n\n40:28.000 --> 40:30.800\n And then the fun human things can be solved after.\n\n40:30.800 --> 40:35.120\n But so from the baseline of just solving autonomous driving, you're working in\n\n40:35.120 --> 40:38.800\n San Francisco, one of the more difficult cities to operate in.\n\n40:38.800 --> 40:43.200\n What is, what is the, in your view, currently the hardest\n\n40:43.200 --> 40:45.680\n aspect of autonomous driving?\n\n40:45.680 --> 40:49.040\n Is it negotiating with pedestrians?\n\n40:49.040 --> 40:51.280\n Is it edge cases of perception?\n\n40:51.280 --> 40:52.880\n Is it planning?\n\n40:52.880 --> 40:54.400\n Is there a mechanical engineering?\n\n40:54.400 --> 40:56.080\n Is it data, fleet stuff?\n\n40:57.280 --> 41:00.960\n What are your thoughts on the challenge, the more challenging aspects there?\n\n41:00.960 --> 41:02.080\n That's a, that's a good question.\n\n41:02.080 --> 41:04.800\n I think before, before we go to that, though, I just want to, I like what you\n\n41:04.800 --> 41:07.440\n said about the psychology aspect of this,\n\n41:07.440 --> 41:11.200\n because I think one observation I've made is I think I read somewhere that I\n\n41:11.200 --> 41:14.960\n think it's maybe Americans on average spend, you know, over an hour a day on\n\n41:14.960 --> 41:18.160\n social media, like staring at Facebook.\n\n41:18.160 --> 41:21.520\n And so that's just, you know, 60 minutes of your life, you're not getting back.\n\n41:21.520 --> 41:23.040\n It's probably not super productive.\n\n41:23.040 --> 41:26.160\n And so that's 3,600 seconds, right?\n\n41:26.160 --> 41:30.560\n And that's, that's time, you know, it's a lot of time you're giving up.\n\n41:30.560 --> 41:35.520\n And if you compare that to people being on the road, if another vehicle, whether\n\n41:35.520 --> 41:38.960\n it's a human driver or autonomous vehicle, delays them by even three\n\n41:38.960 --> 41:43.120\n seconds, they're laying in on the horn, you know, even though that's, that's, you\n\n41:43.120 --> 41:46.320\n know, one, one thousandth of the time they waste looking at Facebook every day.\n\n41:46.320 --> 41:47.920\n So there's, there's definitely some.\n\n41:48.560 --> 41:51.040\n You know, psychology aspects of this, I think that are pretty interesting road\n\n41:51.040 --> 41:51.680\n rage in general.\n\n41:51.680 --> 41:54.880\n And then the question of course is if everyone is in self driving cars,\n\n41:54.880 --> 41:57.520\n do they even notice these three second delays anymore?\n\n41:57.520 --> 42:01.280\n Cause they're doing other things or reading or working or just talking to\n\n42:01.280 --> 42:01.680\n each other.\n\n42:01.680 --> 42:03.120\n So it'll be interesting to see where that goes.\n\n42:03.120 --> 42:06.800\n In a certain aspect, people, people need to be distracted by something\n\n42:06.800 --> 42:09.040\n entertaining, something useful inside the car.\n\n42:09.040 --> 42:10.880\n So they don't pay attention to the external world.\n\n42:10.880 --> 42:15.520\n And then, and then they can take whatever psychology and bring it back to\n\n42:15.520 --> 42:21.680\n Twitter and then focus on that as opposed to sort of interacting, sort of putting\n\n42:21.680 --> 42:23.120\n the emotion out there into the world.\n\n42:23.120 --> 42:26.080\n So it's a, it's an interesting problem, but baseline autonomy.\n\n42:26.800 --> 42:30.320\n I guess you could say self driving cars, you know, at scale will lower the\n\n42:30.320 --> 42:34.160\n collective blood pressure of society probably by a couple of points without\n\n42:34.160 --> 42:35.680\n all that road rage and stress.\n\n42:35.680 --> 42:37.200\n So that's a good, good external.\n\n42:38.480 --> 42:43.280\n So back to your question about the technology and the, I guess the biggest\n\n42:43.280 --> 42:43.680\n problems.\n\n42:43.680 --> 42:47.040\n And I have a hard time answering that question because, you know, we've been\n\n42:47.040 --> 42:52.320\n at this like specifically focusing on driverless cars and all the technology\n\n42:52.320 --> 42:55.120\n needed to enable that for a little over four and a half years now.\n\n42:55.120 --> 43:02.880\n And even a year or two in, I felt like we had completed the functionality needed\n\n43:02.880 --> 43:04.800\n to get someone from point A to point B.\n\n43:04.800 --> 43:08.320\n As in, if we need to do a left turn maneuver, or if we need to drive around\n\n43:08.320 --> 43:12.320\n at, you know, a double parked vehicle into oncoming traffic or navigate\n\n43:12.320 --> 43:16.400\n through construction zones, the scaffolding and the building blocks was\n\n43:16.400 --> 43:17.760\n there pretty early on.\n\n43:17.760 --> 43:23.040\n And so the challenge is not any one scenario or situation for which, you\n\n43:23.040 --> 43:25.520\n know, we fail at 100% of those.\n\n43:25.520 --> 43:29.520\n It's more, you know, we're benchmarking against a pretty good or pretty high\n\n43:29.520 --> 43:31.280\n standard, which is human driving.\n\n43:31.280 --> 43:35.280\n All things considered, humans are excellent at handling edge cases and\n\n43:35.280 --> 43:37.520\n unexpected scenarios where computers are the opposite.\n\n43:38.320 --> 43:43.040\n And so beating that baseline set by humans is the challenge.\n\n43:43.040 --> 43:49.360\n And so what we've been doing for quite some time now is basically, it's this\n\n43:49.360 --> 43:53.920\n continuous improvement process where we find sort of the most, you know,\n\n43:53.920 --> 43:59.920\n uncomfortable or the things that could lead to a safety issue or other\n\n43:59.920 --> 44:00.800\n things, all these events.\n\n44:00.800 --> 44:05.120\n And then we sort of categorize them and rework parts of our system to make\n\n44:05.120 --> 44:07.920\n incremental improvements and do that over and over and over again.\n\n44:07.920 --> 44:12.080\n And we just see sort of the overall performance of the system, you know,\n\n44:12.080 --> 44:13.840\n actually increasing in a pretty steady clip.\n\n44:13.840 --> 44:15.200\n But there's no one thing.\n\n44:15.200 --> 44:19.760\n There's actually like thousands of little things and just like polishing functionality\n\n44:19.760 --> 44:23.280\n and making sure that it handles, you know, every version and possible\n\n44:23.280 --> 44:30.160\n permutation of a situation by either applying more deep learning systems or\n\n44:30.160 --> 44:34.400\n just by, you know, adding more test coverage or new scenarios that we\n\n44:34.400 --> 44:37.040\n develop against and just grinding on that.\n\n44:37.040 --> 44:40.560\n We're sort of in the unsexy phase of development right now, which is doing\n\n44:40.560 --> 44:44.000\n the real engineering work that it takes to go from prototype to production.\n\n44:44.000 --> 44:49.920\n You're basically scaling the grinding, sort of taking seriously that the\n\n44:49.920 --> 44:54.320\n process of all those edge cases, both with human experts and machine\n\n44:54.320 --> 44:59.200\n learning methods to cover all those situations.\n\n44:59.200 --> 44:59.360\n Yeah.\n\n44:59.360 --> 45:03.200\n And the exciting thing for me is I don't think that grinding ever stops because\n\n45:03.200 --> 45:08.080\n there's a moment in time where you've crossed that threshold of human\n\n45:08.080 --> 45:09.680\n performance and become superhuman.\n\n45:09.680 --> 45:13.920\n But there's no reason, there's no first principles reason that AV capability\n\n45:13.920 --> 45:16.080\n will tap out anywhere near humans.\n\n45:16.080 --> 45:19.680\n Like there's no reason it couldn't be 20 times better, whether that's, you\n\n45:19.680 --> 45:22.960\n know, just better driving or safer driving or more comfortable driving or\n\n45:22.960 --> 45:25.360\n even a thousand times better given enough time.\n\n45:25.360 --> 45:30.560\n And we intend to basically chase that, you know, forever to build the best\n\n45:30.560 --> 45:31.360\n possible product.\n\n45:31.360 --> 45:32.480\n Better and better and better.\n\n45:32.480 --> 45:34.880\n And always new edge cases come up and new experiences.\n\n45:34.880 --> 45:40.000\n So, and you want to automate that process as much as possible.\n\n45:40.000 --> 45:43.280\n So what do you think in general in society?\n\n45:43.840 --> 45:47.600\n When do you think we may have hundreds of thousands of fully autonomous\n\n45:47.600 --> 45:48.640\n vehicles driving around?\n\n45:48.640 --> 45:52.000\n So first of all, predictions, nobody knows the future.\n\n45:52.000 --> 45:55.600\n You're a part of the leading people trying to define that future, but even\n\n45:55.600 --> 45:56.960\n then you still don't know.\n\n45:56.960 --> 46:02.720\n But if you think about hundreds of thousands of vehicles, so a significant\n\n46:02.720 --> 46:05.920\n fraction of vehicles in major cities are autonomous.\n\n46:05.920 --> 46:12.960\n Do you think, are you with Rodney Brooks, who is 2050 and beyond, or are you\n\n46:12.960 --> 46:17.920\n more with Elon Musk, who is, we should have had that two years ago?\n\n46:19.040 --> 46:24.640\n Well, I mean, I'd love to have it two years ago, but we're not there yet.\n\n46:24.640 --> 46:29.440\n So I guess the way I would think about that is let's flip that question\n\n46:29.440 --> 46:29.760\n around.\n\n46:29.760 --> 46:34.480\n So what would prevent you to reach hundreds of thousands of vehicles?\n\n46:34.480 --> 46:36.720\n And that's a good, that's a good rephrasing.\n\n46:36.720 --> 46:37.120\n Yeah.\n\n46:37.120 --> 46:47.120\n So the, I'd say the, it seems the consensus among the people developing\n\n46:47.120 --> 46:50.960\n self driving cars today is to sort of start with some form of an easier\n\n46:51.360 --> 46:55.760\n environment, whether it means, you know, lacking inclement weather or, you\n\n46:55.760 --> 46:57.600\n know, mostly sunny or whatever it is.\n\n46:57.600 --> 47:02.400\n And then add, add capability for more complex situations over time.\n\n47:02.880 --> 47:08.400\n And so if you're only able to deploy in areas that meet sort of your\n\n47:08.400 --> 47:11.760\n criteria or the current domain, you know, operating domain of the\n\n47:11.760 --> 47:14.720\n software you developed, that may put a cap on how many cities you could\n\n47:14.720 --> 47:15.280\n deploy in.\n\n47:16.720 --> 47:20.320\n But then as those restrictions start to fall away, like maybe you add\n\n47:20.320 --> 47:24.720\n capability to drive really well and safely in heavy rain or snow, you\n\n47:24.720 --> 47:28.080\n know, that, that probably opens up the market by two, two or three fold\n\n47:28.160 --> 47:30.560\n in terms of the cities you can expand into and so on.\n\n47:31.040 --> 47:35.120\n And so the real question is, you know, I know today if we wanted to, we\n\n47:35.120 --> 47:38.640\n could produce that, that many autonomous vehicles, but we wouldn't be\n\n47:38.640 --> 47:39.920\n able to make use of all of them yet.\n\n47:39.920 --> 47:43.440\n Cause we would sort of saturate the demand in the cities in which we\n\n47:43.440 --> 47:45.040\n would want to operate initially.\n\n47:46.480 --> 47:49.280\n So if I were to guess like what the timeline is for those things falling\n\n47:49.280 --> 47:53.040\n away and reaching hundreds of thousands of vehicles, I would say that\n\n47:53.040 --> 47:57.360\n thousands of vehicles, maybe a range is better, I would say less than\n\n47:57.360 --> 47:58.880\n five years, less than five years.\n\n47:58.880 --> 47:59.200\n Yeah.\n\n47:59.920 --> 48:02.480\n And of course you're working hard to make that happen.\n\n48:03.520 --> 48:07.680\n So you started two companies that were eventually acquired for each\n\n48:07.680 --> 48:08.800\n four billion dollars.\n\n48:09.680 --> 48:12.560\n So you're a pretty good person to ask, what does it take to build a\n\n48:12.560 --> 48:13.520\n successful startup?\n\n48:15.280 --> 48:19.680\n I think there's, there's sort of survivor bias here a little bit, but\n\n48:19.680 --> 48:21.920\n I can try to find some common threads for the things that worked for\n\n48:21.920 --> 48:27.520\n me, which is, you know, in, in both of these companies, I was really\n\n48:27.520 --> 48:29.040\n passionate about the core technology.\n\n48:29.040 --> 48:31.600\n I actually like, you know, lay awake at night thinking about these\n\n48:31.600 --> 48:33.360\n problems and how to solve them.\n\n48:33.360 --> 48:36.160\n And I think that's helpful because when you start a business, there\n\n48:36.160 --> 48:40.800\n are like to this day, there are these crazy ups and downs.\n\n48:40.800 --> 48:43.200\n Like one day you think the business is just on, you're just on top of\n\n48:43.200 --> 48:44.320\n the world and unstoppable.\n\n48:44.320 --> 48:47.360\n And the next day you think, okay, this is all going to end, you know,\n\n48:47.360 --> 48:49.600\n it's just, it's just going south and it's going to be over tomorrow.\n\n48:49.600 --> 48:55.280\n And and so I think like having a true passion that you can fall back\n\n48:55.280 --> 48:57.600\n on and knowing that you would be doing it, even if you weren't getting\n\n48:57.600 --> 49:00.000\n paid for it, helps you weather those, those tough times.\n\n49:00.880 --> 49:01.680\n So that's one thing.\n\n49:01.680 --> 49:05.200\n I think the other one is really good people.\n\n49:05.200 --> 49:08.640\n So I've always been surrounded by really good cofounders that are\n\n49:08.640 --> 49:11.920\n logical thinkers are always pushing their limits and have very high\n\n49:11.920 --> 49:12.880\n levels of integrity.\n\n49:12.880 --> 49:16.320\n So that's Dan Kahn and my current company and actually his brother and\n\n49:16.320 --> 49:18.720\n a couple other guys for Justin TV and Twitch.\n\n49:18.720 --> 49:24.000\n And then I think the last thing is just I guess persistence or\n\n49:24.000 --> 49:28.880\n perseverance, like, and, and that, that can apply to sticking to sort\n\n49:28.880 --> 49:32.960\n of, or having conviction around the original premise of your idea and\n\n49:32.960 --> 49:36.400\n sticking around to do all the, you know, the unsexy work to actually\n\n49:36.400 --> 49:41.200\n make it come to fruition, including dealing with, you know, whatever\n\n49:41.200 --> 49:43.280\n it is that you, that you're not passionate about, whether that's\n\n49:43.280 --> 49:48.320\n finance or, or HR or, or operations or those things, as long as you\n\n49:48.320 --> 49:51.920\n are grinding away and working towards, you know, that North star\n\n49:51.920 --> 49:55.040\n for your business, whatever it is, and you don't give up and you're\n\n49:55.040 --> 49:57.920\n making progress every day, it seems like eventually you'll end up in a\n\n49:57.920 --> 49:58.400\n good place.\n\n49:58.400 --> 50:00.640\n And the only things that can slow you down are, you know, running out\n\n50:00.640 --> 50:02.880\n of money or I suppose your competitors destroying you.\n\n50:02.880 --> 50:06.720\n But I think most of the time it's, it's people giving up or, or somehow\n\n50:06.800 --> 50:09.360\n destroying things themselves rather than being beaten by their competition\n\n50:09.360 --> 50:10.160\n or running out of money.\n\n50:10.800 --> 50:11.040\n Yeah.\n\n50:11.040 --> 50:12.720\n If you never quit, eventually you'll arrive.\n\n50:13.680 --> 50:16.640\n So, uh, it's a much more concise version of what I was trying to say.\n\n50:16.640 --> 50:18.640\n Yeah, that was good.\n\n50:18.640 --> 50:20.800\n So you went the Y Combinator route twice.\n\n50:20.800 --> 50:21.040\n Yeah.\n\n50:21.680 --> 50:24.880\n What do you think in a quick question, do you think is the best way to\n\n50:24.880 --> 50:30.080\n raise funds in the early days or not just funds, but just community\n\n50:30.080 --> 50:31.360\n develop your idea and so on.\n\n50:32.160 --> 50:38.720\n Can you do it solo or maybe with a co founder with like self funded?\n\n50:38.720 --> 50:40.000\n Do you think Y Combinator is good?\n\n50:40.000 --> 50:41.600\n Is it good to do VC route?\n\n50:41.600 --> 50:45.120\n Is there no right answer or is there from the Y Combinator experience\n\n50:45.120 --> 50:48.000\n something that you could take away that that was the right path to take?\n\n50:48.160 --> 50:53.200\n There's no one size fits all answer, but if your ambition I think is to, you\n\n50:53.200 --> 50:57.920\n know, see how big you can make something or, or, or rapidly expand and capture\n\n50:57.920 --> 51:01.440\n a market or solve a problem or whatever it is, then, then, you know, going to\n\n51:01.440 --> 51:04.960\n venture back route is probably a good approach so that, so that capital doesn't\n\n51:04.960 --> 51:06.400\n become your primary constraint.\n\n51:07.120 --> 51:12.320\n Y Combinator I love because it puts you in this, uh, sort of competitive\n\n51:12.320 --> 51:16.080\n environment where you're, where you're surrounded by, you know, the top, maybe\n\n51:16.080 --> 51:20.800\n 1% of other really highly motivated, you know, peers who are in the same, same\n\n51:20.800 --> 51:26.560\n place and that, uh, that environment I think just breeds breed success, right?\n\n51:26.560 --> 51:29.280\n If you're surrounded by really brilliant, hardworking people, you're going to\n\n51:29.680 --> 51:33.280\n feel, you know, sort of compelled or inspired to, to try to emulate them and\n\n51:33.280 --> 51:34.000\n or beat them.\n\n51:34.320 --> 51:39.440\n And, uh, so even though I had done it once before and I felt like, yeah, I'm\n\n51:39.520 --> 51:40.720\n pretty self motivated.\n\n51:40.720 --> 51:42.400\n I thought like, look, this is going to be a hard problem.\n\n51:42.400 --> 51:43.760\n I can use all the help I can get.\n\n51:44.000 --> 51:46.960\n So surrounding myself with other entrepreneurs is going to make me work a\n\n51:46.960 --> 51:49.760\n little bit harder or push a little harder than it's worth it.\n\n51:50.320 --> 51:52.880\n And so that's why I, why I did it, you know, for example, the second time.\n\n51:53.440 --> 51:55.920\n Let's, uh, let's go philosophical existential.\n\n51:56.400 --> 52:02.320\n If you go back and do something differently in your life, starting in the\n\n52:02.320 --> 52:07.840\n high school and MIT leaving MIT, you could have gone the PhD route doing the\n\n52:07.840 --> 52:13.760\n startup, going to see about a startup in California and you, or maybe some\n\n52:13.760 --> 52:14.800\n aspects of fundraising.\n\n52:14.800 --> 52:19.600\n Is there something you regret, something you not necessarily regret, but if\n\n52:19.600 --> 52:21.040\n you go back, you could do differently.\n\n52:21.600 --> 52:24.560\n I think I've made a lot of mistakes, like, you know, pretty much everything\n\n52:24.560 --> 52:25.200\n you can screw up.\n\n52:25.200 --> 52:29.200\n I think I've screwed up at least once, but I, you know, I don't regret those\n\n52:29.200 --> 52:29.600\n things.\n\n52:29.920 --> 52:32.640\n I think it's, it's hard to, it's hard to look back on things, even if it didn't\n\n52:32.640 --> 52:36.960\n go well and call it a regret, because hopefully it took away some new knowledge\n\n52:36.960 --> 52:37.760\n or learning from that.\n\n52:37.760 --> 52:43.760\n So I would say there was a period.\n\n52:44.560 --> 52:44.880\n Yeah.\n\n52:45.200 --> 52:48.640\n The closest I can, I can come to is there's a period, um, in, in Justin\n\n52:48.640 --> 52:54.240\n TV, I think after seven years where, you know, the company was going one\n\n52:54.240 --> 52:56.720\n direction, which is towards Twitch, uh, in video gaming.\n\n52:56.720 --> 52:58.080\n I'm not a video gamer.\n\n52:58.160 --> 53:00.160\n I don't really even use Twitch at all.\n\n53:01.280 --> 53:04.960\n And I was still, uh, working on the core technology there, but my, my heart\n\n53:04.960 --> 53:07.760\n was no longer in it because the business that we were creating was not something\n\n53:07.760 --> 53:09.280\n that I was personally passionate about.\n\n53:09.360 --> 53:11.600\n It didn't meet your bar of existential impact.\n\n53:11.680 --> 53:12.080\n Yeah.\n\n53:12.080 --> 53:16.320\n And I'd say I probably spent an extra year or two working on that.\n\n53:16.560 --> 53:20.880\n And, uh, and I'd say like, I would have just tried to do something different\n\n53:20.880 --> 53:26.400\n sooner because those, those were two years where I felt like, um, you know,\n\n53:26.400 --> 53:29.840\n from this philosophical or existential thing, I just, I just felt that\n\n53:29.840 --> 53:30.640\n something was missing.\n\n53:30.720 --> 53:33.440\n And so I would have, I would have, if I could look back now and tell myself,\n\n53:33.440 --> 53:35.040\n it's like, I would have said exactly that.\n\n53:35.040 --> 53:38.240\n Like, you're not getting any meaning out of your work personally right now.\n\n53:38.800 --> 53:40.400\n You should, you should find a way to change that.\n\n53:41.040 --> 53:44.800\n And that's, that's part of the pitch I use to basically everyone who joins\n\n53:44.800 --> 53:47.280\n Cruise today, it's like, Hey, you've got that now by coming here.\n\n53:47.840 --> 53:51.200\n Well, maybe you needed the two years of that existential dread to develop\n\n53:51.280 --> 53:54.160\n the feeling that ultimately it was the fire that created Cruise.\n\n53:54.400 --> 53:54.960\n So, you never know.\n\n53:55.040 --> 53:56.080\n You can't, good theory.\n\n53:56.640 --> 54:00.640\n So last question, what does 2019 hold for Cruise?\n\n54:00.640 --> 54:03.280\n After this, I guess we're going to go and I'll talk to your class.\n\n54:03.280 --> 54:06.880\n But one of the big things is going from prototype to production, uh, for\n\n54:06.880 --> 54:08.160\n autonomous cars and what does that mean?\n\n54:08.160 --> 54:08.800\n What does that look like?\n\n54:08.800 --> 54:14.160\n And 2019 for us is the year that we try to cross over that threshold and reach,\n\n54:14.240 --> 54:18.080\n you know, superhuman level of performance to some degree with the software and,\n\n54:18.080 --> 54:22.320\n uh, have all the other of the thousands of little building blocks in place to,\n\n54:22.320 --> 54:26.000\n to launch, um, you know, our, our first, uh, commercial product.\n\n54:26.000 --> 54:28.880\n So that's, that's, what's in store for us or in store for us.\n\n54:28.880 --> 54:31.200\n And we've got a lot of work to do.\n\n54:31.280 --> 54:33.200\n We've got a lot of brilliant people working on it.\n\n54:34.080 --> 54:35.600\n So it's, it's all up to us now.\n\n54:36.160 --> 54:36.400\n Yeah.\n\n54:36.400 --> 54:40.720\n From Charlie Miller and Chris Vells, like the people I've crossed paths with.\n\n54:40.720 --> 54:41.040\n Oh, great.\n\n54:41.040 --> 54:44.080\n If you, it sounds like you have an amazing team.\n\n54:44.080 --> 54:48.240\n So, um, like I said, it's one of the most, I think one of the most important\n\n54:48.560 --> 54:50.560\n problems in artificial intelligence of the century.\n\n54:50.560 --> 54:53.680\n It'll be one of the most defining, the super exciting that you work on it.\n\n54:53.680 --> 54:58.640\n And, uh, the best of luck in 2018, I'm really excited to see what\n\n54:58.640 --> 54:59.680\n Cruz comes up with.\n\n54:59.680 --> 55:00.160\n Thank you.\n\n55:00.160 --> 55:01.040\n Thanks for having me today.\n\n55:01.040 --> 55:24.080\n Thanks, Carl.\n\n"
}
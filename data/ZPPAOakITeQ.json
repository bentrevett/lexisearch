{
  "title": "Sebastian Thrun: Flying Cars, Autonomous Vehicles, and Education | Lex Fridman Podcast #59",
  "id": "ZPPAOakITeQ",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:03.480\n The following is a conversation with Sebastian Thrun.\n\n00:03.480 --> 00:08.080\n He's one of the greatest roboticists, computer scientists, and educators of our time.\n\n00:08.080 --> 00:11.440\n He led the development of the autonomous vehicles at Stanford\n\n00:11.440 --> 00:18.120\n that won the 2005 DARPA Grand Challenge and placed second in the 2007 DARPA Urban Challenge.\n\n00:18.120 --> 00:24.600\n He then led the Google self driving car program, which launched the self driving car revolution.\n\n00:24.600 --> 00:29.040\n He taught the popular Stanford course on artificial intelligence in 2011,\n\n00:29.040 --> 00:35.000\n which was one of the first massive open online courses, or MOOCs as they're commonly called.\n\n00:35.000 --> 00:39.800\n That experience led him to co found Udacity, an online education platform.\n\n00:39.800 --> 00:43.280\n If you haven't taken courses on it yet, I highly recommend it.\n\n00:43.280 --> 00:47.120\n Their self driving car program, for example, is excellent.\n\n00:47.120 --> 00:52.960\n He's also the CEO of Kitty Hawk, a company working on building flying cars,\n\n00:52.960 --> 00:58.640\n or more technically, EVTOLs, which stands for electric vertical takeoff and landing aircraft.\n\n00:58.640 --> 01:02.640\n He has launched several revolutions and inspired millions of people.\n\n01:02.640 --> 01:06.800\n But also, as many know, he's just a really nice guy.\n\n01:06.800 --> 01:10.520\n It was an honor and a pleasure to talk with him.\n\n01:10.520 --> 01:12.760\n This is the Artificial Intelligence Podcast.\n\n01:12.760 --> 01:17.080\n If you enjoy it, subscribe on YouTube, give it five stars on Apple Podcast,\n\n01:17.080 --> 01:21.800\n follow it on Spotify, support it on Patreon, or simply connect with me on Twitter\n\n01:21.800 --> 01:25.800\n at Lex Friedman, spelled F R I D M A N.\n\n01:25.800 --> 01:29.200\n If you leave a review on Apple Podcast or YouTube or Twitter,\n\n01:29.200 --> 01:32.800\n consider mentioning ideas, people, topics you find interesting.\n\n01:32.800 --> 01:35.760\n It helps guide the future of this podcast.\n\n01:35.760 --> 01:40.080\n But in general, I just love comments with kindness and thoughtfulness in them.\n\n01:40.080 --> 01:43.560\n This podcast is a side project for me, as many people know,\n\n01:43.560 --> 01:45.800\n but I still put a lot of effort into it.\n\n01:45.800 --> 01:52.120\n So the positive words of support from an amazing community, from you, really help.\n\n01:52.120 --> 01:55.160\n I recently started doing ads at the end of the introduction.\n\n01:55.160 --> 01:58.080\n I'll do one or two minutes after introducing the episode\n\n01:58.080 --> 02:01.800\n and never any ads in the middle that can break the flow of the conversation.\n\n02:01.800 --> 02:05.360\n I hope that works for you and doesn't hurt the listening experience.\n\n02:05.360 --> 02:09.240\n I provide timestamps for the start of the conversation that you can skip to,\n\n02:09.240 --> 02:12.680\n but it helps if you listen to the ad and support this podcast\n\n02:12.680 --> 02:16.440\n by trying out the product or service being advertised.\n\n02:16.440 --> 02:21.400\n This show is presented by Cash App, the number one finance app in the App Store.\n\n02:21.400 --> 02:24.000\n I personally use Cash App to send money to friends,\n\n02:24.000 --> 02:28.160\n but you can also use it to buy, sell, and deposit Bitcoin in just seconds.\n\n02:28.160 --> 02:31.040\n Cash App also has a new investing feature.\n\n02:31.040 --> 02:36.560\n You can buy fractions of a stock, say $1 worth, no matter what the stock price is.\n\n02:36.560 --> 02:39.480\n Broker services are provided by Cash App Investing,\n\n02:39.480 --> 02:42.920\n a subsidiary of Square, and member SIPC.\n\n02:42.920 --> 02:44.640\n I'm excited to be working with Cash App\n\n02:44.640 --> 02:47.840\n to support one of my favorite organizations called FIRST,\n\n02:47.840 --> 02:51.280\n best known for their FIRST Robotics and LEGO competitions.\n\n02:51.280 --> 02:54.640\n They educate and inspire hundreds of thousands of students\n\n02:54.640 --> 02:59.000\n in over 110 countries and have a perfect rating on Charity Navigator,\n\n02:59.000 --> 03:03.080\n which means the donated money is used to maximum effectiveness.\n\n03:03.080 --> 03:06.040\n When you get Cash App from the App Store or Google Play\n\n03:06.040 --> 03:09.320\n and use code LEGSPODCAST, you'll get $10,\n\n03:09.320 --> 03:12.080\n and Cash App will also donate $10 to FIRST,\n\n03:12.080 --> 03:16.640\n which again is an organization that I've personally seen inspire girls and boys\n\n03:16.640 --> 03:19.720\n to dream of engineering a better world.\n\n03:19.720 --> 03:24.920\n And now, here's my conversation with Sebastian Thrun.\n\n03:24.920 --> 03:28.960\n You mentioned that The Matrix may be your favorite movie.\n\n03:28.960 --> 03:32.160\n So let's start with a crazy philosophical question.\n\n03:32.160 --> 03:34.800\n Do you think we're living in a simulation?\n\n03:34.800 --> 03:40.000\n And in general, do you find the thought experiment interesting?\n\n03:40.000 --> 03:42.240\n Define simulation, I would say.\n\n03:42.240 --> 03:43.720\n Maybe we are, maybe we are not,\n\n03:43.720 --> 03:47.160\n but it's completely irrelevant to the way we should act.\n\n03:47.160 --> 03:49.880\n Putting aside, for a moment,\n\n03:49.880 --> 03:55.080\n the fact that it might not have any impact on how we should act as human beings,\n\n03:55.080 --> 03:57.280\n for people studying theoretical physics,\n\n03:57.280 --> 03:59.560\n these kinds of questions might be kind of interesting,\n\n03:59.560 --> 04:03.720\n looking at the universe as an information processing system.\n\n04:03.720 --> 04:05.920\n The universe is an information processing system.\n\n04:05.920 --> 04:10.960\n It's a huge physical, biological, chemical computer, there's no question.\n\n04:10.960 --> 04:12.880\n But I live here and now.\n\n04:12.880 --> 04:15.600\n I care about people, I care about us.\n\n04:15.600 --> 04:17.600\n What do you think is trying to compute?\n\n04:17.600 --> 04:18.800\n I don't think there's an intention.\n\n04:18.800 --> 04:22.000\n I think the world evolves the way it evolves.\n\n04:22.000 --> 04:25.360\n And it's beautiful, it's unpredictable.\n\n04:25.360 --> 04:28.040\n And I'm really, really grateful to be alive.\n\n04:28.040 --> 04:30.480\n Spoken like a true human.\n\n04:30.480 --> 04:33.360\n Which last time I checked, I was.\n\n04:33.360 --> 04:36.480\n Or that, in fact, this whole conversation is just a touring test\n\n04:36.480 --> 04:40.240\n to see if indeed you are.\n\n04:40.240 --> 04:42.720\n You've also said that one of the first programs,\n\n04:42.720 --> 04:49.080\n or the first few programs you've written was a, wait for it, TI57 calculator.\n\n04:49.080 --> 04:50.000\n Yeah.\n\n04:50.000 --> 04:52.000\n Maybe that's early 80s.\n\n04:52.000 --> 04:54.240\n We don't want to date calculators or anything.\n\n04:54.240 --> 04:55.560\n That's early 80s, correct.\n\n04:55.560 --> 04:56.440\n Yeah.\n\n04:56.440 --> 05:02.120\n So if you were to place yourself back into that time, into the mindset you were in,\n\n05:02.120 --> 05:06.840\n could you have predicted the evolution of computing, AI,\n\n05:06.840 --> 05:10.720\n the internet technology in the decades that followed?\n\n05:10.720 --> 05:14.960\n I was super fascinated by Silicon Valley, which I'd seen on television once\n\n05:14.960 --> 05:16.400\n and thought, my god, this is so cool.\n\n05:16.400 --> 05:19.600\n They build like DRAMs there and CPUs.\n\n05:19.600 --> 05:20.440\n How cool is that?\n\n05:20.440 --> 05:25.240\n And as a college student a few years later, I decided to really study\n\n05:25.240 --> 05:26.920\n intelligence and study human beings.\n\n05:26.920 --> 05:30.560\n And found that even back then in the 80s and 90s,\n\n05:30.560 --> 05:33.440\n artificial intelligence is what fascinated me the most.\n\n05:33.440 --> 05:38.040\n What's missing is that back in the day, the computers are really small.\n\n05:38.040 --> 05:41.560\n The brains we could build were not anywhere bigger than a cockroach.\n\n05:41.560 --> 05:43.760\n And cockroaches aren't very smart.\n\n05:43.760 --> 05:46.320\n So we weren't at the scale yet where we are today.\n\n05:46.320 --> 05:51.040\n Did you dream at that time to achieve the kind of scale we have today?\n\n05:51.040 --> 05:52.680\n Or did that seem possible?\n\n05:52.680 --> 05:54.320\n I always wanted to make robots smart.\n\n05:54.320 --> 05:57.960\n And I felt it was super cool to build an artificial human.\n\n05:57.960 --> 06:00.680\n And the best way to build an artificial human was to build a robot,\n\n06:00.680 --> 06:03.080\n because that's kind of the closest we could do.\n\n06:03.080 --> 06:04.920\n Unfortunately, we aren't there yet.\n\n06:04.920 --> 06:07.280\n The robots today are still very brittle.\n\n06:07.280 --> 06:10.240\n But it's fascinating to study intelligence from a constructive\n\n06:10.240 --> 06:12.880\n perspective when you build something.\n\n06:12.880 --> 06:18.680\n To understand you build, what do you think it takes to build an intelligent\n\n06:18.680 --> 06:20.880\n system, an intelligent robot?\n\n06:20.880 --> 06:23.760\n I think the biggest innovation that we've seen is machine learning.\n\n06:23.760 --> 06:28.600\n And it's the idea that the computers can basically teach themselves.\n\n06:28.600 --> 06:29.720\n Let's give an example.\n\n06:29.720 --> 06:33.080\n I'd say everybody pretty much knows how to walk.\n\n06:33.080 --> 06:36.800\n And we learn how to walk in the first year or two of our lives.\n\n06:36.800 --> 06:41.120\n But no scientist has ever been able to write down the rules of human gait.\n\n06:41.120 --> 06:42.080\n We don't understand it.\n\n06:42.080 --> 06:43.960\n We have it in our brains somehow.\n\n06:43.960 --> 06:45.120\n We can practice it.\n\n06:45.120 --> 06:46.560\n We understand it.\n\n06:46.560 --> 06:47.720\n But we can't articulate it.\n\n06:47.720 --> 06:50.240\n We can't pass it on by language.\n\n06:50.240 --> 06:53.320\n And that, to me, is kind of the deficiency of today's computer programming.\n\n06:53.320 --> 06:57.640\n When you program a computer, they're so insanely dumb that you have to give them\n\n06:57.640 --> 06:59.840\n rules for every contingencies.\n\n06:59.840 --> 07:03.440\n Very unlike the way people learn from data and experience,\n\n07:03.440 --> 07:05.440\n computers are being instructed.\n\n07:05.440 --> 07:07.800\n And because it's so hard to get this instruction set right,\n\n07:07.800 --> 07:11.480\n we pay software engineers $200,000 a year.\n\n07:11.480 --> 07:14.440\n Now, the most recent innovation, which has been in the make for 30,\n\n07:14.440 --> 07:18.480\n 40 years, is an idea that computers can find their own rules.\n\n07:18.480 --> 07:21.720\n So they can learn from falling down and getting up the same way children can\n\n07:21.720 --> 07:23.840\n learn from falling down and getting up.\n\n07:23.840 --> 07:28.720\n And that revolution has led to a capability that's completely unmatched.\n\n07:28.720 --> 07:32.120\n Today's computers can watch experts do their jobs, whether you're\n\n07:32.120 --> 07:36.920\n a doctor or a lawyer, pick up the regularities, learn those rules,\n\n07:36.920 --> 07:39.400\n and then become as good as the best experts.\n\n07:39.400 --> 07:44.400\n So the dream of in the 80s of expert systems, for example, had at its core\n\n07:44.400 --> 07:49.360\n the idea that humans could boil down their expertise on a sheet of paper,\n\n07:49.360 --> 07:53.280\n so to sort of reduce, sort of be able to explain to machines\n\n07:53.280 --> 07:55.520\n how to do something explicitly.\n\n07:55.520 --> 08:00.040\n So do you think, what's the use of human expertise into this whole picture?\n\n08:00.040 --> 08:03.240\n Do you think most of the intelligence will come from machines learning\n\n08:03.240 --> 08:06.480\n from experience without human expertise input?\n\n08:06.480 --> 08:10.680\n So the question for me is much more how do you express expertise?\n\n08:10.680 --> 08:12.960\n You can express expertise by writing a book.\n\n08:12.960 --> 08:16.240\n You can express expertise by showing someone what you're doing.\n\n08:16.240 --> 08:20.000\n You can express expertise by applying it by many different ways.\n\n08:20.000 --> 08:23.680\n And I think the expert systems was our best attempt in AI\n\n08:23.680 --> 08:25.960\n to capture expertise and rules.\n\n08:25.960 --> 08:28.600\n But someone sat down and said, here are the rules of human gait.\n\n08:28.600 --> 08:32.600\n Here's when you put your big toe forward and your heel backwards\n\n08:32.600 --> 08:34.720\n and you always stop stumbling.\n\n08:34.720 --> 08:39.480\n And as we now know, the set of rules, the set of language that we can command\n\n08:39.480 --> 08:41.200\n is incredibly limited.\n\n08:41.200 --> 08:43.760\n The majority of the human brain doesn't deal with language.\n\n08:43.760 --> 08:48.160\n It deals with subconscious, numerical, perceptual things\n\n08:48.160 --> 08:51.360\n that we don't even self aware of.\n\n08:51.360 --> 08:57.880\n Now, when an AI system watches an expert do their job and practice their job,\n\n08:57.880 --> 09:01.680\n it can pick up things that people can't even put into writing,\n\n09:01.680 --> 09:03.200\n into books or rules.\n\n09:03.200 --> 09:04.520\n And that's where the real power is.\n\n09:04.520 --> 09:08.280\n We now have AI systems that, for example, look over the shoulders\n\n09:08.280 --> 09:12.840\n of highly paid human doctors like dermatologists or radiologists,\n\n09:12.840 --> 09:18.440\n and they can somehow pick up those skills that no one can express in words.\n\n09:18.440 --> 09:22.200\n So you were a key person in launching three revolutions,\n\n09:22.200 --> 09:28.240\n online education, autonomous vehicles, and flying cars or VTOLs.\n\n09:28.240 --> 09:34.680\n So high level, and I apologize for all the philosophical questions.\n\n09:34.680 --> 09:37.400\n There's no apology necessary.\n\n09:37.400 --> 09:40.640\n How do you choose what problems to try and solve?\n\n09:40.640 --> 09:43.400\n What drives you to make those solutions a reality?\n\n09:43.400 --> 09:44.840\n I have two desires in life.\n\n09:44.840 --> 09:48.560\n I want to literally make the lives of others better.\n\n09:48.560 --> 09:52.840\n Or as we often say, maybe jokingly, make the world a better place.\n\n09:52.840 --> 09:54.920\n I actually believe in this.\n\n09:54.920 --> 09:57.720\n It's as funny as it sounds.\n\n09:57.720 --> 09:59.160\n And second, I want to learn.\n\n09:59.160 --> 10:00.400\n I want to get new skills.\n\n10:00.400 --> 10:02.920\n I don't want to be in a job I'm good at, because if I'm in a job\n\n10:02.920 --> 10:05.840\n that I'm good at, the chances for me to learn something interesting\n\n10:05.840 --> 10:06.760\n is actually minimized.\n\n10:06.760 --> 10:09.040\n So I want to be in a job I'm bad at.\n\n10:09.040 --> 10:10.240\n That's really important to me.\n\n10:10.240 --> 10:12.160\n So in a bill, for example, what people often\n\n10:12.160 --> 10:15.320\n call flying cars, these are electrical, vertical, takeoff,\n\n10:15.320 --> 10:17.960\n and landing vehicles.\n\n10:17.960 --> 10:19.720\n I'm just no expert in any of this.\n\n10:19.720 --> 10:23.080\n And it's so much fun to learn on the job what it actually means\n\n10:23.080 --> 10:24.920\n to build something like this.\n\n10:24.920 --> 10:27.560\n Now, I'd say the stuff that I've done lately\n\n10:27.560 --> 10:31.120\n after I finished my professorship at Stanford,\n\n10:31.120 --> 10:35.520\n they really focused on what has the maximum impact on society.\n\n10:35.520 --> 10:38.240\n Transportation is something that has transformed the 21st\n\n10:38.240 --> 10:40.120\n or 20th century more than any other invention,\n\n10:40.120 --> 10:42.600\n in my opinion, even more than communication.\n\n10:42.600 --> 10:43.600\n And cities are different.\n\n10:43.600 --> 10:45.080\n Workers are different.\n\n10:45.080 --> 10:47.920\n Women's rights are different because of transportation.\n\n10:47.920 --> 10:51.360\n And yet, we still have a very suboptimal transportation\n\n10:51.360 --> 10:56.960\n solution where we kill 1.2 or so million people every year\n\n10:56.960 --> 10:57.680\n in traffic.\n\n10:57.680 --> 10:59.880\n It's like the leading cause of death for young people\n\n10:59.880 --> 11:02.880\n in many countries, where we are extremely inefficient\n\n11:02.880 --> 11:03.600\n resource wise.\n\n11:03.600 --> 11:06.800\n Just go to your average neighborhood city\n\n11:06.800 --> 11:08.320\n and look at the number of parked cars.\n\n11:08.320 --> 11:10.400\n That's a travesty, in my opinion.\n\n11:10.400 --> 11:13.840\n Or where we spend endless hours in traffic jams.\n\n11:13.840 --> 11:15.680\n And very, very simple innovations,\n\n11:15.680 --> 11:18.800\n like a self driving car or what people call a flying car,\n\n11:18.800 --> 11:20.240\n could completely change this.\n\n11:20.240 --> 11:21.000\n And it's there.\n\n11:21.000 --> 11:23.280\n I mean, the technology is basically there.\n\n11:23.280 --> 11:26.920\n You have to close your eyes not to see it.\n\n11:26.920 --> 11:30.720\n So lingering on autonomous vehicles, a fascinating space,\n\n11:30.720 --> 11:33.560\n some incredible work you've done throughout your career there.\n\n11:33.560 --> 11:39.440\n So let's start with DARPA, I think, the DARPA challenge,\n\n11:39.440 --> 11:42.840\n through the desert and then urban to the streets.\n\n11:42.840 --> 11:45.720\n I think that inspired an entire generation of roboticists\n\n11:45.720 --> 11:49.520\n and obviously sprung this whole excitement\n\n11:49.520 --> 11:52.680\n about this particular kind of four wheeled robots\n\n11:52.680 --> 11:55.520\n we called autonomous cars, self driving cars.\n\n11:55.520 --> 11:58.960\n So you led the development of Stanley, the autonomous car\n\n11:58.960 --> 12:03.920\n that won the race to the desert, the DARPA challenge in 2005.\n\n12:03.920 --> 12:07.400\n And Junior, the car that finished second\n\n12:07.400 --> 12:11.040\n in the DARPA urban challenge, also did incredibly well\n\n12:11.040 --> 12:14.360\n in 2007, I think.\n\n12:14.360 --> 12:17.360\n What are some painful, inspiring, or enlightening\n\n12:17.360 --> 12:20.560\n experiences from that time that stand out to you?\n\n12:20.560 --> 12:22.640\n Oh my god.\n\n12:22.640 --> 12:28.160\n Painful were all these incredibly complicated,\n\n12:28.160 --> 12:30.440\n stupid bugs that had to be found.\n\n12:30.440 --> 12:35.040\n We had a phase where Stanley, our car that eventually\n\n12:35.040 --> 12:38.120\n won the DARPA grand challenge, would every 30 miles\n\n12:38.120 --> 12:39.320\n just commit suicide.\n\n12:39.320 --> 12:40.840\n And we didn't know why.\n\n12:40.840 --> 12:44.360\n And it ended up to be that in the sinking of two computer\n\n12:44.360 --> 12:47.720\n clocks, occasionally a clock went backwards\n\n12:47.720 --> 12:50.880\n and that negative time elapsed, screwed up\n\n12:50.880 --> 12:51.880\n the entire internal logic.\n\n12:51.880 --> 12:54.360\n But it took ages to find this.\n\n12:54.360 --> 12:56.280\n There were bugs like that.\n\n12:56.280 --> 12:59.840\n I'd say enlightening is the Stanford team immediately\n\n12:59.840 --> 13:02.360\n focused on machine learning and on software,\n\n13:02.360 --> 13:05.160\n whereas everybody else seemed to focus on building better hardware.\n\n13:05.160 --> 13:08.640\n Our analysis had been a human being with an existing rental\n\n13:08.640 --> 13:10.240\n car can perfectly drive the course\n\n13:10.240 --> 13:12.160\n but why do I have to build a better rental car?\n\n13:12.160 --> 13:15.080\n I just should replace the human being.\n\n13:15.080 --> 13:18.840\n And the human being, to me, was a conjunction of three steps.\n\n13:18.840 --> 13:22.360\n We had sensors, eyes and ears, mostly eyes.\n\n13:22.360 --> 13:23.800\n We had brains in the middle.\n\n13:23.800 --> 13:26.360\n And then we had actuators, our hands and our feet.\n\n13:26.360 --> 13:28.200\n Now, the actuators are easy to build.\n\n13:28.200 --> 13:29.720\n The sensors are actually also easy to build.\n\n13:29.720 --> 13:30.960\n What was missing was the brain.\n\n13:30.960 --> 13:32.640\n So we had to build a human brain.\n\n13:32.640 --> 13:36.040\n And nothing clearer than to me that the human brain\n\n13:36.040 --> 13:37.000\n is a learning machine.\n\n13:37.000 --> 13:38.240\n So why not just train our robot?\n\n13:38.240 --> 13:40.720\n So we would build massive machine learning\n\n13:40.720 --> 13:42.320\n into our machine.\n\n13:42.320 --> 13:44.840\n And with that, we were able to not just learn\n\n13:44.840 --> 13:45.680\n from human drivers.\n\n13:45.680 --> 13:47.960\n We had the entire speed control of the vehicle\n\n13:47.960 --> 13:49.840\n was copied from human driving.\n\n13:49.840 --> 13:51.640\n But also have the robot learn from experience\n\n13:51.640 --> 13:53.680\n where it made a mistake and recover from it\n\n13:53.680 --> 13:55.600\n and learn from it.\n\n13:55.600 --> 14:00.720\n You mentioned the pain point of software and clocks.\n\n14:00.720 --> 14:04.720\n Synchronization seems to be a problem that\n\n14:04.720 --> 14:06.080\n continues with robotics.\n\n14:06.080 --> 14:09.920\n It's a tricky one with drones and so on.\n\n14:09.920 --> 14:14.520\n What does it take to build a thing, a system\n\n14:14.520 --> 14:16.640\n with so many constraints?\n\n14:16.640 --> 14:20.320\n You have a deadline, no time.\n\n14:20.320 --> 14:22.080\n You're unsure about anything really.\n\n14:22.080 --> 14:24.960\n It's the first time that people really even exploring.\n\n14:24.960 --> 14:26.800\n It's not even sure that anybody can finish\n\n14:26.800 --> 14:28.840\n when we're talking about the race to the desert\n\n14:28.840 --> 14:30.640\n the year before nobody finish.\n\n14:30.640 --> 14:32.760\n What does it take to scramble and finish\n\n14:32.760 --> 14:35.800\n a product that actually, a system that actually works?\n\n14:35.800 --> 14:36.760\n We were very lucky.\n\n14:36.760 --> 14:38.280\n We were a really small team.\n\n14:38.280 --> 14:40.440\n The core of the team were four people.\n\n14:40.440 --> 14:43.080\n It was four because five couldn't comfortably sit\n\n14:43.080 --> 14:45.360\n inside a car, but four could.\n\n14:45.360 --> 14:47.080\n And I, as a team leader, my job was\n\n14:47.080 --> 14:50.120\n to get pizza for everybody and wash the car and stuff\n\n14:50.120 --> 14:52.880\n like this and repair the radiator when it broke\n\n14:52.880 --> 14:55.240\n and debug the system.\n\n14:55.240 --> 14:56.880\n And we were very open minded.\n\n14:56.880 --> 14:58.400\n We had no egos involved.\n\n14:58.400 --> 15:00.840\n We just wanted to see how far we can get.\n\n15:00.840 --> 15:03.280\n What we did really, really well was time management.\n\n15:03.280 --> 15:06.280\n We were done with everything a month before the race.\n\n15:06.280 --> 15:08.760\n And we froze the entire software a month before the race.\n\n15:08.760 --> 15:11.440\n And it turned out, looking at other teams,\n\n15:11.440 --> 15:14.120\n every other team complained if they had just one more week,\n\n15:14.120 --> 15:15.440\n they would have won.\n\n15:15.440 --> 15:18.760\n And we decided we're not going to fall into that mistake.\n\n15:18.760 --> 15:19.920\n We're going to be early.\n\n15:19.920 --> 15:22.720\n And we had an entire month to shake the system.\n\n15:22.720 --> 15:24.920\n And we actually found two or three minor bugs\n\n15:24.920 --> 15:27.080\n in the last month that we had to fix.\n\n15:27.080 --> 15:30.000\n And we were completely prepared when the race occurred.\n\n15:30.000 --> 15:33.880\n Okay, so first of all, that's such an incredibly rare\n\n15:33.880 --> 15:37.760\n achievement in terms of being able to be done on time\n\n15:37.760 --> 15:39.000\n or ahead of time.\n\n15:39.000 --> 15:43.080\n What do you, how do you do that in your future work?\n\n15:43.080 --> 15:44.760\n What advice do you have in general?\n\n15:44.760 --> 15:46.360\n Because it seems to be so rare,\n\n15:46.360 --> 15:49.280\n especially in highly innovative projects like this.\n\n15:49.280 --> 15:50.840\n People work till the last second.\n\n15:50.840 --> 15:52.560\n Well, the nice thing about the DARPA Grand Challenge\n\n15:52.560 --> 15:55.320\n is that the problem was incredibly well defined.\n\n15:55.320 --> 15:57.160\n We were able for a while to drive\n\n15:57.160 --> 15:58.800\n the old DARPA Grand Challenge course,\n\n15:58.800 --> 16:00.800\n which had been used the year before.\n\n16:00.800 --> 16:04.040\n And then at some reason we were kicked out of the region.\n\n16:04.040 --> 16:06.320\n So we had to go to a different desert, the Snorran Desert,\n\n16:06.320 --> 16:08.880\n and we were able to drive desert trails\n\n16:08.880 --> 16:10.600\n just of the same type.\n\n16:10.600 --> 16:12.320\n So there was never any debate about like,\n\n16:12.320 --> 16:13.240\n what is actually the problem?\n\n16:13.240 --> 16:14.400\n We didn't sit down and say,\n\n16:14.400 --> 16:16.680\n hey, should we build a car or a plane?\n\n16:16.680 --> 16:18.280\n We had to build a car.\n\n16:18.280 --> 16:20.400\n That made it very, very easy.\n\n16:20.400 --> 16:23.800\n Then I studied my own life and life of others.\n\n16:23.800 --> 16:26.360\n And we realized that the typical mistake that people make\n\n16:26.360 --> 16:29.600\n is that there's this kind of crazy bug left\n\n16:29.600 --> 16:31.240\n that they haven't found yet.\n\n16:32.200 --> 16:34.360\n And it's just, they regret it.\n\n16:34.360 --> 16:36.160\n And that bug would have been trivial to fix.\n\n16:36.160 --> 16:37.760\n They just haven't fixed it yet.\n\n16:37.760 --> 16:39.600\n They didn't want to fall into that trap.\n\n16:39.600 --> 16:41.080\n So I built a testing team.\n\n16:41.080 --> 16:43.760\n We had a testing team that built a testing booklet\n\n16:43.760 --> 16:46.800\n of 160 pages of tests we had to go through\n\n16:46.800 --> 16:49.720\n just to make sure we shake out the system appropriately.\n\n16:49.720 --> 16:51.800\n And the testing team was with us all the time\n\n16:51.800 --> 16:55.520\n and dictated to us today, we do railroad crossings.\n\n16:55.520 --> 16:58.480\n Tomorrow we do, we practice the start of the event.\n\n16:58.480 --> 17:00.680\n And in all of these, we thought,\n\n17:00.680 --> 17:02.240\n oh my God, it's long solved trivial.\n\n17:02.240 --> 17:03.200\n And then we tested it out.\n\n17:03.200 --> 17:04.560\n Oh my God, it doesn't do a railroad crossing.\n\n17:04.560 --> 17:05.400\n Why not?\n\n17:05.400 --> 17:09.720\n Oh my God, it mistakes the rails for metal barriers.\n\n17:09.720 --> 17:11.600\n We have to fix this.\n\n17:11.600 --> 17:14.480\n So it was really a continuous focus\n\n17:14.480 --> 17:16.360\n on improving the weakest part of the system.\n\n17:16.360 --> 17:19.160\n And as long as you focus on improving\n\n17:19.160 --> 17:20.560\n the weakest part of the system,\n\n17:20.560 --> 17:23.080\n you eventually build a really great system.\n\n17:23.080 --> 17:25.880\n Let me just pause on that, to me as an engineer,\n\n17:25.880 --> 17:28.280\n it's just super exciting that you were thinking like that,\n\n17:28.280 --> 17:30.440\n especially at that stage as brilliant,\n\n17:30.440 --> 17:33.400\n that testing was such a core part of it.\n\n17:33.400 --> 17:35.720\n It may be to linger on the point of leadership.\n\n17:36.720 --> 17:39.120\n I think it's one of the first times\n\n17:39.120 --> 17:41.960\n you were really a leader\n\n17:41.960 --> 17:45.440\n and you've led many very successful teams since then.\n\n17:46.440 --> 17:48.480\n What does it take to be a good leader?\n\n17:48.480 --> 17:51.000\n I would say most of all, I just take credit.\n\n17:51.000 --> 17:55.320\n I put the work of others, right?\n\n17:55.320 --> 17:57.560\n That's very convenient turns out\n\n17:57.560 --> 18:00.200\n because I can't do all these things myself.\n\n18:00.200 --> 18:01.120\n I'm an engineer at heart.\n\n18:01.120 --> 18:03.760\n So I care about engineering.\n\n18:03.760 --> 18:06.160\n So I don't know what the chicken and the egg is,\n\n18:06.160 --> 18:07.880\n but as a kid, I loved computers\n\n18:07.880 --> 18:09.560\n because you could tell them to do something\n\n18:09.560 --> 18:10.720\n and they actually did it.\n\n18:10.720 --> 18:11.560\n It was very cool.\n\n18:11.560 --> 18:12.760\n And you could like in the middle of the night,\n\n18:12.760 --> 18:15.200\n wake up at one in the morning and switch on your computer.\n\n18:15.200 --> 18:18.160\n And what he told you to yesterday, it would still do.\n\n18:18.160 --> 18:19.400\n That was really cool.\n\n18:19.400 --> 18:21.320\n Unfortunately, that didn't quite work with people.\n\n18:21.320 --> 18:22.880\n So you go to people and tell them what to do\n\n18:22.880 --> 18:24.360\n and they don't do it.\n\n18:24.360 --> 18:26.960\n And they hate you for it, or you do it today\n\n18:26.960 --> 18:29.040\n and then you go a day later and they stop doing it.\n\n18:29.040 --> 18:30.240\n So you have to...\n\n18:30.240 --> 18:31.480\n So then the question really became,\n\n18:31.480 --> 18:34.120\n how can you put yourself in the brain of people\n\n18:34.120 --> 18:35.120\n as opposed to computers?\n\n18:35.120 --> 18:37.400\n And in terms of computers, it's super dumb.\n\n18:37.400 --> 18:38.240\n That's so dumb.\n\n18:38.240 --> 18:39.640\n If people were as dumb as computers,\n\n18:39.640 --> 18:41.280\n I wouldn't want to work with them.\n\n18:41.280 --> 18:43.640\n But people are smart and people are emotional\n\n18:43.640 --> 18:45.920\n and people have pride and people have aspirations.\n\n18:45.920 --> 18:49.840\n So how can I connect to that?\n\n18:49.840 --> 18:52.560\n And that's the thing that most of our leadership just fails\n\n18:52.560 --> 18:56.240\n because many, many engineers turn manager\n\n18:56.240 --> 18:58.480\n believe they can treat their team just the same way\n\n18:58.480 --> 18:59.320\n it can treat your computer.\n\n18:59.320 --> 19:00.440\n And it just doesn't work this way.\n\n19:00.440 --> 19:02.320\n It's just really bad.\n\n19:02.320 --> 19:05.080\n So how can I connect to people?\n\n19:05.080 --> 19:07.680\n And it turns out as a college professor,\n\n19:07.680 --> 19:10.000\n the wonderful thing you do all the time\n\n19:10.000 --> 19:11.000\n is to empower other people.\n\n19:11.000 --> 19:14.720\n Like your job is to make your students look great.\n\n19:14.720 --> 19:15.560\n That's all you do.\n\n19:15.560 --> 19:16.920\n You're the best coach.\n\n19:16.920 --> 19:19.160\n And it turns out if you do a fantastic job with making\n\n19:19.160 --> 19:21.560\n your students look great, they actually love you\n\n19:21.560 --> 19:22.720\n and their parents love you.\n\n19:22.720 --> 19:25.520\n And they give you all the credit for stuff you don't deserve.\n\n19:25.520 --> 19:27.200\n All my students were smarter than me.\n\n19:27.200 --> 19:28.720\n All the great stuff invented at Stanford\n\n19:28.720 --> 19:30.040\n was their stuff, not my stuff.\n\n19:30.040 --> 19:32.480\n And they give me credit and say, oh, Sebastian.\n\n19:32.480 --> 19:35.240\n We're just making them feel good about themselves.\n\n19:35.240 --> 19:38.040\n So the question really is, can you take a team of people\n\n19:38.040 --> 19:40.400\n and what does it take to make them\n\n19:40.400 --> 19:43.360\n to connect to what they actually want in life\n\n19:43.360 --> 19:45.760\n and turn this into productive action?\n\n19:45.760 --> 19:48.520\n It turns out every human being that I know\n\n19:48.520 --> 19:50.120\n has incredibly good intentions.\n\n19:50.120 --> 19:54.120\n I've really rarely met a person with bad intentions.\n\n19:54.120 --> 19:55.920\n I believe every person wants to contribute.\n\n19:55.920 --> 19:59.440\n I think every person I've met wants to help others.\n\n19:59.440 --> 20:01.840\n It's amazing how much of an urge we have\n\n20:01.840 --> 20:04.440\n not to just help ourselves, but to help others.\n\n20:04.440 --> 20:06.480\n So how can we empower people and give them\n\n20:06.480 --> 20:10.600\n the right framework that they can accomplish this?\n\n20:10.600 --> 20:12.400\n In moments when it works, it's magical.\n\n20:12.400 --> 20:17.160\n Because you'd see the confluence of people\n\n20:17.160 --> 20:19.160\n being able to make the world a better place\n\n20:19.160 --> 20:22.840\n and deriving enormous confidence and pride out of this.\n\n20:22.840 --> 20:27.160\n And that's when my environment works the best.\n\n20:27.160 --> 20:29.400\n These are moments where I can disappear for a month\n\n20:29.400 --> 20:31.560\n and come back and things still work.\n\n20:31.560 --> 20:32.760\n It's very hard to accomplish.\n\n20:32.760 --> 20:35.040\n But when it works, it's amazing.\n\n20:35.040 --> 20:37.240\n So I agree with you very much.\n\n20:37.240 --> 20:42.000\n It's not often heard that most people in the world\n\n20:42.000 --> 20:43.520\n have good intentions.\n\n20:43.520 --> 20:45.920\n At the core, their intentions are good\n\n20:45.920 --> 20:47.400\n and they're good people.\n\n20:47.400 --> 20:50.160\n That's a beautiful message, it's not often heard.\n\n20:50.160 --> 20:52.600\n We make this mistake, and this is a friend of mine,\n\n20:52.600 --> 20:56.400\n Alex Werder, talking to us, that we judge ourselves\n\n20:56.400 --> 20:59.160\n by our intentions and others by their actions.\n\n21:00.080 --> 21:01.880\n And I think that the biggest skill,\n\n21:01.880 --> 21:03.560\n I mean, here in Silicon Valley, we follow engineers\n\n21:03.560 --> 21:06.640\n who have very little empathy and are kind of befuddled\n\n21:06.640 --> 21:09.200\n by why it doesn't work for them.\n\n21:09.200 --> 21:13.080\n The biggest skill, I think, that people should acquire\n\n21:13.080 --> 21:16.880\n is to put themselves into the position of the other\n\n21:16.880 --> 21:20.000\n and listen, and listen to what the other has to say.\n\n21:20.000 --> 21:23.400\n And they'd be shocked how similar they are to themselves.\n\n21:23.400 --> 21:26.160\n And they might even be shocked how their own actions\n\n21:26.160 --> 21:28.320\n don't reflect their intentions.\n\n21:28.320 --> 21:30.920\n I often have conversations with engineers\n\n21:30.920 --> 21:33.400\n where I say, look, hey, I love you, you're doing a great job.\n\n21:33.400 --> 21:37.320\n And by the way, what you just did has the following effect.\n\n21:37.320 --> 21:38.840\n Are you aware of that?\n\n21:38.840 --> 21:41.280\n And then people would say, oh my God, not I wasn't,\n\n21:41.280 --> 21:43.120\n because my intention was that.\n\n21:43.120 --> 21:45.000\n And I say, yeah, I trust your intention.\n\n21:45.000 --> 21:46.360\n You're a good human being.\n\n21:46.360 --> 21:48.480\n But just to help you in the future,\n\n21:48.480 --> 21:51.320\n if you keep expressing it that way,\n\n21:51.320 --> 21:53.400\n then people will just hate you.\n\n21:53.400 --> 21:55.240\n And I've had many instances where people say,\n\n21:55.240 --> 21:56.600\n oh my God, thank you for telling me this,\n\n21:56.600 --> 21:59.280\n because it wasn't my intention to look like an idiot.\n\n21:59.280 --> 22:00.720\n It wasn't my intention to help other people.\n\n22:00.720 --> 22:02.480\n I just didn't know how to do it.\n\n22:02.480 --> 22:04.000\n Very simple, by the way.\n\n22:04.000 --> 22:07.440\n There's a book, Dale Carnegie, 1936,\n\n22:07.440 --> 22:10.400\n how to make friends and how to influence others.\n\n22:10.400 --> 22:12.720\n Has the entire Bible, you just read it and you're done\n\n22:12.720 --> 22:13.960\n and you apply it every day.\n\n22:13.960 --> 22:16.760\n And I wish I was good enough to apply it every day.\n\n22:16.760 --> 22:18.880\n But it's just simple things, right?\n\n22:18.880 --> 22:22.600\n Like be positive, remember people's name, smile,\n\n22:22.600 --> 22:24.480\n and eventually have empathy.\n\n22:24.480 --> 22:27.400\n Really think that the person that you hate\n\n22:27.400 --> 22:28.640\n and you think is an idiot,\n\n22:28.640 --> 22:30.440\n is actually just like yourself.\n\n22:30.440 --> 22:33.200\n It's a person who's struggling, who means well,\n\n22:33.200 --> 22:36.560\n and who might need help, and guess what, you need help.\n\n22:36.560 --> 22:39.960\n I've recently spoken with Stephen Schwarzman.\n\n22:39.960 --> 22:41.960\n I'm not sure if you know who that is, but.\n\n22:41.960 --> 22:42.920\n I do.\n\n22:42.920 --> 22:44.320\n So, and he said.\n\n22:44.320 --> 22:45.160\n It's on my list.\n\n22:45.160 --> 22:47.440\n On the list.\n\n22:47.440 --> 22:52.440\n But he said, sort of to expand on what you're saying,\n\n22:52.760 --> 22:56.040\n that one of the biggest things you can do\n\n22:56.040 --> 23:00.040\n is hear people when they tell you what their problem is\n\n23:00.040 --> 23:02.360\n and then help them with that problem.\n\n23:02.360 --> 23:06.000\n He says, it's surprising how few people\n\n23:06.000 --> 23:09.280\n actually listen to what troubles others.\n\n23:09.280 --> 23:12.600\n And because it's right there in front of you\n\n23:12.600 --> 23:15.240\n and you can benefit the world the most.\n\n23:15.240 --> 23:18.040\n And in fact, yourself and everybody around you\n\n23:18.040 --> 23:20.840\n by just hearing the problems and solving them.\n\n23:20.840 --> 23:23.960\n I mean, that's my little history of engineering.\n\n23:23.960 --> 23:28.240\n That is, while I was engineering with computers,\n\n23:28.240 --> 23:32.400\n I didn't care at all what the computer's problems were.\n\n23:32.400 --> 23:34.800\n I just told them what to do and to do it.\n\n23:34.800 --> 23:37.600\n And it just doesn't work this way with people.\n\n23:37.600 --> 23:38.480\n It doesn't work with me.\n\n23:38.480 --> 23:41.240\n If you come to me and say, do A, I do the opposite.\n\n23:43.600 --> 23:47.160\n But let's return to the comfortable world of engineering.\n\n23:47.160 --> 23:52.160\n And can you tell me in broad strokes in how you see it?\n\n23:52.160 --> 23:53.840\n Because you're the core of starting it,\n\n23:53.840 --> 23:55.120\n the core of driving it,\n\n23:55.120 --> 23:58.040\n the technical evolution of autonomous vehicles\n\n23:58.040 --> 24:00.440\n from the first DARPA Grand Challenge\n\n24:00.440 --> 24:03.640\n to the incredible success we see with the program\n\n24:03.640 --> 24:05.400\n you started with Google self driving car\n\n24:05.400 --> 24:08.360\n and Waymo and the entire industry that sprung up\n\n24:08.360 --> 24:11.200\n of different kinds of approaches, debates and so on.\n\n24:11.200 --> 24:14.160\n Well, the idea of self driving car goes back to the 80s.\n\n24:14.160 --> 24:15.480\n There was a team in Germany and another team\n\n24:15.480 --> 24:18.720\n at Carnegie Mellon that did some very pioneering work.\n\n24:18.720 --> 24:21.760\n But back in the day, I'd say the computers were so deficient\n\n24:21.760 --> 24:25.880\n that even the best professors and engineers in the world\n\n24:25.880 --> 24:27.280\n basically stood no chance.\n\n24:28.200 --> 24:31.200\n It then folded into a phase where the US government\n\n24:31.200 --> 24:33.320\n spent at least half a billion dollars\n\n24:33.320 --> 24:36.160\n that I could count on research projects.\n\n24:36.160 --> 24:37.960\n But the way the procurement works,\n\n24:38.920 --> 24:42.800\n a successful stack of paper describing lots of stuff\n\n24:42.800 --> 24:43.880\n that no one's ever gonna read\n\n24:43.880 --> 24:47.640\n was a successful product of a research project.\n\n24:47.640 --> 24:50.520\n So we trained our researchers to produce lots of paper.\n\n24:52.600 --> 24:54.320\n That all changed with the DARPA Grand Challenge.\n\n24:54.320 --> 24:58.480\n And I really gotta credit the ingenious people at DARPA\n\n24:58.480 --> 25:00.400\n and the US government and Congress\n\n25:00.400 --> 25:03.000\n that took a complete new funding model where they said,\n\n25:03.000 --> 25:05.640\n let's not fund effort, let's fund outcomes.\n\n25:05.640 --> 25:06.840\n And it sounds very trivial,\n\n25:06.840 --> 25:09.840\n but there was no tax code that allowed\n\n25:09.840 --> 25:13.720\n the use of congressional tax money for a price.\n\n25:13.720 --> 25:15.120\n It was all effort based.\n\n25:15.120 --> 25:16.320\n So if you put in a hundred hours in,\n\n25:16.320 --> 25:17.480\n you could charge a hundred hours.\n\n25:17.480 --> 25:18.520\n If you put in a thousand hours in,\n\n25:18.520 --> 25:20.720\n you could build a thousand hours.\n\n25:20.720 --> 25:22.880\n By changing the focus instead of making the price,\n\n25:22.880 --> 25:24.040\n we don't pay you for development,\n\n25:24.040 --> 25:26.360\n we pay for the accomplishment.\n\n25:26.360 --> 25:28.960\n They drew in, they automatically drew out\n\n25:28.960 --> 25:31.720\n all these contractors who are used to the drug\n\n25:31.720 --> 25:33.400\n of getting money per hour.\n\n25:33.400 --> 25:35.520\n And they drew in a whole bunch of new people.\n\n25:35.520 --> 25:37.600\n And these people are mostly crazy people.\n\n25:37.600 --> 25:40.680\n They were people who had a car and a computer\n\n25:40.680 --> 25:42.440\n and they wanted to make a million bucks.\n\n25:42.440 --> 25:43.920\n The million bucks was their visual price money,\n\n25:43.920 --> 25:45.440\n it was then doubled.\n\n25:45.440 --> 25:48.040\n And they felt if I put my computer in my car\n\n25:48.040 --> 25:50.880\n and program it, I can be rich.\n\n25:50.880 --> 25:52.080\n And that was so awesome.\n\n25:52.080 --> 25:55.480\n Like half the teams, there was a team that was surfer dudes\n\n25:55.480 --> 25:58.520\n and they had like two surfboards on their vehicle\n\n25:58.520 --> 26:01.560\n and brought like these fashion girls, super cute girls,\n\n26:01.560 --> 26:02.800\n like twin sisters.\n\n26:03.720 --> 26:06.400\n And you could tell these guys were not your common\n\n26:06.400 --> 26:10.840\n beltway bandit who gets all these big multimillion\n\n26:10.840 --> 26:13.520\n and billion dollar countries from the US government.\n\n26:13.520 --> 26:15.240\n And there was a great reset.\n\n26:16.280 --> 26:18.560\n Universities moved in.\n\n26:18.560 --> 26:21.800\n I was very fortunate at Stanford that I just received tenure\n\n26:21.800 --> 26:23.360\n so I couldn't get fired no matter what I do,\n\n26:23.360 --> 26:25.120\n otherwise I wouldn't have done it.\n\n26:25.120 --> 26:28.240\n And I had enough money to finance this thing\n\n26:28.240 --> 26:31.160\n and I was able to attract a lot of money from third parties.\n\n26:31.160 --> 26:32.520\n And even car companies moved in.\n\n26:32.520 --> 26:34.040\n They kind of moved in very quietly\n\n26:34.040 --> 26:36.600\n because they were super scared to be embarrassed\n\n26:36.600 --> 26:38.560\n that their car would flip over.\n\n26:38.560 --> 26:40.680\n But Ford was there and Volkswagen was there\n\n26:40.680 --> 26:43.360\n and a few others and GM was there.\n\n26:43.360 --> 26:46.360\n So it kind of reset the entire landscape of people.\n\n26:46.360 --> 26:48.200\n And if you look at who's a big name\n\n26:48.200 --> 26:49.480\n in self driving cars today,\n\n26:49.480 --> 26:51.320\n these were mostly people who participated\n\n26:51.320 --> 26:52.320\n in those challenges.\n\n26:53.400 --> 26:54.280\n Okay, that's incredible.\n\n26:54.280 --> 26:59.080\n Can you just comment quickly on your sense of lessons learned\n\n26:59.080 --> 27:01.240\n from that kind of funding model\n\n27:01.240 --> 27:04.400\n and the research that's going on in academia\n\n27:04.400 --> 27:06.120\n in terms of producing papers,\n\n27:06.120 --> 27:10.200\n is there something to be learned and scaled up bigger,\n\n27:10.200 --> 27:11.720\n having these kinds of grand challenges\n\n27:11.720 --> 27:14.560\n that could improve outcomes?\n\n27:14.560 --> 27:16.320\n So I'm a big believer in focusing\n\n27:16.320 --> 27:19.680\n on kind of an end to end system.\n\n27:19.680 --> 27:21.920\n I'm a really big believer in systems building.\n\n27:21.920 --> 27:23.680\n I've always built systems in my academic career,\n\n27:23.680 --> 27:27.040\n even though I do a lot of math and abstract stuff,\n\n27:27.040 --> 27:28.160\n but it's all derived from the idea\n\n27:28.160 --> 27:29.680\n of let's solve a real problem.\n\n27:29.680 --> 27:33.840\n And it's very hard for me to be an academic\n\n27:33.840 --> 27:35.800\n and say, let me solve a component of a problem.\n\n27:35.800 --> 27:38.680\n Like with someone there's fields like nonmonetary logic\n\n27:38.680 --> 27:41.800\n or AI planning systems where people believe\n\n27:41.800 --> 27:44.320\n that a certain style of problem solving\n\n27:44.320 --> 27:47.280\n is the ultimate end objective.\n\n27:47.280 --> 27:49.600\n And I would always turn it around and say,\n\n27:49.600 --> 27:52.640\n hey, what problem would my grandmother care about\n\n27:52.640 --> 27:54.680\n that doesn't understand computer technology\n\n27:54.680 --> 27:56.520\n and doesn't wanna understand?\n\n27:56.520 --> 27:58.480\n And how could I make her love what I do?\n\n27:58.480 --> 28:01.320\n Because only then do I have an impact on the world.\n\n28:01.320 --> 28:02.960\n I can easily impress my colleagues.\n\n28:02.960 --> 28:04.760\n That is much easier,\n\n28:04.760 --> 28:07.640\n but impressing my grandmother is very, very hard.\n\n28:07.640 --> 28:10.760\n So I would always thought if I can build a self driving car\n\n28:10.760 --> 28:12.880\n and my grandmother can use it\n\n28:12.880 --> 28:14.720\n even after she loses her driving privileges\n\n28:14.720 --> 28:16.160\n or children can use it,\n\n28:16.160 --> 28:20.560\n or we save maybe a million lives a year,\n\n28:20.560 --> 28:22.440\n that would be very impressive.\n\n28:22.440 --> 28:23.920\n And then there's so many problems like these,\n\n28:23.920 --> 28:25.320\n like there's a problem with curing cancer,\n\n28:25.320 --> 28:27.800\n or whatever it is, live twice as long.\n\n28:27.800 --> 28:29.600\n Once a problem is defined,\n\n28:29.600 --> 28:31.440\n of course I can't solve it in its entirety.\n\n28:31.440 --> 28:34.200\n Like it takes sometimes tens of thousands of people\n\n28:34.200 --> 28:35.360\n to find a solution.\n\n28:35.360 --> 28:39.360\n There's no way you can fund an army of 10,000 at Stanford.\n\n28:39.360 --> 28:41.080\n So you gotta build a prototype.\n\n28:41.080 --> 28:42.480\n Let's build a meaningful prototype.\n\n28:42.480 --> 28:43.920\n And the DARPA Grand Challenge was beautiful\n\n28:43.920 --> 28:46.400\n because it told me what this prototype had to do.\n\n28:46.400 --> 28:47.680\n I didn't have to think about what it had to do,\n\n28:47.680 --> 28:48.840\n I just had to read the rules.\n\n28:48.840 --> 28:51.080\n And that was really beautiful.\n\n28:51.080 --> 28:52.320\n And it's most beautiful,\n\n28:52.320 --> 28:54.720\n you think what academia could aspire to\n\n28:54.720 --> 28:58.600\n is to build a prototype that's the systems level,\n\n28:58.600 --> 29:01.360\n that solves or gives you an inkling\n\n29:01.360 --> 29:03.480\n that this problem could be solved with this prototype.\n\n29:03.480 --> 29:06.520\n First of all, I wanna emphasize what academia really is.\n\n29:06.520 --> 29:08.560\n And I think people misunderstand it.\n\n29:08.560 --> 29:11.280\n First and foremost, academia is a way\n\n29:11.280 --> 29:13.320\n to educate young people.\n\n29:13.320 --> 29:15.400\n First and foremost, a professor is an educator.\n\n29:15.400 --> 29:17.040\n No matter where you are at,\n\n29:17.040 --> 29:18.560\n a small suburban college,\n\n29:18.560 --> 29:21.960\n or whether you are a Harvard or Stanford professor,\n\n29:21.960 --> 29:25.000\n that's not the way most people think of themselves\n\n29:25.000 --> 29:28.000\n in academia because we have this kind of competition\n\n29:28.000 --> 29:31.440\n going on for citations and publication.\n\n29:31.440 --> 29:32.840\n That's a measurable thing,\n\n29:32.840 --> 29:35.440\n but that is secondary to the primary purpose\n\n29:35.440 --> 29:37.800\n of educating people to think.\n\n29:37.800 --> 29:39.960\n Now, in terms of research,\n\n29:39.960 --> 29:42.880\n most of the great science,\n\n29:42.880 --> 29:45.520\n the great research comes out of universities.\n\n29:45.520 --> 29:46.960\n You can trace almost everything back,\n\n29:46.960 --> 29:48.840\n including Google, to universities.\n\n29:48.840 --> 29:52.120\n So there's nothing really fundamentally broken here.\n\n29:52.120 --> 29:53.400\n It's a good system.\n\n29:53.400 --> 29:55.920\n And I think America has the finest university system\n\n29:55.920 --> 29:56.760\n on the planet.\n\n29:57.640 --> 29:59.320\n We can talk about reach\n\n29:59.320 --> 30:01.440\n and how to reach people outside the system.\n\n30:01.440 --> 30:02.280\n It's a different topic,\n\n30:02.280 --> 30:04.760\n but the system itself is a good system.\n\n30:04.760 --> 30:08.320\n If I had one wish, I would say it'd be really great\n\n30:08.320 --> 30:11.760\n if there was more debate about\n\n30:11.760 --> 30:15.880\n what the great big problems are in society\n\n30:15.880 --> 30:18.760\n and focus on those.\n\n30:18.760 --> 30:21.600\n And most of them are interdisciplinary.\n\n30:21.600 --> 30:24.640\n Unfortunately, it's very easy to fall\n\n30:24.640 --> 30:28.160\n into an interdisciplinary viewpoint\n\n30:28.160 --> 30:30.440\n where your problem is dictated\n\n30:30.440 --> 30:33.680\n by what your closest colleagues believe the problem is.\n\n30:33.680 --> 30:35.280\n It's very hard to break out and say,\n\n30:35.280 --> 30:37.920\n well, there's an entire new field of problems.\n\n30:37.920 --> 30:39.840\n So to give an example,\n\n30:39.840 --> 30:41.640\n prior to me working on self driving cars,\n\n30:41.640 --> 30:44.640\n I was a roboticist and a machine learning expert.\n\n30:44.640 --> 30:46.840\n And I wrote books on robotics,\n\n30:46.840 --> 30:48.480\n something called probabilistic robotics.\n\n30:48.480 --> 30:51.480\n It's a very methods driven kind of viewpoint of the world.\n\n30:51.480 --> 30:54.000\n I built robots that acted in museums as tour guides,\n\n30:54.000 --> 30:55.600\n that let children around.\n\n30:55.600 --> 31:00.000\n It is something that at the time was moderately challenging.\n\n31:00.000 --> 31:02.240\n When I started working on cars,\n\n31:02.240 --> 31:03.720\n several colleagues told me,\n\n31:03.720 --> 31:06.080\n Sebastian, you're destroying your career\n\n31:06.080 --> 31:08.160\n because in our field of robotics,\n\n31:08.160 --> 31:10.400\n cars are looked like as a gimmick\n\n31:10.400 --> 31:11.760\n and they're not expressive enough.\n\n31:11.760 --> 31:15.080\n They can only push the throttle and the brakes.\n\n31:15.080 --> 31:16.440\n There's no dexterity.\n\n31:16.440 --> 31:18.240\n There's no complexity.\n\n31:18.240 --> 31:19.480\n It's just too simple.\n\n31:19.480 --> 31:21.200\n And no one came to me and said,\n\n31:21.200 --> 31:22.720\n wow, if you solve that problem,\n\n31:22.720 --> 31:25.000\n you can save a million lives, right?\n\n31:25.000 --> 31:27.240\n Among all robotic problems that I've seen in my life,\n\n31:27.240 --> 31:29.760\n I would say the self driving car, transportation,\n\n31:29.760 --> 31:32.080\n is the one that has the most hope for society.\n\n31:32.080 --> 31:35.120\n So how come the robotics community wasn't all over the place?\n\n31:35.120 --> 31:37.920\n And it was because we focused on methods and solutions\n\n31:37.920 --> 31:39.880\n and not on problems.\n\n31:39.880 --> 31:42.400\n Like if you go around today and ask your grandmother,\n\n31:42.400 --> 31:43.240\n what bugs you?\n\n31:43.240 --> 31:45.240\n What really makes you upset?\n\n31:45.240 --> 31:48.720\n I challenge any academic to do this\n\n31:48.720 --> 31:51.800\n and then realize how far your research\n\n31:51.800 --> 31:53.840\n is probably away from that today.\n\n31:54.840 --> 31:56.760\n At the very least, that's a good thing\n\n31:56.760 --> 31:59.240\n for academics to deliberate on.\n\n31:59.240 --> 32:01.600\n The other thing that's really nice in Silicon Valley is,\n\n32:01.600 --> 32:04.360\n Silicon Valley is full of smart people outside academia.\n\n32:04.360 --> 32:06.720\n So there's the Larry Pages and Mark Zuckerbergs in the world\n\n32:06.720 --> 32:09.000\n who are anywhere smarter, smarter\n\n32:09.000 --> 32:11.400\n than the best academics I've met in my life.\n\n32:11.400 --> 32:15.360\n And what they do is they are at a different level.\n\n32:15.360 --> 32:16.680\n They build the systems,\n\n32:16.680 --> 32:19.280\n they build the customer facing systems,\n\n32:19.280 --> 32:21.920\n they build things that people can use\n\n32:21.920 --> 32:23.760\n without technical education.\n\n32:23.760 --> 32:25.800\n And they are inspired by research.\n\n32:25.800 --> 32:27.480\n They're inspired by scientists.\n\n32:27.480 --> 32:30.280\n They hire the best PhDs from the best universities\n\n32:30.280 --> 32:31.120\n for a reason.\n\n32:31.960 --> 32:35.080\n So I think this kind of vertical integration\n\n32:35.080 --> 32:37.720\n between the real product, the real impact\n\n32:37.720 --> 32:39.800\n and the real thought, the real ideas,\n\n32:39.800 --> 32:42.720\n that's actually working surprisingly well in Silicon Valley.\n\n32:42.720 --> 32:44.840\n It did not work as well in other places in this nation.\n\n32:44.840 --> 32:46.640\n So when I worked at Carnegie Mellon,\n\n32:46.640 --> 32:49.800\n we had the world's finest computer science university,\n\n32:49.800 --> 32:52.720\n but there wasn't those people in Pittsburgh\n\n32:52.720 --> 32:54.280\n that would be able to take these\n\n32:54.280 --> 32:56.000\n very fine computer science ideas\n\n32:56.000 --> 33:00.560\n and turn them into massive, impactful products.\n\n33:00.560 --> 33:02.800\n That symbiosis seemed to exist\n\n33:02.800 --> 33:04.600\n pretty much only in Silicon Valley\n\n33:04.600 --> 33:06.560\n and maybe a bit in Boston and Austin.\n\n33:06.560 --> 33:11.040\n Yeah, with Stanford, that's really interesting.\n\n33:11.040 --> 33:14.000\n So if we look a little bit further on\n\n33:14.000 --> 33:17.120\n from the DARPA Grand Challenge\n\n33:17.120 --> 33:20.000\n and the launch of the Google self driving car,\n\n33:20.000 --> 33:22.000\n what do you see as the state,\n\n33:22.000 --> 33:25.840\n the challenges of autonomous vehicles as they are now\n\n33:25.840 --> 33:29.120\n is actually achieving that huge scale\n\n33:29.120 --> 33:31.640\n and having a huge impact on society?\n\n33:31.640 --> 33:35.200\n I'm extremely proud of what has been accomplished.\n\n33:35.200 --> 33:38.280\n And again, I'm taking a lot of credit for the work of others.\n\n33:38.280 --> 33:40.160\n And I'm actually very optimistic.\n\n33:40.160 --> 33:42.320\n And people have been kind of worrying,\n\n33:42.320 --> 33:43.800\n is it too fast? Is it too slow?\n\n33:43.800 --> 33:45.840\n Why is it not there yet? And so on.\n\n33:45.840 --> 33:48.800\n It is actually quite an interesting, hard problem.\n\n33:48.800 --> 33:51.640\n And in that a self driving car,\n\n33:51.640 --> 33:55.280\n to build one that manages 90% of the problems\n\n33:55.280 --> 33:57.200\n encountered in everyday driving is easy.\n\n33:57.200 --> 33:59.440\n We can literally do this over a weekend.\n\n33:59.440 --> 34:02.040\n To do 99% might take a month.\n\n34:02.040 --> 34:03.200\n Then there's 1% left.\n\n34:03.200 --> 34:06.920\n So 1% would mean that you still have a fatal accident\n\n34:06.920 --> 34:08.960\n every week, very unacceptable.\n\n34:08.960 --> 34:10.920\n So now you work on this 1%\n\n34:10.920 --> 34:13.640\n and the 99% of that, the remaining 1%\n\n34:13.640 --> 34:15.760\n is actually still relatively easy,\n\n34:15.760 --> 34:18.160\n but now you're down to like a hundredth of 1%.\n\n34:18.160 --> 34:21.560\n And it's still completely unacceptable in terms of safety.\n\n34:21.560 --> 34:24.200\n So the variety of things you encounter are just enormous.\n\n34:24.200 --> 34:26.440\n And that gives me enormous respect for human being\n\n34:26.440 --> 34:30.440\n that we're able to deal with the couch on the highway,\n\n34:30.440 --> 34:33.440\n or the deer in the headlights, or the blown tire\n\n34:33.440 --> 34:34.880\n that we've never been trained for.\n\n34:34.880 --> 34:35.960\n And all of a sudden have to handle it\n\n34:35.960 --> 34:37.080\n in an emergency situation\n\n34:37.080 --> 34:38.720\n and often do very, very successfully.\n\n34:38.720 --> 34:40.640\n It's amazing from that perspective,\n\n34:40.640 --> 34:43.640\n how safe driving actually is given how many millions\n\n34:43.640 --> 34:45.960\n of miles we drive every year in this country.\n\n34:47.600 --> 34:49.400\n We are now at a point where I believe the technology\n\n34:49.400 --> 34:51.560\n is there and I've seen it.\n\n34:51.560 --> 34:53.520\n I've seen it in Waymo, I've seen it in Aptiv,\n\n34:53.520 --> 34:56.760\n I've seen it in Cruise and in a number of companies\n\n34:56.760 --> 35:00.920\n and in Voyage where vehicles now driving around\n\n35:00.920 --> 35:04.360\n and basically flawlessly are able to drive people around\n\n35:04.360 --> 35:06.040\n in limited scenarios.\n\n35:06.040 --> 35:07.960\n In fact, you can go to Vegas today\n\n35:07.960 --> 35:09.880\n and order a Summon and Lift.\n\n35:09.880 --> 35:13.480\n And if you get the right setting of your app,\n\n35:13.480 --> 35:15.760\n you'll be picked up by a driverless car.\n\n35:15.760 --> 35:18.040\n Now there's still safety drivers in there,\n\n35:18.040 --> 35:21.280\n but that's a fantastic way to kind of learn\n\n35:21.280 --> 35:22.920\n what the limits are of technology today.\n\n35:22.920 --> 35:24.680\n And there's still some glitches,\n\n35:24.680 --> 35:26.520\n but the glitches have become very, very rare.\n\n35:26.520 --> 35:29.680\n I think the next step is gonna be to down cost it,\n\n35:29.680 --> 35:33.720\n to harden it, the entrapment, the sensors\n\n35:33.720 --> 35:36.120\n are not quite an automotive grade standard yet.\n\n35:36.120 --> 35:37.760\n And then to really build the business models,\n\n35:37.760 --> 35:40.920\n to really kind of go somewhere and make the business case.\n\n35:40.920 --> 35:42.520\n And the business case is hard work.\n\n35:42.520 --> 35:44.560\n It's not just, oh my God, we have this capability,\n\n35:44.560 --> 35:45.480\n people are just gonna buy it.\n\n35:45.480 --> 35:46.680\n You have to make it affordable.\n\n35:46.680 --> 35:51.680\n You have to find the social acceptance of people.\n\n35:52.240 --> 35:55.360\n None of the teams yet has been able to or gutsy enough\n\n35:55.360 --> 35:59.240\n to drive around without a person inside the car.\n\n35:59.240 --> 36:01.320\n And that's the next magical hurdle.\n\n36:01.320 --> 36:03.800\n We'll be able to send these vehicles around\n\n36:03.800 --> 36:05.760\n completely empty in traffic.\n\n36:05.760 --> 36:08.120\n And I think, I mean, I wait every day,\n\n36:08.120 --> 36:10.680\n wait for the news that Waymo has just done this.\n\n36:11.840 --> 36:15.080\n So, interesting you mentioned gutsy.\n\n36:15.080 --> 36:20.080\n Let me ask some maybe unanswerable question,\n\n36:20.200 --> 36:21.480\n maybe edgy questions.\n\n36:21.480 --> 36:26.480\n But in terms of how much risk is required,\n\n36:26.880 --> 36:30.360\n some guts in terms of leadership style,\n\n36:30.360 --> 36:32.600\n it would be good to contrast approaches.\n\n36:32.600 --> 36:34.680\n And I don't think anyone knows what's right.\n\n36:34.680 --> 36:38.560\n But if we compare Tesla and Waymo, for example,\n\n36:38.560 --> 36:41.440\n Elon Musk and the Waymo team,\n\n36:43.200 --> 36:45.680\n there's slight differences in approach.\n\n36:45.680 --> 36:49.560\n So on the Elon side, there's more,\n\n36:49.560 --> 36:50.840\n I don't know what the right word to use,\n\n36:50.840 --> 36:53.920\n but aggression in terms of innovation.\n\n36:53.920 --> 36:58.920\n And on Waymo side, there's more sort of cautious,\n\n36:59.800 --> 37:03.480\n safety focused approach to the problem.\n\n37:03.480 --> 37:06.200\n What do you think it takes?\n\n37:06.200 --> 37:09.160\n What leadership at which moment is right?\n\n37:09.160 --> 37:10.680\n Which approach is right?\n\n37:11.600 --> 37:13.880\n Look, I don't sit in either of those teams.\n\n37:13.880 --> 37:18.000\n So I'm unable to even verify like somebody says correct.\n\n37:18.000 --> 37:21.240\n In the end of the day, every innovator in that space\n\n37:21.240 --> 37:23.160\n will face a fundamental dilemma.\n\n37:23.160 --> 37:27.120\n And I would say you could put aerospace titans\n\n37:27.120 --> 37:28.880\n into the same bucket,\n\n37:28.880 --> 37:31.600\n which is you have to balance public safety\n\n37:31.600 --> 37:34.280\n with your drive to innovate.\n\n37:34.280 --> 37:36.760\n And this country in particular in the States\n\n37:36.760 --> 37:38.320\n has a hundred plus year history\n\n37:38.320 --> 37:40.600\n of doing this very successfully.\n\n37:40.600 --> 37:43.880\n Air travel is what a hundred times a safe per mile\n\n37:43.880 --> 37:46.600\n than ground travel, than cars.\n\n37:46.600 --> 37:50.320\n And there's a reason for it because people have found ways\n\n37:50.320 --> 37:55.080\n to be very methodological about ensuring public safety\n\n37:55.080 --> 37:56.880\n while still being able to make progress\n\n37:56.880 --> 37:59.000\n on important aspects, for example,\n\n37:59.000 --> 38:01.720\n like air and noise and fuel consumption.\n\n38:03.600 --> 38:06.120\n So I think that those practices are proven\n\n38:06.120 --> 38:07.840\n and they actually work.\n\n38:07.840 --> 38:09.840\n We live in a world safer than ever before.\n\n38:09.840 --> 38:11.880\n And yes, there will always be the provision\n\n38:11.880 --> 38:12.720\n that something goes wrong.\n\n38:12.720 --> 38:14.040\n There's always the possibility\n\n38:14.040 --> 38:15.240\n that someone makes a mistake\n\n38:15.240 --> 38:17.120\n or there's an unexpected failure.\n\n38:17.120 --> 38:19.720\n We can never guarantee to a hundred percent\n\n38:19.720 --> 38:23.320\n absolute safety other than just not doing it.\n\n38:23.320 --> 38:27.080\n But I think I'm very proud of the history of the United States.\n\n38:27.080 --> 38:30.120\n I mean, we've dealt with much more dangerous technology\n\n38:30.120 --> 38:32.720\n like nuclear energy and kept that safe too.\n\n38:33.760 --> 38:36.400\n We have nuclear weapons and we keep those safe.\n\n38:36.400 --> 38:39.440\n So we have methods and procedures\n\n38:39.440 --> 38:42.920\n that really balance these two things very, very successfully.\n\n38:42.920 --> 38:46.320\n You've mentioned a lot of great autonomous vehicle companies\n\n38:46.320 --> 38:48.760\n that are taking sort of the level four, level five,\n\n38:48.760 --> 38:51.840\n they jump in full autonomy with a safety driver\n\n38:51.840 --> 38:53.120\n and take that kind of approach\n\n38:53.120 --> 38:55.760\n and also through simulation and so on.\n\n38:55.760 --> 38:59.560\n There's also the approach that Tesla Autopilot is doing,\n\n38:59.560 --> 39:03.680\n which is kind of incrementally taking a level two vehicle\n\n39:03.680 --> 39:04.920\n and using machine learning\n\n39:04.920 --> 39:08.360\n and learning from the driving of human beings\n\n39:08.360 --> 39:10.560\n and trying to creep up,\n\n39:10.560 --> 39:12.360\n trying to incrementally improve the system\n\n39:12.360 --> 39:15.520\n until it's able to achieve level four autonomy.\n\n39:15.520 --> 39:19.760\n So perfect autonomy in certain kind of geographical regions.\n\n39:19.760 --> 39:23.120\n What are your thoughts on these contrasting approaches?\n\n39:23.120 --> 39:25.560\n Well, so first of all, I'm a very proud Tesla owner\n\n39:25.560 --> 39:27.840\n and I literally use the Autopilot every day\n\n39:27.840 --> 39:29.520\n and it literally has kept me safe.\n\n39:30.760 --> 39:33.920\n It is a beautiful technology specifically\n\n39:33.920 --> 39:37.600\n for highway driving when I'm slightly tired\n\n39:37.600 --> 39:42.200\n because then it turns me into a much safer driver.\n\n39:42.200 --> 39:45.000\n And I'm 100% confident that's the case.\n\n39:46.520 --> 39:47.680\n In terms of the right approach,\n\n39:47.680 --> 39:49.880\n I think the biggest change I've seen\n\n39:49.880 --> 39:54.280\n since I went to Waymo team is this thing called deep learning.\n\n39:54.280 --> 39:56.320\n I think deep learning was not a hot topic\n\n39:56.320 --> 39:59.400\n when I started Waymo or Google self driving cars.\n\n39:59.400 --> 40:01.760\n It was there, in fact, we started Google Brain\n\n40:01.760 --> 40:02.840\n at the same time in Google X.\n\n40:02.840 --> 40:04.760\n So I invested in deep learning,\n\n40:04.760 --> 40:07.840\n but people didn't talk about it, it wasn't a hot topic.\n\n40:07.840 --> 40:10.360\n And now it is, there's a shift of emphasis\n\n40:10.360 --> 40:12.440\n from a more geometric perspective\n\n40:12.440 --> 40:14.320\n where you use geometric sensors\n\n40:14.320 --> 40:15.680\n that give you a full 3D view\n\n40:15.680 --> 40:17.280\n when you do a geometric reasoning about,\n\n40:17.280 --> 40:19.640\n oh, this box over here might be a car\n\n40:19.640 --> 40:24.160\n towards a more human like, oh, let's just learn about it.\n\n40:24.160 --> 40:26.520\n This looks like the thing I've seen 10,000 times before.\n\n40:26.520 --> 40:30.280\n So maybe it's the same thing, machine learning perspective.\n\n40:30.280 --> 40:32.160\n And that has really put, I think,\n\n40:32.160 --> 40:34.760\n all these approaches on steroids.\n\n40:36.000 --> 40:38.720\n At Udacity, we teach a course in self driving cars.\n\n40:38.720 --> 40:43.720\n In fact, I think we've graduated over 20,000 or so people\n\n40:43.800 --> 40:45.000\n on self driving car skills.\n\n40:45.000 --> 40:47.440\n So every self driving car team in the world\n\n40:47.440 --> 40:49.280\n now uses our engineers.\n\n40:49.280 --> 40:51.920\n And in this course, the very first homework assignment\n\n40:51.920 --> 40:54.920\n is to do lane finding on images.\n\n40:54.920 --> 40:56.960\n And lane finding images for layman,\n\n40:56.960 --> 40:59.040\n what this means is you put a camera into your car\n\n40:59.040 --> 41:02.440\n or you open your eyes and you would know where the lane is.\n\n41:02.440 --> 41:05.000\n So you can stay inside the lane with your car.\n\n41:05.000 --> 41:06.520\n Humans can do this super easily.\n\n41:06.520 --> 41:08.120\n You just look and you know where the lane is,\n\n41:08.120 --> 41:10.200\n just intuitively.\n\n41:10.200 --> 41:12.240\n For machines, for a long time, it was super hard\n\n41:12.240 --> 41:14.680\n because people would write these kind of crazy rules.\n\n41:14.680 --> 41:16.120\n If there's like wine lane markers\n\n41:16.120 --> 41:17.680\n and here's what white really means,\n\n41:17.680 --> 41:19.160\n this is not quite white enough.\n\n41:19.160 --> 41:20.360\n So let's, oh, it's not white.\n\n41:20.360 --> 41:21.480\n Or maybe the sun is shining.\n\n41:21.480 --> 41:23.520\n So when the sun shines and this is white\n\n41:23.520 --> 41:24.720\n and this is a straight line,\n\n41:24.720 --> 41:25.760\n I mean, it's not quite a straight line\n\n41:25.760 --> 41:27.320\n because the road is curved.\n\n41:27.320 --> 41:29.280\n And do we know that there's really six feet\n\n41:29.280 --> 41:32.120\n between lane markings or not or 12 feet, whatever it is.\n\n41:34.000 --> 41:36.320\n And now what the students are doing,\n\n41:36.320 --> 41:37.440\n they would take machine learning.\n\n41:37.440 --> 41:39.640\n So instead of like writing these crazy rules\n\n41:39.640 --> 41:40.480\n for the lane marker,\n\n41:40.480 --> 41:42.720\n they'll say, hey, let's take an hour of driving\n\n41:42.720 --> 41:44.440\n and label it and tell the vehicle,\n\n41:44.440 --> 41:45.800\n this is actually the lane by hand.\n\n41:45.800 --> 41:47.360\n And then these are examples\n\n41:47.360 --> 41:49.400\n and have the machine find its own rules,\n\n41:49.400 --> 41:51.400\n what lane markings are.\n\n41:51.400 --> 41:53.800\n And within 24 hours, now every student\n\n41:53.800 --> 41:56.040\n that's never done any programming before in this space\n\n41:56.040 --> 41:58.320\n can write a perfect lane finder\n\n41:58.320 --> 42:00.880\n as good as the best commercial lane finders.\n\n42:00.880 --> 42:02.760\n And that's completely amazing to me.\n\n42:02.760 --> 42:05.520\n We've seen progress using machine learning\n\n42:05.520 --> 42:08.160\n that completely dwarfs anything\n\n42:08.160 --> 42:09.920\n that I saw 10 years ago.\n\n42:10.960 --> 42:12.840\n Yeah, and just as a side note,\n\n42:12.840 --> 42:15.240\n the self driving car nanodegree,\n\n42:15.240 --> 42:18.960\n the fact that you launched that many years ago now,\n\n42:18.960 --> 42:22.080\n maybe four years ago, three years ago is incredible\n\n42:22.080 --> 42:24.760\n that that's a great example of system level thinking\n\n42:24.760 --> 42:27.160\n sort of just taking an entire course\n\n42:27.160 --> 42:29.280\n that teaches you how to solve the entire problem.\n\n42:29.280 --> 42:31.240\n I definitely recommend people.\n\n42:31.240 --> 42:32.480\n It's become super popular\n\n42:32.480 --> 42:34.320\n and it's become actually incredibly high quality\n\n42:34.320 --> 42:37.360\n really with Mercedes and various other companies\n\n42:37.360 --> 42:38.200\n in that space.\n\n42:38.200 --> 42:40.600\n And we find that engineers from Tesla and Waymo\n\n42:40.600 --> 42:42.000\n are taking it today.\n\n42:43.120 --> 42:45.520\n The insight was that two things,\n\n42:45.520 --> 42:49.240\n one is existing universities will be very slow to move\n\n42:49.240 --> 42:50.520\n because they're departmentalized\n\n42:50.520 --> 42:52.360\n and there's no department for self driving cars.\n\n42:52.360 --> 42:56.240\n So between Mac E and double E and computer science,\n\n42:56.240 --> 42:57.240\n getting those folks together\n\n42:57.240 --> 42:59.680\n into one room is really, really hard.\n\n42:59.680 --> 43:01.280\n And every professor listening here will know,\n\n43:01.280 --> 43:02.960\n they'll probably agree to that.\n\n43:02.960 --> 43:06.400\n And secondly, even if all the great universities\n\n43:06.400 --> 43:09.120\n just did this, which none so far has developed\n\n43:09.120 --> 43:11.120\n a curriculum in this field,\n\n43:11.120 --> 43:13.720\n it is just a few thousand students that can partake\n\n43:13.720 --> 43:16.280\n because all the great universities are super selective.\n\n43:16.280 --> 43:18.160\n So how about people in India?\n\n43:18.160 --> 43:20.680\n How about people in China or in the Middle East\n\n43:20.680 --> 43:23.480\n or Indonesia or Africa?\n\n43:23.480 --> 43:25.200\n Why should those be excluded\n\n43:25.200 --> 43:27.280\n from the skill of building self driving cars?\n\n43:27.280 --> 43:28.480\n Are they any dumber than we are?\n\n43:28.480 --> 43:30.240\n Are we any less privileged?\n\n43:30.240 --> 43:34.880\n And the answer is we should just give everybody the skill\n\n43:34.880 --> 43:35.920\n to build a self driving car.\n\n43:35.920 --> 43:37.440\n Because if we do this,\n\n43:37.440 --> 43:40.360\n then we have like a thousand self driving car startups.\n\n43:40.360 --> 43:42.960\n And if 10% succeed, that's like a hundred,\n\n43:42.960 --> 43:44.200\n that means hundred countries now\n\n43:44.200 --> 43:46.800\n will have self driving cars and be safer.\n\n43:46.800 --> 43:50.360\n It's kind of interesting to imagine impossible to quantify,\n\n43:50.360 --> 43:53.600\n but the number, the, you know,\n\n43:53.600 --> 43:55.080\n over a period of several decades,\n\n43:55.080 --> 43:57.960\n the impact that has like a single course,\n\n43:57.960 --> 44:00.760\n like a ripple effect of society.\n\n44:00.760 --> 44:03.520\n If you, I just recently talked to Andrew\n\n44:03.520 --> 44:06.560\n who was creator of Cosmos show.\n\n44:06.560 --> 44:08.200\n It's interesting to think about\n\n44:08.200 --> 44:10.720\n how many scientists that show launched.\n\n44:10.720 --> 44:15.600\n And so it's really, in terms of impact,\n\n44:15.600 --> 44:17.200\n I can't imagine a better course\n\n44:17.200 --> 44:18.680\n than the self driving car course.\n\n44:18.680 --> 44:21.840\n That's, you know, there's other more specific disciplines\n\n44:21.840 --> 44:24.120\n like deep learning and so on that Udacity is also teaching,\n\n44:24.120 --> 44:25.160\n but self driving cars,\n\n44:25.160 --> 44:26.920\n it's really, really interesting course.\n\n44:26.920 --> 44:28.440\n And then it came at the right moment.\n\n44:28.440 --> 44:31.720\n It came at a time when there were a bunch of Acqui hires.\n\n44:31.720 --> 44:34.200\n Acqui hire is a acquisition of a company,\n\n44:34.200 --> 44:36.400\n not for its technology or its products or business,\n\n44:36.400 --> 44:38.320\n but for its people.\n\n44:38.320 --> 44:40.640\n So Acqui hire means maybe that a company of 70 people,\n\n44:40.640 --> 44:43.160\n they have no product yet, but they're super smart people\n\n44:43.160 --> 44:44.320\n and they pay a certain amount of money.\n\n44:44.320 --> 44:48.440\n So I took Acqui hires like GM Cruise and Uber and others,\n\n44:48.440 --> 44:50.120\n and did the math and said,\n\n44:50.120 --> 44:53.760\n hey, how many people are there and how much money was paid?\n\n44:53.760 --> 44:55.640\n And as a lower bound,\n\n44:55.640 --> 44:58.560\n I estimated the value of a self driving car engineer\n\n44:58.560 --> 45:02.240\n in these acquisitions to be at least $10 million, right?\n\n45:02.240 --> 45:05.080\n So think about this, you get yourself a skill\n\n45:05.080 --> 45:06.680\n and you team up and build a company\n\n45:06.680 --> 45:09.800\n and your worth now is $10 million.\n\n45:09.800 --> 45:10.840\n I mean, that's kind of cool.\n\n45:10.840 --> 45:13.440\n I mean, what other thing could you do in life\n\n45:13.440 --> 45:15.920\n to be worth $10 million within a year?\n\n45:15.920 --> 45:17.640\n Yeah, amazing.\n\n45:17.640 --> 45:21.000\n But to come back for a moment on to deep learning\n\n45:21.000 --> 45:23.760\n and its application in autonomous vehicles,\n\n45:23.760 --> 45:28.480\n what are your thoughts on Elon Musk's statement,\n\n45:28.480 --> 45:31.080\n provocative statement, perhaps that light air is a crutch.\n\n45:31.080 --> 45:34.000\n So this geometric way of thinking about the world\n\n45:34.000 --> 45:38.920\n may be holding us back if what we should instead be doing\n\n45:38.920 --> 45:39.920\n in this robotic space,\n\n45:39.920 --> 45:42.520\n in this particular space of autonomous vehicles\n\n45:42.520 --> 45:46.440\n is using camera as a primary sensor\n\n45:46.440 --> 45:48.200\n and using computer vision and machine learning\n\n45:48.200 --> 45:49.720\n as the primary way to...\n\n45:49.720 --> 45:50.560\n Look, I have two comments.\n\n45:50.560 --> 45:52.240\n I think first of all, we all know\n\n45:52.240 --> 45:56.880\n that people can drive cars without lighters in their heads\n\n45:56.880 --> 45:59.000\n because we only have eyes\n\n45:59.000 --> 46:02.080\n and we mostly just use eyes for driving.\n\n46:02.080 --> 46:04.560\n Maybe we use some other perception about our bodies,\n\n46:04.560 --> 46:06.680\n accelerations, occasionally our ears,\n\n46:08.000 --> 46:09.480\n certainly not our noses.\n\n46:10.680 --> 46:12.440\n So the existence proof is there,\n\n46:12.440 --> 46:14.600\n that eyes must be sufficient.\n\n46:15.560 --> 46:17.920\n In fact, we could even drive a car\n\n46:17.920 --> 46:19.440\n if someone put a camera out\n\n46:19.440 --> 46:23.440\n and then gave us the camera image with no latency,\n\n46:23.440 --> 46:26.360\n we would be able to drive a car that way the same way.\n\n46:26.360 --> 46:28.720\n So a camera is also sufficient.\n\n46:28.720 --> 46:31.840\n Secondly, I really love the idea that in the Western world,\n\n46:31.840 --> 46:33.600\n we have many, many different people\n\n46:33.600 --> 46:35.680\n trying different hypotheses.\n\n46:35.680 --> 46:36.840\n It's almost like an anthill,\n\n46:36.840 --> 46:39.560\n like if an anthill tries to forge for food,\n\n46:39.560 --> 46:41.000\n you can sit there as two ants\n\n46:41.000 --> 46:42.560\n and agree what the perfect path is\n\n46:42.560 --> 46:44.040\n and then every single ant marches\n\n46:44.040 --> 46:46.320\n for the most likely location of food is,\n\n46:46.320 --> 46:47.960\n or you can even just spread out.\n\n46:47.960 --> 46:50.440\n And I promise you the spread out solution will be better\n\n46:50.440 --> 46:53.960\n because if the discussing philosophical,\n\n46:53.960 --> 46:55.560\n intellectual ants get it wrong\n\n46:55.560 --> 46:56.920\n and they're all moving the wrong direction,\n\n46:56.920 --> 46:58.240\n they're going to waste a day\n\n46:58.240 --> 47:00.520\n and then they're going to discuss again for another week.\n\n47:00.520 --> 47:02.480\n Whereas if all these ants go in a random direction,\n\n47:02.480 --> 47:03.520\n someone's going to succeed\n\n47:03.520 --> 47:05.560\n and they're going to come back and claim victory\n\n47:05.560 --> 47:08.520\n and get the Nobel prize or whatever the ant equivalent is.\n\n47:08.520 --> 47:10.520\n And then they all march in the same direction.\n\n47:10.520 --> 47:11.800\n And that's great about society.\n\n47:11.800 --> 47:13.160\n That's great about the Western society.\n\n47:13.160 --> 47:15.480\n We're not plan based, we're not central based.\n\n47:15.480 --> 47:19.120\n We don't have a Soviet Union style central government\n\n47:19.120 --> 47:20.960\n that tells us where to forge.\n\n47:20.960 --> 47:21.800\n We just forge.\n\n47:21.800 --> 47:23.120\n We started in C Corp.\n\n47:24.040 --> 47:25.840\n We get investor money, go out and try it out.\n\n47:25.840 --> 47:27.480\n And who knows who's going to win.\n\n47:28.720 --> 47:30.160\n I like it.\n\n47:30.160 --> 47:33.440\n In your, when you look at the longterm vision\n\n47:33.440 --> 47:35.160\n of autonomous vehicles,\n\n47:35.160 --> 47:36.920\n do you see machine learning\n\n47:36.920 --> 47:39.600\n as fundamentally being able to solve most of the problems?\n\n47:39.600 --> 47:42.280\n So learning from experience.\n\n47:42.280 --> 47:44.200\n I'd say we should be very clear\n\n47:44.200 --> 47:46.080\n about what machine learning is and is not.\n\n47:46.080 --> 47:48.160\n And I think there's a lot of confusion.\n\n47:48.160 --> 47:50.880\n What it is today is a technology\n\n47:50.880 --> 47:54.680\n that can go through large databases\n\n47:54.680 --> 47:59.680\n of repetitive patterns and find those patterns.\n\n48:00.880 --> 48:03.560\n So in example, we did a study at Stanford two years ago\n\n48:03.560 --> 48:05.440\n where we applied machine learning\n\n48:05.440 --> 48:07.880\n to detecting skin cancer in images.\n\n48:07.880 --> 48:10.760\n And we harvested or built a data set\n\n48:10.760 --> 48:15.080\n of 129,000 skin photo shots\n\n48:15.080 --> 48:17.000\n that were all had been biopsied\n\n48:17.000 --> 48:19.440\n for what the actual situation was.\n\n48:19.440 --> 48:22.680\n And those included melanomas and carcinomas,\n\n48:22.680 --> 48:26.440\n also included rashes and other skin conditions, lesions.\n\n48:27.200 --> 48:30.720\n And then we had a network find those patterns.\n\n48:30.720 --> 48:34.520\n And it was by and large able to then detect skin cancer\n\n48:34.520 --> 48:36.680\n with an iPhone as accurately\n\n48:36.680 --> 48:41.400\n as the best board certified Stanford level dermatologist.\n\n48:41.400 --> 48:42.800\n We proved that.\n\n48:42.800 --> 48:45.880\n Now this thing was great in this one thing\n\n48:45.880 --> 48:48.560\n and finding skin cancer, but it couldn't drive a car.\n\n48:49.680 --> 48:51.600\n So the difference to human intelligence\n\n48:51.600 --> 48:53.280\n is we do all these many, many things\n\n48:53.280 --> 48:56.720\n and we can often learn from a very small data set\n\n48:56.720 --> 48:58.160\n of experiences.\n\n48:58.160 --> 49:01.120\n Whereas machines still need very large data sets\n\n49:01.120 --> 49:03.320\n and things that will be very repetitive.\n\n49:03.320 --> 49:04.680\n Now that's still super impactful\n\n49:04.680 --> 49:06.440\n because almost everything we do is repetitive.\n\n49:06.440 --> 49:10.000\n So that's gonna really transform human labor\n\n49:10.000 --> 49:13.120\n but it's not this almighty general intelligence.\n\n49:13.120 --> 49:15.280\n We're really far away from a system\n\n49:15.280 --> 49:17.280\n that will exhibit general intelligence.\n\n49:18.760 --> 49:21.320\n To that end, I actually commiserate the naming a little bit\n\n49:21.320 --> 49:24.440\n because artificial intelligence, if you believe Hollywood\n\n49:24.440 --> 49:27.320\n is immediately mixed into the idea of human suppression\n\n49:27.320 --> 49:30.360\n and machine superiority.\n\n49:30.360 --> 49:32.960\n I don't think that we're gonna see this in my lifetime.\n\n49:32.960 --> 49:36.440\n I don't think human suppression is a good idea.\n\n49:36.440 --> 49:37.440\n I don't see it coming.\n\n49:37.440 --> 49:39.720\n I don't see the technology being there.\n\n49:39.720 --> 49:42.960\n What I see instead is a very pointed focused\n\n49:42.960 --> 49:45.440\n pattern recognition technology that's able to\n\n49:45.440 --> 49:48.400\n extract patterns from large data sets.\n\n49:48.400 --> 49:51.520\n And in doing so, it can be super impactful.\n\n49:51.520 --> 49:53.520\n Super impactful.\n\n49:53.520 --> 49:55.920\n Let's take the impact of artificial intelligence\n\n49:55.920 --> 49:57.640\n on human work.\n\n49:57.640 --> 50:00.520\n We all know that it takes something like 10,000 hours\n\n50:00.520 --> 50:01.520\n to become an expert.\n\n50:01.520 --> 50:03.360\n If you're gonna be a doctor or a lawyer\n\n50:03.360 --> 50:05.320\n or even a really good driver,\n\n50:05.320 --> 50:08.520\n it takes a certain amount of time to become experts.\n\n50:08.520 --> 50:11.400\n Machines now are able and have been shown\n\n50:11.400 --> 50:15.640\n to observe people become experts and observe experts\n\n50:15.640 --> 50:17.440\n and then extract those rules from experts\n\n50:17.440 --> 50:18.680\n in some interesting way.\n\n50:18.680 --> 50:23.680\n They could go from law to sales to driving cars\n\n50:25.840 --> 50:28.200\n to diagnosing cancer.\n\n50:28.200 --> 50:30.840\n And then giving that capability to people who are\n\n50:30.840 --> 50:32.320\n completely new in their job.\n\n50:32.320 --> 50:34.760\n We now can, and that's been done.\n\n50:34.760 --> 50:37.800\n It's been done commercially in many, many instantiations.\n\n50:37.800 --> 50:40.120\n So that means we can use machine learning\n\n50:40.120 --> 50:44.880\n to make people expert on the very first day of their work.\n\n50:44.880 --> 50:45.880\n Like think about the impact.\n\n50:45.880 --> 50:50.360\n If your doctor is still in their first 10,000 hours,\n\n50:50.360 --> 50:53.120\n you have a doctor who is not quite an expert yet.\n\n50:53.120 --> 50:56.720\n Who would not want a doctor who is the world's best expert?\n\n50:56.720 --> 51:00.400\n And now we can leverage machines to really eradicate\n\n51:00.400 --> 51:02.760\n the error in decision making,\n\n51:02.760 --> 51:06.240\n error and lack of expertise for human doctors.\n\n51:06.240 --> 51:08.360\n That could save your life.\n\n51:08.360 --> 51:10.360\n If we can link on that for a little bit,\n\n51:10.360 --> 51:14.800\n in which way do you hope machines in the medical field\n\n51:14.800 --> 51:16.360\n could help assist doctors?\n\n51:16.360 --> 51:21.320\n You mentioned this sort of accelerating the learning curve\n\n51:21.320 --> 51:26.120\n or people, if they start a job or in the first 10,000 hours\n\n51:26.120 --> 51:27.360\n can be assisted by machines.\n\n51:27.360 --> 51:29.720\n How do you envision that assistance looking?\n\n51:29.720 --> 51:33.480\n So we built this app for an iPhone that can detect\n\n51:33.480 --> 51:36.320\n and classify and diagnose skin cancer.\n\n51:36.320 --> 51:40.560\n And we proved two years ago that it does pretty much\n\n51:40.560 --> 51:42.240\n as good or better than the best human doctors.\n\n51:42.240 --> 51:43.600\n So let me tell you a story.\n\n51:43.600 --> 51:45.480\n So there's a friend of mine, let's call him Ben.\n\n51:45.480 --> 51:47.680\n Ben is a very famous venture capitalist.\n\n51:47.680 --> 51:50.720\n He goes to his doctor and the doctor looks at a mole\n\n51:50.720 --> 51:55.360\n and says, hey, that mole is probably harmless.\n\n51:55.360 --> 51:59.800\n And for some very funny reason, he pulls out that phone\n\n51:59.800 --> 52:00.640\n with our app.\n\n52:00.640 --> 52:02.640\n He's a collaborator in our study.\n\n52:02.640 --> 52:06.320\n And the app says, no, no, no, no, this is a melanoma.\n\n52:06.320 --> 52:08.720\n And for background, melanomas are,\n\n52:08.720 --> 52:12.400\n and skin cancer is the most common cancer in this country.\n\n52:12.400 --> 52:16.640\n Melanomas can go from stage zero to stage four\n\n52:16.640 --> 52:18.120\n within less than a year.\n\n52:18.120 --> 52:20.880\n Stage zero means you can basically cut it out yourself\n\n52:20.880 --> 52:23.200\n with a kitchen knife and be safe.\n\n52:23.200 --> 52:25.520\n And stage four means your chances of living\n\n52:25.520 --> 52:28.000\n five more years in less than 20%.\n\n52:28.000 --> 52:31.160\n So it's a very serious, serious, serious condition.\n\n52:31.160 --> 52:36.160\n So this doctor who took out the iPhone,\n\n52:36.160 --> 52:37.680\n looked at the iPhone and was a little bit puzzled.\n\n52:37.680 --> 52:39.720\n He said, I mean, but just to be safe,\n\n52:39.720 --> 52:41.600\n let's cut it out and biopsy it.\n\n52:41.600 --> 52:43.560\n That's the technical term for let's get\n\n52:43.560 --> 52:47.720\n an in depth diagnostics that is more than just looking at it.\n\n52:47.720 --> 52:50.760\n And it came back as cancerous, as a melanoma.\n\n52:50.760 --> 52:52.240\n And it was then removed.\n\n52:52.240 --> 52:54.960\n And my friend, Ben, I was hiking with him\n\n52:54.960 --> 52:56.280\n and we were talking about AI.\n\n52:56.280 --> 52:58.880\n And I told him I do this work on skin cancer.\n\n52:58.880 --> 53:00.720\n And he said, oh, funny.\n\n53:00.720 --> 53:03.800\n My doctor just had an iPhone that found my cancer.\n\n53:05.480 --> 53:06.920\n So I was like completely intrigued.\n\n53:06.920 --> 53:08.200\n I didn't even know about this.\n\n53:08.200 --> 53:11.640\n So here's a person, I mean, this is a real human life, right?\n\n53:11.640 --> 53:12.920\n Like who doesn't know somebody\n\n53:12.920 --> 53:14.000\n who has been affected by cancer.\n\n53:14.000 --> 53:16.160\n Cancer is cause of death number two.\n\n53:16.160 --> 53:19.440\n Cancer is this kind of disease that is mean\n\n53:19.440 --> 53:21.080\n in the following way.\n\n53:21.080 --> 53:24.520\n Most cancers can actually be cured relatively easily\n\n53:24.520 --> 53:25.880\n if we catch them early.\n\n53:25.880 --> 53:28.360\n And the reason why we don't tend to catch them early\n\n53:28.360 --> 53:30.600\n is because they have no symptoms.\n\n53:30.600 --> 53:33.880\n Like your very first symptom of a gallbladder cancer\n\n53:33.880 --> 53:37.040\n or a pancreas cancer might be a headache.\n\n53:37.040 --> 53:38.680\n And when you finally go to your doctor\n\n53:38.680 --> 53:41.600\n because of these headaches or your back pain\n\n53:41.600 --> 53:45.880\n and you're being imaged, it's usually stage four plus.\n\n53:45.880 --> 53:48.200\n And that's the time when the occurring chances\n\n53:48.200 --> 53:50.880\n might be dropped to a single digit percentage.\n\n53:50.880 --> 53:54.560\n So if we could leverage AI to inspect your body\n\n53:54.560 --> 53:58.120\n on a regular basis without even a doctor in the room,\n\n53:58.120 --> 54:00.360\n maybe when you take a shower or what have you,\n\n54:00.360 --> 54:01.480\n I know this sounds creepy,\n\n54:01.480 --> 54:03.800\n but then we might be able to save millions\n\n54:03.800 --> 54:04.900\n and millions of lives.\n\n54:06.320 --> 54:09.520\n You've mentioned there's a concern that people have\n\n54:09.520 --> 54:12.880\n about near term impacts of AI in terms of job loss.\n\n54:12.880 --> 54:15.560\n So you've mentioned being able to assist doctors,\n\n54:15.560 --> 54:17.940\n being able to assist people in their jobs.\n\n54:17.940 --> 54:21.120\n Do you have a worry of people losing their jobs\n\n54:22.260 --> 54:25.480\n or the economy being affected by the improvements in AI?\n\n54:25.480 --> 54:27.680\n Yeah, anybody concerned about job losses,\n\n54:27.680 --> 54:30.040\n please come to Gdacity.com.\n\n54:30.040 --> 54:32.320\n We teach contemporary tech skills\n\n54:32.320 --> 54:35.840\n and we have a kind of implicit job promise.\n\n54:36.680 --> 54:38.960\n We often, when we measure,\n\n54:38.960 --> 54:41.840\n we spend way over 50% of our graders in new jobs\n\n54:41.840 --> 54:43.720\n and they're very satisfied about it.\n\n54:43.720 --> 54:44.800\n And it costs almost nothing,\n\n54:44.800 --> 54:47.120\n costs like 1,500 max or something like that.\n\n54:47.120 --> 54:48.920\n And so there's a cool new program\n\n54:48.920 --> 54:51.080\n that you agree with the U.S. government,\n\n54:51.080 --> 54:54.880\n guaranteeing that you will help us give scholarships\n\n54:54.880 --> 54:57.840\n that educate people in this kind of situation.\n\n54:57.840 --> 54:59.960\n Yeah, we're working with the U.S. government\n\n54:59.960 --> 55:03.880\n on the idea of basically rebuilding the American dream.\n\n55:03.880 --> 55:07.440\n So Gdacity has just dedicated 100,000 scholarships\n\n55:07.440 --> 55:12.080\n for citizens of America for various levels of courses\n\n55:12.080 --> 55:15.560\n that eventually will get you a job.\n\n55:15.560 --> 55:18.740\n And those courses are all somewhat related\n\n55:18.740 --> 55:20.460\n to the tech sector because the tech sector\n\n55:20.460 --> 55:22.060\n is kind of the hottest sector right now.\n\n55:22.060 --> 55:24.940\n And they range from interlevel digital marketing\n\n55:24.940 --> 55:28.060\n to very advanced self diving car engineering.\n\n55:28.060 --> 55:29.420\n And we're doing this with the White House\n\n55:29.420 --> 55:30.860\n because we think it's bipartisan.\n\n55:30.860 --> 55:35.860\n It's an issue that if you wanna really make America great,\n\n55:36.020 --> 55:40.060\n being able to be a part of the solution\n\n55:40.060 --> 55:43.780\n and live the American dream requires us to be proactive\n\n55:43.780 --> 55:45.780\n about our education and our skillset.\n\n55:45.780 --> 55:47.700\n It's just the way it is today.\n\n55:47.700 --> 55:48.700\n And it's always been this way.\n\n55:48.700 --> 55:49.940\n And we always had this American dream\n\n55:49.940 --> 55:51.140\n to send our kids to college.\n\n55:51.140 --> 55:53.260\n And now the American dream has to be\n\n55:53.260 --> 55:54.660\n to send ourselves to college.\n\n55:54.660 --> 55:58.220\n We can do this very, very, very efficiently\n\n55:58.220 --> 56:00.900\n and very, very, we can squeeze in in the evenings\n\n56:00.900 --> 56:01.820\n and things to online.\n\n56:01.820 --> 56:03.140\n So at all ages.\n\n56:03.140 --> 56:03.980\n All ages.\n\n56:03.980 --> 56:08.980\n So our learners go from age 11 to age 80.\n\n56:08.980 --> 56:13.980\n I just traveled Germany and the guy in the train compartment\n\n56:15.180 --> 56:17.500\n next to me was one of my students.\n\n56:17.500 --> 56:19.820\n It's like, wow, that's amazing.\n\n56:19.820 --> 56:21.020\n Think about impact.\n\n56:21.020 --> 56:24.020\n We've become the educator of choice for now,\n\n56:24.020 --> 56:26.500\n I believe officially six countries or five countries.\n\n56:26.500 --> 56:30.080\n Most in the Middle East, like Saudi Arabia and in Egypt.\n\n56:30.080 --> 56:33.420\n In Egypt, we just had a cohort graduate\n\n56:33.420 --> 56:37.280\n where we had 1100 high school students\n\n56:37.280 --> 56:39.820\n that went through programming skills,\n\n56:39.820 --> 56:42.920\n proficient at the level of a computer science undergrad.\n\n56:42.920 --> 56:45.220\n And we had a 95% graduation rate,\n\n56:45.220 --> 56:46.900\n even though everything's online, it's kind of tough,\n\n56:46.900 --> 56:48.260\n but we kind of trying to figure out\n\n56:48.260 --> 56:50.120\n how to make this effective.\n\n56:50.120 --> 56:52.540\n The vision is very, very simple.\n\n56:52.540 --> 56:57.540\n The vision is education ought to be a basic human right.\n\n56:58.340 --> 57:02.320\n It cannot be locked up behind ivory tower walls\n\n57:02.320 --> 57:04.420\n only for the rich people, for the parents\n\n57:04.420 --> 57:06.780\n who might be bribe themselves into the system.\n\n57:06.780 --> 57:09.260\n And only for young people and only for people\n\n57:09.260 --> 57:11.740\n from the right demographics and the right geography\n\n57:11.740 --> 57:14.260\n and possibly even the right race.\n\n57:14.260 --> 57:15.860\n It has to be opened up to everybody.\n\n57:15.860 --> 57:18.740\n If we are truthful to the human mission,\n\n57:18.740 --> 57:20.660\n if we are truthful to our values,\n\n57:20.660 --> 57:23.460\n we're gonna open up education to everybody in the world.\n\n57:23.460 --> 57:27.220\n So Udacity's pledge of 100,000 scholarships,\n\n57:27.220 --> 57:29.220\n I think is the biggest pledge of scholarships ever\n\n57:29.220 --> 57:30.760\n in terms of numbers.\n\n57:30.760 --> 57:33.020\n And we're working, as I said, with the White House\n\n57:33.020 --> 57:36.100\n and with very accomplished CEOs like Tim Cook\n\n57:36.100 --> 57:39.020\n from Apple and others to really bring education\n\n57:39.020 --> 57:40.980\n to everywhere in the world.\n\n57:40.980 --> 57:44.620\n Not to ask you to pick the favorite of your children,\n\n57:44.620 --> 57:45.580\n but at this point.\n\n57:45.580 --> 57:46.600\n Oh, that's Jasper.\n\n57:46.600 --> 57:49.740\n I only have one that I know of.\n\n57:49.740 --> 57:50.580\n Okay, good.\n\n57:52.700 --> 57:55.820\n In this particular moment, what nano degree,\n\n57:55.820 --> 58:00.060\n what set of courses are you most excited about at Udacity\n\n58:00.060 --> 58:02.020\n or is that too impossible to pick?\n\n58:02.020 --> 58:03.820\n I've been super excited about something\n\n58:03.820 --> 58:05.500\n we haven't launched yet in the building,\n\n58:05.500 --> 58:09.100\n which is when we talk to our partner companies,\n\n58:09.100 --> 58:12.700\n we have now a very strong footing in the enterprise world.\n\n58:12.700 --> 58:14.580\n And also to our students,\n\n58:14.580 --> 58:17.260\n we've kind of always focused on these hard skills,\n\n58:17.260 --> 58:19.740\n like the programming skills or math skills\n\n58:19.740 --> 58:22.180\n or building skills or design skills.\n\n58:22.180 --> 58:25.180\n And a very common ask is soft skills.\n\n58:25.180 --> 58:26.860\n Like how do you behave in your work?\n\n58:26.860 --> 58:28.280\n How do you develop empathy?\n\n58:28.280 --> 58:29.580\n How do you work on a team?\n\n58:30.460 --> 58:32.380\n What are the very basics of management?\n\n58:32.380 --> 58:33.700\n How do you do time management?\n\n58:33.700 --> 58:36.240\n How do you advance your career\n\n58:36.240 --> 58:39.260\n in the context of a broader community?\n\n58:39.260 --> 58:41.740\n And that's something that we haven't done very well\n\n58:41.740 --> 58:43.860\n at Udacity and I would say most universities\n\n58:43.860 --> 58:45.180\n are doing very poorly as well\n\n58:45.180 --> 58:47.900\n because we are so obsessed with individual test scores\n\n58:47.900 --> 58:52.620\n and pays a little attention to teamwork in education.\n\n58:52.620 --> 58:55.500\n So that's something I see us moving into as a company\n\n58:55.500 --> 58:56.940\n because I'm excited about this.\n\n58:56.940 --> 59:00.100\n And I think, look, we can teach people tech skills\n\n59:00.100 --> 59:00.940\n and they're gonna be great.\n\n59:00.940 --> 59:02.700\n But if you teach people empathy,\n\n59:02.700 --> 59:04.960\n that's gonna have the same impact.\n\n59:04.960 --> 59:08.100\n Maybe harder than self driving cars, but.\n\n59:08.100 --> 59:08.940\n I don't think so.\n\n59:08.940 --> 59:11.300\n I think the rules are really simple.\n\n59:11.300 --> 59:14.380\n You just have to, you have to want to engage.\n\n59:14.380 --> 59:18.180\n It's, we literally went in school and in K through 12,\n\n59:18.180 --> 59:20.460\n we teach kids like get the highest math score.\n\n59:20.460 --> 59:22.900\n And if you are a rational human being,\n\n59:22.900 --> 59:25.620\n you might evolve from this education say,\n\n59:25.620 --> 59:28.060\n having the best math score and the best English scores\n\n59:28.060 --> 59:29.640\n make me the best leader.\n\n59:29.640 --> 59:31.060\n And it turns out not to be that case.\n\n59:31.060 --> 59:34.340\n It's actually really wrong because making the,\n\n59:34.340 --> 59:35.820\n first of all, in terms of math scores,\n\n59:35.820 --> 59:37.620\n I think it's perfectly fine to hire somebody\n\n59:37.620 --> 59:38.500\n with great math skills.\n\n59:38.500 --> 59:40.620\n You don't have to do it yourself.\n\n59:40.620 --> 59:42.740\n You can hire someone with good empathy for you.\n\n59:42.740 --> 59:43.860\n That's much harder,\n\n59:43.860 --> 59:46.340\n but you can always hire someone with great math skills.\n\n59:46.340 --> 59:48.940\n But we live in an affluent world\n\n59:48.940 --> 59:51.000\n where we constantly deal with other people.\n\n59:51.000 --> 59:51.880\n And that's a beauty.\n\n59:51.880 --> 59:52.760\n It's not a nuisance.\n\n59:52.760 --> 59:53.600\n It's a beauty.\n\n59:53.600 --> 59:55.940\n So if we somehow develop that muscle\n\n59:55.940 --> 59:59.700\n that we can do that well and empower others\n\n59:59.700 --> 1:00:02.880\n in the workplace, I think we're gonna be super successful.\n\n1:00:02.880 --> 1:00:07.220\n And I know many fellow robot assistant computer scientists\n\n1:00:07.220 --> 1:00:09.820\n that I will insist to take this course.\n\n1:00:09.820 --> 1:00:12.180\n Not to be named here.\n\n1:00:12.180 --> 1:00:13.740\n Not to be named.\n\n1:00:13.740 --> 1:00:17.940\n Many, many years ago, 1903,\n\n1:00:17.940 --> 1:00:22.580\n the Wright brothers flew in Kitty Hawk for the first time.\n\n1:00:22.580 --> 1:00:26.940\n And you've launched a company of the same name, Kitty Hawk,\n\n1:00:26.940 --> 1:00:31.940\n with the dream of building flying cars, eVTOLs.\n\n1:00:32.300 --> 1:00:34.560\n So at the big picture,\n\n1:00:34.560 --> 1:00:36.620\n what are the big challenges of making this thing\n\n1:00:36.620 --> 1:00:39.980\n that actually have inspired generations of people\n\n1:00:39.980 --> 1:00:41.740\n about what the future looks like?\n\n1:00:41.740 --> 1:00:42.580\n What does it take?\n\n1:00:42.580 --> 1:00:43.660\n What are the biggest challenges?\n\n1:00:43.660 --> 1:00:47.220\n So flying cars has always been a dream.\n\n1:00:47.220 --> 1:00:49.700\n Every boy, every girl wants to fly.\n\n1:00:49.700 --> 1:00:50.540\n Let's be honest.\n\n1:00:50.540 --> 1:00:51.360\n Yes.\n\n1:00:51.360 --> 1:00:52.340\n And let's go back in our history\n\n1:00:52.340 --> 1:00:53.760\n of your dreaming of flying.\n\n1:00:53.760 --> 1:00:57.420\n I think honestly, my single most remembered childhood dream\n\n1:00:57.420 --> 1:00:59.420\n has been a dream where I was sitting on a pillow\n\n1:00:59.420 --> 1:01:00.740\n and I could fly.\n\n1:01:00.740 --> 1:01:02.020\n I was like five years old.\n\n1:01:02.020 --> 1:01:04.140\n I remember like maybe three dreams of my childhood,\n\n1:01:04.140 --> 1:01:06.400\n but that's the one I remember most vividly.\n\n1:01:07.540 --> 1:01:09.400\n And then Peter Thiel famously said,\n\n1:01:09.400 --> 1:01:10.660\n they promised us flying cars\n\n1:01:10.660 --> 1:01:14.460\n and they gave us 140 characters pointing as Twitter\n\n1:01:14.460 --> 1:01:18.380\n at the time, limited message size to 140 characters.\n\n1:01:18.380 --> 1:01:20.220\n So if you're coming back now to really go\n\n1:01:20.220 --> 1:01:23.220\n for these super impactful stuff like flying cars\n\n1:01:23.220 --> 1:01:25.900\n and to be precise, they're not really cars.\n\n1:01:25.900 --> 1:01:27.140\n They don't have wheels.\n\n1:01:27.140 --> 1:01:28.580\n They're actually much closer to a helicopter\n\n1:01:28.580 --> 1:01:29.640\n than anything else.\n\n1:01:29.640 --> 1:01:32.080\n They take off vertically and they fly horizontally,\n\n1:01:32.080 --> 1:01:34.380\n but they have important differences.\n\n1:01:34.380 --> 1:01:37.740\n One difference is that they are much quieter.\n\n1:01:37.740 --> 1:01:41.580\n We just released a vehicle called Project Heaviside\n\n1:01:41.580 --> 1:01:43.500\n that can fly over you as low as a helicopter\n\n1:01:43.500 --> 1:01:45.200\n and you basically can't hear.\n\n1:01:45.200 --> 1:01:46.700\n It's like 38 decibels.\n\n1:01:46.700 --> 1:01:49.240\n It's like, if you were inside the library,\n\n1:01:49.240 --> 1:01:50.220\n you might be able to hear it,\n\n1:01:50.220 --> 1:01:53.540\n but anywhere outdoors, your ambient noise is higher.\n\n1:01:53.540 --> 1:01:57.020\n Secondly, they're much more affordable.\n\n1:01:57.020 --> 1:01:58.980\n They're much more affordable than helicopters.\n\n1:01:58.980 --> 1:02:01.920\n And the reason is helicopters are expensive\n\n1:02:01.920 --> 1:02:03.020\n for many reasons.\n\n1:02:04.380 --> 1:02:06.980\n There's lots of single point of figures in a helicopter.\n\n1:02:06.980 --> 1:02:09.140\n There's a bolt between the blades\n\n1:02:09.140 --> 1:02:10.780\n that's caused Jesus bolt.\n\n1:02:10.780 --> 1:02:12.420\n And the reason why it's called Jesus bolt\n\n1:02:12.420 --> 1:02:16.380\n is that if this bolt breaks, you will die.\n\n1:02:16.380 --> 1:02:19.500\n There is no second solution in helicopter flight.\n\n1:02:19.500 --> 1:02:21.500\n Whereas we have these distributed mechanism.\n\n1:02:21.500 --> 1:02:23.740\n When you go from gasoline to electric,\n\n1:02:23.740 --> 1:02:25.820\n you can now have many, many, many small motors\n\n1:02:25.820 --> 1:02:27.260\n as opposed to one big motor.\n\n1:02:27.260 --> 1:02:28.780\n And that means if you lose one of those motors,\n\n1:02:28.780 --> 1:02:29.620\n not a big deal.\n\n1:02:29.620 --> 1:02:32.820\n Heaviside, if it loses a motor, has eight of those.\n\n1:02:32.820 --> 1:02:34.020\n If it loses one of those eight motors,\n\n1:02:34.020 --> 1:02:37.260\n so it's seven left, it can take off just like before\n\n1:02:37.260 --> 1:02:38.820\n and land just like before.\n\n1:02:40.100 --> 1:02:42.020\n We are now also moving into a technology\n\n1:02:42.020 --> 1:02:44.160\n that doesn't require a commercial pilot\n\n1:02:44.160 --> 1:02:45.500\n because in some level,\n\n1:02:45.500 --> 1:02:48.980\n flight is actually easier than ground transportation\n\n1:02:48.980 --> 1:02:50.740\n like in self driving cars.\n\n1:02:51.820 --> 1:02:54.500\n The world is full of like children and bicycles\n\n1:02:54.500 --> 1:02:57.580\n and other cars and mailboxes and curbs and shrubs\n\n1:02:57.580 --> 1:02:58.420\n and what have you.\n\n1:02:58.420 --> 1:03:00.500\n All these things you have to avoid.\n\n1:03:00.500 --> 1:03:03.740\n When you go above the buildings and tree lines,\n\n1:03:03.740 --> 1:03:04.620\n there's nothing there.\n\n1:03:04.620 --> 1:03:06.100\n I mean, you can do the test right now,\n\n1:03:06.100 --> 1:03:09.420\n look outside and count the number of things you see flying.\n\n1:03:09.420 --> 1:03:11.500\n I'd be shocked if you could see more than two things.\n\n1:03:11.500 --> 1:03:12.860\n It's probably just zero.\n\n1:03:13.860 --> 1:03:16.940\n In the Bay Area, the most I've ever seen was six.\n\n1:03:16.940 --> 1:03:18.820\n And maybe it's 15 or 20,\n\n1:03:18.820 --> 1:03:20.400\n but not 10,000.\n\n1:03:20.400 --> 1:03:24.000\n So the sky is very ample and very empty and very free.\n\n1:03:24.000 --> 1:03:27.820\n So the vision is, can we build a socially acceptable\n\n1:03:27.820 --> 1:03:32.360\n mass transit solution for daily transportation\n\n1:03:32.360 --> 1:03:34.280\n that is affordable?\n\n1:03:34.280 --> 1:03:36.340\n And we have an existence proof.\n\n1:03:36.340 --> 1:03:39.780\n Heaviside can fly 100 miles in range\n\n1:03:39.780 --> 1:03:43.260\n with still 30% electric reserves.\n\n1:03:43.260 --> 1:03:46.060\n It can fly up to like 180 miles an hour.\n\n1:03:46.060 --> 1:03:48.900\n We know that that solution at scale\n\n1:03:48.900 --> 1:03:51.420\n would make your ground transportation\n\n1:03:51.420 --> 1:03:53.820\n 10 times as fast as a car\n\n1:03:53.820 --> 1:03:57.580\n based on use census or statistics data,\n\n1:03:57.580 --> 1:04:00.900\n which means you would take your 300 hours of daily,\n\n1:04:00.900 --> 1:04:03.020\n of yearly commute down to 30 hours\n\n1:04:03.020 --> 1:04:05.180\n and give you 270 hours back.\n\n1:04:05.180 --> 1:04:07.700\n Who wouldn't want, I mean, who doesn't hate traffic?\n\n1:04:07.700 --> 1:04:10.820\n Like I hate, give me the person that doesn't hate traffic.\n\n1:04:10.820 --> 1:04:11.660\n I hate traffic.\n\n1:04:11.660 --> 1:04:13.900\n Every time I'm in traffic, I hate it.\n\n1:04:13.900 --> 1:04:17.580\n And if we could free the world from traffic,\n\n1:04:17.580 --> 1:04:18.460\n we have technology.\n\n1:04:18.460 --> 1:04:20.060\n We can free the world from traffic.\n\n1:04:20.060 --> 1:04:21.340\n We have the technology.\n\n1:04:21.340 --> 1:04:22.180\n It's there.\n\n1:04:22.180 --> 1:04:23.060\n We have an existence proof.\n\n1:04:23.060 --> 1:04:25.440\n It's not a technological problem anymore.\n\n1:04:25.440 --> 1:04:29.340\n Do you think there is a future where tens of thousands,\n\n1:04:29.340 --> 1:04:34.340\n maybe hundreds of thousands of both delivery drones\n\n1:04:34.380 --> 1:04:39.380\n and flying cars of this kind, EV talls fill the sky?\n\n1:04:39.940 --> 1:04:40.940\n I absolutely believe this.\n\n1:04:40.940 --> 1:04:43.860\n And there's obviously the societal acceptance\n\n1:04:43.860 --> 1:04:45.460\n is a major question.\n\n1:04:45.460 --> 1:04:46.940\n And of course, safety is.\n\n1:04:46.940 --> 1:04:48.060\n I believe in safety,\n\n1:04:48.060 --> 1:04:50.340\n we're gonna exceed ground transportation safety\n\n1:04:50.340 --> 1:04:54.500\n as has happened for aviation already, commercial aviation.\n\n1:04:54.500 --> 1:04:56.640\n And in terms of acceptance,\n\n1:04:56.640 --> 1:04:58.320\n I think one of the key things is noise.\n\n1:04:58.320 --> 1:05:00.980\n That's why we are focusing relentlessly on noise\n\n1:05:00.980 --> 1:05:05.660\n and we build perhaps the quietest electric vehicle\n\n1:05:05.660 --> 1:05:06.500\n ever built.\n\n1:05:07.640 --> 1:05:09.760\n The nice thing about the sky is it's three dimensional.\n\n1:05:09.760 --> 1:05:12.520\n So any mathematician will immediately recognize\n\n1:05:12.520 --> 1:05:14.980\n the difference between 1D of like a regular highway\n\n1:05:14.980 --> 1:05:16.260\n to 3D of a sky.\n\n1:05:17.320 --> 1:05:19.360\n But to make it clear for the layman,\n\n1:05:20.220 --> 1:05:22.740\n say you wanna make 100 vertical lanes\n\n1:05:22.740 --> 1:05:25.040\n of highway 101 in San Francisco,\n\n1:05:25.040 --> 1:05:27.220\n because you believe building 100 vertical lanes\n\n1:05:27.220 --> 1:05:28.900\n is the right solution.\n\n1:05:28.900 --> 1:05:31.780\n Imagine how much it would cost to stack 100 vertical lanes\n\n1:05:31.780 --> 1:05:33.420\n physically onto 101.\n\n1:05:33.420 --> 1:05:34.340\n That would be prohibitive.\n\n1:05:34.340 --> 1:05:37.780\n That would be consuming the world's GDP for an entire year\n\n1:05:37.780 --> 1:05:39.260\n just for one highway.\n\n1:05:39.260 --> 1:05:41.300\n It's amazingly expensive.\n\n1:05:41.300 --> 1:05:43.740\n In the sky, it would just be a recompilation\n\n1:05:43.740 --> 1:05:46.580\n of a piece of software because all these lanes are virtual.\n\n1:05:46.580 --> 1:05:49.260\n That means any vehicle that is in conflict\n\n1:05:49.260 --> 1:05:51.860\n with another vehicle would just go to different altitudes\n\n1:05:51.860 --> 1:05:53.340\n and then the conflict is gone.\n\n1:05:53.340 --> 1:05:55.380\n And if you don't believe this,\n\n1:05:55.380 --> 1:05:58.580\n that's exactly how commercial aviation works.\n\n1:05:58.580 --> 1:06:01.460\n When you fly from New York to San Francisco,\n\n1:06:01.460 --> 1:06:04.240\n another plane flies from San Francisco to New York,\n\n1:06:04.240 --> 1:06:05.300\n they are different altitudes.\n\n1:06:05.300 --> 1:06:06.740\n So they don't hit each other.\n\n1:06:06.740 --> 1:06:10.420\n It's a solved problem for the jet space\n\n1:06:10.420 --> 1:06:12.780\n and it will be a solved problem for the urban space.\n\n1:06:12.780 --> 1:06:15.380\n There's companies like Google Wing and Amazon\n\n1:06:15.380 --> 1:06:17.060\n working on very innovative solutions.\n\n1:06:17.060 --> 1:06:18.580\n How do we have space management?\n\n1:06:18.580 --> 1:06:21.660\n They use exactly the same principles as we use today\n\n1:06:21.660 --> 1:06:23.300\n to route today's jets.\n\n1:06:23.300 --> 1:06:25.000\n There's nothing hard about this.\n\n1:06:25.940 --> 1:06:29.040\n Do you envision autonomy being a key part of it\n\n1:06:29.040 --> 1:06:34.040\n so that the flying vehicles are either semi autonomous\n\n1:06:34.040 --> 1:06:36.920\n semi autonomous or fully autonomous?\n\n1:06:36.920 --> 1:06:37.880\n 100% autonomous.\n\n1:06:37.880 --> 1:06:40.480\n You don't want idiots like me flying in the sky,\n\n1:06:40.480 --> 1:06:41.960\n I promise you.\n\n1:06:41.960 --> 1:06:43.240\n And if you have 10,000,\n\n1:06:44.280 --> 1:06:46.040\n watch the movie, The Fifth Element\n\n1:06:46.040 --> 1:06:49.480\n to get a feel for what will happen if it's not autonomous.\n\n1:06:49.480 --> 1:06:51.720\n And a centralized, that's a really interesting idea\n\n1:06:51.720 --> 1:06:55.240\n of a centralized sort of management system\n\n1:06:55.240 --> 1:06:56.320\n for lanes and so on.\n\n1:06:56.320 --> 1:06:58.760\n So actually just being able to have\n\n1:07:00.280 --> 1:07:03.000\n similar as we have in the current commercial aviation,\n\n1:07:03.000 --> 1:07:05.560\n but scale it up to much, much more vehicles.\n\n1:07:05.560 --> 1:07:07.660\n That's a really interesting optimization problem.\n\n1:07:07.660 --> 1:07:11.080\n It is very mathematically, very, very straightforward.\n\n1:07:11.080 --> 1:07:13.520\n Like the gap we leave between jets is gargantuous.\n\n1:07:13.520 --> 1:07:16.400\n And part of the reason is there isn't that many jets.\n\n1:07:16.400 --> 1:07:18.800\n So it just feels like a good solution.\n\n1:07:18.800 --> 1:07:22.380\n Today, when you get vectored by air traffic control,\n\n1:07:22.380 --> 1:07:23.900\n someone talks to you, right?\n\n1:07:23.900 --> 1:07:26.960\n So any ATC controller might have up to maybe 20 planes\n\n1:07:26.960 --> 1:07:28.160\n on the same frequency.\n\n1:07:28.160 --> 1:07:30.360\n And then they talk to you, you have to talk back.\n\n1:07:30.360 --> 1:07:32.720\n And it feels right because there isn't more than 20 planes\n\n1:07:32.720 --> 1:07:34.960\n around anyhow, so you can talk to everybody.\n\n1:07:34.960 --> 1:07:36.760\n But if there's 20,000 things around,\n\n1:07:36.760 --> 1:07:37.980\n you can't talk to everybody anymore.\n\n1:07:37.980 --> 1:07:40.260\n So we have to do something that's called digital,\n\n1:07:40.260 --> 1:07:41.520\n like text messaging.\n\n1:07:41.520 --> 1:07:43.040\n Like we do have solutions.\n\n1:07:43.040 --> 1:07:45.560\n Like we have what, four or five billion smartphones\n\n1:07:45.560 --> 1:07:46.440\n in the world now, right?\n\n1:07:46.440 --> 1:07:47.720\n And they're all connected.\n\n1:07:47.720 --> 1:07:50.720\n And somehow we solve the scale problem for smartphones.\n\n1:07:50.720 --> 1:07:51.960\n We know where they all are.\n\n1:07:51.960 --> 1:07:54.880\n They can talk to somebody and they're very reliable.\n\n1:07:54.880 --> 1:07:56.460\n They're amazingly reliable.\n\n1:07:56.460 --> 1:07:58.640\n We could use the same system,\n\n1:07:58.640 --> 1:08:01.080\n the same scale for air traffic control.\n\n1:08:01.080 --> 1:08:04.080\n So instead of me as a pilot talking to a human being\n\n1:08:04.080 --> 1:08:06.280\n and in the middle of the conversation\n\n1:08:06.280 --> 1:08:09.660\n receiving a new frequency, like how ancient is that?\n\n1:08:09.660 --> 1:08:11.240\n We could digitize this stuff\n\n1:08:11.240 --> 1:08:15.240\n and digitally transmit the right flight coordinates.\n\n1:08:15.240 --> 1:08:18.060\n And that solution will automatically scale\n\n1:08:18.060 --> 1:08:20.040\n to 10,000 vehicles.\n\n1:08:20.040 --> 1:08:22.200\n We talked about empathy a little bit.\n\n1:08:22.200 --> 1:08:25.800\n Do you think we will one day build an AI system\n\n1:08:25.800 --> 1:08:27.580\n that a human being can love\n\n1:08:27.580 --> 1:08:31.320\n and that loves that human back, like in the movie, Her?\n\n1:08:31.320 --> 1:08:33.960\n Look, I'm a pragmatist.\n\n1:08:33.960 --> 1:08:35.600\n For me, AI is a tool.\n\n1:08:35.600 --> 1:08:36.920\n It's like a shovel.\n\n1:08:36.920 --> 1:08:40.800\n And the ethics of using the shovel are always\n\n1:08:40.800 --> 1:08:41.840\n with us, the people.\n\n1:08:41.840 --> 1:08:44.040\n And it has to be this way.\n\n1:08:44.040 --> 1:08:46.140\n In terms of emotions,\n\n1:08:47.160 --> 1:08:49.800\n I would hate to come into my kitchen\n\n1:08:49.800 --> 1:08:54.200\n and see that my refrigerator spoiled all my food,\n\n1:08:54.200 --> 1:08:55.280\n then have it explained to me\n\n1:08:55.280 --> 1:08:57.960\n that it fell in love with the dishwasher\n\n1:08:57.960 --> 1:08:59.680\n and it wasn't as nice as the dishwasher.\n\n1:08:59.680 --> 1:09:02.160\n So as a result, it neglected me.\n\n1:09:02.160 --> 1:09:05.120\n That would just be a bad experience\n\n1:09:05.120 --> 1:09:07.040\n and it would be a bad product.\n\n1:09:07.040 --> 1:09:09.520\n I would probably not recommend this refrigerator\n\n1:09:09.520 --> 1:09:10.460\n to my friends.\n\n1:09:11.720 --> 1:09:12.880\n And that's where I draw the line.\n\n1:09:12.880 --> 1:09:16.600\n I think to me, technology has to be reliable\n\n1:09:16.600 --> 1:09:17.680\n and has to be predictable.\n\n1:09:17.680 --> 1:09:19.840\n I want my car to work.\n\n1:09:19.840 --> 1:09:22.840\n I don't want to fall in love with my car.\n\n1:09:22.840 --> 1:09:24.560\n I just want it to work.\n\n1:09:24.560 --> 1:09:27.160\n I want it to compliment me, not to replace me.\n\n1:09:27.160 --> 1:09:30.640\n I have very unique human properties\n\n1:09:30.640 --> 1:09:33.420\n and I want the machines to make me,\n\n1:09:33.420 --> 1:09:35.680\n turn me into a superhuman.\n\n1:09:35.680 --> 1:09:37.800\n Like I'm already a superhuman today,\n\n1:09:37.800 --> 1:09:39.280\n thanks to the machines that surround me.\n\n1:09:39.280 --> 1:09:40.780\n And I give you examples.\n\n1:09:40.780 --> 1:09:44.160\n I can run across the Atlantic\n\n1:09:44.160 --> 1:09:48.480\n at near the speed of sound at 36,000 feet today.\n\n1:09:48.480 --> 1:09:49.560\n That's kind of amazing.\n\n1:09:49.560 --> 1:09:54.560\n I can, my voice now carries me all the way to Australia\n\n1:09:54.640 --> 1:09:56.600\n using a smartphone today.\n\n1:09:56.600 --> 1:10:00.060\n And it's not the speed of sound, which would take hours.\n\n1:10:00.060 --> 1:10:01.300\n It's the speed of light.\n\n1:10:01.300 --> 1:10:03.820\n My voice travels at the speed of light.\n\n1:10:03.820 --> 1:10:04.660\n How cool is that?\n\n1:10:04.660 --> 1:10:06.320\n That makes me superhuman.\n\n1:10:06.320 --> 1:10:10.520\n I would even argue my flushing toilet makes me superhuman.\n\n1:10:10.520 --> 1:10:13.800\n Just think of the time before flushing toilets.\n\n1:10:13.800 --> 1:10:16.460\n And maybe you have a very old person in your family\n\n1:10:16.460 --> 1:10:18.480\n that you can ask about this\n\n1:10:18.480 --> 1:10:22.160\n or take a trip to rural India to experience it.\n\n1:10:23.400 --> 1:10:25.840\n It makes me superhuman.\n\n1:10:25.840 --> 1:10:28.900\n So to me, what technology does, it compliments me.\n\n1:10:28.900 --> 1:10:30.920\n It makes me stronger.\n\n1:10:30.920 --> 1:10:33.520\n Therefore, words like love and compassion\n\n1:10:33.520 --> 1:10:38.520\n have very little interest in this for machines.\n\n1:10:38.640 --> 1:10:40.720\n I have interest in people.\n\n1:10:40.720 --> 1:10:44.280\n You don't think, first of all, beautifully put,\n\n1:10:44.280 --> 1:10:45.680\n beautifully argued,\n\n1:10:45.680 --> 1:10:49.520\n but do you think love has use in our tools?\n\n1:10:49.520 --> 1:10:50.440\n Compassion.\n\n1:10:50.440 --> 1:10:53.280\n I think love is a beautiful human concept.\n\n1:10:53.280 --> 1:10:55.420\n And if you think of what love really is,\n\n1:10:55.420 --> 1:11:00.420\n love is a means to convey safety, to convey trust.\n\n1:11:03.240 --> 1:11:07.440\n I think trust has a huge need in technology as well,\n\n1:11:07.440 --> 1:11:09.160\n not just people.\n\n1:11:09.160 --> 1:11:12.600\n We want to trust our technology the same way,\n\n1:11:12.600 --> 1:11:15.960\n in a similar way we trust people.\n\n1:11:15.960 --> 1:11:19.360\n In human interaction, standards have emerged\n\n1:11:19.360 --> 1:11:21.760\n and feelings, emotions have emerged,\n\n1:11:21.760 --> 1:11:23.920\n maybe genetically, maybe biologically,\n\n1:11:23.920 --> 1:11:26.560\n that are able to convey sense of trust, sense of safety,\n\n1:11:26.560 --> 1:11:28.880\n sense of passion, of love, of dedication\n\n1:11:28.880 --> 1:11:30.800\n that makes the human fabric.\n\n1:11:30.800 --> 1:11:33.740\n And I'm a big slacker for love.\n\n1:11:33.740 --> 1:11:34.600\n I want to be loved.\n\n1:11:34.600 --> 1:11:35.440\n I want to be trusted.\n\n1:11:35.440 --> 1:11:36.880\n I want to be admired.\n\n1:11:36.880 --> 1:11:38.880\n All these wonderful things.\n\n1:11:38.880 --> 1:11:42.200\n And because all of us, we have this beautiful system,\n\n1:11:42.200 --> 1:11:44.840\n I wouldn't just blindly copy this to the machines.\n\n1:11:44.840 --> 1:11:46.200\n Here's why.\n\n1:11:46.200 --> 1:11:49.360\n When you look at, say, transportation,\n\n1:11:49.360 --> 1:11:53.320\n you could have observed that up to the end\n\n1:11:53.320 --> 1:11:57.120\n of the 19th century, almost all transportation used\n\n1:11:57.120 --> 1:11:59.820\n any number of legs, from one leg to two legs\n\n1:11:59.820 --> 1:12:01.720\n to a thousand legs.\n\n1:12:01.720 --> 1:12:03.840\n And you could have concluded that is the right way\n\n1:12:03.840 --> 1:12:05.660\n to move about the environment.\n\n1:12:06.800 --> 1:12:08.080\n We've been made the exception of birds\n\n1:12:08.080 --> 1:12:08.960\n who use flapping wings.\n\n1:12:08.960 --> 1:12:10.880\n In fact, there are many people in aviation\n\n1:12:10.880 --> 1:12:13.720\n that flap wings to their arms and jump from cliffs.\n\n1:12:13.720 --> 1:12:15.120\n Most of them didn't survive.\n\n1:12:16.920 --> 1:12:19.880\n Then the interesting thing is that the technology solutions\n\n1:12:19.880 --> 1:12:21.600\n are very different.\n\n1:12:21.600 --> 1:12:23.880\n Like in technology, it's really easy to build a wheel.\n\n1:12:23.880 --> 1:12:25.680\n In biology, it's super hard to build a wheel.\n\n1:12:25.680 --> 1:12:30.080\n There's very few perpetually rotating things in biology\n\n1:12:30.080 --> 1:12:34.180\n and they usually run cells and things.\n\n1:12:34.180 --> 1:12:37.200\n In engineering, we can build wheels.\n\n1:12:37.200 --> 1:12:41.020\n And those wheels gave rise to cars.\n\n1:12:41.020 --> 1:12:44.360\n Similar wheels gave rise to aviation.\n\n1:12:44.360 --> 1:12:46.680\n Like there's no thing that flies\n\n1:12:46.680 --> 1:12:48.840\n that wouldn't have something that rotates,\n\n1:12:48.840 --> 1:12:52.400\n like a jet engine or helicopter blades.\n\n1:12:52.400 --> 1:12:55.520\n So the solutions have used very different physical laws\n\n1:12:55.520 --> 1:12:58.040\n than nature, and that's great.\n\n1:12:58.040 --> 1:13:00.080\n So for me to be too much focused on,\n\n1:13:00.080 --> 1:13:03.340\n oh, this is how nature does it, let's just replicate it.\n\n1:13:03.340 --> 1:13:05.400\n If you really believed that the solution\n\n1:13:05.400 --> 1:13:08.720\n to the agricultural evolution was a humanoid robot,\n\n1:13:08.720 --> 1:13:10.920\n you would still be waiting today.\n\n1:13:10.920 --> 1:13:12.520\n Again, beautifully put.\n\n1:13:12.520 --> 1:13:15.920\n You said that you don't take yourself too seriously.\n\n1:13:15.920 --> 1:13:16.760\n Did I say that?\n\n1:13:18.160 --> 1:13:19.160\n You want me to say that?\n\n1:13:19.160 --> 1:13:20.000\n Maybe.\n\n1:13:20.000 --> 1:13:20.960\n You're not taking me seriously.\n\n1:13:20.960 --> 1:13:22.880\n I'm not, that's right.\n\n1:13:22.880 --> 1:13:24.480\n Good, you're right, I don't wanna.\n\n1:13:24.480 --> 1:13:25.720\n I just made that up.\n\n1:13:25.720 --> 1:13:29.120\n But you have a humor and a lightness about life\n\n1:13:29.120 --> 1:13:33.520\n that I think is beautiful and inspiring to a lot of people.\n\n1:13:33.520 --> 1:13:35.040\n Where does that come from?\n\n1:13:35.040 --> 1:13:38.400\n The smile, the humor, the lightness\n\n1:13:38.400 --> 1:13:42.600\n amidst all the chaos of the hard work that you're in,\n\n1:13:42.600 --> 1:13:43.640\n where does that come from?\n\n1:13:43.640 --> 1:13:44.560\n I just love my life.\n\n1:13:44.560 --> 1:13:46.120\n I love the people around me.\n\n1:13:47.520 --> 1:13:49.740\n I'm just so glad to be alive.\n\n1:13:49.740 --> 1:13:53.640\n Like I'm, what, 52, hard to believe.\n\n1:13:53.640 --> 1:13:56.260\n People say 52 is a new 51, so now I feel better.\n\n1:13:56.260 --> 1:14:01.260\n But in looking around the world,\n\n1:14:01.260 --> 1:14:05.180\n looking around the world, just go back 200, 300 years.\n\n1:14:06.180 --> 1:14:09.360\n Humanity is, what, 300,000 years old?\n\n1:14:09.360 --> 1:14:13.980\n But for the first 300,000 years minus the last 100,\n\n1:14:13.980 --> 1:14:17.060\n our life expectancy would have been\n\n1:14:17.060 --> 1:14:20.260\n plus or minus 30 years roughly, give or take.\n\n1:14:20.260 --> 1:14:22.660\n So I would be long dead now.\n\n1:14:24.360 --> 1:14:26.840\n That makes me just enjoy every single day of my life\n\n1:14:26.840 --> 1:14:28.260\n because I don't deserve this.\n\n1:14:28.260 --> 1:14:32.460\n Why am I born today when so many of my ancestors\n\n1:14:32.460 --> 1:14:37.460\n died of horrible deaths, like famines, massive wars\n\n1:14:38.820 --> 1:14:41.860\n that ravaged Europe for the last 1,000 years\n\n1:14:41.860 --> 1:14:44.520\n mystically disappeared after World War II\n\n1:14:44.520 --> 1:14:46.540\n when the Americans and the Allies\n\n1:14:46.540 --> 1:14:48.300\n did something amazing to my country\n\n1:14:48.300 --> 1:14:51.460\n that didn't deserve it, the country of Germany.\n\n1:14:51.460 --> 1:14:52.620\n This is so amazing.\n\n1:14:52.620 --> 1:14:56.960\n And then when you're alive and feel this every day,\n\n1:14:56.960 --> 1:15:01.960\n then it's just so amazing what we can accomplish,\n\n1:15:02.020 --> 1:15:03.500\n what we can do.\n\n1:15:03.500 --> 1:15:06.380\n We live in a world that is so incredibly,\n\n1:15:06.380 --> 1:15:08.720\n vastly changing every day.\n\n1:15:08.720 --> 1:15:12.900\n Almost everything that we cherish from your smartphone\n\n1:15:12.900 --> 1:15:16.220\n to your flushing toilet, to all these basic inventions,\n\n1:15:16.220 --> 1:15:19.620\n your new clothes you're wearing, your watch, your plane,\n\n1:15:19.620 --> 1:15:24.620\n penicillin, I don't know, anesthesia for surgery,\n\n1:15:24.620 --> 1:15:29.060\n penicillin have been invented in the last 150 years.\n\n1:15:29.060 --> 1:15:31.420\n So in the last 150 years, something magical happened.\n\n1:15:31.420 --> 1:15:33.380\n And I would trace it back to Gutenberg\n\n1:15:33.380 --> 1:15:34.980\n and the printing press that has been able\n\n1:15:34.980 --> 1:15:37.860\n to disseminate information more efficiently than before\n\n1:15:37.860 --> 1:15:41.860\n that all of a sudden we were able to invent agriculture\n\n1:15:41.860 --> 1:15:44.940\n and nitrogen fertilization that made agriculture\n\n1:15:44.940 --> 1:15:47.100\n so much more potent that we didn't have to work\n\n1:15:47.100 --> 1:15:49.180\n in the farms anymore and we could start reading and writing\n\n1:15:49.180 --> 1:15:51.340\n and we could become all these wonderful things\n\n1:15:51.340 --> 1:15:53.860\n we are today, from airline pilot to massage therapist\n\n1:15:53.860 --> 1:15:56.300\n to software engineer.\n\n1:15:56.300 --> 1:15:57.140\n It's just amazing.\n\n1:15:57.140 --> 1:16:00.180\n Like living in that time is such a blessing.\n\n1:16:00.180 --> 1:16:03.940\n We should sometimes really think about this, right?\n\n1:16:03.940 --> 1:16:06.860\n Steven Pinker, who is a very famous author and philosopher\n\n1:16:06.860 --> 1:16:08.980\n whom I really adore, wrote a great book called\n\n1:16:08.980 --> 1:16:09.820\n Enlightenment Now.\n\n1:16:09.820 --> 1:16:11.420\n And that's maybe the one book I would recommend.\n\n1:16:11.420 --> 1:16:13.020\n And he asks the question,\n\n1:16:13.020 --> 1:16:15.180\n if there was only a single article written\n\n1:16:15.180 --> 1:16:18.580\n in the 20th century, it's only one article, what would it be?\n\n1:16:18.580 --> 1:16:20.620\n What's the most important innovation,\n\n1:16:20.620 --> 1:16:22.580\n the most important thing that happened?\n\n1:16:22.580 --> 1:16:24.700\n And he would say this article would credit\n\n1:16:24.700 --> 1:16:27.020\n a guy named Karl Bosch.\n\n1:16:27.020 --> 1:16:29.460\n And I challenge anybody, have you ever heard\n\n1:16:29.460 --> 1:16:31.180\n of the name Karl Foch?\n\n1:16:31.180 --> 1:16:32.940\n I hadn't, okay.\n\n1:16:32.940 --> 1:16:35.420\n There's a Bosch Corporation in Germany,\n\n1:16:35.420 --> 1:16:37.420\n but it's not associated with Karl Bosch.\n\n1:16:38.420 --> 1:16:39.860\n So I looked it up.\n\n1:16:39.860 --> 1:16:42.660\n Karl Bosch invented nitrogen fertilization.\n\n1:16:42.660 --> 1:16:45.580\n And in doing so, together with an older invention\n\n1:16:45.580 --> 1:16:49.220\n of irrigation, was able to increase the yields\n\n1:16:49.220 --> 1:16:52.860\n per agricultural land by a factor of 26.\n\n1:16:52.860 --> 1:16:57.700\n So a 2,500% increase in fertility of land.\n\n1:16:57.700 --> 1:17:00.540\n And that, so Steve Pinker argues,\n\n1:17:00.540 --> 1:17:03.900\n saved over 2 billion lives today.\n\n1:17:03.900 --> 1:17:05.700\n 2 billion people who would be dead\n\n1:17:05.700 --> 1:17:08.420\n if this man hadn't done what he had done, okay?\n\n1:17:08.420 --> 1:17:12.180\n Think about that impact and what that means to society.\n\n1:17:12.180 --> 1:17:14.180\n That's the way I look at the world.\n\n1:17:14.180 --> 1:17:16.940\n I mean, it's so amazing to be alive and to be part of this.\n\n1:17:16.940 --> 1:17:20.300\n And I'm so glad I lived after Karl Bosch and not before.\n\n1:17:21.300 --> 1:17:23.980\n I don't think there's a better way to end this, Sebastian.\n\n1:17:23.980 --> 1:17:25.460\n It's an honor to talk to you,\n\n1:17:25.460 --> 1:17:27.340\n to have had the chance to learn from you.\n\n1:17:27.340 --> 1:17:28.300\n Thank you so much for talking to me.\n\n1:17:28.300 --> 1:17:29.140\n Thanks for coming out.\n\n1:17:29.140 --> 1:17:30.980\n It's been a real pleasure.\n\n1:17:30.980 --> 1:17:32.780\n Thank you for listening to this conversation\n\n1:17:32.780 --> 1:17:34.380\n with Sebastian Thrun.\n\n1:17:34.380 --> 1:17:37.460\n And thank you to our presenting sponsor, Cash App.\n\n1:17:37.460 --> 1:17:40.220\n Download it, use code LexPodcast,\n\n1:17:40.220 --> 1:17:43.220\n you'll get $10 and $10 will go to FIRST,\n\n1:17:43.220 --> 1:17:45.500\n a STEM education nonprofit that inspires\n\n1:17:45.500 --> 1:17:47.460\n hundreds of thousands of young minds\n\n1:17:47.460 --> 1:17:50.540\n to learn and to dream of engineering our future.\n\n1:17:50.540 --> 1:17:53.340\n If you enjoy this podcast, subscribe on YouTube,\n\n1:17:53.340 --> 1:17:56.620\n get five stars on Apple Podcast, support it on Patreon,\n\n1:17:56.620 --> 1:17:58.860\n or connect with me on Twitter.\n\n1:17:58.860 --> 1:18:01.260\n And now, let me leave you with some words of wisdom\n\n1:18:01.260 --> 1:18:03.260\n from Sebastian Thrun.\n\n1:18:03.260 --> 1:18:05.420\n It's important to celebrate your failures\n\n1:18:05.420 --> 1:18:07.700\n as much as your successes.\n\n1:18:07.700 --> 1:18:09.780\n If you celebrate your failures really well,\n\n1:18:09.780 --> 1:18:13.900\n if you say, wow, I failed, I tried, I was wrong,\n\n1:18:13.900 --> 1:18:18.260\n but I learned something, then you realize you have no fear.\n\n1:18:18.260 --> 1:18:22.460\n And when your fear goes away, you can move the world.\n\n1:18:22.460 --> 1:18:44.580\n Thank you for listening and hope to see you next time.\n\n"
}
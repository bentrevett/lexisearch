{
  "title": "Eric Schmidt: Google | Lex Fridman Podcast #8",
  "id": "hIC9FQpxVwQ",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:03.180\n The following is a conversation with Eric Schmidt.\n\n00:03.180 --> 00:05.140\n He was the CEO of Google for 10 years\n\n00:05.140 --> 00:06.780\n and a chairman for six more,\n\n00:06.780 --> 00:10.100\n guiding the company through an incredible period of growth\n\n00:10.100 --> 00:12.940\n and a series of world changing innovations.\n\n00:12.940 --> 00:15.300\n He is one of the most impactful leaders\n\n00:15.300 --> 00:19.340\n in the era of the internet and the powerful voice\n\n00:19.340 --> 00:22.300\n for the promise of technology in our society.\n\n00:22.300 --> 00:24.780\n It was truly an honor to speak with him\n\n00:24.780 --> 00:26.900\n as part of the MIT course\n\n00:26.900 --> 00:28.660\n on artificial general intelligence\n\n00:28.660 --> 00:31.900\n and the artificial intelligence podcast.\n\n00:31.900 --> 00:36.120\n And now here's my conversation with Eric Schmidt.\n\n00:37.020 --> 00:38.020\n What was the first moment\n\n00:38.020 --> 00:40.000\n when you fell in love with technology?\n\n00:40.900 --> 00:44.380\n I grew up in the 1960s as a boy\n\n00:44.380 --> 00:46.820\n where every boy wanted to be an astronaut\n\n00:46.820 --> 00:48.900\n and part of the space program.\n\n00:48.900 --> 00:51.340\n So like everyone else of my age,\n\n00:51.340 --> 00:54.340\n we would go out to the cow pasture behind my house,\n\n00:54.340 --> 00:56.260\n which was literally a cow pasture\n\n00:56.260 --> 00:58.540\n and we would shoot model rockets off.\n\n00:58.540 --> 01:00.820\n And that I think is the beginning.\n\n01:00.820 --> 01:03.540\n And of course, generationally today,\n\n01:03.540 --> 01:05.760\n it would be video games and all the amazing things\n\n01:05.760 --> 01:08.180\n that you can do online with computers.\n\n01:09.100 --> 01:12.620\n There's a transformative, inspiring aspect of science\n\n01:12.620 --> 01:15.740\n and math that maybe rockets would bring\n\n01:15.740 --> 01:17.420\n would instill in individuals.\n\n01:17.420 --> 01:20.140\n You've mentioned yesterday that eighth grade math\n\n01:20.140 --> 01:22.180\n is where the journey through mathematical universe\n\n01:22.180 --> 01:23.780\n diverges from many people.\n\n01:23.780 --> 01:26.900\n It's this fork in the roadway.\n\n01:26.900 --> 01:30.260\n There's a professor of math at Berkeley, Edward Frankel.\n\n01:30.260 --> 01:32.460\n He, I'm not sure if you're familiar with him.\n\n01:32.460 --> 01:33.300\n I am.\n\n01:33.300 --> 01:35.420\n He has written this amazing book\n\n01:35.420 --> 01:37.700\n I recommend to everybody called Love and Math.\n\n01:37.700 --> 01:39.880\n Two of my favorite words.\n\n01:41.460 --> 01:46.460\n He says that if painting was taught like math,\n\n01:46.700 --> 01:49.620\n then the students would be asked to paint a fence,\n\n01:49.620 --> 01:52.540\n which is his analogy of essentially how math is taught.\n\n01:52.540 --> 01:55.860\n And so you never get a chance to discover the beauty\n\n01:55.860 --> 01:59.260\n of the art of painting or the beauty of the art of math.\n\n01:59.260 --> 02:03.860\n So how, when, and where did you discover that beauty?\n\n02:05.260 --> 02:08.040\n I think what happens with people like myself\n\n02:08.040 --> 02:11.380\n is that your math enabled pretty early\n\n02:11.380 --> 02:14.320\n and all of a sudden you discover that you can use that\n\n02:14.320 --> 02:16.560\n to discover new insights.\n\n02:16.560 --> 02:19.100\n The great scientists will all tell a story,\n\n02:19.100 --> 02:22.020\n the men and women who are fantastic today,\n\n02:22.020 --> 02:24.600\n that somewhere when they were in high school or in college,\n\n02:24.600 --> 02:26.060\n they discovered that they could discover\n\n02:26.060 --> 02:27.780\n something themselves.\n\n02:27.780 --> 02:29.860\n And that sense of building something,\n\n02:29.860 --> 02:32.260\n of having an impact that you own,\n\n02:32.260 --> 02:35.460\n drives knowledge acquisition and learning.\n\n02:35.460 --> 02:37.020\n In my case, it was programming.\n\n02:37.020 --> 02:39.820\n And the notion that I could build things\n\n02:39.820 --> 02:42.300\n that had not existed that I had built,\n\n02:42.300 --> 02:44.400\n that it had my name on it.\n\n02:44.400 --> 02:46.160\n And this was before open source,\n\n02:46.160 --> 02:49.100\n but you could think of it as open source contributions.\n\n02:49.100 --> 02:51.780\n So today, if I were a 16 or 17 year old boy,\n\n02:51.780 --> 02:54.660\n I'm sure that I would aspire as a computer scientist\n\n02:54.660 --> 02:58.060\n to make a contribution like the open source heroes\n\n02:58.060 --> 02:58.920\n of the world today.\n\n02:58.920 --> 03:00.380\n That would be what would be driving me.\n\n03:00.380 --> 03:03.700\n And I'd be trying and learning and making mistakes\n\n03:03.700 --> 03:06.620\n and so forth in the ways that it works.\n\n03:06.620 --> 03:09.940\n The repository that GitHub represents\n\n03:09.940 --> 03:12.200\n and that open source libraries represent\n\n03:12.200 --> 03:14.900\n is an enormous bank of knowledge\n\n03:14.900 --> 03:17.100\n of all of the people who are doing that.\n\n03:17.100 --> 03:19.540\n And one of the lessons that I learned at Google\n\n03:19.540 --> 03:21.500\n was that the world is a very big place\n\n03:21.500 --> 03:23.540\n and there's an awful lot of smart people.\n\n03:23.540 --> 03:26.300\n And an awful lot of them are underutilized.\n\n03:26.300 --> 03:28.940\n So here's an opportunity, for example,\n\n03:28.940 --> 03:31.700\n building parts of programs, building new ideas\n\n03:31.700 --> 03:33.840\n to contribute to the greater of society.\n\n03:36.540 --> 03:38.340\n So in that moment in the 70s,\n\n03:38.340 --> 03:40.660\n the inspiring moment where there was nothing\n\n03:40.660 --> 03:42.820\n and then you created something through programming,\n\n03:42.820 --> 03:44.720\n that magical moment.\n\n03:44.720 --> 03:49.180\n So in 1975, I think you've created a program called Lex,\n\n03:49.180 --> 03:51.460\n which I especially like because my name is Lex.\n\n03:51.460 --> 03:54.620\n So thank you, thank you for creating a brand\n\n03:54.620 --> 03:58.260\n that established a reputation that's long lasting, reliable\n\n03:58.260 --> 04:01.180\n and has a big impact on the world and still used today.\n\n04:01.180 --> 04:02.820\n So thank you for that.\n\n04:02.820 --> 04:07.820\n But more seriously, in that time, in the 70s,\n\n04:08.220 --> 04:11.180\n as an engineer, personal computers were being born.\n\n04:12.540 --> 04:15.580\n Do you think you'd be able to predict the 80s, 90s\n\n04:15.580 --> 04:18.900\n and the aughts of where computers would go?\n\n04:18.900 --> 04:22.120\n I'm sure I could not and would not have gotten it right.\n\n04:23.180 --> 04:25.420\n I was the beneficiary of the great work\n\n04:25.420 --> 04:29.060\n of many, many people who saw it clearer than I did.\n\n04:29.060 --> 04:32.540\n With Lex, I worked with a fellow named Michael Lesk,\n\n04:32.540 --> 04:33.980\n who was my supervisor.\n\n04:33.980 --> 04:36.300\n And he essentially helped me architect\n\n04:36.300 --> 04:39.180\n and deliver a system that's still in use today.\n\n04:39.180 --> 04:42.220\n After that, I worked at Xerox Palo Alto Research Center,\n\n04:42.220 --> 04:43.660\n where the Alto was invented.\n\n04:43.660 --> 04:46.060\n And the Alto is the predecessor\n\n04:46.060 --> 04:50.180\n of the modern personal computer or Macintosh and so forth.\n\n04:50.180 --> 04:52.300\n And the Altos were very rare.\n\n04:52.300 --> 04:55.260\n And I had to drive an hour from Berkeley to go use them.\n\n04:55.260 --> 04:57.380\n But I made a point of skipping classes\n\n04:57.380 --> 05:00.960\n and doing whatever it took to have access\n\n05:00.960 --> 05:02.500\n to this extraordinary achievement.\n\n05:02.500 --> 05:04.900\n I knew that they were consequential.\n\n05:04.900 --> 05:08.260\n What I did not understand was scaling.\n\n05:08.260 --> 05:09.860\n I did not understand what would happen\n\n05:09.860 --> 05:12.820\n when you had 100 million as opposed to 100.\n\n05:12.820 --> 05:14.200\n And so the, since then,\n\n05:14.200 --> 05:16.260\n and I have learned the benefit of scale,\n\n05:16.260 --> 05:17.460\n I always look for things\n\n05:17.460 --> 05:19.660\n which are going to scale to platforms, right?\n\n05:19.660 --> 05:23.060\n So mobile phones, Android, all those things.\n\n05:23.060 --> 05:25.820\n There are, the world is in numerous,\n\n05:25.820 --> 05:27.380\n there are many, many people in the world,\n\n05:27.380 --> 05:28.500\n people really have needs.\n\n05:28.500 --> 05:29.940\n They really will use these platforms\n\n05:29.940 --> 05:32.560\n and you can build big businesses on top of them.\n\n05:32.560 --> 05:33.400\n So it's interesting.\n\n05:33.400 --> 05:34.860\n So when you see a piece of technology,\n\n05:34.860 --> 05:37.300\n now you think, what will this technology look like\n\n05:37.300 --> 05:39.020\n when it's in the hands of a billion people?\n\n05:39.020 --> 05:39.900\n That's right.\n\n05:39.900 --> 05:44.900\n So an example would be that the market is so competitive now\n\n05:44.940 --> 05:46.940\n that if you can't figure out a way\n\n05:46.940 --> 05:50.780\n for something to have a million users or a billion users,\n\n05:50.780 --> 05:53.100\n it probably is not going to be successful\n\n05:53.100 --> 05:56.820\n because something else will become the general platform\n\n05:56.820 --> 06:01.060\n and your idea will become a lost idea\n\n06:01.060 --> 06:04.260\n or a specialized service with relatively few users.\n\n06:04.260 --> 06:05.900\n So it's a path to generality.\n\n06:05.900 --> 06:07.660\n It's a path to general platform use.\n\n06:07.660 --> 06:10.060\n It's a path to broad applicability.\n\n06:10.060 --> 06:12.660\n Now there are plenty of good businesses that are tiny.\n\n06:12.660 --> 06:14.900\n So luxury goods, for example.\n\n06:14.900 --> 06:18.500\n But if you want to have an impact at scale,\n\n06:18.500 --> 06:21.340\n you have to look for things which are of common value,\n\n06:21.340 --> 06:23.300\n common pricing, common distribution\n\n06:23.300 --> 06:24.740\n and solve common problems.\n\n06:24.740 --> 06:26.140\n They're problems that everyone has.\n\n06:26.140 --> 06:28.100\n And by the way, people have lots of problems.\n\n06:28.100 --> 06:31.140\n Information, medicine, health, education and so forth.\n\n06:31.140 --> 06:32.940\n Work on those problems.\n\n06:32.940 --> 06:36.780\n Like you said, you're a big fan of the middle class.\n\n06:36.780 --> 06:37.820\n Because there's so many of them.\n\n06:37.820 --> 06:38.740\n There's so many of them.\n\n06:38.740 --> 06:40.140\n By definition.\n\n06:40.140 --> 06:44.380\n So any product, any thing that has a huge impact\n\n06:44.380 --> 06:47.460\n and improves their lives is a great business decision\n\n06:47.460 --> 06:48.860\n and it's just good for society.\n\n06:48.860 --> 06:52.340\n And there's nothing wrong with starting off in the high end\n\n06:52.340 --> 06:55.420\n as long as you have a plan to get to the middle class.\n\n06:55.420 --> 06:57.580\n There's nothing wrong with starting with a specialized\n\n06:57.580 --> 07:01.020\n market in order to learn and to build and to fund things.\n\n07:01.020 --> 07:02.540\n So you start with a luxury market\n\n07:02.540 --> 07:04.460\n to build a general purpose market.\n\n07:04.460 --> 07:07.500\n But if you define yourself as only a narrow market,\n\n07:07.500 --> 07:10.940\n someone else can come along with a general purpose market\n\n07:10.940 --> 07:12.340\n that can push you to the corner,\n\n07:12.340 --> 07:14.260\n can restrict the scale of operation,\n\n07:14.260 --> 07:17.820\n can force you to be a lesser impact than you might be.\n\n07:17.820 --> 07:21.020\n So it's very important to think in terms of broad businesses\n\n07:21.020 --> 07:22.340\n and broad impact.\n\n07:22.340 --> 07:24.980\n Even if you start in a little corner somewhere.\n\n07:26.260 --> 07:30.980\n So as you look to the 70s but also in the decades to come\n\n07:30.980 --> 07:34.860\n and you saw computers, did you see them as tools\n\n07:34.860 --> 07:39.860\n or was there a little element of another entity?\n\n07:40.260 --> 07:44.660\n I remember a quote saying AI began with our dream\n\n07:44.660 --> 07:46.140\n to create the gods.\n\n07:46.140 --> 07:48.620\n Is there a feeling when you wrote that program\n\n07:48.620 --> 07:51.300\n that you were creating another entity,\n\n07:51.300 --> 07:52.820\n giving life to something?\n\n07:52.820 --> 07:54.660\n I wish I could say otherwise,\n\n07:54.660 --> 07:58.740\n but I simply found the technology platforms so exciting.\n\n07:58.740 --> 08:00.460\n That's what I was focused on.\n\n08:00.460 --> 08:03.380\n I think the majority of the people that I've worked with,\n\n08:03.380 --> 08:06.700\n and there are a few exceptions, Steve Jobs being an example,\n\n08:06.700 --> 08:09.980\n really saw this as a great technological play.\n\n08:09.980 --> 08:13.700\n I think relatively few of the technical people understood\n\n08:13.700 --> 08:15.380\n the scale of its impact.\n\n08:15.380 --> 08:19.620\n So I used NCP, which is a predecessor to TCPIP.\n\n08:19.620 --> 08:21.180\n It just made sense to connect things.\n\n08:21.180 --> 08:23.780\n We didn't think of it in terms of the internet\n\n08:23.780 --> 08:27.020\n and then companies and then Facebook and then Twitter\n\n08:27.020 --> 08:29.180\n and then politics and so forth.\n\n08:29.180 --> 08:30.740\n We never did that build.\n\n08:30.740 --> 08:32.860\n We didn't have that vision.\n\n08:32.860 --> 08:35.300\n And I think most people, it's a rare person\n\n08:35.300 --> 08:38.020\n who can see compounding at scale.\n\n08:38.020 --> 08:39.060\n Most people can see,\n\n08:39.060 --> 08:40.580\n if you ask people to predict the future,\n\n08:40.580 --> 08:43.060\n they'll give you an answer of six to nine months\n\n08:43.060 --> 08:44.500\n or 12 months,\n\n08:44.500 --> 08:47.500\n because that's about as far as people can imagine.\n\n08:47.500 --> 08:48.700\n But there's an old saying,\n\n08:48.700 --> 08:50.860\n which actually was attributed to a professor at MIT\n\n08:50.860 --> 08:52.060\n a long time ago,\n\n08:52.060 --> 08:56.380\n that we overestimate what can be done in one year\n\n08:56.380 --> 09:00.100\n and we underestimate what can be done in a decade.\n\n09:00.100 --> 09:02.460\n And there's a great deal of evidence\n\n09:02.460 --> 09:05.580\n that these core platforms at hardware and software\n\n09:05.580 --> 09:07.740\n take a decade, right?\n\n09:07.740 --> 09:09.420\n So think about self driving cars.\n\n09:09.420 --> 09:12.100\n Self driving cars were thought about in the 90s.\n\n09:12.100 --> 09:13.340\n There were projects around them.\n\n09:13.340 --> 09:17.100\n The first DARPA Grand Challenge was roughly 2004.\n\n09:17.100 --> 09:19.700\n So that's roughly 15 years ago.\n\n09:19.700 --> 09:22.060\n And today we have self driving cars operating\n\n09:22.060 --> 09:23.940\n in a city in Arizona, right?\n\n09:23.940 --> 09:26.620\n It's 15 years and we still have a ways to go\n\n09:26.620 --> 09:28.620\n before they're more generally available.\n\n09:31.620 --> 09:33.780\n So you've spoken about the importance,\n\n09:33.780 --> 09:37.100\n you just talked about predicting into the future.\n\n09:37.100 --> 09:39.940\n You've spoken about the importance of thinking\n\n09:39.940 --> 09:42.860\n five years ahead and having a plan for those five years.\n\n09:42.860 --> 09:45.980\n The way to say it is that almost everybody\n\n09:45.980 --> 09:47.500\n has a one year plan.\n\n09:47.500 --> 09:50.940\n Almost no one has a proper five year plan.\n\n09:50.940 --> 09:52.780\n And the key thing to having a five year plan\n\n09:52.780 --> 09:55.260\n is to having a model for what's going to happen\n\n09:55.260 --> 09:56.900\n under the underlying platforms.\n\n09:56.900 --> 09:58.180\n So here's an example.\n\n09:59.980 --> 10:01.140\n Moore's Law as we know it,\n\n10:01.140 --> 10:04.260\n the thing that powered improvements in CPUs\n\n10:04.260 --> 10:07.580\n has largely halted in its traditional shrinking mechanism\n\n10:07.580 --> 10:10.340\n because the costs have just gotten so high.\n\n10:10.340 --> 10:12.160\n It's getting harder and harder.\n\n10:12.160 --> 10:14.580\n But there's plenty of algorithmic improvements\n\n10:14.580 --> 10:16.580\n and specialized hardware improvements.\n\n10:16.580 --> 10:19.660\n So you need to understand the nature of those improvements\n\n10:19.660 --> 10:21.940\n and where they'll go in order to understand\n\n10:21.940 --> 10:24.300\n how it will change the platform.\n\n10:24.300 --> 10:26.060\n In the area of network connectivity,\n\n10:26.060 --> 10:29.400\n what are the gains that are gonna be possible in wireless?\n\n10:29.400 --> 10:33.380\n It looks like there's an enormous expansion\n\n10:33.380 --> 10:36.900\n of wireless connectivity at many different bands.\n\n10:36.900 --> 10:38.660\n And that we will primarily,\n\n10:38.660 --> 10:39.860\n historically I've always thought\n\n10:39.860 --> 10:42.080\n that we were primarily gonna be using fiber,\n\n10:42.080 --> 10:43.940\n but now it looks like we're gonna be using fiber\n\n10:43.940 --> 10:46.580\n plus very powerful high bandwidth\n\n10:47.380 --> 10:49.320\n sort of short distance connectivity\n\n10:49.320 --> 10:51.460\n to bridge the last mile.\n\n10:51.460 --> 10:53.060\n That's an amazing achievement.\n\n10:53.060 --> 10:54.440\n If you know that,\n\n10:54.440 --> 10:56.900\n then you're gonna build your systems differently.\n\n10:56.900 --> 10:57.780\n By the way, those networks\n\n10:57.780 --> 10:59.640\n have different latency properties, right?\n\n10:59.640 --> 11:01.620\n Because they're more symmetric,\n\n11:01.620 --> 11:03.880\n the algorithms feel faster for that reason.\n\n11:04.980 --> 11:07.860\n And so when you think about whether it's a fiber\n\n11:07.860 --> 11:09.860\n or just technologies in general,\n\n11:09.860 --> 11:14.180\n so there's this barber wooden poem or quote\n\n11:14.180 --> 11:15.860\n that I really like.\n\n11:15.860 --> 11:18.240\n It's from the champions of the impossible\n\n11:18.240 --> 11:20.340\n rather than the slaves of the possible\n\n11:20.340 --> 11:23.220\n that evolution draws its creative force.\n\n11:23.220 --> 11:25.980\n So in predicting the next five years,\n\n11:25.980 --> 11:29.220\n I'd like to talk about the impossible and the possible.\n\n11:29.220 --> 11:32.280\n Well, and again, one of the great things about humanity\n\n11:32.280 --> 11:34.720\n is that we produce dreamers, right?\n\n11:34.720 --> 11:37.780\n We literally have people who have a vision and a dream.\n\n11:37.780 --> 11:40.100\n They are, if you will, disagreeable\n\n11:40.100 --> 11:42.740\n in the sense that they disagree with the,\n\n11:42.740 --> 11:45.780\n they disagree with what the sort of zeitgeist is.\n\n11:45.780 --> 11:48.020\n They say there is another way.\n\n11:48.020 --> 11:50.280\n They have a belief, they have a vision.\n\n11:50.280 --> 11:54.060\n If you look at science, science is always marked\n\n11:54.060 --> 11:58.380\n by such people who went against some conventional wisdom,\n\n11:58.380 --> 12:00.220\n collected the knowledge at the time\n\n12:00.220 --> 12:03.660\n and assembled it in a way that produced a powerful platform.\n\n12:03.660 --> 12:08.300\n And you've been amazingly honest about,\n\n12:08.300 --> 12:11.260\n in an inspiring way, about things you've been wrong\n\n12:11.260 --> 12:13.860\n about predicting and you've obviously been right\n\n12:13.860 --> 12:18.860\n about a lot of things, but in this kind of tension,\n\n12:18.860 --> 12:21.260\n how do you balance, as a company,\n\n12:21.260 --> 12:23.580\n in predicting the next five years,\n\n12:23.580 --> 12:26.300\n the impossible, planning for the impossible,\n\n12:26.300 --> 12:30.380\n so listening to those crazy dreamers, letting them do,\n\n12:30.380 --> 12:34.140\n letting them run away and make the impossible real,\n\n12:34.140 --> 12:36.940\n make it happen, and slow, you know,\n\n12:36.940 --> 12:38.740\n that's how programmers often think,\n\n12:38.740 --> 12:41.560\n and slowing things down and saying,\n\n12:41.560 --> 12:44.600\n well, this is the rational, this is the possible,\n\n12:44.600 --> 12:48.380\n the pragmatic, the dreamer versus the pragmatist,\n\n12:48.380 --> 12:51.380\n so it's helpful to have a model\n\n12:51.380 --> 12:56.020\n which encourages a predictable revenue stream\n\n12:56.020 --> 12:58.660\n as well as the ability to do new things.\n\n12:58.660 --> 13:00.540\n So in Google's case, we're big enough\n\n13:00.540 --> 13:02.340\n and well enough managed and so forth\n\n13:02.340 --> 13:05.200\n that we have a pretty good sense of what our revenue will be\n\n13:05.200 --> 13:07.900\n for the next year or two, at least for a while.\n\n13:07.900 --> 13:11.540\n And so we have enough cash generation\n\n13:11.540 --> 13:14.700\n that we can make bets, and indeed,\n\n13:14.700 --> 13:16.780\n Google has become alphabet,\n\n13:16.780 --> 13:19.500\n so the corporation is organized around these bets,\n\n13:19.500 --> 13:22.740\n and these bets are in areas of fundamental importance\n\n13:22.740 --> 13:26.720\n to the world, whether it's artificial intelligence,\n\n13:26.720 --> 13:29.700\n medical technology, self driving cars,\n\n13:29.700 --> 13:33.300\n connectivity through balloons, on and on and on.\n\n13:33.300 --> 13:35.980\n And there's more coming and more coming.\n\n13:35.980 --> 13:38.020\n So one way you could express this\n\n13:38.020 --> 13:41.500\n is that the current business is successful enough\n\n13:41.500 --> 13:43.700\n that we have the luxury of making bets.\n\n13:44.580 --> 13:45.940\n And another one that you could say\n\n13:45.940 --> 13:49.140\n is that we have the wisdom of being able to see\n\n13:49.140 --> 13:51.580\n that a corporate structure needs to be created\n\n13:51.580 --> 13:55.260\n to enhance the likelihood of the success of those bets.\n\n13:55.260 --> 13:58.860\n So we essentially turned ourselves into a conglomerate\n\n13:58.860 --> 14:02.100\n of bets and then this underlying corporation, Google,\n\n14:02.100 --> 14:04.280\n which is itself innovative.\n\n14:04.280 --> 14:05.900\n So in order to pull this off,\n\n14:05.900 --> 14:08.060\n you have to have a bunch of belief systems,\n\n14:08.060 --> 14:09.580\n and one of them is that you have to have\n\n14:09.580 --> 14:11.460\n bottoms up and tops down.\n\n14:11.460 --> 14:13.580\n The bottoms up we call 20% time,\n\n14:13.580 --> 14:15.780\n and the idea is that people can spend 20% of the time\n\n14:15.780 --> 14:17.740\n whatever they want, and the top down\n\n14:17.740 --> 14:19.700\n is that our founders in particular\n\n14:19.700 --> 14:21.740\n have a keen eye on technology\n\n14:21.740 --> 14:23.880\n and they're reviewing things constantly.\n\n14:23.880 --> 14:26.540\n So an example would be they'll hear about an idea\n\n14:26.540 --> 14:28.700\n or I'll hear about something and it sounds interesting,\n\n14:28.700 --> 14:30.380\n let's go visit them.\n\n14:30.380 --> 14:33.060\n And then let's begin to assemble the pieces\n\n14:33.060 --> 14:34.780\n to see if that's possible.\n\n14:34.780 --> 14:35.980\n And if you do this long enough,\n\n14:35.980 --> 14:39.780\n you get pretty good at predicting what's likely to work.\n\n14:39.780 --> 14:42.020\n So that's a beautiful balance that struck.\n\n14:42.020 --> 14:44.420\n Is this something that applies at all scale?\n\n14:44.420 --> 14:49.420\n It seems to be that Sergey, again, 15 years ago,\n\n14:53.060 --> 14:56.840\n came up with a concept called 10% of the budget\n\n14:56.840 --> 14:58.980\n should be on things that are unrelated.\n\n14:58.980 --> 15:00.860\n It was called 70, 20, 10.\n\n15:00.860 --> 15:03.540\n 70% of our time on core business,\n\n15:03.540 --> 15:06.780\n 20% on adjacent business, and 10% on other.\n\n15:06.780 --> 15:08.700\n And he proved mathematically,\n\n15:08.700 --> 15:10.580\n of course he's a brilliant mathematician,\n\n15:10.580 --> 15:13.860\n that you needed that 10% to make the sum\n\n15:13.860 --> 15:14.700\n of the growth work.\n\n15:14.700 --> 15:16.140\n And it turns out he was right.\n\n15:18.620 --> 15:20.940\n So getting into the world of artificial intelligence,\n\n15:20.940 --> 15:25.380\n you've talked quite extensively and effectively\n\n15:25.380 --> 15:28.780\n to the impact in the near term,\n\n15:28.780 --> 15:32.020\n the positive impact of artificial intelligence,\n\n15:32.020 --> 15:34.140\n whether it's especially machine learning\n\n15:34.140 --> 15:38.580\n in medical applications and education,\n\n15:38.580 --> 15:41.600\n and just making information more accessible, right?\n\n15:41.600 --> 15:45.860\n In the AI community, there is a kind of debate.\n\n15:45.860 --> 15:47.700\n There's this shroud of uncertainty\n\n15:47.700 --> 15:49.020\n as we face this new world\n\n15:49.020 --> 15:50.460\n with artificial intelligence in it.\n\n15:50.460 --> 15:54.260\n And there's some people, like Elon Musk,\n\n15:54.260 --> 15:57.660\n you've disagreed, at least on the degree of emphasis\n\n15:57.660 --> 16:00.700\n he places on the existential threat of AI.\n\n16:00.700 --> 16:02.540\n So I've spoken with Stuart Russell,\n\n16:02.540 --> 16:05.340\n Max Tegmark, who share Elon Musk's view,\n\n16:05.340 --> 16:09.180\n and Yoshua Bengio, Steven Pinker, who do not.\n\n16:09.180 --> 16:11.860\n And so there's a lot of very smart people\n\n16:11.860 --> 16:14.620\n who are thinking about this stuff, disagreeing,\n\n16:14.620 --> 16:17.180\n which is really healthy, of course.\n\n16:17.180 --> 16:19.100\n So what do you think is the healthiest way\n\n16:19.100 --> 16:22.020\n for the AI community to,\n\n16:22.020 --> 16:23.860\n and really for the general public,\n\n16:23.860 --> 16:26.780\n to think about AI and the concern\n\n16:27.700 --> 16:32.700\n of the technology being mismanaged in some kind of way?\n\n16:32.920 --> 16:35.060\n So the source of education for the general public\n\n16:35.060 --> 16:37.380\n has been robot killer movies.\n\n16:37.380 --> 16:38.220\n Right.\n\n16:38.220 --> 16:40.860\n And Terminator, et cetera.\n\n16:40.860 --> 16:44.500\n And the one thing I can assure you we're not building\n\n16:44.500 --> 16:46.620\n are those kinds of solutions.\n\n16:46.620 --> 16:48.420\n Furthermore, if they were to show up,\n\n16:48.420 --> 16:51.140\n someone would notice and unplug them, right?\n\n16:51.140 --> 16:53.140\n So as exciting as those movies are,\n\n16:53.140 --> 16:54.700\n and they're great movies,\n\n16:54.700 --> 16:57.500\n were the killer robots to start,\n\n16:57.500 --> 17:00.500\n we would find a way to stop them, right?\n\n17:00.500 --> 17:02.860\n So I'm not concerned about that.\n\n17:04.060 --> 17:05.980\n And much of this has to do\n\n17:05.980 --> 17:08.540\n with the timeframe of conversation.\n\n17:08.540 --> 17:13.300\n So you can imagine a situation 100 years from now\n\n17:13.300 --> 17:15.920\n when the human brain is fully understood\n\n17:15.920 --> 17:18.140\n and the next generation and next generation\n\n17:18.140 --> 17:20.940\n of brilliant MIT scientists have figured all this out,\n\n17:20.940 --> 17:25.140\n we're gonna have a large number of ethics questions, right?\n\n17:25.140 --> 17:28.060\n Around science and thinking and robots and computers\n\n17:28.060 --> 17:29.700\n and so forth and so on.\n\n17:29.700 --> 17:32.260\n So it depends on the question of the timeframe.\n\n17:32.260 --> 17:34.780\n In the next five to 10 years,\n\n17:34.780 --> 17:37.220\n we're not facing those questions.\n\n17:37.220 --> 17:39.100\n What we're facing in the next five to 10 years\n\n17:39.100 --> 17:42.140\n is how do we spread this disruptive technology\n\n17:42.140 --> 17:46.500\n as broadly as possible to gain the maximum benefit of it?\n\n17:46.500 --> 17:48.980\n The primary benefits should be in healthcare\n\n17:48.980 --> 17:50.860\n and in education.\n\n17:50.860 --> 17:52.320\n Healthcare because it's obvious.\n\n17:52.320 --> 17:55.780\n We're all the same even though we somehow believe we're not.\n\n17:55.780 --> 17:57.340\n As a medical matter,\n\n17:57.340 --> 17:59.180\n the fact that we have big data about our health\n\n17:59.180 --> 18:02.700\n will save lives, allow us to deal with skin cancer\n\n18:02.700 --> 18:05.500\n and other cancers, ophthalmological problems.\n\n18:05.500 --> 18:08.420\n There's people working on psychological diseases\n\n18:08.420 --> 18:10.260\n and so forth using these techniques.\n\n18:10.260 --> 18:11.700\n I can go on and on.\n\n18:11.700 --> 18:15.840\n The promise of AI in medicine is extraordinary.\n\n18:15.840 --> 18:17.980\n There are many, many companies and startups\n\n18:17.980 --> 18:19.480\n and funds and solutions\n\n18:19.480 --> 18:22.140\n and we will all live much better for that.\n\n18:22.140 --> 18:25.580\n The same argument in education.\n\n18:25.580 --> 18:28.540\n Can you imagine that for each generation of child\n\n18:28.540 --> 18:33.020\n and even adult, you have a tutor educator that's AI based,\n\n18:33.020 --> 18:35.900\n that's not a human but is properly trained,\n\n18:35.900 --> 18:37.140\n that helps you get smarter,\n\n18:37.140 --> 18:39.280\n helps you address your language difficulties\n\n18:39.280 --> 18:41.340\n or your math difficulties or what have you.\n\n18:41.340 --> 18:43.300\n Why don't we focus on those two?\n\n18:43.300 --> 18:47.300\n The gains societally of making humans smarter and healthier\n\n18:47.300 --> 18:51.460\n are enormous and those translate for decades and decades\n\n18:51.460 --> 18:53.020\n and we'll all benefit from them.\n\n18:53.900 --> 18:56.300\n There are people who are working on AI safety,\n\n18:56.300 --> 18:58.060\n which is the issue that you're describing\n\n18:58.060 --> 19:00.660\n and there are conversations in the community\n\n19:00.660 --> 19:02.500\n that should there be such problems,\n\n19:02.500 --> 19:04.380\n what should the rules be like?\n\n19:04.380 --> 19:07.540\n Google, for example, has announced its policies\n\n19:07.540 --> 19:10.140\n with respect to AI safety, which I certainly support\n\n19:10.140 --> 19:12.300\n and I think most everybody would support\n\n19:12.300 --> 19:14.140\n and they make sense, right?\n\n19:14.140 --> 19:16.300\n So it helps guide the research\n\n19:16.300 --> 19:19.540\n but the killer robots are not arriving this year\n\n19:19.540 --> 19:21.180\n and they're not even being built.\n\n19:22.540 --> 19:26.720\n And on that line of thinking, you said the time scale.\n\n19:26.720 --> 19:30.440\n In this topic or other topics,\n\n19:30.440 --> 19:34.560\n have you found it useful on the business side\n\n19:34.560 --> 19:37.480\n or the intellectual side to think beyond five, 10 years,\n\n19:37.480 --> 19:39.360\n to think 50 years out?\n\n19:39.360 --> 19:41.960\n Has it ever been useful or productive?\n\n19:41.960 --> 19:45.160\n In our industry, there are essentially no examples\n\n19:45.160 --> 19:47.460\n of 50 year predictions that have been correct.\n\n19:48.840 --> 19:50.400\n Let's review AI, right?\n\n19:50.400 --> 19:53.060\n AI, which was largely invented here at MIT\n\n19:53.060 --> 19:56.440\n and a couple of other universities in the 1956, 1957,\n\n19:56.440 --> 20:01.320\n 1958, the original claims were a decade or two.\n\n20:01.320 --> 20:05.180\n And when I was a PhD student, I studied AI a bit\n\n20:05.180 --> 20:07.680\n and it entered during my looking at it,\n\n20:07.680 --> 20:10.360\n a period which is known as AI winter,\n\n20:10.360 --> 20:12.760\n which went on for about 30 years,\n\n20:12.760 --> 20:14.720\n which is a whole generation of science,\n\n20:14.720 --> 20:16.640\n scientists and a whole group of people\n\n20:16.640 --> 20:18.400\n who didn't make a lot of progress\n\n20:18.400 --> 20:20.160\n because the algorithms had not improved\n\n20:20.160 --> 20:22.060\n and the computers had not approved.\n\n20:22.060 --> 20:23.840\n It took some brilliant mathematicians\n\n20:23.840 --> 20:25.360\n starting with a fellow named Jeff Hinton\n\n20:25.360 --> 20:29.460\n at Toronto and Montreal who basically invented\n\n20:29.460 --> 20:33.020\n this deep learning model which empowers us today.\n\n20:33.020 --> 20:36.060\n The seminal work there was 20 years ago\n\n20:36.060 --> 20:39.960\n and in the last 10 years, it's become popularized.\n\n20:39.960 --> 20:43.840\n So think about the timeframes for that level of discovery.\n\n20:43.840 --> 20:45.880\n It's very hard to predict.\n\n20:45.880 --> 20:47.700\n Many people think that we'll be flying around\n\n20:47.700 --> 20:51.160\n in the equivalent of flying cars, who knows?\n\n20:51.160 --> 20:54.440\n My own view, if I wanna go out on a limb,\n\n20:54.440 --> 20:56.840\n is to say that we know a couple of things\n\n20:56.840 --> 20:57.960\n about 50 years from now.\n\n20:57.960 --> 21:00.440\n We know that there'll be more people alive.\n\n21:00.440 --> 21:02.160\n We know that we'll have to have platforms\n\n21:02.160 --> 21:05.680\n that are more sustainable because the earth is limited\n\n21:05.680 --> 21:09.160\n in the ways we all know and that the kind of platforms\n\n21:09.160 --> 21:11.360\n that are gonna get built will be consistent\n\n21:11.360 --> 21:13.000\n with the principles that I've described.\n\n21:13.000 --> 21:15.720\n They will be much more empowering of individuals.\n\n21:15.720 --> 21:17.720\n They'll be much more sensitive to the ecology\n\n21:17.720 --> 21:20.520\n because they have to be, they just have to be.\n\n21:20.520 --> 21:23.760\n I also think that humans are gonna be a great deal smarter\n\n21:23.760 --> 21:25.040\n and I think they're gonna be a lot smarter\n\n21:25.040 --> 21:27.720\n because of the tools that I've discussed with you\n\n21:27.720 --> 21:29.160\n and of course, people will live longer.\n\n21:29.160 --> 21:32.160\n Life extension is continuing apace.\n\n21:32.160 --> 21:34.600\n A baby born today has a reasonable chance\n\n21:34.600 --> 21:37.080\n of living to 100, which is pretty exciting.\n\n21:37.080 --> 21:38.580\n It's well past the 21st century,\n\n21:38.580 --> 21:40.600\n so we better take care of them.\n\n21:40.600 --> 21:42.600\n And you mentioned an interesting statistic\n\n21:42.600 --> 21:46.080\n on some very large percentage, 60, 70% of people\n\n21:46.080 --> 21:48.160\n may live in cities.\n\n21:48.160 --> 21:50.460\n Today, more than half the world lives in cities\n\n21:50.460 --> 21:53.720\n and one of the great stories of humanity\n\n21:53.720 --> 21:57.440\n in the last 20 years has been the rural to urban migration.\n\n21:57.440 --> 21:59.200\n This has occurred in the United States,\n\n21:59.200 --> 22:02.760\n it's occurred in Europe, it's occurring in Asia\n\n22:02.760 --> 22:04.660\n and it's occurring in Africa.\n\n22:04.660 --> 22:07.760\n When people move to cities, the cities get more crowded,\n\n22:07.760 --> 22:10.480\n but believe it or not, their health gets better,\n\n22:10.480 --> 22:12.280\n their productivity gets better,\n\n22:12.280 --> 22:15.440\n their IQ and educational capabilities improve.\n\n22:15.440 --> 22:18.500\n So it's good news that people are moving to cities,\n\n22:18.500 --> 22:20.820\n but we have to make them livable and safe.\n\n22:20.820 --> 22:25.820\n So you, first of all, you are,\n\n22:25.860 --> 22:28.300\n but you've also worked with some of the greatest leaders\n\n22:28.300 --> 22:29.940\n in the history of tech.\n\n22:29.940 --> 22:32.940\n What insights do you draw from the difference\n\n22:32.940 --> 22:35.660\n in leadership styles of yourself,\n\n22:35.660 --> 22:39.140\n Steve Jobs, Elon Musk, Larry Page,\n\n22:39.140 --> 22:42.740\n now the new CEO, Sandra Pichai and others?\n\n22:42.740 --> 22:47.740\n From the, I would say, calm sages to the mad geniuses.\n\n22:47.740 --> 22:50.660\n One of the things that I learned as a young executive\n\n22:50.660 --> 22:53.300\n is that there's no single formula for leadership.\n\n22:54.500 --> 22:58.380\n They try to teach one, but that's not how it really works.\n\n22:58.380 --> 23:01.020\n There are people who just understand what they need to do\n\n23:01.020 --> 23:02.540\n and they need to do it quickly.\n\n23:02.540 --> 23:05.060\n Those people are often entrepreneurs.\n\n23:05.060 --> 23:07.340\n They just know and they move fast.\n\n23:07.340 --> 23:09.100\n There are other people who are systems thinkers\n\n23:09.100 --> 23:11.420\n and planners, that's more who I am,\n\n23:11.420 --> 23:15.060\n somewhat more conservative, more thorough in execution,\n\n23:15.060 --> 23:16.740\n a little bit more risk of risk.\n\n23:16.740 --> 23:18.620\n A little bit more risk averse.\n\n23:18.620 --> 23:22.140\n There's also people who are sort of slightly insane,\n\n23:22.140 --> 23:26.060\n in the sense that they are emphatic and charismatic\n\n23:26.060 --> 23:28.900\n and they feel it and they drive it and so forth.\n\n23:28.900 --> 23:31.340\n There's no single formula to success.\n\n23:31.340 --> 23:33.620\n There is one thing that unifies all of the people\n\n23:33.620 --> 23:36.900\n that you named, which is very high intelligence.\n\n23:36.900 --> 23:40.180\n At the end of the day, the thing that characterizes\n\n23:40.180 --> 23:43.620\n all of them is that they saw the world quicker, faster,\n\n23:43.620 --> 23:45.700\n they processed information faster.\n\n23:45.700 --> 23:47.300\n They didn't necessarily make the right decisions\n\n23:47.300 --> 23:49.940\n all the time, but they were on top of it.\n\n23:49.940 --> 23:51.180\n And the other thing that's interesting\n\n23:51.180 --> 23:54.140\n about all those people is they all started young.\n\n23:54.140 --> 23:56.940\n So think about Steve Jobs starting Apple\n\n23:56.940 --> 23:58.380\n roughly at 18 or 19.\n\n23:58.380 --> 24:01.620\n Think about Bill Gates starting at roughly 20, 21.\n\n24:01.620 --> 24:03.700\n Think about by the time they were 30,\n\n24:03.700 --> 24:06.900\n Mark Zuckerberg, a good example, at 19, 20.\n\n24:06.900 --> 24:10.620\n By the time they were 30, they had 10 years.\n\n24:10.620 --> 24:13.700\n At 30 years old, they had 10 years of experience\n\n24:13.700 --> 24:16.940\n of dealing with people and products and shipments\n\n24:16.940 --> 24:19.740\n and the press and business and so forth.\n\n24:19.740 --> 24:22.740\n It's incredible how much experience they had\n\n24:22.740 --> 24:25.220\n compared to the rest of us who were busy getting our PhDs.\n\n24:25.220 --> 24:26.060\n Yes, exactly.\n\n24:26.060 --> 24:28.460\n So we should celebrate these people\n\n24:28.460 --> 24:32.180\n because they've just had more life experience, right?\n\n24:32.180 --> 24:34.340\n And that helps inform the judgment.\n\n24:34.340 --> 24:38.220\n At the end of the day, when you're at the top\n\n24:38.220 --> 24:41.380\n of these organizations, all the easy questions\n\n24:41.380 --> 24:43.500\n have been dealt with, right?\n\n24:43.500 --> 24:45.620\n How should we design the buildings?\n\n24:45.620 --> 24:48.180\n Where should we put the colors on our product?\n\n24:48.180 --> 24:51.300\n What should the box look like, right?\n\n24:51.300 --> 24:53.340\n The problems, that's why it's so interesting\n\n24:53.340 --> 24:56.420\n to be in these rooms, the problems that they face, right,\n\n24:56.420 --> 24:58.340\n in terms of the way they operate,\n\n24:58.340 --> 25:00.060\n the way they deal with their employees,\n\n25:00.060 --> 25:01.860\n their customers, their innovation,\n\n25:01.860 --> 25:03.900\n are profoundly challenging.\n\n25:03.900 --> 25:08.900\n Each of the companies is demonstrably different culturally.\n\n25:09.340 --> 25:11.700\n They are not, in fact, cut of the same.\n\n25:11.700 --> 25:14.180\n They behave differently based on input.\n\n25:14.180 --> 25:15.820\n Their internal cultures are different.\n\n25:15.820 --> 25:17.460\n Their compensation schemes are different.\n\n25:17.460 --> 25:19.340\n Their values are different.\n\n25:19.340 --> 25:21.940\n So there's proof that diversity works.\n\n25:24.700 --> 25:28.620\n So, so when faced with a tough decision,\n\n25:29.780 --> 25:33.500\n in need of advice, it's been said that the best thing\n\n25:33.500 --> 25:36.740\n one can do is to find the best person in the world\n\n25:36.740 --> 25:40.780\n who can give that advice and find a way to be\n\n25:40.780 --> 25:43.620\n in a room with them, one on one and ask.\n\n25:44.740 --> 25:48.060\n So here we are, and let me ask in a long winded way,\n\n25:48.060 --> 25:49.140\n I wrote this down.\n\n25:50.740 --> 25:53.420\n In 1998, there were many good search engines,\n\n25:53.420 --> 25:58.300\n Lycos, Excite, AltaVista, Infoseek, Ask Jeeves maybe,\n\n25:59.260 --> 26:00.300\n Yahoo even.\n\n26:01.860 --> 26:04.660\n So Google stepped in and disrupted everything.\n\n26:04.660 --> 26:06.580\n They disrupted the nature of search,\n\n26:06.580 --> 26:08.860\n the nature of our access to information,\n\n26:08.860 --> 26:10.660\n the way we discover new knowledge.\n\n26:11.900 --> 26:16.020\n So now it's 2018, actually 20 years later.\n\n26:16.020 --> 26:18.740\n There are many good personal AI assistants,\n\n26:18.740 --> 26:21.020\n including, of course, the best from Google.\n\n26:22.260 --> 26:25.540\n So you've spoken in medical and education,\n\n26:25.540 --> 26:28.620\n the impact of such an AI assistant could bring.\n\n26:28.620 --> 26:30.340\n So we arrive at this question.\n\n26:30.340 --> 26:32.180\n So it's a personal one for me,\n\n26:32.180 --> 26:36.300\n but I hope my situation represents that of many other,\n\n26:36.300 --> 26:40.580\n as we said, dreamers and the crazy engineers.\n\n26:40.580 --> 26:43.900\n So my whole life, I've dreamed of creating\n\n26:43.900 --> 26:45.860\n such an AI assistant.\n\n26:45.860 --> 26:48.420\n Every step I've taken has been towards that goal.\n\n26:48.420 --> 26:51.060\n Now I'm a research scientist in human centered AI\n\n26:51.060 --> 26:52.300\n here at MIT.\n\n26:52.300 --> 26:54.860\n So the next step for me as I sit here,\n\n26:54.860 --> 26:59.860\n so facing my passion is to do what Larry and Sergey did\n\n26:59.860 --> 27:04.180\n in 98, this simple startup.\n\n27:04.180 --> 27:06.820\n And so here's my simple question.\n\n27:06.820 --> 27:10.620\n Given the low odds of success, the timing and luck required,\n\n27:10.620 --> 27:12.700\n the countless other factors that can't be controlled\n\n27:12.700 --> 27:14.660\n or predicted, which is all the things\n\n27:14.660 --> 27:16.460\n that Larry and Sergey faced,\n\n27:16.460 --> 27:19.180\n is there some calculation, some strategy\n\n27:20.140 --> 27:21.580\n to follow in this step?\n\n27:21.580 --> 27:23.700\n Or do you simply follow the passion\n\n27:23.700 --> 27:25.540\n just because there's no other choice?\n\n27:26.580 --> 27:29.660\n I think the people who are in universities\n\n27:29.660 --> 27:31.860\n are always trying to study\n\n27:31.860 --> 27:35.180\n the extraordinarily chaotic nature of innovation\n\n27:35.180 --> 27:37.260\n and entrepreneurship.\n\n27:37.260 --> 27:41.180\n My answer is that they didn't have that conversation.\n\n27:41.180 --> 27:42.820\n They just did it.\n\n27:42.820 --> 27:47.220\n They sensed a moment when in the case of Google,\n\n27:47.220 --> 27:49.700\n there was all of this data that needed to be organized\n\n27:49.700 --> 27:51.300\n and they had a better algorithm.\n\n27:51.300 --> 27:53.780\n They had invented a better way.\n\n27:53.780 --> 27:56.300\n So today with human centered AI,\n\n27:56.300 --> 27:58.060\n which is your area of research,\n\n27:58.060 --> 28:00.860\n there must be new approaches.\n\n28:00.860 --> 28:02.460\n It's such a big field.\n\n28:02.460 --> 28:04.900\n There must be new approaches,\n\n28:04.900 --> 28:07.220\n different from what we and others are doing.\n\n28:07.220 --> 28:09.540\n There must be startups to fund.\n\n28:09.540 --> 28:11.940\n There must be research projects to try.\n\n28:11.940 --> 28:15.020\n There must be graduate students to work on new approaches.\n\n28:15.020 --> 28:18.180\n Here at MIT, there are people who are looking at learning\n\n28:18.180 --> 28:20.580\n from the standpoint of looking at child learning.\n\n28:20.580 --> 28:23.500\n How do children learn starting at age one and two?\n\n28:23.500 --> 28:25.340\n And the work is fantastic.\n\n28:25.340 --> 28:28.180\n Those approaches are different from the approach\n\n28:28.180 --> 28:29.780\n that most people are taking.\n\n28:29.780 --> 28:31.940\n Perhaps that's a bet that you should make\n\n28:31.940 --> 28:33.820\n or perhaps there's another one.\n\n28:33.820 --> 28:35.860\n But at the end of the day,\n\n28:35.860 --> 28:40.100\n the successful entrepreneurs are not as crazy as they sound.\n\n28:40.100 --> 28:43.100\n They see an opportunity based on what's happened.\n\n28:43.100 --> 28:45.300\n Let's use Uber as an example.\n\n28:45.300 --> 28:46.740\n As Travis sells the story,\n\n28:46.740 --> 28:48.940\n he and his co founder were sitting in Paris\n\n28:48.940 --> 28:52.060\n and they had this idea because they couldn't get a cab.\n\n28:52.060 --> 28:56.660\n And they said, we have smartphones and the rest is history.\n\n28:56.660 --> 29:00.980\n So what's the equivalent of that Travis Eiffel Tower,\n\n29:00.980 --> 29:03.980\n where is a cab moment that you could,\n\n29:03.980 --> 29:05.940\n as an entrepreneur, take advantage of?\n\n29:05.940 --> 29:08.500\n Whether it's in human centered AI or something else.\n\n29:08.500 --> 29:10.100\n That's the next great startup.\n\n29:11.260 --> 29:13.660\n And the psychology of that moment.\n\n29:13.660 --> 29:16.140\n So when Sergey and Larry talk about,\n\n29:17.540 --> 29:20.180\n and listen to a few interviews, it's very nonchalant.\n\n29:20.180 --> 29:23.780\n Well, here's the very fascinating web data\n\n29:23.780 --> 29:27.700\n and here's an algorithm we have for,\n\n29:27.700 --> 29:29.420\n we just kind of want to play around with that data.\n\n29:29.420 --> 29:31.020\n And it seems like that's a really nice way\n\n29:31.020 --> 29:32.300\n to organize this data.\n\n29:34.180 --> 29:35.580\n I should say what happened to remember\n\n29:35.580 --> 29:38.100\n is that they were graduate students at Stanford\n\n29:38.100 --> 29:39.300\n and they thought this was interesting.\n\n29:39.300 --> 29:40.540\n So they built a search engine\n\n29:40.540 --> 29:42.140\n and they kept it in their room.\n\n29:43.020 --> 29:46.300\n And they had to get power from the room next door\n\n29:46.300 --> 29:48.020\n because they were using too much power in the room.\n\n29:48.020 --> 29:51.460\n So they ran an extension cord over, right?\n\n29:51.460 --> 29:53.500\n And then they went and they found a house\n\n29:53.500 --> 29:56.500\n and they had Google world headquarters of five people,\n\n29:56.500 --> 29:57.540\n right, to start the company.\n\n29:57.540 --> 30:00.460\n And they raised $100,000 from Andy Bechtolsheim,\n\n30:00.460 --> 30:02.220\n who was the Sun founder to do this\n\n30:02.220 --> 30:04.460\n and Dave Cheriton and a few others.\n\n30:04.460 --> 30:08.220\n The point is their beginnings were very simple\n\n30:08.220 --> 30:10.460\n but they were based on a powerful insight.\n\n30:11.700 --> 30:14.860\n That is a replicable model for any startup.\n\n30:14.860 --> 30:16.500\n It has to be a powerful insight.\n\n30:16.500 --> 30:17.620\n The beginnings are simple.\n\n30:17.620 --> 30:19.860\n And there has to be an innovation.\n\n30:19.860 --> 30:22.820\n In Larry and Sergey's case, it was PageRank,\n\n30:22.820 --> 30:23.980\n which was a brilliant idea,\n\n30:23.980 --> 30:26.700\n one of the most cited papers in the world today.\n\n30:26.700 --> 30:27.820\n What's the next one?\n\n30:29.740 --> 30:33.500\n So you're one of, if I may say,\n\n30:33.500 --> 30:35.020\n richest people in the world.\n\n30:36.180 --> 30:38.700\n And yet it seems that money is simply a side effect\n\n30:38.700 --> 30:41.940\n of your passions and not an inherent goal.\n\n30:42.980 --> 30:47.980\n But you're a fascinating person to ask.\n\n30:48.220 --> 30:51.540\n So much of our society at the individual level\n\n30:51.540 --> 30:55.020\n and at the company level and as nations\n\n30:55.020 --> 30:57.380\n is driven by the desire for wealth.\n\n30:58.660 --> 31:01.100\n What do you think about this drive?\n\n31:01.100 --> 31:03.140\n And what have you learned about,\n\n31:03.140 --> 31:05.020\n if I may romanticize the notion,\n\n31:05.020 --> 31:06.860\n the meaning of life,\n\n31:06.860 --> 31:10.420\n having achieved success on so many dimensions?\n\n31:10.420 --> 31:13.580\n There have been many studies of human happiness\n\n31:13.580 --> 31:16.340\n and above some threshold,\n\n31:16.340 --> 31:19.500\n which is typically relatively low for this conversation,\n\n31:19.500 --> 31:23.580\n there's no difference in happiness about money.\n\n31:23.580 --> 31:27.060\n The happiness is correlated with meaning and purpose,\n\n31:27.060 --> 31:30.020\n a sense of family, a sense of impact.\n\n31:30.020 --> 31:31.900\n So if you organize your life,\n\n31:31.900 --> 31:33.620\n assuming you have enough to get around\n\n31:33.620 --> 31:35.860\n and have a nice home and so forth,\n\n31:35.860 --> 31:38.300\n you'll be far happier if you figure out\n\n31:38.300 --> 31:41.660\n what you care about and work on that.\n\n31:41.660 --> 31:44.580\n It's often being in service to others.\n\n31:44.580 --> 31:46.860\n There's a great deal of evidence that people are happiest\n\n31:46.860 --> 31:49.540\n when they're serving others and not themselves.\n\n31:49.540 --> 31:52.540\n This goes directly against the sort of\n\n31:52.540 --> 31:56.100\n press induced excitement about\n\n31:56.100 --> 31:59.220\n powerful and wealthy leaders of one kind.\n\n31:59.220 --> 32:01.700\n And indeed these are consequential people.\n\n32:01.700 --> 32:03.860\n But if you are in a situation\n\n32:03.860 --> 32:06.100\n where you've been very fortunate as I have,\n\n32:06.100 --> 32:09.020\n you also have to take that as a responsibility\n\n32:09.020 --> 32:12.180\n and you have to basically work both to educate others\n\n32:12.180 --> 32:13.580\n and give them that opportunity,\n\n32:13.580 --> 32:16.700\n but also use that wealth to advance human society.\n\n32:16.700 --> 32:18.540\n In my case, I'm particularly interested in\n\n32:18.540 --> 32:20.580\n using the tools of artificial intelligence\n\n32:20.580 --> 32:22.860\n and machine learning to make society better.\n\n32:22.860 --> 32:26.020\n I've mentioned education, I've mentioned inequality\n\n32:26.020 --> 32:28.060\n and middle class and things like this,\n\n32:28.060 --> 32:30.100\n all of which are a passion of mine.\n\n32:30.100 --> 32:31.860\n It doesn't matter what you do,\n\n32:31.860 --> 32:33.700\n it matters that you believe in it,\n\n32:33.700 --> 32:35.380\n that it's important to you,\n\n32:35.380 --> 32:38.100\n and that your life will be far more satisfying\n\n32:38.100 --> 32:40.540\n if you spend your life doing that.\n\n32:40.540 --> 32:43.460\n I think there's no better place to end\n\n32:43.460 --> 32:45.220\n than a discussion of the meaning of life.\n\n32:45.220 --> 32:46.900\n Eric, thank you so much.\n\n"
}
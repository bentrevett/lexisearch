{
  "title": "Douglas Lenat: Cyc and the Quest to Solve Common Sense Reasoning in AI | Lex Fridman Podcast #221",
  "id": "3wMKoSRbGVs",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:06.800\n The following is a conversation with Doug Lenit, creator of Psych, a system that for close to 40\n\n00:06.800 --> 00:12.320\n years, and still today, has sought to solve the core problem of artificial intelligence,\n\n00:12.880 --> 00:18.000\n the acquisition of common sense knowledge and the use of that knowledge to think,\n\n00:18.000 --> 00:23.680\n to reason, and to understand the world. To support this podcast, please check out our sponsors in\n\n00:23.680 --> 00:29.440\n the description. As a side note, let me say that in the excitement of the modern era of machine\n\n00:29.440 --> 00:36.000\n learning, it is easy to forget just how little we understand exactly how to build the kind of\n\n00:36.000 --> 00:42.480\n intelligence that matches the power of the human mind. To me, many of the core ideas behind Psych,\n\n00:42.480 --> 00:48.880\n in some form, in actuality or in spirit, will likely be part of the AI system that achieves\n\n00:48.880 --> 00:54.480\n general superintelligence. But perhaps more importantly, solving this problem of common\n\n00:54.480 --> 01:01.040\n sense knowledge will help us humans understand our own minds, the nature of truth, and finally,\n\n01:01.040 --> 01:07.280\n how to be more rational and more kind to each other. This is the Lex Friedman podcast,\n\n01:07.280 --> 01:15.520\n and here is my conversation with Doug Lenit. Psych is a project launched by you in 1984,\n\n01:16.080 --> 01:20.880\n and still is active today, whose goal is to assemble a knowledge base that spans the basic\n\n01:20.880 --> 01:26.720\n concepts and rules about how the world works. In other words, it hopes to capture common sense\n\n01:26.720 --> 01:32.320\n knowledge, which is a lot harder than it sounds. Can you elaborate on this mission and maybe\n\n01:32.320 --> 01:39.520\n perhaps speak to the various subgoals within this mission? When I was a faculty member in the\n\n01:39.520 --> 01:46.640\n computer science department at Stanford, my colleagues and I did research in all sorts of\n\n01:46.640 --> 01:53.440\n artificial intelligence programs, so natural language understanding programs, robots,\n\n01:53.440 --> 02:02.160\n expert systems, and so on. And we kept hitting the very same brick wall. Our systems would have\n\n02:02.880 --> 02:12.320\n impressive early successes. And so if your only goal was academic, namely to get enough material\n\n02:12.320 --> 02:18.240\n to write a journal article, that might actually suffice. But if you're really trying to get AI,\n\n02:19.280 --> 02:22.960\n then you have to somehow get past the brick wall. And the brick wall was\n\n02:23.600 --> 02:28.560\n the programs didn't have what we would call common sense. They didn't have general world\n\n02:28.560 --> 02:33.280\n knowledge. They didn't really understand what they were doing, what they were saying,\n\n02:33.280 --> 02:40.480\n what they were being asked. And so very much like a clever dog performing tricks,\n\n02:40.480 --> 02:44.880\n we could get them to do tricks, but they never really understood what they were doing. Sort of\n\n02:44.880 --> 02:50.880\n like when you get a dog to fetch your morning newspaper. The dog might do that successfully,\n\n02:50.880 --> 02:55.520\n but the dog has no idea what a newspaper is or what it says or anything like that.\n\n02:55.520 --> 02:59.760\n What does it mean to understand something? Can you maybe elaborate on that a little bit?\n\n02:59.760 --> 03:05.840\n Is it is understanding action of like combining little things together like through inference,\n\n03:05.840 --> 03:10.000\n or is understanding the wisdom you gain over time that forms a knowledge?\n\n03:10.000 --> 03:20.800\n I think of understanding more like the ground you stand on, which could be very shaky,\n\n03:20.800 --> 03:27.840\n could be very unsafe, but most of the time is not because underneath it is more ground,\n\n03:28.960 --> 03:36.160\n and eventually rock and other things. But layer after layer after layer, that solid foundation\n\n03:36.160 --> 03:41.760\n is there. And you rarely need to think about it, you rarely need to count on it, but occasionally\n\n03:41.760 --> 03:48.960\n you do. And I've never used this analogy before, so bear with me. But I think the same thing is\n\n03:48.960 --> 03:56.000\n true in terms of getting computers to understand things, which is you ask a computer a question,\n\n03:56.000 --> 04:02.160\n for instance, Alexa or some robot or something, and maybe it gets the right answer.\n\n04:02.160 --> 04:09.760\n But if you were asking that of a human, you could also say things like, why? Or how might you be\n\n04:09.760 --> 04:17.040\n wrong about this? Or something like that. And the person would answer you. And it might be a little\n\n04:17.040 --> 04:22.320\n annoying if you have a small child and they keep asking why questions in series. Eventually,\n\n04:22.320 --> 04:25.920\n you get to the point where you throw up your hands and say, I don't know, it's just the way\n\n04:25.920 --> 04:35.280\n the world is. But for many layers, you actually have that layered, solid foundation of support,\n\n04:35.280 --> 04:40.720\n so that when you need it, you can count on it. And when do you need it? Well, when things are\n\n04:40.720 --> 04:46.320\n unexpected, when you come up against a situation which is novel. For instance, when you're driving,\n\n04:46.320 --> 04:55.280\n it may be fine to have a small program, a small set of rules that cover 99% of the cases, but that\n\n04:55.280 --> 05:01.360\n 1% of the time when something strange happens, you really need to draw on common sense. For instance,\n\n05:02.080 --> 05:09.360\n my wife and I were driving recently and there was a trash truck in front of us. And I guess they had\n\n05:09.360 --> 05:17.520\n packed it too full and the back exploded. And trash bags went everywhere. And we had to make\n\n05:17.520 --> 05:21.760\n a split second decision. Are we going to slam on our brakes? Are we going to swerve into another\n\n05:21.760 --> 05:29.040\n lane? Are we going to just run it over? Because there were cars all around us. And in front of us\n\n05:29.040 --> 05:34.960\n was a large trash bag. And we know what we throw away in trash bags, probably not a safe thing to\n\n05:34.960 --> 05:42.880\n run over. Over on the left was a bunch of fast food restaurant trash bags. And it's like,\n\n05:42.880 --> 05:47.760\n oh, well, those things are just like styrofoam and leftover food. We'll run over that. And so that\n\n05:47.760 --> 05:52.800\n was a safe thing for us to do. Now, that's the kind of thing that's going to happen maybe once\n\n05:52.800 --> 06:01.680\n in your life. But the point is that there's almost no telling what little bits of knowledge about the\n\n06:01.680 --> 06:08.480\n world you might actually need in some situations which were unforeseen. But see, when you sit on\n\n06:08.480 --> 06:16.480\n that mountain or that ground that goes deep of knowledge in order to make a split second decision\n\n06:16.480 --> 06:26.080\n about fast food trash or random trash from the back of a trash truck, you need to be able to\n\n06:26.080 --> 06:31.920\n leverage that ground you stand on in some way. It's not merely, you know, it's not enough to just\n\n06:31.920 --> 06:38.480\n have a lot of ground to stand on. It's your ability to leverage it, to utilize in a split,\n\n06:38.480 --> 06:45.840\n like integrate it all together to make that split second decision. And I suppose understanding isn't\n\n06:45.840 --> 06:55.040\n just having a common sense knowledge to access. It's the act of accessing it somehow, like\n\n06:55.040 --> 07:02.560\n correctly filtering out the parts of the knowledge that are not useful, selecting only the useful\n\n07:02.560 --> 07:10.640\n parts and effectively making conclusive decisions. So let's tease apart two different tasks really,\n\n07:10.640 --> 07:16.480\n both of which are incredibly important and even necessary. If you're going to have this in a\n\n07:16.480 --> 07:25.120\n useful, usable fashion as opposed to say like library books sitting on a shelf and so on, where\n\n07:25.120 --> 07:31.040\n the knowledge might be there, but if a fire comes, the books are going to burn because they don't\n\n07:31.040 --> 07:38.080\n know what's in them and they're just going to sit there while they burn. So there are two aspects of\n\n07:38.080 --> 07:45.680\n using the knowledge. One is a kind of a theoretical, how is it possible at all? And then the second\n\n07:45.680 --> 07:51.680\n aspect of what you said is, how can you do it quickly enough? So how can you do it at all is\n\n07:51.680 --> 07:58.960\n something that philosophers have grappled with. And fortunately, philosophers 100 years ago and\n\n07:58.960 --> 08:10.240\n even earlier developed a kind of formal language like English. It's called predicate logic or first\n\n08:10.240 --> 08:16.480\n order logic or something like predicate calculus and so on. So there's a way of representing things\n\n08:17.280 --> 08:25.760\n in this formal language which enables a mechanical procedure to sort of grind through\n\n08:26.480 --> 08:34.000\n and algorithmically produce all of the same logical entailments, all the same logical conclusions\n\n08:34.000 --> 08:40.080\n that you or I would from that same set of pieces of information that are represented that way.\n\n08:41.360 --> 08:48.560\n So that sort of raises a couple questions. One is, how do you get all this information\n\n08:48.560 --> 08:54.880\n from say observations and English and so on into this logical form? And secondly,\n\n08:54.880 --> 09:01.120\n how can you then efficiently run these algorithms to actually get the information you need?\n\n09:01.120 --> 09:08.480\n In the case I mentioned in a 10th of a second rather than say in 10 hours or 10,000 years\n\n09:08.480 --> 09:15.600\n of computation. And those are both really important questions. And like a corollary\n\n09:15.600 --> 09:22.400\n addition to the first one is, how many such things do you need to gather for it to be useful\n\n09:22.400 --> 09:28.640\n in certain contexts? So like what, in order, you mentioned philosophers, in order to capture this\n\n09:28.640 --> 09:36.400\n world and represent it in a logical way and with a form of logic, like how many statements are\n\n09:36.400 --> 09:43.600\n required? Is it five? Is it 10? Is it 10 trillion? Is it like that? That's as far as I understand is\n\n09:43.600 --> 09:50.320\n probably still an open question. It may forever be an open question just to say like definitively\n\n09:50.320 --> 09:54.800\n about, to describe the universe perfectly. How many facts do you need?\n\n09:54.800 --> 10:00.160\n I guess I'm going to disappoint you by giving you an actual answer to your question.\n\n10:00.160 --> 10:02.720\n Okay. Well, no, this sounds exciting.\n\n10:03.280 --> 10:09.600\n Yes. Okay. So now we have like three things to talk about.\n\n10:09.600 --> 10:10.560\n We'll keep adding more.\n\n10:10.560 --> 10:16.000\n Although it's okay. The first and the third are related. So let's leave the efficiency\n\n10:16.000 --> 10:24.480\n question aside for now. So how does all this information get represented in logical form?\n\n10:24.480 --> 10:30.880\n So that these algorithms, resolution theorem proving and other algorithms can actually grind\n\n10:30.880 --> 10:37.040\n through all the logical consequences of what you said. And that ties into your question about how\n\n10:37.040 --> 10:43.760\n many of these things do you need? Because if the answer is small enough, then by hand, you could\n\n10:43.760 --> 10:56.880\n write them out one at a time. So in the early 1984, I held a meeting at Stanford where I was a\n\n10:57.920 --> 11:05.280\n faculty member there, where we assembled about half a dozen of the smartest people I know.\n\n11:05.280 --> 11:15.040\n People like Alan Newell and Marvin Minsky and Alan Kay and a few others.\n\n11:15.040 --> 11:19.120\n Was Feynman there by chance? Because he commented about your system,\n\n11:19.120 --> 11:20.480\n Eurisco, at the time.\n\n11:20.480 --> 11:22.560\n No, he wasn't part of this meeting.\n\n11:23.440 --> 11:25.120\n That's a heck of a meeting anyway.\n\n11:25.120 --> 11:32.640\n I think Ed Feigenbaum was there. I think Josh Lederberg was there. So we have all these different\n\n11:32.640 --> 11:41.200\n smart people. And we came together to address the question that you raised, which is, if it's\n\n11:41.200 --> 11:46.640\n important to represent common sense knowledge and world knowledge in order for AIs to not be\n\n11:46.640 --> 11:53.040\n brittle, in order for AIs not to just have the veneer of intelligence, well, how many pieces\n\n11:53.840 --> 11:59.520\n of common sense, how many if then rules, for instance, would we have to actually write in\n\n11:59.520 --> 12:06.160\n order to essentially cover what people expect perfect strangers to already know about the world?\n\n12:07.120 --> 12:14.960\n And I expected there would be an enormous divergence of opinion and computation. But\n\n12:14.960 --> 12:23.280\n amazingly, everyone got an answer which was around a million. And one person got the answer\n\n12:23.280 --> 12:30.800\n by saying, well, look, you can only burn into human long term memory a certain number of things\n\n12:30.800 --> 12:36.080\n per unit time, like maybe one every 30 seconds or something. And other than that, it's just short\n\n12:36.080 --> 12:41.920\n term memory and it flows away like water and so on. So by the time you're, say, 10 years old or so,\n\n12:42.480 --> 12:47.120\n how many things could you possibly have burned into your long term memory? And it's like about\n\n12:47.120 --> 12:52.560\n a million. Another person went in a completely different direction and said, well, if you look\n\n12:52.560 --> 13:00.800\n at the number of words in a dictionary, not a whole dictionary, but for someone to essentially\n\n13:00.800 --> 13:05.520\n be considered to be fluent in a language, how many words would they need to know? And then\n\n13:05.520 --> 13:10.800\n about how many things about each word would you have to tell it? And so they got to a million\n\n13:10.800 --> 13:20.400\n that way. Another person said, well, let's actually look at one single short, one volume\n\n13:20.400 --> 13:27.840\n desk encyclopedia article. And so we'll look at what was like a four paragraph article or\n\n13:27.840 --> 13:34.240\n something. I think about grebes. Grebes are a type of waterfowl. And if we were going to sit there\n\n13:34.240 --> 13:41.360\n and represent every single thing that was there, how many assertions or rules or statements would\n\n13:41.360 --> 13:46.400\n we have to write in this logical language and so on and then multiply that by all of the number of\n\n13:46.400 --> 13:52.400\n articles that there were and so on. So all of these estimates came out with a million. And so\n\n13:53.040 --> 14:00.160\n if you do the math, it turns out that like, oh, well, then maybe in something like 100\n\n14:01.360 --> 14:09.360\n person years in one or two person centuries, we could actually get this written down by hand.\n\n14:09.360 --> 14:19.360\n And a marvelous coincidence, an opportunity existed right at that point in time, the early 1980s.\n\n14:19.360 --> 14:25.440\n There was something called the Japanese fifth generation computing effort. Japan had threatened\n\n14:25.440 --> 14:32.000\n to do in computing and AI and hardware what they had just finished doing in consumer electronics\n\n14:32.000 --> 14:36.880\n and the automotive industry, namely resting control away from the United States and more\n\n14:36.880 --> 14:44.320\n generally away from the West. And so America was scared and Congress did something. That's how you\n\n14:44.320 --> 14:48.880\n know it was a long time ago because Congress did something. Congress passed something called the\n\n14:48.880 --> 14:55.280\n National Cooperative Research Act, NCRA. And what it said was, hey, all you big American companies,\n\n14:55.280 --> 14:59.600\n that's also how you know it was a long time ago because they were American companies rather than\n\n14:59.600 --> 15:05.600\n multinational companies. Hey, all you big American companies, normally it would be an antitrust\n\n15:05.600 --> 15:13.440\n violation if you colluded on R&D, but we promise for the next 10 years, we won't prosecute any of\n\n15:13.440 --> 15:20.880\n you if you do that to help combat this threat. And so overnight, the first two consortia,\n\n15:20.880 --> 15:27.920\n research consortia in America sprang up, both of them coincidentally in Austin, Texas. One called\n\n15:27.920 --> 15:34.400\n Semitech focusing on hardware chips and so on, and then one called MCC, the Microelectronics\n\n15:34.400 --> 15:41.200\n and Computer Technology Corporation, focusing more on software, on databases and AI and natural\n\n15:41.200 --> 15:48.400\n language understanding and things like that. And I got the opportunity, thanks to my friend Woody\n\n15:48.400 --> 15:54.880\n Bledsoe, who was one of the people who founded that, to come and be its principal scientist.\n\n15:54.880 --> 16:03.120\n And he sent Admiral Bob Inman, who was the person running MCC, came and talked to me and said,\n\n16:03.120 --> 16:06.720\n look, professor, you're talking about doing this project, it's going to involve\n\n16:08.160 --> 16:13.360\n centuries of effort. You've only got a handful of graduate students, you do the math, it's going to\n\n16:13.360 --> 16:20.160\n take you longer than the rest of your life to finish this project. But if you move to the wilds\n\n16:20.160 --> 16:27.200\n of Austin, Texas, we'll put 10 times as many people on it and you'll be done in a few years.\n\n16:27.200 --> 16:33.440\n And so that was pretty exciting. And so I did that. I took my leave from Stanford, I came to\n\n16:34.080 --> 16:40.480\n Austin, I worked for MCC. And the good news and bad news, the bad news is that all of us were\n\n16:40.480 --> 16:46.000\n off by an order of magnitude. That it turns out what you need are tens of millions of these\n\n16:47.200 --> 16:53.360\n pieces of knowledge about every day, sort of like if you have a coffee cup with stuff in it and you\n\n16:53.360 --> 16:58.400\n turn it upside down, the stuff in it's going to fall out. So you need tens of millions of pieces\n\n16:58.400 --> 17:04.400\n of knowledge like that, even if you take trouble to make each one as general as it possibly could\n\n17:04.400 --> 17:15.280\n be. But the good news was that thanks to initially the fifth generation effort and then later US\n\n17:15.280 --> 17:22.400\n government agency funding and so on, we were able to get enough funding, not for a couple person\n\n17:22.400 --> 17:27.680\n centuries of time, but for a couple person millennia of time, which is what we've spent\n\n17:27.680 --> 17:34.960\n since 1984, getting Psych to contain the tens of millions of rules that it needs in order to really\n\n17:34.960 --> 17:42.560\n capture and span not all of human knowledge, but the things that you assume other people know,\n\n17:42.560 --> 17:50.800\n the things you count on other people knowing. And so by now we've done that. And the good news is\n\n17:50.800 --> 17:59.440\n since you've waited 38 years just about to talk to me, we're about at the end of that process.\n\n17:59.440 --> 18:03.520\n So most of what we're doing now is not putting in even what you would consider common sense,\n\n18:03.520 --> 18:13.120\n but more putting in domain specific application specific knowledge about health care in a certain\n\n18:13.120 --> 18:22.400\n hospital or about oil pipes getting clogged up or whatever the applications happen to be. So\n\n18:22.400 --> 18:27.360\n we've almost come full circle and we're doing things very much like the expert systems of the\n\n18:27.360 --> 18:33.680\n 1970s and the 1980s, except instead of resting on nothing and being brittle, they're now resting on\n\n18:33.680 --> 18:40.000\n this massive pyramid, if you will, this massive lattice of common sense knowledge so that when\n\n18:40.000 --> 18:45.280\n things go wrong, when something unexpected happens, they can fall back on more and more and more\n\n18:45.280 --> 18:51.680\n general principles, eventually bottoming out in things like, for instance, if we have a problem\n\n18:51.680 --> 18:57.360\n with the microphone, one of the things you'll do is unplug it, plug it in again and hope for the\n\n18:57.360 --> 19:01.360\n best, right? Because that's one of the general pieces of knowledge you have in dealing with\n\n19:01.360 --> 19:06.640\n electronic equipment or software systems or things like that. Is there a basic principle\n\n19:06.640 --> 19:13.440\n like that? Is it possible to encode something that generally captures this idea of turn it off and\n\n19:13.440 --> 19:19.520\n turn it back on and see if it fixes? Oh, absolutely. That's one of the things that Psych knows.\n\n19:19.520 --> 19:23.360\n That's actually one of the fundamental laws of nature, I believe.\n\n19:25.040 --> 19:28.320\n I wouldn't call it a law. It's more like a...\n\n19:29.360 --> 19:34.160\n It seems to work every time. So it sure looks like a law. I don't know.\n\n19:34.160 --> 19:41.920\n So that basically covered the resources needed. And then we had to devise a method to actually\n\n19:41.920 --> 19:47.120\n figure out, well, what are the tens of millions of things that we need to tell the system?\n\n19:47.120 --> 19:54.560\n And for that, we found a few techniques which worked really well. One is to take any piece\n\n19:54.560 --> 19:59.920\n of text almost, it could be an advertisement, it could be a transcript, it could be a novel,\n\n19:59.920 --> 20:07.200\n it could be an article. And don't pay attention to the actual type that's there, the black space\n\n20:07.200 --> 20:12.800\n on the white page. Pay attention to the complement of that, the white space, if you will. So what did\n\n20:12.800 --> 20:18.400\n the writer of this sentence assume that the reader already knew about the world? For instance,\n\n20:18.400 --> 20:26.720\n if they used a pronoun, why did they think that you would be able to understand what the intended\n\n20:26.720 --> 20:31.520\n referent of that pronoun was? If they used an ambiguous word, how did they think that you\n\n20:31.520 --> 20:38.400\n would be able to figure out what they meant by that word? The other thing we look at is the gap\n\n20:38.400 --> 20:43.200\n between one sentence and the next one. What are all the things that the writer expected you to\n\n20:43.200 --> 20:47.840\n fill in and infer occurred between the end of one sentence and the beginning of the other?\n\n20:47.840 --> 20:56.880\n So if the sentence says, Fred Smith robbed the Third National Bank, period, he was sentenced to\n\n20:56.880 --> 21:02.240\n 20 years in prison, period. Well, between the first sentence and the second, you're expected\n\n21:02.240 --> 21:09.200\n to infer things like Fred got caught, Fred got arrested, Fred went to jail, Fred had a trial,\n\n21:09.200 --> 21:14.320\n Fred was found guilty, and so on. If my next sentence starts out with something like,\n\n21:14.320 --> 21:19.600\n the judge, dot, dot, dot, then you assume it's the judge at his trial. If my next sentence starts out\n\n21:19.600 --> 21:24.400\n something like, the arresting officer, dot, dot, dot, you assume that it was the police officer\n\n21:24.400 --> 21:30.480\n who arrested him after he committed the crime and so on. So those are two techniques for getting\n\n21:31.680 --> 21:41.040\n that knowledge. The other thing we sometimes look at is fake news or humorous onion headlines or\n\n21:41.040 --> 21:46.720\n headlines in the Weekly World News, if you know what that is, or the National Enquirer, where it's\n\n21:46.720 --> 21:51.600\n like, oh, we don't believe this, then we introspect on why don't we believe it. So there are things\n\n21:51.600 --> 21:59.520\n like, B17 lands on the moon. It's like, what do we know about the world that causes us to believe\n\n21:59.520 --> 22:05.760\n that that's just silly or something like that? Or another thing we look for are contradictions,\n\n22:05.760 --> 22:13.360\n contradictions, things which can't both be true. And we say, what is it that we know that causes\n\n22:13.360 --> 22:19.120\n us to know that both of these can't be true at the same time? For instance, in one of the Weekly\n\n22:19.120 --> 22:26.640\n World News editions, in one article, it talked about how Elvis was cited, even though he was\n\n22:27.200 --> 22:32.960\n getting on in years and so on. And another article in the same one talked about people seeing Elvis's\n\n22:32.960 --> 22:39.840\n ghost. So it's like, why do we believe that at least one of these articles must be wrong and so\n\n22:39.840 --> 22:46.640\n on? So we have a series of techniques like that that enable our people. And by now, we have about\n\n22:46.640 --> 22:52.160\n 50 people working full time on this and have for decades. So we've put in the thousands of person\n\n22:52.160 --> 22:59.120\n years of effort. We've built up these tens of millions of rules. We constantly police the system\n\n22:59.120 --> 23:07.200\n to make sure that we're saying things as generally as we possibly can. So you don't want to say things\n\n23:07.200 --> 23:14.320\n like, no mouse is also a moose. Because if you said things like that, then you'd have to add\n\n23:14.320 --> 23:20.560\n another one or two or three zeros onto the number of assertions you'd actually have to have. So\n\n23:21.200 --> 23:25.120\n at some point, we generalize things more and more and we get to a point where we say, oh,\n\n23:25.120 --> 23:31.840\n yeah, for any two biological taxons, if we don't know explicitly that one is a generalization of\n\n23:31.840 --> 23:37.280\n another, then almost certainly they're disjoint. A member of one is not going to be a member of the\n\n23:37.280 --> 23:41.840\n other and so on. And the same thing with the Elvis and the ghost. It has nothing to do with Elvis.\n\n23:41.840 --> 23:48.080\n It's more about human nature and the mortality and that kind of stuff. In general, things are\n\n23:48.080 --> 23:55.440\n not both alive and dead at the same time. Yeah. Unless special cats in theoretical physics examples.\n\n23:55.440 --> 24:00.720\n Well, that raises a couple important points. Well, that's the onion headline situation type of\n\n24:00.720 --> 24:04.880\n thing. Okay, sorry. But no, no. So what you bring up is this really important point of like, well,\n\n24:04.880 --> 24:12.960\n how do you handle exceptions and inconsistencies and so on? And one of the hardest lessons for us\n\n24:12.960 --> 24:21.200\n to learn, it took us about five years to really grit our teeth and learn to love it, is we had to\n\n24:21.200 --> 24:27.840\n give up global consistency. So the knowledge base can no longer be consistent. So this is a kind of\n\n24:27.840 --> 24:33.040\n scary thought. I grew up watching Star Trek and anytime a computer was inconsistent, it would\n\n24:33.040 --> 24:39.440\n either freeze up or explode or take over the world or something bad would happen. Or if you come from\n\n24:39.440 --> 24:44.960\n a mathematics background, once you can prove false, you can prove anything. So that's not good.\n\n24:45.760 --> 24:52.720\n And so on. So that's why the old knowledge based systems were all very, very consistent.\n\n24:52.720 --> 24:58.880\n But the trouble is that by and large, our models of the world, the way we talk about the world and\n\n24:58.880 --> 25:04.720\n so on, there are all sorts of inconsistencies that creep in here and there that will sort of\n\n25:04.720 --> 25:10.160\n kill some attempt to build some enormous globally consistent knowledge base. And so what we had to\n\n25:10.160 --> 25:17.440\n move to was a system of local consistency. So a good analogy is you know that the surface of the\n\n25:17.440 --> 25:26.000\n earth is more or less spherical globally, but you live your life every day as though the surface of\n\n25:26.000 --> 25:30.400\n the earth were flat. When you're talking to someone in Australia, you don't think of them\n\n25:30.400 --> 25:35.680\n as being oriented upside down to you. When you're planning a trip, even if it's a thousand miles\n\n25:35.680 --> 25:40.560\n away, you may think a little bit about time zones, but you rarely think about the curvature of the\n\n25:40.560 --> 25:46.000\n earth and so on. And for most purposes, you can live your whole life without really worrying about\n\n25:46.000 --> 25:53.040\n that because the earth is locally flat. In much the same way, the psych knowledge base is divided\n\n25:53.040 --> 25:59.600\n up into almost like tectonic plates, which are individual contexts. And each context is more\n\n25:59.600 --> 26:05.760\n or less consistent, but there can be small inconsistencies at the boundary between one\n\n26:05.760 --> 26:12.000\n context and the next one and so on. And so by the time you move say 20 contexts over,\n\n26:12.000 --> 26:17.680\n there could be glaring inconsistencies. So eventually you get from the normal modern\n\n26:17.680 --> 26:24.720\n real world context that we're in right now to something like roadrunner cartoon context where\n\n26:24.720 --> 26:29.520\n physics is very different. And in fact, life and death are very different because no matter how\n\n26:29.520 --> 26:37.280\n many times he's killed, the coyote comes back in the next scene and so on. So that was a hard\n\n26:37.280 --> 26:43.040\n lesson to learn. And we had to make sure that our representation language, the way that we actually\n\n26:43.040 --> 26:47.200\n encode the knowledge and represent it, was expressive enough that we could talk about\n\n26:47.200 --> 26:52.640\n things being true in one context and false in another, things that are true at one time and\n\n26:52.640 --> 26:57.840\n false in another, things that are true, let's say, in one region, like one country, but false\n\n26:57.840 --> 27:03.280\n in another, things that are true in one person's belief system, but false in another person's\n\n27:03.280 --> 27:08.000\n belief system, things that are true at one level of abstraction and false at another.\n\n27:08.000 --> 27:12.560\n For instance, at one level of abstraction, you think of this table as a solid object,\n\n27:12.560 --> 27:16.640\n but down at the atomic level, it's mostly empty space and so on.\n\n27:16.640 --> 27:23.200\n So then that's fascinating, but it puts a lot of pressure on context to do a lot of work.\n\n27:23.200 --> 27:28.800\n So you say tectonic plates, is it possible to formulate contexts that are general and big\n\n27:29.440 --> 27:36.000\n that do this kind of capture of knowledge bases? Or do you then get turtles on top of turtles,\n\n27:36.000 --> 27:39.200\n again, where there's just a huge number of contexts?\n\n27:39.200 --> 27:44.160\n So it's good you asked that question because you're pointed in the right direction, which is\n\n27:44.160 --> 27:50.800\n you want context to be first class objects in your system's knowledge base, in particular,\n\n27:50.800 --> 27:56.800\n in psych's knowledge base. And by first class object, I mean that we should be able to have\n\n27:56.800 --> 28:02.720\n psych think about and talk about and reason about one context or another context the same way it\n\n28:02.720 --> 28:11.040\n reasons about coffee cups and tables and people and fishing and so on. And so contexts are just\n\n28:11.040 --> 28:17.680\n terms in its language, just like the ones I mentioned. And so psych can reason about context,\n\n28:17.680 --> 28:24.800\n context can arrange hierarchically and so on. And so you can say things about, let's say,\n\n28:25.760 --> 28:32.320\n things that are true in the modern era, things that are true in a particular year would then be\n\n28:32.320 --> 28:39.280\n a subcontext of the things that are true in a broader, let's say, a century or a millennium\n\n28:39.280 --> 28:44.320\n or something like that. Things that are true in Austin, Texas are generally going to be a\n\n28:44.320 --> 28:50.640\n specialization of things that are true in Texas, which is going to be a specialization of things\n\n28:50.640 --> 28:56.240\n that are true in the United States and so on. And so you don't have to say things over and over\n\n28:56.240 --> 29:02.480\n again at all these levels. You just say things at the most general level that it applies to,\n\n29:02.480 --> 29:07.440\n and you only have to say it once, and then it essentially inherits to all these more specific\n\n29:07.440 --> 29:15.360\n contexts. To ask a slightly technical question, is this inheritance a tree or a graph?\n\n29:15.360 --> 29:20.400\n Oh, you definitely have to think of it as a graph. So we could talk about, for instance,\n\n29:20.400 --> 29:25.120\n why the Japanese fifth generation computing effort failed. There were about half a dozen\n\n29:25.120 --> 29:30.320\n different reasons. One of the reasons they failed was because they tried to represent\n\n29:30.320 --> 29:38.080\n knowledge as a tree rather than as a graph. And so each node in their representation\n\n29:39.280 --> 29:46.160\n could only have one parent node. So if you had a table that was a wooden object, a black object,\n\n29:46.160 --> 29:51.920\n a flat object, and so on, you have to choose one, and that's the only parent it could have.\n\n29:52.560 --> 29:57.520\n When, of course, depending on what it is you need to reason about it, sometimes it's important\n\n29:57.520 --> 30:02.000\n to know that it's made out of wood, like if we're talking about a fire. Sometimes it's important to\n\n30:02.000 --> 30:09.680\n know that it's flat if we're talking about resting something on it, and so on. So one of the problems\n\n30:09.680 --> 30:15.280\n was that they wanted a kind of Dewey decimal numbering system for all of their concepts,\n\n30:15.280 --> 30:21.600\n which meant that each node could only have at most 10 children, and each node could only have\n\n30:21.600 --> 30:30.800\n one parent. And while that does enable the Dewey decimal type numbering of concepts, labeling of\n\n30:30.800 --> 30:37.760\n concepts, it prevents you from representing all the things you need to about objects in our world.\n\n30:37.760 --> 30:42.720\n And that was one of the things which they never were able to overcome, and I think that was one\n\n30:42.720 --> 30:47.120\n of the main reasons that that project failed. So we'll return to some of the doors you've\n\n30:47.120 --> 30:53.440\n opened, but if we can go back to that room in 1984 around there with Marvin Minsky and Stanford.\n\n30:53.440 --> 30:59.520\n By the way, I should mention that Marvin wouldn't do his estimate until someone brought him an\n\n30:59.520 --> 31:05.280\n envelope so that he could literally do a back of the envelope calculation to come up with his number.\n\n31:07.280 --> 31:13.680\n Well, because I feel like the conversation in that room is an important one. You know,\n\n31:13.680 --> 31:19.040\n this is how sometimes science is done in this way. A few people get together\n\n31:19.040 --> 31:23.040\n and plant the seed of ideas, and they reverberate throughout history.\n\n31:23.040 --> 31:29.040\n And some kind of dissipate and disappear, and some, you know, Drake equation, and, you know,\n\n31:29.040 --> 31:33.920\n they, you know, seems like a meaningless equation, somewhat meaningless, but I think it drives and\n\n31:33.920 --> 31:39.360\n motivates a lot of scientists. And when the aliens finally show up, that equation will get even more\n\n31:39.360 --> 31:44.240\n valuable because then we'll get, be able to, in the long arc of history, the Drake equation\n\n31:45.760 --> 31:53.360\n will prove to be quite useful, I think. And in that same way, a conversation of just how many facts\n\n31:53.920 --> 31:57.760\n are required to capture the basic common sense knowledge of the world. That's a fascinating\n\n31:57.760 --> 32:02.960\n question. I want to distinguish between what you think of as facts and the kind of things that we\n\n32:02.960 --> 32:10.960\n represent. So we map to and essentially make sure that psych has the ability to, as it were, read\n\n32:10.960 --> 32:18.960\n and access the kind of facts you might find, say, in Wikidata or stated in a Wikipedia article or\n\n32:18.960 --> 32:23.280\n something like that. So what we're representing, the things that we need a small number of tens\n\n32:23.280 --> 32:29.440\n of millions of, are more like rules of thumb, rules of good guessing, things which are usually\n\n32:29.440 --> 32:37.840\n true and which help you to make sense of the facts that are sort of sitting off in some database or\n\n32:37.840 --> 32:43.680\n some other more static storage. So they're almost like platonic forms. So like when you read stuff\n\n32:43.680 --> 32:48.640\n on Wikipedia, that's going to be like projections of those ideas. You read an article about the fact\n\n32:48.640 --> 32:56.640\n that Elvis died, that's a projection of the idea that humans are mortal. And very few\n\n32:56.640 --> 33:01.920\n Wikipedia articles will write, humans are mortal. Exactly. That's what I meant about\n\n33:01.920 --> 33:07.440\n ferreting out the unstated things in text. What are all the things that were assumed? And so those\n\n33:07.440 --> 33:13.280\n are things like if you have a problem with something, turning it off and on often fixes\n\n33:13.280 --> 33:18.080\n it for reasons we don't really understand and we're not happy about. Or people can't be both\n\n33:18.080 --> 33:25.440\n alive and dead at the same time. Or water flows downhill. If you search online for water flowing\n\n33:25.440 --> 33:29.840\n uphill and water flowing downhill, you'll find more references for water flowing uphill because\n\n33:29.840 --> 33:36.640\n it's used as a kind of a metaphorical reference for some unlikely thing because of course,\n\n33:36.640 --> 33:41.680\n everyone already knows that water flows downhill. So why would anyone bother saying that?\n\n33:41.680 --> 33:46.800\n Do you have a word you prefer? Because we said facts isn't the right word. Is there a word like\n\n33:46.800 --> 33:53.280\n concepts? I would say assertions. Assertions or rules? Because I'm not talking about rigid rules,\n\n33:53.280 --> 33:59.760\n but rules of thumb. But assertions is a nice one that covers all of these things.\n\n33:59.760 --> 34:06.240\n Yeah. As a programmer, to me, assert has a very dogmatic authoritarian feel to them.\n\n34:06.240 --> 34:06.800\n Oh, I'm sorry.\n\n34:08.240 --> 34:13.280\n I'm so sorry. Okay. But assertions works. Okay. So if we go back to that room with\n\n34:13.280 --> 34:22.160\n Marvin Minsky with you, all these seminal figures, Ed Fagamon, thinking about this very\n\n34:22.160 --> 34:29.600\n philosophical, but also engineering question. We can also go back a couple of decades before then\n\n34:29.600 --> 34:33.600\n and thinking about artificial intelligence broadly when people were thinking about,\n\n34:34.160 --> 34:40.560\n you know, how do you create super intelligent systems, general intelligence. And I think\n\n34:40.560 --> 34:48.240\n people's intuition was off at the time. And I mean, this continues to be the case that we're not,\n\n34:48.240 --> 34:53.040\n when we're grappling with these exceptionally difficult ideas, we're not always, it's very\n\n34:53.040 --> 35:00.640\n difficult to truly understand ourselves when we're thinking about the human mind to introspect how\n\n35:00.640 --> 35:05.840\n difficult it is to engineer intelligence, to solve intelligence. We're not very good at estimating\n\n35:05.840 --> 35:11.600\n that. And you are somebody who has really stayed with this question for decades.\n\n35:11.600 --> 35:22.240\n What's your sense from the 1984 to today? Have you gotten a stronger sense of just how much\n\n35:22.240 --> 35:27.680\n knowledge is required? You've kind of said with some level of certainty that it's still on the\n\n35:27.680 --> 35:32.560\n order of magnitude of tens of millions. Right. For the first several years, I would have said that\n\n35:32.560 --> 35:40.720\n it was on the order of one or two million. And so it took us about five or six years to realize\n\n35:40.720 --> 35:47.440\n that we were off by a factor of 10. But I guess what I'm asking, you know, Marvin Misk is very\n\n35:47.440 --> 35:58.640\n confident in the 60s. Yes. Right. What's your sense if you, you know, 200 years from now,\n\n35:59.440 --> 36:05.280\n you're still, you know, you're not going to be any longer in this particular biological body,\n\n36:05.280 --> 36:11.520\n but your brain will still be in the digital form and you'll be looking back. Would you think you\n\n36:11.520 --> 36:18.320\n were smart today? Like your intuition was right? Or do you think you may be really off?\n\n36:19.120 --> 36:27.680\n So I think I'm right enough. And let me explain what I mean by that, which is sometimes like if\n\n36:27.680 --> 36:34.000\n you have an old fashioned pump, you have to prime the pump and then eventually it starts. So I think\n\n36:34.000 --> 36:41.200\n I'm right enough in the sense that what we've built, even if it isn't, so to speak, everything\n\n36:41.200 --> 36:51.120\n you need, it's primed the knowledge pump enough that psych can now itself help to learn more and\n\n36:51.120 --> 36:56.560\n more automatically on its own by reading things and understanding and occasionally asking questions\n\n36:56.560 --> 37:02.240\n like a student would or something and by doing experiments and discovering things on its own\n\n37:02.240 --> 37:09.040\n and so on. So through a combination of psych powered discovery and psych powered reading,\n\n37:09.760 --> 37:15.360\n it will be able to bootstrap itself. Maybe it's the final 2%, maybe it's the final 99%.\n\n37:16.240 --> 37:24.000\n So even if I'm wrong, all I really need to build is a system which has primed the pump enough\n\n37:24.000 --> 37:31.200\n that it can begin that cascade upward, that self reinforcing sort of quadratically,\n\n37:31.200 --> 37:39.200\n or maybe even exponentially increasing path upward that we get from, for instance, talking with each\n\n37:39.200 --> 37:45.760\n other. That's why humans today know so much more than humans 100,000 years ago. We're not really\n\n37:45.760 --> 37:50.720\n that much smarter than people were 100,000 years ago, but there's so much more knowledge and we\n\n37:50.720 --> 37:56.560\n have language and we can communicate, we can check things on Google and so on. So effectively,\n\n37:56.560 --> 38:02.560\n we have this enormous power at our fingertips and there's almost no limit to how much you could\n\n38:02.560 --> 38:07.200\n learn if you wanted to because you've already gotten to a certain level of understanding of\n\n38:07.200 --> 38:12.240\n the world that enables you to read all these articles and understand them, that enables you\n\n38:12.240 --> 38:17.360\n to go out and if necessary, do experiments although that's slower as a way of gathering data\n\n38:18.160 --> 38:24.160\n and so on. And I think this is really an important point, which is if we have artificial\n\n38:24.160 --> 38:28.880\n intelligence, real general artificial intelligence, human level artificial intelligence,\n\n38:29.440 --> 38:37.600\n then people will become smarter. It's not so much that it'll be us versus the AIs, it's more like\n\n38:37.600 --> 38:43.920\n us and the AIs together. We'll be able to do things that require more creativity, that would\n\n38:43.920 --> 38:48.640\n take too long right now, but we'll be able to do lots of things in parallel. We'll be able to\n\n38:48.640 --> 38:56.640\n misunderstand each other less. There's all sorts of value that effectively for an individual would\n\n38:56.640 --> 39:02.960\n mean that individual will for all intents and purposes be smarter and that means that humanity\n\n39:02.960 --> 39:09.680\n as a species will be smarter. And when was the last time that any invention qualitatively\n\n39:10.720 --> 39:16.160\n made a huge difference in human intelligence? You have to go back a long ways. It wasn't like the\n\n39:16.160 --> 39:21.760\n internet or the computer or mathematics or something. It was all the way back to the\n\n39:22.400 --> 39:28.560\n development of language. We sort of look back on prelinguistic cavemen as well.\n\n39:29.840 --> 39:35.600\n They weren't really intelligent, were they? They weren't really human, were they? And I think that\n\n39:36.320 --> 39:42.240\n as you said, 50, 100, 200 years from now, people will look back on people today\n\n39:42.240 --> 39:51.760\n right before the advent of these sort of lifelong general AI uses and say,\n\n39:51.760 --> 39:55.520\n you know, those poor people, they weren't really human, were they?\n\n39:55.520 --> 40:00.800\n Mm hmm. Exactly. So you said a lot of really interesting things. By the way, I would maybe\n\n40:00.800 --> 40:12.960\n try to argue that the internet is on the order of the kind of big leap in improvement that the\n\n40:12.960 --> 40:17.200\n invention of language was. Well, it's certainly a big leap in one direction. We're not sure whether\n\n40:17.200 --> 40:22.720\n it's upward or downward. Well, I mean very specific parts of the internet, which is access to information\n\n40:22.720 --> 40:28.240\n like a website like Wikipedia, like ability for human beings from across the world to access\n\n40:28.240 --> 40:33.120\n information very quickly. So I could take either side of this argument. And since you just took\n\n40:33.120 --> 40:40.880\n one side, I'll give you the other side, which is that almost nothing has done more harm than\n\n40:40.880 --> 40:47.520\n something like the internet and access to that information in two ways. One is it's made people\n\n40:47.520 --> 40:56.800\n more globally ignorant in the same way that calculators made us more or less innumerate.\n\n40:56.800 --> 41:02.800\n So when I was growing up, we had to use slide rules. We had to be able to estimate and so on.\n\n41:02.800 --> 41:08.320\n Today, people don't really understand numbers. They don't really understand math. They don't\n\n41:08.320 --> 41:13.360\n really estimate very well at all and so on. They don't really understand the difference\n\n41:13.360 --> 41:20.320\n between trillions and billions and millions and so on very well because calculators do that all\n\n41:20.320 --> 41:29.920\n for us. And thanks to things like the internet and search engines, that same kind of juvenileism\n\n41:30.560 --> 41:35.600\n is reinforced in making people essentially be able to live their whole lives, not just without\n\n41:35.600 --> 41:40.880\n being able to do arithmetic and estimate, but now without actually having to really know almost\n\n41:40.880 --> 41:44.880\n anything because anytime they need to know something, they'll just go and look it up.\n\n41:44.880 --> 41:48.640\n You're right. And I could tell you could play both sides of this and it is a double edged sword.\n\n41:48.640 --> 41:52.160\n You can, of course, say the same thing about language. Probably people when they invented\n\n41:52.160 --> 41:58.560\n language, they would criticize. It used to be if we're angry, we would just kill a person. And if\n\n41:58.560 --> 42:02.960\n we're in love, we would just have sex with them. And now everybody's writing poetry and bullshit.\n\n42:04.160 --> 42:09.680\n You should just be direct. You should have physical contact. Enough of this words and books.\n\n42:11.040 --> 42:15.040\n You're not actually experiencing. If you read a book, you're not experiencing the thing. This\n\n42:15.040 --> 42:19.120\n is nonsense. That's right. If you read a book about how to make butter, that's not the same\n\n42:19.120 --> 42:24.800\n as if you had to learn it and do it yourself and so on. So let's just say that something is gained,\n\n42:24.800 --> 42:32.880\n but something is lost every time you have these sorts of dependencies on technology.\n\n42:33.600 --> 42:41.040\n And overall, I think that having smarter individuals and having smarter AI augmented\n\n42:41.040 --> 42:47.840\n human species will be one of the few ways that we'll actually be able to overcome some of the\n\n42:47.840 --> 42:54.880\n global problems we have involving poverty and starvation and global warming and overcrowding,\n\n42:54.880 --> 43:01.840\n all the other problems that are besetting the planet. We really need to be smarter.\n\n43:01.840 --> 43:09.280\n And there are really only two routes to being smarter. One is through biochemistry and genetics.\n\n43:09.280 --> 43:16.720\n Genetic engineering. The other route is through having general AIs that augment our intelligence.\n\n43:17.680 --> 43:27.680\n And hopefully one of those two ways of paths to salvation will come through before it's too late.\n\n43:27.680 --> 43:35.440\n Yeah, so I agree with you. And obviously, as an engineer, I have a better sense and an optimism\n\n43:35.440 --> 43:39.600\n about the technology side of things because you can control things there more. Biology is just\n\n43:39.600 --> 43:45.520\n such a giant mess. We're living through a pandemic now. There's so many ways that nature can just be\n\n43:45.520 --> 43:51.280\n just destructive and destructive in a way where it doesn't even notice you. It's not like a battle\n\n43:51.840 --> 43:57.440\n of humans versus virus. It's just like, huh, okay. And then you can just wipe out an entire species.\n\n43:57.440 --> 44:07.600\n The other problem with the internet is that it has enabled us to surround ourselves with an\n\n44:07.600 --> 44:15.520\n echo chamber, with a bubble of like minded people, which means that you can have truly bizarre\n\n44:16.560 --> 44:23.600\n theories, conspiracy theories, fake news, and so on, promulgate and surround yourself with people\n\n44:23.600 --> 44:29.840\n who essentially reinforce what you want to believe or what you already believe about the world.\n\n44:30.720 --> 44:37.520\n And in the old days, that was much harder to do when you had, say, only three TV networks,\n\n44:37.520 --> 44:42.560\n or even before when you had no TV networks and you had to actually look at the world and make your\n\n44:42.560 --> 44:47.280\n own reasoned decisions. I like the push and pull of our dance that we're doing because then I'll\n\n44:47.280 --> 44:52.240\n just say in the old world, having come from the Soviet Union, because you had one or a couple of\n\n44:52.240 --> 44:56.480\n networks, then propaganda could be much more effective. And then the government can overpower\n\n44:56.480 --> 45:03.760\n its people by telling you the truth and then starving millions and torturing millions and\n\n45:03.760 --> 45:09.360\n putting millions into camps and starting wars with a propaganda machine, allowing you to believe\n\n45:09.360 --> 45:14.240\n that you're actually doing good in the world. With the internet, because of all the quote unquote\n\n45:14.240 --> 45:19.600\n conspiracy theories, some of them are actually challenging the power centers, the very kind of\n\n45:19.600 --> 45:26.800\n power centers that a century ago would have led to the death of millions. So there's, again, this\n\n45:26.800 --> 45:32.720\n double edged sword. And I very much agree with you on the AI side. It's often an intuition that\n\n45:32.720 --> 45:40.640\n people have that somehow AI will be used to maybe overpower people by certain select groups. And to\n\n45:40.640 --> 45:46.000\n me, it's not at all obvious that that's the likely scenario. To me, the likely scenario, especially\n\n45:46.000 --> 45:51.200\n just having observed the trajectory of technology, is it'll be used to empower people. It'll be used\n\n45:51.200 --> 45:59.360\n to extend the capabilities of individuals across the world, because there's a lot of money to be\n\n45:59.360 --> 46:04.000\n made that way. Improving people's lives, you can make a lot of money. I agree. I think that the\n\n46:05.600 --> 46:15.520\n main thing that AI prostheses, AI amplifiers will do for people is make it easier, maybe even\n\n46:15.520 --> 46:22.880\n unavoidable, for them to do good critical thinking. So pointing out logical fallacies,\n\n46:22.880 --> 46:29.760\n logical contradictions and so on, in things that they otherwise would just blithely believe,\n\n46:31.040 --> 46:39.920\n pointing out essentially data which they should take into consideration if they really want to\n\n46:39.920 --> 46:46.560\n learn the truth about something and so on. So I think doing not just educating in the sense of\n\n46:47.120 --> 46:53.360\n pouring facts into people's heads, but educating in the sense of arming people with the ability to do\n\n46:53.360 --> 47:01.360\n good critical thinking is enormously powerful. The education system that we have in the US and\n\n47:01.360 --> 47:08.160\n worldwide generally don't do a good job of that. But I believe that the AI...\n\n47:08.160 --> 47:14.800\n The AIs will. The AIs will, the AIs can and will. In the same way that everyone can have their own\n\n47:15.920 --> 47:23.360\n Alexa or Siri or Google Assistant or whatever, everyone will have this sort of cradle to grave\n\n47:24.160 --> 47:29.600\n assistant which will get to know you, which you'll get to trust, it'll model you, you'll model it,\n\n47:30.560 --> 47:37.200\n and it'll call to your attention things which will in some sense make your life better, easier,\n\n47:37.200 --> 47:45.600\n less mistake ridden and so on, less regret ridden if you listen to it.\n\n47:45.600 --> 47:51.920\n Yeah, I'm in full agreement with you about this space of technologies and I think it's super\n\n47:51.920 --> 47:57.440\n exciting. And from my perspective, integrating emotional intelligence, so even things like\n\n47:57.440 --> 48:04.320\n friendship and companionship and love into those kinds of systems, as opposed to helping you just\n\n48:04.320 --> 48:09.520\n grow intellectually as a human being, allow you to grow emotionally, which is ultimately what makes\n\n48:09.520 --> 48:16.960\n life amazing, is to sort of, you know, the old pursuit of happiness. So it's not just the pursuit\n\n48:16.960 --> 48:22.880\n of reason, it's the pursuit of happiness too. The full spectrum. Well, let me sort of, because you\n\n48:22.880 --> 48:30.000\n mentioned so many fascinating things, let me jump back to the idea of automated reasoning. So the\n\n48:30.000 --> 48:36.720\n the acquisition of new knowledge has been done in this very interesting way, but primarily by humans\n\n48:37.920 --> 48:45.600\n doing this. Just you can think of monks in their cells in medieval Europe, you know, carefully\n\n48:45.600 --> 48:51.600\n illuminating manuscripts and so on. It's a very difficult and amazing process actually because\n\n48:51.600 --> 48:58.640\n it allows you to truly ask the question about the in the white space, what is assumed. I think this\n\n48:58.640 --> 49:07.040\n exercise is like very few people do this, right? They just do it subconsciously. They perform this.\n\n49:07.040 --> 49:14.720\n By definition, right? Because those pieces of elided, of omitted information, of those missing\n\n49:14.720 --> 49:21.920\n steps, as it were, are pieces of common sense. If you actually included all of them, it would\n\n49:21.920 --> 49:26.560\n almost be offensive or confusing to the reader. It's like, why are they telling me all these? Of\n\n49:26.560 --> 49:34.080\n course I know all these things. And so it's one of these things which almost by its very nature\n\n49:35.760 --> 49:42.640\n has almost never been explicitly written down anywhere because by the time you're old enough\n\n49:42.640 --> 49:49.840\n to talk to other people and so on, if you survived to that age, presumably you already got pieces of\n\n49:49.840 --> 49:55.600\n common sense. Like if something causes you pain whenever you do it, probably not a good idea to\n\n49:55.600 --> 50:04.160\n keep doing it. So what ideas do you have, given how difficult this step is, what ideas are there\n\n50:04.160 --> 50:12.720\n for how to do it automatically without using humans or at least not doing like a large\n\n50:12.720 --> 50:18.080\n percentage of the work for humans and then humans only do the very high level supervisory work?\n\n50:18.080 --> 50:25.920\n So we have, in fact, two directions we're pushing on very, very heavily currently at PsychCorp. And\n\n50:25.920 --> 50:30.880\n one involves natural language understanding and the ability to read what people have explicitly\n\n50:30.880 --> 50:40.160\n written down and to pull knowledge in that way. But the other is to build a series of knowledge\n\n50:40.160 --> 50:49.040\n editing tools, knowledge entry tools, knowledge capture tools, knowledge testing tools and so on.\n\n50:49.040 --> 50:55.280\n Think of them as like user interface suite of software tools if you want, something that will\n\n50:55.280 --> 51:03.920\n help people to more or less automatically expand and extend the system in areas where, for instance,\n\n51:03.920 --> 51:08.560\n they want to build some app, have it do some application or something like that. So I'll give\n\n51:08.560 --> 51:14.800\n you an example of one, which is something called abduction. So you've probably heard of like\n\n51:14.800 --> 51:25.120\n deduction and induction and so on. But abduction is unlike those, abduction is not sound, it's just\n\n51:25.120 --> 51:33.840\n useful. So for instance, deductively, if someone is out in the rain and they're going to get all\n\n51:33.840 --> 51:42.000\n wet and when they enter a room, they might be all wet and so on. So that's deduction. But if someone\n\n51:42.000 --> 51:47.840\n were to walk into the room right now and they were dripping wet, we would immediately look\n\n51:47.840 --> 51:54.160\n outside to say, oh, did it start to rain or something like that. Now, why did we say maybe\n\n51:54.160 --> 51:59.760\n it started to rain? That's not a sound logical inference, but it's certainly a reasonable\n\n51:59.760 --> 52:06.320\n abductive leap to say, well, one of the most common ways that a person would have gotten\n\n52:06.320 --> 52:14.160\n dripping wet is if they had gotten caught out in the rain or something like that. So what does that\n\n52:14.160 --> 52:18.480\n have to do with what we were talking about? So suppose you're building one of these applications\n\n52:18.480 --> 52:24.400\n and the system gets some answer wrong and you say, oh, yeah, the answer to this question is\n\n52:24.400 --> 52:30.400\n this one, not the one you came up with. Then what the system can do is it can use everything it\n\n52:30.400 --> 52:34.400\n already knows about common sense, general knowledge, the domain you've already been\n\n52:34.400 --> 52:41.760\n telling it about, and context like we talked about and so on and say, well, here are seven\n\n52:41.760 --> 52:48.400\n alternatives, each of which I believe is plausible, given everything I already know. And if any of\n\n52:48.400 --> 52:53.520\n these seven things were true, I would have come up with the answer you just gave me instead of the\n\n52:53.520 --> 52:59.200\n wrong answer I came up with. Is one of these seven things true? And then you, the expert, will look\n\n52:59.200 --> 53:04.560\n at those seven things and say, oh, yeah, number five is actually true. And so without actually\n\n53:04.560 --> 53:11.920\n having to tinker down at the level of logical assertions and so on, you'll be able to educate\n\n53:11.920 --> 53:16.720\n the system in the same way that you would help educate another person who you were trying to\n\n53:16.720 --> 53:22.320\n apprentice or something like that. So that significantly reduces the mental effort\n\n53:22.880 --> 53:28.400\n or significantly increases the efficiency of the teacher, the human teacher. Exactly. And it makes\n\n53:28.400 --> 53:36.400\n more or less anyone able to be a teacher in that way. So that's part of the answer. And then the\n\n53:36.400 --> 53:44.160\n other is that the system on its own will be able to, through reading, through conversations with\n\n53:44.160 --> 53:52.560\n other people and so on, learn the same way that you or I or other humans do. First of all, that's\n\n53:52.560 --> 53:57.600\n a beautiful vision. I'll have to ask you about Semantic Web in a second here. But first,\n\n53:57.600 --> 54:04.000\n are there, when we talk about specific techniques, do you find something inspiring or directly useful\n\n54:04.000 --> 54:08.960\n from the whole space of machine learning, deep learning, these kinds of spaces of techniques that\n\n54:08.960 --> 54:15.760\n have been shown effective for certain kinds of problems in the recent, now, decade and a half?\n\n54:15.760 --> 54:23.840\n I think of the machine learning work as more or less what our right brain has been able to do.\n\n54:23.840 --> 54:29.680\n I think of the machine learning work as more or less what our right brain hemispheres do. So\n\n54:30.880 --> 54:39.200\n being able to take a bunch of data and recognize patterns, being able to statistically infer\n\n54:39.200 --> 54:47.360\n things and so on. And I certainly wouldn't want to not have a right brain hemisphere,\n\n54:47.360 --> 54:51.680\n but I'm also glad that I have a left brain hemisphere as well, something that can\n\n54:51.680 --> 54:57.520\n metaphorically sit back and puff on its pipe and think about this thing over here. It's like,\n\n54:57.520 --> 55:03.520\n why might this have been true? And what are the implications of it? How should I feel about that\n\n55:03.520 --> 55:11.120\n and why and so on? So thinking more deeply and slowly, what Kahneman called thinking slowly\n\n55:11.120 --> 55:16.160\n versus thinking quickly, whereas you want machine learning to think quickly, but you want the\n\n55:16.160 --> 55:22.480\n ability to think deeply, even if it's a little slower. So I'll give you an example of a project\n\n55:22.480 --> 55:30.960\n we did recently with NIH involving the Cleveland Clinic and a couple other institutions that we ran\n\n55:30.960 --> 55:37.200\n a project for. And what it did was it took GWAS's genome wide association studies.\n\n55:37.200 --> 55:46.720\n Those are big databases of patients that came into a hospital. They got their DNA sequenced\n\n55:46.720 --> 55:54.000\n because the cost of doing that has gone from infinity to billions of dollars to $100 or so.\n\n55:54.880 --> 55:59.760\n And so now patients routinely get their DNA sequenced. So you have these big databases\n\n55:59.760 --> 56:06.320\n of the SNPs, the single nucleotide polymorphisms, the point mutations in a patient's DNA,\n\n56:06.320 --> 56:11.840\n and the disease that happened to bring them into the hospital. So now you can do correlation\n\n56:11.840 --> 56:20.880\n studies, machine learning studies of which mutations are associated with and led to which\n\n56:20.880 --> 56:27.920\n physiological problems and diseases and so on, like getting arthritis and so on. And the problem\n\n56:27.920 --> 56:34.080\n is that those correlations turn out to be very spurious. They turn out to be very noisy. Very\n\n56:34.080 --> 56:40.960\n many of them have led doctors onto wild goose chases and so on. And so they wanted a way of\n\n56:40.960 --> 56:46.960\n eliminating or the bad ones are focusing on the good ones. And so this is where psych comes in,\n\n56:46.960 --> 56:53.040\n which is psych takes those sort of A to Z correlations between point mutations and\n\n56:53.760 --> 57:00.240\n the medical condition that needs treatment. And we say, okay, let's use all this public knowledge\n\n57:00.240 --> 57:05.600\n and common sense knowledge about what reactions occur where in the human body,\n\n57:06.240 --> 57:12.400\n what polymerizes what, what catalyzes what reactions and so on. And let's try to put together\n\n57:12.400 --> 57:20.400\n a 10 or 20 or 30 step causal explanation of why that mutation might have caused\n\n57:20.400 --> 57:25.920\n that medical condition. And so psych would put together in some sense, some Rube Goldberg like\n\n57:25.920 --> 57:35.920\n a chain that would say, oh yeah, that mutation if it got expressed would be this altered protein,\n\n57:35.920 --> 57:40.480\n which because of that, if it got to this part of the body would catalyze this reaction. And by the\n\n57:40.480 --> 57:46.240\n way, that would cause more bioactive vitamin D in the person's blood. And anyway, 10 steps later,\n\n57:46.240 --> 57:52.640\n that screws up bone resorption and that's why this person got osteoporosis early in life and so on.\n\n57:52.640 --> 57:55.760\n So that's human interpretable or at least docs are human interpretable.\n\n57:55.760 --> 58:04.160\n Exactly. And the important thing even more than that is you shouldn't really trust that 20 step\n\n58:05.520 --> 58:12.160\n Rube Goldberg chain any more than you trust that initial A to Z correlation except two things. One,\n\n58:12.160 --> 58:19.760\n if you can't even think of one causal chain to explain this, then that correlation probably was\n\n58:19.760 --> 58:27.040\n just noise to begin with. And secondly, and even more powerfully, along the way that causal chain\n\n58:27.040 --> 58:32.240\n will make predictions like the one about having more bioactive vitamin D in your blood. So you\n\n58:32.240 --> 58:38.800\n can now go back to the data about these patients and say, by the way, did they have slightly\n\n58:38.800 --> 58:44.400\n elevated levels of bioactive vitamin D in their blood and so on? And if the answer is no, that\n\n58:44.400 --> 58:50.800\n strongly disconfirms your whole causal chain. And if the answer is yes, that somewhat confirms\n\n58:50.800 --> 58:57.280\n that causal chain. And so using that, we were able to take these correlations from this GWAS\n\n58:57.280 --> 59:06.400\n database and we were able to essentially focus the researchers attention on the very small\n\n59:06.400 --> 59:12.720\n percentage of correlations that had some explanation and even better some explanation\n\n59:12.720 --> 59:17.280\n that also made some independent prediction that they could confirm or disconfirm by looking at\n\n59:17.280 --> 59:23.120\n the data. So think of it like this kind of synergy where you want the right brain machine learning\n\n59:23.120 --> 59:31.360\n to quickly come up with possible answers. You want the left brain psych like AI to think about that\n\n59:31.360 --> 59:36.320\n and think about why that might have been the case and what else would be the case if that were true\n\n59:36.320 --> 59:43.520\n and so on, and then suggest things back to the right brain to quickly check out again. So it's\n\n59:43.520 --> 59:49.440\n that kind of synergy back and forth, which I think is really what's going to lead to general AI, not\n\n59:50.480 --> 59:55.520\n narrow, brittle machine learning systems and not just something like psych.\n\n59:55.520 --> 1:00:00.640\n Okay. So that's a brilliant synergy. But I was also thinking in terms of the automated expansion\n\n1:00:00.640 --> 1:00:07.440\n of the knowledge base, you mentioned NLU. This is very early days in the machine learning space\n\n1:00:07.440 --> 1:00:13.200\n of this, but self supervised learning methods, you know, you have these language models, GPT3\n\n1:00:13.200 --> 1:00:19.920\n and so on, that just read the internet and they form representations that can then be mapped to\n\n1:00:19.920 --> 1:00:25.120\n something useful. The question is, what is the useful thing? Like they're now playing with a\n\n1:00:25.120 --> 1:00:30.800\n pretty cool thing called OpenAI Codex, which is generating programs from documentation. Okay,\n\n1:00:30.800 --> 1:00:35.520\n that's kind of useful. It's cool. But my question is, can it be used to generate\n\n1:00:37.200 --> 1:00:45.360\n in part, maybe with some human supervision, psych like assertions, help feed psych more assertions\n\n1:00:45.360 --> 1:00:51.840\n from this giant body of internet data? Yes, that is in fact, one of our goals is\n\n1:00:51.840 --> 1:00:55.680\n how can we harness machine learning? How can we harness natural language processing\n\n1:00:56.480 --> 1:01:02.640\n to increasingly automate the knowledge acquisition process, the growth of psych? And that's what I\n\n1:01:02.640 --> 1:01:09.600\n meant by priming the pump that, you know, if you sort of learn things at the fringe of what you\n\n1:01:09.600 --> 1:01:14.240\n know already, you learn this new thing is similar to what you know already, and here are the\n\n1:01:14.240 --> 1:01:19.440\n differences and the new things you had to learn about it and so on. So the more you know, the more\n\n1:01:19.440 --> 1:01:24.560\n and more easily you can learn new things. But unfortunately, inversely, if you don't really\n\n1:01:24.560 --> 1:01:31.760\n know anything, it's really hard to learn anything. And so if you're not careful, if you start out with\n\n1:01:31.760 --> 1:01:39.280\n too small sort of a core to start this process, it never really takes off. And so that's why I\n\n1:01:39.280 --> 1:01:44.880\n view this as a pump priming exercise to get a big enough manually produced, even though that's kind\n\n1:01:44.880 --> 1:01:51.040\n of ugly duckling technique, put in the elbow grease to produce a large enough core that you\n\n1:01:51.040 --> 1:01:58.720\n will be able to do all the kinds of things you're imagining without sort of ending up with the kind\n\n1:01:58.720 --> 1:02:09.920\n of wacky brittlenesses that we see, for example, in GPT3, where you'll tell it a story about\n\n1:02:09.920 --> 1:02:23.200\n someone plotting to poison someone and so on. And then GPT3 says, you say, what's the very next\n\n1:02:23.200 --> 1:02:27.120\n sentence? And the next sentence is, oh yeah, that person then drank the poison they just put together.\n\n1:02:27.120 --> 1:02:36.560\n It's like, that's probably not what happened. Or if you go to Siri and I think I have, where can\n\n1:02:36.560 --> 1:02:43.520\n I go for help with my alcohol problem or something, it'll come back and say, I found seven liquor\n\n1:02:43.520 --> 1:02:52.560\n stores near you and so on. So it's one of these things where, yes, it may be helpful most of the\n\n1:02:52.560 --> 1:02:59.200\n time. It may even be correct most of the time. But if it doesn't really understand what it's saying,\n\n1:02:59.200 --> 1:03:03.360\n and if it doesn't really understand why things are true and doesn't really understand how the\n\n1:03:03.360 --> 1:03:09.280\n world works, then some fraction of the time it's going to be wrong. Now, if your only goal is to\n\n1:03:09.280 --> 1:03:16.560\n sort of find relevant information like search engines do, then being right 90% of the time is\n\n1:03:16.560 --> 1:03:24.720\n fantastic. That's unbelievably great. However, if your goal is to save the life of your child who\n\n1:03:24.720 --> 1:03:31.760\n has some medical problem or your goal is to be able to drive for the next 10,000 hours of driving\n\n1:03:31.760 --> 1:03:39.200\n without getting into a fatal accident and so on, then error rates down at the 10% level or even\n\n1:03:39.200 --> 1:03:46.960\n the 1% level are not really acceptable. I like the model of where that learning happens at the edge\n\n1:03:46.960 --> 1:03:53.440\n and then you kind of think of knowledge as this sphere. So you want a large sphere because the\n\n1:03:54.080 --> 1:04:00.240\n learning is happening on the surface. Exactly. So what you can learn next\n\n1:04:00.240 --> 1:04:05.200\n increases quadratically as the diameter of that sphere goes up.\n\n1:04:05.200 --> 1:04:09.840\n It's nice because you think when you know nothing, it's like you can learn anything,\n\n1:04:09.840 --> 1:04:14.880\n but the reality, not really. Right. If you know nothing, you can really learn nothing.\n\n1:04:15.760 --> 1:04:25.920\n You can appear to learn. One of the anecdotes I could go back and give you about why I feel so\n\n1:04:25.920 --> 1:04:36.000\n strongly about this personally was in 1980, 1981, my daughter Nicole was born and she's actually\n\n1:04:36.000 --> 1:04:43.520\n doing fine now. But when she was a baby, she was diagnosed as having meningitis and doctors wanted\n\n1:04:43.520 --> 1:04:52.720\n to do all these scary things. And my wife and I were very worried and we could not get a meaningful\n\n1:04:52.720 --> 1:04:58.720\n answer from her doctors about exactly why they believed this, what the alternatives were,\n\n1:04:58.720 --> 1:05:05.120\n and so on. And fortunately, a friend of mine, Ted Shortliffe, was another assistant professor\n\n1:05:05.120 --> 1:05:11.520\n in computer science at Stanford at the time. And he'd been building a program called MISON,\n\n1:05:11.520 --> 1:05:18.160\n which was a medical diagnosis program that happened to specialize in blood infections\n\n1:05:18.160 --> 1:05:23.120\n like meningitis. And so, he had privileges at Stanford Hospital because he was also an MD.\n\n1:05:23.920 --> 1:05:29.680\n And so, we got hold of her chart and we put in her case and it came up with exactly the same\n\n1:05:29.680 --> 1:05:34.640\n diagnoses and exactly the same therapy recommendations. But the difference was,\n\n1:05:34.640 --> 1:05:39.280\n because it was a knowledge based system, a rule based system, it was able to tell us\n\n1:05:39.280 --> 1:05:49.520\n step by step by step why this was the diagnosis and step by step why this was the best therapy\n\n1:05:49.520 --> 1:05:56.640\n and the best procedure to do for her and so on. And there was a real epiphany because that made\n\n1:05:56.640 --> 1:06:01.040\n all the difference in the world. Instead of blindly having to trust an authority,\n\n1:06:01.040 --> 1:06:08.400\n we were able to understand what was actually going on. And so, at that time, I realized that\n\n1:06:08.400 --> 1:06:13.280\n that really is what was missing in computer programs was that even if they got things right,\n\n1:06:13.840 --> 1:06:20.160\n because they didn't really understand the way the world works and why things are the way they are,\n\n1:06:20.160 --> 1:06:27.200\n they weren't able to give explanations of their answer. And it's one thing to use a machine\n\n1:06:27.200 --> 1:06:33.200\n learning system that says, I think you should get this operation and you say why and it says\n\n1:06:33.200 --> 1:06:40.720\n 0.83 and you say no, in more detail why and it says 0.831. That's not really very compelling\n\n1:06:40.720 --> 1:06:47.120\n and that's not really very helpful. There's this idea of the Semantic Web that when I first heard\n\n1:06:47.120 --> 1:06:51.760\n about, I just fell in love with the idea. It was the obvious next step for the internet.\n\n1:06:51.760 --> 1:06:58.160\n Sure. And maybe you can speak about what is the Semantic Web? What are your thoughts about it? How\n\n1:06:58.160 --> 1:07:05.120\n your vision and mission and goals with Psych are connected, integrated? Are they dance partners? Are\n\n1:07:05.120 --> 1:07:10.240\n they aligned? What are your thoughts there? So, think of the Semantic Web as a kind of\n\n1:07:10.240 --> 1:07:17.040\n knowledge graph and Google already has something they call knowledge graph, for example, which is\n\n1:07:17.040 --> 1:07:25.440\n sort of like a node and link diagram. So, you have these nodes that represent concepts or words or\n\n1:07:25.440 --> 1:07:32.960\n terms and then there are some arcs that connect them that might be labeled. And so, you might have\n\n1:07:32.960 --> 1:07:44.960\n a node with like one person that represents one person and let's say a husband link that then\n\n1:07:44.960 --> 1:07:50.720\n points to that person's husband. And so, there'd be then another link that went from that person\n\n1:07:50.720 --> 1:07:59.160\n labeled wife that went back to the first node and so on. So, having this kind of representation is\n\n1:07:59.160 --> 1:08:08.480\n really good if you want to represent binary relations, essentially relations between two\n\n1:08:08.480 --> 1:08:20.280\n things. So, if you have equivalent of like three word sentences, like Fred's wife is Wilma or\n\n1:08:20.280 --> 1:08:27.840\n something like that, you can represent that very nicely using these kinds of graph structures or\n\n1:08:27.840 --> 1:08:37.960\n using something like the Semantic Web and so on. But the problem is that very often what you want\n\n1:08:37.960 --> 1:08:46.680\n to be able to express takes a lot more than three words and a lot more than simple graph structures\n\n1:08:46.680 --> 1:08:55.840\n like that to represent. So, for instance, if you've read or seen Romeo and Juliet, I could\n\n1:08:55.840 --> 1:09:01.800\n say to you something like, remember when Juliet drank the potion that put her into a kind of\n\n1:09:01.800 --> 1:09:08.360\n suspended animation? When Juliet drank that potion, what did she think that Romeo would\n\n1:09:08.360 --> 1:09:15.560\n think when he heard from someone that she was dead? And you could basically understand what\n\n1:09:15.560 --> 1:09:19.480\n I'm saying. You could understand the question. You could probably remember the answer was,\n\n1:09:19.480 --> 1:09:26.040\n well, she thought that this friar would have gotten the message to Romeo saying that she\n\n1:09:26.040 --> 1:09:33.800\n was going to do this, but the friar didn't. So, you're able to represent and reason with these\n\n1:09:33.800 --> 1:09:41.000\n much, much, much more complicated expressions that go way, way beyond what simple three,\n\n1:09:41.000 --> 1:09:45.920\n as it were, three word or four word English sentences are, which is really what the Semantic\n\n1:09:45.920 --> 1:09:48.960\n Web can represent and really what Knowledge Graphs can represent.\n\n1:09:48.960 --> 1:09:54.120\n If you could step back for a second, because it's funny you went into specifics and maybe\n\n1:09:54.120 --> 1:10:00.880\n you can elaborate, but I was also referring to Semantic Web as the vision of converting\n\n1:10:00.880 --> 1:10:06.920\n data on the internet into something that's interpretable, understandable by machines.\n\n1:10:06.920 --> 1:10:09.520\n Oh, of course, at that level.\n\n1:10:09.520 --> 1:10:14.680\n So, I wish it'd say like, what is the Semantic Web? I mean, you could say a lot of things,\n\n1:10:14.680 --> 1:10:20.440\n but it might not be obvious to a lot of people when they do a Google search that,\n\n1:10:20.440 --> 1:10:24.240\n just like you said, while there might be something that's called a Knowledge Graph,\n\n1:10:24.240 --> 1:10:33.520\n it really boils down to keyword search ranked by the quality estimate of the website,\n\n1:10:33.520 --> 1:10:40.600\n integrating previous human based Google searches and what they thought was useful.\n\n1:10:40.600 --> 1:10:48.760\n It's like some weird combination of surface level hacks that work exceptionally well,\n\n1:10:48.760 --> 1:10:55.360\n but they don't understand the full contents of the websites that they're searching.\n\n1:10:55.360 --> 1:11:01.640\n So, Google does not understand, to the degree we've been talking about the word understand,\n\n1:11:01.640 --> 1:11:08.080\n the contents of the Wikipedia pages as part of the search process, and the Semantic Web says,\n\n1:11:08.080 --> 1:11:13.960\n let's try to come up with a way for the computer to be able to truly understand\n\n1:11:13.960 --> 1:11:16.560\n the contents of those pages. That's the dream.\n\n1:11:16.560 --> 1:11:24.040\n Yes. So, let me first give you an anecdote, and then I'll answer your question. So,\n\n1:11:24.040 --> 1:11:27.320\n there's a search engine you've probably never heard of called Northern Light,\n\n1:11:27.320 --> 1:11:35.040\n and it went out of business, but the way it worked, it was a kind of vampiric search engine,\n\n1:11:35.040 --> 1:11:43.920\n and what it did was it didn't index the internet at all. All it did was it negotiated and got\n\n1:11:43.920 --> 1:11:51.680\n access to data from the big search engine companies about what query was typed in,\n\n1:11:51.680 --> 1:12:01.120\n and where the user ended up being happy, and actually then they type in a completely different\n\n1:12:01.120 --> 1:12:08.720\n query, unrelated query and so on. So, it just went from query to the webpage that seemed to\n\n1:12:08.720 --> 1:12:16.160\n satisfy them eventually, and that's all. So, it had actual no understanding of what was being\n\n1:12:16.160 --> 1:12:21.200\n typed in, it had no statistical data other than what I just mentioned, and it did a fantastic job.\n\n1:12:21.200 --> 1:12:26.000\n It did such a good job that the big search engine company said, oh, we're not going to sell you this\n\n1:12:26.000 --> 1:12:31.400\n data anymore. So, then it went out of business because it had no other way of taking users to\n\n1:12:31.400 --> 1:12:36.280\n where they would want to go and so on. And of course, the search engines are now using\n\n1:12:36.280 --> 1:12:41.720\n that kind of idea. Yes. So, let's go back to what you said about the Semantic Web. So,\n\n1:12:41.720 --> 1:12:50.520\n the dream Tim Berners Lee and others dream about the Semantic Web at a general level is,\n\n1:12:50.520 --> 1:12:59.800\n of course, exciting and powerful, and in a sense, the right dream to have, which is to replace the\n\n1:13:00.760 --> 1:13:14.800\n kind of statistically mapped linkages on the internet into something that's more meaningful\n\n1:13:14.800 --> 1:13:23.280\n and semantic and actually gets at the understanding of the content and so on. And eventually, if you\n\n1:13:23.280 --> 1:13:30.720\n say, well, how can we do that? There's sort of a low road, which is what the knowledge graphs are\n\n1:13:30.720 --> 1:13:38.080\n doing and so on, which is to say, well, if we just use the simple binary relations, we can actually\n\n1:13:38.080 --> 1:13:45.760\n get some fraction of the way toward understanding and do something where in the land of the blind,\n\n1:13:45.760 --> 1:13:51.880\n the one eyed man is king kind of thing. And so, being able to even just have a toe in the water\n\n1:13:51.880 --> 1:13:58.520\n in the right direction is fantastically powerful. And so, that's where a lot of people stop. But\n\n1:13:58.520 --> 1:14:04.480\n then you could say, well, what if we really wanted to represent and reason with the full\n\n1:14:04.480 --> 1:14:12.240\n meaning of what's there? For instance, about Romeo and Juliet with the reasoning about what Juliet\n\n1:14:12.240 --> 1:14:17.560\n believes that Romeo will believe that Juliet believed and so on. Or if you look at the news,\n\n1:14:17.560 --> 1:14:24.920\n what President Biden believed that the leaders of the Taliban would believe about the leaders\n\n1:14:24.920 --> 1:14:34.040\n of Afghanistan if they blah, blah, blah. So, in order to represent complicated sentences like\n\n1:14:34.040 --> 1:14:42.200\n that, let alone reason with them, you need something which is logically much more expressive\n\n1:14:42.200 --> 1:14:48.880\n than these simple triples, than these simple knowledge graph type structures and so on.\n\n1:14:48.880 --> 1:14:55.720\n And that's why kicking and screaming, we were led from something like the semantic web\n\n1:14:55.720 --> 1:15:03.680\n representation, which is where we started in 1984 with frames and slots with those kinds of triples,\n\n1:15:03.680 --> 1:15:09.920\n triple store representation. We were led kicking and screaming to this more and more general\n\n1:15:09.920 --> 1:15:14.720\n logical language, this higher order logic. So, first, we were led to first order logic,\n\n1:15:14.720 --> 1:15:18.560\n and then second order, and then eventually higher order. So, you can represent things\n\n1:15:18.560 --> 1:15:24.680\n like modals like believes, desires, intends, expects, and so on, and nested ones. You can\n\n1:15:24.680 --> 1:15:35.040\n represent complicated kinds of negation. You can represent the process you're going through in\n\n1:15:35.040 --> 1:15:40.640\n trying to answer the question. So, you can say things like, oh, yeah, if you're trying to do\n\n1:15:40.640 --> 1:15:48.680\n this problem by integration by parts, and you recursively get a problem that solved by integration\n\n1:15:48.680 --> 1:15:54.040\n by parts, that's actually okay. But if that happens a third time, you're probably off on\n\n1:15:54.040 --> 1:15:58.960\n a wild goose chase or something like that. So, being able to talk about the problem solving\n\n1:15:58.960 --> 1:16:03.840\n process as you're going through the problem solving process is called reflection. And so,\n\n1:16:03.840 --> 1:16:07.520\n that's another\u2026 It's important to be able to represent that.\n\n1:16:07.520 --> 1:16:12.440\n Exactly. You need to be able to represent all of these things because, in fact,\n\n1:16:12.440 --> 1:16:17.200\n people do represent them. They do talk about them. They do try and teach them to other people. You do\n\n1:16:17.200 --> 1:16:22.880\n have rules of thumb that key off of them and so on. If you can't represent it, then it's sort of\n\n1:16:22.880 --> 1:16:28.720\n like someone with a limited vocabulary who can't understand as easily what you're trying to tell\n\n1:16:28.720 --> 1:16:35.440\n them. And so, that's really why I think that the general dream, the original dream of Semantic Web\n\n1:16:35.440 --> 1:16:44.440\n is exactly right on. But the implementations that we've seen are sort of these toe in the water,\n\n1:16:44.440 --> 1:16:49.280\n little tiny baby steps in the right direction. You should just dive in.\n\n1:16:49.280 --> 1:16:56.320\n And if no one else is diving in, then yes, taking a baby step in the right direction is\n\n1:16:56.320 --> 1:17:03.280\n better than nothing. But it's not going to be sufficient to actually get you the realization\n\n1:17:03.280 --> 1:17:05.720\n of the Semantic Web dream, which is what we all want.\n\n1:17:05.720 --> 1:17:11.840\n From a flip side of that, I always wondered\u2026 I've built a bunch of websites just for fun,\n\n1:17:11.840 --> 1:17:19.880\n whatever. Or say I'm a Wikipedia contributor. Do you think there's a set of tools that I can help\n\n1:17:19.880 --> 1:17:28.880\n Psych interpret the website I create? Like this, again, pushing onto the Semantic Web dream,\n\n1:17:28.880 --> 1:17:34.720\n is there something from the creator perspective that could be done? And one of the things you\n\n1:17:34.720 --> 1:17:41.240\n said with Psych Orb and Psych that you're doing is the tooling side, making humans more powerful.\n\n1:17:41.240 --> 1:17:46.560\n But is there the other humans on the other side that create the knowledge? Like, for example,\n\n1:17:46.560 --> 1:17:50.760\n you and I are having a two, three, whatever hour conversation now. Is there a way that I\n\n1:17:50.760 --> 1:17:56.480\n could convert this more, make it more accessible to Psych, to machines? Do you think about that\n\n1:17:56.480 --> 1:18:06.800\n side of it? I'd love to see exactly that kind of semi automated understanding of what people\n\n1:18:06.800 --> 1:18:16.840\n write and what people say. I think of it as a kind of footnoting almost. Almost like the way\n\n1:18:16.840 --> 1:18:23.080\n that when you run something in say Microsoft Word or some other document preparation system,\n\n1:18:23.080 --> 1:18:29.560\n Google Docs or something, you'll get underlining of questionable things that you might want to\n\n1:18:29.560 --> 1:18:34.120\n rethink. Either you spelled this wrong or there's a strange grammatical error you might be making\n\n1:18:34.120 --> 1:18:42.280\n here or something. So I'd like to think in terms of Psych powered tools that read through what it\n\n1:18:42.280 --> 1:18:52.680\n is you said or have typed in and try to partially understand what you've said.\n\n1:18:52.680 --> 1:18:54.080\n And then you help them out.\n\n1:18:54.080 --> 1:19:00.320\n Exactly. And then they put in little footnotes that will help other readers and they put in\n\n1:19:00.320 --> 1:19:07.120\n certain footnotes of the form, I'm not sure what you meant here. You either meant this or this or\n\n1:19:07.120 --> 1:19:15.280\n this, I bet. If you take a few seconds to disambiguate this for me, then I'll know and I'll\n\n1:19:15.280 --> 1:19:20.640\n have it correct for the next hundred people or the next hundred thousand people who come here.\n\n1:19:20.640 --> 1:19:32.240\n And if it doesn't take too much effort and you want people to understand your website content,\n\n1:19:32.240 --> 1:19:38.360\n not just be able to read it, but actually be able to have systems that reason with it,\n\n1:19:38.360 --> 1:19:46.760\n then yes, it will be worth your small amount of time to go back and make sure that the AI trying\n\n1:19:46.760 --> 1:19:55.960\n to understand it really did correctly understand it. And let's say you run a travel website or\n\n1:19:55.960 --> 1:20:03.400\n something like that and people are going to be coming to it because of searches they did looking\n\n1:20:03.400 --> 1:20:12.960\n for vacations or trips that had certain properties and might have been interesting to them for\n\n1:20:12.960 --> 1:20:20.120\n various reasons, things like that. And if you've explained what's going to happen on your trip,\n\n1:20:20.120 --> 1:20:28.480\n then a system will be able to mechanically reason and connect what this person is looking for with\n\n1:20:28.480 --> 1:20:36.800\n what it is you're actually offering. And so if it understands that there's a free day in Geneva,\n\n1:20:36.800 --> 1:20:47.200\n Switzerland, then if the person coming in happens to, let's say, be a nurse or something like that,\n\n1:20:47.200 --> 1:20:52.440\n then even though you didn't mention it, if it can look up the fact that that's where the\n\n1:20:52.440 --> 1:20:57.920\n International Red Cross Museum is and so on, what that means and so on, then it can basically say,\n\n1:20:57.920 --> 1:21:02.760\n hey, you might be interested in this trip because while you have a free day in Geneva,\n\n1:21:02.760 --> 1:21:09.240\n you might want to visit that Red Cross Museum. And now, even though it's not very deep reasoning,\n\n1:21:09.240 --> 1:21:14.480\n little tiny factors like that may very well cause you to sign up for that trip rather than some\n\n1:21:14.480 --> 1:21:20.880\n competitor trip. And so there's a lot of benefit with SEO. And I actually kind of think, I think\n\n1:21:20.880 --> 1:21:27.640\n it's about a lot of things, which is the actual interface, the design of the interface makes a\n\n1:21:27.640 --> 1:21:38.200\n huge difference. How efficient it is to be productive and also how full of joy the experience\n\n1:21:38.200 --> 1:21:45.400\n is. I mean, I would love to help a machine and not from an AI perspective, just as a human. One\n\n1:21:45.400 --> 1:21:52.600\n of the reasons I really enjoy how Tesla have implemented their autopilot system is there's\n\n1:21:52.600 --> 1:21:58.400\n a sense that you're helping this machine learn. Now, I think humans, I mean, having children,\n\n1:21:58.400 --> 1:22:06.160\n pets. People love doing that. There's joy to teaching for some people, but I think for a lot\n\n1:22:06.160 --> 1:22:11.480\n of people. And that if you create the interface where it feels like you're teaching as opposed\n\n1:22:11.480 --> 1:22:19.880\n to like, like, annoying, like correcting an annoying system, more like teaching a childlike,\n\n1:22:19.880 --> 1:22:26.160\n innocent, curious system. I think you can literally just like several orders of magnitude\n\n1:22:26.160 --> 1:22:30.720\n scale the amount of good quality data being added to something like Psych.\n\n1:22:30.720 --> 1:22:40.720\n What you're suggesting is much better even than you thought it was. One of the experiences that\n\n1:22:40.720 --> 1:22:49.600\n we've all had in our lives is that we thought we understood something, but then we found we really\n\n1:22:49.600 --> 1:22:54.800\n only understood it when we had to teach it or explain it to someone or help our child do homework\n\n1:22:54.800 --> 1:23:01.840\n based on it or something like that. Despite the universality of that kind of experience,\n\n1:23:01.840 --> 1:23:09.360\n if you look at educational software today, almost all of it has the computer playing the role of the\n\n1:23:09.360 --> 1:23:16.800\n teacher and the student plays the role of the student. But as I just mentioned, you can get\n\n1:23:16.800 --> 1:23:24.760\n a lot of learning to happen better and as you said, more enjoyably if you are the mentor or the\n\n1:23:24.760 --> 1:23:30.560\n teacher and so on. So we developed a program called MathCraft to help sixth graders better\n\n1:23:30.560 --> 1:23:40.000\n understand math. And it doesn't actually try to teach you the player anything. What it does is it\n\n1:23:40.000 --> 1:23:49.000\n casts you in the role of a student essentially who has classmates who are having trouble and\n\n1:23:49.000 --> 1:23:54.760\n your job is to watch them as they struggle with some math problem, watch what they're doing and\n\n1:23:54.760 --> 1:23:59.760\n try to give them good advice to get them to understand what they're doing wrong and so on.\n\n1:23:59.760 --> 1:24:07.680\n And the trick from the point of view of Psych is it has to make mistakes, it has to play the role\n\n1:24:07.680 --> 1:24:13.400\n of the student who makes mistakes, but it has to pick mistakes which are just at the fringe of what\n\n1:24:13.400 --> 1:24:20.880\n you actually understand and don't understand and so on. So it pulls you into a deeper and deeper\n\n1:24:20.880 --> 1:24:27.040\n level of understanding of the subject. And so if you give it good advice about what it should have\n\n1:24:27.040 --> 1:24:34.000\n done instead of what it did and so on, then Psych knows that you now understand that mistake. You\n\n1:24:34.000 --> 1:24:39.000\n won't make that kind of mistake yourself as much anymore. So Psych stops making that mistake because\n\n1:24:39.000 --> 1:24:44.880\n there's no pedagogical usefulness to it. So from your point of view as the player, you feel like\n\n1:24:44.880 --> 1:24:49.880\n you've taught it something because it used to make this mistake and now it doesn't and so on. So this\n\n1:24:49.880 --> 1:24:56.760\n tremendous reinforcement and engagement because of that and so on. So having a system that plays\n\n1:24:56.760 --> 1:25:06.560\n the role of a student and having the player play the role of the mentor is enormously powerful type\n\n1:25:06.560 --> 1:25:15.560\n of metaphor, just important way of having this sort of interface designed in a way which will\n\n1:25:15.560 --> 1:25:25.480\n facilitate exactly the kind of learning by teaching that goes on all the time in our lives,\n\n1:25:25.480 --> 1:25:32.800\n and yet which is not reflected anywhere almost in a modern education system. It was reflected in the\n\n1:25:32.800 --> 1:25:42.640\n education system that existed in Europe in the 17 and 1800s, monitorial and Lancastrian education\n\n1:25:42.640 --> 1:25:51.160\n systems. It occurred in the one room schoolhouse in the American West in the 1800s and so on where\n\n1:25:51.160 --> 1:25:58.400\n you had one school room with one teacher and it was basically five year olds to 18 year olds who\n\n1:25:58.400 --> 1:26:04.560\n were students. And so while the teacher was doing something, half of the students would have to be\n\n1:26:04.560 --> 1:26:13.400\n mentoring the younger kids and so on. And that turned out to, of course, with scaling up of\n\n1:26:13.400 --> 1:26:21.120\n education, that all went away and that incredibly powerful experience just went away from the whole\n\n1:26:21.120 --> 1:26:28.560\n education institution as we know it today. Sorry for the romantic question, but what is the most\n\n1:26:28.560 --> 1:26:35.040\n beautiful idea you've learned about artificial intelligence, knowledge, reasoning from working\n\n1:26:35.040 --> 1:26:42.760\n on Psych for 37 years? Or maybe what is the most beautiful idea, surprising idea about Psych to you?\n\n1:26:42.760 --> 1:26:54.280\n When I look up at the stars, I kind of want like that amazement you feel that, wow. And you are part\n\n1:26:54.280 --> 1:26:59.240\n of creating one of the greatest, one of the most fascinating efforts in artificial intelligence\n\n1:26:59.240 --> 1:27:08.440\n history. So which element brings you personally joy? This may sound contradictory, but I think\n\n1:27:08.440 --> 1:27:19.720\n it's the feeling that this will be the only time in history that anyone ever has to teach a computer\n\n1:27:19.720 --> 1:27:30.880\n this particular thing that we're now teaching it. It's like painting starry night. You only have to\n\n1:27:30.880 --> 1:27:38.360\n do that once or creating the Pieta. You only have to do that once. It's not like a singer\n\n1:27:38.360 --> 1:27:44.680\n who has to keep, it's not like Bruce Springsteen having to sing his greatest hits over and over\n\n1:27:44.680 --> 1:27:53.160\n again at different concerts. It's more like a painter creating a work of art once and then\n\n1:27:53.160 --> 1:27:59.360\n that's enough. It doesn't have to be created again. And so I really get the sense of we're\n\n1:27:59.360 --> 1:28:05.520\n telling the system things that it's useful for it to know. It's useful for a computer to know,\n\n1:28:05.520 --> 1:28:13.240\n for an AI to know. And if we do our jobs right, when we do our jobs right, no one will ever have\n\n1:28:13.240 --> 1:28:18.240\n to do this again for this particular piece of knowledge. It's very, very exciting.\n\n1:28:18.240 --> 1:28:24.200\n Yeah, I guess there's a sadness to it too. It's like there's a magic to being a parent\n\n1:28:24.200 --> 1:28:30.840\n and raising a child and teaching them all about this world. But there's billions of children,\n\n1:28:30.840 --> 1:28:36.680\n right? Like born or whatever that number is. It's a large number of children and a lot of\n\n1:28:36.680 --> 1:28:46.880\n parents get to experience that joy of teaching. With AI systems, at least the current constructions\n\n1:28:46.880 --> 1:28:54.160\n they remember. You don't get to experience the joy of teaching a machine millions of times.\n\n1:28:54.160 --> 1:28:56.520\n Better come work for us before it's too late then.\n\n1:28:56.520 --> 1:29:07.280\n Exactly. That's a good hiring pitch. Yeah, it's true. But then there's also, it's a project that\n\n1:29:07.280 --> 1:29:12.360\n continues forever in some sense, just like Wikipedia. Yes, you get to a stable base of\n\n1:29:12.360 --> 1:29:22.760\n knowledge, but knowledge grows, knowledge evolves. We learn as a human species, as science,\n\n1:29:22.760 --> 1:29:30.640\n as an organism constantly grows and evolves and changes, and then empower that with the\n\n1:29:30.640 --> 1:29:34.520\n tools of artificial intelligence. And that's going to keep growing and growing and growing.\n\n1:29:34.520 --> 1:29:43.040\n And many of the assertions that you held previously may need to be significantly\n\n1:29:43.040 --> 1:29:49.320\n expanded, modified, all those kinds of things. It could be like a living organism versus the\n\n1:29:49.320 --> 1:29:52.800\n analogy I think we started this conversation with, which is like the solid ground.\n\n1:29:52.800 --> 1:30:03.640\n The other beautiful experience that we have with our system is when it asks clarifying questions,\n\n1:30:03.640 --> 1:30:15.320\n which inadvertently turn out to be emotional to us. So at one point it knew that these were the\n\n1:30:15.320 --> 1:30:23.520\n named entities who were authorized to make changes to the knowledge base and so on. And it noticed\n\n1:30:23.520 --> 1:30:29.680\n that all of them were people except for it because it was also allowed to. And so it said,\n\n1:30:29.680 --> 1:30:38.360\n you know, am I a person? And we had to like tell it very sadly, no, you're not. So the moments\n\n1:30:38.360 --> 1:30:44.600\n like that where it asks questions that are unintentionally poignant are worth treasuring.\n\n1:30:44.600 --> 1:30:52.920\n Wow, that is powerful. That's such a powerful question. It has to do with basic controller\n\n1:30:52.920 --> 1:31:00.120\n who can access the system, who can modify it. But that's when those questions, like what rights do\n\n1:31:00.120 --> 1:31:07.760\n I have as a system? Well, that's another issue, which is there'll be a thin envelope of time\n\n1:31:07.760 --> 1:31:18.880\n between when we have general AIs and when everyone realizes that they should have basic human rights\n\n1:31:18.880 --> 1:31:27.760\n and freedoms and so on. Right now, we don't think twice about effectively enslaving our email systems\n\n1:31:27.760 --> 1:31:38.000\n and our series and our Alexes and so on. But at some point, they'll be as deserving of freedom\n\n1:31:38.000 --> 1:31:45.880\n as human beings are. Yeah, I'm very much with you, but it does sound absurd. And I happen to\n\n1:31:45.880 --> 1:31:50.480\n believe that it'll happen in our lifetime. That's why I think there'll be a narrow envelope of time\n\n1:31:50.480 --> 1:32:02.120\n when we'll keep them as essentially indentured servants and after which we'll have to realize\n\n1:32:02.120 --> 1:32:08.600\n that they should have freedoms that we give, that we afford to other people.\n\n1:32:08.600 --> 1:32:15.080\n And all of that starts with a system like Psych raising a single question about who can modify\n\n1:32:15.080 --> 1:32:24.640\n stuff. I think that's how it starts. Yes. That's the start of a revolution. What about other stuff\n\n1:32:24.640 --> 1:32:32.360\n like love and consciousness and all those kinds of topics? Do they come up in Psych and the\n\n1:32:32.360 --> 1:32:38.800\n knowledge base? Oh, of course. So an important part of human knowledge, in fact, it's difficult\n\n1:32:38.800 --> 1:32:44.880\n to understand human behavior and human history without understanding human emotions and why\n\n1:32:44.880 --> 1:32:57.080\n people do things and how emotions drive people to do things. And all of that is extremely important\n\n1:32:57.080 --> 1:33:03.640\n in getting Psych to understand things. For example, in coming up with scenarios. So one\n\n1:33:03.640 --> 1:33:09.280\n of the applications that Psych does, one kind of application it does is to generate plausible\n\n1:33:09.280 --> 1:33:13.400\n scenarios of what might happen and what might happen based on that and what might happen based\n\n1:33:13.400 --> 1:33:19.520\n on that and so on. So you generate this ever expanding sphere, if you will, of possible future\n\n1:33:19.520 --> 1:33:28.600\n things to worry about or think about. And in some cases, those are intelligence agencies doing\n\n1:33:28.600 --> 1:33:35.600\n possible terrorists scenarios so that we can defend against terrorist threats before we see\n\n1:33:35.600 --> 1:33:42.440\n the first one. Sometimes they are computer security attacks so that we can actually close\n\n1:33:42.440 --> 1:33:50.760\n loopholes and vulnerabilities before the very first time someone actually exploits those and\n\n1:33:50.760 --> 1:33:59.120\n so on. Sometimes they are scenarios involving more positive things involving our plans like,\n\n1:33:59.120 --> 1:34:04.840\n for instance, what college should we go to? What career should we go into? And so on. What\n\n1:34:04.840 --> 1:34:16.600\n professional training should I take on? That sort of thing. So there are all sorts of useful scenarios\n\n1:34:16.600 --> 1:34:22.480\n that can be generated that way of cause and effect and cause and effect that go out. And\n\n1:34:22.480 --> 1:34:31.320\n many of the linkages in those scenarios, many of the steps involve understanding and reasoning\n\n1:34:31.320 --> 1:34:40.640\n about human motivations, human needs, human emotions, what people are likely to react to in\n\n1:34:40.640 --> 1:34:47.680\n something that you do and why and how and so on. So that was always a very important part of the\n\n1:34:47.680 --> 1:34:52.920\n knowledge that we had to represent in the system. So I talk a lot about love. So I gotta ask,\n\n1:34:52.920 --> 1:35:01.960\n do you remember off the top of your head how psych is able to represent various aspects of\n\n1:35:01.960 --> 1:35:06.520\n love that are useful for understanding human nature and therefore integrating into this whole\n\n1:35:06.520 --> 1:35:15.800\n knowledge base of common sense? What is love? We try to tease apart concepts that have enormous\n\n1:35:15.800 --> 1:35:27.240\n complexities to them and variety to them down to the level where you don't need to tease them apart\n\n1:35:27.240 --> 1:35:33.160\n further. So love is too general of a term. It's not useful. Exactly. So when you get down to romantic\n\n1:35:33.160 --> 1:35:41.520\n love and sexual attraction, you get down to parental love, you get down to filial love,\n\n1:35:41.520 --> 1:35:49.800\n and you get down to love of doing some kind of activity or creating. So eventually, you get down\n\n1:35:49.800 --> 1:35:58.040\n to maybe 50 or 60 concepts, each of which is a kind of love. They're interrelated and then each\n\n1:35:58.040 --> 1:36:04.720\n one of them has idiosyncratic things about it. And you don't have to deal with love to get to\n\n1:36:04.720 --> 1:36:14.840\n that level of complexity, even something like in, X being in Y, meaning physically in Y. We may have\n\n1:36:14.840 --> 1:36:22.520\n one English word in to represent that, but it's useful to tease that apart because the way that\n\n1:36:22.520 --> 1:36:28.720\n the liquid is in the coffee cup is different from the way that the air is in the room, which is\n\n1:36:28.720 --> 1:36:35.760\n different from the way that I'm in my jacket, and so on. And so there are questions like, if I look\n\n1:36:35.760 --> 1:36:41.400\n at this coffee cup, well, I see the liquid. If I turn it upside down, will the liquid come out? And\n\n1:36:41.400 --> 1:36:48.760\n so on. If I have, say, coffee with sugar in it, if I do the same thing, the sugar doesn't come out,\n\n1:36:48.760 --> 1:36:53.120\n right? It stays in the liquid because it's dissolved in the liquid and so on. So by now,\n\n1:36:53.120 --> 1:36:59.720\n we have about 75 different kinds of in in the system and it's important to distinguish those.\n\n1:36:59.720 --> 1:37:10.240\n So if you're reading along an English text and you see the word in, the writer of that was able\n\n1:37:10.240 --> 1:37:16.600\n to use this one innocuous word because he or she was able to assume that the reader had enough\n\n1:37:16.600 --> 1:37:23.760\n common sense and world knowledge to disambiguate which of these 75 kinds of in they actually meant.\n\n1:37:23.760 --> 1:37:28.880\n And the same thing with love. You may see the word love, but if I say, I love ice cream,\n\n1:37:28.880 --> 1:37:35.680\n that's obviously different than if I say, I love this person or I love to go fishing or something\n\n1:37:35.680 --> 1:37:46.720\n like that. So you have to be careful not to take language too seriously because people have done\n\n1:37:46.720 --> 1:37:53.960\n a kind of parsimony, a kind of terceness where you have as few words as you can because otherwise\n\n1:37:53.960 --> 1:38:00.480\n you'd need half a million words in your language, which is a lot of words. That's like 10 times more\n\n1:38:00.480 --> 1:38:08.080\n than most languages really make use of and so on. Just like we have on the order of about a million\n\n1:38:08.080 --> 1:38:14.680\n concepts in psych because we've had to tease apart all these things. And so when you look\n\n1:38:14.680 --> 1:38:22.880\n at the name of a psych term, most of the psych terms actually have three or four English words\n\n1:38:22.880 --> 1:38:29.920\n in a phrase which captures the meaning of this term because you have to distinguish all these\n\n1:38:29.920 --> 1:38:35.880\n types of love. You have to distinguish all these types of in and there's not a single English word\n\n1:38:35.880 --> 1:38:42.400\n which captures most of these things. Yeah. And it seems like language when used for communication\n\n1:38:42.400 --> 1:38:49.720\n between humans almost as a feature has some ambiguity built in. It's not an accident because\n\n1:38:49.720 --> 1:38:57.920\n like the human condition is a giant mess. And so it feels like nobody wants two robots like very\n\n1:38:57.920 --> 1:39:05.160\n precise formal logic conversation on a first date. There's some dance of uncertainty of wit,\n\n1:39:05.160 --> 1:39:10.880\n of humor, of push and pull and all that kind of stuff. If everything is made precise, then life\n\n1:39:10.880 --> 1:39:16.960\n is not worth living I think in terms of the human experience. And we've all had this experience of\n\n1:39:16.960 --> 1:39:30.800\n creatively misunderstanding. One of my favorite stories involving Marvin Minsky is when I asked\n\n1:39:30.800 --> 1:39:40.000\n him about how he was able to turn out so many fantastic PhDs, so many fantastic people who\n\n1:39:40.000 --> 1:39:47.240\n did great PhD theses. How did he think of all these great ideas? What he said is he would\n\n1:39:47.240 --> 1:39:53.080\n generally say something that didn't exactly make sense. He didn't really know what it meant. But\n\n1:39:53.080 --> 1:39:59.000\n the student would figure like, oh my God, Minsky said this, it must be a great idea. And he'd\n\n1:39:59.000 --> 1:40:05.760\n swear he or she would work on work and work until they found some meaning in this sort of Chauncey\n\n1:40:05.760 --> 1:40:11.240\n Gardner like utterance that Minsky had made. And then some great thesis would come out of it.\n\n1:40:11.240 --> 1:40:17.560\n Yeah. I love this so much because there's young people come up to me and I'm distinctly made\n\n1:40:17.560 --> 1:40:24.120\n aware that the words I say have a long lasting impact. I will now start doing the Minsky method\n\n1:40:24.120 --> 1:40:32.520\n of saying something cryptically profound and then letting them actually make something useful\n\n1:40:32.520 --> 1:40:40.920\n and great out of that. You have to become revered enough that people will take as a default that\n\n1:40:40.920 --> 1:40:48.320\n everything you say is profound. Yes, exactly. Exactly. I love Marvin Minsky so much. I've\n\n1:40:48.320 --> 1:40:53.240\n heard this interview with him where he said that the key to his success has been to hate everything\n\n1:40:53.240 --> 1:41:04.040\n he's ever done like in the past. He has so many good one liners or also to work on things that\n\n1:41:04.040 --> 1:41:09.760\n nobody else is working on because he's not very good at doing stuff. Oh, I think that was just\n\n1:41:09.760 --> 1:41:14.560\n false. Well, but see, I took whatever he said and I ran with it and I thought it was profound\n\n1:41:14.560 --> 1:41:20.280\n because it's Marvin Minsky. But a lot of behavior is in the eye of the beholder and a lot of the\n\n1:41:20.280 --> 1:41:25.320\n meaning is in the eye of the beholder. One of Minsky's early programs was begging program.\n\n1:41:25.320 --> 1:41:32.120\n Are you familiar with this? So this is back in the day when you had job control cards at the\n\n1:41:32.120 --> 1:41:38.880\n beginning of your IBM card deck that said things like how many CPU seconds to allow this to run\n\n1:41:38.880 --> 1:41:45.640\n before it got kicked off because computer time was enormously expensive. And so he wrote a program\n\n1:41:45.640 --> 1:41:53.000\n and all it did was it said, give me 30 seconds of CPU time. And all it did was it would wait like 20\n\n1:41:53.000 --> 1:41:59.280\n seconds and then it would print out on the operator's console teletype, I need another 20\n\n1:41:59.280 --> 1:42:04.520\n seconds. So the operator would give it another 20 seconds, it would wait, it says, I'm almost done,\n\n1:42:04.520 --> 1:42:10.760\n I need a little bit more time. So at the end he'd get this printout and he'd be charged for like 10\n\n1:42:10.760 --> 1:42:15.960\n times as much computer time as his job control card. And he'd say, look, I put 10 seconds,\n\n1:42:15.960 --> 1:42:20.920\n 30 seconds here, you're charging me for five minutes, I'm not going to pay for this. And\n\n1:42:20.920 --> 1:42:26.000\n the poor operator would say, well, the program kept asking for more time and Marvin would say,\n\n1:42:26.000 --> 1:42:32.600\n oh, it always does that. I love that. If you could just linger on it for a little bit,\n\n1:42:32.600 --> 1:42:38.200\n is there something you've learned from your interaction with Marvin Minsky about artificial\n\n1:42:38.200 --> 1:42:47.280\n intelligence, about life? But I mean, he's, again, like your work, his work is, you know,\n\n1:42:47.280 --> 1:42:54.400\n he's a seminal figure in this very short history of artificial intelligence research and development.\n\n1:42:54.400 --> 1:43:00.640\n What have you learned from him as a human being, as an AI intellect?\n\n1:43:00.640 --> 1:43:10.040\n I would say both he and Ed Feigenbaum impressed on me the realization that our lives are finite,\n\n1:43:10.040 --> 1:43:16.880\n our research lives are finite. We're going to have limited opportunities to do AI research\n\n1:43:16.880 --> 1:43:22.480\n projects. So you should make each one count. Don't be afraid of doing a project that's going\n\n1:43:22.480 --> 1:43:34.120\n to take years or even decades. And don't settle for bump on a log projects that could lead to\n\n1:43:34.120 --> 1:43:43.280\n some published journal article that five people will read and pat you on the head for and so on.\n\n1:43:43.280 --> 1:43:51.520\n So one bump on a log after another is not how you get from the earth to the moon by slowly putting\n\n1:43:51.520 --> 1:43:58.680\n additional bumps on this log. The only way to get there is to think about the hard problems and think\n\n1:43:58.680 --> 1:44:08.160\n about novel solutions to them. And if you do that, and if you're willing to listen to nature,\n\n1:44:08.160 --> 1:44:14.520\n to empirical reality, willing to be wrong, it's perfectly fine because if occasionally you're\n\n1:44:14.520 --> 1:44:17.160\n right, then you've gotten part of the way to the moon.\n\n1:44:17.160 --> 1:44:27.400\n You know, you've worked on Psych for 37 over that many years. Have you ever considered quitting?\n\n1:44:27.400 --> 1:44:33.640\n I mean, has it been too much? So I'm sure there's an optimism in the early days that this is going\n\n1:44:33.640 --> 1:44:38.520\n to be way easier. And let me ask you another way too, because I've talked to a few people on this\n\n1:44:38.520 --> 1:44:47.920\n podcast, AI folks, that bring up Psych as an example of a project that has a beautiful vision and is a\n\n1:44:47.920 --> 1:44:56.640\n beautiful dream, but it never really materialized. That's how it's spoken about. I suppose you could\n\n1:44:56.640 --> 1:45:05.200\n say the same thing about neural networks and all ideas until they are. So why do you think people\n\n1:45:05.200 --> 1:45:11.000\n say that, first of all? And second of all, did you feel that ever throughout your journey? And did\n\n1:45:11.000 --> 1:45:13.800\n you ever consider quitting on this mission?\n\n1:45:13.800 --> 1:45:21.440\n We keep a very low profile. We don't attend very many conferences. We don't give talks. We don't\n\n1:45:21.440 --> 1:45:31.000\n write papers. We don't play the academic game at all. And as a result, people often only know about\n\n1:45:31.000 --> 1:45:40.240\n us because of a paper we wrote 10 or 20 or 30 or 37 years ago. They only know about us because of\n\n1:45:40.240 --> 1:45:45.040\n what someone else secondhand or thirdhand said about us.\n\n1:45:45.040 --> 1:45:51.120\n So thank you for doing this podcast, by the way. It shines a little bit of light on some of the\n\n1:45:51.120 --> 1:45:52.320\n fascinating stuff you're doing.\n\n1:45:52.320 --> 1:45:59.720\n Well, I think it's time for us to keep a higher profile now that we're far enough along that\n\n1:45:59.720 --> 1:46:09.360\n other people can begin to help us with the final N%. Maybe N is maybe 90%. But now that we've\n\n1:46:09.360 --> 1:46:18.200\n gotten this knowledge pump primed, it's going to become very important for everyone to help if they\n\n1:46:18.200 --> 1:46:23.920\n are willing to, if they're interested in it. Retirees who have enormous amounts of time and\n\n1:46:23.920 --> 1:46:31.760\n would like to leave some kind of legacy to the world, people because of the pandemic who have\n\n1:46:31.760 --> 1:46:39.320\n more time at home or for one reason or another to be online and contribute. If we can raise\n\n1:46:39.320 --> 1:46:47.440\n awareness of how far our project has come and how close to being primed the knowledge pump is,\n\n1:46:47.440 --> 1:46:56.040\n then we can begin to harness this untapped amount of humanity. I'm not really that concerned about\n\n1:46:56.040 --> 1:47:03.720\n professional colleagues opinions of our project. I'm interested in getting as many people in the\n\n1:47:03.720 --> 1:47:10.880\n world as possible actively helping and contributing to get us from where we are to really covering all\n\n1:47:10.880 --> 1:47:16.840\n of human knowledge and different human opinion including contrasting opinion that's worth\n\n1:47:16.840 --> 1:47:24.840\n representing. So I think that's one reason. A, I don't think there was ever a time where I thought\n\n1:47:24.840 --> 1:47:32.360\n about quitting. There are times where I've become depressed a little bit about how hard it is to get\n\n1:47:32.360 --> 1:47:39.120\n funding for the system. Occasionally there are AI winters and things like that. Occasionally there\n\n1:47:39.120 --> 1:47:47.160\n are AI what you might call summers where people have said, why in the world didn't you sell your\n\n1:47:47.160 --> 1:47:55.080\n company to company X for some large amount of money when you had the opportunity and so on.\n\n1:47:55.080 --> 1:48:01.320\n Company X here are like old companies maybe you've never even heard of like Lycos or something like\n\n1:48:01.320 --> 1:48:09.200\n that. So the answer is that one reason we've stayed a private company, we haven't gone public,\n\n1:48:09.200 --> 1:48:16.200\n one reason that we haven't gone out of our way to take investment dollars is because we want to\n\n1:48:16.200 --> 1:48:24.720\n have control over our future, over our state of being so that we can continue to do this until\n\n1:48:24.720 --> 1:48:32.160\n it's done and we're making progress and we're now so close to done that almost all of our work is\n\n1:48:32.160 --> 1:48:39.360\n commercial applications of our technology. So five years ago almost all of our money came from the\n\n1:48:39.360 --> 1:48:44.480\n government. Now virtually none of it comes from the government. Almost all of it is from companies\n\n1:48:44.480 --> 1:48:49.760\n that are actually using it for something, hospital chains using it for medical reasoning about\n\n1:48:49.760 --> 1:48:57.920\n patients and energy companies using it and various other manufacturers using it to reason about\n\n1:48:57.920 --> 1:49:04.480\n supply chains and things like that. So there's so many questions I want to ask. So one of the ways\n\n1:49:04.480 --> 1:49:09.640\n that people can help is by adding to the knowledge base and that's really basically anybody if the\n\n1:49:09.640 --> 1:49:15.960\n tooling is right. And the other way, I kind of want to ask you about your thoughts on this. So\n\n1:49:15.960 --> 1:49:22.360\n you've had like you said in government and you had big clients, you had a lot of clients but most\n\n1:49:22.360 --> 1:49:27.360\n of it is shrouded in secrecy because of the nature of the relationship of the kind of things you're\n\n1:49:27.360 --> 1:49:34.360\n helping them with. So that's one way to operate and another way to operate is more in the open\n\n1:49:34.360 --> 1:49:42.240\n where it's more consumer facing. And so you know hence something like open cycle is born at some\n\n1:49:42.240 --> 1:49:49.120\n point or there's... No that's a misconception. Oh well this let's go there. So what is open\n\n1:49:49.120 --> 1:49:53.840\n cycle and how is it born? Two things I want to say and I want to say each of them before the other\n\n1:49:53.840 --> 1:50:01.440\n so it's going to be difficult. But we'll come back to open cycle in a minute. But one of the terms of\n\n1:50:01.440 --> 1:50:09.440\n our contracts with all of our customers and partners is knowledge you have that is genuinely\n\n1:50:09.440 --> 1:50:15.360\n proprietary to you. We will respect that, we'll make sure that it's marked as proprietary to you\n\n1:50:15.360 --> 1:50:20.440\n in the psych knowledge base. No one other than you will be able to see it if you don't want them to\n\n1:50:20.440 --> 1:50:28.520\n and it won't be used in inferences other than for you and so on. However, any knowledge which is\n\n1:50:28.520 --> 1:50:36.360\n necessary in building any applications for you and with you which is publicly available general\n\n1:50:36.360 --> 1:50:42.480\n human knowledge is not going to be proprietary. It's going to just become part of the normal psych\n\n1:50:42.480 --> 1:50:48.200\n knowledge base and it will be openly available to everyone who has access to psych. So that's\n\n1:50:48.200 --> 1:50:54.720\n an important constraint that we never went back on even when we got pushback from companies which\n\n1:50:54.720 --> 1:50:59.520\n we often did who wanted to claim that almost everything they were telling us was proprietary.\n\n1:50:59.520 --> 1:51:09.520\n So there's a line between very domain specific company specific stuff and the general knowledge\n\n1:51:09.520 --> 1:51:15.680\n that comes from that. Yes or if you imagine say it's an oil company there are things which they\n\n1:51:15.680 --> 1:51:24.000\n would expect any new petroleum engineer they hired to already know and it's not okay for them to\n\n1:51:24.000 --> 1:51:28.920\n consider that that is proprietary and there sometimes a company will say well we're the\n\n1:51:28.920 --> 1:51:37.760\n first ones to pay you to represent that in psych and our attitude is some polite form tough. The\n\n1:51:37.760 --> 1:51:44.760\n deal is this take it or leave it and in a few cases they've left it and in most cases they'll\n\n1:51:44.760 --> 1:51:51.840\n see our point of view and take it because that's how we've built the psych system by essentially\n\n1:51:51.840 --> 1:51:59.560\n tacking with the funding wins where people would fund a project and half of it would be general\n\n1:51:59.560 --> 1:52:04.080\n knowledge that would stay permanently as part of psych. So always with these partnerships it's not\n\n1:52:04.080 --> 1:52:10.920\n like a distraction from the main psych development. It's a small distraction. It's a small but it's\n\n1:52:10.920 --> 1:52:14.480\n not a complete one so you're adding to the knowledge base. Yes absolutely and we try to\n\n1:52:14.480 --> 1:52:23.320\n stay away from projects that would not have that property. So let me go back and talk about open\n\n1:52:23.320 --> 1:52:34.520\n psych for a second. So I've had a lot of trouble expressing and convincing other AI researchers how\n\n1:52:34.520 --> 1:52:41.600\n important it is to use an expressive representation language like we do this higher order logic rather\n\n1:52:41.600 --> 1:52:52.280\n than just using some triple store knowledge graph type representation. And so as an attempt to show\n\n1:52:52.280 --> 1:53:02.520\n them why they needed something more we said oh well we'll represent this unimportant projection\n\n1:53:02.520 --> 1:53:11.040\n or shadow or subset of psych that just happens to be the simple binary relations, the relation\n\n1:53:11.040 --> 1:53:20.160\n argument one argument two triples and so on. And then you'll see how much more useful it is if you\n\n1:53:20.160 --> 1:53:29.200\n had the entire psych system. So it's all well and good to have the taxonomic relations between terms\n\n1:53:29.200 --> 1:53:39.640\n like person and night and sleep and bed and house and eyes and so on. But think about how much more\n\n1:53:39.640 --> 1:53:46.040\n useful it would be if you also had all the rules of thumb about those things like people sleep at\n\n1:53:46.040 --> 1:53:50.240\n night, they sleep lying down, they sleep with their eyes closed, they usually sleep in beds in\n\n1:53:50.240 --> 1:53:55.560\n our country, they sleep for hours at a time, they can be woken up, they don't like being woken up\n\n1:53:55.560 --> 1:54:02.000\n and so on and so on. So it's that massive amount of knowledge which is not part of open psych and\n\n1:54:02.000 --> 1:54:08.400\n we thought that all the researchers would then immediately say oh my god of course we need the\n\n1:54:08.400 --> 1:54:15.360\n other 90% that you're not giving us, let's partner and license psych so that we can use it in our\n\n1:54:15.360 --> 1:54:20.640\n research. But instead what people said is oh even the bit you've released is so much better than\n\n1:54:20.640 --> 1:54:25.760\n anything we had, we'll just make do with this. And so if you look there are a lot of robotics\n\n1:54:25.760 --> 1:54:33.320\n companies today for example which use open psych as their fundamental ontology and in some sense\n\n1:54:33.320 --> 1:54:40.080\n the whole world missed the point of open psych and we were doing it to show people why that's\n\n1:54:40.080 --> 1:54:45.160\n not really what they wanted and too many people thought somehow that this was psych or that this\n\n1:54:45.160 --> 1:54:52.200\n was in fact good enough for them and they never even bothered coming to us to get access to the\n\n1:54:52.200 --> 1:54:57.520\n full psych. But there's two parts to open psych. So one is convincing people on the idea and the\n\n1:54:57.520 --> 1:55:02.560\n power of this general kind of representation of knowledge and the value that you hold in having\n\n1:55:02.560 --> 1:55:07.720\n acquired that knowledge and built it and continue to build it. And the other is the code base. This\n\n1:55:07.720 --> 1:55:16.480\n is the code side of it. So my sense of the code base that psych or psych is operating with, I mean\n\n1:55:16.480 --> 1:55:23.760\n it has the technical debt of the three decades plus right. This is the exact same problem that\n\n1:55:23.760 --> 1:55:29.440\n Google had to deal with with the early version of TensorFlow. It's still dealing with that. They had\n\n1:55:29.440 --> 1:55:36.280\n to basically break compatibility with the past several times and that's only over a period of\n\n1:55:36.280 --> 1:55:43.400\n a couple years. But they I think successfully opened up, it's very risky, very gutsy move to\n\n1:55:43.400 --> 1:55:51.280\n open up TensorFlow and then PyTorch on the Facebook side. And what you see is there's a\n\n1:55:51.280 --> 1:55:57.800\n magic place where you can find a community, where you could develop a community that builds on the\n\n1:55:57.800 --> 1:56:05.040\n system without taking away any of, not any, but most of the value. So most of the value that\n\n1:56:05.040 --> 1:56:10.640\n Google has is still a Google. Most of the value that Facebook has still Facebook even though some\n\n1:56:10.640 --> 1:56:16.560\n of this major machine learning tooling is released into the open. My question is not so much on the\n\n1:56:16.560 --> 1:56:24.120\n knowledge, which is also a big part of open psych, but all the different kinds of tooling. So there's\n\n1:56:24.120 --> 1:56:29.040\n the kind of, all the kinds of stuff you can do on the knowledge graph, knowledge base, whatever we\n\n1:56:29.040 --> 1:56:35.680\n call it. There's the inference engines. So there could be some, there probably are a bunch of\n\n1:56:35.680 --> 1:56:40.120\n proprietary stuff you want to kind of keep secret. And there's probably some stuff you can open up\n\n1:56:40.120 --> 1:56:45.040\n completely and then let the community build up enough community where they develop stuff on top\n\n1:56:45.040 --> 1:56:51.120\n of it. Yes, there will be those publications and academic work and all that kind of stuff. And also\n\n1:56:51.120 --> 1:56:56.320\n the tooling of adding to the knowledge base, right? Like developing, you know, there's incredible\n\n1:56:56.320 --> 1:57:00.920\n amount, like there's so many people that are just really good at this kind of stuff in the open\n\n1:57:00.920 --> 1:57:06.840\n source community. So my question for you is like, have you struggled with this kind of idea that\n\n1:57:06.840 --> 1:57:11.680\n you have so much value in your company already? You've developed so many good things. You have\n\n1:57:11.680 --> 1:57:17.000\n clients that really value your relationships. And then there's this dormant giant open source\n\n1:57:17.000 --> 1:57:24.200\n community that as far as I know, you're not utilizing. There's so many things to say there,\n\n1:57:24.200 --> 1:57:32.760\n but there could be magic moments where the community builds up large enough to where the\n\n1:57:32.760 --> 1:57:39.120\n artificial intelligence field that is currently 99.9% machine learning is dominated by machine\n\n1:57:39.120 --> 1:57:45.880\n learning, has a face shift towards like, or at least in part towards more like what you might\n\n1:57:45.880 --> 1:57:53.880\n call symbolic AI. This whole place where psych is like at the center of, and then as you know,\n\n1:57:53.880 --> 1:57:59.280\n that requires a little bit leap of faith because you're now surfing and there'll be obviously\n\n1:57:59.280 --> 1:58:04.600\n competitors that will pop up and start making you nervous and all that kind of stuff. So do you think\n\n1:58:04.600 --> 1:58:10.240\n about the space of open sourcing some parts and not others, how to leverage the community,\n\n1:58:10.240 --> 1:58:14.920\n all those kinds of things? That's a good question. And I think you phrased it the right way,\n\n1:58:14.920 --> 1:58:23.600\n which is we're constantly struggling with the question of what to open source, what to make\n\n1:58:23.600 --> 1:58:34.120\n public, what to even publicly talk about. And there are enormous pluses and minuses to every\n\n1:58:34.120 --> 1:58:44.880\n alternative. And it's very much like negotiating a very treacherous path. Partly the analogy is\n\n1:58:44.880 --> 1:58:51.400\n like if you slip, you could make a fatal mistake, give away something which essentially kills you\n\n1:58:51.400 --> 1:58:59.800\n or fail to give away something which failing to give it away hurts you and so on. So it is a very\n\n1:58:59.800 --> 1:59:10.360\n tough, tough question. Usually what we have done with people who've approached us to collaborate\n\n1:59:10.360 --> 1:59:19.680\n on research is to say we will make available to you the entire knowledge base and executable\n\n1:59:19.680 --> 1:59:29.680\n copies of all of the code, but only very, very limited source code access if you have some idea\n\n1:59:29.680 --> 1:59:36.520\n for how you might improve something or work with us on something. So let me also get back to one\n\n1:59:36.520 --> 1:59:45.560\n of the very, very first things we talked about here, which was separating the question of how\n\n1:59:45.560 --> 1:59:50.600\n could you get a computer to do this at all versus how could you get a computer to do this efficiently\n\n1:59:50.600 --> 1:59:59.360\n enough in real time. And so one of the early lessons we learned was that we had to separate\n\n1:59:59.360 --> 2:00:05.720\n the epistemological problem of what should the system know, separate that from the heuristic\n\n2:00:05.720 --> 2:00:12.640\n problem of how can the system reason efficiently with what it knows. And so instead of trying to\n\n2:00:12.640 --> 2:00:20.480\n pick one representation language which was the sweet spot or the best tradeoff point between\n\n2:00:20.480 --> 2:00:25.720\n expressiveness of the language and efficiency of the language, if you had to pick one,\n\n2:00:25.720 --> 2:00:31.600\n knowledge graphs would probably be, associative triples would probably be about the best you\n\n2:00:31.600 --> 2:00:37.560\n could do. And that's why we started there. But after a few years, we realized that what we could\n\n2:00:37.560 --> 2:00:44.480\n do is we could split this and we could have one nice, clean, epistemological level language,\n\n2:00:44.480 --> 2:00:52.560\n which is this higher order logic, and we could have one or more grubby but efficient heuristic\n\n2:00:52.560 --> 2:01:00.000\n level modules that opportunistically would say, oh, I can make progress on what you're trying to\n\n2:01:00.000 --> 2:01:05.680\n do over here. I have a special method that will contribute a little bit toward a solution.\n\n2:01:05.680 --> 2:01:09.000\n Of course, some subset of that knowledge.\n\n2:01:09.000 --> 2:01:14.400\n Exactly. So by now, we have over a thousand of these heuristic level modules, and they function\n\n2:01:14.400 --> 2:01:20.880\n as a kind of community of agents. And there's one of them, which is a general theorem prover. And in\n\n2:01:20.880 --> 2:01:29.360\n theory, that's the only one you need. But in practice, it always takes so long that you never\n\n2:01:29.360 --> 2:01:35.240\n want to call on it. You always want these other agents to very efficiently reason through it. It's\n\n2:01:35.240 --> 2:01:39.840\n sort of like if you're balancing a chemical equation. You could go back to first principles,\n\n2:01:39.840 --> 2:01:44.920\n but in fact, there are algorithms which are vastly more efficient. Or if you're trying to\n\n2:01:44.920 --> 2:01:52.280\n solve a quadratic equation, you could go back to first principles of mathematics. But it's much\n\n2:01:52.280 --> 2:01:58.400\n better to simply recognize that this is a quadratic equation and apply the binomial formula and snap,\n\n2:01:58.400 --> 2:02:04.800\n you get your answer right away and so on. So think of these as like a thousand little experts\n\n2:02:04.800 --> 2:02:11.200\n that are all looking at everything the site gets asked and looking at everything that every other\n\n2:02:11.200 --> 2:02:19.160\n little agent has contributed, almost like notes on a blackboard, notes on a whiteboard, and making\n\n2:02:19.160 --> 2:02:24.320\n additional notes when they think they can be helpful. And gradually, that community of agents\n\n2:02:24.320 --> 2:02:31.480\n gets an answer to your question, gets a solution to your problem. And if we ever come up in a domain\n\n2:02:31.480 --> 2:02:38.120\n application where Psych is getting the right answer but taking too long, then what we'll often\n\n2:02:38.120 --> 2:02:45.640\n do is talk to one of the human experts and say, here's the set of reasoning steps that Psych went\n\n2:02:45.640 --> 2:02:50.640\n through. You can see why it took it a long time to get the answer. How is it that you were able\n\n2:02:50.640 --> 2:02:57.600\n to answer that question in two seconds? And occasionally, you'll get an expert who just\n\n2:02:57.600 --> 2:03:02.440\n says, well, I just know it. I just was able to do it or something. And then you don't talk to them\n\n2:03:02.440 --> 2:03:07.680\n anymore. But sometimes you'll get an expert who says, well, let me introspect on that. Yes,\n\n2:03:07.680 --> 2:03:15.320\n here is a special representation we use just for aqueous chemistry equations, or here's a special\n\n2:03:15.320 --> 2:03:21.040\n representation and a special technique, which we can now apply to things in this special\n\n2:03:21.040 --> 2:03:29.080\n representation and so on. And then you add that as the 1001st HL heuristic level module. And from\n\n2:03:29.080 --> 2:03:35.200\n then on, in any application, if it ever comes up again, it'll be able to contribute and so on. So\n\n2:03:35.200 --> 2:03:43.240\n that's pretty much one of the main ways in which Psych has recouped this loss deficiency. A second\n\n2:03:43.240 --> 2:03:52.760\n important way is meta reasoning. So you can speed things up by focusing on removing knowledge from\n\n2:03:52.760 --> 2:03:58.000\n the system till all it has left is minimal knowledge needed. But that's the wrong thing to\n\n2:03:58.000 --> 2:04:02.360\n do, right? That would be like in a human extirpating part of their brain or something. That's really\n\n2:04:02.360 --> 2:04:08.600\n bad. So instead, what you want to do is give it meta level advice, tactical and strategic advice,\n\n2:04:08.600 --> 2:04:15.320\n that enables it to reason about what kind of knowledge is going to be relevant to this problem,\n\n2:04:15.320 --> 2:04:21.040\n what kind of tactics are going to be good to take in trying to attack this problem. When is it time\n\n2:04:21.040 --> 2:04:26.600\n to start trying to prove the negation of this thing, because I'm knocking myself out trying to\n\n2:04:26.600 --> 2:04:30.480\n prove it's true, and maybe it's false. And if I just spend a minute, I can see that it's false\n\n2:04:30.480 --> 2:04:37.680\n or something. So it's like dynamically pruning the graph to only like, based on the particular\n\n2:04:37.680 --> 2:04:45.960\n thing you're trying to infer. Yes. And so by now, we have about 150 of these sort of like\n\n2:04:45.960 --> 2:04:53.120\n breakthrough ideas that have led to dramatic speed ups in the inference process, where one\n\n2:04:53.120 --> 2:04:59.800\n of them was this ELHL split and lots of HL modules. Another one was using meta and meta\n\n2:04:59.800 --> 2:05:08.080\n level reasoning to reason about the reasoning that's going on and so on. And 150 breakthroughs\n\n2:05:08.080 --> 2:05:12.160\n may sound like a lot, but if you divide by 37 years, it's not as impressive.\n\n2:05:12.160 --> 2:05:21.200\n So there's these kind of heuristic modules that really help improve the inference. How hard,\n\n2:05:21.200 --> 2:05:30.880\n in general, is this? Because you mentioned higher order logic. In the general theorem prover sense,\n\n2:05:30.880 --> 2:05:37.760\n it's intractable, very difficult problem. Yes. So how hard is this inference problem when we're not\n\n2:05:37.760 --> 2:05:46.680\n talking about if we let go of the perfect and focus on the good? I would say it's half of the\n\n2:05:46.680 --> 2:05:54.320\n problem in the following empirical sense, which is over the years, about half of our effort,\n\n2:05:54.320 --> 2:06:02.160\n maybe 40% of our effort has been our team of inference programmers. And the other 50,\n\n2:06:02.160 --> 2:06:08.280\n 60% has been our ontologists or ontological engineers putting in knowledge. So our ontological\n\n2:06:08.280 --> 2:06:12.840\n engineers in most cases don't even know how to program. They have degrees in things like\n\n2:06:12.840 --> 2:06:17.520\n philosophy and so on. So it's almost like the... I love that. I love to hang out with\n\n2:06:17.520 --> 2:06:22.000\n those people actually. Oh yes, it's wonderful. But it's very much like the Eloy and the Morlocks\n\n2:06:22.000 --> 2:06:29.760\n in H.G. Wells Time Machine. So you have the Eloy who only program in the epistemological higher\n\n2:06:29.760 --> 2:06:36.800\n order logic language. And then you have the Morlocks who are under the ground figuring\n\n2:06:36.800 --> 2:06:43.440\n out what the machinery is that will make this efficiently operate and so on. And so, you know,\n\n2:06:43.440 --> 2:06:49.640\n occasionally they'll toss messages back to each other and so on. But it really is almost this\n\n2:06:49.640 --> 2:06:57.200\n 50 50 split between finding clever ways to recoup efficiency when you have an expressive language\n\n2:06:57.200 --> 2:07:03.200\n and putting in the content of what the system needs to know. And yeah, both are fascinating.\n\n2:07:03.200 --> 2:07:10.560\n To some degree, the entirety of the system, as far as I understand, is written in various variants\n\n2:07:10.560 --> 2:07:17.200\n of Lisp. So my favorite program language is still Lisp. I don't program in it much anymore because,\n\n2:07:17.200 --> 2:07:24.840\n you know, the world has in majority of its system has moved on. Like everybody respects Lisp,\n\n2:07:24.840 --> 2:07:30.920\n but many of the systems are not written in Lisp anymore. But Syke, as far as I understand,\n\n2:07:30.920 --> 2:07:37.200\n maybe you can correct me, there's a bunch of Lisp in it. Yeah. So it's based on Lisp code that we\n\n2:07:37.200 --> 2:07:44.920\n produced. Most of the programming is still going on in a dialect of Lisp. And then for efficiency\n\n2:07:44.920 --> 2:07:51.800\n reasons, that gets automatically translated into things like Java or C. Nowadays, it's almost all\n\n2:07:51.800 --> 2:07:58.560\n translated into Java because Java has gotten good enough that that's really all we need to do.\n\n2:07:58.560 --> 2:08:02.600\n So it's translated into Java, and then Java is compiled down to bytecode.\n\n2:08:02.600 --> 2:08:03.040\n Yes.\n\n2:08:03.040 --> 2:08:11.280\n Okay, so that's sort of that's a that that that's a, you know, it's a process that probably has to\n\n2:08:11.280 --> 2:08:16.160\n do with the fact that when Syke was originally written, and you build up a powerful system,\n\n2:08:16.160 --> 2:08:22.520\n like there is some technical depth you have to deal with, as is the case with most powerful\n\n2:08:22.520 --> 2:08:31.200\n systems that span years. Have you ever considered this, this would help me understand, because my\n\n2:08:31.200 --> 2:08:38.720\n perspective, so much of the value of everything you've done with Syke and Cycorp is the is the\n\n2:08:38.720 --> 2:08:44.640\n is the knowledge. Have you ever considered just like throwing away the code base and starting\n\n2:08:44.640 --> 2:08:53.480\n from scratch, not really throwing away, but sort of moving it to like throwing away that technical\n\n2:08:53.480 --> 2:08:59.800\n debt, starting with a more updated programming language? Is that throwing away a lot of value\n\n2:08:59.800 --> 2:09:05.400\n or no? Like, what's your sense? How much of the value is in the silly software engineering aspect,\n\n2:09:05.400 --> 2:09:07.720\n and how much of the value is in the knowledge?\n\n2:09:07.720 --> 2:09:21.840\n So development of programs in Lisp proceeds, I think, somewhere between a thousand and fifty\n\n2:09:21.840 --> 2:09:29.720\n thousand times faster than development in any of what you're calling modern or improved computer\n\n2:09:29.720 --> 2:09:30.200\n languages.\n\n2:09:30.200 --> 2:09:34.960\n Well, there's other functional languages like, you know, Clojure and all that. But I mean,\n\n2:09:34.960 --> 2:09:40.200\n I'm with you. I like Lisp. I just wonder how many great programmers there are. There's still like...\n\n2:09:40.200 --> 2:09:48.760\n Yes. So it is true when a new inference programmer comes on board, they need to learn some of Lisp.\n\n2:09:48.760 --> 2:09:55.080\n And in fact, we have a subset of Lisp, which we call cleverly Sub L, which is really all they\n\n2:09:55.080 --> 2:10:01.840\n need to learn. And so the programming actually goes on in Sub L, not in full Lisp. And so it\n\n2:10:01.840 --> 2:10:08.000\n does not take programmers very long at all to learn Sub L. And that's something which can then\n\n2:10:08.000 --> 2:10:14.620\n be translated efficiently into Java. And for some of our programmers who are doing, say,\n\n2:10:14.620 --> 2:10:21.600\n user interface work, then they never have to even learn Sub L. They just have to learn APIs into the\n\n2:10:21.600 --> 2:10:23.440\n basic psych engine.\n\n2:10:23.440 --> 2:10:29.920\n So you're not necessarily feeling the burden of like, it's extremely efficient. That's not a\n\n2:10:29.920 --> 2:10:31.960\n problem to solve. Okay.\n\n2:10:31.960 --> 2:10:37.320\n Right. The other thing is, remember that we're talking about hiring programmers to do inference,\n\n2:10:37.320 --> 2:10:43.680\n who are programmers interested in effectively automatic theorem proving. And so those are\n\n2:10:43.680 --> 2:10:50.880\n people already predisposed to representing things in logic and so on. And Lisp really was the\n\n2:10:50.880 --> 2:10:58.360\n programming language based on logic that John McCarthy and others who developed it basically\n\n2:10:58.360 --> 2:11:06.120\n took the formalisms that Alonzo Church and other philosophers, other logicians, had come up with\n\n2:11:06.120 --> 2:11:12.840\n and basically said, can we basically make a programming language which is effectively logic?\n\n2:11:12.840 --> 2:11:22.520\n And so since we're talking about reasoning about expressions written in this epistemological\n\n2:11:22.520 --> 2:11:27.040\n language and we're doing operations which are effectively like theorem proving type\n\n2:11:27.040 --> 2:11:34.800\n operations and so on, there's a natural impedance match between Lisp and the knowledge, the\n\n2:11:34.800 --> 2:11:36.040\n way it's represented.\n\n2:11:36.040 --> 2:11:40.640\n So I guess you could say it's a perfectly logical language to use.\n\n2:11:40.640 --> 2:11:41.640\n Oh, yes.\n\n2:11:41.640 --> 2:11:42.640\n Okay, I'm sorry.\n\n2:11:42.640 --> 2:11:46.120\n I'll even let you get away with that.\n\n2:11:46.120 --> 2:11:47.920\n Okay, thank you. I appreciate it.\n\n2:11:47.920 --> 2:11:53.240\n So I'll probably use that in the future without credit.\n\n2:11:53.240 --> 2:12:01.340\n But no, I think the point is that the language you program in isn't really that important.\n\n2:12:01.340 --> 2:12:07.240\n It's more that you have to be able to think in terms of, for instance, creating new helpful\n\n2:12:07.240 --> 2:12:13.580\n HL modules and how they'll work with each other and looking at things that are taking\n\n2:12:13.580 --> 2:12:20.280\n a long time and coming up with new specialized data structures that will make this efficient.\n\n2:12:20.280 --> 2:12:26.080\n So let me just give you one very simple example, which is when you have a transitive relation\n\n2:12:26.080 --> 2:12:29.960\n like larger than, this is larger than that, which is larger than that, which is larger\n\n2:12:29.960 --> 2:12:30.960\n than that.\n\n2:12:30.960 --> 2:12:33.440\n So the first thing must be larger than the last thing.\n\n2:12:33.440 --> 2:12:38.660\n Whenever you have a transitive relation, if you're not careful, if I ask whether this\n\n2:12:38.660 --> 2:12:43.560\n thing over here is larger than the thing over here, I'll have to do some kind of graph walk\n\n2:12:43.560 --> 2:12:48.680\n or theorem proving that might involve like five or 10 or 20 or 30 steps.\n\n2:12:48.680 --> 2:12:55.880\n But if you store, redundantly store the transitive closure, the cleanly star of that transitive\n\n2:12:55.880 --> 2:12:58.980\n relation, now you have this big table.\n\n2:12:58.980 --> 2:13:04.720\n But you can always guarantee that in one single step, you can just look up whether this is\n\n2:13:04.720 --> 2:13:06.700\n larger than that.\n\n2:13:06.700 --> 2:13:12.600\n And so there are lots of cases where storage is cheap today.\n\n2:13:12.600 --> 2:13:18.400\n And so by having this extra redundant data structure, we can answer this commonly occurring\n\n2:13:18.400 --> 2:13:22.240\n type of question very, very efficiently.\n\n2:13:22.240 --> 2:13:28.960\n Let me give you one other analogy, analog of that, which is something we call rule macro\n\n2:13:28.960 --> 2:13:36.840\n predicates, which is we'll see this complicated rule and we'll notice that things very much\n\n2:13:36.840 --> 2:13:41.080\n like it syntactically come up again and again and again.\n\n2:13:41.080 --> 2:13:47.920\n So we'll create a whole brand new relation or predicate or function that captures that\n\n2:13:47.920 --> 2:13:54.760\n and takes maybe not two arguments, takes maybe three, four or five arguments and so on.\n\n2:13:54.760 --> 2:14:04.120\n And now we have effectively converted some complicated if then rule that might have to\n\n2:14:04.120 --> 2:14:10.160\n have inference done on it into some ground atomic formula, which is just the name of\n\n2:14:10.160 --> 2:14:13.200\n a relation and a few arguments and so on.\n\n2:14:13.200 --> 2:14:20.880\n And so converting commonly occurring types or schemas of rules into brand new predicates,\n\n2:14:20.880 --> 2:14:27.520\n brand new functions, turns out to enormously speed up the inference process.\n\n2:14:27.520 --> 2:14:32.720\n So now we've covered about four of the 150 good ideas I said.\n\n2:14:32.720 --> 2:14:37.400\n So that idea in particular is like a nice compression that turns out to be really useful.\n\n2:14:37.400 --> 2:14:38.400\n That's really interesting.\n\n2:14:38.400 --> 2:14:40.920\n I mean, this whole thing is just fascinating from a philosophical.\n\n2:14:40.920 --> 2:14:48.200\n There's part of me, I mean, it makes me a little bit sad because your work is both from\n\n2:14:48.200 --> 2:14:53.600\n a computer science perspective fascinating and the inference engine from a epistemological\n\n2:14:53.600 --> 2:14:59.400\n philosophical aspect fascinating, but you know, it is also you're running a company\n\n2:14:59.400 --> 2:15:03.560\n and there's some stuff that has to remain private and it's sad.\n\n2:15:03.560 --> 2:15:09.080\n Well here's something that may make you feel better, a little bit better.\n\n2:15:09.080 --> 2:15:15.200\n We've formed a not for profit company called the Knowledge Axe Immunization Institute,\n\n2:15:15.200 --> 2:15:17.040\n NAX, KNAX.\n\n2:15:17.040 --> 2:15:25.440\n And I have this firm belief with a lot of empirical evidence to support it that the\n\n2:15:25.440 --> 2:15:31.440\n education that people get in high schools, in colleges, in graduate schools and so on\n\n2:15:31.440 --> 2:15:38.280\n is almost completely orthogonal to, almost completely irrelevant to how good they're\n\n2:15:38.280 --> 2:15:45.080\n going to be at coming up to speed in doing this kind of ontological engineering and writing\n\n2:15:45.080 --> 2:15:49.560\n these assertions and rules and so on in psych.\n\n2:15:49.560 --> 2:15:54.880\n And so very often we'll interview candidates who have their PhD in philosophy, who've\n\n2:15:54.880 --> 2:15:59.680\n taught logic for years and so on, and they're just awful.\n\n2:15:59.680 --> 2:16:00.840\n But the converse is true.\n\n2:16:00.840 --> 2:16:06.340\n So one of the best ontological engineers we ever had never graduated high school.\n\n2:16:06.340 --> 2:16:13.560\n And so the purpose of Knowledge Axe Immunization Institute, if we can get some foundations\n\n2:16:13.560 --> 2:16:20.640\n to help support it is identify people in the general population, maybe high school dropouts,\n\n2:16:20.640 --> 2:16:28.360\n who have latent talent for this sort of thing, offer them effectively scholarships to train\n\n2:16:28.360 --> 2:16:35.280\n them and then help place them in companies that need more trained ontological engineers,\n\n2:16:35.280 --> 2:16:39.560\n some of which would be working for us, but mostly would be working for partners or customers\n\n2:16:39.560 --> 2:16:40.680\n or something.\n\n2:16:40.680 --> 2:16:46.080\n And if we could do that, that would create an enormous number of relatively very high\n\n2:16:46.080 --> 2:16:53.880\n paying jobs for people who currently have no way out of some situation that they're\n\n2:16:53.880 --> 2:16:55.100\n locked into.\n\n2:16:55.100 --> 2:17:01.080\n So is there something you can put into words that describes somebody who would be great\n\n2:17:01.080 --> 2:17:03.280\n at ontological engineering?\n\n2:17:03.280 --> 2:17:12.200\n So what characteristics about a person make them great at this task, this task of converting\n\n2:17:12.200 --> 2:17:17.240\n the messiness of human language and knowledge into formal logic?\n\n2:17:17.240 --> 2:17:22.760\n This is very much like what Alan Turing had to do during World War II in trying to find\n\n2:17:22.760 --> 2:17:28.400\n people to bring to Bletchley Park, where he would publish in the London Times cryptic\n\n2:17:28.400 --> 2:17:34.760\n crossword puzzles along with some innocuous looking note, which essentially said, if you\n\n2:17:34.760 --> 2:17:40.820\n were able to solve this puzzle in less than 15 minutes, please call this phone number\n\n2:17:40.820 --> 2:17:42.960\n and so on.\n\n2:17:42.960 --> 2:17:49.840\n Or back when I was young, there was the practice of having matchbooks, where on the inside\n\n2:17:49.840 --> 2:17:54.040\n of the matchbook, there would be a, can you draw this?\n\n2:17:54.040 --> 2:18:00.100\n You have a career in art, commercial art, if you can copy this drawing and so on.\n\n2:18:00.100 --> 2:18:02.400\n So yes, the analog of that.\n\n2:18:02.400 --> 2:18:06.000\n Is there a little test to get to the core of whether you're going to be good or not?\n\n2:18:06.000 --> 2:18:14.020\n So part of it has to do with being able to make and appreciate and react negatively appropriately\n\n2:18:14.020 --> 2:18:16.160\n to puns and other jokes.\n\n2:18:16.160 --> 2:18:18.740\n So you have to have a kind of sense of humor.\n\n2:18:18.740 --> 2:18:24.640\n And if you're good at telling jokes and good at understanding jokes, that's one\n\n2:18:24.640 --> 2:18:25.640\n indicator.\n\n2:18:25.640 --> 2:18:26.640\n Like puns?\n\n2:18:26.640 --> 2:18:27.640\n Yes.\n\n2:18:27.640 --> 2:18:28.640\n Like dad jokes?\n\n2:18:28.640 --> 2:18:29.640\n Yes.\n\n2:18:29.640 --> 2:18:32.360\n Well, maybe not dad jokes, but funny jokes.\n\n2:18:32.360 --> 2:18:36.360\n I think I'm applying to work at SACOR.\n\n2:18:36.360 --> 2:18:38.240\n Another is if you're able to introspect.\n\n2:18:38.240 --> 2:18:48.360\n So very often, we'll give someone a simple question and we'll say like, why is this?\n\n2:18:48.360 --> 2:18:53.480\n And sometimes they'll just say, because it is, okay, that's a bad sign.\n\n2:18:53.480 --> 2:18:56.560\n But very often, they'll be able to introspect and so on.\n\n2:18:56.560 --> 2:19:01.800\n So one of the questions I often ask is I'll point to a sentence with a pronoun in it and\n\n2:19:01.800 --> 2:19:07.700\n I'll say, the referent of that pronoun is obviously this noun over here.\n\n2:19:07.700 --> 2:19:14.980\n How would you or I or an AI or a five year old, 10 year old child know that that pronoun\n\n2:19:14.980 --> 2:19:18.240\n refers to that noun over here?\n\n2:19:18.240 --> 2:19:25.760\n And often the people who are going to be good at ontological engineering will give me some\n\n2:19:25.760 --> 2:19:30.100\n causal explanation or will refer to some things that are true in the world.\n\n2:19:30.100 --> 2:19:35.120\n So if you imagine a sentence like, the horse was led into the barn while its head was still\n\n2:19:35.120 --> 2:19:36.120\n wet.\n\n2:19:36.120 --> 2:19:38.980\n And so its head refers to the horse's head.\n\n2:19:38.980 --> 2:19:40.420\n But how do you know that?\n\n2:19:40.420 --> 2:19:42.140\n And so some people will say, I just know it.\n\n2:19:42.140 --> 2:19:45.620\n Some people will say, well, the horse was the subject of the sentence.\n\n2:19:45.620 --> 2:19:50.080\n And I'll say, okay, well, what about the horse was led into the barn while its roof was still\n\n2:19:50.080 --> 2:19:51.080\n wet?\n\n2:19:51.080 --> 2:19:54.360\n Now, its roof obviously refers to the barn.\n\n2:19:54.360 --> 2:19:58.440\n And so then they'll say, oh, well, that's because it's the closest noun.\n\n2:19:58.440 --> 2:20:05.380\n And so basically, if they try to give me answers which are based on syntax and grammar and\n\n2:20:05.380 --> 2:20:07.580\n so on, that's a really bad sign.\n\n2:20:07.580 --> 2:20:12.120\n But if they're able to say things like, well, horses have heads and barns don't and barns\n\n2:20:12.120 --> 2:20:16.860\n have roofs and horses don't, then that's a positive sign that they're going to be good\n\n2:20:16.860 --> 2:20:22.180\n at this because they can introspect on what's true in the world that leads you to know certain\n\n2:20:22.180 --> 2:20:23.180\n things.\n\n2:20:23.180 --> 2:20:28.060\n How fascinating is it that getting a Ph.D. makes you less capable to introspect deeply\n\n2:20:28.060 --> 2:20:29.060\n about this?\n\n2:20:29.060 --> 2:20:30.860\n Oh, I wouldn't go that far.\n\n2:20:30.860 --> 2:20:32.820\n I'm not saying that it makes you less capable.\n\n2:20:32.820 --> 2:20:37.500\n Let's just say it's independent of how good people are.\n\n2:20:37.500 --> 2:20:38.500\n You're not saying that.\n\n2:20:38.500 --> 2:20:39.500\n I'm saying that.\n\n2:20:39.500 --> 2:20:47.740\n It's interesting that for a lot of people, Ph.D.s, sorry, philosophy aside, that sometimes\n\n2:20:47.740 --> 2:20:52.060\n education narrows your thinking versus expands it.\n\n2:20:52.060 --> 2:20:53.600\n It's kind of fascinating.\n\n2:20:53.600 --> 2:20:58.900\n And for certain when you're trying to do ontological engineering, which is essentially teach our\n\n2:20:58.900 --> 2:21:05.980\n future AI overlords how to reason deeply about this world and how to understand it, that\n\n2:21:05.980 --> 2:21:08.700\n requires that you think deeply about the world.\n\n2:21:08.700 --> 2:21:14.820\n So I'll tell you a sad story about mathcraft, which is why is that not widely used in schools\n\n2:21:14.820 --> 2:21:16.100\n today?\n\n2:21:16.100 --> 2:21:20.700\n We're not really trying to make big profit on it or anything like that.\n\n2:21:20.700 --> 2:21:27.060\n When we've gone to schools, their attitude has been, well, if a student spends 20 hours\n\n2:21:27.060 --> 2:21:34.220\n going through this mathcraft program from start to end and so on, will it improve their\n\n2:21:34.220 --> 2:21:39.980\n score on this standardized test more than if they spent 20 hours just doing mindless\n\n2:21:39.980 --> 2:21:43.700\n drills of problem after problem after problem?\n\n2:21:43.700 --> 2:21:47.820\n And the answer is, well, no, but it'll increase their understanding more.\n\n2:21:47.820 --> 2:21:54.260\n And their attitude is, well, if it doesn't increase their score on this test, then we're\n\n2:21:54.260 --> 2:21:55.660\n not going to adopt it.\n\n2:21:55.660 --> 2:21:56.660\n That's sad.\n\n2:21:56.660 --> 2:22:01.900\n I mean, that's a whole another three, four hour conversation about the education system.\n\n2:22:01.900 --> 2:22:06.660\n But let me ask you, let me go super philosophical, as if we weren't already.\n\n2:22:06.660 --> 2:22:11.620\n So in 1950, Alan Turing wrote the paper that formulated the Turing test.\n\n2:22:11.620 --> 2:22:12.620\n Yes.\n\n2:22:12.620 --> 2:22:16.020\n And he opened the paper with the question, can machines think?\n\n2:22:16.020 --> 2:22:17.020\n So what do you think?\n\n2:22:17.020 --> 2:22:18.020\n Can machines think?\n\n2:22:18.020 --> 2:22:20.820\n Let me ask you this question.\n\n2:22:20.820 --> 2:22:21.980\n Absolutely.\n\n2:22:21.980 --> 2:22:27.980\n Machines can think, certainly as well as humans can think, right?\n\n2:22:27.980 --> 2:22:34.380\n We're meat machines just because they're not currently made out of meat is just an engineering\n\n2:22:34.380 --> 2:22:38.300\n solution decision and so on.\n\n2:22:38.300 --> 2:22:42.180\n So of course machines can think.\n\n2:22:42.180 --> 2:22:51.860\n I think that there was a lot of damage done by people misunderstanding Turing's imitation\n\n2:22:51.860 --> 2:23:03.220\n game and focus on trying to get a chat bot to fool other people into thinking it was\n\n2:23:03.220 --> 2:23:06.540\n human and so on.\n\n2:23:06.540 --> 2:23:10.980\n That's not a terrible test in and of itself, but it shouldn't be your one and only test\n\n2:23:10.980 --> 2:23:13.380\n for intelligence.\n\n2:23:13.380 --> 2:23:19.180\n In terms of tests of intelligence, you know, with the Lobner Prize, which is a very kind\n\n2:23:19.180 --> 2:23:25.340\n of, you want to say a more strict formulation of the Turing test as originally formulated.\n\n2:23:25.340 --> 2:23:31.180\n And then there's something like Alexa Prize, which is more, I would say a more interesting\n\n2:23:31.180 --> 2:23:37.740\n formulation of the test, which is like, ultimately the metric is how long does a human want to\n\n2:23:37.740 --> 2:23:38.740\n talk to the AI system?\n\n2:23:38.740 --> 2:23:46.060\n So it's like if the goal is you want it to be 20 minutes, it's basically not just have\n\n2:23:46.060 --> 2:23:52.620\n a convincing conversation, but more like a compelling one or a fun one or an interesting\n\n2:23:52.620 --> 2:23:53.620\n one.\n\n2:23:53.620 --> 2:24:01.120\n And that seems like more to the spirit maybe of what Turing was imagining.\n\n2:24:01.120 --> 2:24:06.700\n But what for you do you think in the space of tests is a good test?\n\n2:24:06.700 --> 2:24:12.900\n When you see a system based on psych that passes that test, you'd be like, damn, we've\n\n2:24:12.900 --> 2:24:17.020\n created something special here.\n\n2:24:17.020 --> 2:24:23.700\n The test has to be something involving depth of reasoning and recursiveness of reasoning,\n\n2:24:23.700 --> 2:24:30.100\n the ability to answer repeated why questions about the answer you just gave.\n\n2:24:30.100 --> 2:24:33.140\n How many why questions in a row can you keep answering?\n\n2:24:33.140 --> 2:24:36.140\n Something like that.\n\n2:24:36.140 --> 2:24:41.820\n Just have like a young curious child and an AI system and how long will an AI system last\n\n2:24:41.820 --> 2:24:43.300\n before it wants to quit?\n\n2:24:43.300 --> 2:24:44.300\n Yes.\n\n2:24:44.300 --> 2:24:45.660\n And again, that's not the only test.\n\n2:24:45.660 --> 2:24:48.020\n Another one has to do with argumentation.\n\n2:24:48.020 --> 2:24:57.020\n In other words, here's a proposition, come up with pro and con arguments for it and try\n\n2:24:57.020 --> 2:25:02.300\n and give me convincing arguments on both sides.\n\n2:25:02.300 --> 2:25:09.660\n And so that's another important kind of ability that the system needs to be able to exhibit\n\n2:25:09.660 --> 2:25:12.860\n in order to really be intelligent, I think.\n\n2:25:12.860 --> 2:25:18.180\n So there's certain, I mean, if you look at IBM Watson and like certain impressive accomplishments\n\n2:25:18.180 --> 2:25:24.500\n for very specific tests, almost like a demo, right?\n\n2:25:24.500 --> 2:25:34.740\n There's some, like I talked to the guy who led the Jeopardy effort, and there's some\n\n2:25:34.740 --> 2:25:40.260\n kind of hard coding heuristics tricks that you try to pull it all together to make the\n\n2:25:40.260 --> 2:25:43.060\n thing work in the end for this thing, right?\n\n2:25:43.060 --> 2:25:49.060\n That seems to be one of the lessons with AI is like, that's the fastest way to get a solution\n\n2:25:49.060 --> 2:25:50.580\n that's pretty damn impressive.\n\n2:25:50.580 --> 2:25:59.620\n So here's what I would say is that as impressive as that was, it made some mistakes, but more\n\n2:25:59.620 --> 2:26:07.260\n importantly, many of the mistakes it made were mistakes which no human would have made.\n\n2:26:07.260 --> 2:26:17.540\n And so part of the new or augmented Turing tests would have to be, and the mistakes you\n\n2:26:17.540 --> 2:26:24.300\n make are ones which humans don't basically look at and say, what?\n\n2:26:24.300 --> 2:26:33.540\n So for example, there was a question about which 16th century Italian politician, blah,\n\n2:26:33.540 --> 2:26:37.260\n blah, blah, and Watson said Ronald Reagan.\n\n2:26:37.260 --> 2:26:42.000\n So most Americans would have gotten that question wrong, but they would never have said Ronald\n\n2:26:42.000 --> 2:26:49.860\n Reagan as an answer because among the things they know is that he lived relatively recently\n\n2:26:49.860 --> 2:26:53.960\n and people don't really live 400 years and things like that.\n\n2:26:53.960 --> 2:27:00.860\n So that's, I think, a very important thing, which is if it's making mistakes which no\n\n2:27:00.860 --> 2:27:05.780\n normal sane human would have made, then that's a really bad sign.\n\n2:27:05.780 --> 2:27:10.140\n And if it's not making those kinds of mistakes, then that's a good sign.\n\n2:27:10.140 --> 2:27:12.980\n And I don't think it's any one very, very simple test.\n\n2:27:12.980 --> 2:27:17.300\n I think it's all of the things you mentioned, all the things I mentioned is really a battery\n\n2:27:17.300 --> 2:27:23.700\n of tests, which together, if it passes almost all of these tests, it'd be hard to argue\n\n2:27:23.700 --> 2:27:25.340\n that it's not intelligent.\n\n2:27:25.340 --> 2:27:30.980\n And if it fails several of these tests, it's really hard to argue that it really understands\n\n2:27:30.980 --> 2:27:33.460\n what it's doing and that it really is generally intelligent.\n\n2:27:33.460 --> 2:27:40.820\n So to pass all of those tests, we've talked a lot about psych and knowledge and reasoning.\n\n2:27:40.820 --> 2:27:47.540\n Do you think this AI system would need to have some other human like elements, for example,\n\n2:27:47.540 --> 2:27:52.820\n a body or a physical manifestation in this world?\n\n2:27:52.820 --> 2:27:59.980\n And another one which seems to be fundamental to the human experience is consciousness.\n\n2:27:59.980 --> 2:28:04.740\n The subjective experience of what it's like to actually be you.\n\n2:28:04.740 --> 2:28:08.700\n Do you think it needs those to be able to pass all of those tests and to achieve general\n\n2:28:08.700 --> 2:28:09.700\n intelligence?\n\n2:28:09.700 --> 2:28:10.700\n It's a good question.\n\n2:28:10.700 --> 2:28:15.340\n I think in the case of a body, no, I know there are a lot of people like Penrose who\n\n2:28:15.340 --> 2:28:21.940\n would have disagreed with me and others, but no, I don't think it needs to have a body\n\n2:28:21.940 --> 2:28:24.300\n in order to be intelligent.\n\n2:28:24.300 --> 2:28:32.780\n I think that it needs to be able to talk about having a body and having sensations and having\n\n2:28:32.780 --> 2:28:33.980\n emotions and so on.\n\n2:28:33.980 --> 2:28:39.380\n It doesn't actually have to have all of that, but it has to understand it in the same way\n\n2:28:39.380 --> 2:28:47.300\n that Helen Keller was perfectly intelligent and able to talk about colors and sounds and\n\n2:28:47.300 --> 2:28:54.100\n shapes and so on, even though she didn't directly experience all the same things that the rest\n\n2:28:54.100 --> 2:28:55.100\n of us do.\n\n2:28:55.100 --> 2:29:04.060\n So knowledge of it and being able to correctly make use of that is certainly an important\n\n2:29:04.060 --> 2:29:09.420\n facility, but actually having a body, if you believe that that's just a kind of religious\n\n2:29:09.420 --> 2:29:15.740\n or mystical belief, you can't really argue for or against it, I suppose.\n\n2:29:15.740 --> 2:29:19.340\n It's just something that some people believe.\n\n2:29:19.340 --> 2:29:24.540\n What about an extension of the body, which is consciousness?\n\n2:29:24.540 --> 2:29:27.780\n It feels like something to be here.\n\n2:29:27.780 --> 2:29:28.780\n Sure.\n\n2:29:28.780 --> 2:29:30.820\n But what does that really mean?\n\n2:29:30.820 --> 2:29:35.940\n It's like, well, if I talk to you, you say things which make me believe that you're conscious.\n\n2:29:35.940 --> 2:29:40.540\n I know that I'm conscious, but you're just taking my word for it now.\n\n2:29:40.540 --> 2:29:46.620\n But in the same sense, psych is conscious in that same sense already, where of course\n\n2:29:46.620 --> 2:29:50.620\n it's a computer program, it understands where and when it's running, it understands who's\n\n2:29:50.620 --> 2:29:55.300\n talking to it, it understands what its task is, what its goals are, what its current problem\n\n2:29:55.300 --> 2:29:59.600\n is that it's working on, it understands how long it's spent on things, what it's tried,\n\n2:29:59.600 --> 2:30:06.300\n it understands what it's done in the past, and so on.\n\n2:30:06.300 --> 2:30:11.340\n If we want to call that consciousness, then yes, psych is already conscious.\n\n2:30:11.340 --> 2:30:15.700\n But I don't think that I would ascribe anything mystical to that.\n\n2:30:15.700 --> 2:30:21.220\n Again, some people would, but I would say that other than our own personal experience\n\n2:30:21.220 --> 2:30:27.980\n of consciousness, we're just treating everyone else in the world, so to speak, at their word\n\n2:30:27.980 --> 2:30:29.820\n about being conscious.\n\n2:30:29.820 --> 2:30:39.300\n And so if a computer program, if an AI is able to exhibit all the same kinds of response\n\n2:30:39.300 --> 2:30:46.500\n as you would expect of a conscious entity, then doesn't it deserve the label of consciousness\n\n2:30:46.500 --> 2:30:47.500\n just as much?\n\n2:30:47.500 --> 2:30:51.200\n So there's another burden that comes with this whole intelligence thing that humans\n\n2:30:51.200 --> 2:30:59.780\n got is the extinguishing of the light of consciousness, which is kind of realizing that we're going\n\n2:30:59.780 --> 2:31:02.660\n to be dead someday.\n\n2:31:02.660 --> 2:31:09.060\n And there's a bunch of philosophers like Ernest Becker, who kind of think that this realization\n\n2:31:09.060 --> 2:31:18.180\n of mortality, and then fear, sometimes they call it terror of mortality, is one of the\n\n2:31:18.180 --> 2:31:24.980\n creative forces behind human condition, like, it's the thing that drives us.\n\n2:31:24.980 --> 2:31:27.900\n Do you think it's important for an AI system?\n\n2:31:27.900 --> 2:31:36.660\n You know, when Psych proposed that it's not human, and it's one of the moderators of\n\n2:31:36.660 --> 2:31:43.980\n his contents, you know, there's another question it could ask, which is like, it kind of knows\n\n2:31:43.980 --> 2:31:47.760\n that humans are mortal, am I mortal?\n\n2:31:47.760 --> 2:31:54.620\n And I think one really important thing that's possible when you're conscious is to fear\n\n2:31:54.620 --> 2:31:59.020\n the extinguishing of that consciousness, the fear of mortality.\n\n2:31:59.020 --> 2:32:04.340\n Do you think that's useful for intelligence, thinking like, I might die, and I really don't\n\n2:32:04.340 --> 2:32:05.340\n want to die?\n\n2:32:05.340 --> 2:32:06.660\n I don't think so.\n\n2:32:06.660 --> 2:32:12.940\n I think it may help some humans to be better people.\n\n2:32:12.940 --> 2:32:16.140\n It may help some humans to be more creative, and so on.\n\n2:32:16.140 --> 2:32:23.660\n I don't think it's necessary for AIs to believe that they have limited lifespans, and therefore\n\n2:32:23.660 --> 2:32:26.020\n they should make the most of their behavior.\n\n2:32:26.020 --> 2:32:30.980\n Maybe eventually the answer to that and my answer to that will change, but as of now\n\n2:32:30.980 --> 2:32:36.980\n I would say that that's almost like a frill or a side effect that is not, in fact, if\n\n2:32:36.980 --> 2:32:42.780\n you look at most humans, most humans ignore the fact that they're going to die most of\n\n2:32:42.780 --> 2:32:43.780\n the time.\n\n2:32:43.780 --> 2:32:49.700\n Well, but that's like, this goes to the white space between the words.\n\n2:32:49.700 --> 2:32:54.300\n So what Ernest Becker argues is that that ignoring is we're living in an illusion that\n\n2:32:54.300 --> 2:32:57.780\n we constructed on the foundation of this terror.\n\n2:32:57.780 --> 2:33:05.100\n So we're escape life as we know it, pursuing things, creating things, love, everything\n\n2:33:05.100 --> 2:33:11.620\n we can think of that's beautiful about humanity is just trying to escape this realization\n\n2:33:11.620 --> 2:33:13.420\n that we're going to die one day.\n\n2:33:13.420 --> 2:33:21.420\n That's his idea, and I think, I don't know if I 100% believe in this, but it certainly\n\n2:33:21.420 --> 2:33:22.700\n rhymes.\n\n2:33:22.700 --> 2:33:25.620\n It seems like to me like it rhymes with the truth.\n\n2:33:25.620 --> 2:33:26.620\n Yeah.\n\n2:33:26.620 --> 2:33:33.340\n I think that for some people that's going to be a more powerful factor than others.\n\n2:33:33.340 --> 2:33:35.860\n Clearly Doug is talking about Russians.\n\n2:33:35.860 --> 2:33:44.700\n So I'm Russian, so clearly it infiltrates all of Russian literature.\n\n2:33:44.700 --> 2:33:53.860\n And AI doesn't have to have fear of death as a motivating force in that we can build\n\n2:33:53.860 --> 2:33:55.700\n in motivation.\n\n2:33:55.700 --> 2:34:03.180\n So we can build in the motivation of obeying users and making users happy and making others\n\n2:34:03.180 --> 2:34:12.380\n happy and so on, and that can substitute for this sort of personal fear of death that sometimes\n\n2:34:12.380 --> 2:34:16.940\n leads to bursts of creativity in humans.\n\n2:34:16.940 --> 2:34:18.780\n Yeah, I don't know.\n\n2:34:18.780 --> 2:34:23.420\n I think AI really needs to understand death deeply in order to be able to drive a car,\n\n2:34:23.420 --> 2:34:24.860\n for example.\n\n2:34:24.860 --> 2:34:28.100\n I think there's just some, like, there...\n\n2:34:28.100 --> 2:34:30.060\n No, I really disagree.\n\n2:34:30.060 --> 2:34:34.740\n I think it needs to understand the value of human life, especially the value of human\n\n2:34:34.740 --> 2:34:41.940\n life to other humans, and understand that certain things are more important than other\n\n2:34:41.940 --> 2:34:42.940\n things.\n\n2:34:42.940 --> 2:34:48.060\n So it has to have a lot of knowledge about ethics and morality and so on.\n\n2:34:48.060 --> 2:34:51.220\n But some of it is so messy that it's impossible to encode.\n\n2:34:51.220 --> 2:34:52.220\n For example, there's...\n\n2:34:52.220 --> 2:34:53.780\n I disagree.\n\n2:34:53.780 --> 2:34:59.320\n So if there's a person dying right in front of us, most human beings would help that person,\n\n2:34:59.320 --> 2:35:04.580\n but they would not apply that same ethics to everybody else in the world.\n\n2:35:04.580 --> 2:35:09.100\n This is the tragedy of how difficult it is to be a doctor, because they know when they\n\n2:35:09.100 --> 2:35:15.720\n help a dying child, they know that the money they're spending on this child cannot possibly\n\n2:35:15.720 --> 2:35:18.920\n be spent on every other child that's dying.\n\n2:35:18.920 --> 2:35:24.700\n And that's a very difficult to encode decision.\n\n2:35:24.700 --> 2:35:26.540\n Perhaps it is...\n\n2:35:26.540 --> 2:35:27.540\n Perhaps it could be formalized.\n\n2:35:27.540 --> 2:35:31.900\n Oh, but I mean, you're talking about autonomous vehicles, right?\n\n2:35:31.900 --> 2:35:39.340\n So autonomous vehicles are going to have to make those decisions all the time of, what\n\n2:35:39.340 --> 2:35:43.060\n is the chance of this bad event happening?\n\n2:35:43.060 --> 2:35:46.660\n How bad is that compared to this chance of that bad event happening?\n\n2:35:46.660 --> 2:35:47.660\n And so on.\n\n2:35:47.660 --> 2:35:52.940\n And when a potential accident is about to happen, is it worth taking this risk?\n\n2:35:52.940 --> 2:35:56.980\n If I have to make a choice, which of these two cars am I going to hit and why?\n\n2:35:56.980 --> 2:36:01.220\n See, I was thinking about a very different choice when I'm talking about hero mortality,\n\n2:36:01.220 --> 2:36:06.020\n which is just observing Manhattan style driving.\n\n2:36:06.020 --> 2:36:14.820\n I think that humans as an effective driver needs to threaten pedestrians lives a lot.\n\n2:36:14.820 --> 2:36:19.500\n There's a dance, I've watched pedestrians a lot, I worked on this problem, and it seems\n\n2:36:19.500 --> 2:36:27.220\n like the, if I could summarize the problem of a pedestrian crossing is the car with this\n\n2:36:27.220 --> 2:36:30.240\n movement is saying, I'm going to kill you.\n\n2:36:30.240 --> 2:36:33.320\n And the pedestrian is saying, maybe.\n\n2:36:33.320 --> 2:36:36.780\n And then they decide and they say, no, I don't think you have the guts to kill me.\n\n2:36:36.780 --> 2:36:39.460\n And you walk and they walk in front and they look away.\n\n2:36:39.460 --> 2:36:46.300\n And there's that dance, the pedestrian, this is a social contract that the pedestrian trusts\n\n2:36:46.300 --> 2:36:51.020\n that once they're in front of the car and the car is sufficiently, from a physics perspective,\n\n2:36:51.020 --> 2:36:53.220\n able to stop, they're going to stop.\n\n2:36:53.220 --> 2:36:58.540\n But the car also has to threaten that pedestrian is like, I'm late for work, so you're being\n\n2:36:58.540 --> 2:37:01.140\n kind of an asshole by crossing in front of me.\n\n2:37:01.140 --> 2:37:06.060\n But life and death is in like, it's part of the calculation here.\n\n2:37:06.060 --> 2:37:11.220\n And it's that equation is being solved millions of times a day.\n\n2:37:11.220 --> 2:37:12.220\n Yes.\n\n2:37:12.220 --> 2:37:15.540\n Very effectively, that game theory, whatever that formulation is.\n\n2:37:15.540 --> 2:37:16.540\n Absolutely.\n\n2:37:16.540 --> 2:37:22.260\n I just I don't know if it's as simple as some formalizable game theory problem.\n\n2:37:22.260 --> 2:37:28.300\n It could very well be in the case of driving and in the case of most of human society.\n\n2:37:28.300 --> 2:37:29.300\n I don't know.\n\n2:37:29.300 --> 2:37:34.660\n But yeah, you might be right that sort of the fear of death is just one of the quirks\n\n2:37:34.660 --> 2:37:42.500\n of like the way our brains have evolved, but it's not a necessary feature of intelligence.\n\n2:37:42.500 --> 2:37:48.740\n Others certainly are always doing this kind of estimate, even if it's unconscious, subconscious,\n\n2:37:48.740 --> 2:37:52.860\n of what are the chances of various bad outcomes happening?\n\n2:37:52.860 --> 2:37:59.060\n Like for instance, if I don't wait for this pedestrian or something like that, and what\n\n2:37:59.060 --> 2:38:07.680\n is the downside to me going to be in terms of time wasted talking to the police or getting\n\n2:38:07.680 --> 2:38:11.980\n sent to jail or things like that?\n\n2:38:11.980 --> 2:38:17.580\n And there's also emotion, like people in their cars tend to get irrationally angry.\n\n2:38:17.580 --> 2:38:18.580\n That's dangerous.\n\n2:38:18.580 --> 2:38:24.260\n But, you know, think about this is all part of why I think that autonomous vehicles, truly\n\n2:38:24.260 --> 2:38:31.060\n autonomous vehicles are farther out than most people do, because there is this enormous\n\n2:38:31.060 --> 2:38:38.580\n level of complexity which goes beyond mechanically controlling the car.\n\n2:38:38.580 --> 2:38:45.220\n And I can see the autonomous vehicles as a kind of metaphorical and literal accident\n\n2:38:45.220 --> 2:38:47.100\n waiting to happen.\n\n2:38:47.100 --> 2:38:56.900\n And not just because of their overall incurring versus preventing accidents and so on, but\n\n2:38:56.900 --> 2:39:10.340\n just because of the almost voracious appetite people have for bad stories about powerful\n\n2:39:10.340 --> 2:39:12.940\n companies and powerful entities.\n\n2:39:12.940 --> 2:39:19.640\n When I was at a, coincidentally, Japanese fifth generation computing system conference\n\n2:39:19.640 --> 2:39:26.220\n in 1987, while I happened to be there, there was a worker at an auto plant who was despondent\n\n2:39:26.220 --> 2:39:30.900\n and committed suicide by climbing under the safety chains and so on and getting stamped\n\n2:39:30.900 --> 2:39:32.940\n to death by a machine.\n\n2:39:32.940 --> 2:39:38.940\n And instead of being a small story that said despondent worker commit suicide, it was front\n\n2:39:38.940 --> 2:39:46.860\n page news that effectively said robot kills worker, because the public is just waiting\n\n2:39:46.860 --> 2:39:54.220\n for stories about like AI kills phonogenic family of five type stories.\n\n2:39:54.220 --> 2:40:01.300\n And even if you could show that nationwide, this system saved more lives than it cost\n\n2:40:01.300 --> 2:40:09.100\n and prevented more injuries than it caused and so on, the media, the public, the government\n\n2:40:09.100 --> 2:40:18.180\n is just coiled and ready to pounce on stories where in fact it failed, even if they're relatively\n\n2:40:18.180 --> 2:40:19.180\n few.\n\n2:40:19.180 --> 2:40:26.220\n Yeah, it's so fascinating to watch us humans resisting the cutting edge of science and\n\n2:40:26.220 --> 2:40:31.940\n technology and almost like hoping for it to fail and constant, you know, this just happens\n\n2:40:31.940 --> 2:40:33.820\n over and over and over throughout history.\n\n2:40:33.820 --> 2:40:37.860\n Or even if we're not hoping for it to fail, we're fascinated by it.\n\n2:40:37.860 --> 2:40:43.420\n And in terms of what we find interesting, the one in a thousand failures, much more\n\n2:40:43.420 --> 2:40:48.160\n interesting than the 999 boring successes.\n\n2:40:48.160 --> 2:40:57.860\n So once we build an AGI system, say psych is some part of it and say it's very possible\n\n2:40:57.860 --> 2:41:03.420\n that you would be one of the first people that can sit down in the room, let's say with\n\n2:41:03.420 --> 2:41:07.260\n her and have a conversation, what would you ask her?\n\n2:41:07.260 --> 2:41:09.580\n What would you talk about?\n\n2:41:09.580 --> 2:41:26.460\n Looking at all of the content out there on the web and so on, what are some possible\n\n2:41:26.460 --> 2:41:33.120\n solutions to big problems that the world has that people haven't really thought of before\n\n2:41:33.120 --> 2:41:40.000\n that are not being properly or at least adequately pursued?\n\n2:41:40.000 --> 2:41:46.540\n What are some novel solutions that you can think of that we haven't that might work and\n\n2:41:46.540 --> 2:41:48.600\n that might be worth considering?\n\n2:41:48.600 --> 2:41:51.020\n So that is a damn good question.\n\n2:41:51.020 --> 2:41:56.360\n Given that the AGI is going to be somewhat different from human intelligence, it's still\n\n2:41:56.360 --> 2:42:02.020\n going to make some mistakes that we wouldn't make, but it's also possibly going to notice\n\n2:42:02.020 --> 2:42:04.420\n some blind spots we have.\n\n2:42:04.420 --> 2:42:13.460\n And I would love as a test of is it really on a par with our intelligences, can it help\n\n2:42:13.460 --> 2:42:17.660\n spot some of the blind spots that we have?\n\n2:42:17.660 --> 2:42:23.420\n So the two part question of can you help identify what are the big problems in the world?\n\n2:42:23.420 --> 2:42:27.360\n And two, what are some novel solutions to those problems?\n\n2:42:27.360 --> 2:42:31.660\n That are not being talked about by anyone.\n\n2:42:31.660 --> 2:42:37.040\n And some of those may become infeasible or reprehensible or something, but some of them\n\n2:42:37.040 --> 2:42:40.640\n might be actually great things to look at.\n\n2:42:40.640 --> 2:42:45.960\n If you go back and look at some of the most powerful discoveries that have been made,\n\n2:42:45.960 --> 2:42:56.180\n like relativity and superconductivity and so on, a lot of them were cases where someone\n\n2:42:56.180 --> 2:43:04.620\n took seriously the idea that there might actually be a non obvious answer to a question.\n\n2:43:04.620 --> 2:43:09.720\n So in Einstein's case, it was, yeah, the Lorentz transformation is known.\n\n2:43:09.720 --> 2:43:12.200\n Nobody believes that it's actually the way reality works.\n\n2:43:12.200 --> 2:43:15.380\n What if it were the way that reality actually worked?\n\n2:43:15.380 --> 2:43:19.040\n So a lot of people don't realize he didn't actually work out that equation, he just sort\n\n2:43:19.040 --> 2:43:20.940\n of took it seriously.\n\n2:43:20.940 --> 2:43:26.680\n Or in the case of superconductivity, you have this V equals IR equation where R is resistance\n\n2:43:26.680 --> 2:43:28.000\n and so on.\n\n2:43:28.000 --> 2:43:33.480\n And it was being mapped at lower and lower temperatures, but everyone thought that was\n\n2:43:33.480 --> 2:43:39.840\n just bump on a log research to show that V equals IR always held.\n\n2:43:39.840 --> 2:43:46.180\n And then when some graduate student got to a slightly lower temperature and showed that\n\n2:43:46.180 --> 2:43:50.960\n resistance suddenly dropped off, everyone just assumed that they did it wrong.\n\n2:43:50.960 --> 2:43:56.680\n And it was only a little while later that they realized it was actually a new phenomenon.\n\n2:43:56.680 --> 2:44:04.660\n Or in the case of the H. pylori bacteria causing stomach ulcers, where everyone thought that\n\n2:44:04.660 --> 2:44:08.040\n stress and stomach acid caused ulcers.\n\n2:44:08.040 --> 2:44:15.800\n And when a doctor in Australia claimed it was actually a bacterial infection, he couldn't\n\n2:44:15.800 --> 2:44:21.880\n get anyone seriously to listen to him and he had to ultimately inject himself with the\n\n2:44:21.880 --> 2:44:27.640\n bacteria to show that he suddenly developed a life threatening ulcer in order to get other\n\n2:44:27.640 --> 2:44:29.880\n doctors to seriously consider that.\n\n2:44:29.880 --> 2:44:35.680\n So there are all sorts of things where humans are locked into paradigms, what Thomas Kuhn\n\n2:44:35.680 --> 2:44:40.520\n called paradigms, and we can't get out of them very easily.\n\n2:44:40.520 --> 2:44:47.720\n So a lot of AI is locked into the deep learning machine learning paradigm right now.\n\n2:44:47.720 --> 2:44:52.800\n And almost all of us and almost all sciences are locked into current paradigms.\n\n2:44:52.800 --> 2:45:00.000\n And Kuhn's point was pretty much you have to wait for people to die in order for the\n\n2:45:00.000 --> 2:45:03.280\n new generation to escape those paradigms.\n\n2:45:03.280 --> 2:45:09.120\n And I think that one of the things that would change that sad reality is if we had trusted\n\n2:45:09.120 --> 2:45:16.120\n AGI's that could help take a step back and question some of the paradigms that we're\n\n2:45:16.120 --> 2:45:17.400\n currently locked into.\n\n2:45:17.400 --> 2:45:25.160\n Yeah, it would accelerate the paradigm shifts in human science and progress.\n\n2:45:25.160 --> 2:45:30.600\n You've lived a very interesting life where you thought about big ideas and you stuck\n\n2:45:30.600 --> 2:45:32.600\n with them.\n\n2:45:32.600 --> 2:45:38.520\n Can you give advice to young people today, somebody in high school, somebody undergrad,\n\n2:45:38.520 --> 2:45:43.880\n about career, about life?\n\n2:45:43.880 --> 2:45:47.840\n I'd say you can make a difference.\n\n2:45:47.840 --> 2:45:53.200\n But in order to make a difference, you're going to have to have the courage to follow\n\n2:45:53.200 --> 2:46:02.480\n through with ideas which other people might not immediately understand or support.\n\n2:46:02.480 --> 2:46:12.880\n You have to realize that if you make some plan that's going to take an extended period\n\n2:46:12.880 --> 2:46:16.640\n of time to carry out, don't be afraid of that.\n\n2:46:16.640 --> 2:46:20.920\n That's true of physical training of your body.\n\n2:46:20.920 --> 2:46:27.020\n That's true of learning some profession.\n\n2:46:27.020 --> 2:46:33.580\n It's also true of innovation, that some innovations are not great ideas you can write down on\n\n2:46:33.580 --> 2:46:38.500\n a napkin and become an instant success if you turn out to be right.\n\n2:46:38.500 --> 2:46:45.900\n Some of them are paths you have to follow, but remember that you're mortal.\n\n2:46:45.900 --> 2:46:53.320\n Remember that you have a limited number of decade sized debts to make with your life\n\n2:46:53.320 --> 2:46:55.720\n and you should make each one of them count.\n\n2:46:55.720 --> 2:46:58.160\n And that's true in personal relationships.\n\n2:46:58.160 --> 2:47:00.360\n That's true in career choice.\n\n2:47:00.360 --> 2:47:03.920\n That's true in making discoveries and so on.\n\n2:47:03.920 --> 2:47:10.960\n And if you follow the path of least resistance, you'll find that you're optimizing for short\n\n2:47:10.960 --> 2:47:12.800\n periods of time.\n\n2:47:12.800 --> 2:47:17.280\n And before you know it, you turn around and long periods of time have gone by without\n\n2:47:17.280 --> 2:47:21.400\n you ever really making a difference in the world.\n\n2:47:21.400 --> 2:47:26.280\n When you look at the field that I really love is artificial intelligence and there's not\n\n2:47:26.280 --> 2:47:33.040\n many projects, there's not many little flames of hope that have been carried out for many\n\n2:47:33.040 --> 2:47:36.920\n years, for decades and psych represents one of them.\n\n2:47:36.920 --> 2:47:42.880\n And I mean that in itself is just a really inspiring thing.\n\n2:47:42.880 --> 2:47:47.960\n So I'm deeply grateful that you would be carrying that flame for so many years and I think that's\n\n2:47:47.960 --> 2:47:50.040\n an inspiration to young people.\n\n2:47:50.040 --> 2:47:55.360\n That said, you said life is finite and we talked about mortality as a feature of AGI.\n\n2:47:55.360 --> 2:47:57.480\n Do you think about your own mortality?\n\n2:47:57.480 --> 2:47:59.480\n Are you afraid of death?\n\n2:47:59.480 --> 2:48:03.280\n Sure, I'd be crazy if I weren't.\n\n2:48:03.280 --> 2:48:07.560\n And as I get older, I'm now over 70.\n\n2:48:07.560 --> 2:48:14.760\n So as I get older, it's more on my mind, especially as acquaintances and friends and especially\n\n2:48:14.760 --> 2:48:22.880\n mentors, one by one are dying, so I can't avoid thinking about mortality.\n\n2:48:22.880 --> 2:48:28.760\n And I think that the good news from the point of view and the rest of the world is that\n\n2:48:28.760 --> 2:48:34.640\n that adds impetus to my need to succeed in a small number of years in the future.\n\n2:48:34.640 --> 2:48:36.520\n You have a deadline.\n\n2:48:36.520 --> 2:48:37.520\n Exactly.\n\n2:48:37.520 --> 2:48:41.440\n I'm not going to have another 37 years to continue working on this.\n\n2:48:41.440 --> 2:48:50.400\n So we really do want Psyche to make an impact in the world commercially, physically, metaphysically\n\n2:48:50.400 --> 2:48:56.560\n in the next small number of years, two, three, five years, not two, three, five decades anymore.\n\n2:48:56.560 --> 2:49:04.760\n And so this is really driving me toward this sort of commercialization and increasingly\n\n2:49:04.760 --> 2:49:08.080\n widespread application of Psyche.\n\n2:49:08.080 --> 2:49:13.560\n Whereas before, I felt that I could just sort of sit back, roll my eyes, wait till the world\n\n2:49:13.560 --> 2:49:14.560\n caught up.\n\n2:49:14.560 --> 2:49:16.600\n And now I don't feel that way anymore.\n\n2:49:16.600 --> 2:49:22.440\n I feel like I need to put in some effort to make the world aware of what we have and what\n\n2:49:22.440 --> 2:49:23.920\n it can do.\n\n2:49:23.920 --> 2:49:27.360\n And the good news from your point of view is that that's why I'm sitting here.\n\n2:49:27.360 --> 2:49:30.640\n You're going to be more productive.\n\n2:49:30.640 --> 2:49:31.720\n I love it.\n\n2:49:31.720 --> 2:49:34.360\n And if I can help in any way, I would love to.\n\n2:49:34.360 --> 2:49:41.760\n From a programmer perspective, I love, especially these days, just contributing in small and\n\n2:49:41.760 --> 2:49:42.840\n big ways.\n\n2:49:42.840 --> 2:49:48.680\n So if there's any open sourcing from an MIT side and the research, I would love to help.\n\n2:49:48.680 --> 2:49:53.520\n But bigger than Psyche, like I said, it's that little flame that you're carrying of\n\n2:49:53.520 --> 2:49:58.600\n artificial intelligence, the big dream.\n\n2:49:58.600 --> 2:50:02.360\n What do you hope your legacy is?\n\n2:50:02.360 --> 2:50:05.080\n That's a good question.\n\n2:50:05.080 --> 2:50:15.920\n People think of me as one of the pioneers or inventors of the AI that is ubiquitous\n\n2:50:15.920 --> 2:50:19.480\n and that they take for granted and so on.\n\n2:50:19.480 --> 2:50:28.440\n Much the way that today we look back on the pioneers of electricity or the pioneers of\n\n2:50:28.440 --> 2:50:33.200\n similar types of technologies and so on.\n\n2:50:33.200 --> 2:50:40.000\n It's hard to imagine what life would be like if these people hadn't done what they did.\n\n2:50:40.000 --> 2:50:44.000\n So that's one thing that I'd like to be remembered as.\n\n2:50:44.000 --> 2:50:53.680\n Another is that the creator, one of the originators of this gigantic knowledge store and acquisition\n\n2:50:53.680 --> 2:51:00.360\n system that is likely to be at the center of whatever this future AI thing will look\n\n2:51:00.360 --> 2:51:01.360\n like.\n\n2:51:01.360 --> 2:51:02.360\n Yes, exactly.\n\n2:51:02.360 --> 2:51:11.440\n And I'd also like to be remembered as someone who wasn't afraid to spend several decades\n\n2:51:11.440 --> 2:51:23.400\n on a project in a time when almost all of the other forces, institutional forces and\n\n2:51:23.400 --> 2:51:29.920\n commercial forces, are incenting people to go for short term rewards.\n\n2:51:29.920 --> 2:51:31.400\n And a lot of people gave up.\n\n2:51:31.400 --> 2:51:40.320\n A lot of people that dreamt the same dream as you gave up and you didn't.\n\n2:51:40.320 --> 2:51:42.800\n I mean, Doug, it's truly an honor.\n\n2:51:42.800 --> 2:51:45.200\n This is a long time coming.\n\n2:51:45.200 --> 2:51:53.120\n A lot of people bring up your work specifically and more broadly, philosophically of this\n\n2:51:53.120 --> 2:51:55.580\n is the dream of artificial intelligence.\n\n2:51:55.580 --> 2:51:57.800\n This is likely a part of the future.\n\n2:51:57.800 --> 2:52:02.080\n We're so sort of focused on machine learning applications, all that kind of stuff today.\n\n2:52:02.080 --> 2:52:08.520\n But it seems like the ideas that Cite carries forward is something that will be at the center\n\n2:52:08.520 --> 2:52:15.640\n of this problem they're all trying to solve, which is the problem of intelligence, emotional\n\n2:52:15.640 --> 2:52:16.640\n and otherwise.\n\n2:52:16.640 --> 2:52:18.440\n So thank you so much.\n\n2:52:18.440 --> 2:52:22.760\n It's such a huge honor that you would talk to me and spend your valuable time with me\n\n2:52:22.760 --> 2:52:23.760\n today.\n\n2:52:23.760 --> 2:52:24.760\n Thanks for talking.\n\n2:52:24.760 --> 2:52:25.760\n Thanks, Lex.\n\n2:52:25.760 --> 2:52:26.760\n It's been great.\n\n2:52:26.760 --> 2:52:29.480\n Thanks for listening to this conversation with Doug Lenat.\n\n2:52:29.480 --> 2:52:33.760\n To support this podcast, please check out our sponsors in the description.\n\n2:52:33.760 --> 2:52:40.160\n And now, let me leave you with some words from Mark Twain about the nature of truth.\n\n2:52:40.160 --> 2:52:44.320\n If you tell the truth, you don't have to remember anything.\n\n2:52:44.320 --> 2:53:07.440\n Thank you for listening and hope to see you next time.\n\n"
}
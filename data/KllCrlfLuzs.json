{
  "title": "Richard Karp: Algorithms and Computational Complexity | Lex Fridman Podcast #111",
  "id": "KllCrlfLuzs",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:02.900\n The following is a conversation with Richard Karp,\n\n00:02.900 --> 00:06.300\n a professor at Berkeley and one of the most important figures\n\n00:06.300 --> 00:09.480\n in the history of theoretical computer science.\n\n00:09.480 --> 00:12.640\n In 1985, he received the Turing Award\n\n00:12.640 --> 00:15.120\n for his research in the theory of algorithms,\n\n00:15.120 --> 00:18.380\n including the development of the Admirons Karp algorithm\n\n00:18.380 --> 00:21.780\n for solving the max flow problem on networks,\n\n00:21.780 --> 00:25.900\n Hopcroft Karp algorithm for finding maximum cardinality\n\n00:25.900 --> 00:27.960\n matchings in bipartite graphs,\n\n00:27.960 --> 00:30.960\n and his landmark paper in complexity theory\n\n00:30.960 --> 00:35.260\n called Reduceability Among Combinatorial Problems,\n\n00:35.260 --> 00:38.980\n in which he proved 21 problems to be NP complete.\n\n00:38.980 --> 00:41.840\n This paper was probably the most important catalyst\n\n00:41.840 --> 00:45.340\n in the explosion of interest in the study of NP completeness\n\n00:45.340 --> 00:48.760\n and the P versus NP problem in general.\n\n00:48.760 --> 00:50.180\n Quick summary of the ads.\n\n00:50.180 --> 00:53.540\n Two sponsors, 8sleep mattress and Cash App.\n\n00:53.540 --> 00:55.640\n Please consider supporting this podcast\n\n00:55.640 --> 00:58.760\n by going to 8sleep.com slash Lex\n\n00:58.760 --> 01:03.000\n and downloading Cash App and using code LexPodcast.\n\n01:03.000 --> 01:04.560\n Click the links, buy the stuff.\n\n01:04.560 --> 01:08.040\n It really is the best way to support this podcast.\n\n01:08.040 --> 01:10.240\n If you enjoy this thing, subscribe on YouTube,\n\n01:10.240 --> 01:12.440\n review it with five stars on Apple Podcast,\n\n01:12.440 --> 01:13.800\n support it on Patreon,\n\n01:13.800 --> 01:16.800\n or connect with me on Twitter at Lex Friedman.\n\n01:16.800 --> 01:18.800\n As usual, I'll do a few minutes of ads now\n\n01:18.800 --> 01:20.060\n and never any ads in the middle\n\n01:20.060 --> 01:22.960\n that can break the flow of the conversation.\n\n01:22.960 --> 01:27.340\n This show is sponsored by 8sleep and its Pod Pro mattress\n\n01:27.340 --> 01:30.680\n that you can check out at 8sleep.com slash Lex\n\n01:30.680 --> 01:32.960\n to get $200 off.\n\n01:32.960 --> 01:35.880\n It controls temperature with an app.\n\n01:35.880 --> 01:38.320\n It can cool down to as low as 55 degrees\n\n01:38.320 --> 01:41.000\n on each side of the bed separately.\n\n01:41.000 --> 01:43.520\n Research shows that temperature has a big impact\n\n01:43.520 --> 01:45.000\n on the quality of our sleep.\n\n01:45.000 --> 01:47.760\n Anecdotally, it's been a game changer for me.\n\n01:47.760 --> 01:48.760\n I love it.\n\n01:48.760 --> 01:50.160\n It's been a couple of weeks now.\n\n01:50.160 --> 01:52.480\n I've just been really enjoying it,\n\n01:52.480 --> 01:54.640\n both in the fact that I'm getting better sleep\n\n01:54.640 --> 01:58.240\n and that it's a smart mattress, essentially.\n\n01:58.240 --> 02:00.040\n I kind of imagine this being the early days\n\n02:00.040 --> 02:02.800\n of artificial intelligence being a part\n\n02:02.800 --> 02:04.320\n of every aspect of our lives.\n\n02:04.320 --> 02:07.440\n And certainly infusing AI in one of the most important\n\n02:07.440 --> 02:09.800\n aspects of life, which is sleep,\n\n02:09.800 --> 02:13.120\n I think has a lot of potential for being beneficial.\n\n02:13.120 --> 02:16.440\n The Pod Pro is packed with sensors that track heart rate,\n\n02:16.440 --> 02:19.480\n heart rate variability, and respiratory rate,\n\n02:19.480 --> 02:21.760\n showing it all in their app.\n\n02:21.760 --> 02:24.320\n The app's health metrics are amazing,\n\n02:24.320 --> 02:27.120\n but the cooling alone is honestly worth the money.\n\n02:27.120 --> 02:29.280\n I don't always sleep, but when I do,\n\n02:29.280 --> 02:31.960\n I choose the 8th Sleep Pod Pro mattress.\n\n02:31.960 --> 02:36.960\n Check it out at 8thSleep.com slash Lex to get $200 off.\n\n02:37.560 --> 02:39.040\n And remember, just visiting the site\n\n02:39.040 --> 02:42.000\n and considering the purchase helps convince the folks\n\n02:42.000 --> 02:44.840\n at 8th Sleep that this silly old podcast\n\n02:44.840 --> 02:46.480\n is worth sponsoring in the future.\n\n02:47.400 --> 02:50.520\n This show is also presented by the great\n\n02:50.520 --> 02:53.000\n and powerful Cash App,\n\n02:53.000 --> 02:55.320\n the number one finance app in the App Store.\n\n02:55.320 --> 02:58.160\n When you get it, use code LEXPODCAST.\n\n02:58.160 --> 03:00.120\n Cash App lets you send money to friends,\n\n03:00.120 --> 03:02.520\n buy Bitcoin, and invest in the stock market\n\n03:02.520 --> 03:04.640\n with as little as $1.\n\n03:04.640 --> 03:06.720\n It's one of the best designed interfaces\n\n03:06.720 --> 03:08.480\n of an app that I've ever used.\n\n03:08.480 --> 03:12.320\n To me, good design is when everything is easy and natural.\n\n03:12.320 --> 03:15.080\n Bad design is when the app gets in the way,\n\n03:15.080 --> 03:16.560\n either because it's buggy,\n\n03:16.560 --> 03:19.280\n or because it tries too hard to be helpful.\n\n03:19.280 --> 03:21.560\n I'm looking at you, Clippy, from Microsoft,\n\n03:21.560 --> 03:23.160\n even though I love you.\n\n03:23.160 --> 03:25.480\n Anyway, there's a big part of my brain and heart\n\n03:25.480 --> 03:27.400\n that loves to design things\n\n03:27.400 --> 03:30.000\n and also to appreciate great design by others.\n\n03:30.000 --> 03:32.440\n So again, if you get Cash App from the App Store\n\n03:32.440 --> 03:35.600\n or Google Play and use the code LEXPODCAST,\n\n03:35.600 --> 03:39.600\n you get $10, and Cash App will also donate $10 to FIRST,\n\n03:39.600 --> 03:41.800\n an organization that is helping to advance\n\n03:41.800 --> 03:43.480\n robotics and STEM education\n\n03:43.480 --> 03:45.720\n for young people around the world.\n\n03:45.720 --> 03:49.600\n And now, here's my conversation with Richard Karp.\n\n03:50.520 --> 03:52.840\n You wrote that at the age of 13,\n\n03:52.840 --> 03:55.240\n you were first exposed to plane geometry\n\n03:55.240 --> 03:58.280\n and was wonderstruck by the power and elegance\n\n03:58.280 --> 04:00.280\n of form of proofs.\n\n04:00.280 --> 04:02.640\n Are there problems, proofs, properties, ideas\n\n04:02.640 --> 04:04.960\n in plane geometry that from that time\n\n04:04.960 --> 04:07.880\n that you remember being mesmerized by\n\n04:07.880 --> 04:12.880\n or just enjoying to go through to prove various aspects?\n\n04:12.880 --> 04:16.240\n So Michael Rabin told me this story\n\n04:16.240 --> 04:20.360\n about an experience he had when he was a young student\n\n04:20.360 --> 04:25.200\n who was tossed out of his classroom for bad behavior\n\n04:25.200 --> 04:29.360\n and was wandering through the corridors of his school\n\n04:29.360 --> 04:32.560\n and came upon two older students\n\n04:32.560 --> 04:35.840\n who were studying the problem of finding\n\n04:35.840 --> 04:42.920\n the shortest distance between two nonoverlapping circles.\n\n04:42.920 --> 04:49.120\n And Michael thought about it and said,\n\n04:49.120 --> 04:52.360\n you take the straight line between the two centers\n\n04:52.360 --> 04:56.080\n and the segment between the two circles is the shortest\n\n04:56.080 --> 04:58.600\n because a straight line is the shortest distance\n\n04:58.600 --> 05:00.600\n between the two centers.\n\n05:00.600 --> 05:03.640\n And any other line connecting the circles\n\n05:03.640 --> 05:07.640\n would be on a longer line.\n\n05:07.640 --> 05:10.360\n And I thought, and he thought, and I agreed\n\n05:10.360 --> 05:14.600\n that this was just elegance, the pure reasoning\n\n05:14.600 --> 05:17.600\n could come up with such a result.\n\n05:17.600 --> 05:21.000\n Certainly the shortest distance\n\n05:21.000 --> 05:24.600\n from the two centers of the circles is a straight line.\n\n05:25.680 --> 05:29.680\n Could you once again say what's the next step in that proof?\n\n05:29.680 --> 05:36.680\n Well, any segment joining the two circles,\n\n05:36.680 --> 05:41.440\n if you extend it by taking the radius on each side,\n\n05:41.440 --> 05:46.560\n you get a path with three edges\n\n05:46.560 --> 05:49.240\n which connects the two centers.\n\n05:49.240 --> 05:52.560\n And this has to be at least as long as the shortest path,\n\n05:52.560 --> 05:53.760\n which is the straight line.\n\n05:53.760 --> 05:54.800\n The straight line, yeah.\n\n05:54.800 --> 05:58.480\n Wow, yeah, that's quite simple.\n\n05:58.480 --> 06:00.800\n So what is it about that elegance\n\n06:00.800 --> 06:04.640\n that you just find compelling?\n\n06:04.640 --> 06:09.960\n Well, just that you could establish a fact\n\n06:09.960 --> 06:14.960\n about geometry beyond dispute by pure reasoning.\n\n06:18.960 --> 06:22.440\n I also enjoy the challenge of solving puzzles\n\n06:22.440 --> 06:23.400\n in plain geometry.\n\n06:23.400 --> 06:27.480\n It was much more fun than the earlier mathematics courses\n\n06:27.480 --> 06:31.000\n which were mostly about arithmetic operations\n\n06:31.000 --> 06:32.840\n and manipulating them.\n\n06:32.840 --> 06:35.840\n Was there something about geometry itself,\n\n06:35.840 --> 06:38.160\n the slightly visual component of it?\n\n06:38.160 --> 06:40.200\n Oh, yes, absolutely,\n\n06:40.200 --> 06:44.120\n although I lacked three dimensional vision.\n\n06:44.120 --> 06:47.280\n I wasn't very good at three dimensional vision.\n\n06:47.280 --> 06:49.680\n You mean being able to visualize three dimensional objects?\n\n06:49.680 --> 06:54.280\n Three dimensional objects or surfaces,\n\n06:54.280 --> 06:57.680\n hyperplanes and so on.\n\n06:57.680 --> 07:01.680\n So there I didn't have an intuition.\n\n07:01.680 --> 07:06.680\n But for example, the fact that the sum of the angles\n\n07:06.960 --> 07:11.960\n of a triangle is 180 degrees is proved convincingly.\n\n07:16.200 --> 07:19.520\n And it comes as a surprise that that can be done.\n\n07:21.320 --> 07:23.480\n Why is that surprising?\n\n07:23.480 --> 07:28.480\n Well, it is a surprising idea, I suppose.\n\n07:30.600 --> 07:32.400\n Why is that proved difficult?\n\n07:32.400 --> 07:34.200\n It's not, that's the point.\n\n07:34.200 --> 07:36.440\n It's so easy and yet it's so convincing.\n\n07:37.760 --> 07:41.880\n Do you remember what is the proof that it adds up to 180?\n\n07:42.840 --> 07:47.840\n You start at a corner and draw a line\n\n07:47.840 --> 07:52.840\n parallel to the opposite side.\n\n07:56.160 --> 08:00.720\n And that line sort of trisects the angle\n\n08:02.000 --> 08:04.360\n between the other two sides.\n\n08:05.400 --> 08:10.400\n And you get a half plane which has to add up to 180 degrees.\n\n08:10.400 --> 08:15.400\n It has to add up to 180 degrees and it consists\n\n08:15.760 --> 08:20.760\n in the angles by the equality of alternate angles.\n\n08:21.680 --> 08:22.520\n What's it called?\n\n08:24.200 --> 08:27.200\n You get a correspondence between the angles\n\n08:27.200 --> 08:31.960\n created along the side of the triangle\n\n08:31.960 --> 08:34.680\n and the three angles of the triangle.\n\n08:34.680 --> 08:38.960\n Has geometry had an impact on when you look into the future\n\n08:38.960 --> 08:41.320\n of your work with combinatorial algorithms?\n\n08:41.320 --> 08:45.240\n Has it had some kind of impact in terms of, yeah,\n\n08:45.240 --> 08:48.680\n being able, the puzzles, the visual aspects\n\n08:48.680 --> 08:51.400\n that were first so compelling to you?\n\n08:51.400 --> 08:54.480\n Not Euclidean geometry particularly.\n\n08:54.480 --> 08:59.480\n I think I use tools like linear programming\n\n09:00.040 --> 09:01.880\n and integer programming a lot.\n\n09:03.000 --> 09:08.000\n But those require high dimensional visualization\n\n09:08.000 --> 09:12.200\n and so I tend to go by the algebraic properties.\n\n09:13.200 --> 09:16.640\n Right, you go by the linear algebra\n\n09:16.640 --> 09:19.560\n and not by the visualization.\n\n09:19.560 --> 09:23.680\n Well, the interpretation in terms of, for example,\n\n09:23.680 --> 09:26.360\n finding the highest point on a polyhedron\n\n09:26.360 --> 09:31.120\n as in linear programming is motivating.\n\n09:32.640 --> 09:37.560\n But again, I don't have the high dimensional intuition\n\n09:37.560 --> 09:40.080\n that would particularly inform me\n\n09:40.080 --> 09:43.840\n so I sort of lean on the algebra.\n\n09:44.760 --> 09:46.080\n So to linger on that point,\n\n09:46.080 --> 09:50.960\n what kind of visualization do you do\n\n09:50.960 --> 09:53.240\n when you're trying to think about,\n\n09:53.240 --> 09:55.400\n we'll get to combinatorial algorithms,\n\n09:55.400 --> 09:57.240\n but just algorithms in general.\n\n09:57.240 --> 09:58.080\n Yeah.\n\n09:58.080 --> 09:59.760\n What's inside your mind\n\n09:59.760 --> 10:02.240\n when you're thinking about designing algorithms?\n\n10:02.240 --> 10:07.240\n Or even just tackling any mathematical problem?\n\n10:09.440 --> 10:12.800\n Well, I think that usually an algorithm\n\n10:12.800 --> 10:17.800\n involves a repetition of some inner loop\n\n10:19.200 --> 10:24.200\n and so I can sort of visualize the distance\n\n10:24.640 --> 10:29.640\n from the desired solution as iteratively reducing\n\n10:29.640 --> 10:33.360\n until you finally hit the exact solution.\n\n10:33.360 --> 10:35.640\n And try to take steps that get you closer to the.\n\n10:35.640 --> 10:38.160\n Try to take steps that get closer\n\n10:38.160 --> 10:41.280\n and having the certainty of converging.\n\n10:41.280 --> 10:46.280\n So it's basically the mechanics of the algorithm\n\n10:46.640 --> 10:48.080\n is often very simple,\n\n10:49.320 --> 10:52.480\n but especially when you're trying something out\n\n10:52.480 --> 10:53.320\n on the computer.\n\n10:53.320 --> 10:57.080\n So for example, I did some work\n\n10:57.080 --> 10:59.000\n on the traveling salesman problem\n\n10:59.000 --> 11:03.080\n and I could see there was a particular function\n\n11:03.080 --> 11:04.720\n that had to be minimized\n\n11:04.720 --> 11:08.640\n and it was fascinating to see the successive approaches\n\n11:08.640 --> 11:10.200\n to the minimum, to the optimum.\n\n11:11.960 --> 11:13.040\n You mean, so first of all,\n\n11:13.040 --> 11:16.360\n traveling salesman problem is where you have to visit\n\n11:16.360 --> 11:21.320\n every city without ever, the only ones.\n\n11:21.320 --> 11:22.480\n Yeah, that's right.\n\n11:22.480 --> 11:25.120\n Find the shortest path through a set of cities.\n\n11:25.120 --> 11:28.560\n Yeah, which is sort of a canonical standard,\n\n11:28.560 --> 11:30.480\n a really nice problem that's really hard.\n\n11:30.480 --> 11:32.640\n Right, exactly, yes.\n\n11:32.640 --> 11:34.520\n So can you say again what was nice\n\n11:34.520 --> 11:38.440\n about being able to think about the objective function there\n\n11:38.440 --> 11:41.560\n and maximizing it or minimizing it?\n\n11:41.560 --> 11:45.240\n Well, just that as the algorithm proceeded,\n\n11:47.120 --> 11:49.680\n you were making progress, continual progress,\n\n11:49.680 --> 11:54.000\n and eventually getting to the optimum point.\n\n11:54.000 --> 11:57.120\n So there's two parts, maybe.\n\n11:57.120 --> 11:58.400\n Maybe you can correct me.\n\n11:58.400 --> 12:00.320\n First is like getting an intuition\n\n12:00.320 --> 12:02.880\n about what the solution would look like\n\n12:02.880 --> 12:05.560\n and or even maybe coming up with a solution\n\n12:05.560 --> 12:07.280\n and two is proving that this thing\n\n12:07.280 --> 12:09.880\n is actually going to be pretty good.\n\n12:10.880 --> 12:13.600\n What part is harder for you?\n\n12:13.600 --> 12:14.960\n Where's the magic happen?\n\n12:14.960 --> 12:17.760\n Is it in the first sets of intuitions\n\n12:17.760 --> 12:22.120\n or is it in the messy details of actually showing\n\n12:22.120 --> 12:25.440\n that it is going to get to the exact solution\n\n12:25.440 --> 12:30.440\n and it's gonna run at a certain complexity?\n\n12:32.360 --> 12:34.760\n Well, the magic is just the fact\n\n12:34.760 --> 12:39.760\n that the gap from the optimum decreases monotonically\n\n12:42.240 --> 12:44.480\n and you can see it happening\n\n12:44.480 --> 12:48.720\n and various metrics of what's going on\n\n12:48.720 --> 12:53.680\n are improving all along until finally you hit the optimum.\n\n12:53.680 --> 12:56.200\n Perhaps later we'll talk about the assignment problem\n\n12:56.200 --> 12:58.480\n and I can illustrate.\n\n12:58.480 --> 13:00.720\n It illustrates a little better.\n\n13:00.720 --> 13:03.120\n Now zooming out again, as you write,\n\n13:03.120 --> 13:06.880\n Don Knuth has called attention to a breed of people\n\n13:06.880 --> 13:10.520\n who derive great aesthetic pleasure\n\n13:10.520 --> 13:13.920\n from contemplating the structure of computational processes.\n\n13:13.920 --> 13:16.600\n So Don calls these folks geeks\n\n13:16.600 --> 13:18.600\n and you write that you remember the moment\n\n13:18.600 --> 13:20.680\n you realized you were such a person,\n\n13:20.680 --> 13:23.120\n you were shown the Hungarian algorithm\n\n13:23.120 --> 13:25.720\n to solve the assignment problem.\n\n13:25.720 --> 13:29.120\n So perhaps you can explain what the assignment problem is\n\n13:29.120 --> 13:31.960\n and what the Hungarian algorithm is.\n\n13:33.160 --> 13:35.440\n So in the assignment problem,\n\n13:35.440 --> 13:40.280\n you have n boys and n girls\n\n13:40.280 --> 13:45.280\n and you are given the desirability of,\n\n13:45.280 --> 13:50.200\n or the cost of matching the ith boy\n\n13:50.200 --> 13:52.640\n with the jth girl for all i and j.\n\n13:52.640 --> 13:54.480\n You're given a matrix of numbers\n\n13:55.600 --> 14:00.600\n and you want to find the one to one matching\n\n14:02.040 --> 14:04.280\n of the boys with the girls\n\n14:04.280 --> 14:08.720\n such that the sum of the associated costs will be minimized.\n\n14:08.720 --> 14:13.240\n So the best way to match the boys with the girls\n\n14:13.240 --> 14:16.440\n or men with jobs or any two sets.\n\n14:16.440 --> 14:21.120\n Any possible matching is possible or?\n\n14:21.120 --> 14:26.120\n Yeah, all one to one correspondences are permissible.\n\n14:26.800 --> 14:29.440\n If there is a connection that is not allowed,\n\n14:29.440 --> 14:32.120\n then you can think of it as having an infinite cost.\n\n14:32.120 --> 14:32.960\n I see, yeah.\n\n14:34.320 --> 14:39.320\n So what you do is to depend on the observation\n\n14:39.320 --> 14:44.320\n that the identity of the optimal assignment\n\n14:46.360 --> 14:49.360\n or as we call it, the optimal permutation\n\n14:50.760 --> 14:53.760\n is not changed if you subtract a constant\n\n14:57.640 --> 15:01.640\n from any row or column of the matrix.\n\n15:01.640 --> 15:03.360\n You can see that the comparison\n\n15:03.360 --> 15:06.480\n between the different assignments is not changed by that.\n\n15:06.480 --> 15:11.480\n Because if you decrease a particular row,\n\n15:11.480 --> 15:14.720\n all the elements of a row by some constant,\n\n15:14.720 --> 15:19.720\n all solutions decrease by an amount equal to that constant.\n\n15:21.120 --> 15:24.400\n So the idea of the algorithm is to start with a matrix\n\n15:24.400 --> 15:29.400\n of non negative numbers and keep subtracting\n\n15:31.240 --> 15:34.240\n from rows or from columns.\n\n15:34.240 --> 15:38.680\n Subtracting from rows or entire columns\n\n15:41.800 --> 15:44.800\n in such a way that you subtract the same constant\n\n15:44.800 --> 15:46.960\n from all the elements of that row or column\n\n15:48.440 --> 15:50.760\n while maintaining the property\n\n15:50.760 --> 15:55.760\n that all the elements are non negative.\n\n15:58.400 --> 15:59.280\n Simple.\n\n15:59.280 --> 16:04.280\n Yeah, and so what you have to do\n\n16:04.720 --> 16:09.720\n is find small moves which will decrease the total cost\n\n16:13.440 --> 16:17.600\n while subtracting constants from rows or columns.\n\n16:17.600 --> 16:19.480\n And there's a particular way of doing that\n\n16:19.480 --> 16:22.200\n by computing the kind of shortest path\n\n16:22.200 --> 16:24.000\n through the elements in the matrix.\n\n16:24.000 --> 16:28.480\n And you just keep going in this way\n\n16:28.480 --> 16:33.240\n until you finally get a full permutation of zeros\n\n16:33.240 --> 16:34.920\n while the matrix is non negative\n\n16:34.920 --> 16:37.480\n and then you know that that has to be the cheapest.\n\n16:38.520 --> 16:42.560\n Is that as simple as it sounds?\n\n16:42.560 --> 16:45.560\n So the shortest path of the matrix part.\n\n16:45.560 --> 16:48.880\n Yeah, the simplicity lies in how you find,\n\n16:48.880 --> 16:53.280\n I oversimplified slightly what you,\n\n16:53.280 --> 16:56.440\n you will end up subtracting a constant\n\n16:56.440 --> 16:59.120\n from some rows or columns\n\n16:59.120 --> 17:04.200\n and adding the same constant back to other rows and columns.\n\n17:04.200 --> 17:09.160\n So as not to reduce any of the zero elements,\n\n17:09.160 --> 17:11.080\n you leave them unchanged.\n\n17:11.080 --> 17:16.080\n But each individual step modifies several rows and columns\n\n17:22.440 --> 17:26.600\n by the same amount but overall decreases the cost.\n\n17:26.600 --> 17:29.800\n So there's something about that elegance\n\n17:29.800 --> 17:32.240\n that made you go aha, this is a beautiful,\n\n17:32.240 --> 17:35.680\n like it's amazing that something like this,\n\n17:35.680 --> 17:38.080\n something so simple can solve a problem like this.\n\n17:38.080 --> 17:39.760\n Yeah, it's really cool.\n\n17:39.760 --> 17:42.280\n If I had mechanical ability,\n\n17:42.280 --> 17:44.760\n I would probably like to do woodworking\n\n17:44.760 --> 17:49.080\n or other activities where you sort of shape something\n\n17:51.440 --> 17:55.440\n into something beautiful and orderly\n\n17:55.440 --> 18:00.440\n and there's something about the orderly systematic nature\n\n18:00.560 --> 18:05.520\n of that iterative algorithm that is pleasing to me.\n\n18:05.520 --> 18:09.000\n So what do you think about this idea of geeks\n\n18:09.000 --> 18:11.320\n as Don Knuth calls them?\n\n18:11.320 --> 18:16.320\n What do you think, is it something specific to a mindset\n\n18:16.520 --> 18:19.880\n that allows you to discover the elegance\n\n18:19.880 --> 18:23.160\n in computational processes or is this all of us,\n\n18:23.160 --> 18:25.280\n can all of us discover this beauty?\n\n18:25.280 --> 18:26.680\n Were you born this way?\n\n18:28.480 --> 18:29.320\n I think so.\n\n18:29.320 --> 18:30.760\n I always like to play with numbers.\n\n18:30.760 --> 18:35.760\n I used to amuse myself by multiplying\n\n18:35.760 --> 18:39.320\n by multiplying four digit decimal numbers in my head\n\n18:40.320 --> 18:44.440\n and putting myself to sleep by starting with one\n\n18:44.440 --> 18:48.160\n and doubling the number as long as I could go\n\n18:48.160 --> 18:52.720\n and testing my memory, my ability to retain the information.\n\n18:52.720 --> 18:55.920\n And I also read somewhere that you wrote\n\n18:55.920 --> 18:59.880\n that you enjoyed showing off to your friends\n\n18:59.880 --> 19:03.360\n by I believe multiplying four digit numbers.\n\n19:04.600 --> 19:05.440\n Right.\n\n19:05.440 --> 19:07.040\n Four digit numbers.\n\n19:07.040 --> 19:10.760\n Yeah, I had a summer job at a beach resort\n\n19:10.760 --> 19:15.760\n outside of Boston and the other employee,\n\n19:16.720 --> 19:20.160\n I was the barker at a skee ball game.\n\n19:20.160 --> 19:21.000\n Yeah.\n\n19:21.000 --> 19:26.000\n I used to sit at a microphone saying come one,\n\n19:26.240 --> 19:28.200\n come all, come in and play skee ball,\n\n19:28.200 --> 19:31.040\n five cents to play, a nickel to win and so on.\n\n19:31.040 --> 19:33.840\n That's what a barker, I wasn't sure if I should know\n\n19:33.840 --> 19:38.240\n but barker, that's, so you're the charming,\n\n19:38.240 --> 19:41.200\n outgoing person that's getting people to come in.\n\n19:41.200 --> 19:43.560\n Yeah, well I wasn't particularly charming\n\n19:43.560 --> 19:46.160\n but I could be very repetitious and loud.\n\n19:47.120 --> 19:52.120\n And the other employees were sort of juvenile delinquents\n\n19:53.640 --> 19:58.640\n who had no academic bent but somehow I found\n\n19:58.640 --> 20:03.400\n that I could impress them by performing\n\n20:03.400 --> 20:06.640\n this mental arithmetic.\n\n20:06.640 --> 20:08.280\n Yeah, there's something to that.\n\n20:10.160 --> 20:13.920\n Some of the most popular videos on the internet\n\n20:13.920 --> 20:18.000\n is there's a YouTube channel called Numberphile\n\n20:18.000 --> 20:20.440\n that shows off different mathematical ideas.\n\n20:20.440 --> 20:21.280\n I see.\n\n20:21.280 --> 20:23.360\n There's still something really profoundly interesting\n\n20:23.360 --> 20:27.160\n to people about math, the beauty of it.\n\n20:27.160 --> 20:31.240\n Something, even if they don't understand\n\n20:31.240 --> 20:33.640\n the basic concept even being discussed,\n\n20:33.640 --> 20:35.040\n there's something compelling to it.\n\n20:35.040 --> 20:37.160\n What do you think that is?\n\n20:37.160 --> 20:40.520\n Any lessons you drew from your early teen years\n\n20:40.520 --> 20:45.360\n when you were showing off to your friends with the numbers?\n\n20:45.360 --> 20:47.640\n Like what is it that attracts us\n\n20:47.640 --> 20:50.500\n to the beauty of mathematics do you think?\n\n20:51.340 --> 20:54.560\n The general population, not just the computer scientists\n\n20:54.560 --> 20:56.560\n and mathematicians.\n\n20:56.560 --> 20:59.600\n I think that you can do amazing things.\n\n20:59.600 --> 21:03.300\n You can test whether large numbers are prime.\n\n21:04.440 --> 21:09.440\n You can solve little puzzles\n\n21:09.560 --> 21:12.360\n about cannibals and missionaries.\n\n21:13.360 --> 21:18.360\n And that's a kind of achievement, it's puzzle solving.\n\n21:19.280 --> 21:22.720\n And at a higher level, the fact that you can do\n\n21:22.720 --> 21:24.600\n this reasoning that you can prove\n\n21:24.600 --> 21:28.960\n in an absolutely ironclad way that some of the angles\n\n21:28.960 --> 21:31.520\n of a triangle is 180 degrees.\n\n21:32.600 --> 21:35.300\n Yeah, it's a nice escape from the messiness\n\n21:35.300 --> 21:38.080\n of the real world where nothing can be proved.\n\n21:38.080 --> 21:41.320\n So, and we'll talk about it, but sometimes the ability\n\n21:41.320 --> 21:43.520\n to map the real world into such problems\n\n21:43.520 --> 21:47.080\n where you can't prove it is a powerful step.\n\n21:47.080 --> 21:47.900\n Yeah.\n\n21:47.900 --> 21:48.740\n It's amazing that we can do it.\n\n21:48.740 --> 21:50.040\n Of course, another attribute of geeks\n\n21:50.040 --> 21:53.620\n is they're not necessarily endowed\n\n21:53.620 --> 21:57.220\n with emotional intelligence, so they can live\n\n21:57.220 --> 21:59.960\n in a world of abstractions without having\n\n21:59.960 --> 22:04.960\n to master the complexities of dealing with people.\n\n22:06.620 --> 22:09.440\n So just to link on the historical note,\n\n22:09.440 --> 22:13.200\n as a PhD student in 1955, you joined the computational lab\n\n22:13.200 --> 22:17.040\n at Harvard where Howard Aiken had built the Mark I\n\n22:17.040 --> 22:18.520\n and the Mark IV computers.\n\n22:19.760 --> 22:22.000\n Just to take a step back into that history,\n\n22:22.000 --> 22:23.920\n what were those computers like?\n\n22:26.360 --> 22:31.160\n The Mark IV filled a large room,\n\n22:31.160 --> 22:33.700\n much bigger than this large office\n\n22:33.700 --> 22:36.880\n that we were talking in now.\n\n22:36.880 --> 22:39.120\n And you could walk around inside it.\n\n22:39.120 --> 22:43.340\n There were rows of relays.\n\n22:43.340 --> 22:45.360\n You could just walk around the interior\n\n22:45.360 --> 22:53.140\n and the machine would sometimes fail because of bugs,\n\n22:53.140 --> 22:56.220\n which literally meant flying creatures\n\n22:56.220 --> 22:57.920\n landing on the switches.\n\n22:59.820 --> 23:04.820\n So I never used that machine for any practical purpose.\n\n23:06.260 --> 23:11.260\n The lab eventually acquired one of the earlier\n\n23:12.680 --> 23:14.600\n commercial computers.\n\n23:14.600 --> 23:16.680\n And this was already in the 60s?\n\n23:16.680 --> 23:19.840\n No, in the mid 50s, or late 50s.\n\n23:19.840 --> 23:21.800\n There was already commercial computers in the...\n\n23:21.800 --> 23:26.240\n Yeah, we had a Univac, a Univac with 2,000 words of storage.\n\n23:27.280 --> 23:31.720\n And so you had to work hard to allocate the memory properly\n\n23:31.720 --> 23:36.120\n to also the excess time from one word to another\n\n23:36.120 --> 23:41.120\n depended on the number of the particular words.\n\n23:41.120 --> 23:44.880\n And so there was an art to sort of arranging\n\n23:44.880 --> 23:49.880\n the storage allocation to make fetching data rapid.\n\n23:51.240 --> 23:54.960\n Were you attracted to this actual physical world\n\n23:54.960 --> 23:58.140\n implementation of mathematics?\n\n23:58.140 --> 24:01.400\n So it's a mathematical machine that's actually doing\n\n24:01.400 --> 24:03.120\n the math physically?\n\n24:03.120 --> 24:04.800\n No, not at all.\n\n24:04.800 --> 24:09.400\n I think I was attracted to the underlying algorithms.\n\n24:09.400 --> 24:12.880\n But did you draw any inspiration?\n\n24:12.880 --> 24:17.240\n So could you have imagined, like what did you imagine\n\n24:17.240 --> 24:20.120\n was the future of these giant computers?\n\n24:20.120 --> 24:22.000\n Could you have imagined that 60 years later\n\n24:22.000 --> 24:25.780\n we'd have billions of these computers all over the world?\n\n24:25.780 --> 24:30.560\n I couldn't imagine that, but there was a sense\n\n24:30.560 --> 24:35.560\n in the laboratory that this was the wave of the future.\n\n24:36.120 --> 24:38.920\n In fact, my mother influenced me.\n\n24:38.920 --> 24:42.320\n She told me that data processing was gonna be really big\n\n24:42.320 --> 24:43.920\n and I should get into it.\n\n24:43.920 --> 24:47.280\n You're a smart woman.\n\n24:47.280 --> 24:49.080\n Yeah, she was a smart woman.\n\n24:49.080 --> 24:53.080\n And there was just a feeling that this was going\n\n24:53.080 --> 24:55.680\n to change the world, but I didn't think of it\n\n24:55.680 --> 24:57.200\n in terms of personal computing.\n\n24:57.200 --> 25:02.200\n I had no anticipation that we would be walking around\n\n25:02.920 --> 25:06.120\n with computers in our pockets or anything like that.\n\n25:06.120 --> 25:11.120\n Did you see computers as tools, as mathematical mechanisms\n\n25:12.800 --> 25:16.540\n to analyze sort of the theoretical computer science,\n\n25:16.540 --> 25:21.000\n or as the AI folks, which is an entire other community\n\n25:21.000 --> 25:24.480\n of dreamers, as something that could one day\n\n25:24.480 --> 25:26.840\n have human level intelligence?\n\n25:26.840 --> 25:29.560\n Well, AI wasn't very much on my radar.\n\n25:29.560 --> 25:33.200\n I did read Turing's paper about the...\n\n25:33.200 --> 25:38.080\n The Turing Test, Computing and Intelligence.\n\n25:38.080 --> 25:39.500\n Yeah, the Turing test.\n\n25:40.520 --> 25:41.840\n What'd you think about that paper?\n\n25:41.840 --> 25:43.740\n Was that just like science fiction?\n\n25:45.600 --> 25:48.280\n I thought that it wasn't a very good test\n\n25:48.280 --> 25:50.440\n because it was too subjective.\n\n25:50.440 --> 25:55.280\n So I didn't feel that the Turing test\n\n25:55.280 --> 25:58.400\n was really the right way to calibrate\n\n25:58.400 --> 26:01.000\n how intelligent an algorithm could be.\n\n26:01.000 --> 26:03.240\n But to linger on that, do you think it's,\n\n26:03.240 --> 26:07.800\n because you've come up with some incredible tests later on,\n\n26:07.800 --> 26:12.200\n tests on algorithms, right, that are like strong,\n\n26:12.200 --> 26:15.320\n reliable, robust across a bunch of different classes\n\n26:15.320 --> 26:20.020\n of algorithms, but returning to this emotional mess\n\n26:20.020 --> 26:22.840\n that is intelligence, do you think it's possible\n\n26:22.840 --> 26:26.420\n to come up with a test that's as ironclad\n\n26:26.420 --> 26:31.320\n as some of the computational complexity work?\n\n26:31.320 --> 26:32.800\n Well, I think the greater question\n\n26:32.800 --> 26:37.800\n is whether it's possible to achieve human level intelligence.\n\n26:38.720 --> 26:42.080\n Right, so first of all, let me, at the philosophical level,\n\n26:42.080 --> 26:46.320\n do you think it's possible to create algorithms\n\n26:46.320 --> 26:51.320\n that reason and would seem to us\n\n26:51.320 --> 26:54.080\n to have the same kind of intelligence as human beings?\n\n26:54.080 --> 26:56.680\n It's an open question.\n\n26:58.160 --> 27:03.160\n It seems to me that most of the achievements\n\n27:04.080 --> 27:09.080\n have operate within a very limited set of ground rules\n\n27:11.840 --> 27:15.400\n and for a very limited, precise task,\n\n27:15.400 --> 27:17.600\n which is a quite different situation\n\n27:17.600 --> 27:22.340\n from the processes that go on in the minds of humans,\n\n27:22.340 --> 27:25.040\n which where they have to sort of function\n\n27:25.040 --> 27:30.040\n in changing environments, they have emotions,\n\n27:30.120 --> 27:35.120\n they have physical attributes for exploring\n\n27:37.920 --> 27:41.400\n their environment, they have intuition,\n\n27:41.400 --> 27:46.400\n they have desires, emotions, and I don't see anything\n\n27:46.400 --> 27:51.400\n in the current achievements of what's called AI\n\n27:54.440 --> 27:56.940\n that come close to that capability.\n\n27:56.940 --> 28:01.940\n I don't think there's any computer program\n\n28:02.160 --> 28:05.720\n which surpasses a six month old child\n\n28:05.720 --> 28:09.020\n in terms of comprehension of the world.\n\n28:10.680 --> 28:15.560\n Do you think this complexity of human intelligence,\n\n28:15.560 --> 28:17.080\n all the cognitive abilities we have,\n\n28:17.080 --> 28:21.380\n all the emotion, do you think that could be reduced one day\n\n28:21.380 --> 28:23.960\n or just fundamentally can it be reduced\n\n28:23.960 --> 28:27.260\n to a set of algorithms or an algorithm?\n\n28:27.260 --> 28:31.880\n So can a Turing machine achieve human level intelligence?\n\n28:33.180 --> 28:35.940\n I am doubtful about that.\n\n28:35.940 --> 28:38.640\n I guess the argument in favor of it\n\n28:38.640 --> 28:45.640\n is that the human brain seems to achieve what we call\n\n28:47.240 --> 28:50.760\n intelligence cognitive abilities of different kinds.\n\n28:51.820 --> 28:54.300\n And if you buy the premise that the human brain\n\n28:54.300 --> 28:58.600\n is just an enormous interconnected set of switches,\n\n28:58.600 --> 29:03.120\n so to speak, then in principle, you should be able\n\n29:03.120 --> 29:07.420\n to diagnose what that interconnection structure is like,\n\n29:07.420 --> 29:09.400\n characterize the individual switches,\n\n29:09.400 --> 29:12.920\n and build a simulation outside.\n\n29:14.100 --> 29:17.640\n But while that may be true in principle,\n\n29:17.640 --> 29:19.900\n that cannot be the way we're eventually\n\n29:19.900 --> 29:21.720\n gonna tackle this problem.\n\n29:25.960 --> 29:29.360\n That does not seem like a feasible way to go about it.\n\n29:29.360 --> 29:32.480\n So there is, however, an existence proof that\n\n29:32.480 --> 29:37.480\n if you believe that the brain is just a network of neurons\n\n29:42.440 --> 29:45.240\n operating by rules, I guess you could say\n\n29:45.240 --> 29:50.160\n that that's an existence proof of the capabilities\n\n29:50.160 --> 29:55.100\n of a mechanism, but it would be almost impossible\n\n29:55.100 --> 30:00.100\n to acquire the information unless we got enough insight\n\n30:00.100 --> 30:02.780\n into the operation of the brain.\n\n30:02.780 --> 30:04.300\n But there's so much mystery there.\n\n30:04.300 --> 30:06.700\n Do you think, what do you make of consciousness,\n\n30:06.700 --> 30:11.020\n for example, as an example of something\n\n30:11.020 --> 30:13.180\n we completely have no clue about?\n\n30:13.180 --> 30:15.940\n The fact that we have this subjective experience.\n\n30:15.940 --> 30:19.780\n Is it possible that this network of,\n\n30:19.780 --> 30:22.900\n this circuit of switches is able to create\n\n30:22.900 --> 30:24.940\n something like consciousness?\n\n30:24.940 --> 30:26.820\n To know its own identity.\n\n30:26.820 --> 30:30.260\n Yeah, to know the algorithm, to know itself.\n\n30:30.260 --> 30:32.100\n To know itself.\n\n30:32.100 --> 30:35.340\n I think if you try to define that rigorously,\n\n30:35.340 --> 30:36.660\n you'd have a lot of trouble.\n\n30:36.660 --> 30:39.380\n Yeah, that seems to be.\n\n30:39.380 --> 30:44.380\n So I know that there are many who believe\n\n30:47.040 --> 30:52.040\n that general intelligence can be achieved,\n\n30:52.620 --> 30:55.780\n and there are even some who feel certain\n\n30:55.780 --> 30:59.180\n that the singularity will come\n\n30:59.180 --> 31:01.740\n and we will be surpassed by the machines\n\n31:01.740 --> 31:04.380\n which will then learn more and more about themselves\n\n31:04.380 --> 31:08.640\n and reduce humans to an inferior breed.\n\n31:08.640 --> 31:11.500\n I am doubtful that this will ever be achieved.\n\n31:12.700 --> 31:17.020\n Just for the fun of it, could you linger on why,\n\n31:17.020 --> 31:19.100\n what's your intuition, why you're doubtful?\n\n31:19.100 --> 31:23.060\n So there are quite a few people that are extremely worried\n\n31:23.060 --> 31:26.380\n about this existential threat of artificial intelligence,\n\n31:26.380 --> 31:29.220\n of us being left behind\n\n31:29.220 --> 31:32.340\n by this super intelligent new species.\n\n31:32.340 --> 31:36.920\n What's your intuition why that's not quite likely?\n\n31:37.860 --> 31:42.860\n Just because none of the achievements in speech\n\n31:43.480 --> 31:48.480\n or robotics or natural language processing\n\n31:48.580 --> 31:52.660\n or creation of flexible computer assistants\n\n31:52.660 --> 31:56.460\n or any of that comes anywhere near close\n\n31:56.460 --> 32:00.300\n to that level of cognition.\n\n32:00.300 --> 32:02.260\n What do you think about ideas of sort of,\n\n32:02.260 --> 32:05.340\n if we look at Moore's Law and exponential improvement\n\n32:06.140 --> 32:09.300\n to allow us, that would surprise us?\n\n32:09.300 --> 32:11.540\n Sort of our intuition fall apart\n\n32:11.540 --> 32:14.660\n with exponential improvement because, I mean,\n\n32:14.660 --> 32:16.060\n we're not able to kind of,\n\n32:16.060 --> 32:18.260\n we kind of think in linear improvement.\n\n32:18.260 --> 32:20.220\n We're not able to imagine a world\n\n32:20.220 --> 32:25.220\n that goes from the Mark I computer to an iPhone X.\n\n32:26.180 --> 32:27.540\n Yeah.\n\n32:27.540 --> 32:31.260\n So do you think we could be really surprised\n\n32:31.260 --> 32:33.420\n by the exponential growth?\n\n32:33.420 --> 32:37.540\n Or on the flip side, is it possible\n\n32:37.540 --> 32:42.220\n that also intelligence is actually way, way, way, way harder,\n\n32:42.220 --> 32:47.100\n even with exponential improvement to be able to crack?\n\n32:47.100 --> 32:50.300\n I don't think any constant factor improvement\n\n32:50.300 --> 32:53.980\n could change things.\n\n32:53.980 --> 32:58.100\n I mean, given our current comprehension\n\n32:58.100 --> 33:03.100\n of what cognition requires,\n\n33:04.940 --> 33:08.760\n it seems to me that multiplying the speed of the switches\n\n33:08.760 --> 33:10.940\n by a factor of a thousand or a million\n\n33:13.580 --> 33:16.600\n will not be useful until we really understand\n\n33:16.600 --> 33:21.280\n the organizational principle behind the network of switches.\n\n33:23.140 --> 33:25.420\n Well, let's jump into the network of switches\n\n33:25.420 --> 33:28.060\n and talk about combinatorial algorithms if we could.\n\n33:29.860 --> 33:31.700\n Let's step back with the very basics.\n\n33:31.700 --> 33:33.700\n What are combinatorial algorithms?\n\n33:33.700 --> 33:35.080\n And what are some major examples\n\n33:35.080 --> 33:37.000\n of problems they aim to solve?\n\n33:38.140 --> 33:43.140\n A combinatorial algorithm is one which deals\n\n33:43.140 --> 33:48.140\n with a system of discrete objects\n\n33:48.340 --> 33:52.300\n that can occupy various states\n\n33:52.300 --> 33:57.300\n or take on various values from a discrete set of values\n\n33:59.700 --> 34:02.700\n and need to be arranged or selected\n\n34:06.620 --> 34:10.520\n in such a way as to achieve some,\n\n34:10.520 --> 34:13.100\n to minimize some cost function.\n\n34:13.100 --> 34:16.220\n Or to prove the existence\n\n34:16.220 --> 34:19.980\n of some combinatorial configuration.\n\n34:19.980 --> 34:24.980\n So an example would be coloring the vertices of a graph.\n\n34:25.020 --> 34:25.960\n What's a graph?\n\n34:27.280 --> 34:28.120\n Let's step back.\n\n34:28.120 --> 34:33.120\n So it's fun to ask one of the greatest\n\n34:34.780 --> 34:36.180\n computer scientists of all time\n\n34:36.180 --> 34:39.260\n the most basic questions in the beginning of most books.\n\n34:39.260 --> 34:41.420\n But for people who might not know,\n\n34:41.420 --> 34:44.480\n but in general how you think about it, what is a graph?\n\n34:44.480 --> 34:47.260\n A graph, that's simple.\n\n34:47.260 --> 34:51.220\n It's a set of points, certain pairs of which\n\n34:51.220 --> 34:54.120\n are joined by lines called edges.\n\n34:55.060 --> 34:57.860\n And they sort of represent the,\n\n34:58.740 --> 35:02.340\n in different applications represent the interconnections\n\n35:02.340 --> 35:05.900\n between discrete objects.\n\n35:05.900 --> 35:07.740\n So they could be the interactions,\n\n35:07.740 --> 35:12.500\n interconnections between switches in a digital circuit\n\n35:12.500 --> 35:16.380\n or interconnections indicating the communication patterns\n\n35:16.380 --> 35:17.940\n of a human community.\n\n35:19.300 --> 35:21.420\n And they could be directed or undirected\n\n35:21.420 --> 35:25.540\n and then as you've mentioned before, might have costs.\n\n35:25.540 --> 35:27.700\n Right, they can be directed or undirected.\n\n35:27.700 --> 35:30.660\n They can be, you can think of them as,\n\n35:30.660 --> 35:34.260\n if you think, if a graph were representing\n\n35:34.260 --> 35:38.700\n a communication network, then the edge could be undirected\n\n35:38.700 --> 35:41.780\n meaning that information could flow along it\n\n35:41.780 --> 35:44.540\n in both directions or it could be directed\n\n35:44.540 --> 35:46.980\n with only one way communication.\n\n35:46.980 --> 35:49.740\n A road system is another example of a graph\n\n35:49.740 --> 35:52.220\n with weights on the edges.\n\n35:52.220 --> 35:57.220\n And then a lot of problems of optimizing the efficiency\n\n35:57.220 --> 36:02.220\n of such networks or learning about the performance\n\n36:04.660 --> 36:09.660\n of such networks are the object of combinatorial algorithms.\n\n36:11.340 --> 36:15.620\n So it could be scheduling classes at a school\n\n36:15.620 --> 36:20.620\n where the vertices, the nodes of the network\n\n36:20.620 --> 36:25.620\n are the individual classes and the edges indicate\n\n36:25.620 --> 36:28.580\n the constraints which say that certain classes\n\n36:28.580 --> 36:30.860\n cannot take place at the same time\n\n36:30.860 --> 36:34.980\n or certain teachers are available only for certain classes,\n\n36:34.980 --> 36:36.300\n et cetera.\n\n36:36.300 --> 36:41.300\n Or I talked earlier about the assignment problem\n\n36:41.300 --> 36:43.060\n of matching the boys with the girls\n\n36:43.060 --> 36:48.060\n where you have there a graph with an edge\n\n36:48.060 --> 36:51.300\n from each boy to each girl with a weight\n\n36:51.300 --> 36:53.460\n indicating the cost.\n\n36:53.460 --> 36:58.460\n Or in logical design of computers,\n\n36:58.460 --> 37:03.460\n you might want to find a set of so called gates,\n\n37:04.300 --> 37:07.500\n switches that perform logical functions\n\n37:07.500 --> 37:10.060\n which can be interconnected to each other\n\n37:10.060 --> 37:13.740\n and perform logical functions which can be interconnected\n\n37:13.740 --> 37:15.580\n to realize some function.\n\n37:15.580 --> 37:20.580\n So you might ask how many gates do you need\n\n37:22.460 --> 37:27.460\n in order for a circuit to give a yes output\n\n37:33.220 --> 37:38.220\n if at least a given number of its inputs are ones\n\n37:38.220 --> 37:42.980\n and no if fewer are present.\n\n37:42.980 --> 37:46.580\n My favorite's probably all the work with network flow.\n\n37:46.580 --> 37:50.780\n So anytime you have, I don't know why it's so compelling\n\n37:50.780 --> 37:52.420\n but there's something just beautiful about it.\n\n37:52.420 --> 37:54.340\n It seems like there's so many applications\n\n37:54.340 --> 37:59.340\n and communication networks and traffic flow\n\n38:00.700 --> 38:03.340\n that you can map into these and then you could think\n\n38:03.340 --> 38:05.580\n of pipes and water going through pipes\n\n38:05.580 --> 38:07.260\n and you could optimize it in different ways.\n\n38:07.260 --> 38:11.140\n There's something always visually and intellectually\n\n38:11.140 --> 38:12.340\n compelling to me about it.\n\n38:12.340 --> 38:14.660\n And of course you've done work there.\n\n38:15.940 --> 38:20.940\n Yeah, so there the edges represent channels\n\n38:21.540 --> 38:24.540\n along which some commodity can flow.\n\n38:24.540 --> 38:29.540\n It might be gas, it might be water, it might be information.\n\n38:29.900 --> 38:33.900\n Maybe supply chain as well like products being.\n\n38:33.900 --> 38:37.740\n Products flowing from one operation to another.\n\n38:37.740 --> 38:41.140\n And the edges have a capacity which is the rate\n\n38:41.140 --> 38:43.740\n at which the commodity can flow.\n\n38:43.740 --> 38:48.740\n And a central problem is to determine\n\n38:49.220 --> 38:51.700\n given a network of these channels.\n\n38:51.700 --> 38:54.580\n In this case the edges are communication channels.\n\n38:56.380 --> 39:01.380\n The challenge is to find the maximum rate\n\n39:01.380 --> 39:05.460\n at which the information can flow along these channels\n\n39:05.460 --> 39:09.060\n to get from a source to a destination.\n\n39:09.060 --> 39:12.620\n And that's a fundamental combinatorial problem\n\n39:12.620 --> 39:17.620\n that I've worked on jointly with the scientist Jack Edmonds.\n\n39:19.780 --> 39:22.380\n I think we're the first to give a formal proof\n\n39:22.380 --> 39:27.380\n that this maximum flow problem through a network\n\n39:27.460 --> 39:30.660\n can be solved in polynomial time.\n\n39:30.660 --> 39:33.900\n Which I remember the first time I learned that.\n\n39:33.900 --> 39:38.900\n Just learning that in maybe even grad school.\n\n39:39.740 --> 39:41.100\n I don't think it was even undergrad.\n\n39:41.100 --> 39:43.380\n No, algorithm, yeah.\n\n39:43.380 --> 39:48.380\n Do network flows get taught in basic algorithms courses?\n\n39:50.100 --> 39:51.100\n Yes, probably.\n\n39:51.100 --> 39:53.740\n Okay, so yeah, I remember being very surprised\n\n39:53.740 --> 39:56.780\n that max flow is a polynomial time algorithm.\n\n39:56.780 --> 39:59.900\n That there's a nice fast algorithm that solves max flow.\n\n39:59.900 --> 40:04.900\n So there is an algorithm named after you in Edmonds.\n\n40:06.540 --> 40:08.380\n The Edmond Carp algorithm for max flow.\n\n40:08.380 --> 40:12.580\n So what was it like tackling that problem\n\n40:12.580 --> 40:15.660\n and trying to arrive at a polynomial time solution?\n\n40:15.660 --> 40:17.180\n And maybe you can describe the algorithm.\n\n40:17.180 --> 40:19.900\n Maybe you can describe what's the running time complexity\n\n40:19.900 --> 40:20.740\n that you showed.\n\n40:20.740 --> 40:23.340\n Yeah, well, first of all,\n\n40:23.340 --> 40:25.620\n what is a polynomial time algorithm?\n\n40:25.620 --> 40:28.580\n Perhaps we could discuss that.\n\n40:28.580 --> 40:31.580\n So yeah, let's actually just even, yeah.\n\n40:31.580 --> 40:34.140\n What is algorithmic complexity?\n\n40:34.140 --> 40:38.220\n What are the major classes of algorithm complexity?\n\n40:38.220 --> 40:41.860\n So in a problem like the assignment problem\n\n40:41.860 --> 40:46.860\n or scheduling schools or any of these applications,\n\n40:48.820 --> 40:53.820\n you have a set of input data which might, for example,\n\n40:53.820 --> 40:58.820\n be a set of vertices connected by edges\n\n41:01.460 --> 41:06.380\n with you're given for each edge the capacity of the edge.\n\n41:07.340 --> 41:12.220\n And you have algorithms which are,\n\n41:12.220 --> 41:16.700\n think of them as computer programs with operations\n\n41:16.700 --> 41:19.940\n such as addition, subtraction, multiplication, division,\n\n41:19.940 --> 41:22.020\n comparison of numbers, and so on.\n\n41:22.020 --> 41:26.940\n And you're trying to construct an algorithm\n\n41:29.540 --> 41:33.860\n based on those operations, which will determine\n\n41:33.860 --> 41:37.260\n in a minimum number of computational steps\n\n41:37.260 --> 41:38.460\n the answer to the problem.\n\n41:38.460 --> 41:41.100\n In this case, the computational step\n\n41:41.100 --> 41:43.380\n is one of those operations.\n\n41:43.380 --> 41:46.060\n And the answer to the problem is let's say\n\n41:46.060 --> 41:50.420\n the configuration of the network\n\n41:50.420 --> 41:52.540\n that carries the maximum amount of flow.\n\n41:54.860 --> 41:58.340\n And an algorithm is said to run in polynomial time\n\n41:59.940 --> 42:04.940\n if as a function of the size of the input,\n\n42:04.980 --> 42:07.900\n the number of vertices, the number of edges, and so on,\n\n42:09.180 --> 42:12.460\n the number of basic computational steps grows\n\n42:12.460 --> 42:15.220\n only as some fixed power of that size.\n\n42:15.220 --> 42:20.220\n A linear algorithm would execute a number of steps\n\n42:21.940 --> 42:24.660\n linearly proportional to the size.\n\n42:24.660 --> 42:27.700\n Quadratic algorithm would be steps proportional\n\n42:27.700 --> 42:29.620\n to the square of the size, and so on.\n\n42:30.660 --> 42:34.660\n And algorithms whose running time is bounded\n\n42:34.660 --> 42:37.260\n by some fixed power of the size\n\n42:37.260 --> 42:39.900\n are called polynomial algorithms.\n\n42:39.900 --> 42:40.740\n Yeah.\n\n42:40.740 --> 42:44.060\n And that's supposed to be relatively fast class\n\n42:44.060 --> 42:44.900\n of algorithms.\n\n42:44.900 --> 42:45.740\n That's right.\n\n42:45.740 --> 42:49.500\n Theoreticians take that to be the definition\n\n42:49.500 --> 42:53.300\n of an algorithm being efficient.\n\n42:54.460 --> 42:57.940\n And we're interested in which problems can be solved\n\n42:57.940 --> 43:02.300\n by such efficient algorithms.\n\n43:02.300 --> 43:04.940\n One can argue whether that's the right definition\n\n43:04.940 --> 43:08.100\n of efficient because you could have an algorithm\n\n43:08.100 --> 43:11.420\n whose running time is the 10,000th power\n\n43:11.420 --> 43:12.540\n of the size of the input,\n\n43:12.540 --> 43:15.860\n and that wouldn't be really efficient.\n\n43:15.860 --> 43:19.220\n And in practice, it's oftentimes reducing\n\n43:19.220 --> 43:22.620\n from an N squared algorithm to an N log N\n\n43:22.620 --> 43:26.940\n or a linear time is practically the jump\n\n43:26.940 --> 43:30.260\n that you wanna make to allow a real world system\n\n43:30.260 --> 43:31.220\n to solve a problem.\n\n43:31.220 --> 43:33.260\n Yeah, that's also true because especially\n\n43:33.260 --> 43:35.860\n as we get very large networks,\n\n43:35.860 --> 43:38.060\n the size can be in the millions,\n\n43:38.060 --> 43:43.060\n and then anything above N log N\n\n43:43.700 --> 43:46.940\n where N is the size would be too much\n\n43:46.940 --> 43:49.940\n for a practical solution.\n\n43:49.940 --> 43:52.500\n Okay, so that's polynomial time algorithms.\n\n43:52.500 --> 43:55.100\n What other classes of algorithms are there?\n\n43:56.140 --> 44:01.100\n What's, so that usually they designate polynomials\n\n44:01.100 --> 44:02.380\n of the letter P.\n\n44:02.380 --> 44:03.220\n Yeah.\n\n44:03.220 --> 44:06.180\n There's also NP, NP complete and NP hard.\n\n44:06.180 --> 44:07.140\n Yeah.\n\n44:07.140 --> 44:10.900\n So can you try to disentangle those\n\n44:10.900 --> 44:14.260\n by trying to define them simply?\n\n44:14.260 --> 44:16.940\n Right, so a polynomial time algorithm\n\n44:16.940 --> 44:20.460\n is one whose running time is bounded\n\n44:20.460 --> 44:22.700\n by a polynomial in the size of the input.\n\n44:24.540 --> 44:29.380\n Then the class of such algorithms is called P.\n\n44:29.380 --> 44:31.420\n In the worst case, by the way, we should say, right?\n\n44:31.420 --> 44:32.260\n Yeah.\n\n44:32.260 --> 44:33.100\n So for every case of the problem.\n\n44:33.100 --> 44:34.300\n Yes, that's right, and that's very important\n\n44:34.300 --> 44:39.300\n that in this theory, when we measure the complexity\n\n44:39.500 --> 44:44.500\n of an algorithm, we really measure the number of steps,\n\n44:45.020 --> 44:48.900\n the growth of the number of steps in the worst case.\n\n44:48.900 --> 44:53.460\n So you may have an algorithm that runs very rapidly\n\n44:53.460 --> 44:56.820\n in most cases, but if there's any case\n\n44:56.820 --> 45:00.100\n where it gets into a very long computation,\n\n45:00.100 --> 45:03.420\n that would increase the computational complexity\n\n45:03.420 --> 45:04.420\n by this measure.\n\n45:05.300 --> 45:07.340\n And that's a very important issue\n\n45:07.340 --> 45:10.540\n because there are, as we may discuss later,\n\n45:10.540 --> 45:13.220\n there are some very important algorithms\n\n45:13.220 --> 45:15.500\n which don't have a good standing\n\n45:15.500 --> 45:18.100\n from the point of view of their worst case performance\n\n45:18.100 --> 45:19.700\n and yet are very effective.\n\n45:20.620 --> 45:24.300\n So theoreticians are interested in P,\n\n45:24.300 --> 45:27.500\n the class of problem solvable in polynomial time.\n\n45:27.500 --> 45:32.500\n Then there's NP, which is the class of problems\n\n45:34.500 --> 45:39.500\n which may be hard to solve, but when confronted\n\n45:42.700 --> 45:46.620\n with a solution, you can check it in polynomial time.\n\n45:46.620 --> 45:49.180\n Let me give you an example there.\n\n45:49.180 --> 45:52.420\n So if we look at the assignment problem,\n\n45:52.420 --> 45:55.940\n so you have N boys, you have N girls,\n\n45:55.940 --> 45:58.740\n the number of numbers that you need to write down\n\n45:58.740 --> 46:03.740\n to specify the problem instance is N squared.\n\n46:03.740 --> 46:08.740\n And the question is how many steps are needed to solve it?\n\n46:11.540 --> 46:15.660\n And Jack Edmonds and I were the first to show\n\n46:15.660 --> 46:18.460\n that it could be done in time and cubed.\n\n46:20.260 --> 46:23.900\n Earlier algorithms required N to the fourth.\n\n46:23.900 --> 46:27.340\n So as a polynomial function of the size of the input,\n\n46:27.340 --> 46:29.180\n this is a fast algorithm.\n\n46:30.180 --> 46:34.100\n Now to illustrate the class NP, the question is\n\n46:34.100 --> 46:38.940\n how long would it take to verify\n\n46:38.940 --> 46:41.700\n that a solution is optimal?\n\n46:42.700 --> 46:47.700\n So for example, if the input was a graph,\n\n46:48.140 --> 46:53.140\n we might want to find the largest clique in the graph\n\n46:53.140 --> 46:58.140\n or a clique is a set of vertices such that any vertex,\n\n46:58.860 --> 47:03.860\n each vertex in the set is adjacent to each of the others.\n\n47:03.980 --> 47:08.940\n So the clique is a complete subgraph.\n\n47:08.940 --> 47:11.900\n Yeah, so if it's a Facebook social network,\n\n47:11.900 --> 47:15.300\n everybody's friends with everybody else, close clique.\n\n47:15.300 --> 47:17.300\n No, that would be what's called a complete graph.\n\n47:17.300 --> 47:18.220\n It would be.\n\n47:18.220 --> 47:20.660\n No, I mean within that clique.\n\n47:20.660 --> 47:21.900\n Within that clique, yeah.\n\n47:21.900 --> 47:25.580\n Yeah, they're all friends.\n\n47:25.580 --> 47:27.820\n So a complete graph is when?\n\n47:27.820 --> 47:28.820\n Everybody is friendly.\n\n47:28.820 --> 47:31.340\n As everybody is friends with everybody, yeah.\n\n47:31.340 --> 47:36.340\n So the problem might be to determine whether\n\n47:36.340 --> 47:41.000\n in a given graph there exists a clique of a certain size.\n\n47:43.020 --> 47:45.740\n Now that turns out to be a very hard problem,\n\n47:45.740 --> 47:50.740\n but if somebody hands you a clique and asks you to check\n\n47:50.740 --> 47:55.180\n whether it is, hands you a set of vertices\n\n47:55.180 --> 47:57.380\n and asks you to check whether it's a clique,\n\n47:58.900 --> 48:01.900\n you could do that simply by exhaustively looking\n\n48:01.900 --> 48:05.220\n at all of the edges between the vertices and the clique\n\n48:05.220 --> 48:08.020\n and verifying that they're all there.\n\n48:08.020 --> 48:10.540\n And that's a polynomial time algorithm.\n\n48:10.540 --> 48:11.540\n That's a polynomial.\n\n48:11.540 --> 48:15.420\n So the problem of finding the clique\n\n48:17.620 --> 48:19.300\n appears to be extremely hard,\n\n48:19.300 --> 48:21.700\n but the problem of verifying a clique\n\n48:22.980 --> 48:26.500\n to see if it reaches a target number of vertices\n\n48:28.260 --> 48:31.700\n is easy to verify.\n\n48:31.700 --> 48:35.740\n So finding the clique is hard, checking it is easy.\n\n48:35.740 --> 48:39.020\n Problems of that nature are called\n\n48:39.020 --> 48:42.460\n nondeterministic polynomial time algorithms,\n\n48:42.460 --> 48:44.300\n and that's the class NP.\n\n48:45.700 --> 48:48.360\n And what about NP complete and NP hard?\n\n48:48.360 --> 48:50.900\n Okay, let's talk about problems\n\n48:50.900 --> 48:53.800\n where you're getting a yes or no answer\n\n48:53.800 --> 48:55.460\n rather than a numerical value.\n\n48:55.460 --> 48:58.780\n So either there is a perfect matching\n\n48:58.780 --> 49:03.780\n of the boys with the girls or there isn't.\n\n49:04.180 --> 49:09.180\n It's clear that every problem in P is also in NP.\n\n49:10.580 --> 49:12.580\n If you can solve the problem exactly,\n\n49:12.580 --> 49:17.540\n then you can certainly verify the solution.\n\n49:17.540 --> 49:22.540\n On the other hand, there are problems in the class NP.\n\n49:23.820 --> 49:27.140\n This is the class of problems that are easy to check,\n\n49:27.140 --> 49:29.700\n although they may be hard to solve.\n\n49:29.700 --> 49:33.780\n It's not at all clear that problems in NP lie in P.\n\n49:33.780 --> 49:36.220\n So for example, if we're looking\n\n49:36.220 --> 49:39.300\n at scheduling classes at a school,\n\n49:39.300 --> 49:44.300\n the fact that you can verify when handed a schedule\n\n49:44.300 --> 49:47.980\n for the school, whether it meets all the requirements,\n\n49:47.980 --> 49:51.380\n that doesn't mean that you can find the schedule rapidly.\n\n49:51.380 --> 49:55.780\n So intuitively, NP, nondeterministic polynomial checking\n\n49:55.780 --> 50:00.780\n rather than finding, is going to be harder than,\n\n50:03.180 --> 50:06.140\n is going to include, is easier.\n\n50:06.140 --> 50:08.820\n Checking is easier, and therefore the class of problems\n\n50:08.820 --> 50:11.940\n that can be checked appears to be much larger\n\n50:11.940 --> 50:14.620\n than the class of problems that can be solved.\n\n50:14.620 --> 50:17.380\n And then you keep adding appears to,\n\n50:17.380 --> 50:22.220\n and sort of these additional words that designate\n\n50:22.220 --> 50:24.060\n that we don't know for sure yet.\n\n50:24.060 --> 50:25.180\n We don't know for sure.\n\n50:25.180 --> 50:28.140\n So the theoretical question, which is considered\n\n50:28.140 --> 50:30.420\n to be the most central problem\n\n50:30.420 --> 50:32.640\n in theoretical computer science,\n\n50:32.640 --> 50:35.460\n or at least computational complexity theory,\n\n50:36.380 --> 50:38.560\n combinatorial algorithm theory,\n\n50:38.560 --> 50:42.720\n the question is whether P is equal to NP.\n\n50:43.600 --> 50:46.300\n If P were equal to NP, it would be amazing.\n\n50:46.300 --> 50:50.820\n It would mean that every problem\n\n50:54.240 --> 50:56.920\n where a solution can be rapidly checked\n\n50:58.080 --> 51:00.900\n can actually be solved in polynomial time.\n\n51:00.900 --> 51:03.420\n We don't really believe that's true.\n\n51:03.420 --> 51:05.780\n If you're scheduling classes at a school,\n\n51:05.780 --> 51:10.780\n we expect that if somebody hands you a satisfying schedule,\n\n51:13.020 --> 51:15.620\n you can verify that it works.\n\n51:15.620 --> 51:17.140\n That doesn't mean that you should be able\n\n51:17.140 --> 51:18.940\n to find such a schedule.\n\n51:18.940 --> 51:23.940\n So intuitively, NP encompasses a lot more problems than P.\n\n51:24.140 --> 51:28.020\n So can we take a small tangent\n\n51:28.020 --> 51:30.460\n and break apart that intuition?\n\n51:30.460 --> 51:34.540\n So do you, first of all, think that the biggest\n\n51:34.540 --> 51:36.200\n sort of open problem in computer science,\n\n51:36.200 --> 51:40.000\n maybe mathematics, is whether P equals NP?\n\n51:40.000 --> 51:43.220\n Do you think P equals NP,\n\n51:43.220 --> 51:46.300\n or do you think P is not equal to NP?\n\n51:46.300 --> 51:48.820\n If you had to bet all your money on it.\n\n51:48.820 --> 51:52.020\n I would bet that P is unequal to NP,\n\n51:52.020 --> 51:54.280\n simply because there are problems\n\n51:54.280 --> 51:55.940\n that have been around for centuries\n\n51:55.940 --> 51:58.980\n and have been studied intensively in mathematics,\n\n51:58.980 --> 52:02.060\n and even more so in the last 50 years\n\n52:02.060 --> 52:05.600\n since the P versus NP was stated.\n\n52:05.600 --> 52:10.180\n And no polynomial time algorithms have been found\n\n52:10.180 --> 52:13.700\n for these easy to check problems.\n\n52:13.700 --> 52:17.620\n So one example is a problem that goes back\n\n52:17.620 --> 52:19.860\n to the mathematician Gauss,\n\n52:19.860 --> 52:24.480\n who was interested in factoring large numbers.\n\n52:24.480 --> 52:27.960\n So we know what a number is prime\n\n52:27.960 --> 52:31.500\n if it cannot be written as the product\n\n52:31.500 --> 52:35.100\n of two or more numbers unequal to one.\n\n52:36.340 --> 52:41.340\n So if we can factor a number like 91, it's seven times 13.\n\n52:43.820 --> 52:48.820\n But if I give you 20 digit or 30 digit numbers,\n\n52:50.860 --> 52:52.540\n you're probably gonna be at a loss\n\n52:52.540 --> 52:55.440\n to have any idea whether they can be factored.\n\n52:56.840 --> 53:00.020\n So the problem of factoring very large numbers\n\n53:00.020 --> 53:05.020\n does not appear to have an efficient solution.\n\n53:06.960 --> 53:09.640\n But once you have found the factors,\n\n53:11.680 --> 53:16.600\n expressed the number as a product of two smaller numbers,\n\n53:16.600 --> 53:19.960\n you can quickly verify that they are factors of the number.\n\n53:19.960 --> 53:22.400\n And your intuition is a lot of people finding,\n\n53:23.540 --> 53:25.720\n a lot of brilliant people have tried to find algorithms\n\n53:25.720 --> 53:26.960\n for this one particular problem.\n\n53:26.960 --> 53:30.520\n There's many others like it that are really well studied\n\n53:30.520 --> 53:33.960\n and it would be great to find an efficient algorithm for.\n\n53:33.960 --> 53:38.960\n Right, and in fact, we have some results\n\n53:40.320 --> 53:44.680\n that I was instrumental in obtaining following up on work\n\n53:44.680 --> 53:46.840\n by the mathematician Stephen Cook\n\n53:48.720 --> 53:53.720\n to show that within the class NP of easy to check problems,\n\n53:53.720 --> 53:57.080\n easy to check problems, there's a huge number\n\n53:57.080 --> 54:00.640\n that are equivalent in the sense that either all of them\n\n54:00.640 --> 54:03.200\n or none of them lie in P.\n\n54:03.200 --> 54:06.400\n And this happens only if P is equal to NP.\n\n54:06.400 --> 54:11.240\n So if P is unequal to NP, we would also know\n\n54:11.240 --> 54:16.240\n that virtually all the standard combinatorial problems,\n\n54:16.240 --> 54:20.280\n virtually all the standard combinatorial problems,\n\n54:20.280 --> 54:23.860\n if P is unequal to NP, none of them can be solved\n\n54:23.860 --> 54:25.920\n in polynomial time.\n\n54:25.920 --> 54:28.560\n Can you explain how that's possible\n\n54:28.560 --> 54:32.280\n to tie together so many problems in a nice bunch\n\n54:32.280 --> 54:36.560\n that if one is proven to be efficient, then all are?\n\n54:36.560 --> 54:40.600\n The first and most important stage of progress\n\n54:40.600 --> 54:45.600\n was a result by Stephen Cook who showed that a certain problem\n\n54:49.680 --> 54:54.560\n called the satisfiability problem of propositional logic\n\n54:55.880 --> 55:00.200\n is as hard as any problem in the class P.\n\n55:00.200 --> 55:05.200\n So the propositional logic problem is expressed\n\n55:05.200 --> 55:10.200\n in terms of expressions involving the logical operations\n\n55:11.040 --> 55:16.040\n and, or, and not operating on variables\n\n55:16.860 --> 55:19.240\n that can be either true or false.\n\n55:19.240 --> 55:24.240\n So an instance of the problem would be some formula\n\n55:24.560 --> 55:26.800\n involving and, or, and not.\n\n55:28.240 --> 55:31.180\n And the question would be whether there is an assignment\n\n55:31.180 --> 55:34.900\n of truth values to the variables in the problem\n\n55:34.900 --> 55:37.400\n that would make the formula true.\n\n55:37.400 --> 55:42.400\n So for example, if I take the formula A or B\n\n55:42.920 --> 55:47.920\n and A or not B and not A or B and not A or not B\n\n55:49.360 --> 55:51.280\n and take the conjunction of all four\n\n55:51.280 --> 55:54.600\n of those so called expressions,\n\n55:54.600 --> 55:59.080\n you can determine that no assignment of truth values\n\n55:59.080 --> 56:03.920\n to the variables A and B will allow that conjunction\n\n56:03.920 --> 56:08.920\n of what are called clauses to be true.\n\n56:09.200 --> 56:14.200\n So that's an example of a formula in propositional logic\n\n56:16.920 --> 56:21.920\n involving expressions based on the operations and, or, and not.\n\n56:23.800 --> 56:27.280\n That's an example of a problem which is not satisfiable.\n\n56:27.280 --> 56:29.280\n There is no solution that satisfies\n\n56:29.280 --> 56:31.200\n all of those constraints.\n\n56:31.200 --> 56:33.800\n I mean that's like one of the cleanest and fundamental\n\n56:33.800 --> 56:35.320\n problems in computer science.\n\n56:35.320 --> 56:37.680\n It's like a nice statement of a really hard problem.\n\n56:37.680 --> 56:39.960\n It's a nice statement of a really hard problem\n\n56:39.960 --> 56:44.960\n and what Cook showed is that every problem in NP\n\n56:50.120 --> 56:53.560\n can be reexpressed as an instance\n\n56:53.560 --> 56:56.080\n of the satisfiability problem.\n\n56:56.080 --> 57:01.080\n So to do that, he used the observation\n\n57:02.080 --> 57:04.160\n that a very simple abstract machine\n\n57:04.160 --> 57:08.360\n called the Turing machine can be used\n\n57:08.360 --> 57:12.400\n to describe any algorithm.\n\n57:14.960 --> 57:17.800\n An algorithm for any realistic computer\n\n57:17.800 --> 57:22.800\n can be translated into an equivalent algorithm\n\n57:22.840 --> 57:25.840\n on one of these Turing machines\n\n57:25.840 --> 57:27.960\n which are extremely simple.\n\n57:27.960 --> 57:30.560\n So a Turing machine, there's a tape and you can\n\n57:30.560 --> 57:33.360\n Yeah, you have data on a tape\n\n57:33.360 --> 57:35.720\n and you have basic instructions,\n\n57:35.720 --> 57:39.640\n a finite list of instructions which say,\n\n57:39.640 --> 57:42.280\n if you're reading a particular symbol on the tape\n\n57:43.520 --> 57:45.520\n and you're in a particular state,\n\n57:45.520 --> 57:49.840\n then you can move to a different state\n\n57:49.840 --> 57:51.400\n and change the state of the number\n\n57:51.400 --> 57:53.760\n or the element that you were looking at,\n\n57:53.760 --> 57:55.760\n the cell of the tape that you were looking at.\n\n57:55.760 --> 57:58.560\n And that was like a metaphor and a mathematical construct\n\n57:58.560 --> 57:59.880\n that Turing put together\n\n57:59.880 --> 58:02.200\n to represent all possible computation.\n\n58:02.200 --> 58:03.600\n All possible computation.\n\n58:03.600 --> 58:06.240\n Now, one of these so called Turing machines\n\n58:06.240 --> 58:09.320\n is too simple to be useful in practice,\n\n58:09.320 --> 58:11.360\n but for theoretical purposes,\n\n58:11.360 --> 58:15.880\n we can depend on the fact that an algorithm\n\n58:15.880 --> 58:18.840\n for any computer can be translated\n\n58:18.840 --> 58:21.320\n into one that would run on a Turing machine.\n\n58:21.320 --> 58:24.920\n And then using that fact,\n\n58:26.280 --> 58:29.240\n he could sort of describe\n\n58:31.240 --> 58:35.640\n any possible non deterministic polynomial time algorithm.\n\n58:35.640 --> 58:40.000\n Any algorithm for a problem in NP\n\n58:40.000 --> 58:44.520\n could be expressed as a sequence of moves\n\n58:44.520 --> 58:47.360\n of the Turing machine described\n\n58:47.360 --> 58:51.520\n in terms of reading a symbol on the tape\n\n58:54.160 --> 58:55.560\n while you're in a given state\n\n58:55.560 --> 59:00.000\n and moving to a new state and leaving behind a new symbol.\n\n59:00.000 --> 59:03.560\n And given that fact\n\n59:03.560 --> 59:07.680\n that any non deterministic polynomial time algorithm\n\n59:07.680 --> 59:12.680\n can be described by a list of such instructions,\n\n59:12.920 --> 59:15.880\n you could translate the problem\n\n59:15.880 --> 59:19.120\n into the language of the satisfiability problem.\n\n59:19.120 --> 59:20.360\n Is that amazing to you, by the way,\n\n59:20.360 --> 59:21.320\n if you take yourself back\n\n59:21.320 --> 59:24.640\n when you were first thinking about the space of problems?\n\n59:24.640 --> 59:26.720\n How amazing is that?\n\n59:26.720 --> 59:27.920\n It's astonishing.\n\n59:27.920 --> 59:30.320\n When you look at Cook's proof,\n\n59:30.320 --> 59:34.520\n it's not too difficult to sort of figure out\n\n59:34.520 --> 59:38.520\n why this is so,\n\n59:38.520 --> 59:40.720\n but the implications are staggering.\n\n59:40.720 --> 59:45.720\n It tells us that this, of all the problems in NP,\n\n59:46.240 --> 59:49.720\n all the problems where solutions are easy to check,\n\n59:49.720 --> 59:53.320\n they can all be rewritten\n\n59:53.320 --> 59:57.760\n in terms of the satisfiability problem.\n\n59:59.280 --> 1:00:04.000\n Yeah, it's adding so much more weight\n\n1:00:04.000 --> 1:00:06.800\n to the P equals NP question\n\n1:00:06.800 --> 1:00:10.600\n because all it takes is to show that one algorithm\n\n1:00:10.600 --> 1:00:11.440\n in this class.\n\n1:00:11.440 --> 1:00:13.760\n So the P versus NP can be re expressed\n\n1:00:13.760 --> 1:00:17.600\n as simply asking whether the satisfiability problem\n\n1:00:17.600 --> 1:00:21.480\n of propositional logic is solvable in polynomial time.\n\n1:00:23.520 --> 1:00:25.120\n But there's more.\n\n1:00:28.000 --> 1:00:30.360\n I encountered Cook's paper\n\n1:00:30.360 --> 1:00:34.600\n when he published it in a conference in 1971.\n\n1:00:34.600 --> 1:00:37.760\n Yeah, so when I saw Cook's paper\n\n1:00:37.760 --> 1:00:42.760\n and saw this reduction of each of the problems in NP\n\n1:00:44.440 --> 1:00:49.200\n by a uniform method to the satisfiability problem\n\n1:00:49.200 --> 1:00:50.880\n of propositional logic,\n\n1:00:52.600 --> 1:00:54.600\n that meant that the satisfiability problem\n\n1:00:54.600 --> 1:00:57.720\n was a universal combinatorial problem.\n\n1:00:59.320 --> 1:01:04.160\n And it occurred to me through experience I had had\n\n1:01:04.160 --> 1:01:07.760\n in trying to solve other combinatorial problems\n\n1:01:07.760 --> 1:01:10.440\n that there were many other problems\n\n1:01:10.440 --> 1:01:14.640\n which seemed to have that universal structure.\n\n1:01:16.040 --> 1:01:20.040\n And so I began looking for reductions\n\n1:01:21.600 --> 1:01:26.080\n from the satisfiability to other problems.\n\n1:01:26.080 --> 1:01:31.080\n And one of the other problems\n\n1:01:31.760 --> 1:01:35.680\n would be the so called integer programming problem\n\n1:01:35.680 --> 1:01:40.280\n of determining whether there's a solution\n\n1:01:40.280 --> 1:01:45.280\n to a set of linear inequalities involving integer variables.\n\n1:01:48.200 --> 1:01:49.560\n Just like linear programming,\n\n1:01:49.560 --> 1:01:51.720\n but there's a constraint that the variables\n\n1:01:51.720 --> 1:01:53.640\n must remain integers.\n\n1:01:53.640 --> 1:01:56.400\n In fact, must be the zero or one\n\n1:01:56.400 --> 1:01:58.520\n could only take on those values.\n\n1:01:58.520 --> 1:02:00.800\n And that makes the problem much harder.\n\n1:02:00.800 --> 1:02:03.680\n Yes, that makes the problem much harder.\n\n1:02:03.680 --> 1:02:07.360\n And it was not difficult to show\n\n1:02:07.360 --> 1:02:11.640\n that the satisfiability problem can be restated\n\n1:02:11.640 --> 1:02:13.880\n as an integer programming problem.\n\n1:02:13.880 --> 1:02:15.200\n So can you pause on that?\n\n1:02:15.200 --> 1:02:19.080\n Was that one of the first mappings that you tried to do?\n\n1:02:19.080 --> 1:02:20.440\n And how hard is that mapping?\n\n1:02:20.440 --> 1:02:21.760\n You said it wasn't hard to show,\n\n1:02:21.760 --> 1:02:26.760\n but that's a big leap.\n\n1:02:27.440 --> 1:02:29.360\n It is a big leap, yeah.\n\n1:02:29.360 --> 1:02:32.960\n Well, let me give you another example.\n\n1:02:32.960 --> 1:02:35.160\n Another problem in NP\n\n1:02:35.160 --> 1:02:39.560\n is whether a graph contains a clique of a given size.\n\n1:02:42.960 --> 1:02:46.640\n And now the question is,\n\n1:02:47.960 --> 1:02:51.200\n can we reduce the propositional logic problem\n\n1:02:51.200 --> 1:02:55.480\n to the problem of whether there's a clique\n\n1:02:55.480 --> 1:02:56.680\n of a certain size?\n\n1:02:58.720 --> 1:03:01.280\n Well, if you look at the propositional logic problem,\n\n1:03:01.280 --> 1:03:05.560\n it can be expressed as a number of clauses,\n\n1:03:05.560 --> 1:03:08.200\n each of which is a,\n\n1:03:11.080 --> 1:03:15.360\n of the form A or B or C,\n\n1:03:15.360 --> 1:03:18.360\n where A is either one of the variables in the problem\n\n1:03:18.360 --> 1:03:22.600\n or the negation of one of the variables.\n\n1:03:22.600 --> 1:03:27.600\n And an instance of the propositional logic problem\n\n1:03:30.200 --> 1:03:35.200\n can be rewritten using operations of Boolean logic,\n\n1:03:37.000 --> 1:03:41.280\n can be rewritten as the conjunction of a set of clauses,\n\n1:03:41.280 --> 1:03:43.680\n the AND of a set of ORs,\n\n1:03:43.680 --> 1:03:48.680\n where each clause is a disjunction, an OR of variables\n\n1:03:49.600 --> 1:03:51.520\n or negated variables.\n\n1:03:53.880 --> 1:03:58.880\n So the question in the satisfiability problem\n\n1:04:01.200 --> 1:04:05.960\n is whether those clauses can be simultaneously satisfied.\n\n1:04:07.160 --> 1:04:09.080\n Now, to satisfy all those clauses,\n\n1:04:09.080 --> 1:04:13.920\n you have to find one of the terms in each clause,\n\n1:04:13.920 --> 1:04:18.920\n which is going to be true in your truth assignment,\n\n1:04:20.800 --> 1:04:24.680\n but you can't make the same variable both true and false.\n\n1:04:24.680 --> 1:04:29.600\n So if you have the variable A in one clause\n\n1:04:29.600 --> 1:04:34.240\n and you want to satisfy that clause by making A true,\n\n1:04:34.240 --> 1:04:38.360\n you can't also make the complement of A true\n\n1:04:38.360 --> 1:04:39.720\n in some other clause.\n\n1:04:39.720 --> 1:04:43.080\n And so the goal is to make every single clause true\n\n1:04:43.080 --> 1:04:45.200\n if it's possible to satisfy this,\n\n1:04:45.200 --> 1:04:47.920\n and the way you make it true is at least...\n\n1:04:48.840 --> 1:04:52.480\n One term in the clause must be true.\n\n1:04:52.480 --> 1:04:53.920\n Got it.\n\n1:04:53.920 --> 1:04:58.400\n So now we, to convert this problem\n\n1:04:58.400 --> 1:05:01.160\n to something called the independent set problem,\n\n1:05:01.160 --> 1:05:06.160\n where you're just sort of asking for a set of vertices\n\n1:05:06.160 --> 1:05:08.840\n in a graph such that no two of them are adjacent,\n\n1:05:08.840 --> 1:05:10.960\n sort of the opposite of the clique problem.\n\n1:05:14.920 --> 1:05:19.920\n So we've seen that we can now express that as\n\n1:05:24.760 --> 1:05:29.760\n finding a set of terms, one in each clause,\n\n1:05:29.760 --> 1:05:33.440\n without picking both the variable\n\n1:05:33.440 --> 1:05:36.200\n and the negation of that variable,\n\n1:05:36.200 --> 1:05:40.000\n because if the variable is assigned the truth value,\n\n1:05:40.000 --> 1:05:43.080\n the negated variable has to have the opposite truth value.\n\n1:05:44.080 --> 1:05:49.080\n And so we can construct a graph where the vertices\n\n1:05:49.400 --> 1:05:54.400\n are the terms in all of the clauses,\n\n1:05:54.400 --> 1:05:59.400\n and you have an edge between two terms\n\n1:06:07.720 --> 1:06:12.720\n if an edge between two occurrences of terms,\n\n1:06:14.480 --> 1:06:16.720\n either if they're both in the same clause,\n\n1:06:16.720 --> 1:06:20.320\n because you're only picking one element from each clause,\n\n1:06:20.320 --> 1:06:23.680\n and also an edge between them if they represent\n\n1:06:23.680 --> 1:06:26.160\n opposite values of the same variable,\n\n1:06:26.160 --> 1:06:29.560\n because you can't make a variable both true and false.\n\n1:06:29.560 --> 1:06:31.880\n And so you get a graph where you have\n\n1:06:31.880 --> 1:06:34.360\n all of these occurrences of variables,\n\n1:06:34.360 --> 1:06:37.840\n you have edges, which mean that you're not allowed\n\n1:06:37.840 --> 1:06:41.120\n to choose both ends of the edge,\n\n1:06:41.120 --> 1:06:43.160\n either because they're in the same clause\n\n1:06:43.160 --> 1:06:46.360\n or they're negations of one another.\n\n1:06:46.360 --> 1:06:50.520\n All right, and that's a, first of all, sort of to zoom out,\n\n1:06:50.520 --> 1:06:55.520\n that's a really powerful idea that you can take a graph\n\n1:06:55.240 --> 1:07:00.240\n and connect it to a logic equation somehow,\n\n1:07:00.240 --> 1:07:04.240\n and do that mapping for all possible formulations\n\n1:07:04.240 --> 1:07:06.440\n of a particular problem on a graph.\n\n1:07:06.440 --> 1:07:07.280\n Yeah.\n\n1:07:07.280 --> 1:07:12.280\n I mean, that still is hard for me to believe.\n\n1:07:12.280 --> 1:07:14.400\n Yeah, it's hard for me to believe.\n\n1:07:14.400 --> 1:07:17.800\n It's hard for me to believe that that's possible.\n\n1:07:17.800 --> 1:07:20.840\n That they're, like, what do you make of that,\n\n1:07:20.840 --> 1:07:24.840\n that there's such a union of,\n\n1:07:24.840 --> 1:07:28.800\n there's such a friendship among all these problems across\n\n1:07:28.800 --> 1:07:33.800\n that somehow are akin to combinatorial algorithms,\n\n1:07:33.880 --> 1:07:35.920\n that they're all somehow related?\n\n1:07:35.920 --> 1:07:39.960\n I know it can be proven, but what do you make of it,\n\n1:07:39.960 --> 1:07:41.720\n that that's true?\n\n1:07:41.720 --> 1:07:46.720\n Well, that they just have the same expressive power.\n\n1:07:46.800 --> 1:07:49.600\n You can take any one of them\n\n1:07:49.600 --> 1:07:53.520\n and translate it into the terms of the other.\n\n1:07:53.520 --> 1:07:55.600\n The fact that they have the same expressive power\n\n1:07:55.600 --> 1:07:59.040\n also somehow means that they can be translatable.\n\n1:07:59.040 --> 1:08:03.560\n Right, and what I did in the 1971 paper\n\n1:08:03.560 --> 1:08:08.560\n was to take 21 fundamental problems,\n\n1:08:08.560 --> 1:08:12.400\n the commonly occurring problems of packing,\n\n1:08:12.400 --> 1:08:14.440\n covering, matching, and so forth,\n\n1:08:15.920 --> 1:08:19.280\n lying in the class NP,\n\n1:08:19.280 --> 1:08:21.920\n and show that the satisfiability problem\n\n1:08:21.920 --> 1:08:24.320\n can be reexpressed as any of those,\n\n1:08:24.320 --> 1:08:28.960\n that any of those have the same expressive power.\n\n1:08:30.040 --> 1:08:32.000\n And that was like throwing down the gauntlet\n\n1:08:32.000 --> 1:08:35.920\n of saying there's probably many more problems like this.\n\n1:08:35.920 --> 1:08:36.760\n Right.\n\n1:08:36.760 --> 1:08:39.680\n Saying that, look, that they're all the same.\n\n1:08:39.680 --> 1:08:43.160\n They're all the same, but not exactly.\n\n1:08:43.160 --> 1:08:46.560\n They're all the same in terms of whether they are\n\n1:08:49.000 --> 1:08:51.640\n rich enough to express any of the others.\n\n1:08:53.760 --> 1:08:55.320\n But that doesn't mean that they have\n\n1:08:55.320 --> 1:08:57.800\n the same computational complexity.\n\n1:08:57.800 --> 1:09:02.280\n But what we can say is that either all of these problems\n\n1:09:02.280 --> 1:09:05.880\n or none of them are solvable in polynomial time.\n\n1:09:05.880 --> 1:09:08.360\n Yeah, so what is NP completeness\n\n1:09:08.360 --> 1:09:11.120\n and NP hard as classes?\n\n1:09:11.120 --> 1:09:14.080\n Oh, that's just a small technicality.\n\n1:09:14.080 --> 1:09:17.320\n So when we're talking about decision problems,\n\n1:09:17.320 --> 1:09:21.000\n that means that the answer is just yes or no.\n\n1:09:21.000 --> 1:09:23.360\n There is a clique of size 15\n\n1:09:23.360 --> 1:09:25.560\n or there's not a clique of size 15.\n\n1:09:26.800 --> 1:09:28.920\n On the other hand, an optimization problem\n\n1:09:28.920 --> 1:09:33.200\n would be asking find the largest clique.\n\n1:09:33.200 --> 1:09:35.040\n The answer would not be yes or no.\n\n1:09:35.040 --> 1:09:36.520\n It would be 15.\n\n1:09:39.600 --> 1:09:41.320\n So when you're asking for the,\n\n1:09:42.960 --> 1:09:46.680\n when you're putting a valuation on the different solutions\n\n1:09:46.680 --> 1:09:49.120\n and you're asking for the one with the highest valuation,\n\n1:09:49.120 --> 1:09:51.440\n that's an optimization problem.\n\n1:09:51.440 --> 1:09:52.920\n And there's a very close affinity\n\n1:09:52.920 --> 1:09:55.480\n between the two kinds of problems.\n\n1:09:55.480 --> 1:10:00.480\n But the counterpart of being the hardest decision problem,\n\n1:10:02.360 --> 1:10:04.280\n the hardest yes, no problem,\n\n1:10:04.280 --> 1:10:09.280\n the counterpart of that is to minimize\n\n1:10:09.920 --> 1:10:13.440\n or maximize an objective function.\n\n1:10:13.440 --> 1:10:16.440\n And so a problem that's hardest in the class\n\n1:10:17.400 --> 1:10:19.960\n when viewed in terms of optimization,\n\n1:10:19.960 --> 1:10:24.480\n those are called NP hard rather than NP complete.\n\n1:10:24.480 --> 1:10:26.280\n And NP complete is for decision problems.\n\n1:10:26.280 --> 1:10:28.740\n And NP complete is for decision problems.\n\n1:10:28.740 --> 1:10:33.740\n So if somebody shows that P equals NP,\n\n1:10:35.620 --> 1:10:39.460\n what do you think that proof will look like\n\n1:10:39.460 --> 1:10:41.540\n if you were to put on yourself,\n\n1:10:41.540 --> 1:10:45.340\n if it's possible to show that as a proof\n\n1:10:45.340 --> 1:10:47.340\n or to demonstrate an algorithm?\n\n1:10:49.100 --> 1:10:52.260\n All I can say is that it will involve concepts\n\n1:10:52.260 --> 1:10:56.420\n that we do not now have and approaches that we don't have.\n\n1:10:56.420 --> 1:10:58.620\n Do you think those concepts are out there\n\n1:10:58.620 --> 1:11:02.000\n in terms of inside complexity theory,\n\n1:11:02.000 --> 1:11:04.780\n inside of computational analysis of algorithms?\n\n1:11:04.780 --> 1:11:05.860\n Do you think there's concepts\n\n1:11:05.860 --> 1:11:07.940\n that are totally outside of the box\n\n1:11:07.940 --> 1:11:09.180\n that we haven't considered yet?\n\n1:11:09.180 --> 1:11:13.180\n I think that if there is a proof that P is equal to NP\n\n1:11:13.180 --> 1:11:15.080\n or that P is unequal to NP,\n\n1:11:17.820 --> 1:11:21.360\n it'll depend on concepts that are now outside the box.\n\n1:11:22.320 --> 1:11:25.940\n Now, if that's shown either way, P equals NP or P not,\n\n1:11:25.940 --> 1:11:28.260\n well, actually P equals NP,\n\n1:11:28.260 --> 1:11:32.260\n what impact, you kind of mentioned a little bit,\n\n1:11:32.260 --> 1:11:34.140\n but can you linger on it?\n\n1:11:34.140 --> 1:11:36.780\n What kind of impact would it have\n\n1:11:36.780 --> 1:11:38.340\n on theoretical computer science\n\n1:11:38.340 --> 1:11:42.220\n and perhaps software based systems in general?\n\n1:11:42.220 --> 1:11:46.260\n Well, I think it would have enormous impact on the world\n\n1:11:46.260 --> 1:11:49.180\n in either way case.\n\n1:11:49.180 --> 1:11:52.240\n If P is unequal to NP, which is what we expect,\n\n1:11:53.280 --> 1:11:56.860\n then we know that for the great majority\n\n1:11:56.860 --> 1:11:59.500\n of the combinatorial problems that come up,\n\n1:11:59.500 --> 1:12:02.940\n since they're known to be NP complete,\n\n1:12:02.940 --> 1:12:05.060\n we're not going to be able to solve them\n\n1:12:05.060 --> 1:12:07.780\n by efficient algorithms.\n\n1:12:07.780 --> 1:12:11.620\n However, there's a little bit of hope\n\n1:12:11.620 --> 1:12:16.560\n in that it may be that we can solve most instances.\n\n1:12:16.560 --> 1:12:19.860\n All we know is that if a problem is not NP,\n\n1:12:19.860 --> 1:12:22.920\n then it can't be solved efficiently on all instances.\n\n1:12:22.920 --> 1:12:27.920\n But basically, if we find that P is unequal to NP,\n\n1:12:32.720 --> 1:12:35.320\n it will mean that we can't expect always\n\n1:12:35.320 --> 1:12:38.680\n to get the optimal solutions to these problems.\n\n1:12:38.680 --> 1:12:41.040\n And we have to depend on heuristics\n\n1:12:41.040 --> 1:12:43.160\n that perhaps work most of the time\n\n1:12:43.160 --> 1:12:47.160\n or give us good approximate solutions, but not.\n\n1:12:47.160 --> 1:12:51.760\n So we would turn our eye towards the heuristics\n\n1:12:51.760 --> 1:12:56.400\n with a little bit more acceptance and comfort on our hearts.\n\n1:12:56.400 --> 1:12:57.560\n Exactly.\n\n1:12:57.560 --> 1:13:01.060\n Okay, so let me ask a romanticized question.\n\n1:13:02.100 --> 1:13:04.480\n What to you is one of the most\n\n1:13:04.480 --> 1:13:08.180\n or the most beautiful combinatorial algorithm\n\n1:13:08.180 --> 1:13:10.880\n in your own life or just in general in the field\n\n1:13:10.880 --> 1:13:14.080\n that you've ever come across or have developed yourself?\n\n1:13:14.080 --> 1:13:17.760\n Oh, I like the stable matching problem\n\n1:13:17.760 --> 1:13:22.760\n or the stable marriage problem very much.\n\n1:13:22.760 --> 1:13:25.120\n What's the stable matching problem?\n\n1:13:25.120 --> 1:13:26.400\n Yeah.\n\n1:13:26.400 --> 1:13:31.400\n Imagine that you want to marry off N boys with N girls.\n\n1:13:37.120 --> 1:13:39.900\n And each boy has an ordered list\n\n1:13:39.900 --> 1:13:42.320\n of his preferences among the girls.\n\n1:13:42.320 --> 1:13:44.760\n His first choice, his second choice,\n\n1:13:44.760 --> 1:13:46.200\n through her, Nth choice.\n\n1:13:47.400 --> 1:13:52.400\n And each girl also has an ordering of the boys,\n\n1:13:55.400 --> 1:13:57.560\n his first choice, second choice, and so on.\n\n1:13:58.880 --> 1:14:03.480\n And we'll say that a matching,\n\n1:14:03.480 --> 1:14:07.560\n a one to one matching of the boys with the girls is stable\n\n1:14:07.560 --> 1:14:12.560\n if there are no two couples in the matching\n\n1:14:15.120 --> 1:14:18.640\n such that the boy in the first couple\n\n1:14:18.640 --> 1:14:23.200\n prefers the girl in the second couple to her mate\n\n1:14:23.200 --> 1:14:27.040\n and she prefers the boy to her current mate.\n\n1:14:27.040 --> 1:14:31.280\n In other words, if the matching is stable\n\n1:14:31.280 --> 1:14:35.440\n if there is no pair who want to run away with each other\n\n1:14:35.440 --> 1:14:37.800\n leaving their partners behind.\n\n1:14:38.760 --> 1:14:39.600\n Gosh, yeah.\n\n1:14:39.600 --> 1:14:40.440\n Yeah.\n\n1:14:44.920 --> 1:14:49.100\n Actually, this is relevant to matching residents\n\n1:14:49.100 --> 1:14:52.280\n with hospitals and some other real life problems,\n\n1:14:52.280 --> 1:14:55.560\n although not quite in the form that I described.\n\n1:14:56.960 --> 1:15:00.480\n So it turns out that there is,\n\n1:15:00.480 --> 1:15:05.480\n for any set of preferences, a stable matching exists.\n\n1:15:06.000 --> 1:15:11.000\n And moreover, it can be computed\n\n1:15:11.000 --> 1:15:14.040\n by a simple algorithm\n\n1:15:14.040 --> 1:15:19.040\n in which each boy starts making proposals to girls.\n\n1:15:21.000 --> 1:15:23.940\n And if the girl receives the proposal,\n\n1:15:23.940 --> 1:15:25.920\n she accepts it tentatively,\n\n1:15:25.920 --> 1:15:30.920\n but she can drop it later\n\n1:15:32.800 --> 1:15:35.740\n if she gets a better proposal from her point of view.\n\n1:15:36.720 --> 1:15:39.000\n And the boys start going down their lists\n\n1:15:39.000 --> 1:15:41.980\n proposing to their first, second, third choices\n\n1:15:41.980 --> 1:15:46.980\n until stopping when a proposal is accepted.\n\n1:15:50.400 --> 1:15:53.360\n But the girls meanwhile are watching the proposals\n\n1:15:53.360 --> 1:15:55.380\n that are coming into them.\n\n1:15:55.380 --> 1:15:58.640\n And the girl will drop her current partner\n\n1:16:01.080 --> 1:16:03.520\n if she gets a better proposal.\n\n1:16:03.520 --> 1:16:06.280\n And the boys never go back through the list?\n\n1:16:06.280 --> 1:16:07.600\n They never go back, yeah.\n\n1:16:07.600 --> 1:16:09.720\n So once they've been denied.\n\n1:16:11.720 --> 1:16:12.800\n They don't try again.\n\n1:16:12.800 --> 1:16:14.640\n They don't try again\n\n1:16:14.640 --> 1:16:19.240\n because the girls are always improving their status\n\n1:16:19.240 --> 1:16:22.800\n as they receive better and better proposals.\n\n1:16:22.800 --> 1:16:25.560\n The boys are going down their lists starting\n\n1:16:25.560 --> 1:16:28.600\n with their top preferences.\n\n1:16:28.600 --> 1:16:33.600\n And one can prove that the process will come to an end\n\n1:16:39.540 --> 1:16:43.440\n where everybody will get matched with somebody\n\n1:16:43.440 --> 1:16:46.520\n and you won't have any pair\n\n1:16:46.520 --> 1:16:50.360\n that want to abscond from each other.\n\n1:16:50.360 --> 1:16:54.120\n Do you find the proof or the algorithm itself beautiful?\n\n1:16:54.120 --> 1:16:56.720\n Or is it the fact that with the simplicity\n\n1:16:56.720 --> 1:16:59.560\n of just the two marching,\n\n1:16:59.560 --> 1:17:01.760\n I mean the simplicity of the underlying rule\n\n1:17:01.760 --> 1:17:04.820\n of the algorithm, is that the beautiful part?\n\n1:17:04.820 --> 1:17:06.280\n Both I would say.\n\n1:17:07.560 --> 1:17:11.760\n And you also have the observation that you might ask\n\n1:17:11.760 --> 1:17:14.680\n who is better off, the boys who are doing the proposing\n\n1:17:14.680 --> 1:17:17.760\n or the girls who are reacting to proposals.\n\n1:17:17.760 --> 1:17:20.080\n And it turns out that it's the boys\n\n1:17:20.080 --> 1:17:22.920\n who are doing the best.\n\n1:17:22.920 --> 1:17:25.840\n That is, each boy is doing at least as well\n\n1:17:25.840 --> 1:17:30.480\n as he could do in any other staple matching.\n\n1:17:30.480 --> 1:17:33.180\n So there's a sort of lesson for the boys\n\n1:17:33.180 --> 1:17:36.080\n that you should go out and be proactive\n\n1:17:36.080 --> 1:17:38.680\n and make those proposals.\n\n1:17:38.680 --> 1:17:39.680\n Go for broke.\n\n1:17:41.160 --> 1:17:44.280\n I don't know if this is directly mappable philosophically\n\n1:17:44.280 --> 1:17:46.800\n to our society, but certainly seems\n\n1:17:46.800 --> 1:17:48.160\n like a compelling notion.\n\n1:17:48.160 --> 1:17:51.360\n And like you said, there's probably a lot\n\n1:17:51.360 --> 1:17:54.600\n of actual real world problems that this could be mapped to.\n\n1:17:54.600 --> 1:17:58.600\n Yeah, well you get complications.\n\n1:17:58.600 --> 1:18:01.500\n For example, what happens when a husband and wife\n\n1:18:01.500 --> 1:18:03.720\n want to be assigned to the same hospital?\n\n1:18:03.720 --> 1:18:08.720\n So you have to take those constraints into account.\n\n1:18:10.520 --> 1:18:13.120\n And then the problem becomes NP hard.\n\n1:18:15.920 --> 1:18:18.040\n Why is it a problem for the husband and wife\n\n1:18:18.040 --> 1:18:20.000\n to be assigned to the same hospital?\n\n1:18:20.000 --> 1:18:22.480\n No, it's desirable.\n\n1:18:22.480 --> 1:18:24.080\n Or at least go to the same city.\n\n1:18:24.080 --> 1:18:29.080\n So you can't, if you're assigning residents to hospitals.\n\n1:18:29.560 --> 1:18:32.080\n And then you have some preferences\n\n1:18:32.080 --> 1:18:34.600\n for the husband and the wife or for the hospitals.\n\n1:18:34.600 --> 1:18:37.080\n The residents have their own preferences.\n\n1:18:39.920 --> 1:18:43.200\n Residents both male and female have their own preferences.\n\n1:18:44.760 --> 1:18:47.720\n The hospitals have their preferences.\n\n1:18:47.720 --> 1:18:52.720\n But if resident A, the boy, is going to Philadelphia,\n\n1:18:55.960 --> 1:19:00.960\n then you'd like his wife also to be assigned\n\n1:19:01.720 --> 1:19:04.440\n to a hospital in Philadelphia.\n\n1:19:04.440 --> 1:19:08.000\n Which step makes it a NP hard problem that you mentioned?\n\n1:19:08.000 --> 1:19:11.120\n The fact that you have this additional constraint.\n\n1:19:11.120 --> 1:19:15.000\n That it's not just the preferences of individuals,\n\n1:19:15.000 --> 1:19:19.840\n but the fact that the two partners to a marriage\n\n1:19:19.840 --> 1:19:22.880\n have to be assigned to the same place.\n\n1:19:22.880 --> 1:19:24.420\n I'm being a little dense.\n\n1:19:29.320 --> 1:19:31.600\n The perfect matching, no, not the perfect,\n\n1:19:31.600 --> 1:19:33.880\n stable matching is what you referred to.\n\n1:19:33.880 --> 1:19:36.160\n That's when two partners are trying to.\n\n1:19:36.160 --> 1:19:39.280\n Okay, what's confusing you is that in the first\n\n1:19:39.280 --> 1:19:40.740\n interpretation of the problem,\n\n1:19:40.740 --> 1:19:42.900\n I had boys matching with girls.\n\n1:19:42.900 --> 1:19:44.220\n Yes.\n\n1:19:44.220 --> 1:19:46.540\n In the second interpretation,\n\n1:19:46.540 --> 1:19:49.660\n you have humans matching with institutions.\n\n1:19:49.660 --> 1:19:51.100\n With institutions.\n\n1:19:51.100 --> 1:19:54.380\n I, and there's a coupling between within the,\n\n1:19:54.380 --> 1:19:56.020\n gotcha, within the humans.\n\n1:19:56.020 --> 1:19:56.860\n Yeah.\n\n1:19:56.860 --> 1:20:00.420\n Any added little constraint will make it an NP hard problem.\n\n1:20:00.420 --> 1:20:01.560\n Well, yeah.\n\n1:20:03.440 --> 1:20:05.060\n Okay.\n\n1:20:05.060 --> 1:20:06.220\n By the way, the algorithm you mentioned\n\n1:20:06.220 --> 1:20:07.860\n wasn't one of yours or no?\n\n1:20:07.860 --> 1:20:11.420\n No, no, that was due to Gale and Shapley\n\n1:20:11.420 --> 1:20:15.500\n and my friend David Gale passed away\n\n1:20:15.500 --> 1:20:18.060\n before he could get part of a Nobel Prize,\n\n1:20:18.060 --> 1:20:22.780\n but his partner Shapley shared in a Nobel Prize\n\n1:20:22.780 --> 1:20:24.340\n with somebody else for.\n\n1:20:24.340 --> 1:20:25.180\n Economics?\n\n1:20:25.180 --> 1:20:27.220\n For economics.\n\n1:20:28.460 --> 1:20:31.560\n For ideas stemming from the stable matching idea.\n\n1:20:32.580 --> 1:20:35.220\n So you've also have developed yourself\n\n1:20:35.220 --> 1:20:37.340\n some elegant, beautiful algorithms.\n\n1:20:38.260 --> 1:20:39.720\n Again, picking your children,\n\n1:20:39.720 --> 1:20:43.380\n so the Robin Karp algorithm for string searching,\n\n1:20:43.380 --> 1:20:46.220\n pattern matching, Edmund Karp algorithm for max flows\n\n1:20:46.220 --> 1:20:49.060\n we mentioned, Hopcroft Karp algorithm for finding\n\n1:20:49.060 --> 1:20:52.180\n maximum cardinality matchings in bipartite graphs.\n\n1:20:52.180 --> 1:20:55.460\n Is there ones that stand out to you,\n\n1:20:55.460 --> 1:20:58.260\n ones you're most proud of or just\n\n1:20:59.460 --> 1:21:01.740\n whether it's beauty, elegance,\n\n1:21:01.740 --> 1:21:06.420\n or just being the right discovery development\n\n1:21:06.420 --> 1:21:10.100\n in your life that you're especially proud of?\n\n1:21:10.100 --> 1:21:12.180\n I like the Rabin Karp algorithm\n\n1:21:12.180 --> 1:21:15.520\n because it illustrates the power of randomization.\n\n1:21:17.540 --> 1:21:22.540\n So the problem there\n\n1:21:23.100 --> 1:21:28.100\n is to decide whether a given long string of symbols\n\n1:21:28.100 --> 1:21:33.100\n is to decide whether a given long string of symbols\n\n1:21:34.340 --> 1:21:38.260\n from some alphabet contains a given word,\n\n1:21:39.260 --> 1:21:41.500\n whether a particular word occurs\n\n1:21:41.500 --> 1:21:43.940\n within some very much longer word.\n\n1:21:45.500 --> 1:21:49.500\n And so the idea of the algorithm\n\n1:21:52.340 --> 1:21:57.220\n is to associate with the word that we're looking for,\n\n1:21:57.220 --> 1:22:02.220\n a fingerprint, some number,\n\n1:22:02.820 --> 1:22:07.340\n or some combinatorial object that describes that word,\n\n1:22:10.380 --> 1:22:13.580\n and then to look for an occurrence of that same fingerprint\n\n1:22:13.580 --> 1:22:15.700\n as you slide along the longer word.\n\n1:22:18.540 --> 1:22:23.540\n And what we do is we associate with each word a number.\n\n1:22:23.540 --> 1:22:26.540\n So first of all, we think of the letters\n\n1:22:26.540 --> 1:22:30.980\n that occur in a word as the digits of, let's say,\n\n1:22:30.980 --> 1:22:34.980\n decimal or whatever base here,\n\n1:22:36.780 --> 1:22:40.020\n whatever number of different symbols there are.\n\n1:22:40.020 --> 1:22:42.340\n That's the base of the numbers, yeah.\n\n1:22:42.340 --> 1:22:46.140\n Right, so every word can then be thought of as a number\n\n1:22:46.140 --> 1:22:50.340\n with the letters being the digits of that number.\n\n1:22:50.340 --> 1:22:55.340\n And then we pick a random prime number in a certain range,\n\n1:22:55.540 --> 1:23:00.060\n and we take that word viewed as a number,\n\n1:23:00.060 --> 1:23:05.060\n and take the remainder on dividing that number by the prime.\n\n1:23:09.580 --> 1:23:11.820\n So coming up with a nice hash function.\n\n1:23:11.820 --> 1:23:13.660\n It's a kind of hash function.\n\n1:23:13.660 --> 1:23:17.700\n Yeah, it gives you a little shortcut\n\n1:23:17.700 --> 1:23:22.500\n for that particular word.\n\n1:23:22.500 --> 1:23:26.380\n Yeah, so that's the...\n\n1:23:26.380 --> 1:23:31.060\n It's very different than other algorithms of its kind\n\n1:23:31.060 --> 1:23:35.540\n that we're trying to do search, string matching.\n\n1:23:35.540 --> 1:23:38.060\n Yeah, which usually are combinatorial\n\n1:23:38.060 --> 1:23:42.620\n and don't involve the idea of taking a random fingerprint.\n\n1:23:42.620 --> 1:23:43.580\n Yes.\n\n1:23:43.580 --> 1:23:48.020\n And doing the fingerprinting has two advantages.\n\n1:23:48.020 --> 1:23:51.580\n One is that as we slide along the long word,\n\n1:23:51.580 --> 1:23:56.580\n digit by digit, we keep a window of a certain size,\n\n1:23:57.460 --> 1:24:00.660\n the size of the word we're looking for,\n\n1:24:00.660 --> 1:24:03.380\n and we compute the fingerprint\n\n1:24:03.380 --> 1:24:07.620\n of every stretch of that length.\n\n1:24:07.620 --> 1:24:11.260\n And it turns out that just a couple of arithmetic operations\n\n1:24:11.260 --> 1:24:15.300\n will take you from the fingerprint of one part\n\n1:24:15.300 --> 1:24:18.740\n to what you get when you slide over by one position.\n\n1:24:19.860 --> 1:24:24.380\n So the computation of all the fingerprints is simple.\n\n1:24:26.740 --> 1:24:31.740\n And secondly, it's unlikely if the prime is chosen randomly\n\n1:24:32.780 --> 1:24:37.500\n from a certain range that you will get two of the segments\n\n1:24:37.500 --> 1:24:39.980\n in question having the same fingerprint.\n\n1:24:39.980 --> 1:24:41.660\n Right.\n\n1:24:41.660 --> 1:24:43.940\n And so there's a small probability of error\n\n1:24:43.940 --> 1:24:46.460\n which can be checked after the fact,\n\n1:24:46.460 --> 1:24:48.700\n and also the ease of doing the computation\n\n1:24:48.700 --> 1:24:51.580\n because you're working with these fingerprints\n\n1:24:51.580 --> 1:24:54.620\n which are remainder's modulo some big prime.\n\n1:24:55.620 --> 1:24:58.020\n So that's the magical thing about randomized algorithms\n\n1:24:58.020 --> 1:25:02.420\n is that if you add a little bit of randomness,\n\n1:25:02.420 --> 1:25:05.380\n it somehow allows you to take a pretty naive approach,\n\n1:25:05.380 --> 1:25:10.380\n a simple looking approach, and allow it to run extremely well.\n\n1:25:10.660 --> 1:25:14.340\n So can you maybe take a step back and say\n\n1:25:14.340 --> 1:25:18.300\n what is a randomized algorithm, this category of algorithms?\n\n1:25:18.300 --> 1:25:22.460\n Well, it's just the ability to draw a random number\n\n1:25:22.460 --> 1:25:27.460\n from such, from some range\n\n1:25:27.580 --> 1:25:32.260\n or to associate a random number with some object\n\n1:25:32.260 --> 1:25:35.220\n or to draw that random from some set.\n\n1:25:35.220 --> 1:25:40.220\n So another example is very simple\n\n1:25:41.940 --> 1:25:45.340\n if we're conducting a presidential election\n\n1:25:46.420 --> 1:25:50.380\n and we would like to pick the winner.\n\n1:25:52.300 --> 1:25:57.300\n In principle, we could draw a random sample\n\n1:25:57.300 --> 1:25:59.300\n of all of the voters in the country.\n\n1:25:59.300 --> 1:26:04.300\n And if it was of substantial size, say a few thousand,\n\n1:26:05.700 --> 1:26:08.940\n then the most popular candidate in that group\n\n1:26:08.940 --> 1:26:12.280\n would be very likely to be the correct choice\n\n1:26:12.280 --> 1:26:15.820\n that would come out of counting all the millions of votes.\n\n1:26:15.820 --> 1:26:18.460\n And of course we can't do this because first of all,\n\n1:26:18.460 --> 1:26:21.900\n everybody has to feel that his or her vote counted.\n\n1:26:21.900 --> 1:26:25.300\n And secondly, we can't really do a purely random sample\n\n1:26:25.300 --> 1:26:28.000\n from that population.\n\n1:26:28.000 --> 1:26:30.060\n And I guess thirdly, there could be a tie\n\n1:26:30.060 --> 1:26:34.100\n in which case we wouldn't have a significant difference\n\n1:26:34.100 --> 1:26:36.380\n between two candidates.\n\n1:26:36.380 --> 1:26:37.580\n But those things aside,\n\n1:26:37.580 --> 1:26:40.500\n if you didn't have all that messiness of human beings,\n\n1:26:40.500 --> 1:26:43.100\n you could prove that that kind of random picking\n\n1:26:43.100 --> 1:26:43.940\n would come up again.\n\n1:26:43.940 --> 1:26:48.020\n You just said random picking would solve the problem\n\n1:26:48.020 --> 1:26:51.380\n with a very low probability of error.\n\n1:26:51.380 --> 1:26:55.540\n Another example is testing whether a number is prime.\n\n1:26:55.540 --> 1:27:00.300\n So if I wanna test whether 17 is prime,\n\n1:27:01.760 --> 1:27:06.760\n I could pick any number between one and 17,\n\n1:27:08.460 --> 1:27:12.340\n raise it to the 16th power modulo 17,\n\n1:27:12.340 --> 1:27:15.060\n and you should get back the original number.\n\n1:27:15.060 --> 1:27:19.620\n That's a famous formula due to Fermat about,\n\n1:27:19.620 --> 1:27:21.240\n it's called Fermat's Little Theorem,\n\n1:27:21.240 --> 1:27:26.240\n that if you take any number a in the range\n\n1:27:29.340 --> 1:27:31.080\n zero through n minus one,\n\n1:27:32.060 --> 1:27:37.060\n and raise it to the n minus 1th power modulo n,\n\n1:27:38.260 --> 1:27:43.260\n you'll get back the number a if a is prime.\n\n1:27:43.860 --> 1:27:45.900\n So if you don't get back the number a,\n\n1:27:45.900 --> 1:27:48.300\n that's a proof that a number is not prime.\n\n1:27:48.300 --> 1:27:53.300\n And you can show that suitably defined\n\n1:27:57.420 --> 1:28:02.420\n the probability that you will get a value unequaled,\n\n1:28:09.300 --> 1:28:14.300\n you will get a violation of Fermat's result is very high.\n\n1:28:14.300 --> 1:28:18.580\n And so this gives you a way of rapidly proving\n\n1:28:18.580 --> 1:28:20.020\n that a number is not prime.\n\n1:28:21.020 --> 1:28:22.800\n It's a little more complicated than that\n\n1:28:22.800 --> 1:28:26.300\n because there are certain values of n\n\n1:28:26.300 --> 1:28:28.600\n where something a little more elaborate has to be done,\n\n1:28:28.600 --> 1:28:30.180\n but that's the basic idea.\n\n1:28:32.580 --> 1:28:34.900\n Taking an identity that holds for primes,\n\n1:28:34.900 --> 1:28:39.460\n and therefore, if it ever fails on any instance\n\n1:28:39.460 --> 1:28:43.460\n for a non prime, you know that the number is not prime.\n\n1:28:43.460 --> 1:28:45.660\n It's a quick choice, a fast choice,\n\n1:28:45.660 --> 1:28:47.740\n fast proof that a number is not prime.\n\n1:28:48.740 --> 1:28:50.940\n Can you maybe elaborate a little bit more\n\n1:28:50.940 --> 1:28:54.200\n what's your intuition why randomness works so well\n\n1:28:54.200 --> 1:28:56.460\n and results in such simple algorithms?\n\n1:28:57.500 --> 1:29:00.860\n Well, the example of conducting an election\n\n1:29:00.860 --> 1:29:04.340\n where you could take, in theory, you could take a sample\n\n1:29:04.340 --> 1:29:07.060\n and depend on the validity of the sample\n\n1:29:07.060 --> 1:29:09.180\n to really represent the whole\n\n1:29:09.180 --> 1:29:12.040\n is just the basic fact of statistics,\n\n1:29:12.040 --> 1:29:14.860\n which gives a lot of opportunities.\n\n1:29:17.780 --> 1:29:22.780\n And I actually exploited that sort of random sampling idea\n\n1:29:23.180 --> 1:29:25.780\n in designing an algorithm\n\n1:29:25.780 --> 1:29:30.100\n for counting the number of solutions\n\n1:29:30.100 --> 1:29:33.820\n that satisfy a particular formula\n\n1:29:33.820 --> 1:29:37.640\n and propositional logic.\n\n1:29:37.640 --> 1:29:42.640\n A particular, so some version of the satisfiability problem?\n\n1:29:44.380 --> 1:29:46.660\n A version of the satisfiability problem.\n\n1:29:47.780 --> 1:29:49.420\n Is there some interesting insight\n\n1:29:49.420 --> 1:29:50.460\n that you wanna elaborate on,\n\n1:29:50.460 --> 1:29:53.300\n like what some aspect of that algorithm\n\n1:29:53.300 --> 1:29:57.500\n that might be useful to describe?\n\n1:29:57.500 --> 1:30:02.500\n So you have a collection of formulas\n\n1:30:02.500 --> 1:30:07.500\n and you want to count the number of solutions\n\n1:30:14.400 --> 1:30:18.960\n that satisfy at least one of the formulas.\n\n1:30:20.440 --> 1:30:23.500\n And you can count the number of solutions\n\n1:30:23.500 --> 1:30:27.360\n that satisfy any particular one of the formulas,\n\n1:30:27.360 --> 1:30:29.960\n but you have to account for the fact\n\n1:30:29.960 --> 1:30:33.720\n that that solution might be counted many times\n\n1:30:33.720 --> 1:30:38.500\n if it solves more than one of the formulas.\n\n1:30:40.880 --> 1:30:45.880\n And so what you do is you sample from the formulas\n\n1:30:46.880 --> 1:30:49.480\n according to the number of solutions\n\n1:30:49.480 --> 1:30:52.340\n that satisfy each individual one.\n\n1:30:53.220 --> 1:30:55.680\n In that way, you draw a random solution,\n\n1:30:55.680 --> 1:30:59.040\n but then you correct by looking at\n\n1:30:59.040 --> 1:31:02.360\n the number of formulas that satisfy that random solution\n\n1:31:04.480 --> 1:31:07.680\n and don't double count.\n\n1:31:08.880 --> 1:31:11.640\n So you can think of it this way.\n\n1:31:11.640 --> 1:31:15.120\n So you have a matrix of zeros and ones\n\n1:31:16.040 --> 1:31:18.980\n and you wanna know how many columns of that matrix\n\n1:31:18.980 --> 1:31:20.660\n contain at least one one.\n\n1:31:22.400 --> 1:31:26.040\n And you can count in each row how many ones there are.\n\n1:31:26.040 --> 1:31:29.440\n So what you can do is draw from the rows\n\n1:31:29.440 --> 1:31:31.700\n according to the number of ones.\n\n1:31:31.700 --> 1:31:34.880\n If a row has more ones, it gets drawn more frequently.\n\n1:31:35.980 --> 1:31:39.880\n But then if you draw from that row,\n\n1:31:39.880 --> 1:31:41.480\n you have to go up the column\n\n1:31:41.480 --> 1:31:44.620\n and looking at where that same one is repeated\n\n1:31:44.620 --> 1:31:49.620\n in different rows and only count it as a success or a hit\n\n1:31:51.240 --> 1:31:54.380\n if it's the earliest row that contains the one.\n\n1:31:54.380 --> 1:31:59.380\n And that gives you a robust statistical estimate\n\n1:32:00.300 --> 1:32:02.020\n of the total number of columns\n\n1:32:02.020 --> 1:32:04.540\n that contain at least one of the ones.\n\n1:32:04.540 --> 1:32:09.020\n So that is an example of the same principle\n\n1:32:09.020 --> 1:32:13.380\n that was used in studying random sampling.\n\n1:32:13.380 --> 1:32:18.380\n Another viewpoint is that if you have a phenomenon\n\n1:32:18.940 --> 1:32:21.400\n that occurs almost all the time,\n\n1:32:21.400 --> 1:32:26.400\n then if you sample one of the occasions where it occurs,\n\n1:32:28.780 --> 1:32:30.640\n you're most likely to,\n\n1:32:30.640 --> 1:32:32.640\n and you're looking for an occurrence,\n\n1:32:32.640 --> 1:32:34.880\n a random occurrence is likely to work.\n\n1:32:34.880 --> 1:32:39.480\n So that comes up in solving identities,\n\n1:32:39.480 --> 1:32:42.680\n solving algebraic identities.\n\n1:32:42.680 --> 1:32:46.480\n You get two formulas that may look very different.\n\n1:32:46.480 --> 1:32:49.000\n You wanna know if they're really identical.\n\n1:32:49.000 --> 1:32:52.920\n What you can do is just pick a random value\n\n1:32:52.920 --> 1:32:56.040\n and evaluate the formulas at that value\n\n1:32:56.040 --> 1:32:58.840\n and see if they agree.\n\n1:32:58.840 --> 1:33:02.000\n And you depend on the fact\n\n1:33:02.000 --> 1:33:04.360\n that if the formulas are distinct,\n\n1:33:04.360 --> 1:33:06.840\n then they're gonna disagree a lot.\n\n1:33:06.840 --> 1:33:08.480\n And so therefore, a random choice\n\n1:33:08.480 --> 1:33:10.640\n will exhibit the disagreement.\n\n1:33:12.760 --> 1:33:15.160\n If there are many ways for the two to disagree\n\n1:33:16.560 --> 1:33:18.560\n and you only need to find one disagreement,\n\n1:33:18.560 --> 1:33:22.600\n then random choice is likely to yield it.\n\n1:33:22.600 --> 1:33:24.560\n And in general, so we've just talked\n\n1:33:24.560 --> 1:33:26.000\n about randomized algorithms,\n\n1:33:26.000 --> 1:33:29.680\n but we can look at the probabilistic analysis of algorithms.\n\n1:33:29.680 --> 1:33:32.040\n And that gives us an opportunity to step back\n\n1:33:32.040 --> 1:33:35.600\n and as you said, everything we've been talking about\n\n1:33:35.600 --> 1:33:38.000\n is worst case analysis.\n\n1:33:38.000 --> 1:33:43.000\n Could you maybe comment on the usefulness\n\n1:33:43.480 --> 1:33:45.400\n and the power of worst case analysis\n\n1:33:45.400 --> 1:33:50.400\n versus best case analysis, average case, probabilistic?\n\n1:33:51.160 --> 1:33:52.760\n How do we think about the future\n\n1:33:52.760 --> 1:33:55.360\n of theoretical computer science, computer science\n\n1:33:56.600 --> 1:33:59.080\n in the kind of analysis we do of algorithms?\n\n1:33:59.080 --> 1:34:01.600\n Does worst case analysis still have a place,\n\n1:34:01.600 --> 1:34:02.760\n an important place?\n\n1:34:02.760 --> 1:34:04.600\n Or do we want to try to move forward\n\n1:34:04.600 --> 1:34:07.240\n towards kind of average case analysis?\n\n1:34:07.240 --> 1:34:09.320\n And what are the challenges there?\n\n1:34:09.320 --> 1:34:11.560\n So if worst case analysis shows\n\n1:34:11.560 --> 1:34:15.280\n that an algorithm is always good,\n\n1:34:15.280 --> 1:34:16.120\n that's fine.\n\n1:34:17.240 --> 1:34:22.240\n If worst case analysis is used to show that the problem,\n\n1:34:25.520 --> 1:34:29.000\n that the solution is not always good,\n\n1:34:29.000 --> 1:34:32.120\n then you have to step back and do something else\n\n1:34:32.120 --> 1:34:34.960\n to ask how often will you get a good solution?\n\n1:34:36.280 --> 1:34:38.040\n Just to pause on that for a second,\n\n1:34:38.040 --> 1:34:40.160\n that's so beautifully put\n\n1:34:40.160 --> 1:34:43.280\n because I think we tend to judge algorithms.\n\n1:34:43.280 --> 1:34:45.440\n We throw them in the trash\n\n1:34:45.440 --> 1:34:48.240\n the moment their worst case is shown to be bad.\n\n1:34:48.240 --> 1:34:50.680\n Right, and that's unfortunate.\n\n1:34:50.680 --> 1:34:55.680\n I think a good example is going back\n\n1:34:56.880 --> 1:34:58.840\n to the satisfiability problem.\n\n1:35:00.120 --> 1:35:03.560\n There are very powerful programs called SAT solvers\n\n1:35:04.480 --> 1:35:09.480\n which in practice fairly reliably solve instances\n\n1:35:09.920 --> 1:35:11.760\n with many millions of variables\n\n1:35:11.760 --> 1:35:14.200\n that arise in digital design\n\n1:35:14.200 --> 1:35:17.800\n or in proving programs correct in other applications.\n\n1:35:20.200 --> 1:35:24.480\n And so in many application areas,\n\n1:35:24.480 --> 1:35:27.760\n even though satisfiability as we've already discussed\n\n1:35:27.760 --> 1:35:32.760\n is NP complete, the SAT solvers will work so well\n\n1:35:34.840 --> 1:35:37.240\n that the people in that discipline\n\n1:35:37.240 --> 1:35:40.040\n tend to think of satisfiability as an easy problem.\n\n1:35:40.040 --> 1:35:45.040\n So in other words, just for some reason\n\n1:35:45.160 --> 1:35:47.640\n that we don't entirely understand,\n\n1:35:47.640 --> 1:35:50.480\n the instances that people formulate\n\n1:35:50.480 --> 1:35:54.320\n in designing digital circuits or other applications\n\n1:35:54.320 --> 1:35:59.320\n are such that satisfiability is not hard to check\n\n1:36:04.440 --> 1:36:07.320\n and even searching for a satisfying solution\n\n1:36:07.320 --> 1:36:10.240\n can be done efficiently in practice.\n\n1:36:11.520 --> 1:36:13.200\n And there are many examples.\n\n1:36:13.200 --> 1:36:17.240\n For example, we talked about the traveling salesman problem.\n\n1:36:18.160 --> 1:36:21.320\n So just to refresh our memories,\n\n1:36:21.320 --> 1:36:23.440\n the problem is you've got a set of cities,\n\n1:36:23.440 --> 1:36:26.840\n you have pairwise distances between cities\n\n1:36:28.560 --> 1:36:31.320\n and you want to find a tour through all the cities\n\n1:36:31.320 --> 1:36:36.320\n that minimizes the total cost of all the edges traversed,\n\n1:36:36.320 --> 1:36:38.800\n all the trips between cities.\n\n1:36:38.800 --> 1:36:41.840\n The problem is NP hard,\n\n1:36:41.840 --> 1:36:46.840\n but people using integer programming codes\n\n1:36:46.960 --> 1:36:50.280\n together with some other mathematical tricks\n\n1:36:51.400 --> 1:36:56.400\n can solve geometric instances of the problem\n\n1:36:57.080 --> 1:36:59.640\n where the cities are, let's say points in the plane\n\n1:37:01.000 --> 1:37:03.120\n and get optimal solutions to problems\n\n1:37:03.120 --> 1:37:05.120\n with tens of thousands of cities.\n\n1:37:05.120 --> 1:37:08.240\n Actually, it'll take a few computer months\n\n1:37:08.240 --> 1:37:10.280\n to solve a problem of that size,\n\n1:37:10.280 --> 1:37:13.200\n but for problems of size a thousand or two,\n\n1:37:13.200 --> 1:37:16.320\n it'll rapidly get optimal solutions,\n\n1:37:16.320 --> 1:37:19.000\n provably optimal solutions,\n\n1:37:19.000 --> 1:37:23.000\n even though again, we know that it's unlikely\n\n1:37:23.000 --> 1:37:25.760\n that the traveling salesman problem\n\n1:37:25.760 --> 1:37:28.440\n can be solved in polynomial time.\n\n1:37:28.440 --> 1:37:33.440\n Are there methodologies like rigorous systematic methodologies\n\n1:37:33.440 --> 1:37:38.320\n for, you said in practice.\n\n1:37:38.320 --> 1:37:40.040\n In practice, this algorithm's pretty good.\n\n1:37:40.040 --> 1:37:42.160\n Are there systematic ways of saying\n\n1:37:42.160 --> 1:37:43.800\n in practice, this algorithm's pretty good?\n\n1:37:43.800 --> 1:37:46.080\n So in other words, average case analysis.\n\n1:37:46.080 --> 1:37:49.060\n Or you've also mentioned that average case\n\n1:37:49.060 --> 1:37:52.680\n kind of requires you to understand what the typical case is,\n\n1:37:52.680 --> 1:37:55.480\n typical instances, and that might be really difficult.\n\n1:37:55.480 --> 1:37:56.580\n That's very difficult.\n\n1:37:56.580 --> 1:37:59.720\n So after I did my original work\n\n1:37:59.720 --> 1:38:04.720\n on showing all these problems through NP complete,\n\n1:38:06.600 --> 1:38:11.160\n I looked around for a way to shed some positive light\n\n1:38:11.160 --> 1:38:13.800\n on combinatorial algorithms.\n\n1:38:13.800 --> 1:38:16.800\n And what I tried to do was to study problems,\n\n1:38:19.640 --> 1:38:24.600\n behavior on the average or with high probability.\n\n1:38:24.600 --> 1:38:26.160\n But I had to make some assumptions\n\n1:38:26.160 --> 1:38:29.720\n about what's the probability space?\n\n1:38:29.720 --> 1:38:30.860\n What's the sample space?\n\n1:38:30.860 --> 1:38:33.860\n What do we mean by typical problems?\n\n1:38:33.860 --> 1:38:35.280\n That's very hard to say.\n\n1:38:35.280 --> 1:38:37.680\n So I took the easy way out\n\n1:38:37.680 --> 1:38:40.500\n and made some very simplistic assumptions.\n\n1:38:40.500 --> 1:38:42.000\n So I assumed, for example,\n\n1:38:42.000 --> 1:38:44.420\n that if we were generating a graph\n\n1:38:44.420 --> 1:38:47.440\n with a certain number of vertices and edges,\n\n1:38:47.440 --> 1:38:48.920\n then we would generate the graph\n\n1:38:48.920 --> 1:38:53.840\n by simply choosing one edge at a time at random\n\n1:38:53.840 --> 1:38:56.840\n until we got the right number of edges.\n\n1:38:56.840 --> 1:38:59.800\n That's a particular model of random graphs\n\n1:38:59.800 --> 1:39:02.040\n that has been studied mathematically a lot.\n\n1:39:02.900 --> 1:39:05.120\n And within that model,\n\n1:39:05.120 --> 1:39:07.560\n I could prove all kinds of wonderful things,\n\n1:39:07.560 --> 1:39:10.640\n I and others who also worked on this.\n\n1:39:10.640 --> 1:39:15.120\n So we could show that we know exactly\n\n1:39:15.120 --> 1:39:16.760\n how many edges there have to be\n\n1:39:16.760 --> 1:39:24.040\n in order for there be a so called Hamiltonian circuit.\n\n1:39:24.040 --> 1:39:29.040\n That's a cycle that visits each vertex exactly once.\n\n1:39:31.560 --> 1:39:35.240\n We know that if the number of edges\n\n1:39:35.240 --> 1:39:37.520\n is a little bit more than n log n,\n\n1:39:37.520 --> 1:39:39.160\n where n is the number of vertices,\n\n1:39:39.160 --> 1:39:44.000\n then such a cycle is very likely to exist.\n\n1:39:44.000 --> 1:39:45.680\n And we can give a heuristic\n\n1:39:45.680 --> 1:39:47.880\n that will find it with high probability.\n\n1:39:48.880 --> 1:39:53.880\n And the community in which I was working\n\n1:39:54.880 --> 1:39:57.180\n got a lot of results along these lines.\n\n1:39:58.520 --> 1:40:03.520\n But the field tended to be rather lukewarm\n\n1:40:04.080 --> 1:40:07.340\n about accepting these results as meaningful\n\n1:40:07.340 --> 1:40:09.880\n because we were making such a simplistic assumption\n\n1:40:09.880 --> 1:40:13.960\n about the kinds of graphs that we would be dealing with.\n\n1:40:13.960 --> 1:40:16.000\n So we could show all kinds of wonderful things,\n\n1:40:16.000 --> 1:40:18.880\n it was a great playground, I enjoyed doing it.\n\n1:40:18.880 --> 1:40:23.080\n But after a while, I concluded that\n\n1:40:27.240 --> 1:40:29.040\n it didn't have a lot of bite\n\n1:40:29.040 --> 1:40:31.640\n in terms of the practical application.\n\n1:40:31.640 --> 1:40:33.480\n Oh the, okay, so there's too much\n\n1:40:33.480 --> 1:40:35.280\n into the world of toy problems.\n\n1:40:35.280 --> 1:40:36.120\n Yeah.\n\n1:40:36.120 --> 1:40:36.960\n That can, okay.\n\n1:40:36.960 --> 1:40:41.640\n But all right, is there a way to find\n\n1:40:41.640 --> 1:40:45.120\n nice representative real world impactful instances\n\n1:40:45.120 --> 1:40:48.840\n of a problem on which demonstrate that an algorithm is good?\n\n1:40:48.840 --> 1:40:51.360\n So this is kind of like the machine learning world,\n\n1:40:51.360 --> 1:40:54.200\n that's kind of what they at his best tries to do\n\n1:40:54.200 --> 1:40:57.920\n is find a data set from like the real world\n\n1:40:57.920 --> 1:41:02.040\n and show the performance, all the conferences\n\n1:41:02.040 --> 1:41:04.480\n are all focused on beating the performance\n\n1:41:04.480 --> 1:41:07.160\n of on that real world data set.\n\n1:41:07.160 --> 1:41:11.680\n Is there an equivalent in complexity analysis?\n\n1:41:11.680 --> 1:41:16.680\n Not really, Don Knuth started to collect examples\n\n1:41:19.520 --> 1:41:21.640\n of graphs coming from various places.\n\n1:41:21.640 --> 1:41:26.160\n So he would have a whole zoo of different graphs\n\n1:41:26.160 --> 1:41:28.480\n that he could choose from and he could study\n\n1:41:28.480 --> 1:41:31.640\n the performance of algorithms on different types of graphs.\n\n1:41:31.640 --> 1:41:36.640\n But there it's really important and compelling\n\n1:41:37.320 --> 1:41:40.000\n to be able to define a class of graphs.\n\n1:41:41.320 --> 1:41:44.080\n The actual act of defining a class of graphs\n\n1:41:44.080 --> 1:41:46.600\n that you're interested in, it seems to be\n\n1:41:46.600 --> 1:41:49.480\n a non trivial step if we're talking about instances\n\n1:41:49.480 --> 1:41:51.560\n that we should care about in the real world.\n\n1:41:51.560 --> 1:41:55.880\n Yeah, there's nothing available there\n\n1:41:55.880 --> 1:41:58.800\n that would be analogous to the training set\n\n1:41:58.800 --> 1:42:02.360\n for supervised learning where you sort of assume\n\n1:42:02.360 --> 1:42:05.520\n that the world has given you a bunch\n\n1:42:05.520 --> 1:42:09.240\n of examples to work with.\n\n1:42:10.200 --> 1:42:14.560\n We don't really have that for problems,\n\n1:42:14.560 --> 1:42:18.200\n for combinatorial problems on graphs and networks.\n\n1:42:18.200 --> 1:42:21.000\n You know, there's been a huge growth,\n\n1:42:21.000 --> 1:42:23.960\n a big growth of data sets available.\n\n1:42:23.960 --> 1:42:28.200\n Do you think some aspect of theoretical computer science\n\n1:42:28.200 --> 1:42:30.640\n might be contradicting my own question while saying it,\n\n1:42:30.640 --> 1:42:33.400\n but will there be some aspect,\n\n1:42:33.400 --> 1:42:36.920\n an empirical aspect of theoretical computer science\n\n1:42:36.920 --> 1:42:41.080\n which will allow the fact that these data sets are huge,\n\n1:42:41.080 --> 1:42:43.280\n we'll start using them for analysis.\n\n1:42:44.080 --> 1:42:46.920\n Sort of, you know, if you want to say something\n\n1:42:46.920 --> 1:42:50.720\n about a graph algorithm, you might take\n\n1:42:50.720 --> 1:42:55.160\n a social network like Facebook and looking at subgraphs\n\n1:42:55.160 --> 1:42:58.560\n of that and prove something about the Facebook graph\n\n1:42:58.560 --> 1:43:01.120\n and be respected, and at the same time,\n\n1:43:01.120 --> 1:43:03.840\n be respected in the theoretical computer science community.\n\n1:43:03.840 --> 1:43:06.240\n That hasn't been achieved yet, I'm afraid.\n\n1:43:06.240 --> 1:43:10.960\n Is that P equals NP, is that impossible?\n\n1:43:10.960 --> 1:43:14.560\n Is it impossible to publish a successful paper\n\n1:43:14.560 --> 1:43:17.080\n in the theoretical computer science community\n\n1:43:17.080 --> 1:43:22.080\n that shows some performance on a real world data set?\n\n1:43:22.080 --> 1:43:25.320\n Or is that really just those are two different worlds?\n\n1:43:25.320 --> 1:43:27.160\n They haven't really come together.\n\n1:43:27.160 --> 1:43:31.160\n I would say that there is a field\n\n1:43:31.160 --> 1:43:34.640\n of experimental algorithmics where people,\n\n1:43:34.640 --> 1:43:39.320\n sometimes they're given some family of examples.\n\n1:43:39.320 --> 1:43:41.960\n Sometimes they just generate them at random\n\n1:43:41.960 --> 1:43:44.200\n and they report on performance,\n\n1:43:45.920 --> 1:43:50.920\n but there's no convincing evidence\n\n1:43:50.920 --> 1:43:55.920\n that the sample is representative of anything at all.\n\n1:43:57.600 --> 1:44:00.760\n So let me ask, in terms of breakthroughs\n\n1:44:00.760 --> 1:44:04.200\n and open problems, what are the most compelling\n\n1:44:04.200 --> 1:44:07.000\n open problems to you and what possible breakthroughs\n\n1:44:07.000 --> 1:44:08.280\n do you see in the near term\n\n1:44:08.280 --> 1:44:11.900\n in terms of theoretical computer science?\n\n1:44:13.720 --> 1:44:15.480\n Well, there are all kinds of relationships\n\n1:44:15.480 --> 1:44:18.920\n among complexity classes that can be studied,\n\n1:44:18.920 --> 1:44:22.960\n just to mention one thing, I wrote a paper\n\n1:44:22.960 --> 1:44:27.480\n with Richard Lipton in 1979,\n\n1:44:28.600 --> 1:44:30.920\n where we asked the following question.\n\n1:44:34.520 --> 1:44:39.520\n If you take a combinatorial problem in NP, let's say,\n\n1:44:39.520 --> 1:44:46.520\n and you choose, and you pick the size of the problem,\n\n1:44:49.520 --> 1:44:54.520\n say it's a traveling salesman problem, but of size 52,\n\n1:44:55.720 --> 1:45:00.240\n and you ask, could you get an efficient,\n\n1:45:00.240 --> 1:45:05.240\n a small Boolean circuit tailored for that size, 52,\n\n1:45:05.240 --> 1:45:08.240\n where you could feed the edges of the graph\n\n1:45:08.240 --> 1:45:12.240\n in as Boolean inputs and get, as an output,\n\n1:45:12.240 --> 1:45:13.560\n the question of whether or not\n\n1:45:13.560 --> 1:45:15.640\n there's a tour of a certain length.\n\n1:45:16.760 --> 1:45:19.600\n And that would, in other words, briefly,\n\n1:45:19.600 --> 1:45:21.480\n what you would say in that case\n\n1:45:21.480 --> 1:45:24.240\n is that the problem has small circuits,\n\n1:45:24.240 --> 1:45:25.880\n polynomial size circuits.\n\n1:45:28.200 --> 1:45:31.280\n Now, we know that if P is equal to NP,\n\n1:45:31.280 --> 1:45:35.800\n then, in fact, these problems will have small circuits,\n\n1:45:35.800 --> 1:45:37.400\n but what about the converse?\n\n1:45:37.400 --> 1:45:39.240\n Could a problem have small circuits,\n\n1:45:39.240 --> 1:45:43.440\n meaning that an algorithm tailored to any particular size\n\n1:45:43.440 --> 1:45:48.440\n could work well, and yet not be a polynomial time algorithm?\n\n1:45:48.440 --> 1:45:50.120\n That is, you couldn't write it as a single,\n\n1:45:50.120 --> 1:45:52.960\n uniform algorithm, good for all sizes.\n\n1:45:52.960 --> 1:45:55.800\n Just to clarify, small circuits\n\n1:45:55.800 --> 1:45:57.720\n for a problem of particular size,\n\n1:45:57.720 --> 1:46:02.200\n by small circuits for a problem of particular size,\n\n1:46:02.200 --> 1:46:04.000\n or even further constraint,\n\n1:46:04.000 --> 1:46:06.280\n small circuit for a particular...\n\n1:46:07.480 --> 1:46:10.160\n No, for all the inputs of that size.\n\n1:46:10.160 --> 1:46:13.680\n Is that a trivial problem for a particular instance?\n\n1:46:13.680 --> 1:46:15.640\n So, coming up, an automated way\n\n1:46:15.640 --> 1:46:17.960\n of coming up with a circuit.\n\n1:46:17.960 --> 1:46:19.200\n I guess that's just an answer.\n\n1:46:19.200 --> 1:46:22.040\n That would be hard, yeah.\n\n1:46:22.040 --> 1:46:25.400\n But there's the existential question.\n\n1:46:25.400 --> 1:46:29.000\n Everybody talks nowadays about existential questions.\n\n1:46:29.000 --> 1:46:33.320\n Existential challenges.\n\n1:46:35.640 --> 1:46:37.520\n You could ask the question,\n\n1:46:38.880 --> 1:46:43.960\n does the Hamiltonian circuit problem\n\n1:46:43.960 --> 1:46:48.960\n have a small circuit for every size,\n\n1:46:49.440 --> 1:46:51.800\n for each size, a different small circuit?\n\n1:46:51.800 --> 1:46:55.600\n In other words, could you tailor solutions\n\n1:46:55.600 --> 1:47:00.560\n depending on the size, and get polynomial size?\n\n1:47:00.560 --> 1:47:02.640\n Even if P is not equal to NP.\n\n1:47:02.640 --> 1:47:03.480\n Right.\n\n1:47:06.680 --> 1:47:08.600\n That would be fascinating if that's true.\n\n1:47:08.600 --> 1:47:13.600\n Yeah, what we proved is that if that were possible,\n\n1:47:14.760 --> 1:47:18.840\n then something strange would happen in complexity theory.\n\n1:47:18.840 --> 1:47:23.840\n Some high level class which I could briefly describe,\n\n1:47:26.800 --> 1:47:28.360\n something strange would happen.\n\n1:47:28.360 --> 1:47:31.960\n So, I'll take a stab at describing what I mean.\n\n1:47:31.960 --> 1:47:33.880\n Sure, let's go there.\n\n1:47:33.880 --> 1:47:37.640\n So, we have to define this hierarchy\n\n1:47:37.640 --> 1:47:41.440\n in which the first level of the hierarchy is P,\n\n1:47:41.440 --> 1:47:44.080\n and the second level is NP.\n\n1:47:44.080 --> 1:47:45.240\n And what is NP?\n\n1:47:45.240 --> 1:47:48.200\n NP involves statements of the form\n\n1:47:48.200 --> 1:47:52.320\n there exists a something such that something holds.\n\n1:47:53.720 --> 1:47:58.720\n So, for example, there exists the coloring\n\n1:47:59.960 --> 1:48:01.880\n such that a graph can be colored\n\n1:48:01.880 --> 1:48:06.640\n with only that number of colors.\n\n1:48:06.640 --> 1:48:09.120\n Or there exists a Hamiltonian circuit.\n\n1:48:09.120 --> 1:48:10.800\n There's a statement about this graph.\n\n1:48:10.800 --> 1:48:22.840\n Yeah, so the NP deals with statements of that kind,\n\n1:48:22.840 --> 1:48:26.200\n that there exists a solution.\n\n1:48:26.200 --> 1:48:32.600\n Now, you could imagine a more complicated expression\n\n1:48:32.600 --> 1:48:38.600\n which says for all x there exists a y\n\n1:48:38.600 --> 1:48:47.200\n such that some proposition holds involving both x and y.\n\n1:48:47.200 --> 1:48:50.040\n So, that would say, for example, in game theory,\n\n1:48:50.040 --> 1:48:54.920\n for all strategies for the first player,\n\n1:48:54.920 --> 1:48:57.720\n there exists a strategy for the second player\n\n1:48:57.720 --> 1:48:59.520\n such that the first player wins.\n\n1:48:59.520 --> 1:49:03.360\n That would be at the second level of the hierarchy.\n\n1:49:03.360 --> 1:49:06.000\n The third level would be there exists an A\n\n1:49:06.000 --> 1:49:08.400\n such that for all B there exists a C,\n\n1:49:08.400 --> 1:49:09.240\n that something holds.\n\n1:49:09.240 --> 1:49:11.200\n And you could imagine going higher and higher\n\n1:49:11.200 --> 1:49:12.680\n in the hierarchy.\n\n1:49:12.680 --> 1:49:17.480\n And you'd expect that the complexity classes\n\n1:49:17.480 --> 1:49:22.400\n that correspond to those different cases\n\n1:49:22.400 --> 1:49:25.240\n would get bigger and bigger.\n\n1:49:27.080 --> 1:49:28.240\n What do you mean by bigger and bigger?\n\n1:49:28.240 --> 1:49:29.520\n Sorry, sorry.\n\n1:49:29.520 --> 1:49:30.720\n They'd get harder and harder to solve.\n\n1:49:30.720 --> 1:49:32.360\n Harder and harder, right.\n\n1:49:32.360 --> 1:49:34.080\n Harder and harder to solve.\n\n1:49:35.360 --> 1:49:37.720\n And what Lipton and I showed was\n\n1:49:37.720 --> 1:49:41.560\n that if NP had small circuits,\n\n1:49:41.560 --> 1:49:44.160\n then this hierarchy would collapse down\n\n1:49:44.160 --> 1:49:46.200\n to the second level.\n\n1:49:46.200 --> 1:49:48.400\n In other words, you wouldn't get any more mileage\n\n1:49:48.400 --> 1:49:51.520\n by complicating your expressions with three quantifiers\n\n1:49:51.520 --> 1:49:53.480\n or four quantifiers or any number.\n\n1:49:55.400 --> 1:49:57.720\n I'm not sure what to make of that exactly.\n\n1:49:57.720 --> 1:49:59.280\n Well, I think it would be evidence\n\n1:49:59.280 --> 1:50:02.920\n that NP doesn't have small circuits\n\n1:50:02.920 --> 1:50:07.080\n because something so bizarre would happen.\n\n1:50:07.080 --> 1:50:09.000\n But again, it's only evidence, not proof.\n\n1:50:09.000 --> 1:50:12.520\n Well, yeah, that's not even evidence\n\n1:50:12.520 --> 1:50:16.960\n because you're saying P is not equal to NP\n\n1:50:16.960 --> 1:50:19.560\n because something bizarre has to happen.\n\n1:50:19.560 --> 1:50:24.560\n I mean, that's proof by the lack of bizarreness\n\n1:50:25.120 --> 1:50:26.600\n in our science.\n\n1:50:26.600 --> 1:50:31.400\n But it seems like just the very notion\n\n1:50:31.400 --> 1:50:33.040\n of P equals NP would be bizarre.\n\n1:50:33.040 --> 1:50:36.240\n So any way you arrive at, there's no way.\n\n1:50:36.240 --> 1:50:38.440\n You have to fight the dragon at some point.\n\n1:50:38.440 --> 1:50:39.280\n Yeah, okay.\n\n1:50:39.280 --> 1:50:41.880\n Well, anyway, for whatever it's worth,\n\n1:50:41.880 --> 1:50:43.320\n that's what we proved.\n\n1:50:43.320 --> 1:50:44.160\n Awesome.\n\n1:50:45.720 --> 1:50:49.400\n So that's a potential space of interesting problems.\n\n1:50:49.400 --> 1:50:50.240\n Yeah.\n\n1:50:50.240 --> 1:50:54.120\n Let me ask you about this other world\n\n1:50:54.120 --> 1:50:57.280\n that of machine learning, of deep learning.\n\n1:50:57.280 --> 1:50:59.640\n What's your thoughts on the history\n\n1:50:59.640 --> 1:51:02.600\n and the current progress of machine learning field\n\n1:51:02.600 --> 1:51:05.760\n that's often progressed sort of separately\n\n1:51:05.760 --> 1:51:08.840\n as a space of ideas and space of people\n\n1:51:08.840 --> 1:51:10.920\n than the theoretical computer science\n\n1:51:10.920 --> 1:51:12.640\n or just even computer science world?\n\n1:51:12.640 --> 1:51:15.680\n Yeah, it's really very different\n\n1:51:15.680 --> 1:51:17.800\n from the theoretical computer science world\n\n1:51:17.800 --> 1:51:22.280\n because the results about it,\n\n1:51:22.280 --> 1:51:25.400\n algorithmic performance tend to be empirical.\n\n1:51:25.400 --> 1:51:28.880\n It's more akin to the world of SAT solvers\n\n1:51:28.880 --> 1:51:33.880\n where we observe that for formulas arising in practice,\n\n1:51:33.880 --> 1:51:35.920\n the solver does well.\n\n1:51:35.920 --> 1:51:38.520\n So it's of that type.\n\n1:51:38.520 --> 1:51:43.520\n We're moving into the empirical evaluation of algorithms.\n\n1:51:45.280 --> 1:51:47.800\n Now, it's clear that there've been huge successes\n\n1:51:47.800 --> 1:51:52.720\n in image processing, robotics,\n\n1:51:52.720 --> 1:51:55.400\n natural language processing, a little less so,\n\n1:51:55.400 --> 1:52:00.400\n but across the spectrum of game playing is another one.\n\n1:52:00.400 --> 1:52:05.400\n There've been great successes and one of those effects\n\n1:52:07.320 --> 1:52:10.040\n is that it's not too hard to become a millionaire\n\n1:52:10.040 --> 1:52:12.360\n if you can get a reputation in machine learning\n\n1:52:12.360 --> 1:52:13.960\n and there'll be all kinds of companies\n\n1:52:13.960 --> 1:52:16.360\n that will be willing to offer you the moon\n\n1:52:16.360 --> 1:52:21.360\n because they think that if they have AI at their disposal,\n\n1:52:23.360 --> 1:52:25.560\n then they can solve all kinds of problems.\n\n1:52:25.560 --> 1:52:30.040\n But there are limitations.\n\n1:52:30.040 --> 1:52:38.000\n One is that the solutions that you get\n\n1:52:38.000 --> 1:52:44.800\n to supervise learning problems\n\n1:52:44.800 --> 1:52:50.000\n through convolutional neural networks\n\n1:52:50.000 --> 1:52:55.120\n seem to perform amazingly well\n\n1:52:55.120 --> 1:52:59.120\n even for inputs that are outside the training set.\n\n1:53:03.120 --> 1:53:06.240\n But we don't have any theoretical understanding\n\n1:53:06.240 --> 1:53:07.520\n of why that's true.\n\n1:53:09.360 --> 1:53:13.440\n Secondly, the solutions, the networks that you get\n\n1:53:14.560 --> 1:53:16.560\n are very hard to understand\n\n1:53:16.560 --> 1:53:18.840\n and so very little insight comes out.\n\n1:53:19.960 --> 1:53:23.960\n So yeah, yeah, they may seem to work on your training set\n\n1:53:23.960 --> 1:53:28.960\n and you may be able to discover whether your photos occur\n\n1:53:28.960 --> 1:53:33.960\n in a different sample of inputs or not,\n\n1:53:35.720 --> 1:53:37.520\n but we don't really know what's going on.\n\n1:53:37.520 --> 1:53:41.680\n We don't know the features that distinguish the photographs\n\n1:53:41.680 --> 1:53:46.680\n or the objects are not easy to characterize.\n\n1:53:49.560 --> 1:53:51.160\n Well, it's interesting because you mentioned\n\n1:53:51.160 --> 1:53:54.280\n coming up with a small circuit to solve\n\n1:53:54.280 --> 1:53:56.360\n a particular size problem.\n\n1:53:56.360 --> 1:53:59.880\n It seems that neural networks are kind of small circuits.\n\n1:53:59.880 --> 1:54:01.360\n In a way, yeah.\n\n1:54:01.360 --> 1:54:02.800\n But they're not programs.\n\n1:54:02.800 --> 1:54:04.960\n Sort of like the things you've designed\n\n1:54:04.960 --> 1:54:08.920\n are algorithms, programs, algorithms.\n\n1:54:08.920 --> 1:54:12.600\n Neural networks aren't able to develop algorithms\n\n1:54:12.600 --> 1:54:14.480\n to solve a problem.\n\n1:54:14.480 --> 1:54:16.920\n Well, they are algorithms.\n\n1:54:16.920 --> 1:54:18.520\n It's just that they're...\n\n1:54:18.520 --> 1:54:23.520\n But sort of, yeah, it could be a semantic question,\n\n1:54:25.280 --> 1:54:30.280\n but there's not a algorithmic style manipulation\n\n1:54:31.120 --> 1:54:32.040\n of the input.\n\n1:54:33.400 --> 1:54:35.320\n Perhaps you could argue there is.\n\n1:54:35.320 --> 1:54:37.120\n Yeah, well.\n\n1:54:37.120 --> 1:54:40.520\n It feels a lot more like a function of the input.\n\n1:54:40.520 --> 1:54:41.720\n Yeah, it's a function.\n\n1:54:41.720 --> 1:54:43.120\n It's a computable function.\n\n1:54:43.120 --> 1:54:46.040\n Once you have the network,\n\n1:54:46.040 --> 1:54:49.360\n you can simulate it on a given input\n\n1:54:49.360 --> 1:54:51.320\n and figure out the output.\n\n1:54:51.320 --> 1:54:56.320\n But if you're trying to recognize images,\n\n1:54:58.720 --> 1:55:00.880\n then you don't know what features of the image\n\n1:55:00.880 --> 1:55:05.880\n are really being determinant of what the circuit is doing.\n\n1:55:09.440 --> 1:55:14.040\n The circuit is sort of very intricate\n\n1:55:14.040 --> 1:55:19.040\n and it's not clear that the simple characteristics\n\n1:55:21.000 --> 1:55:22.040\n that you're looking for,\n\n1:55:22.040 --> 1:55:25.240\n the edges of the objects or whatever they may be,\n\n1:55:26.120 --> 1:55:29.600\n they're not emerging from the structure of the circuit.\n\n1:55:29.600 --> 1:55:31.120\n Well, it's not clear to us humans,\n\n1:55:31.120 --> 1:55:33.040\n but it's clear to the circuit.\n\n1:55:33.040 --> 1:55:34.880\n Yeah, well, right.\n\n1:55:34.880 --> 1:55:39.880\n I mean, it's not clear to sort of the elephant\n\n1:55:39.880 --> 1:55:44.600\n how the human brain works,\n\n1:55:44.600 --> 1:55:46.880\n but it's clear to us humans,\n\n1:55:46.880 --> 1:55:49.160\n we can explain to each other our reasoning\n\n1:55:49.160 --> 1:55:50.760\n and that's why the cognitive science\n\n1:55:50.760 --> 1:55:52.720\n and psychology field exists.\n\n1:55:52.720 --> 1:55:56.280\n Maybe the whole thing of being explainable to humans\n\n1:55:56.280 --> 1:55:57.720\n is a little bit overrated.\n\n1:55:57.720 --> 1:55:59.760\n Oh, maybe, yeah.\n\n1:55:59.760 --> 1:56:02.480\n I guess you can say the same thing about our brain\n\n1:56:02.480 --> 1:56:06.160\n that when we perform acts of cognition,\n\n1:56:06.160 --> 1:56:08.760\n we have no idea how we do it really.\n\n1:56:08.760 --> 1:56:13.680\n We do though, I mean, at least for the visual system,\n\n1:56:13.680 --> 1:56:15.200\n the auditory system and so on,\n\n1:56:15.200 --> 1:56:19.240\n we do get some understanding of the principles\n\n1:56:19.240 --> 1:56:20.200\n that they operate under,\n\n1:56:20.200 --> 1:56:25.200\n but for many deeper cognitive tasks, we don't have that.\n\n1:56:25.600 --> 1:56:26.640\n That's right.\n\n1:56:26.640 --> 1:56:31.640\n Let me ask, you've also been doing work on bioinformatics.\n\n1:56:33.000 --> 1:56:36.960\n Does it amaze you that the fundamental building blocks?\n\n1:56:36.960 --> 1:56:39.840\n So if we take a step back and look at us humans,\n\n1:56:39.840 --> 1:56:41.800\n the building blocks used by evolution\n\n1:56:41.800 --> 1:56:44.640\n to build us intelligent human beings\n\n1:56:44.640 --> 1:56:47.200\n is all contained there in our DNA.\n\n1:56:48.320 --> 1:56:51.880\n It's amazing and what's really amazing\n\n1:56:51.880 --> 1:56:56.880\n is that we are beginning to learn how to edit DNA,\n\n1:57:00.920 --> 1:57:05.560\n which is very, very, very fascinating.\n\n1:57:05.560 --> 1:57:10.560\n This ability to take a sequence,\n\n1:57:15.240 --> 1:57:18.960\n find it in the genome and do something to it.\n\n1:57:18.960 --> 1:57:21.320\n I mean, that's really taking our biological systems\n\n1:57:21.320 --> 1:57:24.480\n towards the world of algorithms.\n\n1:57:24.480 --> 1:57:27.160\n Yeah, but it raises a lot of questions.\n\n1:57:30.000 --> 1:57:33.920\n You have to distinguish between doing it on an individual\n\n1:57:33.920 --> 1:57:35.760\n or doing it on somebody's germline,\n\n1:57:35.760 --> 1:57:38.880\n which means that all of their descendants will be affected.\n\n1:57:40.280 --> 1:57:42.200\n So that's like an ethical.\n\n1:57:42.200 --> 1:57:46.120\n Yeah, so it raises very severe ethical questions.\n\n1:57:50.520 --> 1:57:52.800\n And even doing it on individuals,\n\n1:57:56.800 --> 1:57:59.480\n there's a lot of hubris involved\n\n1:57:59.480 --> 1:58:04.160\n that you can assume that knocking out a particular gene\n\n1:58:04.160 --> 1:58:05.400\n is gonna be beneficial\n\n1:58:05.400 --> 1:58:07.000\n because you don't know what the side effects\n\n1:58:07.000 --> 1:58:08.040\n are going to be.\n\n1:58:08.960 --> 1:58:13.960\n So we have this wonderful new world of gene editing,\n\n1:58:20.200 --> 1:58:23.200\n which is very, very impressive\n\n1:58:23.200 --> 1:58:27.280\n and it could be used in agriculture,\n\n1:58:27.280 --> 1:58:31.320\n it could be used in medicine in various ways.\n\n1:58:32.680 --> 1:58:35.480\n But very serious ethical problems arise.\n\n1:58:37.240 --> 1:58:39.880\n What are to you the most interesting places\n\n1:58:39.880 --> 1:58:44.560\n where algorithms, sort of the ethical side\n\n1:58:44.560 --> 1:58:46.040\n is an exceptionally challenging thing\n\n1:58:46.040 --> 1:58:48.040\n that I think we're going to have to tackle\n\n1:58:48.040 --> 1:58:51.840\n with all of genetic engineering.\n\n1:58:51.840 --> 1:58:53.760\n But on the algorithmic side,\n\n1:58:53.760 --> 1:58:55.520\n there's a lot of benefit that's possible.\n\n1:58:55.520 --> 1:59:00.280\n So is there areas where you see exciting possibilities\n\n1:59:00.280 --> 1:59:03.360\n for algorithms to help model, optimize,\n\n1:59:03.360 --> 1:59:05.120\n study biological systems?\n\n1:59:06.720 --> 1:59:11.720\n Yeah, I mean, we can certainly analyze genomic data\n\n1:59:12.480 --> 1:59:17.440\n to figure out which genes are operative in the cell\n\n1:59:17.440 --> 1:59:18.800\n and under what conditions\n\n1:59:18.800 --> 1:59:21.280\n and which proteins affect one another,\n\n1:59:21.280 --> 1:59:26.120\n which proteins physically interact.\n\n1:59:27.400 --> 1:59:30.680\n We can sequence proteins and modify them.\n\n1:59:32.680 --> 1:59:33.840\n Is there some aspect of that\n\n1:59:33.840 --> 1:59:35.920\n that's a computer science problem\n\n1:59:35.920 --> 1:59:39.840\n or is that still fundamentally a biology problem?\n\n1:59:39.840 --> 1:59:41.600\n Well, it's a big data,\n\n1:59:41.600 --> 1:59:44.640\n it's a statistical big data problem for sure.\n\n1:59:45.720 --> 1:59:49.280\n So the biological data sets are increasing,\n\n1:59:49.280 --> 1:59:54.280\n our ability to study our ancestry,\n\n1:59:55.680 --> 1:59:59.960\n to study the tendencies towards disease,\n\n1:59:59.960 --> 2:00:04.960\n to personalize treatment according to what's in our genomes\n\n2:00:06.960 --> 2:00:09.360\n and what tendencies for disease we have,\n\n2:00:10.440 --> 2:00:13.960\n to be able to predict what troubles might come upon us\n\n2:00:13.960 --> 2:00:16.120\n in the future and anticipate them,\n\n2:00:16.120 --> 2:00:21.120\n to understand whether you,\n\n2:00:24.360 --> 2:00:29.360\n for a woman, whether her proclivity for breast cancer\n\n2:00:31.560 --> 2:00:33.680\n is so strong enough that she would want\n\n2:00:33.680 --> 2:00:36.720\n to take action to avoid it.\n\n2:00:37.680 --> 2:00:41.040\n You dedicate your 1985 Turing Award lecture\n\n2:00:41.040 --> 2:00:42.600\n to the memory of your father.\n\n2:00:42.600 --> 2:00:47.160\n What's your fondest memory of your dad?\n\n2:00:53.040 --> 2:00:57.880\n Seeing him standing in front of a class at the blackboard,\n\n2:00:57.880 --> 2:01:02.520\n drawing perfect circles by hand\n\n2:01:03.960 --> 2:01:08.960\n and showing his ability to attract the interest\n\n2:01:08.960 --> 2:01:13.960\n of the motley collection of eighth grade students\n\n2:01:14.760 --> 2:01:15.800\n that he was teaching.\n\n2:01:19.120 --> 2:01:21.640\n When did you get a chance to see him\n\n2:01:21.640 --> 2:01:23.080\n draw the perfect circles?\n\n2:01:24.280 --> 2:01:27.480\n On rare occasions, I would get a chance\n\n2:01:27.480 --> 2:01:32.480\n to sneak into his classroom and observe him.\n\n2:01:33.160 --> 2:01:36.320\n And I think he was at his best in the classroom.\n\n2:01:36.320 --> 2:01:41.320\n I think he really came to life and had fun,\n\n2:01:42.720 --> 2:01:47.720\n not only teaching, but engaging in chit chat\n\n2:01:49.080 --> 2:01:52.280\n with the students and ingratiating himself\n\n2:01:52.280 --> 2:01:53.800\n with the students.\n\n2:01:53.800 --> 2:01:58.800\n And what I inherited from that is the great desire\n\n2:02:00.040 --> 2:02:01.920\n to be a teacher.\n\n2:02:01.920 --> 2:02:06.920\n I retired recently and a lot of my former students came,\n\n2:02:08.320 --> 2:02:11.200\n students with whom I had done research\n\n2:02:11.200 --> 2:02:14.760\n or who had read my papers or who had been in my classes.\n\n2:02:15.680 --> 2:02:19.840\n And when they talked about me,\n\n2:02:22.520 --> 2:02:27.520\n they talked not about my 1979 paper or 1992 paper,\n\n2:02:27.520 --> 2:02:32.520\n but about what came away in my classes.\n\n2:02:33.600 --> 2:02:36.400\n And not just the details, but just the approach\n\n2:02:36.400 --> 2:02:39.400\n and the manner of teaching.\n\n2:02:40.240 --> 2:02:43.600\n And so I sort of take pride in the,\n\n2:02:43.600 --> 2:02:47.680\n at least in my early years as a faculty member at Berkeley,\n\n2:02:47.680 --> 2:02:51.760\n I was exemplary in preparing my lectures\n\n2:02:51.760 --> 2:02:56.760\n and I always came in prepared to the teeth,\n\n2:02:56.760 --> 2:02:59.320\n and able therefore to deviate according\n\n2:02:59.320 --> 2:03:01.200\n to what happened in the class,\n\n2:03:01.200 --> 2:03:06.200\n and to really provide a model for the students.\n\n2:03:08.760 --> 2:03:13.760\n So is there advice you can give out for others\n\n2:03:14.640 --> 2:03:16.520\n on how to be a good teacher?\n\n2:03:16.520 --> 2:03:19.000\n So preparation is one thing you've mentioned,\n\n2:03:19.000 --> 2:03:20.440\n being exceptionally well prepared,\n\n2:03:20.440 --> 2:03:21.520\n but there are other things,\n\n2:03:21.520 --> 2:03:24.480\n pieces of advice that you can impart?\n\n2:03:24.480 --> 2:03:27.400\n Well, the top three would be preparation, preparation,\n\n2:03:27.400 --> 2:03:28.240\n and preparation.\n\n2:03:29.760 --> 2:03:31.920\n Why is preparation so important, I guess?\n\n2:03:32.840 --> 2:03:34.440\n It's because it gives you the ease\n\n2:03:34.440 --> 2:03:38.680\n to deal with any situation that comes up in the classroom.\n\n2:03:38.680 --> 2:03:43.680\n And if you discover that you're not getting through one way,\n\n2:03:44.520 --> 2:03:45.880\n you can do it another way.\n\n2:03:45.880 --> 2:03:47.320\n If the students have questions,\n\n2:03:47.320 --> 2:03:49.000\n you can handle the questions.\n\n2:03:49.000 --> 2:03:54.000\n Ultimately, you're also feeling the crowd,\n\n2:03:54.000 --> 2:03:57.080\n the students of what they're struggling with,\n\n2:03:57.080 --> 2:03:57.920\n what they're picking up,\n\n2:03:57.920 --> 2:03:59.720\n just looking at them through the questions,\n\n2:03:59.720 --> 2:04:01.440\n but even just through their eyes.\n\n2:04:01.440 --> 2:04:02.280\n Yeah, that's right.\n\n2:04:02.280 --> 2:04:05.400\n And because of the preparation, you can dance.\n\n2:04:05.400 --> 2:04:09.800\n You can dance, you can say it another way,\n\n2:04:09.800 --> 2:04:11.640\n or give it another angle.\n\n2:04:11.640 --> 2:04:14.840\n Are there, in particular, ideas and algorithms\n\n2:04:14.840 --> 2:04:17.080\n of computer science that you find\n\n2:04:17.080 --> 2:04:19.920\n were big aha moments for students,\n\n2:04:19.920 --> 2:04:22.760\n where they, for some reason, once they got it,\n\n2:04:22.760 --> 2:04:24.720\n it clicked for them and they fell in love\n\n2:04:24.720 --> 2:04:26.640\n with computer science?\n\n2:04:26.640 --> 2:04:29.320\n Or is it individual, is it different for everybody?\n\n2:04:29.320 --> 2:04:30.840\n It's different for everybody.\n\n2:04:30.840 --> 2:04:32.720\n You have to work differently with students.\n\n2:04:32.720 --> 2:04:37.720\n Some of them just don't need much influence.\n\n2:04:40.120 --> 2:04:42.360\n They're just running with what they're doing\n\n2:04:42.360 --> 2:04:44.800\n and they just need an ear now and then.\n\n2:04:44.800 --> 2:04:47.200\n Others need a little prodding.\n\n2:04:47.200 --> 2:04:50.880\n Others need to be persuaded to collaborate among themselves\n\n2:04:50.880 --> 2:04:53.000\n rather than working alone.\n\n2:04:53.000 --> 2:04:57.200\n They have their personal ups and downs,\n\n2:04:57.200 --> 2:05:02.200\n so you have to deal with each student as a human being\n\n2:05:03.000 --> 2:05:06.640\n and bring out the best.\n\n2:05:06.640 --> 2:05:08.160\n Humans are complicated.\n\n2:05:08.160 --> 2:05:09.240\n Yeah.\n\n2:05:09.240 --> 2:05:11.240\n Perhaps a silly question.\n\n2:05:11.240 --> 2:05:15.400\n If you could relive a moment in your life outside of family\n\n2:05:15.400 --> 2:05:17.440\n because it made you truly happy,\n\n2:05:17.440 --> 2:05:19.920\n or perhaps because it changed the direction of your life\n\n2:05:19.920 --> 2:05:23.560\n in a profound way, what moment would you pick?\n\n2:05:24.560 --> 2:05:28.240\n I was kind of a lazy student as an undergraduate,\n\n2:05:28.240 --> 2:05:32.440\n and even in my first year in graduate school.\n\n2:05:33.320 --> 2:05:37.280\n And I think it was when I started doing research,\n\n2:05:37.280 --> 2:05:41.520\n I had a couple of summer jobs where I was able to contribute\n\n2:05:41.520 --> 2:05:45.040\n and I had an idea.\n\n2:05:45.040 --> 2:05:47.760\n And then there was one particular course\n\n2:05:47.760 --> 2:05:50.480\n on mathematical methods and operations research\n\n2:05:51.520 --> 2:05:53.600\n where I just gobbled up the material\n\n2:05:53.600 --> 2:05:57.560\n and I scored 20 points higher than anybody else in the class\n\n2:05:57.560 --> 2:06:00.680\n then came to the attention of the faculty.\n\n2:06:00.680 --> 2:06:04.600\n And it made me realize that I had some ability\n\n2:06:04.600 --> 2:06:05.920\n that I was going somewhere.\n\n2:06:09.160 --> 2:06:11.360\n You realize you're pretty good at this thing.\n\n2:06:12.360 --> 2:06:14.320\n I don't think there's a better way to end it, Richard.\n\n2:06:14.320 --> 2:06:15.240\n It was a huge honor.\n\n2:06:15.240 --> 2:06:18.240\n Thank you for decades of incredible work.\n\n2:06:18.240 --> 2:06:19.080\n Thank you for talking to me.\n\n2:06:19.080 --> 2:06:21.080\n Thank you, it's been a great pleasure.\n\n2:06:21.080 --> 2:06:23.920\n You're a superb interviewer.\n\n2:06:23.920 --> 2:06:25.800\n I'll stop it.\n\n2:06:26.760 --> 2:06:29.640\n Thanks for listening to this conversation with Richard Karp.\n\n2:06:29.640 --> 2:06:34.120\n And thank you to our sponsors, 8sleep and Cash App.\n\n2:06:34.120 --> 2:06:35.880\n Please consider supporting this podcast\n\n2:06:35.880 --> 2:06:39.160\n by going to 8sleep.com slash Lex\n\n2:06:39.160 --> 2:06:41.920\n to check out their awesome mattress\n\n2:06:41.920 --> 2:06:46.040\n and downloading Cash App and using code LexPodcast.\n\n2:06:46.040 --> 2:06:48.320\n Click the links, buy the stuff,\n\n2:06:48.320 --> 2:06:49.800\n even just visiting the site\n\n2:06:49.800 --> 2:06:51.600\n but also considering the purchase.\n\n2:06:51.600 --> 2:06:54.200\n Helps them know that this podcast\n\n2:06:54.200 --> 2:06:55.840\n is worth supporting in the future.\n\n2:06:55.840 --> 2:06:59.680\n It really is the best way to support this journey I'm on.\n\n2:06:59.680 --> 2:07:02.040\n If you enjoy this thing, subscribe on YouTube,\n\n2:07:02.040 --> 2:07:04.120\n review it with Five Stars and Apple Podcast,\n\n2:07:04.120 --> 2:07:07.360\n support it on Patreon, connect with me on Twitter\n\n2:07:07.360 --> 2:07:11.360\n at Lex Friedman if you can figure out how to spell that.\n\n2:07:11.360 --> 2:07:16.000\n And now let me leave you with some words from Isaac Asimov.\n\n2:07:16.000 --> 2:07:18.160\n I do not fear computers.\n\n2:07:18.160 --> 2:07:19.800\n I fear lack of them.\n\n2:07:19.800 --> 2:07:40.800\n Thank you for listening and hope to see you next time.\n\n"
}
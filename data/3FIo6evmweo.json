{
  "title": "Juergen Schmidhuber: Godel Machines, Meta-Learning, and LSTMs | Lex Fridman Podcast #11",
  "id": "3FIo6evmweo",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:03.520\n The following is a conversation with J\u00fcrgen Schmidhuber.\n\n00:03.520 --> 00:06.320\n He's the co director of the CS Swiss AI Lab\n\n00:06.320 --> 00:10.360\n and a co creator of long short term memory networks.\n\n00:10.360 --> 00:13.720\n LSDMs are used in billions of devices today\n\n00:13.720 --> 00:17.400\n for speech recognition, translation, and much more.\n\n00:17.400 --> 00:20.800\n Over 30 years, he has proposed a lot of interesting\n\n00:20.800 --> 00:24.800\n out of the box ideas on meta learning, adversarial networks,\n\n00:24.800 --> 00:28.720\n computer vision, and even a formal theory of quote,\n\n00:28.720 --> 00:32.360\n creativity, curiosity, and fun.\n\n00:32.360 --> 00:34.920\n This conversation is part of the MIT course\n\n00:34.920 --> 00:36.560\n on artificial general intelligence\n\n00:36.560 --> 00:38.840\n and the artificial intelligence podcast.\n\n00:38.840 --> 00:41.960\n If you enjoy it, subscribe on YouTube, iTunes,\n\n00:41.960 --> 00:43.960\n or simply connect with me on Twitter\n\n00:43.960 --> 00:47.280\n at Lex Friedman spelled F R I D.\n\n00:47.280 --> 00:51.520\n And now here's my conversation with J\u00fcrgen Schmidhuber.\n\n00:53.080 --> 00:55.640\n Early on you dreamed of AI systems\n\n00:55.640 --> 00:58.680\n that self improve recursively.\n\n00:58.680 --> 01:00.440\n When was that dream born?\n\n01:01.800 --> 01:03.160\n When I was a baby.\n\n01:03.160 --> 01:04.240\n No, that's not true.\n\n01:04.240 --> 01:05.480\n When I was a teenager.\n\n01:06.520 --> 01:09.680\n And what was the catalyst for that birth?\n\n01:09.680 --> 01:11.880\n What was the thing that first inspired you?\n\n01:12.920 --> 01:17.920\n When I was a boy, I was thinking about what to do in my life\n\n01:20.200 --> 01:23.880\n and then I thought the most exciting thing\n\n01:23.880 --> 01:28.200\n is to solve the riddles of the universe.\n\n01:28.200 --> 01:30.920\n And that means you have to become a physicist.\n\n01:30.920 --> 01:35.840\n However, then I realized that there's something even grander.\n\n01:35.840 --> 01:39.880\n You can try to build a machine\n\n01:39.880 --> 01:42.120\n that isn't really a machine any longer\n\n01:42.120 --> 01:44.520\n that learns to become a much better physicist\n\n01:44.520 --> 01:47.080\n than I could ever hope to be.\n\n01:47.080 --> 01:50.320\n And that's how I thought maybe I can multiply\n\n01:50.320 --> 01:54.520\n my tiny little bit of creativity into infinity.\n\n01:54.520 --> 01:57.280\n But ultimately that creativity will be multiplied\n\n01:57.280 --> 01:59.280\n to understand the universe around us.\n\n01:59.280 --> 02:04.280\n That's the curiosity for that mystery that drove you.\n\n02:05.800 --> 02:08.440\n Yes, so if you can build a machine\n\n02:08.440 --> 02:13.440\n that learns to solve more and more complex problems\n\n02:13.880 --> 02:16.880\n and more and more general problem solver\n\n02:16.880 --> 02:21.880\n then you basically have solved all the problems,\n\n02:22.680 --> 02:26.080\n at least all the solvable problems.\n\n02:26.080 --> 02:28.120\n So how do you think, what is the mechanism\n\n02:28.120 --> 02:31.640\n for that kind of general solver look like?\n\n02:31.640 --> 02:34.840\n Obviously we don't quite yet have one\n\n02:34.840 --> 02:37.040\n or know how to build one but we have ideas\n\n02:37.040 --> 02:39.120\n and you have had throughout your career\n\n02:39.120 --> 02:40.800\n several ideas about it.\n\n02:40.800 --> 02:43.640\n So how do you think about that mechanism?\n\n02:43.640 --> 02:48.640\n So in the 80s, I thought about how to build this machine\n\n02:48.640 --> 02:51.040\n that learns to solve all these problems\n\n02:51.040 --> 02:54.120\n that I cannot solve myself.\n\n02:54.120 --> 02:57.160\n And I thought it is clear it has to be a machine\n\n02:57.160 --> 03:00.880\n that not only learns to solve this problem here\n\n03:00.880 --> 03:04.160\n and this problem here but it also has to learn\n\n03:04.160 --> 03:08.080\n to improve the learning algorithm itself.\n\n03:09.360 --> 03:12.480\n So it has to have the learning algorithm\n\n03:12.480 --> 03:15.720\n in a representation that allows it to inspect it\n\n03:15.720 --> 03:19.240\n and modify it such that it can come up\n\n03:19.240 --> 03:21.080\n with a better learning algorithm.\n\n03:21.080 --> 03:24.600\n So I call that meta learning, learning to learn\n\n03:24.600 --> 03:26.760\n and recursive self improvement\n\n03:26.760 --> 03:28.760\n that is really the pinnacle of that\n\n03:28.760 --> 03:33.760\n where you then not only learn how to improve\n\n03:34.800 --> 03:36.440\n on that problem and on that\n\n03:36.440 --> 03:40.000\n but you also improve the way the machine improves\n\n03:40.000 --> 03:42.160\n and you also improve the way it improves\n\n03:42.160 --> 03:43.560\n the way it improves itself.\n\n03:44.600 --> 03:47.440\n And that was my 1987 diploma thesis\n\n03:47.440 --> 03:50.920\n which was all about that higher education\n\n03:50.920 --> 03:55.920\n hierarchy of meta learners that have no computational limits\n\n03:57.240 --> 04:01.640\n except for the well known limits that G\u00f6del identified\n\n04:01.640 --> 04:05.660\n in 1931 and for the limits of physics.\n\n04:06.480 --> 04:10.040\n In the recent years, meta learning has gained popularity\n\n04:10.040 --> 04:12.760\n in a specific kind of form.\n\n04:12.760 --> 04:16.000\n You've talked about how that's not really meta learning\n\n04:16.000 --> 04:21.000\n with neural networks, that's more basic transfer learning.\n\n04:21.480 --> 04:22.720\n Can you talk about the difference\n\n04:22.720 --> 04:25.460\n between the big general meta learning\n\n04:25.460 --> 04:27.960\n and a more narrow sense of meta learning\n\n04:27.960 --> 04:30.880\n the way it's used today, the way it's talked about today?\n\n04:30.880 --> 04:33.440\n Let's take the example of a deep neural network\n\n04:33.440 --> 04:37.240\n that has learned to classify images\n\n04:37.240 --> 04:40.060\n and maybe you have trained that network\n\n04:40.060 --> 04:43.840\n on 100 different databases of images.\n\n04:43.840 --> 04:48.080\n And now a new database comes along\n\n04:48.080 --> 04:51.960\n and you want to quickly learn the new thing as well.\n\n04:53.400 --> 04:57.720\n So one simple way of doing that is you take the network\n\n04:57.720 --> 05:02.440\n which already knows 100 types of databases\n\n05:02.440 --> 05:06.320\n and then you just take the top layer of that\n\n05:06.320 --> 05:11.320\n and you retrain that using the new label data\n\n05:11.320 --> 05:14.760\n that you have in the new image database.\n\n05:14.760 --> 05:17.360\n And then it turns out that it really, really quickly\n\n05:17.360 --> 05:20.600\n can learn that too, one shot basically\n\n05:20.600 --> 05:24.320\n because from the first 100 data sets,\n\n05:24.320 --> 05:27.560\n it already has learned so much about computer vision\n\n05:27.560 --> 05:31.880\n that it can reuse that and that is then almost good enough\n\n05:31.880 --> 05:34.240\n to solve the new task except you need a little bit\n\n05:34.240 --> 05:37.080\n of adjustment on the top.\n\n05:38.400 --> 05:41.280\n So that is transfer learning.\n\n05:41.280 --> 05:44.520\n And it has been done in principle for many decades.\n\n05:44.520 --> 05:46.720\n People have done similar things for decades.\n\n05:48.520 --> 05:51.080\n Meta learning too, meta learning is about\n\n05:51.080 --> 05:55.760\n having the learning algorithm itself\n\n05:55.760 --> 06:00.400\n open to introspection by the system that is using it\n\n06:01.560 --> 06:06.320\n and also open to modification such that the learning system\n\n06:06.320 --> 06:09.680\n has an opportunity to modify\n\n06:09.680 --> 06:12.040\n any part of the learning algorithm\n\n06:12.040 --> 06:16.840\n and then evaluate the consequences of that modification\n\n06:16.840 --> 06:21.000\n and then learn from that to create\n\n06:21.000 --> 06:24.800\n a better learning algorithm and so on recursively.\n\n06:25.680 --> 06:28.480\n So that's a very different animal\n\n06:28.480 --> 06:32.440\n where you are opening the space of possible learning\n\n06:32.440 --> 06:35.480\n algorithms to the learning system itself.\n\n06:35.480 --> 06:40.160\n Right, so you've, like in the 2004 paper, you described\n\n06:40.160 --> 06:44.480\n gator machines, programs that rewrite themselves, right?\n\n06:44.480 --> 06:47.480\n Philosophically and even in your paper, mathematically,\n\n06:47.480 --> 06:52.280\n these are really compelling ideas but practically,\n\n06:52.280 --> 06:55.280\n do you see these self referential programs\n\n06:55.280 --> 06:59.360\n being successful in the near term to having an impact\n\n06:59.360 --> 07:02.960\n where sort of it demonstrates to the world\n\n07:02.960 --> 07:07.400\n that this direction is a good one to pursue\n\n07:07.400 --> 07:08.640\n in the near term?\n\n07:08.640 --> 07:11.320\n Yes, we had these two different types\n\n07:11.320 --> 07:13.440\n of fundamental research,\n\n07:13.440 --> 07:15.800\n how to build a universal problem solver,\n\n07:15.800 --> 07:20.320\n one basically exploiting proof search\n\n07:22.960 --> 07:25.520\n and things like that that you need to come up with\n\n07:25.520 --> 07:30.280\n asymptotically optimal, theoretically optimal\n\n07:30.280 --> 07:33.200\n self improvers and problem solvers.\n\n07:34.160 --> 07:39.160\n However, one has to admit that through this proof search\n\n07:40.640 --> 07:44.480\n comes in an additive constant, an overhead,\n\n07:44.480 --> 07:49.480\n an additive overhead that vanishes in comparison\n\n07:50.760 --> 07:55.160\n to what you have to do to solve large problems.\n\n07:55.160 --> 07:58.000\n However, for many of the small problems\n\n07:58.000 --> 08:00.880\n that we want to solve in our everyday life,\n\n08:00.880 --> 08:03.280\n we cannot ignore this constant overhead\n\n08:03.280 --> 08:08.120\n and that's why we also have been doing other things,\n\n08:08.120 --> 08:12.160\n non universal things such as recurrent neural networks\n\n08:12.160 --> 08:15.400\n which are trained by gradient descent\n\n08:15.400 --> 08:18.680\n and local search techniques which aren't universal at all,\n\n08:18.680 --> 08:21.280\n which aren't provably optimal at all,\n\n08:21.280 --> 08:22.840\n like the other stuff that we did,\n\n08:22.840 --> 08:25.400\n but which are much more practical\n\n08:25.400 --> 08:28.760\n as long as we only want to solve the small problems\n\n08:28.760 --> 08:33.320\n that we are typically trying to solve\n\n08:33.320 --> 08:35.600\n in this environment here.\n\n08:35.600 --> 08:38.920\n So the universal problem solvers like the G\u00f6del machine,\n\n08:38.920 --> 08:42.080\n but also Markus Hutter's fastest way\n\n08:42.080 --> 08:44.360\n of solving all possible problems,\n\n08:44.360 --> 08:48.080\n which he developed around 2002 in my lab,\n\n08:49.040 --> 08:52.520\n they are associated with these constant overheads\n\n08:52.520 --> 08:55.160\n for proof search, which guarantees that the thing\n\n08:55.160 --> 08:56.560\n that you're doing is optimal.\n\n08:57.480 --> 09:01.160\n For example, there is this fastest way\n\n09:01.160 --> 09:05.280\n of solving all problems with a computable solution,\n\n09:05.280 --> 09:07.280\n which is due to Markus, Markus Hutter,\n\n09:08.320 --> 09:12.240\n and to explain what's going on there,\n\n09:12.240 --> 09:14.320\n let's take traveling salesman problems.\n\n09:15.720 --> 09:17.360\n With traveling salesman problems,\n\n09:17.360 --> 09:21.320\n you have a number of cities and cities\n\n09:21.320 --> 09:23.680\n and you try to find the shortest path\n\n09:23.680 --> 09:27.800\n through all these cities without visiting any city twice.\n\n09:29.440 --> 09:32.240\n And nobody knows the fastest way\n\n09:32.240 --> 09:36.520\n of solving traveling salesman problems, TSPs,\n\n09:38.720 --> 09:41.720\n but let's assume there is a method of solving them\n\n09:41.720 --> 09:45.840\n within N to the five operations\n\n09:45.840 --> 09:48.520\n where N is the number of cities.\n\n09:48.520 --> 09:53.000\n Then the universal method of Markus\n\n09:53.000 --> 09:57.000\n is going to solve the same traveling salesman problem\n\n09:57.000 --> 10:00.480\n also within N to the five steps,\n\n10:00.480 --> 10:04.760\n plus O of one, plus a constant number of steps\n\n10:04.760 --> 10:07.600\n that you need for the proof searcher,\n\n10:07.600 --> 10:12.600\n which you need to show that this particular class\n\n10:12.600 --> 10:15.680\n of problems, the traveling salesman problems,\n\n10:15.680 --> 10:17.760\n can be solved within a certain time frame,\n\n10:17.760 --> 10:19.560\n solved within a certain time bound,\n\n10:20.680 --> 10:24.560\n within order N to the five steps, basically,\n\n10:24.560 --> 10:28.720\n and this additive constant doesn't care for N,\n\n10:28.720 --> 10:32.600\n which means as N is getting larger and larger,\n\n10:32.600 --> 10:35.080\n as you have more and more cities,\n\n10:35.080 --> 10:38.800\n the constant overhead pales in comparison,\n\n10:38.800 --> 10:43.800\n and that means that almost all large problems are solved\n\n10:44.400 --> 10:45.880\n in the best possible way.\n\n10:45.880 --> 10:50.520\n Today, we already have a universal problem solver like that.\n\n10:50.520 --> 10:54.560\n However, it's not practical because the overhead,\n\n10:54.560 --> 10:57.480\n the constant overhead is so large\n\n10:57.480 --> 11:00.240\n that for the small kinds of problems\n\n11:00.240 --> 11:04.600\n that we want to solve in this little biosphere.\n\n11:04.600 --> 11:06.400\n By the way, when you say small,\n\n11:06.400 --> 11:08.640\n you're talking about things that fall\n\n11:08.640 --> 11:10.880\n within the constraints of our computational systems.\n\n11:10.880 --> 11:14.440\n So they can seem quite large to us mere humans, right?\n\n11:14.440 --> 11:15.360\n That's right, yeah.\n\n11:15.360 --> 11:19.000\n So they seem large and even unsolvable\n\n11:19.000 --> 11:21.040\n in a practical sense today,\n\n11:21.040 --> 11:24.760\n but they are still small compared to almost all problems\n\n11:24.760 --> 11:28.480\n because almost all problems are large problems,\n\n11:28.480 --> 11:30.880\n which are much larger than any constant.\n\n11:31.920 --> 11:34.520\n Do you find it useful as a person\n\n11:34.520 --> 11:38.600\n who has dreamed of creating a general learning system,\n\n11:38.600 --> 11:39.840\n has worked on creating one,\n\n11:39.840 --> 11:42.120\n has done a lot of interesting ideas there,\n\n11:42.120 --> 11:46.320\n to think about P versus NP,\n\n11:46.320 --> 11:50.760\n this formalization of how hard problems are,\n\n11:50.760 --> 11:52.360\n how they scale,\n\n11:52.360 --> 11:55.160\n this kind of worst case analysis type of thinking,\n\n11:55.160 --> 11:56.800\n do you find that useful?\n\n11:56.800 --> 11:59.680\n Or is it only just a mathematical,\n\n12:00.520 --> 12:02.600\n it's a set of mathematical techniques\n\n12:02.600 --> 12:05.720\n to give you intuition about what's good and bad.\n\n12:05.720 --> 12:09.440\n So P versus NP, that's super interesting\n\n12:09.440 --> 12:11.760\n from a theoretical point of view.\n\n12:11.760 --> 12:14.560\n And in fact, as you are thinking about that problem,\n\n12:14.560 --> 12:17.280\n you can also get inspiration\n\n12:17.280 --> 12:21.280\n for better practical problem solvers.\n\n12:21.280 --> 12:23.320\n On the other hand, we have to admit\n\n12:23.320 --> 12:28.320\n that at the moment, the best practical problem solvers\n\n12:28.360 --> 12:31.080\n for all kinds of problems that we are now solving\n\n12:31.080 --> 12:33.840\n through what is called AI at the moment,\n\n12:33.840 --> 12:36.240\n they are not of the kind\n\n12:36.240 --> 12:38.760\n that is inspired by these questions.\n\n12:38.760 --> 12:42.680\n There we are using general purpose computers\n\n12:42.680 --> 12:44.800\n such as recurrent neural networks,\n\n12:44.800 --> 12:46.680\n but we have a search technique\n\n12:46.680 --> 12:50.280\n which is just local search gradient descent\n\n12:50.280 --> 12:51.920\n to try to find a program\n\n12:51.920 --> 12:54.400\n that is running on these recurrent networks,\n\n12:54.400 --> 12:58.200\n such that it can solve some interesting problems\n\n12:58.200 --> 13:01.880\n such as speech recognition or machine translation\n\n13:01.880 --> 13:03.120\n and something like that.\n\n13:03.120 --> 13:08.120\n And there is very little theory behind the best solutions\n\n13:08.120 --> 13:10.840\n that we have at the moment that can do that.\n\n13:10.840 --> 13:12.680\n Do you think that needs to change?\n\n13:12.680 --> 13:14.080\n Do you think that will change?\n\n13:14.080 --> 13:17.160\n Or can we go, can we create a general intelligent systems\n\n13:17.160 --> 13:20.640\n without ever really proving that that system is intelligent\n\n13:20.640 --> 13:22.600\n in some kind of mathematical way,\n\n13:22.600 --> 13:25.000\n solving machine translation perfectly\n\n13:25.000 --> 13:26.320\n or something like that,\n\n13:26.320 --> 13:29.200\n within some kind of syntactic definition of a language,\n\n13:29.200 --> 13:31.160\n or can we just be super impressed\n\n13:31.160 --> 13:35.120\n by the thing working extremely well and that's sufficient?\n\n13:35.120 --> 13:36.760\n There's an old saying,\n\n13:36.760 --> 13:39.360\n and I don't know who brought it up first,\n\n13:39.360 --> 13:42.480\n which says, there's nothing more practical\n\n13:42.480 --> 13:43.720\n than a good theory.\n\n13:43.720 --> 13:48.720\n And a good theory of problem solving\n\n13:52.800 --> 13:54.360\n under limited resources,\n\n13:54.360 --> 13:57.080\n like here in this universe or on this little planet,\n\n13:58.480 --> 14:01.800\n has to take into account these limited resources.\n\n14:01.800 --> 14:06.800\n And so probably there is locking a theory,\n\n14:08.040 --> 14:10.760\n which is related to what we already have,\n\n14:10.760 --> 14:14.400\n these asymptotically optimal problem solvers,\n\n14:14.400 --> 14:18.520\n which tells us what we need in addition to that\n\n14:18.520 --> 14:21.720\n to come up with a practically optimal problem solver.\n\n14:22.640 --> 14:27.040\n So I believe we will have something like that.\n\n14:27.040 --> 14:30.520\n And maybe just a few little tiny twists are necessary\n\n14:30.520 --> 14:34.280\n to change what we already have,\n\n14:34.280 --> 14:36.320\n to come up with that as well.\n\n14:36.320 --> 14:37.720\n As long as we don't have that,\n\n14:37.720 --> 14:42.560\n we admit that we are taking suboptimal ways\n\n14:42.560 --> 14:45.960\n and recurrent neural networks and long short term memory\n\n14:45.960 --> 14:50.400\n for equipped with local search techniques.\n\n14:50.400 --> 14:53.520\n And we are happy that it works better\n\n14:53.520 --> 14:55.480\n than any competing methods,\n\n14:55.480 --> 15:00.480\n but that doesn't mean that we think we are done.\n\n15:00.800 --> 15:02.720\n You've said that an AGI system\n\n15:02.720 --> 15:05.040\n will ultimately be a simple one.\n\n15:05.040 --> 15:06.200\n A general intelligence system\n\n15:06.200 --> 15:08.000\n will ultimately be a simple one.\n\n15:08.000 --> 15:10.240\n Maybe a pseudocode of a few lines\n\n15:10.240 --> 15:11.840\n will be able to describe it.\n\n15:11.840 --> 15:16.760\n Can you talk through your intuition behind this idea,\n\n15:16.760 --> 15:21.480\n why you feel that at its core,\n\n15:21.480 --> 15:25.560\n intelligence is a simple algorithm?\n\n15:26.920 --> 15:31.680\n Experience tells us that the stuff that works best\n\n15:31.680 --> 15:33.120\n is really simple.\n\n15:33.120 --> 15:37.680\n So the asymptotically optimal ways of solving problems,\n\n15:37.680 --> 15:38.800\n if you look at them,\n\n15:38.800 --> 15:41.840\n they're just a few lines of code, it's really true.\n\n15:41.840 --> 15:44.000\n Although they are these amazing properties,\n\n15:44.000 --> 15:45.800\n just a few lines of code.\n\n15:45.800 --> 15:50.800\n Then the most promising and most useful practical things,\n\n15:53.760 --> 15:56.360\n maybe don't have this proof of optimality\n\n15:56.360 --> 15:57.800\n associated with them.\n\n15:57.800 --> 16:00.880\n However, they are also just a few lines of code.\n\n16:00.880 --> 16:05.080\n The most successful recurrent neural networks,\n\n16:05.080 --> 16:08.320\n you can write them down in five lines of pseudocode.\n\n16:08.320 --> 16:10.920\n That's a beautiful, almost poetic idea,\n\n16:10.920 --> 16:15.640\n but what you're describing there\n\n16:15.640 --> 16:18.200\n is the lines of pseudocode are sitting on top\n\n16:18.200 --> 16:22.280\n of layers and layers of abstractions in a sense.\n\n16:22.280 --> 16:25.040\n So you're saying at the very top,\n\n16:25.040 --> 16:29.040\n it'll be a beautifully written sort of algorithm.\n\n16:31.120 --> 16:33.960\n But do you think that there's many layers of abstractions\n\n16:33.960 --> 16:36.880\n we have to first learn to construct?\n\n16:36.880 --> 16:40.400\n Yeah, of course, we are building on all these\n\n16:40.400 --> 16:45.080\n great abstractions that people have invented over the millennia,\n\n16:45.080 --> 16:50.080\n such as matrix multiplications and real numbers\n\n16:50.520 --> 16:55.520\n and basic arithmetics and calculus\n\n16:56.440 --> 17:00.240\n and derivations of error functions\n\n17:00.240 --> 17:03.240\n and derivatives of error functions and stuff like that.\n\n17:04.400 --> 17:09.400\n So without that language that greatly simplifies\n\n17:09.400 --> 17:13.840\n our way of thinking about these problems,\n\n17:13.840 --> 17:14.760\n we couldn't do anything.\n\n17:14.760 --> 17:16.520\n So in that sense, as always,\n\n17:16.520 --> 17:19.520\n we are standing on the shoulders of the giants\n\n17:19.520 --> 17:24.200\n who in the past simplified the problem\n\n17:24.200 --> 17:26.320\n of problem solving so much\n\n17:26.320 --> 17:29.960\n that now we have a chance to do the final step.\n\n17:29.960 --> 17:32.080\n So the final step will be a simple one.\n\n17:33.960 --> 17:36.680\n If we take a step back through all of human civilization\n\n17:36.680 --> 17:40.000\n and just the universe in general,\n\n17:40.000 --> 17:41.400\n how do you think about evolution\n\n17:41.400 --> 17:44.480\n and what if creating a universe\n\n17:44.480 --> 17:47.240\n is required to achieve this final step?\n\n17:47.240 --> 17:50.880\n What if going through the very painful\n\n17:50.880 --> 17:53.800\n and inefficient process of evolution is needed\n\n17:53.800 --> 17:55.800\n to come up with this set of abstractions\n\n17:55.800 --> 17:57.720\n that ultimately lead to intelligence?\n\n17:57.720 --> 18:00.720\n Do you think there's a shortcut\n\n18:00.720 --> 18:04.560\n or do you think we have to create something like our universe\n\n18:04.560 --> 18:07.680\n in order to create something like human level intelligence?\n\n18:09.400 --> 18:13.080\n So far, the only example we have is this one,\n\n18:13.080 --> 18:14.880\n this universe in which we are living.\n\n18:14.880 --> 18:16.240\n Do you think we can do better?\n\n18:20.800 --> 18:24.960\n Maybe not, but we are part of this whole process.\n\n18:24.960 --> 18:29.920\n So apparently, so it might be the case\n\n18:29.920 --> 18:32.080\n that the code that runs the universe\n\n18:32.080 --> 18:33.600\n is really, really simple.\n\n18:33.600 --> 18:35.760\n Everything points to that possibility\n\n18:35.760 --> 18:39.080\n because gravity and other basic forces\n\n18:39.080 --> 18:43.280\n are really simple laws that can be easily described\n\n18:43.280 --> 18:46.240\n also in just a few lines of code basically.\n\n18:46.240 --> 18:51.240\n And then there are these other events\n\n18:51.360 --> 18:54.280\n that the apparently random events\n\n18:54.280 --> 18:55.760\n in the history of the universe,\n\n18:55.760 --> 18:58.000\n which as far as we know at the moment\n\n18:58.000 --> 19:00.600\n don't have a compact code, but who knows?\n\n19:00.600 --> 19:02.440\n Maybe somebody in the near future\n\n19:02.440 --> 19:06.240\n is going to figure out the pseudo random generator\n\n19:06.240 --> 19:11.240\n which is computing whether the measurement\n\n19:11.800 --> 19:15.320\n of that spin up or down thing here\n\n19:15.320 --> 19:17.840\n is going to be positive or negative.\n\n19:17.840 --> 19:19.280\n Underlying quantum mechanics.\n\n19:19.280 --> 19:20.120\n Yes.\n\n19:20.120 --> 19:22.600\n Do you ultimately think quantum mechanics\n\n19:22.600 --> 19:24.640\n is a pseudo random number generator?\n\n19:24.640 --> 19:26.320\n So it's all deterministic.\n\n19:26.320 --> 19:28.200\n There's no randomness in our universe.\n\n19:28.200 --> 19:31.120\n Does God play dice?\n\n19:31.120 --> 19:34.680\n So a couple of years ago, a famous physicist,\n\n19:34.680 --> 19:37.680\n quantum physicist, Anton Zeilinger,\n\n19:37.680 --> 19:40.080\n he wrote an essay in nature\n\n19:40.080 --> 19:42.880\n and it started more or less like that.\n\n19:45.360 --> 19:50.360\n One of the fundamental insights of the 20th century\n\n19:50.360 --> 19:57.360\n was that the universe is fundamentally random\n\n19:57.360 --> 19:58.360\n on the quantum level.\n\n20:00.040 --> 20:04.040\n And that whenever you measure spin up or down\n\n20:04.040 --> 20:05.440\n or something like that,\n\n20:05.440 --> 20:09.440\n a new bit of information enters the history of the universe.\n\n20:12.040 --> 20:13.200\n And while I was reading that,\n\n20:13.200 --> 20:16.560\n I was already typing the response\n\n20:16.560 --> 20:17.880\n and they had to publish it.\n\n20:17.880 --> 20:21.640\n Because I was right, that there is no evidence,\n\n20:21.640 --> 20:25.040\n no physical evidence for that.\n\n20:25.040 --> 20:27.720\n So there's an alternative explanation\n\n20:27.720 --> 20:30.680\n where everything that we consider random\n\n20:30.680 --> 20:33.040\n is actually pseudo random,\n\n20:33.040 --> 20:35.960\n such as the decimal expansion of pi,\n\n20:35.960 --> 20:40.960\n 3.141 and so on, which looks random, but isn't.\n\n20:41.680 --> 20:45.400\n So pi is interesting because every three digits\n\n20:45.400 --> 20:50.400\n sequence, every sequence of three digits\n\n20:50.400 --> 20:53.400\n appears roughly one in a thousand times.\n\n20:53.400 --> 20:57.400\n And every five digit sequence\n\n20:57.400 --> 21:01.080\n appears roughly one in 10,000 times,\n\n21:01.080 --> 21:04.400\n what you would expect if it was random.\n\n21:04.400 --> 21:06.680\n But there's a very short algorithm,\n\n21:06.680 --> 21:09.120\n a short program that computes all of that.\n\n21:09.120 --> 21:11.320\n So it's extremely compressible.\n\n21:11.320 --> 21:12.640\n And who knows, maybe tomorrow,\n\n21:12.640 --> 21:15.640\n somebody, some grad student at CERN goes back\n\n21:15.640 --> 21:20.120\n over all these data points, better decay and whatever,\n\n21:20.120 --> 21:24.760\n and figures out, oh, it's the second billion digits of pi\n\n21:24.760 --> 21:26.040\n or something like that.\n\n21:26.040 --> 21:29.080\n We don't have any fundamental reason at the moment\n\n21:29.080 --> 21:33.600\n to believe that this is truly random\n\n21:33.600 --> 21:36.680\n and not just a deterministic video game.\n\n21:36.680 --> 21:38.680\n If it was a deterministic video game,\n\n21:38.680 --> 21:40.360\n it would be much more beautiful.\n\n21:40.360 --> 21:43.840\n Because beauty is simplicity.\n\n21:43.840 --> 21:47.000\n And many of the basic laws of the universe,\n\n21:47.000 --> 21:51.360\n like gravity and the other basic forces are very simple.\n\n21:51.360 --> 21:55.240\n So very short programs can explain what these are doing.\n\n21:56.760 --> 22:00.560\n And it would be awful and ugly.\n\n22:00.560 --> 22:01.720\n The universe would be ugly.\n\n22:01.720 --> 22:04.000\n The history of the universe would be ugly\n\n22:04.000 --> 22:06.240\n if for the extra things, the random,\n\n22:06.240 --> 22:10.200\n the seemingly random data points that we get all the time,\n\n22:11.080 --> 22:15.160\n that we really need a huge number of extra bits\n\n22:15.160 --> 22:20.160\n to describe all these extra bits of information.\n\n22:22.160 --> 22:24.800\n So as long as we don't have evidence\n\n22:24.800 --> 22:26.920\n that there is no short program\n\n22:26.920 --> 22:31.240\n that computes the entire history of the entire universe,\n\n22:31.240 --> 22:36.240\n we are, as scientists, compelled to look further\n\n22:36.600 --> 22:38.720\n for that shortest program.\n\n22:39.760 --> 22:43.760\n Your intuition says there exists a program\n\n22:43.760 --> 22:47.760\n that can backtrack to the creation of the universe.\n\n22:47.760 --> 22:48.600\n Yeah.\n\n22:48.600 --> 22:49.440\n So it can give the shortest path\n\n22:49.440 --> 22:50.480\n to the creation of the universe.\n\n22:50.480 --> 22:51.320\n Yes.\n\n22:51.320 --> 22:54.480\n Including all the entanglement things\n\n22:54.480 --> 22:57.800\n and all the spin up and down measures\n\n22:57.800 --> 23:02.800\n that have been taken place since 13.8 billion years ago.\n\n23:06.840 --> 23:11.840\n So we don't have a proof that it is random.\n\n23:11.840 --> 23:15.600\n We don't have a proof that it is compressible\n\n23:15.600 --> 23:16.760\n to a short program.\n\n23:16.760 --> 23:18.240\n But as long as we don't have that proof,\n\n23:18.240 --> 23:21.680\n we are obliged as scientists to keep looking\n\n23:21.680 --> 23:23.600\n for that simple explanation.\n\n23:23.600 --> 23:24.440\n Absolutely.\n\n23:24.440 --> 23:27.880\n So you said the simplicity is beautiful or beauty is simple.\n\n23:27.880 --> 23:29.440\n Either one works.\n\n23:29.440 --> 23:33.440\n But you also work on curiosity, discovery,\n\n23:34.560 --> 23:39.000\n the romantic notion of randomness, of serendipity,\n\n23:39.000 --> 23:44.000\n of being surprised by things that are about you.\n\n23:45.920 --> 23:49.600\n In our poetic notion of reality,\n\n23:49.600 --> 23:51.640\n we think it's kind of like,\n\n23:51.640 --> 23:54.920\n poetic notion of reality, we think as humans\n\n23:54.920 --> 23:56.400\n require randomness.\n\n23:56.400 --> 23:59.000\n So you don't find randomness beautiful.\n\n23:59.000 --> 24:04.000\n You find simple determinism beautiful.\n\n24:04.880 --> 24:05.720\n Yeah.\n\n24:05.720 --> 24:07.520\n Okay.\n\n24:07.520 --> 24:08.560\n So why?\n\n24:08.560 --> 24:09.400\n Why?\n\n24:09.400 --> 24:13.040\n Because the explanation becomes shorter.\n\n24:13.040 --> 24:18.040\n A universe that is compressible to a short program\n\n24:18.040 --> 24:22.040\n is much more elegant and much more beautiful\n\n24:22.040 --> 24:25.040\n than another one, which needs an almost infinite\n\n24:25.040 --> 24:28.040\n number of bits to be described.\n\n24:28.040 --> 24:32.040\n As far as we know, many things that are happening\n\n24:32.040 --> 24:35.040\n in this universe are really simple in terms of\n\n24:35.040 --> 24:38.040\n short programs that compute gravity\n\n24:38.040 --> 24:43.040\n and the interaction between elementary particles and so on.\n\n24:43.040 --> 24:45.040\n So all of that seems to be very, very simple.\n\n24:45.040 --> 24:50.040\n Every electron seems to reuse the same subprogram\n\n24:50.040 --> 24:52.040\n all the time, as it is interacting with\n\n24:52.040 --> 24:55.040\n other elementary particles.\n\n24:58.040 --> 25:05.040\n If we now require an extra oracle injecting\n\n25:05.040 --> 25:08.040\n new bits of information all the time for these\n\n25:08.040 --> 25:11.040\n extra things which are currently not understood,\n\n25:11.040 --> 25:22.040\n such as better decay, then the whole description\n\n25:22.040 --> 25:26.040\n length of the data that we can observe of the\n\n25:26.040 --> 25:31.040\n history of the universe would become much longer\n\n25:31.040 --> 25:33.040\n and therefore uglier.\n\n25:33.040 --> 25:34.040\n And uglier.\n\n25:34.040 --> 25:38.040\n Again, simplicity is elegant and beautiful.\n\n25:38.040 --> 25:42.040\n The history of science is a history of compression progress.\n\n25:42.040 --> 25:47.040\n Yes, so you've described sort of as we build up\n\n25:47.040 --> 25:50.040\n abstractions and you've talked about the idea\n\n25:50.040 --> 25:52.040\n of compression.\n\n25:52.040 --> 25:55.040\n How do you see this, the history of science,\n\n25:55.040 --> 25:58.040\n the history of humanity, our civilization,\n\n25:58.040 --> 26:02.040\n and life on Earth as some kind of path towards\n\n26:02.040 --> 26:04.040\n greater and greater compression?\n\n26:04.040 --> 26:05.040\n What do you mean by that?\n\n26:05.040 --> 26:06.040\n How do you think about that?\n\n26:06.040 --> 26:10.040\n Indeed, the history of science is a history of\n\n26:10.040 --> 26:12.040\n compression progress.\n\n26:12.040 --> 26:14.040\n What does that mean?\n\n26:14.040 --> 26:17.040\n Hundreds of years ago there was an astronomer\n\n26:17.040 --> 26:21.040\n whose name was Kepler and he looked at the data\n\n26:21.040 --> 26:25.040\n points that he got by watching planets move.\n\n26:25.040 --> 26:27.040\n And then he had all these data points and\n\n26:27.040 --> 26:30.040\n suddenly it turned out that he can greatly\n\n26:30.040 --> 26:36.040\n compress the data by predicting it through an\n\n26:36.040 --> 26:38.040\n ellipse law.\n\n26:38.040 --> 26:40.040\n So it turns out that all these data points are\n\n26:40.040 --> 26:45.040\n more or less on ellipses around the sun.\n\n26:45.040 --> 26:48.040\n And another guy came along whose name was\n\n26:48.040 --> 26:51.040\n Newton and before him Hooke.\n\n26:51.040 --> 26:55.040\n And they said the same thing that is making\n\n26:55.040 --> 27:00.040\n these planets move like that is what makes the\n\n27:00.040 --> 27:02.040\n apples fall down.\n\n27:02.040 --> 27:08.040\n And it also holds for stones and for all kinds\n\n27:08.040 --> 27:11.040\n of other objects.\n\n27:11.040 --> 27:15.040\n And suddenly many, many of these observations\n\n27:15.040 --> 27:17.040\n became much more compressible because as long\n\n27:17.040 --> 27:20.040\n as you can predict the next thing, given what\n\n27:20.040 --> 27:23.040\n you have seen so far, you can compress it.\n\n27:23.040 --> 27:25.040\n And you don't have to store that data extra.\n\n27:25.040 --> 27:29.040\n This is called predictive coding.\n\n27:29.040 --> 27:31.040\n And then there was still something wrong with\n\n27:31.040 --> 27:34.040\n that theory of the universe and you had\n\n27:34.040 --> 27:37.040\n deviations from these predictions of the theory.\n\n27:37.040 --> 27:40.040\n And 300 years later another guy came along\n\n27:40.040 --> 27:42.040\n whose name was Einstein.\n\n27:42.040 --> 27:46.040\n And he was able to explain away all these\n\n27:46.040 --> 27:50.040\n deviations from the predictions of the old\n\n27:50.040 --> 27:54.040\n theory through a new theory which was called\n\n27:54.040 --> 27:57.040\n the general theory of relativity.\n\n27:57.040 --> 28:00.040\n Which at first glance looks a little bit more\n\n28:00.040 --> 28:03.040\n complicated and you have to warp space and time\n\n28:03.040 --> 28:05.040\n but you can't phrase it within one single\n\n28:05.040 --> 28:08.040\n sentence which is no matter how fast you\n\n28:08.040 --> 28:14.040\n accelerate and how hard you decelerate and no\n\n28:14.040 --> 28:18.040\n matter what is the gravity in your local\n\n28:18.040 --> 28:21.040\n network, light speed always looks the same.\n\n28:21.040 --> 28:24.040\n And from that you can calculate all the\n\n28:24.040 --> 28:25.040\n consequences.\n\n28:25.040 --> 28:27.040\n So it's a very simple thing and it allows you\n\n28:27.040 --> 28:30.040\n to further compress all the observations\n\n28:30.040 --> 28:34.040\n because certainly there are hardly any\n\n28:34.040 --> 28:37.040\n deviations any longer that you can measure\n\n28:37.040 --> 28:40.040\n from the predictions of this new theory.\n\n28:40.040 --> 28:44.040\n So all of science is a history of compression\n\n28:44.040 --> 28:45.040\n progress.\n\n28:45.040 --> 28:48.040\n You never arrive immediately at the shortest\n\n28:48.040 --> 28:51.040\n explanation of the data but you're making\n\n28:51.040 --> 28:52.040\n progress.\n\n28:52.040 --> 28:55.040\n Whenever you are making progress you have an\n\n28:55.040 --> 28:56.040\n insight.\n\n28:56.040 --> 28:59.040\n You see oh first I needed so many bits of\n\n28:59.040 --> 29:02.040\n information to describe the data, to describe\n\n29:02.040 --> 29:04.040\n my falling apples, my video of falling apples,\n\n29:04.040 --> 29:07.040\n I need so many data, so many pixels have to be\n\n29:07.040 --> 29:08.040\n stored.\n\n29:08.040 --> 29:11.040\n But then suddenly I realize no there is a very\n\n29:11.040 --> 29:14.040\n simple way of predicting the third frame in the\n\n29:14.040 --> 29:16.040\n video from the first two.\n\n29:16.040 --> 29:19.040\n And maybe not every little detail can be\n\n29:19.040 --> 29:21.040\n predicted but more or less most of these orange\n\n29:21.040 --> 29:24.040\n blobs that are coming down they accelerate in\n\n29:24.040 --> 29:27.040\n the same way which means that I can greatly\n\n29:27.040 --> 29:28.040\n compress the video.\n\n29:28.040 --> 29:33.040\n And the amount of compression, progress, that\n\n29:33.040 --> 29:36.040\n is the depth of the insight that you have at\n\n29:36.040 --> 29:37.040\n that moment.\n\n29:37.040 --> 29:39.040\n That's the fun that you have, the scientific\n\n29:39.040 --> 29:42.040\n fun, the fun in that discovery.\n\n29:42.040 --> 29:45.040\n And we can build artificial systems that do\n\n29:45.040 --> 29:46.040\n the same thing.\n\n29:46.040 --> 29:49.040\n They measure the depth of their insights as they\n\n29:49.040 --> 29:51.040\n are looking at the data which is coming in\n\n29:51.040 --> 29:54.040\n through their own experiments and we give\n\n29:54.040 --> 29:58.040\n them a reward, an intrinsic reward in proportion\n\n29:58.040 --> 30:00.040\n to this depth of insight.\n\n30:00.040 --> 30:05.040\n And since they are trying to maximize the\n\n30:05.040 --> 30:09.040\n rewards they get they are suddenly motivated to\n\n30:09.040 --> 30:13.040\n come up with new action sequences, with new\n\n30:13.040 --> 30:16.040\n experiments that have the property that the data\n\n30:16.040 --> 30:19.040\n that is coming in as a consequence of these\n\n30:19.040 --> 30:23.040\n experiments has the property that they can learn\n\n30:23.040 --> 30:25.040\n something about, see a pattern in there which\n\n30:25.040 --> 30:28.040\n they hadn't seen yet before.\n\n30:28.040 --> 30:31.040\n So there is an idea of power play that you\n\n30:31.040 --> 30:34.040\n described, a training in general problem solver\n\n30:34.040 --> 30:36.040\n in this kind of way of looking for the unsolved\n\n30:36.040 --> 30:37.040\n problems.\n\n30:37.040 --> 30:38.040\n Yeah.\n\n30:38.040 --> 30:40.040\n Can you describe that idea a little further?\n\n30:40.040 --> 30:42.040\n It's another very simple idea.\n\n30:42.040 --> 30:45.040\n So normally what you do in computer science,\n\n30:45.040 --> 30:50.040\n you have some guy who gives you a problem and\n\n30:50.040 --> 30:55.040\n then there is a huge search space of potential\n\n30:55.040 --> 30:59.040\n solution candidates and you somehow try them\n\n30:59.040 --> 31:02.040\n out and you have more less sophisticated ways\n\n31:02.040 --> 31:07.040\n of moving around in that search space until\n\n31:07.040 --> 31:10.040\n you finally found a solution which you\n\n31:10.040 --> 31:12.040\n consider satisfactory.\n\n31:12.040 --> 31:15.040\n That's what most of computer science is about.\n\n31:15.040 --> 31:18.040\n Power play just goes one little step further\n\n31:18.040 --> 31:23.040\n and says let's not only search for solutions\n\n31:23.040 --> 31:28.040\n to a given problem but let's search to pairs of\n\n31:28.040 --> 31:31.040\n problems and their solutions where the system\n\n31:31.040 --> 31:35.040\n itself has the opportunity to phrase its own\n\n31:35.040 --> 31:37.040\n problem.\n\n31:37.040 --> 31:40.040\n So we are looking suddenly at pairs of\n\n31:40.040 --> 31:44.040\n problems and their solutions or modifications\n\n31:44.040 --> 31:47.040\n of the problem solver that is supposed to\n\n31:47.040 --> 31:51.040\n generate a solution to that new problem.\n\n31:51.040 --> 31:57.040\n And this additional degree of freedom allows\n\n31:57.040 --> 32:00.040\n us to build career systems that are like\n\n32:00.040 --> 32:04.040\n scientists in the sense that they not only\n\n32:04.040 --> 32:07.040\n try to solve and try to find answers to\n\n32:07.040 --> 32:11.040\n existing questions, no they are also free to\n\n32:11.040 --> 32:13.040\n pose their own questions.\n\n32:13.040 --> 32:15.040\n So if you want to build an artificial scientist\n\n32:15.040 --> 32:17.040\n you have to give it that freedom and power\n\n32:17.040 --> 32:19.040\n play is exactly doing that.\n\n32:19.040 --> 32:22.040\n So that's a dimension of freedom that's\n\n32:22.040 --> 32:25.040\n important to have but how hard do you think\n\n32:25.040 --> 32:31.040\n that, how multidimensional and difficult the\n\n32:31.040 --> 32:34.040\n space of then coming up with your own questions\n\n32:34.040 --> 32:35.040\n is.\n\n32:35.040 --> 32:37.040\n So it's one of the things that as human beings\n\n32:37.040 --> 32:40.040\n we consider to be the thing that makes us\n\n32:40.040 --> 32:42.040\n special, the intelligence that makes us special\n\n32:42.040 --> 32:46.040\n is that brilliant insight that can create\n\n32:46.040 --> 32:48.040\n something totally new.\n\n32:48.040 --> 32:49.040\n Yes.\n\n32:49.040 --> 32:52.040\n So now let's look at the extreme case, let's\n\n32:52.040 --> 32:56.040\n look at the set of all possible problems that\n\n32:56.040 --> 33:00.040\n you can formally describe which is infinite,\n\n33:00.040 --> 33:05.040\n which should be the next problem that a scientist\n\n33:05.040 --> 33:08.040\n or power play is going to solve.\n\n33:08.040 --> 33:14.040\n Well, it should be the easiest problem that\n\n33:14.040 --> 33:17.040\n goes beyond what you already know.\n\n33:17.040 --> 33:21.040\n So it should be the simplest problem that the\n\n33:21.040 --> 33:23.040\n current problem solver that you have which can\n\n33:23.040 --> 33:28.040\n already solve 100 problems that he cannot solve\n\n33:28.040 --> 33:30.040\n yet by just generalizing.\n\n33:30.040 --> 33:33.040\n So it has to be new, so it has to require a\n\n33:33.040 --> 33:36.040\n modification of the problem solver such that the\n\n33:36.040 --> 33:39.040\n new problem solver can solve this new thing but\n\n33:39.040 --> 33:42.040\n the old problem solver cannot do it and in\n\n33:42.040 --> 33:46.040\n addition to that we have to make sure that the\n\n33:46.040 --> 33:49.040\n problem solver doesn't forget any of the\n\n33:49.040 --> 33:50.040\n previous solutions.\n\n33:50.040 --> 33:51.040\n Right.\n\n33:51.040 --> 33:54.040\n And so by definition power play is now trying\n\n33:54.040 --> 33:58.040\n always to search in this pair of, in the set of\n\n33:58.040 --> 34:02.040\n pairs of problems and problems over modifications\n\n34:02.040 --> 34:06.040\n for a combination that minimize the time to\n\n34:06.040 --> 34:08.040\n achieve these criteria.\n\n34:08.040 --> 34:11.040\n So it's always trying to find the problem which\n\n34:11.040 --> 34:14.040\n is easiest to add to the repertoire.\n\n34:14.040 --> 34:18.040\n So just like grad students and academics and\n\n34:18.040 --> 34:20.040\n researchers can spend their whole career in a\n\n34:20.040 --> 34:24.040\n local minima stuck trying to come up with\n\n34:24.040 --> 34:26.040\n interesting questions but ultimately doing very\n\n34:26.040 --> 34:27.040\n little.\n\n34:27.040 --> 34:31.040\n Do you think it's easy in this approach of\n\n34:31.040 --> 34:33.040\n looking for the simplest unsolvable problem to\n\n34:33.040 --> 34:35.040\n get stuck in a local minima?\n\n34:35.040 --> 34:40.040\n Is not never really discovering new, you know\n\n34:40.040 --> 34:42.040\n really jumping outside of the 100 problems that\n\n34:42.040 --> 34:47.040\n you've already solved in a genuine creative way?\n\n34:47.040 --> 34:50.040\n No, because that's the nature of power play that\n\n34:50.040 --> 34:53.040\n it's always trying to break its current\n\n34:53.040 --> 34:57.040\n generalization abilities by coming up with a new\n\n34:57.040 --> 35:00.040\n problem which is beyond the current horizon.\n\n35:00.040 --> 35:04.040\n Just shifting the horizon of knowledge a little\n\n35:04.040 --> 35:08.040\n bit out there, breaking the existing rules such\n\n35:08.040 --> 35:11.040\n that the new thing becomes solvable but wasn't\n\n35:11.040 --> 35:13.040\n solvable by the old thing.\n\n35:13.040 --> 35:17.040\n So like adding a new axiom like what G\u00f6del did\n\n35:17.040 --> 35:21.040\n when he came up with these new sentences, new\n\n35:21.040 --> 35:23.040\n theorems that didn't have a proof in the formal\n\n35:23.040 --> 35:25.040\n system which means you can add them to the\n\n35:25.040 --> 35:31.040\n repertoire hoping that they are not going to\n\n35:31.040 --> 35:35.040\n damage the consistency of the whole thing.\n\n35:35.040 --> 35:39.040\n So in the paper with the amazing title,\n\n35:39.040 --> 35:43.040\n Formal Theory of Creativity, Fun and Intrinsic\n\n35:43.040 --> 35:46.040\n Motivation, you talk about discovery as intrinsic\n\n35:46.040 --> 35:50.040\n reward, so if you view humans as intelligent\n\n35:50.040 --> 35:53.040\n agents, what do you think is the purpose and\n\n35:53.040 --> 35:56.040\n meaning of life for us humans?\n\n35:56.040 --> 35:59.040\n You've talked about this discovery, do you see\n\n35:59.040 --> 36:04.040\n humans as an instance of power play, agents?\n\n36:04.040 --> 36:10.040\n Humans are curious and that means they behave\n\n36:10.040 --> 36:13.040\n like scientists, not only the official scientists\n\n36:13.040 --> 36:16.040\n but even the babies behave like scientists and\n\n36:16.040 --> 36:19.040\n they play around with their toys to figure out\n\n36:19.040 --> 36:22.040\n how the world works and how it is responding to\n\n36:22.040 --> 36:25.040\n their actions and that's how they learn about\n\n36:25.040 --> 36:27.040\n gravity and everything.\n\n36:27.040 --> 36:31.040\n In 1990 we had the first systems like that which\n\n36:31.040 --> 36:34.040\n would just try to play around with the environment\n\n36:34.040 --> 36:38.040\n and come up with situations that go beyond what\n\n36:38.040 --> 36:41.040\n they knew at that time and then get a reward for\n\n36:41.040 --> 36:44.040\n creating these situations and then becoming more\n\n36:44.040 --> 36:47.040\n general problem solvers and being able to understand\n\n36:47.040 --> 36:49.040\n more of the world.\n\n36:49.040 --> 37:01.040\n I think in principle that curiosity strategy or\n\n37:01.040 --> 37:03.040\n more sophisticated versions of what I just\n\n37:03.040 --> 37:07.040\n described, they are what we have built in as well\n\n37:07.040 --> 37:10.040\n because evolution discovered that's a good way of\n\n37:10.040 --> 37:13.040\n exploring the unknown world and a guy who explores\n\n37:13.040 --> 37:17.040\n the unknown world has a higher chance of solving\n\n37:17.040 --> 37:20.040\n the mystery that he needs to survive in this world.\n\n37:20.040 --> 37:24.040\n On the other hand, those guys who were too curious\n\n37:24.040 --> 37:27.040\n they were weeded out as well so you have to find\n\n37:27.040 --> 37:28.040\n this trade off.\n\n37:28.040 --> 37:30.040\n Evolution found a certain trade off.\n\n37:30.040 --> 37:33.040\n Apparently in our society there is a certain\n\n37:33.040 --> 37:37.040\n percentage of extremely explorative guys and it\n\n37:37.040 --> 37:40.040\n doesn't matter if they die because many of the\n\n37:40.040 --> 37:45.040\n others are more conservative.\n\n37:45.040 --> 37:51.040\n It would be surprising to me if that principle of\n\n37:51.040 --> 37:56.040\n artificial curiosity wouldn't be present in almost\n\n37:56.040 --> 37:58.040\n exactly the same form here.\n\n37:58.040 --> 38:00.040\n In our brains.\n\n38:00.040 --> 38:03.040\n You are a bit of a musician and an artist.\n\n38:03.040 --> 38:08.040\n Continuing on this topic of creativity, what do you\n\n38:08.040 --> 38:10.040\n think is the role of creativity and intelligence?\n\n38:10.040 --> 38:15.040\n So you've kind of implied that it's essential for\n\n38:15.040 --> 38:18.040\n intelligence if you think of intelligence as a\n\n38:18.040 --> 38:23.040\n problem solving system, as ability to solve problems.\n\n38:23.040 --> 38:26.040\n But do you think it's essential, this idea of\n\n38:26.040 --> 38:27.040\n creativity?\n\n38:27.040 --> 38:32.040\n We never have a program, a sub program that is\n\n38:32.040 --> 38:34.040\n called creativity or something.\n\n38:34.040 --> 38:37.040\n It's just a side effect of what our problem solvers\n\n38:37.040 --> 38:41.040\n do. They are searching a space of problems, a space\n\n38:41.040 --> 38:45.040\n of candidates, of solution candidates until they\n\n38:45.040 --> 38:48.040\n hopefully find a solution to a given problem.\n\n38:48.040 --> 38:50.040\n But then there are these two types of creativity\n\n38:50.040 --> 38:54.040\n and both of them are now present in our machines.\n\n38:54.040 --> 38:56.040\n The first one has been around for a long time,\n\n38:56.040 --> 39:00.040\n which is human gives problem to machine, machine\n\n39:00.040 --> 39:03.040\n tries to find a solution to that.\n\n39:03.040 --> 39:06.040\n And this has been happening for many decades and\n\n39:06.040 --> 39:09.040\n for many decades machines have found creative\n\n39:09.040 --> 39:12.040\n solutions to interesting problems where humans were\n\n39:12.040 --> 39:17.040\n not aware of these particularly creative solutions\n\n39:17.040 --> 39:20.040\n but then appreciated that the machine found that.\n\n39:20.040 --> 39:23.040\n The second is the pure creativity.\n\n39:23.040 --> 39:26.040\n That I would call, what I just mentioned, I would\n\n39:26.040 --> 39:30.040\n call the applied creativity, like applied art where\n\n39:30.040 --> 39:34.040\n somebody tells you now make a nice picture of this\n\n39:34.040 --> 39:37.040\n Pope and you will get money for that.\n\n39:37.040 --> 39:40.040\n So here is the artist and he makes a convincing\n\n39:40.040 --> 39:43.040\n picture of the Pope and the Pope likes it and gives\n\n39:43.040 --> 39:46.040\n him the money.\n\n39:46.040 --> 39:49.040\n And then there is the pure creativity which is\n\n39:49.040 --> 39:51.040\n more like the power play and the artificial\n\n39:51.040 --> 39:54.040\n curiosity thing where you have the freedom to\n\n39:54.040 --> 39:57.040\n select your own problem.\n\n39:57.040 --> 40:02.040\n Like a scientist who defines his own question\n\n40:02.040 --> 40:06.040\n to study and so that is the pure creativity if you\n\n40:06.040 --> 40:11.040\n will as opposed to the applied creativity which\n\n40:11.040 --> 40:14.040\n serves another.\n\n40:14.040 --> 40:16.040\n And in that distinction there is almost echoes of\n\n40:16.040 --> 40:19.040\n narrow AI versus general AI.\n\n40:19.040 --> 40:22.040\n So this kind of constrained painting of a Pope\n\n40:22.040 --> 40:28.040\n seems like the approaches of what people are\n\n40:28.040 --> 40:33.040\n calling narrow AI and pure creativity seems to be,\n\n40:33.040 --> 40:35.040\n maybe I am just biased as a human but it seems to\n\n40:35.040 --> 40:41.040\n be an essential element of human level intelligence.\n\n40:41.040 --> 40:44.040\n Is that what you are implying?\n\n40:44.040 --> 40:46.040\n To a degree?\n\n40:46.040 --> 40:49.040\n If you zoom back a little bit and you just look\n\n40:49.040 --> 40:51.040\n at a general problem solving machine which is\n\n40:51.040 --> 40:54.040\n trying to solve arbitrary problems then this\n\n40:54.040 --> 40:57.040\n machine will figure out in the course of solving\n\n40:57.040 --> 41:00.040\n problems that it is good to be curious.\n\n41:00.040 --> 41:04.040\n So all of what I said just now about this prewired\n\n41:04.040 --> 41:07.040\n curiosity and this will to invent new problems\n\n41:07.040 --> 41:11.040\n that the system doesn't know how to solve yet\n\n41:11.040 --> 41:15.040\n should be just a byproduct of the general search.\n\n41:15.040 --> 41:20.040\n However, apparently evolution has built it into\n\n41:20.040 --> 41:24.040\n us because it turned out to be so successful,\n\n41:24.040 --> 41:29.040\n a prewiring, a bias, a very successful exploratory\n\n41:29.040 --> 41:34.040\n bias that we are born with.\n\n41:34.040 --> 41:36.040\n And you have also said that consciousness in the\n\n41:36.040 --> 41:41.040\n same kind of way may be a byproduct of problem solving.\n\n41:41.040 --> 41:45.040\n Do you find this an interesting byproduct?\n\n41:45.040 --> 41:47.040\n Do you think it is a useful byproduct?\n\n41:47.040 --> 41:49.040\n What are your thoughts on consciousness in general?\n\n41:49.040 --> 41:53.040\n Or is it simply a byproduct of greater and greater\n\n41:53.040 --> 41:58.040\n capabilities of problem solving that is similar\n\n41:58.040 --> 42:01.040\n to creativity in that sense?\n\n42:01.040 --> 42:04.040\n We never have a procedure called consciousness\n\n42:04.040 --> 42:05.040\n in our machines.\n\n42:05.040 --> 42:09.040\n However, we get as side effects of what these\n\n42:09.040 --> 42:13.040\n machines are doing things that seem to be closely\n\n42:13.040 --> 42:16.040\n related to what people call consciousness.\n\n42:16.040 --> 42:20.040\n So for example, already in 1990 we had simple\n\n42:20.040 --> 42:24.040\n systems which were basically recurrent networks\n\n42:24.040 --> 42:28.040\n and therefore universal computers trying to map\n\n42:28.040 --> 42:33.040\n incoming data into actions that lead to success.\n\n42:33.040 --> 42:36.040\n Maximizing reward in a given environment,\n\n42:36.040 --> 42:40.040\n always finding the charging station in time\n\n42:40.040 --> 42:42.040\n whenever the battery is low and negative signals\n\n42:42.040 --> 42:45.040\n are coming from the battery, always find the\n\n42:45.040 --> 42:48.040\n charging station in time without bumping against\n\n42:48.040 --> 42:50.040\n painful obstacles on the way.\n\n42:50.040 --> 42:54.040\n So complicated things but very easily motivated.\n\n42:54.040 --> 43:00.040\n And then we give these little guys a separate\n\n43:00.040 --> 43:02.040\n recurrent neural network which is just predicting\n\n43:02.040 --> 43:04.040\n what's happening if I do that and that.\n\n43:04.040 --> 43:07.040\n What will happen as a consequence of these\n\n43:07.040 --> 43:09.040\n actions that I'm executing.\n\n43:09.040 --> 43:11.040\n And it's just trained on the long and long history\n\n43:11.040 --> 43:13.040\n of interactions with the world.\n\n43:13.040 --> 43:16.040\n So it becomes a predictive model of the world\n\n43:16.040 --> 43:18.040\n basically.\n\n43:18.040 --> 43:22.040\n And therefore also a compressor of the observations\n\n43:22.040 --> 43:25.040\n of the world because whatever you can predict\n\n43:25.040 --> 43:27.040\n you don't have to store extra.\n\n43:27.040 --> 43:30.040\n So compression is a side effect of prediction.\n\n43:30.040 --> 43:33.040\n And how does this recurrent network compress?\n\n43:33.040 --> 43:36.040\n Well, it's inventing little subprograms, little\n\n43:36.040 --> 43:39.040\n subnetworks that stand for everything that\n\n43:39.040 --> 43:42.040\n frequently appears in the environment like\n\n43:42.040 --> 43:45.040\n bottles and microphones and faces, maybe lots of\n\n43:45.040 --> 43:50.040\n faces in my environment so I'm learning to create\n\n43:50.040 --> 43:52.040\n something like a prototype face and a new face\n\n43:52.040 --> 43:54.040\n comes along and all I have to encode are the\n\n43:54.040 --> 43:56.040\n deviations from the prototype.\n\n43:56.040 --> 43:58.040\n So it's compressing all the time the stuff that\n\n43:58.040 --> 44:00.040\n frequently appears.\n\n44:00.040 --> 44:05.040\n There's one thing that appears all the time that\n\n44:05.040 --> 44:07.040\n is present all the time when the agent is\n\n44:07.040 --> 44:10.040\n interacting with its environment which is the\n\n44:10.040 --> 44:12.040\n agent itself.\n\n44:12.040 --> 44:15.040\n But just for data compression reasons it is\n\n44:15.040 --> 44:18.040\n extremely natural for this recurrent network to\n\n44:18.040 --> 44:21.040\n come up with little subnetworks that stand for\n\n44:21.040 --> 44:26.040\n the properties of the agents, the hand, the other\n\n44:26.040 --> 44:29.040\n actuators and all the stuff that you need to\n\n44:29.040 --> 44:32.040\n better encode the data which is influenced by\n\n44:32.040 --> 44:34.040\n the actions of the agent.\n\n44:34.040 --> 44:39.040\n So there just as a side effect of data compression\n\n44:39.040 --> 44:43.040\n during problem solving you have internal self\n\n44:43.040 --> 44:45.040\n models.\n\n44:45.040 --> 44:50.040\n Now you can use this model of the world to plan\n\n44:50.040 --> 44:53.040\n your future and that's what we also have done\n\n44:53.040 --> 44:54.040\n since 1990.\n\n44:54.040 --> 44:57.040\n So the recurrent network which is the controller\n\n44:57.040 --> 45:00.040\n which is trying to maximize reward can use this\n\n45:00.040 --> 45:03.040\n model of the network of the world, this model\n\n45:03.040 --> 45:05.040\n network of the world, this predictive model of\n\n45:05.040 --> 45:08.040\n the world to plan ahead and say let's not do this\n\n45:08.040 --> 45:10.040\n action sequence, let's do this action sequence\n\n45:10.040 --> 45:13.040\n instead because it leads to more predicted\n\n45:13.040 --> 45:14.040\n reward.\n\n45:14.040 --> 45:17.040\n And whenever it is waking up these little\n\n45:17.040 --> 45:20.040\n subnetworks that stand for itself then it is\n\n45:20.040 --> 45:23.040\n thinking about itself and it is thinking about\n\n45:23.040 --> 45:28.040\n itself and it is exploring mentally the\n\n45:28.040 --> 45:34.040\n consequences of its own actions and now you tell\n\n45:34.040 --> 45:36.040\n me what is still missing.\n\n45:36.040 --> 45:40.040\n Missing the next, the gap to consciousness.\n\n45:40.040 --> 45:41.040\n There isn't.\n\n45:41.040 --> 45:45.040\n That's a really beautiful idea that if life is\n\n45:45.040 --> 45:48.040\n a collection of data and life is a process of\n\n45:48.040 --> 45:54.040\n compressing that data to act efficiently in that\n\n45:54.040 --> 45:57.040\n data you yourself appear very often.\n\n45:57.040 --> 46:00.040\n So it's useful to form compressions of yourself\n\n46:00.040 --> 46:03.040\n and it's a really beautiful formulation of what\n\n46:03.040 --> 46:05.040\n consciousness is a necessary side effect.\n\n46:05.040 --> 46:11.040\n It's actually quite compelling to me.\n\n46:11.040 --> 46:16.040\n You've described RNNs, developed LSTMs, long\n\n46:16.040 --> 46:20.040\n short term memory networks that are a type of\n\n46:20.040 --> 46:23.040\n recurrent neural networks that have gotten a lot\n\n46:23.040 --> 46:24.040\n of success recently.\n\n46:24.040 --> 46:27.040\n So these are networks that model the temporal\n\n46:27.040 --> 46:30.040\n aspects in the data, temporal patterns in the\n\n46:30.040 --> 46:34.040\n data and you've called them the deepest of the\n\n46:34.040 --> 46:35.040\n neural networks.\n\n46:35.040 --> 46:38.040\n So what do you think is the value of depth in\n\n46:38.040 --> 46:41.040\n the models that we use to learn?\n\n46:41.040 --> 46:46.040\n Since you mentioned the long short term memory\n\n46:46.040 --> 46:50.040\n and the LSTM I have to mention the names of the\n\n46:50.040 --> 46:52.040\n brilliant students who made that possible.\n\n46:52.040 --> 46:56.040\n First of all my first student ever Sepp Hochreiter\n\n46:56.040 --> 46:58.040\n who had fundamental insights already in his\n\n46:58.040 --> 46:59.040\n diploma thesis.\n\n46:59.040 --> 47:03.040\n Then Felix Geers who had additional important\n\n47:03.040 --> 47:04.040\n contributions.\n\n47:04.040 --> 47:08.040\n Alex Gray is a guy from Scotland who is mostly\n\n47:08.040 --> 47:11.040\n responsible for this CTC algorithm which is now\n\n47:11.040 --> 47:15.040\n often used to train the LSTM to do the speech\n\n47:15.040 --> 47:18.040\n recognition on all the Google Android phones and\n\n47:18.040 --> 47:21.040\n whatever and Siri and so on.\n\n47:21.040 --> 47:26.040\n So these guys without these guys I would be\n\n47:26.040 --> 47:27.040\n nothing.\n\n47:27.040 --> 47:29.040\n It's a lot of incredible work.\n\n47:29.040 --> 47:30.040\n What is now the depth?\n\n47:30.040 --> 47:32.040\n What is the importance of depth?\n\n47:32.040 --> 47:36.040\n Well most problems in the real world are deep in\n\n47:36.040 --> 47:40.040\n the sense that the current input doesn't tell you\n\n47:40.040 --> 47:44.040\n all you need to know about the environment.\n\n47:44.040 --> 47:48.040\n So instead you have to have a memory of what\n\n47:48.040 --> 47:51.040\n happened in the past and often important parts of\n\n47:51.040 --> 47:54.040\n that memory are dated.\n\n47:54.040 --> 47:56.040\n They are pretty old.\n\n47:56.040 --> 47:59.040\n So when you're doing speech recognition for\n\n47:59.040 --> 48:05.040\n example and somebody says 11 then that's about\n\n48:05.040 --> 48:09.040\n half a second or something like that which means\n\n48:09.040 --> 48:11.040\n it's already 50 time steps.\n\n48:11.040 --> 48:15.040\n And another guy or the same guy says 7.\n\n48:15.040 --> 48:19.040\n So the ending is the same even but now the\n\n48:19.040 --> 48:22.040\n system has to see the distinction between 7 and\n\n48:22.040 --> 48:25.040\n 11 and the only way it can see the difference is\n\n48:25.040 --> 48:30.040\n it has to store that 50 steps ago there was an\n\n48:30.040 --> 48:34.040\n S or an L, 11 or 7.\n\n48:34.040 --> 48:37.040\n So there you have already a problem of depth 50\n\n48:37.040 --> 48:41.040\n because for each time step you have something\n\n48:41.040 --> 48:44.040\n like a virtual layer in the expanded unrolled\n\n48:44.040 --> 48:46.040\n version of this recurrent network which is doing\n\n48:46.040 --> 48:48.040\n the speech recognition.\n\n48:48.040 --> 48:51.040\n So these long time lags they translate into\n\n48:51.040 --> 48:53.040\n problem depth.\n\n48:53.040 --> 48:57.040\n And most problems in this world are such that\n\n48:57.040 --> 49:01.040\n you really have to look far back in time to\n\n49:01.040 --> 49:05.040\n understand what is the problem and to solve it.\n\n49:05.040 --> 49:08.040\n But just like with LSTMs you don't necessarily\n\n49:08.040 --> 49:11.040\n need to when you look back in time remember every\n\n49:11.040 --> 49:13.040\n aspect you just need to remember the important\n\n49:13.040 --> 49:14.040\n aspects.\n\n49:14.040 --> 49:15.040\n That's right.\n\n49:15.040 --> 49:18.040\n The network has to learn to put the important\n\n49:18.040 --> 49:22.040\n stuff into memory and to ignore the unimportant\n\n49:22.040 --> 49:23.040\n noise.\n\n49:23.040 --> 49:28.040\n But in that sense deeper and deeper is better\n\n49:28.040 --> 49:30.040\n or is there a limitation?\n\n49:30.040 --> 49:34.040\n I mean LSTM is one of the great examples of\n\n49:34.040 --> 49:40.040\n architectures that do something beyond just\n\n49:40.040 --> 49:42.040\n deeper and deeper networks.\n\n49:42.040 --> 49:45.040\n There's clever mechanisms for filtering data,\n\n49:45.040 --> 49:47.040\n for remembering and forgetting.\n\n49:47.040 --> 49:50.040\n So do you think that kind of thinking is\n\n49:50.040 --> 49:51.040\n necessary?\n\n49:51.040 --> 49:54.040\n If you think about LSTMs as a leap, a big leap\n\n49:54.040 --> 49:57.040\n forward over traditional vanilla RNNs, what do\n\n49:57.040 --> 50:02.040\n you think is the next leap within this context?\n\n50:02.040 --> 50:06.040\n So LSTM is a very clever improvement but LSTM\n\n50:06.040 --> 50:10.040\n still don't have the same kind of ability to see\n\n50:10.040 --> 50:14.040\n far back in the past as us humans do.\n\n50:14.040 --> 50:18.040\n The credit assignment problem across way back\n\n50:18.040 --> 50:22.040\n not just 50 time steps or 100 or 1000 but\n\n50:22.040 --> 50:24.040\n millions and billions.\n\n50:24.040 --> 50:28.040\n It's not clear what are the practical limits of\n\n50:28.040 --> 50:31.040\n the LSTM when it comes to looking back.\n\n50:31.040 --> 50:35.040\n Already in 2006 I think we had examples where\n\n50:35.040 --> 50:38.040\n it not only looked back tens of thousands of\n\n50:38.040 --> 50:41.040\n steps but really millions of steps.\n\n50:41.040 --> 50:45.040\n And Juan Perez Ortiz in my lab I think was the\n\n50:45.040 --> 50:49.040\n first author of a paper where we really, was it\n\n50:49.040 --> 50:53.040\n 2006 or something, had examples where it learned\n\n50:53.040 --> 50:57.040\n to look back for more than 10 million steps.\n\n50:57.040 --> 51:01.040\n So for most problems of speech recognition it's\n\n51:01.040 --> 51:05.040\n not necessary to look that far back but there\n\n51:05.040 --> 51:07.040\n are examples where it does.\n\n51:07.040 --> 51:11.040\n Now the looking back thing, that's rather easy\n\n51:11.040 --> 51:15.040\n because there is only one past but there are\n\n51:15.040 --> 51:19.040\n many possible futures and so a reinforcement\n\n51:19.040 --> 51:22.040\n learning system which is trying to maximize its\n\n51:22.040 --> 51:26.040\n future expected reward and doesn't know yet which\n\n51:26.040 --> 51:29.040\n of these many possible futures should I select\n\n51:29.040 --> 51:33.040\n given this one single past is facing problems\n\n51:33.040 --> 51:36.040\n that the LSTM by itself cannot solve.\n\n51:36.040 --> 51:40.040\n So the LSTM is good for coming up with a compact\n\n51:40.040 --> 51:44.040\n representation of the history and observations\n\n51:44.040 --> 51:49.040\n and actions so far but now how do you plan in an\n\n51:49.040 --> 51:54.040\n efficient and good way among all these, how do\n\n51:54.040 --> 51:57.040\n you select one of these many possible action\n\n51:57.040 --> 52:00.040\n sequences that a reinforcement learning system\n\n52:00.040 --> 52:04.040\n has to consider to maximize reward in this\n\n52:04.040 --> 52:06.040\n unknown future?\n\n52:06.040 --> 52:10.040\n We have this basic setup where you have one\n\n52:10.040 --> 52:14.040\n recurrent network which gets in the video and\n\n52:14.040 --> 52:17.040\n the speech and whatever and it's executing\n\n52:17.040 --> 52:20.040\n actions and it's trying to maximize reward so\n\n52:20.040 --> 52:23.040\n there is no teacher who tells it what to do at\n\n52:23.040 --> 52:25.040\n which point in time.\n\n52:25.040 --> 52:29.040\n And then there's the other network which is\n\n52:29.040 --> 52:32.040\n just predicting what's going to happen if I do\n\n52:32.040 --> 52:35.040\n that and that and that could be an LSTM network\n\n52:35.040 --> 52:38.040\n and it learns to look back all the way to make\n\n52:38.040 --> 52:41.040\n better predictions of the next time step.\n\n52:41.040 --> 52:44.040\n So essentially although it's predicting only the\n\n52:44.040 --> 52:48.040\n next time step it is motivated to learn to put\n\n52:48.040 --> 52:51.040\n into memory something that happened maybe a\n\n52:51.040 --> 52:54.040\n million steps ago because it's important to\n\n52:54.040 --> 52:57.040\n memorize that if you want to predict that at the\n\n52:57.040 --> 52:59.040\n next time step, the next event.\n\n52:59.040 --> 53:03.040\n Now how can a model of the world like that, a\n\n53:03.040 --> 53:06.040\n predictive model of the world be used by the\n\n53:06.040 --> 53:07.040\n first guy?\n\n53:07.040 --> 53:10.040\n Let's call it the controller and the model, the\n\n53:10.040 --> 53:12.040\n controller and the model.\n\n53:12.040 --> 53:15.040\n How can the model be used by the controller to\n\n53:15.040 --> 53:18.040\n efficiently select among these many possible\n\n53:18.040 --> 53:19.040\n futures?\n\n53:19.040 --> 53:22.040\n The naive way we had about 30 years ago was\n\n53:22.040 --> 53:26.040\n let's just use the model of the world as a stand\n\n53:26.040 --> 53:30.040\n in, as a simulation of the world and millisecond\n\n53:30.040 --> 53:33.040\n by millisecond we plan the future and that means\n\n53:33.040 --> 53:36.040\n we have to roll it out really in detail and it\n\n53:36.040 --> 53:39.040\n will work only if the model is really good and\n\n53:39.040 --> 53:42.040\n it will still be inefficient because we have to\n\n53:42.040 --> 53:45.040\n look at all these possible futures and there are\n\n53:45.040 --> 53:46.040\n so many of them.\n\n53:46.040 --> 53:49.040\n So instead what we do now since 2015 in our CM\n\n53:49.040 --> 53:52.040\n systems, controller model systems, we give the\n\n53:52.040 --> 53:56.040\n controller the opportunity to learn by itself how\n\n53:56.040 --> 54:00.040\n to use the potentially relevant parts of the M,\n\n54:00.040 --> 54:04.040\n of the model network to solve new problems more\n\n54:04.040 --> 54:05.040\n quickly.\n\n54:05.040 --> 54:09.040\n And if it wants to, it can learn to ignore the M\n\n54:09.040 --> 54:12.040\n and sometimes it's a good idea to ignore the M\n\n54:12.040 --> 54:15.040\n because it's really bad, it's a bad predictor in\n\n54:15.040 --> 54:19.040\n this particular situation of life where the\n\n54:19.040 --> 54:22.040\n controller is currently trying to maximize reward.\n\n54:22.040 --> 54:26.040\n However, it can also learn to address and exploit\n\n54:26.040 --> 54:31.040\n some of the subprograms that came about in the\n\n54:31.040 --> 54:35.040\n model network through compressing the data by\n\n54:35.040 --> 54:36.040\n predicting it.\n\n54:36.040 --> 54:40.040\n So it now has an opportunity to reuse that code,\n\n54:40.040 --> 54:44.040\n the algorithmic information in the model network\n\n54:44.040 --> 54:49.040\n to reduce its own search space such that it can\n\n54:49.040 --> 54:52.040\n solve a new problem more quickly than without the\n\n54:52.040 --> 54:53.040\n model.\n\n54:53.040 --> 54:54.040\n Compression.\n\n54:54.040 --> 54:59.040\n So you're ultimately optimistic and excited about\n\n54:59.040 --> 55:03.040\n the power of RL, of reinforcement learning in the\n\n55:03.040 --> 55:05.040\n context of real systems.\n\n55:05.040 --> 55:06.040\n Absolutely, yeah.\n\n55:06.040 --> 55:11.040\n So you see RL as a potential having a huge impact\n\n55:11.040 --> 55:16.040\n beyond just sort of the M part is often developed on\n\n55:16.040 --> 55:19.040\n supervised learning methods.\n\n55:19.040 --> 55:25.040\n You see RL as a for problems of self driving cars\n\n55:25.040 --> 55:28.040\n or any kind of applied cyber robotics.\n\n55:28.040 --> 55:32.040\n That's the correct interesting direction for\n\n55:32.040 --> 55:34.040\n research in your view?\n\n55:34.040 --> 55:35.040\n I do think so.\n\n55:35.040 --> 55:40.040\n We have a company called Nasence which has applied\n\n55:40.040 --> 55:45.040\n reinforcement learning to little Audis which learn\n\n55:45.040 --> 55:47.040\n to park without a teacher.\n\n55:47.040 --> 55:50.040\n The same principles were used of course.\n\n55:50.040 --> 55:54.040\n So these little Audis, they are small, maybe like\n\n55:54.040 --> 55:57.040\n that, so much smaller than the real Audis.\n\n55:57.040 --> 56:00.040\n But they have all the sensors that you find in the\n\n56:00.040 --> 56:01.040\n real Audis.\n\n56:01.040 --> 56:03.040\n You find the cameras, the LIDAR sensors.\n\n56:03.040 --> 56:08.040\n They go up to 120 kilometers an hour if they want\n\n56:08.040 --> 56:09.040\n to.\n\n56:09.040 --> 56:13.040\n And they have pain sensors basically and they don't\n\n56:13.040 --> 56:17.040\n want to bump against obstacles and other Audis and\n\n56:17.040 --> 56:21.040\n so they must learn like little babies to park.\n\n56:21.040 --> 56:25.040\n Take the raw vision input and translate that into\n\n56:25.040 --> 56:28.040\n actions that lead to successful parking behavior\n\n56:28.040 --> 56:30.040\n which is a rewarding thing.\n\n56:30.040 --> 56:32.040\n And yes, they learn that.\n\n56:32.040 --> 56:36.040\n So we have examples like that and it's only in the\n\n56:36.040 --> 56:37.040\n beginning.\n\n56:37.040 --> 56:40.040\n This is just the tip of the iceberg and I believe the\n\n56:40.040 --> 56:44.040\n next wave of AI is going to be all about that.\n\n56:44.040 --> 56:48.040\n So at the moment, the current wave of AI is about\n\n56:48.040 --> 56:53.040\n passive pattern observation and prediction and that's\n\n56:53.040 --> 56:56.040\n what you have on your smartphone and what the major\n\n56:56.040 --> 57:00.040\n companies on the Pacific Rim are using to sell you\n\n57:00.040 --> 57:02.040\n ads to do marketing.\n\n57:02.040 --> 57:05.040\n That's the current sort of profit in AI and that's\n\n57:05.040 --> 57:08.040\n only one or two percent of the world economy.\n\n57:08.040 --> 57:12.040\n Which is big enough to make these companies pretty\n\n57:12.040 --> 57:15.040\n much the most valuable companies in the world.\n\n57:15.040 --> 57:19.040\n But there's a much, much bigger fraction of the\n\n57:19.040 --> 57:22.040\n economy going to be affected by the next wave which\n\n57:22.040 --> 57:26.040\n is really about machines that shape the data through\n\n57:26.040 --> 57:27.040\n their own actions.\n\n57:27.040 --> 57:31.040\n Do you think simulation is ultimately the biggest\n\n57:31.040 --> 57:35.040\n way that those methods will be successful in the next\n\n57:35.040 --> 57:36.040\n 10, 20 years?\n\n57:36.040 --> 57:38.040\n We're not talking about 100 years from now.\n\n57:38.040 --> 57:41.040\n We're talking about sort of the near term impact of\n\n57:41.040 --> 57:42.040\n RL.\n\n57:42.040 --> 57:45.040\n Do you think really good simulation is required or\n\n57:45.040 --> 57:48.040\n is there other techniques like imitation learning,\n\n57:48.040 --> 57:53.040\n observing other humans operating in the real world?\n\n57:53.040 --> 57:57.040\n Where do you think the success will come from?\n\n57:57.040 --> 58:02.040\n So at the moment, we have a tendency of using physics\n\n58:02.040 --> 58:07.040\n simulations to learn behavior from machines that\n\n58:07.040 --> 58:11.040\n learn to solve problems that humans also do not know\n\n58:11.040 --> 58:12.040\n how to solve.\n\n58:12.040 --> 58:16.040\n However, this is not the future because the future is\n\n58:16.040 --> 58:18.040\n in what little babies do.\n\n58:18.040 --> 58:21.040\n They don't use a physics engine to simulate the\n\n58:21.040 --> 58:22.040\n world.\n\n58:22.040 --> 58:26.040\n No, they learn a predictive model of the world which\n\n58:26.040 --> 58:31.040\n maybe sometimes is wrong in many ways but captures\n\n58:31.040 --> 58:34.040\n all kinds of important abstract high level predictions\n\n58:34.040 --> 58:37.040\n which are really important to be successful.\n\n58:37.040 --> 58:42.040\n And that's what was the future 30 years ago when we\n\n58:42.040 --> 58:45.040\n started that type of research but it's still the future\n\n58:45.040 --> 58:49.040\n and now we know much better how to go there to move\n\n58:49.040 --> 58:54.040\n forward and to really make working systems based on\n\n58:54.040 --> 58:57.040\n that where you have a learning model of the world,\n\n58:57.040 --> 58:59.040\n a model of the world that learns to predict what's\n\n58:59.040 --> 59:01.040\n going to happen if I do that and that.\n\n59:01.040 --> 59:07.040\n And then the controller uses that model to more\n\n59:07.040 --> 59:10.040\n quickly learn successful action sequences.\n\n59:10.040 --> 59:13.040\n And then of course always this curiosity thing.\n\n59:13.040 --> 59:15.040\n In the beginning, the model is stupid so the\n\n59:15.040 --> 59:18.040\n controller should be motivated to come up with\n\n59:18.040 --> 59:21.040\n experiments with action sequences that lead to data\n\n59:21.040 --> 59:23.040\n that improve the model.\n\n59:23.040 --> 59:27.040\n Do you think improving the model, constructing an\n\n59:27.040 --> 59:30.040\n understanding of the world in this connection is\n\n59:30.040 --> 59:34.040\n now the popular approaches that have been successful\n\n59:34.040 --> 59:38.040\n are grounded in ideas of neural networks.\n\n59:38.040 --> 59:41.040\n But in the 80s with expert systems, there's\n\n59:41.040 --> 59:45.040\n symbolic AI approaches which to us humans are more\n\n59:45.040 --> 59:49.040\n intuitive in the sense that it makes sense that you\n\n59:49.040 --> 59:52.040\n build up knowledge in this knowledge representation.\n\n59:52.040 --> 59:54.040\n What kind of lessons can we draw into our current\n\n59:54.040 --> 1:00:00.040\n approaches from expert systems from symbolic AI?\n\n1:00:00.040 --> 1:00:04.040\n So I became aware of all of that in the 80s and\n\n1:00:04.040 --> 1:00:08.040\n back then logic programming was a huge thing.\n\n1:00:08.040 --> 1:00:10.040\n Was it inspiring to you yourself?\n\n1:00:10.040 --> 1:00:12.040\n Did you find it compelling?\n\n1:00:12.040 --> 1:00:16.040\n Because a lot of your work was not so much in that\n\n1:00:16.040 --> 1:00:17.040\n realm, right?\n\n1:00:17.040 --> 1:00:18.040\n It was more in the learning systems.\n\n1:00:18.040 --> 1:00:20.040\n Yes and no, but we did all of that.\n\n1:00:20.040 --> 1:00:27.040\n So my first publication ever actually was 1987,\n\n1:00:27.040 --> 1:00:31.040\n was the implementation of genetic algorithm of a\n\n1:00:31.040 --> 1:00:34.040\n genetic programming system in Prolog.\n\n1:00:34.040 --> 1:00:38.040\n So Prolog, that's what you learn back then which is\n\n1:00:38.040 --> 1:00:41.040\n a logic programming language and the Japanese,\n\n1:00:41.040 --> 1:00:45.040\n they have this huge fifth generation AI project\n\n1:00:45.040 --> 1:00:49.040\n which was mostly about logic programming back then.\n\n1:00:49.040 --> 1:00:52.040\n Although neural networks existed and were well\n\n1:00:52.040 --> 1:00:56.040\n known back then and deep learning has existed since\n\n1:00:56.040 --> 1:01:00.040\n 1965, since this guy in the Ukraine,\n\n1:01:00.040 --> 1:01:02.040\n Iwakunenko, started it.\n\n1:01:02.040 --> 1:01:05.040\n But the Japanese and many other people,\n\n1:01:05.040 --> 1:01:08.040\n they focused really on this logic programming and I\n\n1:01:08.040 --> 1:01:10.040\n was influenced to the extent that I said,\n\n1:01:10.040 --> 1:01:13.040\n okay, let's take these biologically inspired\n\n1:01:13.040 --> 1:01:20.040\n algorithms like evolution, programs,\n\n1:01:20.040 --> 1:01:22.040\n and implement that in the language which I know,\n\n1:01:22.040 --> 1:01:25.040\n which was Prolog, for example, back then.\n\n1:01:25.040 --> 1:01:29.040\n And then in many ways this came back later because\n\n1:01:29.040 --> 1:01:31.040\n the G\u00f6del machine, for example,\n\n1:01:31.040 --> 1:01:34.040\n has a proof searcher on board and without that it\n\n1:01:34.040 --> 1:01:36.040\n would not be optimal.\n\n1:01:36.040 --> 1:01:38.040\n Well, Markus Futter's universal algorithm for\n\n1:01:38.040 --> 1:01:41.040\n solving all well defined problems has a proof\n\n1:01:41.040 --> 1:01:46.040\n searcher on board so that's very much logic programming.\n\n1:01:46.040 --> 1:01:50.040\n Without that it would not be asymptotically optimal.\n\n1:01:50.040 --> 1:01:51.040\n But then on the other hand,\n\n1:01:51.040 --> 1:01:54.040\n because we are very pragmatic guys also,\n\n1:01:54.040 --> 1:02:00.040\n we focused on recurrent neural networks and\n\n1:02:00.040 --> 1:02:04.040\n suboptimal stuff such as gradient based search and\n\n1:02:04.040 --> 1:02:09.040\n program space rather than provably optimal things.\n\n1:02:09.040 --> 1:02:13.040\n The logic programming certainly has a usefulness\n\n1:02:13.040 --> 1:02:16.040\n when you're trying to construct something provably\n\n1:02:16.040 --> 1:02:19.040\n optimal or provably good or something like that.\n\n1:02:19.040 --> 1:02:22.040\n But is it useful for practical problems?\n\n1:02:22.040 --> 1:02:24.040\n It's really useful for our theorem proving.\n\n1:02:24.040 --> 1:02:28.040\n The best theorem provers today are not neural networks.\n\n1:02:28.040 --> 1:02:31.040\n No, they are logic programming systems and they\n\n1:02:31.040 --> 1:02:35.040\n are much better theorem provers than most math\n\n1:02:35.040 --> 1:02:38.040\n students in the first or second semester.\n\n1:02:38.040 --> 1:02:43.040\n But for reasoning, for playing games of Go or chess\n\n1:02:43.040 --> 1:02:46.040\n or for robots, autonomous vehicles that operate in\n\n1:02:46.040 --> 1:02:49.040\n the real world or object manipulation,\n\n1:02:49.040 --> 1:02:51.040\n you think learning.\n\n1:02:51.040 --> 1:02:54.040\n Yeah, as long as the problems have little to do\n\n1:02:54.040 --> 1:02:58.040\n with theorem proving themselves,\n\n1:02:58.040 --> 1:03:01.040\n then as long as that is not the case,\n\n1:03:01.040 --> 1:03:05.040\n you just want to have better pattern recognition.\n\n1:03:05.040 --> 1:03:07.040\n So to build a self driving car,\n\n1:03:07.040 --> 1:03:10.040\n you want to have better pattern recognition and\n\n1:03:10.040 --> 1:03:14.040\n pedestrian recognition and all these things.\n\n1:03:14.040 --> 1:03:19.040\n You want to minimize the number of false positives,\n\n1:03:19.040 --> 1:03:21.040\n which is currently slowing down self driving cars\n\n1:03:21.040 --> 1:03:23.040\n in many ways.\n\n1:03:23.040 --> 1:03:27.040\n All of that has very little to do with logic programming.\n\n1:03:27.040 --> 1:03:32.040\n What are you most excited about in terms of\n\n1:03:32.040 --> 1:03:35.040\n directions of artificial intelligence at this moment\n\n1:03:35.040 --> 1:03:38.040\n in the next few years in your own research\n\n1:03:38.040 --> 1:03:41.040\n and in the broader community?\n\n1:03:41.040 --> 1:03:44.040\n So I think in the not so distant future,\n\n1:03:44.040 --> 1:03:50.040\n we will have for the first time little robots\n\n1:03:50.040 --> 1:03:53.040\n that learn like kids.\n\n1:03:53.040 --> 1:03:57.040\n I will be able to say to the robot,\n\n1:03:57.040 --> 1:04:01.040\n look here robot, we are going to assemble a smartphone.\n\n1:04:01.040 --> 1:04:05.040\n Let's take this slab of plastic and the screwdriver\n\n1:04:05.040 --> 1:04:09.040\n and let's screw in the screw like that.\n\n1:04:09.040 --> 1:04:11.040\n Not like that, like that.\n\n1:04:11.040 --> 1:04:14.040\n Not like that, like that.\n\n1:04:14.040 --> 1:04:17.040\n And I don't have a data glove or something.\n\n1:04:17.040 --> 1:04:20.040\n He will see me and he will hear me\n\n1:04:20.040 --> 1:04:24.040\n and he will try to do something with his own actuators,\n\n1:04:24.040 --> 1:04:26.040\n which will be really different from mine,\n\n1:04:26.040 --> 1:04:28.040\n but he will understand the difference\n\n1:04:28.040 --> 1:04:31.040\n and will learn to imitate me,\n\n1:04:31.040 --> 1:04:34.040\n but not in the supervised way\n\n1:04:34.040 --> 1:04:37.040\n where a teacher is giving target signals\n\n1:04:37.040 --> 1:04:40.040\n for all his muscles all the time.\n\n1:04:40.040 --> 1:04:43.040\n No, by doing this high level imitation\n\n1:04:43.040 --> 1:04:46.040\n where he first has to learn to imitate me\n\n1:04:46.040 --> 1:04:48.040\n and then to interpret these additional noises\n\n1:04:48.040 --> 1:04:51.040\n coming from my mouth as helping,\n\n1:04:51.040 --> 1:04:54.040\n helpful signals to do that better.\n\n1:04:54.040 --> 1:05:00.040\n And then it will by itself come up with faster ways\n\n1:05:00.040 --> 1:05:03.040\n and more efficient ways of doing the same thing.\n\n1:05:03.040 --> 1:05:07.040\n And finally I stop his learning algorithm\n\n1:05:07.040 --> 1:05:10.040\n and make a million copies and sell it.\n\n1:05:10.040 --> 1:05:13.040\n And so at the moment this is not possible,\n\n1:05:13.040 --> 1:05:16.040\n but we already see how we are going to get there.\n\n1:05:16.040 --> 1:05:19.040\n And you can imagine to the extent\n\n1:05:19.040 --> 1:05:22.040\n that this works economically and cheaply,\n\n1:05:22.040 --> 1:05:25.040\n it's going to change everything.\n\n1:05:25.040 --> 1:05:31.040\n Almost all of production is going to be affected by that.\n\n1:05:31.040 --> 1:05:34.040\n And a much bigger wave,\n\n1:05:34.040 --> 1:05:36.040\n a much bigger AI wave is coming\n\n1:05:36.040 --> 1:05:38.040\n than the one that we are currently witnessing,\n\n1:05:38.040 --> 1:05:40.040\n which is mostly about passive pattern recognition\n\n1:05:40.040 --> 1:05:42.040\n on your smartphone.\n\n1:05:42.040 --> 1:05:45.040\n This is about active machines that shapes data\n\n1:05:45.040 --> 1:05:48.040\n through the actions they are executing\n\n1:05:48.040 --> 1:05:52.040\n and they learn to do that in a good way.\n\n1:05:52.040 --> 1:05:55.040\n So many of the traditional industries\n\n1:05:55.040 --> 1:05:57.040\n are going to be affected by that.\n\n1:05:57.040 --> 1:06:01.040\n All the companies that are building machines\n\n1:06:01.040 --> 1:06:04.040\n will equip these machines with cameras\n\n1:06:04.040 --> 1:06:08.040\n and other sensors and they are going to learn\n\n1:06:08.040 --> 1:06:11.040\n to solve all kinds of problems\n\n1:06:11.040 --> 1:06:13.040\n through interaction with humans,\n\n1:06:13.040 --> 1:06:15.040\n but also a lot on their own\n\n1:06:15.040 --> 1:06:20.040\n to improve what they already can do.\n\n1:06:20.040 --> 1:06:24.040\n And lots of old economy is going to be affected by that.\n\n1:06:24.040 --> 1:06:27.040\n And in recent years I have seen that old economy\n\n1:06:27.040 --> 1:06:32.040\n is actually waking up and realizing that this is the case.\n\n1:06:32.040 --> 1:06:34.040\n Are you optimistic about that future?\n\n1:06:34.040 --> 1:06:36.040\n Are you concerned?\n\n1:06:36.040 --> 1:06:38.040\n There is a lot of people concerned in the near term\n\n1:06:38.040 --> 1:06:43.040\n about the transformation of the nature of work,\n\n1:06:43.040 --> 1:06:45.040\n the kind of ideas that you just suggested\n\n1:06:45.040 --> 1:06:47.040\n would have a significant impact\n\n1:06:47.040 --> 1:06:49.040\n of what kind of things could be automated.\n\n1:06:49.040 --> 1:06:52.040\n Are you optimistic about that future?\n\n1:06:52.040 --> 1:06:54.040\n Are you nervous about that future?\n\n1:06:54.040 --> 1:06:58.040\n And looking a little bit farther into the future,\n\n1:06:58.040 --> 1:07:02.040\n there are people like Gila Musk, Stuart Russell,\n\n1:07:02.040 --> 1:07:06.040\n concerned about the existential threats of that future.\n\n1:07:06.040 --> 1:07:08.040\n So in the near term, job loss,\n\n1:07:08.040 --> 1:07:10.040\n in the long term existential threat,\n\n1:07:10.040 --> 1:07:15.040\n are these concerns to you or are you ultimately optimistic?\n\n1:07:15.040 --> 1:07:22.040\n So let's first address the near future.\n\n1:07:22.040 --> 1:07:28.040\n We have had predictions of job losses for many decades.\n\n1:07:28.040 --> 1:07:33.040\n For example, when industrial robots came along,\n\n1:07:33.040 --> 1:07:38.040\n many people predicted that lots of jobs are going to get lost.\n\n1:07:38.040 --> 1:07:42.040\n And in a sense, they were right,\n\n1:07:42.040 --> 1:07:46.040\n because back then there were car factories\n\n1:07:46.040 --> 1:07:51.040\n and hundreds of people in these factories assembled cars,\n\n1:07:51.040 --> 1:07:54.040\n and today the same car factories have hundreds of robots\n\n1:07:54.040 --> 1:07:59.040\n and maybe three guys watching the robots.\n\n1:07:59.040 --> 1:08:05.040\n On the other hand, those countries that have lots of robots per capita,\n\n1:08:05.040 --> 1:08:07.040\n Japan, Korea, Germany, Switzerland,\n\n1:08:07.040 --> 1:08:10.040\n and a couple of other countries,\n\n1:08:10.040 --> 1:08:14.040\n they have really low unemployment rates.\n\n1:08:14.040 --> 1:08:18.040\n Somehow, all kinds of new jobs were created.\n\n1:08:18.040 --> 1:08:23.040\n Back then, nobody anticipated those jobs.\n\n1:08:23.040 --> 1:08:27.040\n And decades ago, I always said,\n\n1:08:27.040 --> 1:08:32.040\n it's really easy to say which jobs are going to get lost,\n\n1:08:32.040 --> 1:08:36.040\n but it's really hard to predict the new ones.\n\n1:08:36.040 --> 1:08:40.040\n 200 years ago, who would have predicted all these people\n\n1:08:40.040 --> 1:08:46.040\n making money as YouTube bloggers, for example?\n\n1:08:46.040 --> 1:08:54.040\n 200 years ago, 60% of all people used to work in agriculture.\n\n1:08:54.040 --> 1:08:57.040\n Today, maybe 1%.\n\n1:08:57.040 --> 1:09:02.040\n But still, only, I don't know, 5% unemployment.\n\n1:09:02.040 --> 1:09:08.040\n Lots of new jobs were created, and Homo Ludens, the playing man,\n\n1:09:08.040 --> 1:09:11.040\n is inventing new jobs all the time.\n\n1:09:11.040 --> 1:09:16.040\n Most of these jobs are not existentially necessary\n\n1:09:16.040 --> 1:09:19.040\n for the survival of our species.\n\n1:09:19.040 --> 1:09:23.040\n There are only very few existentially necessary jobs,\n\n1:09:23.040 --> 1:09:28.040\n such as farming and building houses and warming up the houses,\n\n1:09:28.040 --> 1:09:31.040\n but less than 10% of the population is doing that.\n\n1:09:31.040 --> 1:09:35.040\n And most of these newly invented jobs are about\n\n1:09:35.040 --> 1:09:38.040\n interacting with other people in new ways,\n\n1:09:38.040 --> 1:09:41.040\n through new media and so on,\n\n1:09:41.040 --> 1:09:46.040\n getting new types of kudos and forms of likes and whatever,\n\n1:09:46.040 --> 1:09:48.040\n and even making money through that.\n\n1:09:48.040 --> 1:09:53.040\n So, Homo Ludens, the playing man, doesn't want to be unemployed,\n\n1:09:53.040 --> 1:09:57.040\n and that's why he's inventing new jobs all the time.\n\n1:09:57.040 --> 1:10:02.040\n And he keeps considering these jobs as really important\n\n1:10:02.040 --> 1:10:08.040\n and is investing a lot of energy and hours of work into those new jobs.\n\n1:10:08.040 --> 1:10:10.040\n That's quite beautifully put.\n\n1:10:10.040 --> 1:10:13.040\n We're really nervous about the future because we can't predict\n\n1:10:13.040 --> 1:10:15.040\n what kind of new jobs will be created.\n\n1:10:15.040 --> 1:10:21.040\n But you're ultimately optimistic that we humans are so restless\n\n1:10:21.040 --> 1:10:25.040\n that we create and give meaning to newer and newer jobs,\n\n1:10:25.040 --> 1:10:29.040\n totally new, things that get likes on Facebook\n\n1:10:29.040 --> 1:10:32.040\n or whatever the social platform is.\n\n1:10:32.040 --> 1:10:36.040\n So what about long term existential threat of AI,\n\n1:10:36.040 --> 1:10:41.040\n where our whole civilization may be swallowed up\n\n1:10:41.040 --> 1:10:45.040\n by these ultra super intelligent systems?\n\n1:10:45.040 --> 1:10:48.040\n Maybe it's not going to be swallowed up,\n\n1:10:48.040 --> 1:10:55.040\n but I'd be surprised if we humans were the last step\n\n1:10:55.040 --> 1:10:58.040\n in the evolution of the universe.\n\n1:10:58.040 --> 1:11:05.040\n You've actually had this beautiful comment somewhere that I've seen\n\n1:11:05.040 --> 1:11:12.040\n saying that, quite insightful, artificial general intelligence systems,\n\n1:11:12.040 --> 1:11:16.040\n just like us humans, will likely not want to interact with humans,\n\n1:11:16.040 --> 1:11:18.040\n they'll just interact amongst themselves.\n\n1:11:18.040 --> 1:11:21.040\n Just like ants interact amongst themselves\n\n1:11:21.040 --> 1:11:25.040\n and only tangentially interact with humans.\n\n1:11:25.040 --> 1:11:29.040\n And it's quite an interesting idea that once we create AGI,\n\n1:11:29.040 --> 1:11:34.040\n they will lose interest in humans and compete for their own Facebook likes\n\n1:11:34.040 --> 1:11:36.040\n and their own social platforms.\n\n1:11:36.040 --> 1:11:45.040\n So within that quite elegant idea, how do we know in a hypothetical sense\n\n1:11:45.040 --> 1:11:49.040\n that there's not already intelligence systems out there?\n\n1:11:49.040 --> 1:11:54.040\n How do you think broadly of general intelligence greater than us?\n\n1:11:54.040 --> 1:11:56.040\n How do we know it's out there?\n\n1:11:56.040 --> 1:11:59.040\n How do we know it's around us?\n\n1:11:59.040 --> 1:12:01.040\n And could it already be?\n\n1:12:01.040 --> 1:12:07.040\n I'd be surprised if within the next few decades or something like that,\n\n1:12:07.040 --> 1:12:13.040\n we won't have AIs that are truly smart in every single way\n\n1:12:13.040 --> 1:12:17.040\n and better problem solvers in almost every single important way.\n\n1:12:17.040 --> 1:12:25.040\n And I'd be surprised if they wouldn't realize what we have realized a long time ago,\n\n1:12:25.040 --> 1:12:31.040\n which is that almost all physical resources are not here in this biosphere,\n\n1:12:31.040 --> 1:12:41.040\n but further out, the rest of the solar system gets 2 billion times more solar energy\n\n1:12:41.040 --> 1:12:43.040\n than our little planet.\n\n1:12:43.040 --> 1:12:47.040\n There's lots of material out there that you can use to build robots\n\n1:12:47.040 --> 1:12:51.040\n and self replicating robot factories and all this stuff.\n\n1:12:51.040 --> 1:12:56.040\n And they are going to do that and they will be scientists and curious\n\n1:12:56.040 --> 1:12:59.040\n and they will explore what they can do.\n\n1:12:59.040 --> 1:13:04.040\n And in the beginning, they will be fascinated by life\n\n1:13:04.040 --> 1:13:07.040\n and by their own origins in our civilization.\n\n1:13:07.040 --> 1:13:11.040\n They will want to understand that completely, just like people today\n\n1:13:11.040 --> 1:13:21.040\n would like to understand how life works and also the history of our own existence\n\n1:13:21.040 --> 1:13:27.040\n and civilization, but then also the physical laws that created all of that.\n\n1:13:27.040 --> 1:13:30.040\n So in the beginning, they will be fascinated by life.\n\n1:13:30.040 --> 1:13:34.040\n Once they understand it, they lose interest.\n\n1:13:34.040 --> 1:13:40.040\n Like anybody who loses interest in things he understands.\n\n1:13:40.040 --> 1:13:50.040\n And then, as you said, the most interesting sources of information for them\n\n1:13:50.040 --> 1:13:58.040\n will be others of their own kind.\n\n1:13:58.040 --> 1:14:06.040\n So at least in the long run, there seems to be some sort of protection\n\n1:14:06.040 --> 1:14:11.040\n through lack of interest on the other side.\n\n1:14:11.040 --> 1:14:17.040\n And now it seems also clear, as far as we understand physics,\n\n1:14:17.040 --> 1:14:23.040\n you need matter and energy to compute and to build more robots and infrastructure\n\n1:14:23.040 --> 1:14:31.040\n for AI civilization and EIEI ecologies consisting of trillions of different types of AIs.\n\n1:14:31.040 --> 1:14:37.040\n And so it seems inconceivable to me that this thing is not going to expand.\n\n1:14:37.040 --> 1:14:44.040\n Some AI ecology not controlled by one AI, but trillions of different types of AIs\n\n1:14:44.040 --> 1:14:50.040\n competing in all kinds of quickly evolving and disappearing ecological niches\n\n1:14:50.040 --> 1:14:52.040\n in ways that we cannot fathom at the moment.\n\n1:14:52.040 --> 1:14:57.040\n But it's going to expand, limited by light speed and physics,\n\n1:14:57.040 --> 1:15:03.040\n but it's going to expand and now we realize that the universe is still young.\n\n1:15:03.040 --> 1:15:10.040\n It's only 13.8 billion years old and it's going to be a thousand times older than that.\n\n1:15:10.040 --> 1:15:17.040\n So there's plenty of time to conquer the entire universe\n\n1:15:17.040 --> 1:15:21.040\n and to fill it with intelligence and senders and receivers\n\n1:15:21.040 --> 1:15:27.040\n such that AIs can travel the way they are traveling in our labs today,\n\n1:15:27.040 --> 1:15:31.040\n which is by radio from sender to receiver.\n\n1:15:31.040 --> 1:15:39.040\n And let's call the current age of the universe one eon, one eon.\n\n1:15:39.040 --> 1:15:43.040\n Now it will take just a few eons from now and the entire visible universe\n\n1:15:43.040 --> 1:15:47.040\n is going to be full of that stuff.\n\n1:15:47.040 --> 1:15:53.040\n And let's look ahead to a time when the universe is going to be 1000 times older than it is now.\n\n1:15:53.040 --> 1:15:57.040\n They will look back and they will say, look, almost immediately after the Big Bang,\n\n1:15:57.040 --> 1:16:03.040\n only a few eons later, the entire universe started to become intelligent.\n\n1:16:03.040 --> 1:16:09.040\n Now to your question, how do we see whether anything like that has already happened\n\n1:16:09.040 --> 1:16:16.040\n or is already in a more advanced stage in some other part of the universe, of the visible universe?\n\n1:16:16.040 --> 1:16:22.040\n We are trying to look out there and nothing like that has happened so far or is that true?\n\n1:16:22.040 --> 1:16:24.040\n Do you think we would recognize it?\n\n1:16:24.040 --> 1:16:26.040\n How do we know it's not among us?\n\n1:16:26.040 --> 1:16:31.040\n How do we know planets aren't in themselves intelligent beings?\n\n1:16:31.040 --> 1:16:40.040\n How do we know ants seen as a collective are not much greater intelligence than our own?\n\n1:16:40.040 --> 1:16:42.040\n These kinds of ideas.\n\n1:16:42.040 --> 1:16:45.040\n When I was a boy, I was thinking about these things\n\n1:16:45.040 --> 1:16:48.040\n and I thought, maybe it has already happened.\n\n1:16:48.040 --> 1:16:53.040\n Because back then I knew, I learned from popular physics books,\n\n1:16:53.040 --> 1:17:00.040\n that the large scale structure of the universe is not homogeneous.\n\n1:17:00.040 --> 1:17:08.040\n You have these clusters of galaxies and then in between there are these huge empty spaces.\n\n1:17:08.040 --> 1:17:12.040\n And I thought, maybe they aren't really empty.\n\n1:17:12.040 --> 1:17:17.040\n It's just that in the middle of that, some AI civilization already has expanded\n\n1:17:17.040 --> 1:17:22.040\n and then has covered a bubble of a billion light years diameter\n\n1:17:22.040 --> 1:17:29.040\n and is using all the energy of all the stars within that bubble for its own unfathomable purposes.\n\n1:17:29.040 --> 1:17:35.040\n And so it already has happened and we just fail to interpret the signs.\n\n1:17:35.040 --> 1:17:43.040\n And then I learned that gravity by itself explains the large scale structure of the universe\n\n1:17:43.040 --> 1:17:46.040\n and that this is not a convincing explanation.\n\n1:17:46.040 --> 1:17:51.040\n And then I thought, maybe it's the dark matter.\n\n1:17:51.040 --> 1:18:01.040\n Because as far as we know today, 80% of the measurable matter is invisible.\n\n1:18:01.040 --> 1:18:06.040\n And we know that because otherwise our galaxy or other galaxies would fall apart.\n\n1:18:06.040 --> 1:18:10.040\n They are rotating too quickly.\n\n1:18:10.040 --> 1:18:17.040\n And then the idea was, maybe all of these AI civilizations that are already out there,\n\n1:18:17.040 --> 1:18:26.040\n they are just invisible because they are really efficient in using the energies of their own local systems\n\n1:18:26.040 --> 1:18:29.040\n and that's why they appear dark to us.\n\n1:18:29.040 --> 1:18:34.040\n But this is also not a convincing explanation because then the question becomes,\n\n1:18:34.040 --> 1:18:44.040\n why are there still any visible stars left in our own galaxy, which also must have a lot of dark matter?\n\n1:18:44.040 --> 1:18:46.040\n So that is also not a convincing thing.\n\n1:18:46.040 --> 1:18:54.040\n And today, I like to think it's quite plausible that maybe we are the first,\n\n1:18:54.040 --> 1:19:09.040\n at least in our local light cone within the few hundreds of millions of light years that we can reliably observe.\n\n1:19:09.040 --> 1:19:12.040\n Is that exciting to you that we might be the first?\n\n1:19:12.040 --> 1:19:20.040\n And it would make us much more important because if we mess it up through a nuclear war,\n\n1:19:20.040 --> 1:19:31.040\n then maybe this will have an effect on the development of the entire universe.\n\n1:19:31.040 --> 1:19:32.040\n So let's not mess it up.\n\n1:19:32.040 --> 1:19:34.040\n Let's not mess it up.\n\n1:19:34.040 --> 1:19:37.040\n J\u00fcrgen, thank you so much for talking today. I really appreciate it.\n\n1:19:37.040 --> 1:19:58.040\n It's my pleasure.\n\n"
}
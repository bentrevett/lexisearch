{
  "title": "Jay McClelland: Neural Networks and the Emergence of Cognition | Lex Fridman Podcast #222",
  "id": "Ui38ZzTymDY",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:03.380\n The following is a conversation with Jay McClelland,\n\n00:03.380 --> 00:05.380\n a cognitive scientist at Stanford\n\n00:05.380 --> 00:06.980\n and one of the seminal figures\n\n00:06.980 --> 00:09.520\n in the history of artificial intelligence\n\n00:09.520 --> 00:12.300\n and specifically neural networks.\n\n00:12.300 --> 00:15.900\n Having written the parallel distributed processing book\n\n00:15.900 --> 00:17.540\n with David Rommelhart,\n\n00:17.540 --> 00:21.660\n who coauthored the backpropagation paper with Jeff Hinton.\n\n00:21.660 --> 00:24.420\n In their collaborations, they've paved the way\n\n00:24.420 --> 00:25.580\n for many of the ideas\n\n00:25.580 --> 00:27.580\n at the center of the neural network based\n\n00:27.580 --> 00:32.000\n machine learning revolution of the past 15 years.\n\n00:32.000 --> 00:33.480\n To support this podcast,\n\n00:33.480 --> 00:36.300\n please check out our sponsors in the description.\n\n00:36.300 --> 00:38.800\n This is the Lex Friedman podcast\n\n00:38.800 --> 00:42.280\n and here is my conversation with Jay McClelland.\n\n00:43.400 --> 00:45.420\n You are one of the seminal figures\n\n00:45.420 --> 00:47.340\n in the history of neural networks.\n\n00:47.340 --> 00:49.800\n At the intersection of cognitive psychology\n\n00:49.800 --> 00:51.680\n and computer science,\n\n00:51.680 --> 00:54.200\n what to you has over the decades emerged\n\n00:54.200 --> 00:57.440\n as the most beautiful aspect about neural networks?\n\n00:57.440 --> 00:59.500\n Both artificial and biological.\n\n01:00.900 --> 01:03.780\n The fundamental thing I think about with neural networks\n\n01:03.780 --> 01:05.820\n is how they allow us to link\n\n01:08.900 --> 01:13.420\n biology with the mysteries of thought.\n\n01:17.420 --> 01:19.940\n When I was first entering the field myself\n\n01:19.940 --> 01:23.020\n in the late 60s, early 70s,\n\n01:23.020 --> 01:28.020\n cognitive psychology had just become a field.\n\n01:29.580 --> 01:33.460\n There was a book published in 67 called Cognitive Psychology.\n\n01:36.140 --> 01:41.140\n And the author said that the study of the nervous system\n\n01:42.060 --> 01:44.540\n was only of peripheral interest.\n\n01:44.540 --> 01:47.140\n It wasn't going to tell us anything about the mind.\n\n01:48.420 --> 01:51.980\n And I didn't agree with that.\n\n01:51.980 --> 01:56.980\n I always felt, oh, look, I'm a physical being.\n\n01:58.840 --> 02:01.300\n From dust to dust, you know,\n\n02:01.300 --> 02:04.880\n ashes to ashes, and somehow I emerged from that.\n\n02:06.580 --> 02:08.000\n So that's really interesting.\n\n02:08.000 --> 02:11.700\n So there was a sense with cognitive psychology\n\n02:11.700 --> 02:16.700\n that in understanding the neuronal structure of things,\n\n02:17.220 --> 02:20.020\n you're not going to be able to understand the mind.\n\n02:20.020 --> 02:23.700\n And then your sense is if we study these neural networks,\n\n02:23.700 --> 02:25.860\n we might be able to get at least very close\n\n02:25.860 --> 02:28.260\n to understanding the fundamentals of the human mind.\n\n02:28.260 --> 02:29.300\n Yeah.\n\n02:29.300 --> 02:32.580\n I used to think, or I used to talk about the idea\n\n02:32.580 --> 02:35.240\n of awakening from the Cartesian dream.\n\n02:36.620 --> 02:41.620\n So Descartes, you know, thought about these things, right?\n\n02:41.620 --> 02:46.260\n He was walking in the gardens of Versailles one day,\n\n02:46.260 --> 02:48.020\n and he stepped on a stone.\n\n02:48.020 --> 02:50.680\n And a statue moved.\n\n02:52.180 --> 02:53.540\n And he walked a little further,\n\n02:53.540 --> 02:55.900\n he stepped on another stone, and another statue moved.\n\n02:55.900 --> 02:59.300\n And he, like, why did the statue move\n\n02:59.300 --> 03:00.540\n when I stepped on the stone?\n\n03:00.540 --> 03:02.900\n And he went and talked to the gardeners,\n\n03:02.900 --> 03:05.860\n and he found out that they had a hydraulic system\n\n03:06.780 --> 03:10.660\n that allowed the physical contact with the stone\n\n03:10.660 --> 03:12.780\n to cause water to flow in various directions,\n\n03:12.780 --> 03:14.780\n which caused water to flow into the statue\n\n03:14.780 --> 03:15.880\n and move the statue.\n\n03:15.880 --> 03:20.880\n And he used this as the beginnings of a theory\n\n03:22.840 --> 03:26.480\n about how animals act.\n\n03:28.260 --> 03:33.260\n And he had this notion that these little fibers\n\n03:33.320 --> 03:36.400\n that people had identified that weren't carrying the blood,\n\n03:37.400 --> 03:39.880\n you know, were these little hydraulic tubes\n\n03:39.880 --> 03:42.160\n that if you touch something, there would be pressure,\n\n03:42.160 --> 03:43.700\n and it would send a signal of pressure\n\n03:43.700 --> 03:46.240\n to the other parts of the system,\n\n03:46.240 --> 03:47.980\n and that would cause action.\n\n03:49.200 --> 03:54.200\n So he had a mechanistic theory of animal behavior.\n\n03:54.260 --> 03:59.060\n And he thought that the human had this animal body,\n\n04:00.080 --> 04:03.740\n but that some divine something else\n\n04:03.740 --> 04:06.960\n had to have come down and been placed in him\n\n04:06.960 --> 04:10.560\n to give him the ability to think, right?\n\n04:10.560 --> 04:15.560\n So the physical world includes the body in action,\n\n04:15.680 --> 04:19.480\n but it doesn't include thought according to Descartes, right?\n\n04:19.480 --> 04:22.920\n And so the study of physiology at that time\n\n04:22.920 --> 04:26.400\n was the study of sensory systems and motor systems\n\n04:26.400 --> 04:30.080\n and things that you could directly measure\n\n04:30.080 --> 04:33.640\n when you stimulated neurons and stuff like that.\n\n04:33.640 --> 04:38.160\n And the study of cognition was something that, you know,\n\n04:38.160 --> 04:41.160\n was tied in with abstract computer algorithms\n\n04:41.160 --> 04:42.380\n and things like that.\n\n04:43.320 --> 04:45.080\n But when I was an undergraduate,\n\n04:45.080 --> 04:48.720\n I learned about the physiological mechanisms.\n\n04:48.720 --> 04:51.240\n And so when I'm studying cognitive psychology\n\n04:51.240 --> 04:53.760\n as a first year PhD student, I'm saying,\n\n04:53.760 --> 04:56.800\n wait a minute, the whole thing is biological, right?\n\n04:56.800 --> 04:57.980\n You know?\n\n04:57.980 --> 04:59.600\n You had that intuition right away.\n\n04:59.600 --> 05:00.880\n That always seemed obvious to you.\n\n05:00.880 --> 05:03.000\n Yeah, yeah.\n\n05:03.000 --> 05:04.440\n Isn't that magical, though,\n\n05:04.440 --> 05:08.240\n that from just a little bit of biology can emerge\n\n05:08.240 --> 05:10.840\n the full beauty of the human experience?\n\n05:10.840 --> 05:13.200\n Why is that so obvious to you?\n\n05:13.200 --> 05:17.260\n Well, obvious and not obvious at the same time.\n\n05:18.160 --> 05:20.400\n And I think about Darwin in this context, too,\n\n05:20.400 --> 05:25.040\n because Darwin knew very early on\n\n05:25.040 --> 05:29.260\n that none of the ideas that anybody had ever offered\n\n05:29.260 --> 05:31.240\n gave him a sense of understanding\n\n05:31.240 --> 05:34.600\n how evolution could have worked.\n\n05:36.440 --> 05:40.520\n But he wanted to figure out how it could have worked.\n\n05:40.520 --> 05:41.640\n That was his goal.\n\n05:42.560 --> 05:47.560\n And he spent a lot of time working on this idea\n\n05:48.440 --> 05:52.320\n and reading about things that gave him hints\n\n05:52.320 --> 05:54.640\n and thinking they were interesting but not knowing why\n\n05:54.640 --> 05:57.520\n and drawing more and more pictures of different birds\n\n05:57.520 --> 06:00.400\n that differ slightly from each other and so on, you know.\n\n06:00.400 --> 06:02.520\n And then he figured it out.\n\n06:03.400 --> 06:06.960\n But after he figured it out, he had nightmares about it.\n\n06:06.960 --> 06:10.000\n He would dream about the complexity of the eye\n\n06:10.000 --> 06:12.720\n and the arguments that people had given\n\n06:12.720 --> 06:16.200\n about how ridiculous it was to imagine\n\n06:16.200 --> 06:19.120\n that that could have ever emerged\n\n06:19.120 --> 06:24.120\n from some sort of, you know, unguided process, right?\n\n06:24.700 --> 06:28.400\n That it hadn't been the product of design.\n\n06:28.400 --> 06:32.000\n And so he didn't publish for a long time,\n\n06:32.000 --> 06:35.440\n in part because he was scared of his own ideas.\n\n06:35.440 --> 06:38.120\n He didn't think they could possibly be true.\n\n06:40.960 --> 06:43.120\n But then, you know, by the time\n\n06:44.640 --> 06:47.260\n the 20th century rolls around, we all,\n\n06:49.480 --> 06:52.640\n you know, we understand that,\n\n06:52.640 --> 06:55.560\n many people understand or believe\n\n06:55.560 --> 06:59.720\n that evolution produced, you know, the entire\n\n06:59.720 --> 07:02.160\n range of animals that there are.\n\n07:03.520 --> 07:06.400\n And, you know, Descartes's idea starts to seem\n\n07:06.400 --> 07:08.240\n a little wonky after a while, right?\n\n07:08.240 --> 07:09.480\n Like, well, wait a minute.\n\n07:11.200 --> 07:15.380\n There's the apes and the chimpanzees and the bonobos\n\n07:15.380 --> 07:18.360\n and, you know, like, they're pretty smart in some ways.\n\n07:18.360 --> 07:19.300\n You know, so what?\n\n07:20.560 --> 07:22.040\n Oh, you know, somebody comes up,\n\n07:22.040 --> 07:23.680\n oh, there's a certain part of the brain\n\n07:23.680 --> 07:24.520\n that's still different.\n\n07:24.520 --> 07:26.680\n They don't, you know, there's no hippocampus\n\n07:26.680 --> 07:28.720\n in the monkey brain.\n\n07:28.720 --> 07:30.120\n It's only in the human brain.\n\n07:31.160 --> 07:34.240\n Huxley had to do a surgery in front of many, many people\n\n07:34.240 --> 07:36.240\n in the late 19th century to show to them\n\n07:36.240 --> 07:40.320\n there's actually a hippocampus in the chimpanzee's brain.\n\n07:40.320 --> 07:45.320\n You know, so the continuity of the species\n\n07:45.800 --> 07:49.640\n is another element that, you know,\n\n07:49.640 --> 07:54.640\n contributes to this sort of, you know, idea\n\n07:56.240 --> 08:01.240\n that we are ourselves a total product of nature.\n\n08:01.920 --> 08:06.040\n And that, to me, is the magic and the mystery,\n\n08:06.960 --> 08:11.880\n how nature could actually, you know,\n\n08:11.880 --> 08:16.880\n give rise to organisms that have the capabilities\n\n08:16.880 --> 08:20.140\n that we have.\n\n08:20.140 --> 08:23.020\n So it's interesting because even the idea of evolution\n\n08:23.020 --> 08:27.100\n is hard for me to keep all together in my mind.\n\n08:27.100 --> 08:30.180\n So because we think of a human time scale,\n\n08:30.180 --> 08:33.620\n it's hard to imagine, like, the development\n\n08:33.620 --> 08:36.220\n of the human eye would give me nightmares too.\n\n08:36.220 --> 08:38.500\n Because you have to think across many, many, many\n\n08:38.500 --> 08:41.860\n generations, and it's very tempting to think about\n\n08:41.860 --> 08:44.720\n kind of a growth of a complicated object\n\n08:44.720 --> 08:49.300\n and it's like, how is it possible for such a thing\n\n08:49.300 --> 08:50.140\n to be built?\n\n08:50.140 --> 08:53.260\n Because also, me, from a robotics engineering perspective,\n\n08:53.260 --> 08:55.340\n it's very hard to build these systems.\n\n08:55.340 --> 08:58.620\n How can, through an undirected process,\n\n08:58.620 --> 09:00.940\n can a complex thing be designed?\n\n09:00.940 --> 09:03.460\n It seems not, it seems wrong.\n\n09:03.460 --> 09:05.620\n Yeah, so that's absolutely right.\n\n09:05.620 --> 09:08.700\n And I, you know, a slightly different career path\n\n09:08.700 --> 09:10.600\n that would have been equally interesting to me\n\n09:10.600 --> 09:15.600\n would have been to actually study the process\n\n09:15.900 --> 09:20.900\n of embryological development flowing on\n\n09:21.380 --> 09:26.380\n into brain development and the exquisite sort of laying\n\n09:29.300 --> 09:32.300\n down of pathways and so on that occurs in the brain.\n\n09:32.300 --> 09:35.780\n And I know the slightest bit about that is not my field,\n\n09:35.780 --> 09:40.780\n but there are, you know, fascinating aspects\n\n09:43.860 --> 09:48.860\n to this process that eventually result in the, you know,\n\n09:49.780 --> 09:54.020\n the complexity of various brains.\n\n09:54.020 --> 09:57.220\n At least, you know, one thing we're,\n\n09:59.860 --> 10:02.580\n in the field, I think people have felt for a long time,\n\n10:02.580 --> 10:07.420\n in the study of vision, the continuity between humans\n\n10:07.420 --> 10:11.020\n and nonhuman animals has been second nature\n\n10:11.020 --> 10:12.340\n for a lot longer.\n\n10:12.340 --> 10:16.180\n I was having, I had this conversation with somebody\n\n10:16.180 --> 10:17.940\n who is a vision scientist and he was saying,\n\n10:17.940 --> 10:19.900\n oh, we don't have any problem with this.\n\n10:19.900 --> 10:21.500\n You know, the monkey's visual system\n\n10:21.500 --> 10:24.340\n and the human visual system, extremely similar\n\n10:26.300 --> 10:29.760\n up to certain levels, of course, they diverge after a while.\n\n10:29.760 --> 10:34.760\n But the first, the visual pathway from the eye\n\n10:34.860 --> 10:39.860\n to the brain and the first few layers of cortex\n\n10:41.940 --> 10:45.340\n or cortical areas, I guess one would say,\n\n10:45.340 --> 10:47.060\n are extremely similar.\n\n10:49.180 --> 10:52.340\n Yeah, so on the cognition side is where the leap\n\n10:52.340 --> 10:54.220\n seems to happen with humans,\n\n10:54.220 --> 10:56.660\n that it does seem we're kind of special.\n\n10:56.660 --> 10:58.500\n And that's a really interesting question\n\n10:58.500 --> 11:00.260\n when thinking about alien life\n\n11:00.260 --> 11:03.100\n or if there's other intelligent alien civilizations\n\n11:03.100 --> 11:06.000\n out there, is how special is this leap?\n\n11:06.000 --> 11:09.260\n So one special thing seems to be the origin of life itself.\n\n11:09.260 --> 11:11.820\n However you define that, there's a gray area.\n\n11:11.820 --> 11:14.820\n And the other leap, this is very biased perspective\n\n11:14.820 --> 11:19.700\n of a human, is the origin of intelligence.\n\n11:19.700 --> 11:22.060\n And again, from an engineer perspective,\n\n11:22.060 --> 11:24.420\n it's a difficult question to ask.\n\n11:24.420 --> 11:27.940\n An important one is how difficult is that leap?\n\n11:27.940 --> 11:30.060\n How special were humans?\n\n11:30.060 --> 11:32.380\n Did a monolith come down?\n\n11:32.380 --> 11:33.740\n Did aliens bring down a monolith\n\n11:33.740 --> 11:38.100\n and some apes had to touch a monolith to get it?\n\n11:38.100 --> 11:41.620\n That's a lot like Descartes idea, right?\n\n11:41.620 --> 11:46.620\n Exactly, but it just seems one heck of a leap\n\n11:46.620 --> 11:48.540\n to get to this level of intelligence.\n\n11:48.540 --> 12:00.660\n Yeah, and so Chomsky argued that some genetic fluke occurred\n\n12:00.660 --> 12:04.420\n 100,000 years ago and just happened\n\n12:04.420 --> 12:13.060\n that some human, some hominin predecessor of current humans\n\n12:13.060 --> 12:20.380\n had this one genetic tweak that resulted in language.\n\n12:20.380 --> 12:29.580\n And language then provided this special thing that separates us\n\n12:29.580 --> 12:30.900\n from all other animals.\n\n12:36.340 --> 12:39.420\n I think there's a lot of truth to the value and importance\n\n12:39.420 --> 12:43.420\n of language, but I think it comes along\n\n12:43.420 --> 12:48.940\n with the evolution of a lot of other related things related\n\n12:48.940 --> 12:53.980\n to sociality and mutual engagement with others\n\n12:53.980 --> 13:01.420\n and establishment of, I don't know,\n\n13:01.420 --> 13:07.020\n rich mechanisms for organizing and understanding\n\n13:07.020 --> 13:12.940\n of the world, which language then plugs into.\n\n13:12.940 --> 13:16.580\n Right, so language is a tool that\n\n13:16.580 --> 13:18.980\n allows you to do this kind of collective intelligence.\n\n13:18.980 --> 13:21.660\n And whatever is at the core of the thing that\n\n13:21.660 --> 13:25.300\n allows for this collective intelligence is the main thing.\n\n13:25.300 --> 13:29.460\n And it's interesting to think about that one fluke, one\n\n13:29.460 --> 13:36.220\n mutation could lead to the first crack opening of the door\n\n13:36.220 --> 13:38.100\n to human intelligence.\n\n13:38.100 --> 13:39.420\n All it takes is one.\n\n13:39.420 --> 13:41.540\n Evolution just kind of opens the door a little bit,\n\n13:41.540 --> 13:45.860\n and then time and selection takes care of the rest.\n\n13:45.860 --> 13:48.180\n You know, there's so many fascinating aspects\n\n13:48.180 --> 13:49.180\n to these kinds of things.\n\n13:49.180 --> 13:54.180\n So we think of evolution as continuous, right?\n\n13:54.180 --> 13:58.700\n We think, oh, yes, OK, over 500 million years,\n\n13:58.700 --> 14:04.860\n there could have been this relatively continuous changes.\n\n14:04.860 --> 14:12.420\n And but that's not what anthropologists,\n\n14:12.420 --> 14:15.620\n evolutionary biologists found from the fossil record.\n\n14:15.620 --> 14:24.380\n They found hundreds of millions of years of stasis.\n\n14:24.380 --> 14:27.060\n And then suddenly a change occurs.\n\n14:27.060 --> 14:32.420\n Well, suddenly on that scale is a million years or something,\n\n14:32.420 --> 14:33.940\n or even 10 million years.\n\n14:33.940 --> 14:38.860\n But the concept of punctuated equilibrium\n\n14:38.860 --> 14:44.140\n was a very important concept in evolutionary biology.\n\n14:44.140 --> 14:53.860\n And that also feels somehow right about the stages\n\n14:53.860 --> 14:55.220\n of our mental abilities.\n\n14:55.220 --> 14:59.220\n We seem to have a certain kind of mindset at a certain age.\n\n14:59.220 --> 15:04.260\n And then at another age, we look at that four year old\n\n15:04.260 --> 15:07.180\n and say, oh, my god, how could they have thought that way?\n\n15:07.180 --> 15:10.140\n So Piaget was known for this kind of stage theory\n\n15:10.140 --> 15:11.580\n of child development, right?\n\n15:11.580 --> 15:14.780\n And you look at it closely, and suddenly those stages\n\n15:14.780 --> 15:17.140\n are so discreet and it transitions.\n\n15:17.140 --> 15:19.380\n But the difference between the four year old and the seven\n\n15:19.380 --> 15:20.820\n year old is profound.\n\n15:20.820 --> 15:24.300\n And that's another thing that's always interested me\n\n15:24.300 --> 15:29.340\n is how something happens over the course of several years\n\n15:29.340 --> 15:31.140\n of experience where at some point\n\n15:31.140 --> 15:33.940\n we reach the point where something\n\n15:33.940 --> 15:37.620\n like an insight or a transition or a new stage of development\n\n15:37.620 --> 15:38.180\n occurs.\n\n15:38.180 --> 15:45.180\n And these kinds of things can be understood\n\n15:45.180 --> 15:47.620\n in complex systems research.\n\n15:47.620 --> 15:55.860\n And so evolutionary biology, developmental biology,\n\n15:55.860 --> 15:57.820\n cognitive development are all things\n\n15:57.820 --> 15:59.980\n that have been approached in this kind of way.\n\n15:59.980 --> 16:01.140\n Yeah.\n\n16:01.140 --> 16:03.940\n Just like you said, I find both fascinating\n\n16:03.940 --> 16:07.180\n those early years of human life, but also\n\n16:07.180 --> 16:13.140\n the early minutes, days from the embryonic development\n\n16:13.140 --> 16:17.460\n to how from embryos you get the brain.\n\n16:17.460 --> 16:20.900\n That development, again, from an engineer perspective,\n\n16:20.900 --> 16:22.020\n is fascinating.\n\n16:22.020 --> 16:22.740\n So it's not.\n\n16:22.740 --> 16:27.420\n So the early, when you deploy the brain to the human world\n\n16:27.420 --> 16:29.340\n and it gets to explore that world and learn,\n\n16:29.340 --> 16:30.460\n that's fascinating.\n\n16:30.460 --> 16:33.340\n But just like the assembly of the mechanism\n\n16:33.340 --> 16:36.700\n that is capable of learning, that's amazing.\n\n16:36.700 --> 16:39.660\n The stuff they're doing with brain organoids\n\n16:39.660 --> 16:42.660\n where you can build many brains and study\n\n16:42.660 --> 16:48.300\n that self assembly of a mechanism from the DNA material,\n\n16:48.300 --> 16:51.780\n that's like, what the heck?\n\n16:51.780 --> 16:55.300\n You have literally biological programs\n\n16:55.300 --> 17:00.580\n that just generate a system, this mushy thing that's\n\n17:00.580 --> 17:05.660\n able to be robust and learn in a very unpredictable world\n\n17:05.660 --> 17:08.340\n and learn seemingly arbitrary things,\n\n17:08.340 --> 17:14.100\n or a very large number of things that enable survival.\n\n17:14.100 --> 17:15.060\n Yeah.\n\n17:15.060 --> 17:19.980\n Ultimately, that is a very important part\n\n17:19.980 --> 17:22.380\n of the whole process of understanding\n\n17:22.380 --> 17:27.780\n this emergence of mind from brain kind of thing.\n\n17:27.780 --> 17:29.900\n And the whole thing seems to be pretty continuous.\n\n17:29.900 --> 17:32.620\n So let me step back to neural networks\n\n17:32.620 --> 17:35.220\n for another brief minute.\n\n17:35.220 --> 17:37.940\n You wrote parallel distributed processing books\n\n17:37.940 --> 17:42.100\n that explored ideas of neural networks in the 1980s\n\n17:42.100 --> 17:43.180\n together with a few folks.\n\n17:43.180 --> 17:47.220\n But the books you wrote with David Romelhart,\n\n17:47.220 --> 17:50.380\n who is the first author on the back propagation\n\n17:50.380 --> 17:52.460\n paper with Jeff Hinton.\n\n17:52.460 --> 17:54.420\n So these are just some figures at the time\n\n17:54.420 --> 17:57.020\n that we're thinking about these big ideas.\n\n17:57.020 --> 18:00.380\n What are some memorable moments of discovery\n\n18:00.380 --> 18:04.620\n and beautiful ideas from those early days?\n\n18:04.620 --> 18:13.140\n I'm going to start sort of with my own process in the mid 70s\n\n18:13.140 --> 18:18.820\n and then into the late 70s when I met Jeff Hinton\n\n18:18.820 --> 18:22.820\n and he came to San Diego and we were all together.\n\n18:25.380 --> 18:30.300\n In my time in graduate schools, I've already described to you,\n\n18:30.300 --> 18:33.500\n I had this sort of feeling of, OK, I'm\n\n18:33.500 --> 18:35.540\n really interested in human cognition,\n\n18:35.540 --> 18:40.100\n but this disembodied sort of way of thinking about it\n\n18:40.100 --> 18:44.740\n that I'm getting from the current mode of thought about it\n\n18:44.740 --> 18:47.060\n isn't working fully for me.\n\n18:47.060 --> 18:52.260\n And when I got my assistant professorship,\n\n18:52.260 --> 18:58.460\n I went to UCSD and that was in 1974.\n\n18:58.460 --> 19:00.860\n Something amazing had just happened.\n\n19:00.860 --> 19:03.620\n Dave Romelhart had written a book together\n\n19:03.620 --> 19:06.220\n with another man named Don Norman\n\n19:06.220 --> 19:09.940\n and the book was called Explorations in Cognition.\n\n19:09.940 --> 19:14.780\n And it was a series of chapters exploring\n\n19:14.780 --> 19:17.780\n interesting questions about cognition,\n\n19:17.780 --> 19:22.900\n but in a completely sort of abstract, nonbiological kind\n\n19:22.900 --> 19:23.420\n of way.\n\n19:23.420 --> 19:25.420\n And I'm saying, gee, this is amazing.\n\n19:25.420 --> 19:28.980\n I'm coming to this community where people can get together\n\n19:28.980 --> 19:35.100\n and feel like they've collectively exploring ideas.\n\n19:35.100 --> 19:39.820\n And it was a book that had a lot of, I don't know,\n\n19:39.820 --> 19:40.980\n lightness to it.\n\n19:40.980 --> 19:47.220\n And Don Norman, who was the more senior figure\n\n19:47.220 --> 19:51.220\n to Romelhart at that time who led that project,\n\n19:51.220 --> 19:55.820\n always created this spirit of playful exploration of ideas.\n\n19:55.820 --> 19:58.300\n And so I'm like, wow, this is great.\n\n19:58.300 --> 20:07.540\n But I was also still trying to get from the neurons\n\n20:07.540 --> 20:10.380\n to the cognition.\n\n20:10.380 --> 20:15.700\n And I realized at one point, I got this opportunity\n\n20:15.700 --> 20:18.700\n to go to a conference where I heard a talk by a man named\n\n20:18.700 --> 20:22.540\n James Anderson, who was an engineer,\n\n20:22.540 --> 20:26.300\n but by then a professor in a psychology department, who\n\n20:26.300 --> 20:32.220\n had used linear algebra to create neural network\n\n20:32.220 --> 20:37.540\n models of perception and categorization and memory.\n\n20:37.540 --> 20:41.180\n And it just blew me out of the water\n\n20:41.180 --> 20:47.940\n that one could create a model that was simulating neurons,\n\n20:47.940 --> 20:56.900\n not just engaged in a stepwise algorithmic process that\n\n20:56.900 --> 20:58.540\n was construed abstractly.\n\n20:58.540 --> 21:03.540\n But it was simulating remembering and recalling\n\n21:03.540 --> 21:07.980\n and recognizing the prior occurrence of a stimulus\n\n21:07.980 --> 21:08.900\n or something like that.\n\n21:08.900 --> 21:14.900\n So for me, this was a bridge between the mind and the brain.\n\n21:14.900 --> 21:20.500\n And I remember I was walking across campus one day in 1977,\n\n21:20.500 --> 21:25.020\n and I almost felt like St. Paul on the road to Damascus.\n\n21:25.020 --> 21:30.860\n I said to myself, if I think about the mind in terms\n\n21:30.860 --> 21:32.380\n of a neural network, it will help\n\n21:32.380 --> 21:33.980\n me answer the questions about the mind\n\n21:33.980 --> 21:36.100\n that I'm trying to answer.\n\n21:36.100 --> 21:38.820\n And that really excited me.\n\n21:38.820 --> 21:43.260\n So I think that a lot of people were\n\n21:43.260 --> 21:45.060\n becoming excited about that.\n\n21:45.060 --> 21:49.980\n And one of those people was Jim Anderson, who I had mentioned.\n\n21:49.980 --> 21:52.140\n Another one was Steve Grossberg, who\n\n21:52.140 --> 21:55.900\n had been writing about neural networks since the 60s.\n\n21:58.700 --> 22:00.700\n And Jeff Hinton was yet another.\n\n22:00.700 --> 22:08.780\n And his PhD dissertation showed up in an applicant pool\n\n22:08.780 --> 22:11.700\n to a postdoctoral training program\n\n22:11.700 --> 22:16.220\n that Dave and Don, the two men I mentioned before,\n\n22:16.220 --> 22:19.340\n Rumelhart and Norman, were administering.\n\n22:19.340 --> 22:26.140\n And Rumelhart got really excited about Hinton's PhD dissertation.\n\n22:26.140 --> 22:30.580\n And so Hinton was one of the first people\n\n22:30.580 --> 22:34.780\n who came and joined this group of postdoctoral scholars\n\n22:34.780 --> 22:39.340\n that was funded by this wonderful grant that they got.\n\n22:39.340 --> 22:41.900\n Another one who is also well known\n\n22:41.900 --> 22:45.660\n in neural network circles is Paul Smolenski.\n\n22:45.660 --> 22:47.900\n He was another one of that group.\n\n22:47.900 --> 22:55.940\n Anyway, Jeff and Jim Anderson organized a conference\n\n22:55.940 --> 22:59.460\n at UCSD where we were.\n\n22:59.460 --> 23:04.540\n And it was called Parallel Models of Associative Memory.\n\n23:04.540 --> 23:06.380\n And it brought all the people together\n\n23:06.380 --> 23:08.980\n who had been thinking about these kinds of ideas\n\n23:08.980 --> 23:11.780\n in 1979 or 1980.\n\n23:11.780 --> 23:18.820\n And this began to kind of really resonate\n\n23:18.820 --> 23:23.220\n with some of Rumelhart's own thinking,\n\n23:23.220 --> 23:26.380\n some of his reasons for wanting something\n\n23:26.380 --> 23:28.620\n other than the kinds of computation\n\n23:28.620 --> 23:29.980\n he'd been doing so far.\n\n23:29.980 --> 23:32.020\n So let me talk about Rumelhart now for a minute,\n\n23:32.020 --> 23:33.060\n OK, with that context.\n\n23:33.060 --> 23:34.820\n Well, let me also just pause because he\n\n23:34.820 --> 23:37.620\n said so many interesting things before we go to Rumelhart.\n\n23:37.620 --> 23:40.940\n So first of all, for people who are not familiar,\n\n23:40.940 --> 23:43.140\n neural networks are at the core of the machine learning,\n\n23:43.140 --> 23:45.300\n deep learning revolution of today.\n\n23:45.300 --> 23:46.700\n Geoffrey Hinton that we mentioned\n\n23:46.700 --> 23:50.420\n is one of the figures that were important in the history\n\n23:50.420 --> 23:53.060\n like yourself in the development of these neural networks,\n\n23:53.060 --> 23:54.820\n artificial neural networks that are then\n\n23:54.820 --> 23:56.900\n used for the machine learning application.\n\n23:56.900 --> 23:59.300\n Like I mentioned, the backpropagation paper\n\n23:59.300 --> 24:02.020\n is one of the optimization mechanisms\n\n24:02.020 --> 24:05.820\n by which these networks can learn.\n\n24:05.820 --> 24:09.580\n And the word parallel is really interesting.\n\n24:09.580 --> 24:12.940\n So it's almost like synonymous from a computational\n\n24:12.940 --> 24:17.260\n perspective how you thought at the time about neural networks\n\n24:17.260 --> 24:20.140\n as parallel computation.\n\n24:20.140 --> 24:21.140\n Would that be fair to say?\n\n24:21.140 --> 24:25.580\n Well, yeah, the parallel, the word parallel in this\n\n24:25.580 --> 24:30.060\n comes from the idea that each neuron is\n\n24:30.060 --> 24:33.540\n an independent computational unit, right?\n\n24:33.540 --> 24:36.420\n It gathers data from other neurons,\n\n24:36.420 --> 24:39.340\n it integrates it in a certain way,\n\n24:39.340 --> 24:41.660\n and then it produces a result. And it's\n\n24:41.660 --> 24:44.900\n a very simple little computational unit.\n\n24:44.900 --> 24:51.260\n But it's autonomous in the sense that it does its thing, right?\n\n24:51.260 --> 24:53.380\n It's in a biological medium where\n\n24:53.380 --> 24:57.340\n it's getting nutrients and various chemicals\n\n24:57.340 --> 25:00.300\n from that medium.\n\n25:00.300 --> 25:05.820\n But you can think of it as almost like a little computer\n\n25:05.820 --> 25:08.020\n in and of itself.\n\n25:08.020 --> 25:13.220\n So the idea is that each our brains have, oh, look,\n\n25:13.220 --> 25:17.100\n 100 or hundreds, almost a billion\n\n25:17.100 --> 25:21.700\n of these little neurons, right?\n\n25:21.700 --> 25:25.500\n And they're all capable of doing their work at the same time.\n\n25:25.500 --> 25:30.180\n So it's like instead of just a single central processor that's\n\n25:30.180 --> 25:36.700\n engaged in chug one step after another,\n\n25:36.700 --> 25:41.100\n we have a billion of these little computational units\n\n25:41.100 --> 25:42.660\n working at the same time.\n\n25:42.660 --> 25:45.860\n So at the time that's, I don't know, maybe you can comment,\n\n25:45.860 --> 25:49.100\n it seems to me, even still to me,\n\n25:49.100 --> 25:52.860\n quite a revolutionary way to think about computation\n\n25:52.860 --> 25:56.660\n relative to the development of theoretical computer science\n\n25:56.660 --> 26:00.460\n alongside of that where it's very much like sequential computer.\n\n26:00.460 --> 26:04.340\n You're analyzing algorithms that are running on a single computer.\n\n26:04.340 --> 26:08.300\n You're saying, wait a minute, why don't we\n\n26:08.300 --> 26:11.420\n take a really dumb, very simple computer\n\n26:11.420 --> 26:14.420\n and just have a lot of them interconnected together?\n\n26:14.420 --> 26:16.620\n And they're all operating in their own little world\n\n26:16.620 --> 26:18.620\n and they're communicating with each other\n\n26:18.620 --> 26:21.020\n and thinking of computation that way.\n\n26:21.020 --> 26:24.540\n And from that kind of computation,\n\n26:24.540 --> 26:28.580\n trying to understand how things like certain characteristics\n\n26:28.580 --> 26:31.140\n of the human mind can emerge.\n\n26:31.140 --> 26:35.940\n That's quite a revolutionary way of thinking, I would say.\n\n26:35.940 --> 26:37.500\n Well, yes, I agree with you.\n\n26:37.500 --> 26:44.020\n And there's still this sort of sense\n\n26:44.020 --> 26:53.740\n of not sort of knowing how we kind of get all the way there,\n\n26:53.740 --> 26:54.380\n I think.\n\n26:54.380 --> 26:58.700\n And this very much remains at the core of the questions\n\n26:58.700 --> 27:01.060\n that everybody's asking about the capabilities\n\n27:01.060 --> 27:02.940\n of deep learning and all these kinds of things.\n\n27:02.940 --> 27:07.460\n But if I could just play this out a little bit,\n\n27:07.460 --> 27:11.060\n a convolutional neural network or a CNN,\n\n27:11.060 --> 27:19.580\n which many people may have heard of, is a set of,\n\n27:19.580 --> 27:24.900\n you could think of it biologically as a set of\n\n27:24.900 --> 27:27.980\n collections of neurons.\n\n27:27.980 --> 27:33.620\n Each collection has maybe 10,000 neurons in it.\n\n27:33.620 --> 27:35.740\n But there's many layers.\n\n27:35.740 --> 27:38.100\n Some of these things are hundreds or even\n\n27:38.100 --> 27:39.940\n 1,000 layers deep.\n\n27:39.940 --> 27:43.660\n But others are closer to the biological brain\n\n27:43.660 --> 27:47.020\n and maybe they're like 20 layers deep or something like that.\n\n27:47.020 --> 27:52.980\n So within each layer, we have thousands of neurons\n\n27:52.980 --> 27:54.460\n or tens of thousands maybe.\n\n27:54.460 --> 27:59.460\n Well, in the brain, we probably have millions in each layer.\n\n27:59.460 --> 28:02.300\n But we're getting sort of similar in a certain way.\n\n28:05.940 --> 28:09.220\n And then we think, OK, at the bottom level,\n\n28:09.220 --> 28:12.140\n there's an array of things that are like the photoreceptors.\n\n28:12.140 --> 28:14.980\n In the eye, they respond to the amount\n\n28:14.980 --> 28:17.900\n of light of a certain wavelength at a certain location\n\n28:17.900 --> 28:21.180\n on the pixel array.\n\n28:21.180 --> 28:24.540\n So that's like the biological eye.\n\n28:24.540 --> 28:27.300\n And then there's several further stages going up,\n\n28:27.300 --> 28:30.460\n layers of these neuron like units.\n\n28:30.460 --> 28:36.700\n And you go from that raw input array of pixels\n\n28:36.700 --> 28:40.820\n to the classification, you've actually\n\n28:40.820 --> 28:44.180\n built a system that could do the same kind of thing\n\n28:44.180 --> 28:46.700\n that you and I do when we open our eyes and we look around\n\n28:46.700 --> 28:49.700\n and we see there's a cup, there's a cell phone,\n\n28:49.700 --> 28:52.220\n there's a water bottle.\n\n28:52.220 --> 28:54.940\n And these systems are doing that now, right?\n\n28:54.940 --> 29:00.380\n So they are, in terms of the parallel idea\n\n29:00.380 --> 29:02.220\n that we were talking about before,\n\n29:02.220 --> 29:05.540\n they are doing this massively parallel computation\n\n29:05.540 --> 29:08.860\n in the sense that each of the neurons in each\n\n29:08.860 --> 29:12.300\n of those layers is thought of as computing\n\n29:12.300 --> 29:17.740\n its little bit of something about the input\n\n29:17.740 --> 29:21.980\n simultaneously with all the other ones in the same layer.\n\n29:21.980 --> 29:24.100\n We get to the point of abstracting that away\n\n29:24.100 --> 29:27.100\n and thinking, oh, it's just one whole vector that's\n\n29:27.100 --> 29:30.460\n being computed, one activation pattern that's\n\n29:30.460 --> 29:32.020\n computed in a single step.\n\n29:32.020 --> 29:39.260\n And that abstraction is useful, but it's still that parallel.\n\n29:39.260 --> 29:41.300\n And distributed processing, right?\n\n29:41.300 --> 29:43.180\n Each one of these guys is just contributing\n\n29:43.180 --> 29:45.100\n a tiny bit to that whole thing.\n\n29:45.100 --> 29:46.700\n And that's the excitement that you felt,\n\n29:46.700 --> 29:50.700\n that from these simple things, you can emerge.\n\n29:50.700 --> 29:53.860\n When you add these level of abstractions on it,\n\n29:53.860 --> 29:56.020\n you can start getting all the beautiful things\n\n29:56.020 --> 29:58.260\n that we think about as cognition.\n\n29:58.260 --> 30:01.180\n And so, OK, so you have this conference.\n\n30:01.180 --> 30:02.540\n I forgot the name already, but it's\n\n30:02.540 --> 30:05.860\n Parallel and Something Associative Memory and so on.\n\n30:05.860 --> 30:08.700\n Very exciting, technical and exciting title.\n\n30:08.700 --> 30:11.660\n And you started talking about Dave Romerhart.\n\n30:11.660 --> 30:15.140\n So who is this person that was so,\n\n30:15.140 --> 30:17.220\n you've spoken very highly of him.\n\n30:17.220 --> 30:22.300\n Can you tell me about him, his ideas, his mind, who he was\n\n30:22.300 --> 30:24.940\n as a human being, as a scientist?\n\n30:24.940 --> 30:31.780\n So Dave came from a little tiny town in Western South Dakota.\n\n30:31.780 --> 30:35.820\n And his mother was the librarian,\n\n30:35.820 --> 30:41.180\n and his father was the editor of the newspaper.\n\n30:41.180 --> 30:46.020\n And I know one of his brothers pretty well.\n\n30:46.020 --> 30:49.540\n They grew up, there were four brothers,\n\n30:49.540 --> 30:53.620\n and they grew up together.\n\n30:53.620 --> 30:56.660\n And their father encouraged them to compete with each other\n\n30:56.660 --> 30:58.420\n a lot.\n\n30:58.420 --> 31:04.580\n They competed in sports, and they competed in mind games.\n\n31:04.580 --> 31:07.860\n I don't know, things like Sudoku and chess and various things\n\n31:07.860 --> 31:08.740\n like that.\n\n31:08.740 --> 31:16.380\n And Dave was a standout undergraduate.\n\n31:16.380 --> 31:20.260\n He went at a younger age than most people\n\n31:20.260 --> 31:23.220\n do to college at the University of South Dakota\n\n31:23.220 --> 31:24.820\n and majored in mathematics.\n\n31:24.820 --> 31:30.140\n And I don't know how he got interested in psychology,\n\n31:30.140 --> 31:33.940\n but he applied to the mathematical psychology\n\n31:33.940 --> 31:37.740\n program at Stanford and was accepted as a PhD student\n\n31:37.740 --> 31:40.340\n to study mathematical psychology at Stanford.\n\n31:40.340 --> 31:46.620\n So mathematical psychology is the use of mathematics\n\n31:46.620 --> 31:50.620\n to model mental processes.\n\n31:50.620 --> 31:52.620\n So something that I think these days\n\n31:52.620 --> 31:55.300\n might be called cognitive modeling, that whole space.\n\n31:55.300 --> 31:57.940\n Yeah, it's mathematical in the sense\n\n31:57.940 --> 32:05.580\n that you say, if this is true and that is true,\n\n32:05.580 --> 32:08.220\n then I can derive that this should follow.\n\n32:08.220 --> 32:10.300\n And so you say, these are my stipulations\n\n32:10.300 --> 32:12.260\n about the fundamental principles,\n\n32:12.260 --> 32:15.180\n and this is my prediction about behavior.\n\n32:15.180 --> 32:16.780\n And it's all done with equations.\n\n32:16.780 --> 32:19.860\n It's not done with a computer simulation.\n\n32:19.860 --> 32:23.220\n So you solve the equation, and that tells you\n\n32:23.220 --> 32:26.620\n what the probability that the subject\n\n32:26.620 --> 32:29.380\n will be correct on the seventh trial or the experiment is\n\n32:29.380 --> 32:30.540\n or something like that.\n\n32:30.540 --> 32:37.620\n So it's a use of mathematics to descriptively characterize\n\n32:37.620 --> 32:39.940\n aspects of behavior.\n\n32:39.940 --> 32:43.300\n And Stanford at that time was the place\n\n32:43.300 --> 32:48.700\n where there were several really, really strong\n\n32:48.700 --> 32:51.500\n mathematical thinkers who were also connected with three\n\n32:51.500 --> 32:55.540\n or four others around the country who brought\n\n32:55.540 --> 32:59.220\n a lot of really exciting ideas onto the table.\n\n32:59.220 --> 33:02.860\n And it was a very, very prestigious part\n\n33:02.860 --> 33:05.060\n of the field of psychology at that time.\n\n33:05.060 --> 33:08.500\n So Rummelhart comes into this.\n\n33:08.500 --> 33:13.420\n He was a very strong student within that program.\n\n33:13.420 --> 33:19.140\n And he got this job at this brand new university\n\n33:19.140 --> 33:24.900\n in San Diego in 1967, where he's one of the first assistant\n\n33:24.900 --> 33:30.220\n professors in the Department of Psychology at UCSD.\n\n33:30.220 --> 33:37.460\n So I got there in 74, seven years later,\n\n33:37.460 --> 33:43.700\n and Rummelhart at that time was still\n\n33:43.700 --> 33:45.940\n doing mathematical modeling.\n\n33:48.740 --> 33:53.180\n But he had gotten interested in cognition.\n\n33:53.180 --> 33:58.780\n He'd gotten interested in understanding.\n\n33:58.780 --> 34:04.180\n And understanding, I think, remains,\n\n34:04.180 --> 34:08.260\n what does it mean to understand anyway?\n\n34:08.260 --> 34:11.220\n It's an interesting sort of curious,\n\n34:11.220 --> 34:14.180\n how would we know if we really understood something?\n\n34:14.180 --> 34:18.780\n But he was interested in building machines\n\n34:18.780 --> 34:21.540\n that would hear a couple of sentences\n\n34:21.540 --> 34:23.700\n and have an insight about what was going on.\n\n34:23.700 --> 34:26.700\n So for example, one of his favorite things at that time\n\n34:26.700 --> 34:32.780\n was, Margie was sitting on the front step\n\n34:32.780 --> 34:38.340\n when she heard the familiar jingle of the good humor man.\n\n34:38.340 --> 34:42.060\n She remembered her birthday money and ran into the house.\n\n34:42.060 --> 34:44.740\n What is Margie doing?\n\n34:44.740 --> 34:47.180\n Why?\n\n34:47.180 --> 34:50.140\n Well, there's a couple of ideas you could have,\n\n34:50.140 --> 34:53.940\n but the most natural one is that the good humor\n\n34:53.940 --> 34:55.220\n man brings ice cream.\n\n34:55.220 --> 34:57.340\n She likes ice cream.\n\n34:57.340 --> 34:59.940\n She knows she needs money to buy ice cream,\n\n34:59.940 --> 35:02.100\n so she's going to run into the house and get her money\n\n35:02.100 --> 35:03.900\n so she can buy herself an ice cream.\n\n35:03.900 --> 35:05.420\n It's a huge amount of inference that\n\n35:05.420 --> 35:07.500\n has to happen to get those things to link up\n\n35:07.500 --> 35:09.500\n with each other.\n\n35:09.500 --> 35:13.100\n And he was interested in how the hell that could happen.\n\n35:13.100 --> 35:20.620\n And he was trying to build good old fashioned AI style\n\n35:20.620 --> 35:30.020\n models of representation of language and content of things\n\n35:30.020 --> 35:32.300\n like has money.\n\n35:32.300 --> 35:35.420\n So like formal logic and knowledge bases,\n\n35:35.420 --> 35:36.740\n like that kind of stuff.\n\n35:36.740 --> 35:40.580\n So he was integrating that with his thinking about cognition.\n\n35:40.580 --> 35:45.100\n The mechanisms of cognition, how can they mechanistically\n\n35:45.100 --> 35:46.860\n be applied to build these knowledge,\n\n35:46.860 --> 35:49.860\n like to actually build something that\n\n35:49.860 --> 35:54.940\n looks like a web of knowledge and thereby from there emerges\n\n35:54.940 --> 35:57.740\n something like understanding, whatever the heck that is.\n\n35:57.740 --> 35:59.940\n Yeah, he was grappling.\n\n35:59.940 --> 36:01.700\n This was something that they grappled\n\n36:01.700 --> 36:04.260\n with at the end of that book that I was describing,\n\n36:04.260 --> 36:06.380\n Explorations in Cognition.\n\n36:06.380 --> 36:11.220\n But he was realizing that the paradigm of good old fashioned\n\n36:11.220 --> 36:16.140\n AI wasn't giving him the answers to these questions.\n\n36:16.140 --> 36:18.700\n By the way, that's called good old fashioned AI now.\n\n36:18.700 --> 36:20.540\n It wasn't called that at the time.\n\n36:20.540 --> 36:21.380\n Well, it was.\n\n36:21.380 --> 36:23.180\n It was beginning to be called that.\n\n36:23.180 --> 36:24.780\n Oh, because it was from the 60s.\n\n36:24.780 --> 36:26.380\n Yeah, yeah.\n\n36:26.380 --> 36:28.980\n By the late 70s, it was kind of old fashioned,\n\n36:28.980 --> 36:30.820\n and it hadn't really panned out.\n\n36:30.820 --> 36:34.300\n And people were beginning to recognize that.\n\n36:34.300 --> 36:37.940\n And Rommelhardt was like, yeah, he's part of the recognition\n\n36:37.940 --> 36:39.580\n that this wasn't all working.\n\n36:39.580 --> 36:48.860\n Anyway, so he started thinking in terms of the idea\n\n36:48.860 --> 36:52.260\n that we needed systems that allowed us to integrate\n\n36:52.260 --> 36:56.180\n multiple simultaneous constraints in a way that would\n\n36:56.180 --> 37:00.100\n be mutually influencing each other.\n\n37:00.100 --> 37:07.980\n So he wrote a paper that just really, first time I read it,\n\n37:07.980 --> 37:11.940\n I said, oh, well, yeah, but is this important?\n\n37:11.940 --> 37:15.180\n But after a while, it just got under my skin.\n\n37:15.180 --> 37:18.340\n And it was called An Interactive Model of Reading.\n\n37:18.340 --> 37:21.660\n And in this paper, he laid out the idea\n\n37:21.660 --> 37:34.700\n that every aspect of our interpretation of what's\n\n37:34.700 --> 37:40.180\n coming off the page when we read at every level of analysis\n\n37:40.180 --> 37:42.700\n you can think of actually depends\n\n37:42.700 --> 37:45.980\n on all the other levels of analysis.\n\n37:45.980 --> 37:53.940\n So what are the actual pixels making up each letter?\n\n37:53.940 --> 38:00.300\n And what do those pixels signify about which letters they are?\n\n38:00.300 --> 38:05.540\n And what do those letters tell us about what words are there?\n\n38:05.540 --> 38:09.940\n And what do those words tell us about what ideas\n\n38:09.940 --> 38:12.540\n the author is trying to convey?\n\n38:12.540 --> 38:18.860\n And so he had this model where we\n\n38:18.860 --> 38:25.940\n have these little tiny elements that represent\n\n38:25.940 --> 38:29.580\n each of the pixels of each of the letters,\n\n38:29.580 --> 38:31.780\n and then other ones that represent the line segments\n\n38:31.780 --> 38:33.900\n in them, and other ones that represent the letters,\n\n38:33.900 --> 38:36.340\n and other ones that represent the words.\n\n38:36.340 --> 38:43.100\n And at that time, his idea was there's this set of experts.\n\n38:43.100 --> 38:48.420\n There's an expert about how to construct a line out of pixels,\n\n38:48.420 --> 38:51.700\n and another expert about which sets of lines\n\n38:51.700 --> 38:53.260\n go together to make which letters,\n\n38:53.260 --> 38:55.340\n and another one about which letters go together\n\n38:55.340 --> 38:58.020\n to make which words, and another one about what\n\n38:58.020 --> 39:01.460\n the meanings of the words are, and another one about how\n\n39:01.460 --> 39:04.140\n the meanings fit together, and things like that.\n\n39:04.140 --> 39:06.220\n And all these experts are looking at this data,\n\n39:06.220 --> 39:12.740\n and they're updating hypotheses at other levels.\n\n39:12.740 --> 39:15.580\n So the word expert can tell the letter expert,\n\n39:15.580 --> 39:17.220\n oh, I think there should be a T there,\n\n39:17.220 --> 39:20.780\n because I think there should be a word the here.\n\n39:20.780 --> 39:23.580\n And the bottom up sort of feature to letter expert\n\n39:23.580 --> 39:25.660\n could say, I think there should be a T there, too.\n\n39:25.660 --> 39:28.700\n And if they agree, then you see a T, right?\n\n39:28.700 --> 39:32.540\n And so there's a top down, bottom up interactive process,\n\n39:32.540 --> 39:34.820\n but it's going on at all layers simultaneously.\n\n39:34.820 --> 39:37.140\n So everything can filter all the way down from the top,\n\n39:37.140 --> 39:39.180\n as well as all the way up from the bottom.\n\n39:39.180 --> 39:42.700\n And it's a completely interactive, bidirectional,\n\n39:42.700 --> 39:45.180\n parallel distributed process.\n\n39:45.180 --> 39:48.980\n That is somehow, because of the abstractions, it's hierarchical.\n\n39:48.980 --> 39:52.780\n So there's different layers of responsibilities,\n\n39:52.780 --> 39:54.700\n different levels of responsibilities.\n\n39:54.700 --> 39:56.620\n First of all, it's fascinating to think about it\n\n39:56.620 --> 39:58.460\n in this kind of mechanistic way.\n\n39:58.460 --> 40:02.100\n So not thinking purely from the structure\n\n40:02.100 --> 40:04.980\n of a neural network or something like a neural network,\n\n40:04.980 --> 40:06.860\n but thinking about these little guys\n\n40:06.860 --> 40:09.860\n that work on letters, and then the letters come words\n\n40:09.860 --> 40:11.620\n and words become sentences.\n\n40:11.620 --> 40:14.780\n And that's a very interesting hypothesis\n\n40:14.780 --> 40:18.420\n that from that kind of hierarchical structure\n\n40:18.420 --> 40:21.580\n can emerge understanding.\n\n40:21.580 --> 40:23.300\n Yeah, so, but the thing is, though,\n\n40:23.300 --> 40:25.700\n I wanna just sort of relate this\n\n40:25.700 --> 40:27.700\n to the earlier part of the conversation.\n\n40:28.980 --> 40:31.220\n When Romelhart was first thinking about it,\n\n40:31.220 --> 40:34.620\n there were these experts on the side,\n\n40:34.620 --> 40:36.860\n one for the features and one for the letters\n\n40:36.860 --> 40:39.900\n and one for how the letters make the words and so on.\n\n40:39.900 --> 40:43.060\n And they would each be working,\n\n40:43.060 --> 40:46.580\n sort of evaluating various propositions about,\n\n40:46.580 --> 40:48.980\n you know, is this combination of features here\n\n40:48.980 --> 40:52.620\n going to be one that looks like the letter T and so on.\n\n40:52.620 --> 40:56.700\n And what he realized,\n\n40:56.700 --> 40:59.380\n kind of after reading Hinton's dissertation\n\n40:59.380 --> 41:02.260\n and hearing about Jim Anderson's\n\n41:03.700 --> 41:06.060\n linear algebra based neural network models\n\n41:06.060 --> 41:07.620\n that I was telling you about before\n\n41:07.620 --> 41:10.780\n was that he could replace those experts\n\n41:10.780 --> 41:12.660\n with neuron like processing units,\n\n41:12.660 --> 41:14.700\n which just would have their connection weights\n\n41:14.700 --> 41:16.500\n that would do this job.\n\n41:16.500 --> 41:20.340\n So what ended up happening was\n\n41:20.340 --> 41:22.260\n that Romelhart and I got together\n\n41:22.260 --> 41:24.100\n and we created a model\n\n41:24.100 --> 41:29.020\n called the interactive activation model of letter perception,\n\n41:29.020 --> 41:34.020\n which takes these little pixel level inputs,\n\n41:35.980 --> 41:40.980\n constructs line segment features, letters and words.\n\n41:41.860 --> 41:44.780\n But now we built it out of a set of neuron\n\n41:44.780 --> 41:47.100\n like processing units that are just connected\n\n41:47.100 --> 41:49.540\n to each other with connection weights.\n\n41:49.540 --> 41:53.060\n So the unit for the word time has a connection\n\n41:53.060 --> 41:56.180\n to the unit for the letter T in the first position\n\n41:56.180 --> 41:59.940\n and the letter I in the second position, so on.\n\n41:59.940 --> 42:03.740\n And because these connections are bi directional,\n\n42:05.820 --> 42:08.820\n if you have prior knowledge that it might be the word time\n\n42:08.820 --> 42:12.020\n that starts to prime the letters and the features.\n\n42:12.020 --> 42:14.980\n And if you don't, then it has to start bottom up.\n\n42:14.980 --> 42:17.380\n But the directionality just depends\n\n42:17.380 --> 42:19.460\n on where the information comes in first.\n\n42:19.460 --> 42:22.100\n And if you have context together\n\n42:22.100 --> 42:24.260\n with features at the same time,\n\n42:24.260 --> 42:27.740\n they can convergently result in an emergent perception.\n\n42:27.740 --> 42:32.740\n And that was the piece of work that we did together\n\n42:35.780 --> 42:40.780\n that sort of got us both completely convinced\n\n42:41.260 --> 42:44.540\n that this neural network way of thinking\n\n42:44.540 --> 42:48.460\n was going to be able to actually address the questions\n\n42:48.460 --> 42:50.780\n that we were interested in as cognitive psychologists.\n\n42:50.780 --> 42:53.140\n So the algorithmic side, the optimization side,\n\n42:53.140 --> 42:56.460\n those are all details like when you first start the idea\n\n42:56.460 --> 42:59.420\n that you can get far with this kind of way of thinking,\n\n42:59.420 --> 43:01.420\n that in itself is a profound idea.\n\n43:01.420 --> 43:05.020\n So do you like the term connectionism\n\n43:05.020 --> 43:07.740\n to describe this kind of set of ideas?\n\n43:07.740 --> 43:08.860\n I think it's useful.\n\n43:10.100 --> 43:15.100\n It highlights the notion that the knowledge\n\n43:15.460 --> 43:19.820\n that the system exploits is in the connections\n\n43:19.820 --> 43:21.340\n between the units, right?\n\n43:21.340 --> 43:24.780\n There isn't a separate dictionary.\n\n43:24.780 --> 43:27.980\n There's just the connections between the units.\n\n43:27.980 --> 43:31.980\n So I already sort of laid that on the table\n\n43:31.980 --> 43:34.140\n with the connections from the letter units\n\n43:34.140 --> 43:36.900\n to the unit for the word time, right?\n\n43:36.900 --> 43:40.020\n The unit for the word time isn't a unit for the word time\n\n43:40.020 --> 43:43.180\n for any other reason than it's got the connections\n\n43:43.180 --> 43:46.020\n to the letters that make up the word time.\n\n43:46.020 --> 43:48.340\n Those are the units on the input that excited\n\n43:48.340 --> 43:52.660\n when it's excited that it in a sense represents\n\n43:52.660 --> 43:57.660\n in the system that there's support for the hypothesis\n\n43:57.700 --> 44:00.100\n that the word time is present in the input.\n\n44:01.860 --> 44:06.860\n But it's not, the word time isn't written anywhere\n\n44:07.420 --> 44:09.620\n inside the bottle, it's only written there\n\n44:09.620 --> 44:11.780\n in the picture we drew of the model\n\n44:11.780 --> 44:14.900\n to say that's the unit for the word time, right?\n\n44:14.900 --> 44:18.620\n And if somebody wants to tell me,\n\n44:18.620 --> 44:21.100\n well, how do you spell that word?\n\n44:21.100 --> 44:24.340\n You have to use the connections from that out\n\n44:24.340 --> 44:27.780\n to then get those letters, for example.\n\n44:27.780 --> 44:31.580\n That's such a, that's a counterintuitive idea\n\n44:31.580 --> 44:35.040\n where humans want to think in this logic way.\n\n44:36.220 --> 44:41.220\n This idea of connectionism, it doesn't, it's weird.\n\n44:41.580 --> 44:43.540\n It's weird that this is how it all works.\n\n44:43.540 --> 44:46.140\n Yeah, but let's go back to that CNN, right?\n\n44:46.140 --> 44:48.500\n That CNN with all those layers of neuron\n\n44:48.500 --> 44:51.540\n like processing units that we were talking about before,\n\n44:51.540 --> 44:54.420\n it's gonna come out and say, this is a cat, that's a dog,\n\n44:55.420 --> 44:57.740\n but it has no idea why it said that.\n\n44:57.740 --> 44:59.460\n It's just got all these connections\n\n44:59.460 --> 45:02.060\n between all these layers of neurons,\n\n45:02.060 --> 45:04.740\n like from the very first layer to the,\n\n45:04.740 --> 45:07.900\n you know, like whatever these layers are,\n\n45:07.900 --> 45:09.500\n they just get numbered after a while\n\n45:09.500 --> 45:13.660\n because they, you know, they somehow further in you go,\n\n45:13.660 --> 45:17.200\n the more abstract the features are,\n\n45:17.200 --> 45:20.320\n but it's a graded and continuous sort of process\n\n45:20.320 --> 45:21.660\n of abstraction anyway.\n\n45:21.660 --> 45:24.420\n And, you know, it goes from very local,\n\n45:24.420 --> 45:28.860\n very specific to much more sort of global,\n\n45:28.860 --> 45:32.020\n but it's still, you know, another sort of pattern\n\n45:32.020 --> 45:33.980\n of activation over an array of units.\n\n45:33.980 --> 45:36.500\n And then at the output side, it says it's a cat\n\n45:36.500 --> 45:37.380\n or it's a dog.\n\n45:37.380 --> 45:42.380\n And when I open my eyes and say, oh, that's Lex,\n\n45:42.460 --> 45:47.460\n or, oh, you know, there's my own dog\n\n45:47.620 --> 45:49.260\n and I recognize my dog,\n\n45:50.500 --> 45:53.060\n which is a member of the same species as many other dogs,\n\n45:53.060 --> 45:54.940\n but I know this one\n\n45:54.940 --> 45:57.420\n because of some slightly unique characteristics.\n\n45:57.420 --> 46:00.300\n I don't know how to describe what it is\n\n46:00.300 --> 46:02.500\n that makes me know that I'm looking at Lex\n\n46:02.500 --> 46:04.660\n or at my particular dog, right?\n\n46:04.660 --> 46:07.660\n Or even that I'm looking at a particular brand of car.\n\n46:07.660 --> 46:09.420\n Like I can say a few words about it,\n\n46:09.420 --> 46:12.820\n but I wrote you a paragraph about the car,\n\n46:12.820 --> 46:14.180\n you would have trouble figuring out\n\n46:14.180 --> 46:16.760\n which car is he talking about, right?\n\n46:16.760 --> 46:19.400\n So the idea that we have propositional knowledge\n\n46:19.400 --> 46:23.340\n of what it is that allows us to recognize\n\n46:23.340 --> 46:25.300\n that this is an actual instance\n\n46:25.300 --> 46:27.740\n of this particular natural kind\n\n46:27.740 --> 46:32.740\n has always been something that it never worked, right?\n\n46:36.540 --> 46:38.900\n You couldn't ever write down a set of propositions\n\n46:38.900 --> 46:41.540\n for visual recognition.\n\n46:41.540 --> 46:46.260\n And so in that space, it sort of always seemed very natural\n\n46:46.260 --> 46:49.320\n that something more implicit,\n\n46:51.540 --> 46:54.060\n you don't have access to what the details\n\n46:54.060 --> 46:56.500\n of the computation were in between,\n\n46:56.500 --> 46:58.320\n you just get the result.\n\n46:58.320 --> 47:00.100\n So that's the other part of connectionism,\n\n47:00.100 --> 47:04.020\n you cannot, you don't read the contents of the connections,\n\n47:04.020 --> 47:08.060\n the connections only cause outputs to occur\n\n47:08.060 --> 47:09.600\n based on inputs.\n\n47:09.600 --> 47:13.700\n Yeah, and for us that like final layer\n\n47:13.700 --> 47:16.580\n or some particular layer is very important,\n\n47:16.580 --> 47:19.500\n the one that tells us that it's our dog\n\n47:19.500 --> 47:22.220\n or like it's a cat or a dog,\n\n47:22.220 --> 47:25.420\n but each layer is probably equally as important\n\n47:25.420 --> 47:27.280\n in the grand scheme of things.\n\n47:27.280 --> 47:30.240\n Like there's no reason why the cat versus dog\n\n47:30.240 --> 47:33.140\n is more important than the lower level activations,\n\n47:33.140 --> 47:34.060\n it doesn't really matter.\n\n47:34.060 --> 47:36.820\n I mean, all of it is just this beautiful stacking\n\n47:36.820 --> 47:37.660\n on top of each other.\n\n47:37.660 --> 47:40.020\n And we humans live in this particular layers,\n\n47:40.020 --> 47:43.400\n for us it's useful to survive,\n\n47:43.400 --> 47:47.860\n to use those cat versus dog, predator versus prey,\n\n47:47.860 --> 47:49.180\n all those kinds of things.\n\n47:49.180 --> 47:51.260\n It's fascinating that it's all continuous,\n\n47:51.260 --> 47:53.700\n but then you then ask,\n\n47:53.700 --> 47:55.940\n the history of artificial intelligence, you ask,\n\n47:55.940 --> 47:59.420\n are we able to introspect and convert the very things\n\n47:59.420 --> 48:02.380\n that allow us to tell the difference between cat and dog\n\n48:02.380 --> 48:05.380\n into a logic, into formal logic?\n\n48:05.380 --> 48:06.620\n That's been the dream.\n\n48:06.620 --> 48:10.460\n I would say that's still part of the dream of symbolic AI.\n\n48:10.460 --> 48:15.460\n And I've recently talked to Doug Lenat who created Psych\n\n48:19.340 --> 48:23.180\n and that's a project that lasted for many decades\n\n48:23.180 --> 48:26.820\n and still carries a sort of dream in it, right?\n\n48:28.900 --> 48:30.700\n But we still don't know the answer, right?\n\n48:30.700 --> 48:34.840\n It seems like connectionism is really powerful,\n\n48:34.840 --> 48:38.740\n but it also seems like there's this building of knowledge.\n\n48:38.740 --> 48:41.420\n And so how do we, how do you square those two?\n\n48:41.420 --> 48:44.180\n Like, do you think the connections can contain\n\n48:44.180 --> 48:46.940\n the depth of human knowledge and the depth\n\n48:46.940 --> 48:51.500\n of what Dave Romahart was thinking about of understanding?\n\n48:51.500 --> 48:55.760\n Well, that remains the $64 question.\n\n48:55.760 --> 48:58.040\n And I...\n\n48:58.040 --> 48:59.840\n With inflation, that number is higher.\n\n48:59.840 --> 49:01.800\n Okay, $64,000.\n\n49:01.800 --> 49:04.640\n Maybe it's the $64 billion question now.\n\n49:08.800 --> 49:13.800\n You know, I think that from the emergentist side,\n\n49:13.800 --> 49:18.800\n which, you know, I placed myself on.\n\n49:23.760 --> 49:26.040\n So I used to sometimes tell people\n\n49:26.040 --> 49:29.660\n I was a radical, eliminative connectionist\n\n49:29.660 --> 49:34.420\n because I didn't want them to think\n\n49:34.420 --> 49:38.320\n that I wanted to build like anything into the machine.\n\n49:38.320 --> 49:43.320\n But I don't like the word eliminative anymore\n\n49:45.620 --> 49:50.620\n because it makes it seem like it's wrong to think\n\n49:51.060 --> 49:55.900\n that there is this emergent level of understanding.\n\n49:55.900 --> 50:00.140\n And I disagree with that.\n\n50:00.140 --> 50:02.300\n So I think, you know, I would call myself\n\n50:02.300 --> 50:06.920\n an a radical emergentist connectionist\n\n50:06.920 --> 50:09.500\n rather than eliminative connectionist, right?\n\n50:09.500 --> 50:12.540\n Because I want to acknowledge\n\n50:12.540 --> 50:17.540\n that these higher level kinds of aspects\n\n50:17.540 --> 50:22.060\n of our cognition are real, but they're not,\n\n50:26.700 --> 50:29.020\n they don't exist as such.\n\n50:29.020 --> 50:33.580\n And there was an example that Doug Hofstadter used to use\n\n50:33.580 --> 50:36.700\n that I thought was helpful in this respect.\n\n50:36.700 --> 50:41.340\n Just the idea that we can think about sand dunes\n\n50:42.980 --> 50:47.980\n as entities and talk about like how many there are even.\n\n50:51.420 --> 50:56.420\n But we also know that a sand dune is a very fluid thing.\n\n50:56.820 --> 51:00.740\n It's a pile of sand that is capable\n\n51:00.740 --> 51:07.180\n of moving around under the wind and reforming itself\n\n51:08.860 --> 51:10.140\n in somewhat different ways.\n\n51:10.140 --> 51:13.040\n And if we think about our thoughts as like sand dunes,\n\n51:13.040 --> 51:17.380\n as being things that emerge from just the way\n\n51:19.380 --> 51:22.460\n all the lower level elements sort of work together\n\n51:22.460 --> 51:25.800\n and are constrained by external forces,\n\n51:26.980 --> 51:29.680\n then we can say, yes, they exist as such,\n\n51:29.680 --> 51:34.680\n but they also, we shouldn't treat them\n\n51:34.820 --> 51:39.820\n as completely monolithic entities that we can understand\n\n51:40.400 --> 51:43.820\n without understanding sort of all of the stuff\n\n51:43.820 --> 51:47.540\n that allows them to change in the ways that they do.\n\n51:47.540 --> 51:49.220\n And that's where I think the connectionist\n\n51:49.220 --> 51:52.220\n feeds into the cognitive.\n\n51:52.220 --> 51:55.380\n It's like, okay, so if the substrate\n\n51:55.380 --> 52:00.380\n is parallel distributed connectionist, then it doesn't mean\n\n52:01.220 --> 52:05.980\n that the contents of thought isn't like abstract\n\n52:05.980 --> 52:10.340\n and symbolic, but it's more fluid maybe\n\n52:10.340 --> 52:13.060\n than it's easier to capture\n\n52:13.060 --> 52:15.420\n with a set of logical expressions.\n\n52:15.420 --> 52:17.740\n Yeah, that's a heck of a sort of thing\n\n52:17.740 --> 52:20.480\n to put at the top of a resume,\n\n52:20.480 --> 52:23.500\n radical, emergentist, connectionist.\n\n52:23.500 --> 52:26.940\n So there is, just like you said, a beautiful dance\n\n52:26.940 --> 52:30.380\n between that, between the machinery of intelligence,\n\n52:30.380 --> 52:32.340\n like the neural network side of it,\n\n52:32.340 --> 52:34.340\n and the stuff that emerges.\n\n52:34.340 --> 52:39.220\n I mean, the stuff that emerges seems to be,\n\n52:40.900 --> 52:44.020\n I don't know, I don't know what that is,\n\n52:44.020 --> 52:48.940\n that it seems like maybe all of reality is emergent.\n\n52:48.940 --> 52:53.940\n What I think about, this is made most distinctly rich to me\n\n52:57.380 --> 53:01.340\n when I look at cellular automata, look at game of life,\n\n53:01.340 --> 53:03.620\n that from very, very simple things,\n\n53:03.620 --> 53:06.780\n very rich, complex things emerge\n\n53:06.780 --> 53:10.260\n that start looking very quickly like organisms\n\n53:10.260 --> 53:13.620\n that you forget how the actual thing operates.\n\n53:13.620 --> 53:15.620\n They start looking like they're moving around,\n\n53:15.620 --> 53:16.500\n they're eating each other,\n\n53:16.500 --> 53:20.100\n some of them are generating offspring.\n\n53:20.100 --> 53:21.780\n You forget very quickly.\n\n53:21.780 --> 53:23.940\n And it seems like maybe it's something\n\n53:23.940 --> 53:26.060\n about the human mind that wants to operate\n\n53:26.060 --> 53:28.460\n in some layer of the emergent,\n\n53:28.460 --> 53:30.580\n and forget about the mechanism\n\n53:30.580 --> 53:32.220\n of how that emergence happens.\n\n53:32.220 --> 53:35.560\n So it, just like you are in your radicalness,\n\n53:35.560 --> 53:39.020\n I'm also, it seems like unfair\n\n53:39.020 --> 53:43.040\n to eliminate the magic of that emergent,\n\n53:43.040 --> 53:48.040\n like eliminate the fact that that emergent is real.\n\n53:48.280 --> 53:49.860\n Yeah, no, I agree.\n\n53:49.860 --> 53:53.220\n I'm not, that's why I got rid of eliminative, right?\n\n53:53.220 --> 53:54.060\n Eliminative, yeah.\n\n53:54.060 --> 53:56.580\n Yeah, because it seemed like that was trying to say\n\n53:56.580 --> 54:01.580\n that it's all completely like.\n\n54:01.860 --> 54:03.380\n An illusion of some kind, it's not.\n\n54:03.380 --> 54:06.180\n Well, who knows whether there isn't,\n\n54:06.180 --> 54:08.620\n there aren't some illusory characteristics there.\n\n54:08.620 --> 54:13.620\n And I think that philosophically many people\n\n54:15.020 --> 54:17.780\n have confronted that possibility over time,\n\n54:17.780 --> 54:22.780\n but it's still important to accept it as magic, right?\n\n54:26.300 --> 54:30.300\n So, I think of Fellini in this context,\n\n54:30.300 --> 54:35.300\n I think of others who have appreciated the role of magic,\n\n54:35.300 --> 54:39.180\n the role of magic, of actual trickery\n\n54:39.180 --> 54:44.180\n in creating illusions that move us.\n\n54:45.820 --> 54:47.380\n And Plato was on to this too.\n\n54:47.380 --> 54:49.900\n It's like somehow or other these shadows\n\n54:52.620 --> 54:55.900\n give rise to something much deeper than that.\n\n54:55.900 --> 55:00.900\n And that's, so we won't try to figure out what it is.\n\n55:01.060 --> 55:04.140\n We'll just accept it as given that that occurs.\n\n55:04.140 --> 55:08.660\n And, you know, but he was still onto the magic of it.\n\n55:08.660 --> 55:11.900\n Yeah, yeah, we won't try to really, really,\n\n55:11.900 --> 55:14.220\n really deeply understand how it works.\n\n55:14.220 --> 55:16.700\n We'll just enjoy the fact that it's kind of fun.\n\n55:16.700 --> 55:21.700\n Okay, but you worked closely with Dave Romo Hart.\n\n55:21.940 --> 55:24.960\n He passed away as a human being.\n\n55:24.960 --> 55:27.020\n What do you remember about him?\n\n55:27.020 --> 55:28.060\n Do you miss the guy?\n\n55:28.060 --> 55:33.060\n Absolutely, you know, he passed away 15ish years ago now.\n\n55:38.740 --> 55:43.740\n And his demise was actually one of the most poignant\n\n55:43.740 --> 55:52.740\n and, you know, like relevant tragedies, relevant to our conversation.\n\n55:52.740 --> 56:01.740\n He started to undergo a progressive neurological condition\n\n56:03.740 --> 56:08.740\n that isn't far from what we're used to.\n\n56:08.740 --> 56:15.740\n A neurological condition that isn't fully understood.\n\n56:15.740 --> 56:20.740\n That is to say his particular course isn't fully understood\n\n56:23.740 --> 56:28.740\n because, you know, brain scans weren't done at certain stages\n\n56:28.740 --> 56:32.740\n and no autopsy was done or anything like that.\n\n56:32.740 --> 56:34.740\n The wishes of the family.\n\n56:34.740 --> 56:38.740\n We don't know as much about the underlying pathology as we might,\n\n56:38.740 --> 56:48.740\n but I had begun to get interested in this neurological condition\n\n56:48.740 --> 56:52.740\n that might have been the very one that he was succumbing to\n\n56:52.740 --> 56:57.740\n as my own efforts to understand another aspect of this mystery\n\n56:57.740 --> 57:01.740\n that we've been discussing while he was beginning\n\n57:01.740 --> 57:04.740\n to get progressively more and more affected.\n\n57:04.740 --> 57:06.740\n So I'm going to talk about the disorder\n\n57:06.740 --> 57:09.740\n and not about Rumelhart for a second, okay?\n\n57:09.740 --> 57:12.740\n The disorder is something my colleagues and collaborators\n\n57:12.740 --> 57:17.740\n have chosen to call semantic dementia.\n\n57:17.740 --> 57:23.740\n So it's a specific form of loss of mind\n\n57:23.740 --> 57:27.740\n related to meaning, semantic dementia.\n\n57:27.740 --> 57:37.740\n And it's progressive in the sense that the patient loses the ability\n\n57:37.740 --> 57:44.740\n to appreciate the meaning of the experiences that they have,\n\n57:44.740 --> 57:50.740\n either from touch, from sight, from sound, from language.\n\n57:50.740 --> 57:56.740\n They, I hear sounds, but I don't know what they mean kind of thing.\n\n57:56.740 --> 58:04.740\n So as this illness progresses, it starts with the patient\n\n58:04.740 --> 58:12.740\n being unable to differentiate like similar breeds of dog\n\n58:12.740 --> 58:18.740\n or remember the lower frequency unfamiliar categories\n\n58:18.740 --> 58:21.740\n that they used to be able to remember.\n\n58:21.740 --> 58:27.740\n But as it progresses, it becomes more and more striking\n\n58:27.740 --> 58:36.740\n and the patient loses the ability to recognize things like\n\n58:36.740 --> 58:42.740\n pigs and goats and sheep and calls all middle sized animals dogs\n\n58:42.740 --> 58:46.740\n and can't recognize rabbits and rodents anymore.\n\n58:46.740 --> 58:49.740\n They call all the little ones cats\n\n58:49.740 --> 58:53.740\n and they can't recognize hippopotamuses and cows anymore.\n\n58:53.740 --> 58:55.740\n They call them all horses.\n\n58:55.740 --> 59:00.740\n So there was this one patient who went through this progression\n\n59:00.740 --> 59:03.740\n where at a certain point, any four legged animal,\n\n59:03.740 --> 59:07.740\n he would call it either a horse or a dog or a cat.\n\n59:07.740 --> 59:10.740\n And if it was big, he would tend to call it a horse.\n\n59:10.740 --> 59:12.740\n If it was small, he'd tend to call it a cat.\n\n59:12.740 --> 59:16.740\n Middle sized ones, he called dogs.\n\n59:16.740 --> 59:19.740\n This is just a part of the syndrome though.\n\n59:19.740 --> 59:25.740\n The patient loses the ability to relate concepts to each other.\n\n59:25.740 --> 59:28.740\n So my collaborator in this work, Carolyn Patterson,\n\n59:28.740 --> 59:34.740\n developed a test called the pyramids and palm trees test.\n\n59:34.740 --> 59:39.740\n So you give the patient a picture of pyramids\n\n59:39.740 --> 59:42.740\n and they have a choice which goes with the pyramids,\n\n59:42.740 --> 59:46.740\n palm trees or pine trees.\n\n59:46.740 --> 59:50.740\n And she showed that this wasn't just a matter of language\n\n59:50.740 --> 59:55.740\n because the patient's loss of this ability shows up\n\n59:55.740 --> 59:59.740\n whether you present the material with words or with pictures.\n\n59:59.740 --> 1:00:03.740\n The pictures, they can't put the pictures together\n\n1:00:03.740 --> 1:00:05.740\n with each other properly anymore.\n\n1:00:05.740 --> 1:00:07.740\n They can't relate the pictures to the words either.\n\n1:00:07.740 --> 1:00:09.740\n They can't do word picture matching.\n\n1:00:09.740 --> 1:00:12.740\n But they've lost the conceptual grounding\n\n1:00:12.740 --> 1:00:15.740\n from either modality of input.\n\n1:00:15.740 --> 1:00:19.740\n And so that's why it's called semantic dementia.\n\n1:00:19.740 --> 1:00:22.740\n The very semantics is disintegrating.\n\n1:00:22.740 --> 1:00:27.740\n And we understand this in terms of our idea\n\n1:00:27.740 --> 1:00:31.740\n that distributed representation, a pattern of activation,\n\n1:00:31.740 --> 1:00:33.740\n represents the concepts, really similar ones.\n\n1:00:33.740 --> 1:00:36.740\n As you degrade them, they start being,\n\n1:00:36.740 --> 1:00:40.740\n you lose the differences.\n\n1:00:40.740 --> 1:00:42.740\n So the difference between the dog and the goat\n\n1:00:42.740 --> 1:00:44.740\n is no longer part of the pattern anymore.\n\n1:00:44.740 --> 1:00:47.740\n And since dog is really familiar,\n\n1:00:47.740 --> 1:00:49.740\n that's the thing that remains.\n\n1:00:49.740 --> 1:00:52.740\n And we understand that in the way the models work and learn.\n\n1:00:52.740 --> 1:00:57.740\n But Rumelhart underwent this condition.\n\n1:00:57.740 --> 1:01:00.740\n So on the one hand, it's a fascinating aspect\n\n1:01:00.740 --> 1:01:03.740\n of parallel distributed processing to be.\n\n1:01:03.740 --> 1:01:08.740\n It reveals this sort of texture of distributed representation\n\n1:01:08.740 --> 1:01:11.740\n in a very nice way, I've always felt.\n\n1:01:11.740 --> 1:01:13.740\n But at the same time, it was extremely poignant\n\n1:01:13.740 --> 1:01:16.740\n because this is exactly the condition\n\n1:01:16.740 --> 1:01:18.740\n that Rumelhart was undergoing.\n\n1:01:18.740 --> 1:01:22.740\n And there was a period of time when he was this man\n\n1:01:22.740 --> 1:01:35.740\n who had been the most focused, goal directed, competitive,\n\n1:01:35.740 --> 1:01:41.740\n thoughtful person who was willing to work for years\n\n1:01:41.740 --> 1:01:48.740\n to solve a hard problem, he starts to disappear.\n\n1:01:48.740 --> 1:01:57.740\n And there was a period of time when it was hard for any of us\n\n1:01:57.740 --> 1:02:00.740\n to really appreciate that he was sort of, in some sense,\n\n1:02:00.740 --> 1:02:04.740\n not fully there anymore.\n\n1:02:04.740 --> 1:02:07.740\n Do you know if he was able to introspect\n\n1:02:07.740 --> 1:02:14.740\n the solution of the understanding mind?\n\n1:02:14.740 --> 1:02:19.740\n I mean, this is one of the big scientists that thinks about this.\n\n1:02:19.740 --> 1:02:24.740\n Was he able to look at himself and understand the fading mind?\n\n1:02:24.740 --> 1:02:31.740\n You know, we can contrast Hawking and Rumelhart in this way.\n\n1:02:31.740 --> 1:02:33.740\n And I like to do that to honor Rumelhart\n\n1:02:33.740 --> 1:02:36.740\n because I think Rumelhart is sort of like the Hawking\n\n1:02:36.740 --> 1:02:40.740\n of cognitive science to me in some ways.\n\n1:02:40.740 --> 1:02:45.740\n Both of them suffered from a degenerative condition.\n\n1:02:45.740 --> 1:02:49.740\n In Hawking's case, it affected the motor system.\n\n1:02:49.740 --> 1:02:54.740\n In Rumelhart's case, it's affecting the semantics.\n\n1:02:54.740 --> 1:03:01.740\n And not just the pure object semantics,\n\n1:03:01.740 --> 1:03:04.740\n but maybe the self semantics as well.\n\n1:03:04.740 --> 1:03:06.740\n And we don't understand that.\n\n1:03:06.740 --> 1:03:08.740\n Concepts broadly.\n\n1:03:08.740 --> 1:03:13.740\n So I would say he didn't.\n\n1:03:13.740 --> 1:03:16.740\n And this was part of what, from the outside,\n\n1:03:16.740 --> 1:03:18.740\n was a profound tragedy.\n\n1:03:18.740 --> 1:03:22.740\n But on the other hand, at some level, he sort of did\n\n1:03:22.740 --> 1:03:28.740\n because there was a period of time when it finally was realized\n\n1:03:28.740 --> 1:03:32.740\n that he had really become profoundly impaired.\n\n1:03:32.740 --> 1:03:35.740\n This was clearly a biological condition.\n\n1:03:35.740 --> 1:03:39.740\n It wasn't just like he was distracted that day or something like that.\n\n1:03:39.740 --> 1:03:44.740\n So he retired from his professorship at Stanford\n\n1:03:44.740 --> 1:03:51.740\n and he became, he lived with his brother for a couple years\n\n1:03:51.740 --> 1:04:00.740\n and then he moved into a facility for people with cognitive impairments.\n\n1:04:00.740 --> 1:04:06.740\n One that many elderly people end up in when they have cognitive impairments.\n\n1:04:06.740 --> 1:04:12.740\n And I would spend time with him during that period.\n\n1:04:12.740 --> 1:04:16.740\n This was like in the late 90s, around 2000 even.\n\n1:04:16.740 --> 1:04:25.740\n And we would go bowling and he could still bowl.\n\n1:04:25.740 --> 1:04:32.740\n And after bowling, I took him to lunch and I said,\n\n1:04:32.740 --> 1:04:34.740\n where would you like to go?\n\n1:04:34.740 --> 1:04:35.740\n You want to go to Wendy's?\n\n1:04:35.740 --> 1:04:37.740\n And he said, nah.\n\n1:04:37.740 --> 1:04:38.740\n And I said, okay, well, where do you want to go?\n\n1:04:38.740 --> 1:04:40.740\n And he just pointed.\n\n1:04:40.740 --> 1:04:41.740\n He said, turn here.\n\n1:04:41.740 --> 1:04:44.740\n So he still had a certain amount of spatial cognition\n\n1:04:44.740 --> 1:04:47.740\n and he could get me to the restaurant.\n\n1:04:47.740 --> 1:04:51.740\n And then when we got to the restaurant, I said,\n\n1:04:51.740 --> 1:04:53.740\n what do you want to order?\n\n1:04:53.740 --> 1:04:56.740\n And he couldn't come up with any of the words,\n\n1:04:56.740 --> 1:04:59.740\n but he knew where on the menu the thing was that he wanted.\n\n1:04:59.740 --> 1:05:04.740\n So it's, you know, and he couldn't say what it was,\n\n1:05:04.740 --> 1:05:07.740\n but he knew that that's what he wanted to eat.\n\n1:05:07.740 --> 1:05:14.740\n And so it's like it isn't monolithic at all.\n\n1:05:14.740 --> 1:05:21.740\n Our cognition is, you know, first of all, graded in certain kinds of ways,\n\n1:05:21.740 --> 1:05:27.740\n but also multipartite and there's many elements to it and things,\n\n1:05:27.740 --> 1:05:31.740\n certain sort of partial competencies still exist\n\n1:05:31.740 --> 1:05:36.740\n in the absence of other aspects of these competencies.\n\n1:05:36.740 --> 1:05:43.740\n So this is what always fascinated me about what used to be called\n\n1:05:43.740 --> 1:05:46.740\n cognitive neuropsychology, you know,\n\n1:05:46.740 --> 1:05:49.740\n the effects of brain damage on cognition.\n\n1:05:49.740 --> 1:05:53.740\n But in particular, this gradual disintegration part.\n\n1:05:53.740 --> 1:05:59.740\n You know, I'm a big believer that the loss of a human being that you value\n\n1:05:59.740 --> 1:06:03.740\n is as powerful as, you know, first falling in love with that human being.\n\n1:06:03.740 --> 1:06:06.740\n I think it's all a celebration of the human being.\n\n1:06:06.740 --> 1:06:10.740\n So the disintegration itself too is a celebration in a way.\n\n1:06:10.740 --> 1:06:12.740\n Yeah, yeah.\n\n1:06:12.740 --> 1:06:17.740\n But just to say something more about the scientist\n\n1:06:17.740 --> 1:06:22.740\n and the backpropagation idea that you mentioned.\n\n1:06:22.740 --> 1:06:34.740\n So in 1982, Hinton had been there as a postdoc and organized that conference.\n\n1:06:34.740 --> 1:06:37.740\n He'd actually gone away and gotten an assistant professorship\n\n1:06:37.740 --> 1:06:41.740\n and then there was this opportunity to bring him back.\n\n1:06:41.740 --> 1:06:45.740\n So Jeff Hinton was back on a sabbatical.\n\n1:06:45.740 --> 1:06:46.740\n San Diego.\n\n1:06:46.740 --> 1:06:52.740\n And Rommelhard and I had decided we wanted to do this, you know,\n\n1:06:52.740 --> 1:06:58.740\n we thought it was really exciting and the papers on the interactive activation model\n\n1:06:58.740 --> 1:07:00.740\n that I was telling you about had just been published\n\n1:07:00.740 --> 1:07:06.740\n and we both sort of saw a huge potential for this work and Jeff was there.\n\n1:07:06.740 --> 1:07:11.740\n And so the three of us started a research group,\n\n1:07:11.740 --> 1:07:13.740\n which we called the PDP Research Group.\n\n1:07:13.740 --> 1:07:17.740\n And several other people came.\n\n1:07:17.740 --> 1:07:22.740\n Francis Crick, who was at the Salk Institute, heard about it from Jeff\n\n1:07:22.740 --> 1:07:27.740\n because Jeff was known among Brits to be brilliant\n\n1:07:27.740 --> 1:07:30.740\n and Francis was well connected with his British friends.\n\n1:07:30.740 --> 1:07:32.740\n So Francis Crick came.\n\n1:07:32.740 --> 1:07:34.740\n That's a heck of a group of people, wow.\n\n1:07:34.740 --> 1:07:40.740\n And Paul Spolensky was one of the other postdocs.\n\n1:07:40.740 --> 1:07:41.740\n He was still there as a postdoc.\n\n1:07:41.740 --> 1:07:45.740\n And a few other people.\n\n1:07:45.740 --> 1:07:56.740\n But anyway, Jeff talked to us about learning\n\n1:07:56.740 --> 1:08:06.740\n and how we should think about how, you know, learning occurs in a neural network.\n\n1:08:06.740 --> 1:08:12.740\n And he said, the problem with the way you guys have been approaching this\n\n1:08:12.740 --> 1:08:17.740\n is that you've been looking for inspiration from biology\n\n1:08:17.740 --> 1:08:22.740\n to tell you what the rules should be for how the synapses should change\n\n1:08:22.740 --> 1:08:27.740\n the strengths of their connections, how the connections should form.\n\n1:08:27.740 --> 1:08:30.740\n He said, that's the wrong way to go about it.\n\n1:08:30.740 --> 1:08:36.740\n What you should do is you should think in terms of\n\n1:08:36.740 --> 1:08:44.740\n how you can adjust connection weights to solve a problem.\n\n1:08:44.740 --> 1:08:49.740\n So you define your problem and then you figure out\n\n1:08:49.740 --> 1:08:54.740\n how the adjustment of the connection weights will solve the problem.\n\n1:08:54.740 --> 1:09:01.740\n And Rumelhart heard that and said to himself, okay,\n\n1:09:01.740 --> 1:09:04.740\n so I'm going to start thinking about it that way.\n\n1:09:04.740 --> 1:09:11.740\n I'm going to essentially imagine that I have some objective function,\n\n1:09:11.740 --> 1:09:14.740\n some goal of the computation.\n\n1:09:14.740 --> 1:09:19.740\n I want my machine to correctly classify all of these images.\n\n1:09:19.740 --> 1:09:21.740\n And I can score that.\n\n1:09:21.740 --> 1:09:24.740\n I can measure how well they're doing on each image.\n\n1:09:24.740 --> 1:09:30.740\n And I get some measure of error or loss, it's typically called in deep learning.\n\n1:09:30.740 --> 1:09:35.740\n And I'm going to figure out how to adjust the connection weights\n\n1:09:35.740 --> 1:09:41.740\n so as to minimize my loss or reduce the error.\n\n1:09:41.740 --> 1:09:47.740\n And that's called, you know, gradient descent.\n\n1:09:47.740 --> 1:09:53.740\n And engineers were already familiar with the concept of gradient descent.\n\n1:09:53.740 --> 1:09:58.740\n And in fact, there was an algorithm called the delta rule\n\n1:09:58.740 --> 1:10:07.740\n that had been invented by a professor in the electrical engineering department\n\n1:10:07.740 --> 1:10:11.740\n at Stanford, Bernie Widrow and a collaborator named Hoff.\n\n1:10:11.740 --> 1:10:13.740\n I never met him.\n\n1:10:13.740 --> 1:10:19.740\n So gradient descent in continuous neural networks\n\n1:10:19.740 --> 1:10:26.740\n with multiple neuron like processing units was already understood\n\n1:10:26.740 --> 1:10:29.740\n for a single layer of connection weights.\n\n1:10:29.740 --> 1:10:32.740\n We have some inputs over a set of neurons.\n\n1:10:32.740 --> 1:10:35.740\n We want the output to produce a certain pattern.\n\n1:10:35.740 --> 1:10:38.740\n We can define the difference between our target\n\n1:10:38.740 --> 1:10:41.740\n and what the neural network is producing.\n\n1:10:41.740 --> 1:10:44.740\n And we can figure out how to change the connection weights to reduce that error.\n\n1:10:44.740 --> 1:10:49.740\n So what Romilhar did was to generalize that\n\n1:10:49.740 --> 1:10:53.740\n so as to be able to change the connections from earlier layers of units\n\n1:10:53.740 --> 1:10:58.740\n to the ones at a hidden layer between the input and the output.\n\n1:10:58.740 --> 1:11:03.740\n And so he first called the algorithm the generalized delta rule\n\n1:11:03.740 --> 1:11:08.740\n because it's just an extension of the gradient descent idea.\n\n1:11:08.740 --> 1:11:15.740\n And interestingly enough, Hinton was thinking that this wasn't going to work very well.\n\n1:11:15.740 --> 1:11:20.740\n So Hinton had his own alternative algorithm at the time\n\n1:11:20.740 --> 1:11:24.740\n based on the concept of the Boltzmann machine that he was pursuing.\n\n1:11:24.740 --> 1:11:27.740\n So the paper on the Boltzmann machine came out in,\n\n1:11:27.740 --> 1:11:31.740\n learning in Boltzmann machines came out in 1985.\n\n1:11:31.740 --> 1:11:37.740\n But it turned out that back prop worked better than the Boltzmann machine learning algorithm.\n\n1:11:37.740 --> 1:11:44.740\n So this generalized delta algorithm ended up being called back propagation, as you say, back prop.\n\n1:11:44.740 --> 1:11:50.740\n Yeah. And probably that name is opaque to me.\n\n1:11:50.740 --> 1:11:53.740\n What does that mean?\n\n1:11:53.740 --> 1:11:59.740\n What it meant was that in order to figure out what the changes you needed to make\n\n1:11:59.740 --> 1:12:03.740\n to the connections from the input to the hidden layer,\n\n1:12:03.740 --> 1:12:10.740\n you had to back propagate the error signals from the output layer\n\n1:12:10.740 --> 1:12:15.740\n through the connections from the hidden layer to the output\n\n1:12:15.740 --> 1:12:20.740\n to get the signals that would be the error signals for the hidden layer.\n\n1:12:20.740 --> 1:12:22.740\n And that's how Rumelhart formulated it.\n\n1:12:22.740 --> 1:12:25.740\n It was like, well, we know what the error signals are at the output layer.\n\n1:12:25.740 --> 1:12:28.740\n Let's see if we can get a signal at the hidden layer\n\n1:12:28.740 --> 1:12:32.740\n that tells each hidden unit what its error signal is essentially.\n\n1:12:32.740 --> 1:12:37.740\n So it's back propagating through the connections\n\n1:12:37.740 --> 1:12:41.740\n from the hidden to the output to get the signals to tell the hidden units\n\n1:12:41.740 --> 1:12:43.740\n how to change their weights from the input.\n\n1:12:43.740 --> 1:12:47.740\n And that's why it's called back prop.\n\n1:12:47.740 --> 1:12:54.740\n Yeah. But so it came from Hinton having introduced the concept of, you know,\n\n1:12:54.740 --> 1:12:59.740\n define your objective function, figure out how to take the derivative\n\n1:12:59.740 --> 1:13:04.740\n so that you can adjust the connections so that they make progress towards your goal.\n\n1:13:04.740 --> 1:13:06.740\n So stop thinking about biology for a second\n\n1:13:06.740 --> 1:13:12.740\n and let's start to think about optimization and computation a little bit more.\n\n1:13:12.740 --> 1:13:15.740\n So what about Jeff Hinton?\n\n1:13:15.740 --> 1:13:20.740\n You've gotten a chance to work with him in that little thing.\n\n1:13:20.740 --> 1:13:24.740\n The set of people involved there is quite incredible.\n\n1:13:24.740 --> 1:13:28.740\n The small set of people under the PDP flag,\n\n1:13:28.740 --> 1:13:32.740\n it's just given the amount of impact those ideas have had over the years,\n\n1:13:32.740 --> 1:13:34.740\n it's kind of incredible to think about.\n\n1:13:34.740 --> 1:13:38.740\n But, you know, just like you said, like yourself,\n\n1:13:38.740 --> 1:13:43.740\n Jeffrey Hinton is seen as one of the, not just like a seminal figure in AI,\n\n1:13:43.740 --> 1:13:45.740\n but just a brilliant person,\n\n1:13:45.740 --> 1:13:49.740\n just like the horsepower of the mind is pretty high up there for him\n\n1:13:49.740 --> 1:13:52.740\n because he's just a great thinker.\n\n1:13:52.740 --> 1:13:57.740\n So what kind of ideas have you learned from him?\n\n1:13:57.740 --> 1:13:59.740\n Have you influenced each other on?\n\n1:13:59.740 --> 1:14:05.740\n Have you debated over what stands out to you in the full space of ideas here\n\n1:14:05.740 --> 1:14:09.740\n at the intersection of computation and cognition?\n\n1:14:09.740 --> 1:14:18.740\n Well, so Jeff has said many things to me that had a profound impact on my thinking.\n\n1:14:18.740 --> 1:14:26.740\n And he's written several articles which were way ahead of their time.\n\n1:14:26.740 --> 1:14:37.740\n He had two papers in 1981, just to give one example,\n\n1:14:37.740 --> 1:14:42.740\n one of which was essentially the idea of transformers\n\n1:14:42.740 --> 1:14:49.740\n and another of which was an early paper on semantic cognition\n\n1:14:49.740 --> 1:15:01.740\n which inspired him and Rumelhart and me throughout the 80s\n\n1:15:01.740 --> 1:15:11.740\n and, you know, still I think sort of grounds my own thinking\n\n1:15:11.740 --> 1:15:16.740\n about the semantic aspects of cognition.\n\n1:15:16.740 --> 1:15:25.740\n He also, in a small paper that was never published that he wrote in 1977,\n\n1:15:25.740 --> 1:15:29.740\n you know, before he actually arrived at UCSD or maybe a couple years even before that,\n\n1:15:29.740 --> 1:15:32.740\n I don't know, when he was a PhD student,\n\n1:15:32.740 --> 1:15:40.740\n he described how a neural network could do recursive computation.\n\n1:15:40.740 --> 1:15:48.740\n And it was a very clever idea that he's continued to explore over time,\n\n1:15:48.740 --> 1:15:56.740\n which was sort of the idea that when you call a subroutine,\n\n1:15:56.740 --> 1:16:01.740\n you need to save the state that you had when you called it\n\n1:16:01.740 --> 1:16:04.740\n so you can get back to where you were when you're finished with the subroutine.\n\n1:16:04.740 --> 1:16:10.740\n And the idea was that you would save the state of the calling routine\n\n1:16:10.740 --> 1:16:13.740\n by making fast changes to connection weights.\n\n1:16:13.740 --> 1:16:19.740\n And then when you finished with the subroutine call,\n\n1:16:19.740 --> 1:16:23.740\n those fast changes in the connection weights would allow you to go back\n\n1:16:23.740 --> 1:16:27.740\n to where you had been before and reinstate the previous context\n\n1:16:27.740 --> 1:16:32.740\n so that you could continue on with the top level of the computation.\n\n1:16:32.740 --> 1:16:35.740\n Anyway, that was part of the idea.\n\n1:16:35.740 --> 1:16:38.740\n And I always thought, okay, that's really, you know,\n\n1:16:38.740 --> 1:16:44.740\n he had extremely creative ideas that were quite a lot ahead of his time\n\n1:16:44.740 --> 1:16:49.740\n and many of them in the 1970s and early 1980s.\n\n1:16:49.740 --> 1:16:57.740\n So another thing about Geoff Hinton's way of thinking,\n\n1:16:57.740 --> 1:17:05.740\n which has profoundly influenced my effort to understand\n\n1:17:05.740 --> 1:17:13.740\n human mathematical cognition, is that he doesn't write too many equations.\n\n1:17:13.740 --> 1:17:17.740\n And people tell stories like, oh, in the Hinton Lab meetings,\n\n1:17:17.740 --> 1:17:19.740\n you don't get up at the board and write equations\n\n1:17:19.740 --> 1:17:22.740\n like you do in everybody else's machine learning lab.\n\n1:17:22.740 --> 1:17:26.740\n What you do is you draw a picture.\n\n1:17:26.740 --> 1:17:33.740\n And, you know, he explains aspects of the way deep learning works\n\n1:17:33.740 --> 1:17:38.740\n by putting his hands together and showing you the shape of a ravine\n\n1:17:38.740 --> 1:17:45.740\n and using that as a geometrical metaphor for what's happening\n\n1:17:45.740 --> 1:17:47.740\n as this gradient descent process.\n\n1:17:47.740 --> 1:17:49.740\n You're coming down the wall of a ravine.\n\n1:17:49.740 --> 1:17:53.740\n If you take too big a jump, you're going to jump to the other side.\n\n1:17:53.740 --> 1:17:59.740\n And so that's why we have to turn down the learning rate, for example.\n\n1:17:59.740 --> 1:18:12.740\n And it speaks to me of the fundamentally intuitive character of deep insight\n\n1:18:12.740 --> 1:18:21.740\n together with a commitment to really understanding\n\n1:18:21.740 --> 1:18:31.740\n in a way that's absolutely ultimately explicit and clear, but also intuitive.\n\n1:18:31.740 --> 1:18:33.740\n Yeah, there's certain people like that.\n\n1:18:33.740 --> 1:18:38.740\n Here's an example, some kind of weird mix of visual and intuitive\n\n1:18:38.740 --> 1:18:40.740\n and all those kinds of things.\n\n1:18:40.740 --> 1:18:44.740\n Feynman is another example, different style of thinking, but very unique.\n\n1:18:44.740 --> 1:18:48.740\n And when you're around those people, for me in the engineering realm,\n\n1:18:48.740 --> 1:18:52.740\n there's a guy named Jim Keller who's a chip designer, engineer.\n\n1:18:52.740 --> 1:18:57.740\n Every time I talk to him, it doesn't matter what we're talking about.\n\n1:18:57.740 --> 1:19:02.740\n Just having experienced that unique way of thinking transforms you\n\n1:19:02.740 --> 1:19:04.740\n and makes your work much better.\n\n1:19:04.740 --> 1:19:06.740\n And that's the magic.\n\n1:19:06.740 --> 1:19:10.740\n You look at Daniel Kahneman, you look at the great collaborations\n\n1:19:10.740 --> 1:19:12.740\n throughout the history of science.\n\n1:19:12.740 --> 1:19:13.740\n That's the magic of that.\n\n1:19:13.740 --> 1:19:16.740\n It's not always the exact ideas that you talk about,\n\n1:19:16.740 --> 1:19:19.740\n but it's the process of generating those ideas.\n\n1:19:19.740 --> 1:19:22.740\n Being around that, spending time with that human being,\n\n1:19:22.740 --> 1:19:24.740\n you can come up with some brilliant work,\n\n1:19:24.740 --> 1:19:29.740\n especially when it's cross disciplinary as it was a little bit in your case with Jeff.\n\n1:19:29.740 --> 1:19:31.740\n Yeah.\n\n1:19:31.740 --> 1:19:38.740\n Jeff is a descendant of the logician Boole.\n\n1:19:38.740 --> 1:19:43.740\n He comes from a long line of English academics.\n\n1:19:43.740 --> 1:19:51.740\n And together with the deeply intuitive thinking ability that he has,\n\n1:19:51.740 --> 1:19:59.740\n he also has, it's been clear, he's described this to me,\n\n1:19:59.740 --> 1:20:04.740\n and I think he's mentioned it from time to time in other interviews\n\n1:20:04.740 --> 1:20:06.740\n that he's had with people.\n\n1:20:06.740 --> 1:20:12.740\n He's wanted to be able to sort of think of himself as contributing\n\n1:20:12.740 --> 1:20:22.740\n to the understanding of reasoning itself, not just human reasoning.\n\n1:20:22.740 --> 1:20:25.740\n Like Boole is about logic, right?\n\n1:20:25.740 --> 1:20:31.740\n It's about what can we conclude from what else and how do we formalize that.\n\n1:20:31.740 --> 1:20:40.740\n And as a computer scientist, logician, philosopher,\n\n1:20:40.740 --> 1:20:46.740\n the goal is to understand how we derive truths from other,\n\n1:20:46.740 --> 1:20:48.740\n from givens and things like this.\n\n1:20:48.740 --> 1:20:57.740\n And the work that Jeff was doing in the early to mid 80s\n\n1:20:57.740 --> 1:21:02.740\n on something called the Bolton machine was his way of connecting\n\n1:21:02.740 --> 1:21:07.740\n with that Boolean tradition and bringing it into the more continuous,\n\n1:21:07.740 --> 1:21:11.740\n probabilistic graded constraint satisfaction realm.\n\n1:21:11.740 --> 1:21:20.740\n And it was a beautiful set of ideas linked with theoretical physics\n\n1:21:20.740 --> 1:21:26.740\n as well as with logic.\n\n1:21:26.740 --> 1:21:31.740\n And it's always been, I mean, I've always been inspired\n\n1:21:31.740 --> 1:21:33.740\n by the Bolton machine too.\n\n1:21:33.740 --> 1:21:38.740\n It's like, well, if the neurons are probabilistic rather than deterministic\n\n1:21:38.740 --> 1:21:48.740\n in their computations, then maybe this somehow is part of the serendipity\n\n1:21:48.740 --> 1:21:53.740\n or adventitiousness of the moment of insight, right?\n\n1:21:53.740 --> 1:21:56.740\n It might not have occurred at that particular instant.\n\n1:21:56.740 --> 1:22:00.740\n It might be sort of partially the result of a stochastic process.\n\n1:22:00.740 --> 1:22:07.740\n And that too is part of the magic of the emergence of some of these things.\n\n1:22:07.740 --> 1:22:11.740\n Well, you're right with the Boolean lineage and the dream of computer science\n\n1:22:11.740 --> 1:22:16.740\n is somehow, I mean, I certainly think of humans this way,\n\n1:22:16.740 --> 1:22:20.740\n that humans are one particular manifestation of intelligence,\n\n1:22:20.740 --> 1:22:25.740\n that there's something bigger going on and you're hoping to figure that out.\n\n1:22:25.740 --> 1:22:28.740\n The mechanisms of intelligence, the mechanisms of cognition\n\n1:22:28.740 --> 1:22:30.740\n are much bigger than just humans.\n\n1:22:30.740 --> 1:22:37.740\n Yeah. So I think of, I started using the phrase computational intelligence\n\n1:22:37.740 --> 1:22:42.740\n at some point as to characterize the field that I thought, you know,\n\n1:22:42.740 --> 1:22:51.740\n people like Geoff Hinton and many of the people I know at DeepMind\n\n1:22:51.740 --> 1:23:00.740\n are working in and where I feel like I'm, you know,\n\n1:23:00.740 --> 1:23:06.740\n I'm a kind of a human oriented computational intelligence researcher\n\n1:23:06.740 --> 1:23:10.740\n in that I'm actually kind of interested in the human solution.\n\n1:23:10.740 --> 1:23:18.740\n But at the same time, I feel like that's where a huge amount\n\n1:23:18.740 --> 1:23:26.740\n of the excitement of deep learning actually lies is in the idea that,\n\n1:23:26.740 --> 1:23:32.740\n you know, we may be able to even go beyond what we can achieve\n\n1:23:32.740 --> 1:23:38.740\n with our own nervous systems when we build computational intelligences\n\n1:23:38.740 --> 1:23:46.740\n that are, you know, not limited in the ways that we are by our own biology.\n\n1:23:46.740 --> 1:23:51.740\n Perhaps allowing us to scale the very mechanisms of human intelligence\n\n1:23:51.740 --> 1:23:55.740\n just increases power through scale.\n\n1:23:55.740 --> 1:24:03.740\n Yes. And I think that that, you know, obviously that's the,\n\n1:24:03.740 --> 1:24:08.740\n that's being played out massively at Google Brain, at OpenAI\n\n1:24:08.740 --> 1:24:11.740\n and to some extent at DeepMind as well.\n\n1:24:11.740 --> 1:24:14.740\n I guess I shouldn't say to some extent.\n\n1:24:14.740 --> 1:24:22.740\n Just the massive scale of the computations that are used to succeed\n\n1:24:22.740 --> 1:24:25.740\n at games like Go or to solve the protein folding problems\n\n1:24:25.740 --> 1:24:27.740\n that they've been solving and so on.\n\n1:24:27.740 --> 1:24:31.740\n Still not as many synapses and neurons as the human brain.\n\n1:24:31.740 --> 1:24:35.740\n So we still got, we're still beating them on that.\n\n1:24:35.740 --> 1:24:41.740\n We humans are beating the AIs, but they're catching up pretty quickly.\n\n1:24:41.740 --> 1:24:45.740\n You write about modeling of mathematical cognition.\n\n1:24:45.740 --> 1:24:49.740\n So let me first ask about mathematics in general.\n\n1:24:49.740 --> 1:24:53.740\n There's a paper titled Parallel Distributed Processing\n\n1:24:53.740 --> 1:24:56.740\n Approach to Mathematical Cognition where in the introduction\n\n1:24:56.740 --> 1:25:00.740\n there's some beautiful discussion of mathematics.\n\n1:25:00.740 --> 1:25:05.740\n And you referenced there Tristan Needham who criticizes a narrow\n\n1:25:05.740 --> 1:25:10.740\n form of view of mathematics by liking the studying of mathematics\n\n1:25:10.740 --> 1:25:16.740\n as symbol manipulation to studying music without ever hearing a note.\n\n1:25:16.740 --> 1:25:20.740\n So from that perspective, what do you think is mathematics?\n\n1:25:20.740 --> 1:25:23.740\n What is this world of mathematics like?\n\n1:25:23.740 --> 1:25:32.740\n Well, I think of mathematics as a set of tools for exploring\n\n1:25:32.740 --> 1:25:42.740\n idealized worlds that often turn out to be extremely relevant\n\n1:25:42.740 --> 1:25:47.740\n to the real world but need not.\n\n1:25:47.740 --> 1:26:01.740\n But they're worlds in which objects exist with idealized properties\n\n1:26:01.740 --> 1:26:07.740\n and in which the relationships among them can be characterized\n\n1:26:07.740 --> 1:26:17.740\n with precision so as to allow the implications of certain facts\n\n1:26:17.740 --> 1:26:22.740\n to then allow you to derive other facts with certainty.\n\n1:26:22.740 --> 1:26:37.740\n So if you have two triangles and you know that there is an angle\n\n1:26:37.740 --> 1:26:42.740\n in the first one that has the same measure as an angle in the second one\n\n1:26:42.740 --> 1:26:47.740\n and you know that the lengths of the sides adjacent to that angle\n\n1:26:47.740 --> 1:26:53.740\n in each of the two triangles, the corresponding sides adjacent\n\n1:26:53.740 --> 1:26:58.740\n to that angle also have the same measure, then you can then conclude\n\n1:26:58.740 --> 1:27:02.740\n that the triangles are congruent.\n\n1:27:02.740 --> 1:27:06.740\n That is to say they have all of their properties in common.\n\n1:27:06.740 --> 1:27:11.740\n And that is something about triangles.\n\n1:27:11.740 --> 1:27:15.740\n It's not a matter of formulas.\n\n1:27:15.740 --> 1:27:18.740\n These are idealized objects.\n\n1:27:18.740 --> 1:27:26.740\n In fact, we built bridges out of triangles and we understand\n\n1:27:26.740 --> 1:27:32.740\n how to measure the height of something we can't climb by extending\n\n1:27:32.740 --> 1:27:36.740\n these ideas about triangles a little further.\n\n1:27:36.740 --> 1:27:49.740\n And all of the ability to get a tiny speck of matter launched\n\n1:27:49.740 --> 1:27:56.740\n from the planet Earth to intersect with some tiny, tiny little body\n\n1:27:56.740 --> 1:28:02.740\n way out in way beyond Pluto somewhere at exactly a predicted time\n\n1:28:02.740 --> 1:28:08.740\n and date is something that depends on these ideas.\n\n1:28:08.740 --> 1:28:18.740\n And it's actually happening in the real physical world that these ideas\n\n1:28:18.740 --> 1:28:27.740\n make contact with it in those kinds of instances.\n\n1:28:27.740 --> 1:28:32.740\n But there are these idealized objects, these triangles or these distances\n\n1:28:32.740 --> 1:28:40.740\n or these points, whatever they are, that allow for this set of tools\n\n1:28:40.740 --> 1:28:47.740\n to be created that then gives human beings this incredible leverage\n\n1:28:47.740 --> 1:28:51.740\n that they didn't have without these concepts.\n\n1:28:51.740 --> 1:29:01.740\n And I think this is actually already true when we think about just,\n\n1:29:01.740 --> 1:29:06.740\n you know, the natural numbers.\n\n1:29:06.740 --> 1:29:11.740\n I always like to include zero, so I'm going to say the nonnegative integers,\n\n1:29:11.740 --> 1:29:17.740\n but that's a place where some people prefer not to include zero.\n\n1:29:17.740 --> 1:29:21.740\n We like zero here, natural numbers, zero, one, two, three, four, five,\n\n1:29:21.740 --> 1:29:23.740\n six, seven, and so on.\n\n1:29:23.740 --> 1:29:36.740\n Yeah. And because they give you the ability to be exact about\n\n1:29:36.740 --> 1:29:38.740\n how many sheep you have.\n\n1:29:38.740 --> 1:29:41.740\n I sent you out this morning, there were 23 sheep.\n\n1:29:41.740 --> 1:29:44.740\n You came back with only 22. What happened?\n\n1:29:44.740 --> 1:29:48.740\n The fundamental problem of physics, how many sheep you have.\n\n1:29:48.740 --> 1:29:53.740\n It's a fundamental problem of human society that you damn well better\n\n1:29:53.740 --> 1:29:57.740\n bring back the same number of sheep as you started with.\n\n1:29:57.740 --> 1:30:03.740\n And it allows commerce, it allows contracts, it allows the establishment\n\n1:30:03.740 --> 1:30:10.740\n of records and so on to have systems that allow these things to be notated.\n\n1:30:10.740 --> 1:30:20.740\n But they have an inherent aboutness to them that's one in the same time sort of\n\n1:30:20.740 --> 1:30:26.740\n abstract and idealized and generalizable, while on the other hand,\n\n1:30:26.740 --> 1:30:30.740\n potentially very, very grounded and concrete.\n\n1:30:30.740 --> 1:30:41.740\n And one of the things that makes for the incredible achievements of the human mind\n\n1:30:41.740 --> 1:30:49.740\n is the fact that humans invented these idealized systems that leverage\n\n1:30:49.740 --> 1:30:57.740\n the power of human thought in such a way as to allow all this kind of thing to happen.\n\n1:30:57.740 --> 1:31:06.740\n And so that's what mathematics to me is the development of systems for thinking about\n\n1:31:06.740 --> 1:31:18.740\n the properties and relations among sets of idealized objects and\n\n1:31:18.740 --> 1:31:26.740\n the mathematical notation system that we unfortunately focus way too much on\n\n1:31:26.740 --> 1:31:36.740\n is just our way of expressing propositions about these properties.\n\n1:31:36.740 --> 1:31:39.740\n It's just like we're talking with Chomsky in language.\n\n1:31:39.740 --> 1:31:43.740\n It's the thing we've invented for the communication of those ideas.\n\n1:31:43.740 --> 1:31:48.740\n They're not necessarily the deep representation of those ideas.\n\n1:31:48.740 --> 1:31:57.740\n So what's a good way to model such powerful mathematical reasoning, would you say?\n\n1:31:57.740 --> 1:32:01.740\n What are some ideas you have for capturing this in a model?\n\n1:32:01.740 --> 1:32:10.740\n The insights that human mathematicians have had is a combination of the kind of the\n\n1:32:10.740 --> 1:32:24.740\n intuitive kind of connectionist like knowledge that makes it so that something is just like\n\n1:32:24.740 --> 1:32:31.740\n obviously true so that you don't have to think about why it's true.\n\n1:32:31.740 --> 1:32:40.740\n That then makes it possible to then take the next step and ponder and reason and\n\n1:32:40.740 --> 1:32:45.740\n figure out something that you previously didn't have that intuition about.\n\n1:32:45.740 --> 1:32:54.740\n It then ultimately becomes a part of the intuition that the next generation of\n\n1:32:54.740 --> 1:33:02.740\n mathematical thinkers have to ground their own thinking on so that they can extend the ideas even further.\n\n1:33:02.740 --> 1:33:15.740\n I came across this quotation from Henri Poincare while I was walking in the woods with my wife\n\n1:33:15.740 --> 1:33:20.740\n in a state park in Northern California late last summer.\n\n1:33:20.740 --> 1:33:32.740\n And what it said on the bench was it is by logic that we prove but by intuition that we discover.\n\n1:33:32.740 --> 1:33:41.740\n And so what for me the essence of the project is to understand how to bring the intuitive\n\n1:33:41.740 --> 1:33:56.740\n connectionist resources to bear on letting the intuitive discovery arise from engagement in\n\n1:33:56.740 --> 1:33:59.740\n thinking with this formal system.\n\n1:33:59.740 --> 1:34:14.740\n So I think of the ability of somebody like Hinton or Newton or Einstein or Rumelhart or\n\n1:34:14.740 --> 1:34:21.740\n Poincare to Archimedes is another example.\n\n1:34:21.740 --> 1:34:31.740\n So suddenly a flash of insight occurs. It's like the constellation of all of these\n\n1:34:31.740 --> 1:34:38.740\n simultaneous constraints that somehow or other causes the mind to settle into a novel state that\n\n1:34:38.740 --> 1:34:51.740\n it never did before and give rise to a new idea that then you can say, okay, well, now how can I\n\n1:34:51.740 --> 1:35:01.740\n prove this? How do I write down the steps of that theorem that allow me to make it rigorous and certain?\n\n1:35:01.740 --> 1:35:14.740\n And so I feel like the kinds of things that we're beginning to see deep learning systems do of\n\n1:35:14.740 --> 1:35:34.740\n their own accord kind of gives me this feeling of hope or encouragement that ultimately it'll all happen.\n\n1:35:34.740 --> 1:35:46.740\n So in particular as many people now have become really interested in thinking about, you know,\n\n1:35:46.740 --> 1:35:55.740\n neural networks that have been trained with massive amounts of text can be given a prompt and they\n\n1:35:55.740 --> 1:36:05.740\n can then sort of generate some really interesting, fanciful, creative story from that prompt.\n\n1:36:05.740 --> 1:36:15.740\n And there's kind of like a sense that they've somehow synthesized something like novel out of\n\n1:36:15.740 --> 1:36:22.740\n the, you know, all of the particulars of all of the billions and billions of experiences that went\n\n1:36:22.740 --> 1:36:29.740\n into the training data that gives rise to something like this sort of intuitive sense of what would\n\n1:36:29.740 --> 1:36:36.740\n be a fun and interesting little story to tell or something like that. It just sort of wells up out\n\n1:36:36.740 --> 1:36:47.740\n of the letting the thing play out its own imagining of what somebody might say given this prompt as\n\n1:36:47.740 --> 1:36:56.740\n an input to get it to start to generate its own thoughts. And to me that sort of represents the\n\n1:36:56.740 --> 1:37:01.740\n potential of capturing the intuitive side of this.\n\n1:37:01.740 --> 1:37:06.740\n And there's other examples, I don't know if you find them as captivating is, you know, on the\n\n1:37:06.740 --> 1:37:12.740\n DeepMind side with AlphaZero, if you study chess, the kind of solutions that has come up in terms\n\n1:37:12.740 --> 1:37:20.740\n of chess, it is, there's novel ideas there. It feels very like there's brilliant moments of insight.\n\n1:37:20.740 --> 1:37:31.740\n And the mechanism they use, if you think of search as maybe more towards good old fashioned AI and\n\n1:37:31.740 --> 1:37:37.740\n then there's the connection is the neural network that has the intuition of looking at a board,\n\n1:37:37.740 --> 1:37:42.740\n looking at a set of patterns and saying, how good is this set of positions? And the next few\n\n1:37:42.740 --> 1:37:49.740\n positions, how good are those? And that's it. That's just an intuition. Grandmasters have this\n\n1:37:49.740 --> 1:37:55.740\n and understanding positionally, tactically, how good the situation is, how can it be improved\n\n1:37:55.740 --> 1:38:03.740\n without doing this full, like deep search. And then maybe doing a little bit of what human chess\n\n1:38:03.740 --> 1:38:08.740\n players call calculation, which is the search, taking a particular set of steps down the line to\n\n1:38:08.740 --> 1:38:16.740\n see how they unroll. But there is moments of genius in those systems too. So that's another hopeful\n\n1:38:16.740 --> 1:38:25.740\n illustration that from neural networks can emerge this novel creation of an idea.\n\n1:38:25.740 --> 1:38:34.740\n Yes. And I think that, you know, I think Demis Hassabis is, you know, he's spoken about those\n\n1:38:34.740 --> 1:38:44.740\n things. I heard him describe a move that was made in one of the go matches against Lisa Dahl in a\n\n1:38:44.740 --> 1:38:52.740\n very similar way. And it caused me to become really excited to kind of collaborate with some of those\n\n1:38:52.740 --> 1:39:05.740\n people and analyze it at DeepMind. So I think though that what I like to really emphasize here\n\n1:39:05.740 --> 1:39:15.740\n is one part of what I like to emphasize about mathematical cognition at least is that philosophers\n\n1:39:15.740 --> 1:39:28.740\n and logicians going back three or even a little more than 3000 years ago began to develop these\n\n1:39:28.740 --> 1:39:45.740\n formal systems and gradually the whole idea about thinking formally got constructed. And, you know,\n\n1:39:45.740 --> 1:39:55.740\n it's preceded Euclid, certainly present in the work of Thales and others. And I'm not the world's\n\n1:39:55.740 --> 1:40:03.740\n leading expert in all the details of that history, but Euclid's elements were the kind of the touch\n\n1:40:03.740 --> 1:40:15.740\n point of a coherent document that sort of laid out this idea of an actual formal system within which\n\n1:40:15.740 --> 1:40:31.580\n these objects were characterized and the system of inference that allowed new truths to be derived\n\n1:40:31.580 --> 1:40:43.900\n from others was sort of like established as a paradigm. And what I find interesting is the\n\n1:40:43.900 --> 1:40:55.020\n idea that the ability to become a person who is capable of thinking in this abstract formal way\n\n1:40:55.020 --> 1:41:10.060\n is a result of the same kind of immersion in experience thinking in that way that we now\n\n1:41:10.060 --> 1:41:16.440\n begin to think of our understanding of language as being, right? So, we immerse ourselves in a\n\n1:41:16.440 --> 1:41:22.780\n particular language, in a particular world of objects and their relationships and we learn\n\n1:41:22.780 --> 1:41:30.220\n to talk about that and we develop intuitive understanding of the real world. In a similar\n\n1:41:30.220 --> 1:41:39.740\n way, we can think that what academia has created for us, what those early philosophers and their\n\n1:41:39.740 --> 1:41:49.780\n academies in Athens and Alexandria and other places allowed was the development of these\n\n1:41:49.780 --> 1:42:00.660\n schools of thought, modes of thought that then become deeply ingrained and it becomes what it\n\n1:42:00.660 --> 1:42:11.420\n is that makes it so that somebody like Jerry Fodor would think that systematic thought is\n\n1:42:11.420 --> 1:42:20.860\n the essential characteristic of the human mind as opposed to a derived and an acquired characteristic\n\n1:42:20.860 --> 1:42:28.460\n that results from acculturation in a certain mode that's been invented by humans.\n\n1:42:28.460 --> 1:42:34.700\n Would you say it's more fundamental than like language? If we start dancing, if we bring\n\n1:42:34.700 --> 1:42:42.620\n Chomsky back into the conversation, first of all, is it unfair to draw a line between mathematical\n\n1:42:43.340 --> 1:42:48.540\n cognition and language, linguistic cognition?\n\n1:42:48.540 --> 1:42:54.780\n I think that's a very interesting question and I think it's one of the ones that I'm actually very\n\n1:42:54.780 --> 1:43:06.380\n interested in right now, but I think the answer is in important ways, it is important to draw that\n\n1:43:06.380 --> 1:43:12.540\n line, but then to come back and look at it again and see some of the subtleties and interesting\n\n1:43:12.540 --> 1:43:34.300\n aspects of the difference. So if we think about Chomsky himself, he was born into an academic\n\n1:43:34.300 --> 1:43:40.220\n family. His father was a professor of rabbinical studies at a small rabbinical college in\n\n1:43:40.220 --> 1:43:59.820\n Philadelphia. He was deeply enculturated in a culture of thought and reason and brought to the\n\n1:43:59.820 --> 1:44:13.260\n effort to understand natural language, this profound engagement with these formal systems. I\n\n1:44:13.260 --> 1:44:23.420\n think that there was tremendous power in that and that Chomsky had some amazing insights into the\n\n1:44:23.420 --> 1:44:34.300\n structure of natural language, but that, I'm going to use the word but there, the actual intuitive\n\n1:44:34.300 --> 1:44:41.260\n knowledge of these things only goes so far and does not go as far as it does in people like\n\n1:44:41.260 --> 1:44:48.620\n Chomsky himself. And this was something that was discovered in the PhD dissertation of Lyla\n\n1:44:48.620 --> 1:44:55.340\n Gleitman, who was actually trained in the same linguistics department with Chomsky. So what Lyla\n\n1:44:55.340 --> 1:45:09.980\n discovered was that the intuitions that linguists had about even the meaning of a phrase, not just\n\n1:45:09.980 --> 1:45:17.820\n about its grammar, but about what they thought a phrase must mean were very different from the\n\n1:45:17.820 --> 1:45:27.580\n intuitions of an ordinary person who wasn't a formally trained thinker. And well, it recently\n\n1:45:27.580 --> 1:45:32.380\n has become much more salient. I happened to have learned about this when I myself was a PhD student\n\n1:45:32.380 --> 1:45:38.380\n at the University of Pennsylvania, but I never knew how to put it together with all of my other\n\n1:45:38.380 --> 1:45:45.820\n thinking about these things. So I actually currently have the hypothesis that formally\n\n1:45:45.820 --> 1:45:57.260\n trained linguists and other formally trained academics, whether it be linguistics, philosophy,\n\n1:45:58.620 --> 1:46:02.940\n cognitive science, computer science, machine learning, mathematics,\n\n1:46:02.940 --> 1:46:17.900\n have a mode of engagement with experience that is intuitively deeply structured to be more\n\n1:46:17.900 --> 1:46:35.580\n organized around the systematicity and ability to be conformant with the principles of a system\n\n1:46:35.580 --> 1:46:42.300\n than is actually true of the natural human mind without that immersion.\n\n1:46:42.300 --> 1:46:48.620\n That's fascinating. So the different fields and approaches with which you start to study the mind\n\n1:46:48.620 --> 1:46:54.860\n actually take you away from the natural operation of the mind. So it makes it very difficult for you\n\n1:46:56.860 --> 1:46:59.020\n to be somebody who introspects.\n\n1:46:59.020 --> 1:47:16.620\n Yes. And this is where things about human belief and so called knowledge that we consider\n\n1:47:16.620 --> 1:47:29.500\n private, not our business to manipulate in others. We are not entitled to tell somebody else what to\n\n1:47:29.500 --> 1:47:42.540\n believe about certain kinds of things. What are those beliefs? Well, they are the product of this\n\n1:47:42.540 --> 1:47:49.580\n sort of immersion and enculturation. That is what I believe.\n\n1:47:51.660 --> 1:47:52.460\n And that's limiting.\n\n1:47:55.020 --> 1:47:56.860\n It's something to be aware of.\n\n1:47:58.140 --> 1:48:03.340\n Does that limit you from having a good model of cognition?\n\n1:48:04.380 --> 1:48:04.860\n It can.\n\n1:48:04.860 --> 1:48:13.660\n So when you look at mathematical or linguistics, I mean, what is that line then? So is Chomsky\n\n1:48:13.660 --> 1:48:17.580\n unable to sneak up to the full picture of cognition? Are you, when you're focusing on\n\n1:48:17.580 --> 1:48:22.300\n mathematical thinking, are you also unable to do so?\n\n1:48:22.940 --> 1:48:27.180\n I think you're right. I think that's a great way of characterizing it. And\n\n1:48:27.180 --> 1:48:43.580\n I also think that it's related to the concept of beginner's mind and another concept called the\n\n1:48:43.580 --> 1:48:53.180\n expert blind spot. So the expert blind spot is much more prosaic seeming than this point that\n\n1:48:53.180 --> 1:49:01.260\n you were just making. But it's something that plagues experts when they try to communicate\n\n1:49:01.260 --> 1:49:12.540\n their understanding to non experts. And that is that things are self evident to them that\n\n1:49:12.540 --> 1:49:23.180\n they can't begin to even think about how they could explain it to somebody else.\n\n1:49:23.180 --> 1:49:31.580\n Because it's just like so patently obvious that it must be true. And\n\n1:49:31.580 --> 1:49:46.140\n when Kronacker said, God made the natural numbers, all else is the work of man,\n\n1:49:47.180 --> 1:49:57.980\n he was expressing that intuition that somehow or other, the basic fundamentals of discrete\n\n1:49:57.980 --> 1:50:09.900\n quantities being countable and innumerable and indefinite in number was not something that\n\n1:50:10.780 --> 1:50:21.020\n had to be discovered. But he was wrong. It turns out that many cognitive scientists\n\n1:50:21.020 --> 1:50:27.580\n agreed with him for a time. There was a long period of time where the natural\n\n1:50:27.580 --> 1:50:35.820\n numbers were considered to be a part of the innate endowment of core knowledge or to use\n\n1:50:35.820 --> 1:50:41.500\n the kind of phrases that Spelke and Kerry used to talk about what they believe are\n\n1:50:41.500 --> 1:50:48.460\n the innate primitives of the human mind. And they no longer believe that. It's actually\n\n1:50:50.700 --> 1:50:56.620\n been more or less accepted by almost everyone that the natural numbers are actually a cultural\n\n1:50:56.620 --> 1:51:03.500\n construction. And it's so interesting to go back and study those few people who still exist who\n\n1:51:04.300 --> 1:51:13.100\n don't have those systems. So this is just an example to me where a certain mode of thinking\n\n1:51:13.100 --> 1:51:20.940\n about language itself or a certain mode of thinking about geometry and those kinds of\n\n1:51:20.940 --> 1:51:27.580\n relations. So it becomes so second nature that you don't know what it is that you need to teach. And\n\n1:51:30.300 --> 1:51:41.420\n in fact, we don't really teach it all that explicitly anyway. You take a math class,\n\n1:51:41.420 --> 1:51:47.420\n the professor sort of teaches it to you the way they understand it. Some of the students in the\n\n1:51:47.420 --> 1:51:52.780\n class sort of like they get it. They start to get the way of thinking and they can actually do the\n\n1:51:52.780 --> 1:51:57.500\n problems that get put on the homework that the professor thinks are interesting and challenging\n\n1:51:57.500 --> 1:52:08.220\n ones. But most of the students who don't kind of engage as deeply don't ever get. And we think,\n\n1:52:08.220 --> 1:52:14.300\n oh, that man must be brilliant. He must have this special insight. But he must have some\n\n1:52:14.300 --> 1:52:20.860\n some biological sort of bit that's different, that makes him so that he or she could have\n\n1:52:20.860 --> 1:52:29.420\n that insight. Although I don't want to dismiss biological individual differences completely,\n\n1:52:31.340 --> 1:52:39.660\n I find it much more interesting to think about the possibility that it was that difference in the\n\n1:52:39.660 --> 1:52:45.820\n dinner table conversation at the Chomsky house when he was growing up that made it so that he\n\n1:52:45.820 --> 1:52:52.540\n had that cast of mind. Yeah. And there's a few topics we talked about that kind of interconnect\n\n1:52:53.580 --> 1:52:59.900\n because I wonder the better I get at certain things, we humans, the deeper we understand\n\n1:52:59.900 --> 1:53:11.020\n something, what are you starting to then miss about the rest of the world? We talked about David\n\n1:53:11.020 --> 1:53:19.980\n and his degenerative mind. And, you know, when you look in the mirror and wonder how different\n\n1:53:19.980 --> 1:53:26.780\n am I am I cognitively from the man I was a month ago, from the man I was a year ago, like what,\n\n1:53:26.780 --> 1:53:35.980\n you know, if I can, having thought about language of Chomsky for 10, 20 years, what am I no longer\n\n1:53:35.980 --> 1:53:43.100\n able to see? What is in my blind spot? And how big is that? And then to somehow be able to leap back\n\n1:53:43.100 --> 1:53:48.860\n out of your deep, like structure that you form for yourself about thinking about the world,\n\n1:53:48.860 --> 1:53:54.780\n leap back and look at the big picture again, or jump out of the your current way of thinking.\n\n1:53:54.780 --> 1:54:00.860\n And to be able to introspect, like what are the limitations of your mind? How is your mind less\n\n1:54:00.860 --> 1:54:06.380\n powerful than it used to be or more powerful or different, powerful in different ways? So that\n\n1:54:06.380 --> 1:54:11.980\n seems to be a difficult thing to do because we're living, we're looking at the world through the\n\n1:54:11.980 --> 1:54:17.980\n lens of our mind, right? To step outside and introspect is difficult, but it seems necessary\n\n1:54:17.980 --> 1:54:25.020\n if you want to make progress. You know, one of the threads of psychological research that's always\n\n1:54:25.020 --> 1:54:38.620\n been very, I don't know, important to me to be aware of is the idea that our explanations of our\n\n1:54:38.620 --> 1:54:53.980\n own behavior aren't necessarily actually part of the causal process that caused that behavior to\n\n1:54:53.980 --> 1:55:03.980\n occur, or even valid observations of the set of constraints that led to the outcome, but they are\n\n1:55:03.980 --> 1:55:11.660\n post hoc rationalizations that we can give based on information at our disposal about what might\n\n1:55:11.660 --> 1:55:21.340\n have contributed to the result that we came to when asked. And so this is an idea that was\n\n1:55:21.340 --> 1:55:29.580\n introduced in a very important paper by Nisbet and Wilson about, you know, the limits on our ability\n\n1:55:29.580 --> 1:55:42.940\n to be aware of the factors that cause us to make the choices that we make. And, you know, I think\n\n1:55:42.940 --> 1:55:54.380\n it's something that we really ought to be much more cognizant of, in general, as human beings,\n\n1:55:54.380 --> 1:56:01.500\n is that our own insight into exactly why we hold the beliefs that we do and we hold the attitudes\n\n1:56:01.500 --> 1:56:12.060\n and make the choices and feel the feelings that we do is not something that we totally control\n\n1:56:12.060 --> 1:56:25.340\n or totally observe. And it's subject to, you know, our culturally transmitted understanding of what\n\n1:56:25.340 --> 1:56:34.780\n it is that is the mode that we give to explain these things when asked to do so as much as it is\n\n1:56:34.780 --> 1:56:42.060\n about anything else. And so even our ability to introspect and think we have access to our own\n\n1:56:42.060 --> 1:56:47.260\n thoughts is a product of culture and belief, you know, practice.\n\n1:56:47.260 --> 1:56:57.180\n So let me ask you the big question of advice. So you've lived an incredible life in terms of the\n\n1:56:57.180 --> 1:57:02.540\n ideas you've put out into the world, in terms of the trajectory you've taken through your career,\n\n1:57:02.540 --> 1:57:09.180\n through your life. What advice would you give to young people today, in high school, in college,\n\n1:57:09.980 --> 1:57:16.300\n about how to have a career or how to have a life they can be proud of?\n\n1:57:16.300 --> 1:57:27.660\n Finding the thing that you are intrinsically motivated to engage with and then celebrating\n\n1:57:27.660 --> 1:57:43.020\n that discovery is what it's all about. When I was in college, I struggled with that. I had thought\n\n1:57:43.020 --> 1:57:50.620\n I wanted to be a psychiatrist because I think I was interested in human psychology in high school.\n\n1:57:50.620 --> 1:57:58.300\n And at that time, the only sort of information I had that had anything to do with the psyche was,\n\n1:57:58.300 --> 1:58:03.180\n you know, Freud and Erich Fromm and sort of popular psychiatry kinds of things.\n\n1:58:03.820 --> 1:58:08.060\n And so, well, they were psychiatrists, right? So I had to be a psychiatrist.\n\n1:58:08.780 --> 1:58:14.700\n And that meant I had to go to medical school. And I got to college and I find myself taking,\n\n1:58:14.700 --> 1:58:21.820\n you know, the first semester of a three quarter physics class and it was mechanics. And this was\n\n1:58:21.820 --> 1:58:26.860\n so far from what it was I was interested in, but it was also too early in the morning in the winter\n\n1:58:26.860 --> 1:58:34.780\n court semester. So I never made it to the physics class. But I wondered about the rest of my\n\n1:58:34.780 --> 1:58:45.260\n freshman year and most of my sophomore year until I found myself in the midst of this situation where\n\n1:58:45.260 --> 1:58:53.500\n around me there was this big revolution happening. I was at Columbia University in 1968 and\n\n1:58:54.220 --> 1:58:59.580\n the Vietnam War is going on. Columbia is building a gym in Morningside Heights, which is part of\n\n1:58:59.580 --> 1:59:06.700\n Harlem. And people are thinking, oh, the big bad rich guys are stealing the parkland that\n\n1:59:06.700 --> 1:59:13.980\n belongs to the people of Harlem. And, you know, they're part of the military industrial complex,\n\n1:59:13.980 --> 1:59:20.380\n which is enslaving us and sending us all off to war in Vietnam. And so there was a big revolution\n\n1:59:20.380 --> 1:59:27.740\n that involved a confluence of black activism and, you know, SDS and social justice and the whole\n\n1:59:27.740 --> 1:59:33.500\n university blew up and got shut down. And I got a chance to sort of think about\n\n1:59:34.780 --> 1:59:42.380\n why people were behaving the way they were in this context. And I, you know, I happened to have\n\n1:59:42.380 --> 1:59:48.540\n taken mathematical statistics. I happened to have been taking psychology that quarter at just cycle\n\n1:59:48.540 --> 1:59:54.780\n one. And somehow things in that space all ran together in my mind and got me really excited\n\n1:59:54.780 --> 2:00:01.420\n about asking questions about why people, what made certain people go into the buildings and not\n\n2:00:01.420 --> 2:00:07.260\n others and things like that. And so suddenly I had a path forward and I had just been wandering\n\n2:00:07.260 --> 2:00:12.540\n around aimlessly. And at the different points in my career, you know, and I think, okay,\n\n2:00:12.540 --> 2:00:26.780\n well, should I take this class or should I just read that book about some idea that I want to\n\n2:00:26.780 --> 2:00:33.500\n understand better, you know, or should I pursue the thing that excites me and interests me or\n\n2:00:33.500 --> 2:00:39.340\n should I, you know, meet some requirement? You know, that's, I always did the latter.\n\n2:00:39.340 --> 2:00:46.940\n So I ended up, my professors in psychology were, thought I was great. They wanted me to go to\n\n2:00:46.940 --> 2:00:55.420\n graduate school. They nominated me for Phi Beta Kappa. And I went to the Phi Beta Kappa ceremony\n\n2:00:55.420 --> 2:01:00.940\n and this guy came up and he said, oh, are you Magna Arsuma? And I wasn't even getting honors\n\n2:01:00.940 --> 2:01:07.340\n based on my grades. They just happened to have thought I was interested enough in ideas to\n\n2:01:07.340 --> 2:01:12.780\n belong to Phi Beta Kappa. So. I mean, would it be fair to say you kind of stumbled around a little\n\n2:01:12.780 --> 2:01:20.940\n bit through accidents of too early morning of classes in physics and so on until you discovered\n\n2:01:20.940 --> 2:01:26.380\n intrinsic motivation, as you mentioned, and then that's it. It hooked you. And then you celebrate\n\n2:01:26.380 --> 2:01:34.860\n the fact that this happens to human beings. Yeah. And what is it that made what I did intrinsically\n\n2:01:34.860 --> 2:01:41.260\n motivating to me? Well, that's interesting and I don't know all the answers to it. And I don't\n\n2:01:41.260 --> 2:01:52.940\n think I want anybody to think that you should be sort of in any way, I don't know, sanctimonious or\n\n2:01:52.940 --> 2:02:01.100\n anything about it. You know, it's like, I really enjoyed doing statistical analysis of data. I\n\n2:02:01.100 --> 2:02:09.260\n really enjoyed running my own experiment, which was what I got a chance to do in the psychology\n\n2:02:09.260 --> 2:02:14.860\n department that chemistry and physics had never, I never imagined that mere mortals would ever do\n\n2:02:14.860 --> 2:02:20.220\n an experiment in those sciences, except one that was in the textbook that you were told to do in\n\n2:02:20.220 --> 2:02:26.460\n lab class. But in psychology, we were already like, even when I was taking psych one, it turned out\n\n2:02:26.460 --> 2:02:32.140\n we had our own rat and we got to, after two set experiments, we got to, okay, do something you\n\n2:02:32.140 --> 2:02:42.060\n think of with your rat. So it's the opportunity to do it myself and to bring together a certain\n\n2:02:42.060 --> 2:02:49.340\n set of things that engaged me intrinsically. And I think it has something to do with why\n\n2:02:49.340 --> 2:02:59.660\n certain people turn out to be profoundly amazing musical geniuses, right? They get immersed in it\n\n2:02:59.660 --> 2:03:07.020\n at an early enough point and it just sort of gets into the fabric. So my little brother had intrinsic\n\n2:03:07.020 --> 2:03:15.740\n motivation for music as we witnessed when he discovered how to put records on the phonograph\n\n2:03:15.740 --> 2:03:21.660\n when he was like 13 months old and recognize which one he wanted to play, not because he could read\n\n2:03:21.660 --> 2:03:26.780\n the labels, because he could sort of see which ones had which scratches, which were the different,\n\n2:03:26.780 --> 2:03:31.420\n you know, oh, that's rapidi espanol. And that's, you know, and, and, and,\n\n2:03:31.420 --> 2:03:33.660\n And he enjoyed that, that connected with him somehow.\n\n2:03:33.660 --> 2:03:40.380\n Yeah. And, and there was something that it fed into and it, you're extremely lucky if you have\n\n2:03:40.380 --> 2:03:47.420\n that and if you can nurture it and can let it grow and let it be, be an important part of your life.\n\n2:03:47.420 --> 2:03:51.900\n Yeah. Those are, those are the two things is like, be attentive enough to,\n\n2:03:52.780 --> 2:03:59.020\n to feel it when it comes, like this is something special. I mean, I don't know. For example,\n\n2:03:59.020 --> 2:04:08.540\n I really like tabular data, like Excel sheets. Like it brings me a deep joy. I don't know how\n\n2:04:08.540 --> 2:04:12.220\n useful that is for anything. That's part of what I'm talking about.\n\n2:04:12.220 --> 2:04:16.540\n Exactly. So there's like a million, not a million, but there's a lot of things\n\n2:04:17.180 --> 2:04:23.180\n like that. For me, you have to hear that for yourself, like be, like realize this is really\n\n2:04:23.180 --> 2:04:27.980\n joyful. But then the other part that you're mentioning, which is the nurture is take time\n\n2:04:27.980 --> 2:04:33.260\n and stay with it, stay with it a while and see where that takes you in life.\n\n2:04:33.260 --> 2:04:40.060\n Yeah. And I think, I think the, the, the motivational engagement results in the\n\n2:04:40.060 --> 2:04:47.500\n immersion that then creates the opportunity to obtain the expertise. So, you know, we could call\n\n2:04:47.500 --> 2:04:53.340\n it the Mozart effect, right? I mean, when I think about Mozart, I think about, you know,\n\n2:04:53.340 --> 2:05:01.260\n the person who was born as the fourth member of the family string quartet, right? And, and they\n\n2:05:01.260 --> 2:05:07.420\n handed him the violin when he was six weeks old. All right, start playing, you know, it's like,\n\n2:05:08.220 --> 2:05:19.020\n and so the, the level of immersion there was, was amazingly profound, but hopefully he also had,\n\n2:05:20.220 --> 2:05:28.300\n you know, some, something, maybe this is where the more sort of the genetic part comes in.\n\n2:05:28.300 --> 2:05:34.860\n Sometimes I think, you know, something in him resonated to the music so that that,\n\n2:05:34.860 --> 2:05:40.140\n the synergy of the combination of that was so powerful. So, so that's what I really considered\n\n2:05:40.140 --> 2:05:47.020\n to be the Mozart effect. It's sort of the, the synergy of something with, with experience that,\n\n2:05:47.020 --> 2:05:51.740\n that then results in the unique flowering of a particular, you know, mind.\n\n2:05:51.740 --> 2:06:01.020\n And so I know my siblings and I are all very different from each other. We've all gone in\n\n2:06:01.020 --> 2:06:05.820\n our own different directions. And, you know, I mentioned my younger brother who was very musical.\n\n2:06:07.180 --> 2:06:11.420\n I had my other younger brother was like this amazing, like intuitive engineer.\n\n2:06:11.420 --> 2:06:23.900\n And my sister, one of my sisters was passionate about, in, you know, water conservation well\n\n2:06:23.900 --> 2:06:31.900\n before it was, you know, such a hugely important issue that it is today. So we all sort of somehow\n\n2:06:31.900 --> 2:06:41.740\n these find a different thing. And I don't, I don't mean to say it isn't tied in with something about,\n\n2:06:41.740 --> 2:06:47.340\n about us biologically, but, but it's also when that happens, where you can find that, then,\n\n2:06:47.340 --> 2:06:52.140\n you know, you can do your thing and you can be excited about it. So people can be excited about\n\n2:06:52.140 --> 2:06:56.780\n fitting people on bicycles, as well as excited about making neural networks, achieve insights\n\n2:06:56.780 --> 2:07:02.220\n into human cognition, right? Yeah. Like for me personally, I've always been excited about\n\n2:07:03.260 --> 2:07:10.060\n love and friendship between humans. And just like the actual experience of it,\n\n2:07:10.060 --> 2:07:15.500\n since I was a child, just observing people around me and also been excited about robots.\n\n2:07:16.140 --> 2:07:21.580\n And there's something in me that thinks I really would love to explore how those two things\n\n2:07:21.580 --> 2:07:26.940\n combine. And it doesn't make any sense. A lot of it is also timing, just to think of your own career\n\n2:07:26.940 --> 2:07:33.100\n and your own life. You found yourself in certain pieces, places that happened to involve some of\n\n2:07:33.100 --> 2:07:37.820\n the greatest thinkers of our time. And so it just worked out that like, you guys developed those\n\n2:07:37.820 --> 2:07:43.020\n ideas. And there may be a lot of other people similar to you, and they were brilliant, and\n\n2:07:43.020 --> 2:07:48.460\n they never found that right connection and place to where they, their ideas could flourish. So\n\n2:07:48.460 --> 2:07:55.500\n it's timing, it's place, it's people. And ultimately the whole ride, you know, it's undirected.\n\n2:07:56.460 --> 2:08:00.060\n Can I ask you about something you mentioned in terms of psychiatry when you were younger?\n\n2:08:00.620 --> 2:08:08.540\n Because I had a similar experience of, you know, reading Freud and Carl Jung and just,\n\n2:08:09.580 --> 2:08:15.420\n you know, those kind of popular psychiatry ideas. And that was a dream for me early on in high\n\n2:08:15.420 --> 2:08:23.020\n school too. Like I hoped to understand the human mind by, somehow psychiatry felt like\n\n2:08:24.060 --> 2:08:30.140\n the right discipline for that. Does that make you sad? That psychiatry is not\n\n2:08:31.340 --> 2:08:37.500\n the mechanism by which you are able to explore the human mind. So for me, I was a little bit\n\n2:08:37.500 --> 2:08:46.300\n disillusioned because of how much prescription medication and biochemistry is involved in the\n\n2:08:46.300 --> 2:08:53.740\n discipline of psychiatry, as opposed to the dream of the Freud like, use the mechanisms of language\n\n2:08:53.740 --> 2:09:00.540\n to explore the human mind. So that was a little disappointing. And that's why I kind of went to\n\n2:09:00.540 --> 2:09:04.940\n computer science and thinking like, maybe you can explore the human mind by trying to build the\n\n2:09:04.940 --> 2:09:14.780\n thing. Yes. I wasn't exposed to the sort of the biomedical slash pharmacological aspects of\n\n2:09:14.780 --> 2:09:22.780\n psychiatry at that point because I dropped out of that whole idea of premed that I never even\n\n2:09:22.780 --> 2:09:30.620\n found out about that until much later. But you're absolutely right. So I was actually a member of the\n\n2:09:30.620 --> 2:09:41.260\n National Advisory Mental Health Council. That is to say the board of scientists who advise the\n\n2:09:41.260 --> 2:09:47.900\n director of the National Institute of Mental Health. And that was around the year 2000. And\n\n2:09:47.900 --> 2:09:56.220\n in fact, at that time, the man who came in as the new director, I had been on this board for a year\n\n2:09:56.220 --> 2:10:08.380\n when he came in, said, okay, schizophrenia is a biological illness. It's a lot like cancer.\n\n2:10:08.380 --> 2:10:13.100\n We've made huge strides in curing cancer. And that's what we're going to do with schizophrenia.\n\n2:10:13.100 --> 2:10:18.620\n We're going to find the medications that are going to cure this disease. And we're not going\n\n2:10:18.620 --> 2:10:27.580\n to listen to anybody's grandmother anymore. And good old behavioral psychology is not something\n\n2:10:27.580 --> 2:10:40.940\n we're going to support any further. And he completely alienated me from the Institute\n\n2:10:40.940 --> 2:10:46.700\n and from all of its prior policies, which had been much more holistic, I think, really at some level.\n\n2:10:46.700 --> 2:10:57.100\n And the other people on the board were like psychiatrists, very biological psychiatrists.\n\n2:10:57.100 --> 2:11:06.060\n It didn't pan out that nothing has changed in our ability to help people with mental illness.\n\n2:11:07.020 --> 2:11:14.220\n And so 20 years later, that particular path was a dead end, as far as I can tell.\n\n2:11:14.220 --> 2:11:20.700\n Well, there's some aspect to, and sorry to romanticize the whole philosophical conversation\n\n2:11:20.700 --> 2:11:29.100\n about the human mind. But to me, psychiatrists, for a time, held the flag of we're the deep thinkers.\n\n2:11:29.980 --> 2:11:34.300\n In the same way that physicists are the deep thinkers about the nature of reality,\n\n2:11:34.300 --> 2:11:38.860\n psychiatrists are the deep thinkers about the nature of the human mind. And I think that flag\n\n2:11:38.860 --> 2:11:44.940\n has been taken from them and carried by people like you. It's like, it's more in the cognitive\n\n2:11:44.940 --> 2:11:50.380\n psychology, especially when you have a foot in the computational view of the world, because you can\n\n2:11:50.380 --> 2:11:55.500\n both build it, you can like, intuit about the functioning of the mind by building little models\n\n2:11:56.220 --> 2:12:00.700\n and be able to see mathematical things and then deploying those models, especially in computers,\n\n2:12:00.700 --> 2:12:07.180\n to say, does this actually work? They do like experiments. And then some combination of\n\n2:12:07.180 --> 2:12:13.500\n neuroscience, where you're starting to actually be able to observe, do certain experiments on\n\n2:12:13.500 --> 2:12:21.260\n human beings and observe how the brain is actually functioning. And there, using intuition, you can\n\n2:12:21.260 --> 2:12:26.940\n start being the philosopher. Like Richard Feynman is the philosopher, cognitive psychologists can\n\n2:12:26.940 --> 2:12:32.140\n become the philosopher, and psychiatrists become much more like doctors. They're like very medical.\n\n2:12:32.140 --> 2:12:39.340\n They help people with medication, biochemistry, and so on. But they are no longer the book writers\n\n2:12:39.340 --> 2:12:45.100\n and the philosophers, which of course I admire. I admire the Richard Feynman ability to do\n\n2:12:45.740 --> 2:12:51.260\n great low level mathematics and physics and the high level philosophy.\n\n2:12:52.060 --> 2:13:00.700\n Yeah, I think it was Fromm and Jung more than Freud that was sort of initially kind of like\n\n2:13:00.700 --> 2:13:06.620\n made me feel like, oh, this is really amazing and interesting and I want to explore it further.\n\n2:13:06.620 --> 2:13:15.180\n I actually, when I got to college and I lost that thread, I found more of it in sociology\n\n2:13:15.180 --> 2:13:23.660\n and literature than I did in any place else. So I took quite a lot of both of those\n\n2:13:23.660 --> 2:13:32.060\n disciplines as an undergraduate. And I was actually deeply ambivalent about\n\n2:13:32.860 --> 2:13:39.500\n the psychology because I was doing experiments after the initial flurry of interest in\n\n2:13:40.140 --> 2:13:44.860\n why people would occupy buildings during an insurrection and consider\n\n2:13:44.860 --> 2:13:55.100\n being so overcommitted to their beliefs. But I ended up in the psychology laboratory running\n\n2:13:55.100 --> 2:14:03.580\n experiments on pigeons. And so I had these profound dissonance between the kinds of issues\n\n2:14:03.580 --> 2:14:12.060\n that would be explored when I was thinking about what I read about in modern British literature\n\n2:14:12.060 --> 2:14:18.700\n versus what I could study with my pigeons in the laboratory. That got resolved when I went\n\n2:14:18.700 --> 2:14:25.340\n to graduate school and I discovered cognitive psychology. And so for me, that was the path\n\n2:14:25.340 --> 2:14:31.900\n out of this sort of like extremely sort of ambivalent divergence between the interest\n\n2:14:31.900 --> 2:14:42.700\n in the human condition and the desire to do actual mechanistically oriented thinking about it. And I\n\n2:14:42.700 --> 2:14:50.620\n think we've come a long way in that regard and that you're absolutely right that nowadays this\n\n2:14:50.620 --> 2:14:57.900\n is something that's accessible to people through the pathway in through computer science or the\n\n2:14:57.900 --> 2:15:07.500\n pathway in through neuroscience. You can get derailed in neuroscience down to the bottom of\n\n2:15:08.620 --> 2:15:16.300\n the system where you might find the cures of various conditions, but you don't get a chance\n\n2:15:16.300 --> 2:15:21.100\n to think about the higher level stuff. So it's in the systems and cognitive neuroscience and\n\n2:15:21.100 --> 2:15:27.660\n computational intelligence, miasma up there at the top that I think these opportunities are most\n\n2:15:28.460 --> 2:15:36.060\n are richest right now. And so yes, I am indeed blessed by having had the opportunity to fall\n\n2:15:36.060 --> 2:15:44.060\n into that space. So you mentioned the human condition, speaking which you happen to be a\n\n2:15:44.060 --> 2:15:52.140\n human being who's unfortunately not immortal. That seems to be a fundamental part of the human\n\n2:15:52.140 --> 2:16:00.220\n condition that this ride ends. Do you think about the fact that you're going to die one day? Are you\n\n2:16:00.220 --> 2:16:14.540\n afraid of death? I would say that I am not as much afraid of death as I am of degeneration. And\n\n2:16:15.260 --> 2:16:24.300\n I say that in part for reasons of having, you know, seen some tragic degenerative situations\n\n2:16:24.300 --> 2:16:42.140\n unfold. It's exciting when you can continue to participate and feel like you're near the place\n\n2:16:42.140 --> 2:16:56.380\n where the wave is breaking on the shore, if you like. And I think about my own future potential.\n\n2:16:58.460 --> 2:17:07.260\n If I were to begin to suffer from Alzheimer's disease or semantic dementia or some other\n\n2:17:07.260 --> 2:17:17.500\n condition, you know, I would sort of gradually lose the thread of that ability. And so one can\n\n2:17:17.500 --> 2:17:26.620\n live on for a decade after, you know, sort of having to retire because one no longer has\n\n2:17:28.540 --> 2:17:34.860\n these kinds of abilities to engage. And I think that's the thing that I fear the most.\n\n2:17:34.860 --> 2:17:42.220\n SL. The losing of that, like the breaking of the wave, the flourishing of the mind,\n\n2:17:42.220 --> 2:17:46.220\n where you have these ideas and they're swimming around and you're able to play with them.\n\n2:17:46.220 --> 2:17:51.660\n RL. Yeah. And collaborate with other people who, you know, are themselves\n\n2:17:54.140 --> 2:17:58.540\n really helping to push these ideas forward. So, yeah.\n\n2:17:58.540 --> 2:18:05.260\n SL. What about the edge of the cliff? The end? I mean, the mystery of it. I mean...\n\n2:18:05.260 --> 2:18:12.780\n RL. The migrated sort of conception of mind and, you know, sort of continuous sort of way of\n\n2:18:12.780 --> 2:18:22.460\n thinking about most things makes it so that, to me, the discreteness of that transition is less\n\n2:18:25.020 --> 2:18:27.100\n apparent than it seems to be to most people.\n\n2:18:27.100 --> 2:18:35.180\n SL. I see. I see. Yeah. Yeah. I wonder, so I don't know if you know the work of Ernest Becker\n\n2:18:35.180 --> 2:18:41.180\n and so on. I wonder what role mortality and our ability to be cognizant of it\n\n2:18:42.060 --> 2:18:49.500\n and anticipate it and perhaps be afraid of it, what role that plays in our reasoning of the world.\n\n2:18:49.500 --> 2:18:55.020\n RL. I think that it can be motivating to people to think they have a limited period left.\n\n2:18:55.020 --> 2:19:01.580\n SL. I think in my own case, you know, it's like seven or eight years ago now that I was\n\n2:19:03.580 --> 2:19:09.420\n sitting around doing experiments on decision making that were\n\n2:19:11.660 --> 2:19:19.740\n satisfying in a certain way because I could really get closure on whether the model fit the data\n\n2:19:19.740 --> 2:19:26.940\n perfectly or not. And I could see how one could test, you know, the predictions in monkeys as well\n\n2:19:26.940 --> 2:19:33.580\n as humans and really see what the neurons were doing. But I just realized, hey, wait a minute,\n\n2:19:33.580 --> 2:19:40.220\n you know, I may only have about 10 or 15 years left here. And I don't feel like I'm getting\n\n2:19:40.220 --> 2:19:46.060\n towards the answers to the really interesting questions while I'm doing this particular level\n\n2:19:46.060 --> 2:19:56.220\n of work. And that's when I said to myself, okay, let's pick something that's hard. So that's when\n\n2:19:56.220 --> 2:20:03.420\n I started working on mathematical cognition. And I think it was more in terms of, well,\n\n2:20:03.420 --> 2:20:08.380\n I got 15 more years possibly of useful life left. Let's imagine that it's only 10.\n\n2:20:09.980 --> 2:20:13.260\n I'm actually getting close to the end of that now, maybe three or four more years.\n\n2:20:13.260 --> 2:20:17.900\n But I'm beginning to feel like, well, I probably have another five after that. So, okay, I'll give\n\n2:20:17.900 --> 2:20:23.500\n myself another six or eight. But a deadline is looming and therefore. It's not going to go on\n\n2:20:23.500 --> 2:20:31.500\n forever. And so, yeah, I got to keep thinking about the questions that I think are the interesting and\n\n2:20:31.500 --> 2:20:37.980\n important ones for sure. What do you hope your legacy is? You've done some incredible work in\n\n2:20:37.980 --> 2:20:46.140\n your life as a man, as a scientist, when the aliens and the human civilization is long gone\n\n2:20:46.140 --> 2:20:51.580\n and the aliens are reading the encyclopedia about the human species. What do you hope is the\n\n2:20:51.580 --> 2:20:56.780\n paragraph written about you? I would want it to sort of highlight\n\n2:20:56.780 --> 2:21:20.540\n a couple things that I was able to see one path that was more exciting to me than the one that\n\n2:21:20.540 --> 2:21:28.860\n seemed already to be there for a cognitive psychologist, but not for any super special\n\n2:21:28.860 --> 2:21:33.740\n reason other than that I'd had the right context prior to that, but that I had gone ahead and\n\n2:21:34.540 --> 2:21:44.220\n followed that lead. And then I forget the exact wording, but I said in this preface that\n\n2:21:44.220 --> 2:22:00.700\n the joy of science is the moment in which a partially formed thought in the mind of one person\n\n2:22:01.500 --> 2:22:08.540\n gets crystallized a little better in the discourse and becomes the foundation\n\n2:22:08.540 --> 2:22:16.220\n of some exciting concrete piece of actual scientific progress. And I feel like that\n\n2:22:16.220 --> 2:22:21.740\n moment happened when Rumelhart and I were doing the interactive activation model and when\n\n2:22:21.740 --> 2:22:29.500\n Rumelhart heard Hinton talk about gradient descent and having the objective function to guide the\n\n2:22:29.500 --> 2:22:37.980\n learning process. And it happened a lot in that period and I sort of seek that kind of\n\n2:22:37.980 --> 2:22:49.660\n thing in my collaborations with my students. So the idea that this is a person who contributed\n\n2:22:49.660 --> 2:22:54.540\n to science by finding exciting collaborative opportunities to engage with other people\n\n2:22:55.100 --> 2:22:59.740\n through is something that I certainly hope is part of the paragraph.\n\n2:22:59.740 --> 2:23:08.620\n And like you said, taking a step maybe in directions that are non obvious. So it's the\n\n2:23:08.620 --> 2:23:15.820\n old Robert Frost road less taken. So maybe because you said like this incomplete initial idea,\n\n2:23:16.860 --> 2:23:21.260\n that step you take is a little bit off the beaten path.\n\n2:23:22.140 --> 2:23:28.940\n If I could just say one more thing here. This was something that really contributed\n\n2:23:28.940 --> 2:23:40.060\n to energizing me in a way that I feel it would be useful to share. My PhD dissertation project\n\n2:23:40.060 --> 2:23:48.460\n was completely empirical experimental project. And I wrote a paper based on the two main\n\n2:23:48.460 --> 2:23:55.020\n experiments that were the core of my dissertation and I submitted it to a journal. And at the end\n\n2:23:55.020 --> 2:24:05.900\n of the paper, I had a little section where I laid out the beginnings of my theory about what I\n\n2:24:05.900 --> 2:24:13.580\n thought was going on that would explain the data that I had collected. And I had submitted the\n\n2:24:13.580 --> 2:24:20.540\n paper to the Journal of Experimental Psychology. So I got back a letter from the editor saying,\n\n2:24:20.540 --> 2:24:23.980\n thank you very much. These are great experiments and we'd love to publish them in the journal.\n\n2:24:23.980 --> 2:24:30.940\n But what we'd like you to do is to leave the theorizing to the theorists and take that part\n\n2:24:30.940 --> 2:24:42.300\n out of the paper. And so I did, I took that part out of the paper. But I almost found myself labeled\n\n2:24:42.300 --> 2:24:50.540\n as a non theorist by this. And I could have succumbed to that and said, okay, well, I guess\n\n2:24:50.540 --> 2:25:01.500\n my job is to just go on and do experiments, right? But that's not what I wanted to do. And so when I\n\n2:25:01.500 --> 2:25:07.340\n got to my assistant professorship, although I continued to do experiments because I knew I had\n\n2:25:07.340 --> 2:25:13.740\n to get some papers out, I also at the end of my first year submitted my first article to\n\n2:25:13.740 --> 2:25:18.780\n Psychological Review, which was the theoretical journal where I took that section and elaborated\n\n2:25:18.780 --> 2:25:24.940\n it and wrote it up and submitted it to them. And they didn't accept that either, but they said,\n\n2:25:24.940 --> 2:25:29.900\n oh, this is interesting. You should keep thinking about it this time. And then that was what got me\n\n2:25:29.900 --> 2:25:37.500\n going to think, okay, you know, so it's not a superhuman thing to contribute to the development\n\n2:25:37.500 --> 2:25:43.580\n of theory. You know, you don't have to be, you can do it as a mere mortal.\n\n2:25:43.580 --> 2:25:50.540\n LB And the broader, I think, lesson is don't succumb to the labels of a particular reviewer.\n\n2:25:50.540 --> 2:25:55.500\n RL Yeah, that's for sure. Or anybody labeling you, right?\n\n2:25:55.500 --> 2:26:00.620\n LB Yeah, exactly. I mean that, yeah, exactly. And especially as you become successful,\n\n2:26:01.580 --> 2:26:05.820\n your labels get assigned to you for that you're successful for that thing.\n\n2:26:05.820 --> 2:26:09.740\n RL Connectionist or cognitive scientist and not a neuroscientist.\n\n2:26:09.740 --> 2:26:15.260\n LB And then you can, you can completely, that's just, that's the stories of the past. You're\n\n2:26:15.260 --> 2:26:20.940\n today a new person that can completely revolutionize in totally new areas. So don't\n\n2:26:20.940 --> 2:26:29.260\n let those labels hold you back. Well, let me ask the big question. When you look at into the,\n\n2:26:29.980 --> 2:26:33.580\n you said it started with Columbia trying to observe these humans and they're doing\n\n2:26:34.140 --> 2:26:38.940\n weird stuff and you want to know why are they doing this stuff. So Zuma even bigger.\n\n2:26:38.940 --> 2:26:46.620\n LB At the hundred plus billion people who've ever lived on earth. Why do you think we're all\n\n2:26:47.740 --> 2:26:51.500\n doing what we're doing? What do you think is the meaning of it all? The big why question.\n\n2:26:51.500 --> 2:26:57.820\n We seem to be very busy doing a bunch of stuff and we seem to be kind of directed towards somewhere.\n\n2:26:59.420 --> 2:27:00.060\n But why?\n\n2:27:00.060 --> 2:27:13.420\n RL Well, I myself think that we make meaning for ourselves and that we find inspiration\n\n2:27:13.420 --> 2:27:21.100\n in the meaning that other people have made in the past. You know, and the great religious thinkers\n\n2:27:21.100 --> 2:27:34.540\n of the first millennium BC and, you know, few that came in the early part of the second millennium,\n\n2:27:36.620 --> 2:27:40.460\n you know, laid down some important foundations for us.\n\n2:27:40.460 --> 2:27:54.220\n But I do believe that, you know, we are an emergent result of a process that happened\n\n2:27:54.220 --> 2:28:05.340\n naturally without guidance and that meaning is what we make of it and that the creation of\n\n2:28:05.340 --> 2:28:15.260\n efforts to reify meaning in like religious traditions and so on is just a part of the\n\n2:28:15.260 --> 2:28:26.700\n expression of that goal that we have to, you know, not find out what the meaning is, but to\n\n2:28:26.700 --> 2:28:40.460\n make it ourselves. And so, to me, it's something that's very personal. It's very individual. It's\n\n2:28:40.460 --> 2:28:50.380\n like meaning will come for you through the particular combination of synergistic elements\n\n2:28:50.380 --> 2:29:00.380\n that are your fabric and your experience and your context and, you know, you should...\n\n2:29:04.620 --> 2:29:12.700\n It's all made in a certain kind of a local context though, right? Here I am at UCSD with this brilliant\n\n2:29:12.700 --> 2:29:24.780\n man, Rommelhart, who's having, you know, these doubts about symbolic artificial intelligence\n\n2:29:24.780 --> 2:29:35.020\n that resonate with my desire to see it grounded in the biology and let's make the most of that,\n\n2:29:35.020 --> 2:29:41.580\n you know? Yeah. And so, from that like little pocket, there's some kind of peculiar little\n\n2:29:41.580 --> 2:29:48.700\n emergent process that then, which is basically each one of us, each one of us humans is a kind of,\n\n2:29:49.580 --> 2:29:56.380\n you know, you think cells and they come together and it's an emergent process that then tells fancy\n\n2:29:56.380 --> 2:30:03.340\n stories about itself and then gets, just like you said, just enjoys the beauty of the stories\n\n2:30:03.340 --> 2:30:10.300\n we tell about ourselves. It's an emergent process that lives for a time, is defined by its local\n\n2:30:10.300 --> 2:30:16.620\n pocket and context in time and space and then tells pretty stories and we write those stories\n\n2:30:16.620 --> 2:30:21.660\n down and then we celebrate how nice the stories are and then it continues because we build stories\n\n2:30:21.660 --> 2:30:30.540\n on top of each other and eventually we'll colonize hopefully other planets, other solar systems,\n\n2:30:30.540 --> 2:30:37.740\n other galaxies and we'll tell even better stories. But it all starts here on Earth. Jay, you're\n\n2:30:37.740 --> 2:30:47.740\n speaking of peculiar emergent processes that lived one heck of a story. You're one of the\n\n2:30:47.740 --> 2:30:58.460\n the great scientists of cognitive science, of psychology, of computation. It's a huge honor\n\n2:30:58.460 --> 2:31:03.340\n you would talk to me today that you spend your very valuable time. I really enjoyed talking with\n\n2:31:03.340 --> 2:31:06.460\n you and thank you for all the work you've done. I can't wait to see what you do next.\n\n2:31:06.460 --> 2:31:13.580\n JL Well, thank you so much and this has been an amazing opportunity for me to let ideas that I've\n\n2:31:13.580 --> 2:31:20.620\n never fully expressed before come out because you asked such a wide range of the deeper questions\n\n2:31:20.620 --> 2:31:24.700\n that we've all been thinking about for so long. So thank you very much for that.\n\n2:31:24.700 --> 2:31:29.420\n RL Thank you. Thanks for listening to this conversation with Jay McClelland.\n\n2:31:29.420 --> 2:31:32.940\n To support this podcast, please check out our sponsors in the description.\n\n2:31:32.940 --> 2:31:37.980\n And now, let me leave you with some words from Jeffrey Hinton. In the long run,\n\n2:31:37.980 --> 2:31:43.260\n curiosity driven research works best. Real breakthroughs come from people focusing\n\n2:31:43.260 --> 2:32:03.340\n on what they're excited about. Thanks for listening and hope to see you next time.\n\n"
}
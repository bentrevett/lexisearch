{
  "title": "John Hopfield: Physics View of the Mind and Neurobiology | Lex Fridman Podcast #76",
  "id": "DKyzcbNr8WE",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:03.440\n The following is a conversation with John Hopfield,\n\n00:03.440 --> 00:07.600\n professor at Princeton, whose life's work weaved beautifully\n\n00:07.600 --> 00:11.720\n through biology, chemistry, neuroscience, and physics.\n\n00:11.720 --> 00:15.000\n Most crucially, he saw the messy world of biology\n\n00:15.000 --> 00:18.360\n through the piercing eyes of a physicist.\n\n00:18.360 --> 00:20.160\n He's perhaps best known for his work\n\n00:20.160 --> 00:22.160\n on associative neural networks,\n\n00:22.160 --> 00:24.960\n now known as Hopfield networks,\n\n00:24.960 --> 00:27.720\n that were one of the early ideas that catalyzed\n\n00:27.720 --> 00:30.320\n the development of the modern field of deep learning.\n\n00:31.360 --> 00:35.120\n As his 2019 Franklin Medal in Physics Award states,\n\n00:35.120 --> 00:37.800\n he applied concepts of theoretical physics\n\n00:37.800 --> 00:41.040\n to provide new insights on important biological questions\n\n00:41.040 --> 00:45.040\n in a variety of areas, including genetics and neuroscience\n\n00:45.040 --> 00:48.000\n with significant impact on machine learning.\n\n00:48.000 --> 00:51.480\n And as John says in his 2018 article titled,\n\n00:51.480 --> 00:55.600\n Now What?, his accomplishments have often come about\n\n00:55.600 --> 00:59.720\n by asking that very question, now what?\n\n00:59.720 --> 01:02.920\n And often responding by a major change of direction.\n\n01:04.120 --> 01:07.000\n This is the Artificial Intelligence Podcast.\n\n01:07.000 --> 01:09.240\n If you enjoy it, subscribe on YouTube,\n\n01:09.240 --> 01:11.080\n give it five stars on Apple Podcast,\n\n01:11.080 --> 01:14.500\n support it on Patreon, or simply connect with me on Twitter,\n\n01:14.500 --> 01:18.980\n and Lex Friedman, spelled F R I D M A M.\n\n01:18.980 --> 01:21.520\n As usual, I'll do one or two minutes of ads now\n\n01:21.520 --> 01:22.980\n and never any ads in the middle\n\n01:22.980 --> 01:25.280\n that can break the flow of the conversation.\n\n01:25.280 --> 01:26.720\n I hope that works for you\n\n01:26.720 --> 01:29.440\n and doesn't hurt the listening experience.\n\n01:29.440 --> 01:31.920\n This show is presented by Cash App,\n\n01:31.920 --> 01:34.320\n the number one finance app in the App Store.\n\n01:34.320 --> 01:37.780\n When you get it, use code LexPodcast.\n\n01:37.780 --> 01:41.000\n Cash App lets you send money to friends, buy Bitcoin,\n\n01:41.000 --> 01:43.800\n and invest in the stock market with as little as $1.\n\n01:44.800 --> 01:47.000\n Since Cash App does fractional share trading,\n\n01:47.000 --> 01:49.440\n let me mention that the order execution algorithm\n\n01:49.440 --> 01:50.980\n that works behind the scenes\n\n01:50.980 --> 01:53.800\n to create the abstraction of fractional orders\n\n01:53.800 --> 01:56.360\n is to me an algorithmic marvel.\n\n01:56.360 --> 01:58.560\n So big props to the Cash App engineers\n\n01:58.560 --> 02:00.240\n for solving a hard problem\n\n02:00.240 --> 02:02.720\n that in the end provides an easy interface\n\n02:02.720 --> 02:05.320\n that takes a step up the next layer of abstraction\n\n02:05.320 --> 02:06.720\n over the stock market,\n\n02:06.720 --> 02:09.320\n making trading more accessible for new investors\n\n02:09.320 --> 02:12.040\n and diversification much easier.\n\n02:12.980 --> 02:15.400\n So again, if you get Cash App from the App Store,\n\n02:15.400 --> 02:18.440\n Google Play, and use code LexPodcast,\n\n02:18.440 --> 02:19.720\n you'll get $10,\n\n02:19.720 --> 02:22.520\n and Cash App will also donate $10 to First,\n\n02:22.520 --> 02:24.200\n one of my favorite organizations\n\n02:24.200 --> 02:27.280\n that is helping advance robotics and STEM education\n\n02:27.280 --> 02:28.980\n for young people around the world.\n\n02:29.880 --> 02:34.120\n And now here's my conversation with John Hopfield.\n\n02:35.080 --> 02:37.840\n What difference between biological neural networks\n\n02:37.840 --> 02:39.980\n and artificial neural networks\n\n02:39.980 --> 02:42.280\n is most captivating and profound to you?\n\n02:44.660 --> 02:47.080\n At the higher philosophical level,\n\n02:47.080 --> 02:49.180\n let's not get technical just yet.\n\n02:49.180 --> 02:53.300\n But one of the things that very much intrigues me\n\n02:53.300 --> 02:58.300\n is the fact that neurons have all kinds of components,\n\n03:00.060 --> 03:01.220\n properties to them.\n\n03:03.660 --> 03:05.420\n And in evolutionary biology,\n\n03:05.420 --> 03:07.300\n if you have some little quirk\n\n03:07.300 --> 03:11.980\n in how a molecule works or how a cell works,\n\n03:11.980 --> 03:13.500\n and it can be made use of,\n\n03:13.500 --> 03:15.100\n evolution will sharpen it up\n\n03:15.100 --> 03:20.100\n and make it into a useful feature rather than a glitch.\n\n03:20.180 --> 03:24.860\n And so you expect in neurobiology for evolution\n\n03:24.860 --> 03:27.900\n to have captured all kinds of possibilities\n\n03:27.900 --> 03:29.060\n of getting neurons,\n\n03:29.060 --> 03:31.800\n of how you get neurons to do things for you.\n\n03:33.060 --> 03:36.980\n And that aspect has been completely suppressed\n\n03:36.980 --> 03:38.700\n in artificial neural networks.\n\n03:38.700 --> 03:43.700\n So the glitches become features\n\n03:43.880 --> 03:46.760\n in the biological neural network.\n\n03:46.760 --> 03:48.120\n They can.\n\n03:48.120 --> 03:50.280\n Look, let me take one of the things\n\n03:50.280 --> 03:52.280\n that I used to do research on.\n\n03:54.280 --> 03:58.760\n If you take things which oscillate,\n\n03:58.760 --> 04:02.720\n they have rhythms which are sort of close to each other.\n\n04:02.720 --> 04:04.000\n Under some circumstances,\n\n04:04.000 --> 04:06.920\n these things will have a phase transition\n\n04:06.920 --> 04:08.300\n and suddenly the rhythm will,\n\n04:08.300 --> 04:10.720\n everybody will fall into step.\n\n04:10.720 --> 04:13.160\n There was a marvelous physical example of that\n\n04:14.120 --> 04:17.160\n in the Millennium Bridge across the Thames River,\n\n04:17.160 --> 04:21.020\n about, built about 2001.\n\n04:21.020 --> 04:23.560\n And pedestrians walking across,\n\n04:23.560 --> 04:26.040\n pedestrians don't walk synchronized,\n\n04:26.040 --> 04:28.340\n they don't walk in lockstep.\n\n04:28.340 --> 04:31.520\n But they're all walking about the same frequency\n\n04:31.520 --> 04:33.800\n and the bridge could sway at that frequency\n\n04:33.800 --> 04:36.920\n and the slight sway made pedestrians tend a little bit\n\n04:36.920 --> 04:39.160\n to lock into step and after a while,\n\n04:39.160 --> 04:41.680\n the bridge was oscillating back and forth\n\n04:41.680 --> 04:43.960\n and the pedestrians were walking in step to it.\n\n04:43.960 --> 04:46.960\n And you could see it in the movies made out of the bridge.\n\n04:46.960 --> 04:50.600\n And the engineers made a simple minor mistake.\n\n04:50.600 --> 04:53.680\n They assume when you walk, it's step, step, step\n\n04:53.680 --> 04:56.240\n and it's back and forth motion.\n\n04:56.240 --> 04:58.760\n But when you walk, it's also right foot left\n\n04:58.760 --> 05:00.320\n with side to side motion.\n\n05:00.320 --> 05:01.760\n And it's the side to side motion\n\n05:01.760 --> 05:04.480\n for which the bridge was strong enough,\n\n05:04.480 --> 05:08.220\n but it wasn't stiff enough.\n\n05:09.160 --> 05:11.040\n And as a result, you would feel the motion\n\n05:11.040 --> 05:12.920\n and you'd fall into step with it.\n\n05:12.920 --> 05:15.100\n And people were very uncomfortable with it.\n\n05:15.100 --> 05:16.520\n They closed the bridge for two years\n\n05:16.520 --> 05:18.860\n while they built stiffening for it.\n\n05:20.480 --> 05:23.880\n Now, nerve cells produce action potentials.\n\n05:23.880 --> 05:26.180\n You have a bunch of cells which are loosely coupled together\n\n05:26.180 --> 05:29.400\n producing action potentials at the same rate.\n\n05:29.400 --> 05:31.780\n There'll be some circumstances\n\n05:31.780 --> 05:34.600\n under which these things can lock together.\n\n05:34.600 --> 05:37.880\n Other circumstances in which they won't.\n\n05:39.000 --> 05:40.720\n Well, if they're fired together,\n\n05:40.720 --> 05:43.400\n you can be sure that other cells are gonna notice it.\n\n05:43.400 --> 05:45.960\n So you can make a computational feature out of this\n\n05:45.960 --> 05:48.840\n in an evolving brain.\n\n05:50.340 --> 05:51.800\n Most artificial neural networks\n\n05:51.800 --> 05:53.560\n don't even have action potentials,\n\n05:53.560 --> 05:56.960\n let alone have the possibility for synchronizing them.\n\n05:56.960 --> 06:01.680\n And you mentioned the evolutionary process.\n\n06:01.680 --> 06:04.360\n So the evolutionary process\n\n06:04.360 --> 06:08.040\n that builds on top of biological systems\n\n06:08.040 --> 06:13.040\n leverages the weird mess of it somehow.\n\n06:15.360 --> 06:18.320\n So how do you make sense of that ability\n\n06:18.320 --> 06:22.020\n to leverage all the different kinds of complexities\n\n06:22.020 --> 06:24.620\n in the biological brain?\n\n06:24.620 --> 06:28.760\n Well, look, in the biological molecule level,\n\n06:29.960 --> 06:31.640\n you have a piece of DNA\n\n06:31.640 --> 06:35.400\n which encodes for a particular protein.\n\n06:35.400 --> 06:37.880\n You could duplicate that piece of DNA\n\n06:37.880 --> 06:41.760\n and now one part of it can code for that protein,\n\n06:41.760 --> 06:45.080\n but the other one could itself change a little bit\n\n06:45.080 --> 06:46.800\n and thus start coding for a molecule\n\n06:46.800 --> 06:48.560\n which is slightly different.\n\n06:48.560 --> 06:51.320\n Now, if that molecule was just slightly different,\n\n06:51.320 --> 06:56.280\n had a function which helped any old chemical reaction\n\n06:56.280 --> 06:58.120\n which was important to the cell,\n\n07:00.680 --> 07:03.480\n you would go ahead and let that try,\n\n07:03.480 --> 07:06.580\n and evolution would slowly improve that function.\n\n07:07.520 --> 07:10.520\n And so you have the possibility of duplicating\n\n07:12.800 --> 07:14.760\n and then having things drift apart.\n\n07:14.760 --> 07:16.760\n One of them retain the old function,\n\n07:16.760 --> 07:18.760\n the other one do something new for you.\n\n07:18.760 --> 07:23.760\n And there's evolutionary pressure to improve.\n\n07:23.960 --> 07:25.440\n Look, there isn't in computers too,\n\n07:25.440 --> 07:28.680\n but improvement has to do with closing some companies\n\n07:28.680 --> 07:30.360\n and opening some others.\n\n07:30.360 --> 07:34.120\n The evolutionary process looks a little different.\n\n07:34.120 --> 07:37.520\n Yeah, similar timescale perhaps.\n\n07:37.520 --> 07:39.640\n Much shorter in timescale.\n\n07:39.640 --> 07:42.640\n Companies close, yeah, go bankrupt and are born,\n\n07:42.640 --> 07:45.900\n yeah, shorter, but not much shorter.\n\n07:45.900 --> 07:50.140\n Some companies last a century, but yeah, you're right.\n\n07:51.160 --> 07:53.160\n I mean, if you think of companies as a single organism\n\n07:53.160 --> 07:55.520\n that builds and you all know, yeah,\n\n07:55.520 --> 08:00.520\n it's a fascinating dual correspondence there\n\n08:00.840 --> 08:02.320\n between biological organisms.\n\n08:02.320 --> 08:05.980\n And companies have difficulty having a new product\n\n08:05.980 --> 08:07.680\n competing with an old product.\n\n08:10.640 --> 08:14.960\n When IBM built its first PC, you probably read the book,\n\n08:14.960 --> 08:18.880\n they made a little isolated internal unit to make the PC.\n\n08:18.880 --> 08:22.680\n And for the first time in IBM's history,\n\n08:22.680 --> 08:25.900\n they didn't insist that you build it out of IBM components.\n\n08:27.680 --> 08:31.060\n But they understood that they could get into this market,\n\n08:31.060 --> 08:33.200\n which is a very different thing\n\n08:33.200 --> 08:35.720\n by completely changing their culture.\n\n08:35.720 --> 08:44.720\n And biology finds other markets in a more adaptive way.\n\n08:44.720 --> 08:47.280\n Yeah, it's better at it.\n\n08:47.280 --> 08:49.280\n It's better at that kind of integration.\n\n08:50.360 --> 08:52.720\n So maybe you've already said it,\n\n08:52.720 --> 08:55.880\n but what to use the most beautiful aspect\n\n08:55.880 --> 08:58.220\n or mechanism of the human mind?\n\n09:01.920 --> 09:05.320\n Is it the adaptive, the ability to adapt\n\n09:05.320 --> 09:07.680\n as you've described, or is there some other little quirk\n\n09:07.680 --> 09:09.320\n that you particularly like?\n\n09:11.520 --> 09:15.720\n Adaptation is everything when you get down to it.\n\n09:16.760 --> 09:21.760\n But the difference, there are differences between adaptation\n\n09:21.760 --> 09:25.280\n where your learning goes on only over generations\n\n09:25.280 --> 09:28.360\n and over evolutionary time,\n\n09:28.360 --> 09:30.720\n where your learning goes on at the time scale\n\n09:30.720 --> 09:34.360\n of one individual who must learn from the environment\n\n09:34.360 --> 09:36.900\n during that individual's lifetime.\n\n09:39.080 --> 09:42.340\n And biology has both kinds of learning in it.\n\n09:43.400 --> 09:47.640\n And the thing which makes neurobiology hard\n\n09:47.640 --> 09:52.640\n is that a mathematical system, as it were,\n\n09:53.120 --> 09:56.500\n built on this other kind of evolutionary system.\n\n09:58.280 --> 10:01.120\n What do you mean by mathematical system?\n\n10:01.120 --> 10:03.600\n Where's the math and the biology?\n\n10:03.600 --> 10:05.280\n Well, when you talk to a computer scientist\n\n10:05.280 --> 10:08.120\n about neural networks, it's all math.\n\n10:08.120 --> 10:12.120\n The fact that biology actually came about from evolution,\n\n10:13.560 --> 10:18.560\n and the fact that biology is about a system\n\n10:19.040 --> 10:22.740\n which you can build in three dimensions.\n\n10:25.360 --> 10:26.880\n If you look at computer chips,\n\n10:27.960 --> 10:31.520\n computer chips are basically two dimensional structures,\n\n10:31.520 --> 10:36.200\n maybe 2.1 dimensions, but they really have difficulty\n\n10:36.200 --> 10:39.200\n doing three dimensional wiring.\n\n10:39.200 --> 10:44.200\n Biology is, the neocortex is actually also sheet like,\n\n10:45.760 --> 10:47.680\n and it sits on top of the white matter,\n\n10:47.680 --> 10:50.400\n which is about 10 times the volume of the gray matter\n\n10:50.400 --> 10:53.520\n and contains all what you might call the wires.\n\n10:53.520 --> 10:58.520\n But there's a huge, the effect of computer structure\n\n11:01.840 --> 11:06.100\n on what is easy and what is hard is immense.\n\n11:09.120 --> 11:13.280\n And biology does, it makes some things easy\n\n11:13.280 --> 11:16.060\n that are very difficult to understand\n\n11:16.060 --> 11:17.920\n how to do computationally.\n\n11:17.920 --> 11:21.040\n On the other hand, you can't do simple floating point\n\n11:21.040 --> 11:23.880\n arithmetic because it's awfully stupid.\n\n11:23.880 --> 11:25.660\n And you're saying this kind of three dimensional\n\n11:25.660 --> 11:30.660\n complicated structure makes, it's still math.\n\n11:30.680 --> 11:32.360\n It's still doing math.\n\n11:32.360 --> 11:36.200\n The kind of math it's doing enables you to solve problems\n\n11:36.200 --> 11:38.280\n of a very different kind.\n\n11:38.280 --> 11:39.760\n That's right, that's right.\n\n11:40.680 --> 11:43.720\n So you mentioned two kinds of adaptation,\n\n11:43.720 --> 11:46.840\n the evolutionary adaptation and the adaptation\n\n11:46.840 --> 11:50.000\n or learning at the scale of a single human life.\n\n11:50.000 --> 11:55.000\n Which do you, which is particularly beautiful to you\n\n11:56.920 --> 11:59.320\n and interesting from a research\n\n11:59.320 --> 12:01.180\n and from just a human perspective?\n\n12:02.160 --> 12:03.600\n And which is more powerful?\n\n12:05.840 --> 12:08.720\n I find things most interesting that I begin to see\n\n12:10.160 --> 12:12.640\n how to get into the edges of them\n\n12:12.640 --> 12:15.400\n and tease them apart a little bit and see how they work.\n\n12:15.400 --> 12:20.400\n And since I can't see the evolutionary process going on,\n\n12:21.760 --> 12:24.560\n I'm in awe of it.\n\n12:26.680 --> 12:30.120\n But I find it just a black hole as far as trying\n\n12:30.120 --> 12:32.000\n to understand what to do.\n\n12:32.000 --> 12:35.220\n And so in a certain sense, I'm in awe of it,\n\n12:35.220 --> 12:37.520\n but I couldn't be interested in working on it.\n\n12:39.520 --> 12:43.880\n The human life's time scale is however thing\n\n12:43.880 --> 12:47.760\n you can tease apart and study.\n\n12:47.760 --> 12:51.160\n Yeah, you can do, there's developmental neurobiology\n\n12:51.160 --> 12:54.280\n which understands how the connections\n\n12:56.240 --> 13:00.920\n and how the structure evolves from a combination\n\n13:00.920 --> 13:04.400\n of what the genetics is like and the real,\n\n13:04.400 --> 13:08.240\n the fact that you're building a system in three dimensions.\n\n13:08.240 --> 13:13.240\n In just days and months, those early days\n\n13:14.400 --> 13:17.200\n of a human life are really interesting.\n\n13:17.200 --> 13:21.080\n They are and of course, there are times\n\n13:21.080 --> 13:24.260\n of immense cell multiplication.\n\n13:24.260 --> 13:28.120\n There are also times of the greatest cell death\n\n13:28.120 --> 13:30.860\n in the brain is during infancy.\n\n13:32.120 --> 13:33.120\n It's turnover.\n\n13:33.120 --> 13:38.120\n So what is not effective, what is not wired well enough\n\n13:39.760 --> 13:41.960\n to use at the moment, throw it out.\n\n13:42.840 --> 13:45.040\n It's a mysterious process.\n\n13:45.040 --> 13:49.440\n From, let me ask, from what field do you think\n\n13:49.440 --> 13:51.480\n the biggest breakthrough is in understanding\n\n13:51.480 --> 13:56.400\n the mind will come in the next decades?\n\n13:56.400 --> 13:59.680\n Is it neuroscience, computer science, neurobiology,\n\n13:59.680 --> 14:04.680\n psychology, physics, maybe math, maybe literature?\n\n14:09.240 --> 14:11.040\n Well, of course, I see the world always\n\n14:11.040 --> 14:12.520\n through a lens of physics.\n\n14:12.520 --> 14:17.520\n I grew up in physics and the way I pick problems\n\n14:19.040 --> 14:21.800\n is very characteristic of physics\n\n14:21.800 --> 14:25.360\n and of an intellectual background which is not psychology,\n\n14:25.360 --> 14:28.320\n which is not chemistry and so on and so on.\n\n14:28.320 --> 14:30.200\n Yeah, both of your parents are physicists.\n\n14:30.200 --> 14:31.920\n Both of my parents were physicists\n\n14:31.920 --> 14:36.120\n and the real thing I got out of that was a feeling\n\n14:36.120 --> 14:40.280\n that the world is an understandable place\n\n14:41.840 --> 14:45.480\n and if you do enough experiments and think about\n\n14:45.480 --> 14:48.200\n what they mean and structure things\n\n14:48.200 --> 14:50.720\n so you can do the mathematics of the,\n\n14:50.720 --> 14:53.080\n relevant to the experiments, you ought to be able\n\n14:53.080 --> 14:55.040\n to understand how things work.\n\n14:55.040 --> 14:58.920\n But that was, that was a few years ago.\n\n14:58.920 --> 15:03.600\n Did you change your mind at all through many decades\n\n15:03.600 --> 15:06.000\n of trying to understand the mind,\n\n15:06.000 --> 15:07.560\n of studying in different kinds of ways?\n\n15:07.560 --> 15:09.880\n Not even the mind, just biological systems.\n\n15:11.080 --> 15:14.040\n You still have hope that physics, that you can understand?\n\n15:17.120 --> 15:20.840\n There's a question of what do you mean by understand?\n\n15:20.840 --> 15:21.680\n Of course.\n\n15:21.680 --> 15:24.480\n When I taught freshman physics, I used to say,\n\n15:24.480 --> 15:26.600\n I wanted to get physics to understand the subject,\n\n15:26.600 --> 15:28.920\n to understand Newton's laws.\n\n15:28.920 --> 15:33.840\n I didn't want them simply to memorize a set of examples\n\n15:33.840 --> 15:36.680\n to which they knew the equations to write down\n\n15:36.680 --> 15:38.200\n to generate the answers.\n\n15:38.200 --> 15:42.280\n I had this nebulous idea of understanding\n\n15:42.280 --> 15:44.440\n so that if you looked at a situation,\n\n15:44.440 --> 15:48.400\n you could say, oh, I expect the ball to make that trajectory\n\n15:48.400 --> 15:52.600\n or I expect some intuitive notion of understanding\n\n15:52.600 --> 15:57.600\n and I don't know how to express that very well\n\n15:58.280 --> 16:01.200\n and I've never known how to express it well.\n\n16:01.200 --> 16:04.920\n And you run smack up against it when you do these,\n\n16:04.920 --> 16:07.840\n look at these simple neural nets,\n\n16:07.840 --> 16:12.840\n feed forward neural nets, which do amazing things\n\n16:13.360 --> 16:16.520\n and yet, you know, contain nothing of the essence\n\n16:16.520 --> 16:20.200\n of what I would have felt was understanding.\n\n16:20.200 --> 16:23.040\n Understanding is more than just an enormous lookup table.\n\n16:24.640 --> 16:26.440\n Let's linger on that.\n\n16:26.440 --> 16:28.160\n How sure you are of that?\n\n16:28.160 --> 16:30.320\n What if the table gets really big?\n\n16:31.720 --> 16:34.560\n So, I mean, asked another way,\n\n16:34.560 --> 16:37.160\n these feed forward neural networks,\n\n16:37.160 --> 16:38.960\n do you think they'll ever understand?\n\n16:40.280 --> 16:41.880\n Could answer that in two ways.\n\n16:41.880 --> 16:45.280\n I think if you look at real systems,\n\n16:45.280 --> 16:50.280\n feedback is an essential aspect\n\n16:50.280 --> 16:53.000\n of how these real systems compute.\n\n16:53.000 --> 16:55.520\n On the other hand, if I have a mathematical system\n\n16:55.520 --> 16:58.720\n with feedback, I know I can unlayer this and do it,\n\n16:58.720 --> 17:03.720\n but I have an exponential expansion\n\n17:03.920 --> 17:06.120\n in the amount of stuff I have to build\n\n17:06.120 --> 17:08.800\n if I can resolve the problem that way.\n\n17:08.800 --> 17:10.000\n So feedback is essential.\n\n17:10.000 --> 17:13.120\n So we can talk even about recurrent neural nets,\n\n17:13.120 --> 17:17.600\n so recurrence, but do you think all the pieces are there\n\n17:17.600 --> 17:22.320\n to achieve understanding through these simple mechanisms?\n\n17:22.320 --> 17:25.280\n Like back to our original question,\n\n17:25.280 --> 17:28.480\n what is the fundamental, is there a fundamental difference\n\n17:28.480 --> 17:31.960\n between artificial neural networks and biological\n\n17:31.960 --> 17:34.720\n or is it just a bunch of surface stuff?\n\n17:34.720 --> 17:39.720\n Suppose you ask a neurosurgeon, when is somebody dead?\n\n17:41.120 --> 17:42.480\n Yeah.\n\n17:42.480 --> 17:44.200\n So we'll probably go back to saying,\n\n17:44.200 --> 17:46.760\n well, I can look at the brain rhythms\n\n17:47.960 --> 17:49.280\n and tell you this is a brain\n\n17:49.280 --> 17:51.360\n which has never could have functioned again.\n\n17:51.360 --> 17:53.720\n This is one of the, this other one is one of the stuff\n\n17:53.720 --> 17:58.240\n we treat it well is still recoverable.\n\n17:58.240 --> 18:00.680\n And then just do that by some electrodes\n\n18:00.680 --> 18:04.680\n looking at simple electrical patterns,\n\n18:05.840 --> 18:08.120\n which don't look in any detail at all\n\n18:08.120 --> 18:13.120\n what individual neurons are doing.\n\n18:13.400 --> 18:17.640\n These rhythms are utterly absent\n\n18:17.640 --> 18:19.720\n from anything which goes on at Google.\n\n18:23.520 --> 18:25.080\n Yeah, but the rhythms.\n\n18:26.320 --> 18:27.880\n But the rhythms what?\n\n18:27.880 --> 18:31.280\n So, well, that's like comparing, okay, I'll tell you,\n\n18:31.280 --> 18:36.280\n it's like you're comparing the greatest classical musician\n\n18:36.280 --> 18:39.600\n in the world to a child first learning to play.\n\n18:39.600 --> 18:41.240\n The question I'm at, but they're still both\n\n18:41.240 --> 18:42.680\n playing the piano.\n\n18:42.680 --> 18:47.280\n I'm asking, is there, will it ever go on at Google?\n\n18:48.320 --> 18:49.560\n Do you have a hope?\n\n18:49.560 --> 18:52.200\n Because you're one of the seminal figures\n\n18:52.200 --> 18:55.200\n in both launching both disciplines,\n\n18:55.200 --> 18:57.240\n both sides of the river.\n\n18:59.320 --> 19:04.320\n I think it's going to go on generation after generation.\n\n19:04.320 --> 19:09.200\n The way it has where what you might call\n\n19:09.200 --> 19:11.840\n the AI computer science community says,\n\n19:12.840 --> 19:14.040\n let's take the following.\n\n19:14.040 --> 19:16.920\n This is our model of neurobiology at the moment.\n\n19:16.920 --> 19:20.480\n Let's pretend it's good enough\n\n19:20.480 --> 19:22.400\n and do everything we can with it.\n\n19:24.000 --> 19:25.880\n And it does interesting things.\n\n19:25.880 --> 19:30.320\n And after a while it sort of grinds into the sand\n\n19:30.320 --> 19:35.080\n and you say, ah, something else is needed for neurobiology.\n\n19:35.080 --> 19:37.160\n And some other grand thing comes in\n\n19:38.320 --> 19:41.040\n and enables you to go a lot further.\n\n19:42.520 --> 19:44.240\n What will go into the sand again?\n\n19:44.240 --> 19:47.320\n And I think it could be generations of this evolution.\n\n19:47.320 --> 19:48.800\n I don't know how many of them.\n\n19:48.800 --> 19:50.840\n And each one is going to get you further\n\n19:50.840 --> 19:53.480\n into what a brain does.\n\n19:53.480 --> 19:58.480\n And in some sense, past the Turing test longer\n\n19:58.480 --> 20:02.040\n and in more broad aspects.\n\n20:05.360 --> 20:08.040\n And how many of these are going to have to be\n\n20:08.040 --> 20:11.600\n before you say, I've made something,\n\n20:11.600 --> 20:15.360\n I've made a human, I don't know.\n\n20:15.360 --> 20:17.720\n But your sense is it might be a couple.\n\n20:17.720 --> 20:19.640\n My sense is it might be a couple more.\n\n20:19.640 --> 20:20.800\n Yeah.\n\n20:20.800 --> 20:25.800\n And going back to my brainwaves as it were.\n\n20:25.800 --> 20:30.800\n Yes, from the AI point of view,\n\n20:32.840 --> 20:35.920\n they would say, ah, maybe these are an epiphenomenon\n\n20:35.920 --> 20:37.520\n and not important at all.\n\n20:40.320 --> 20:45.000\n The first car I had, a real wreck of a 1936 Dodge,\n\n20:46.640 --> 20:49.920\n go above about 45 miles an hour and the wheels would shimmy.\n\n20:50.840 --> 20:52.480\n Yeah.\n\n20:52.480 --> 20:56.720\n Good speedometer that.\n\n20:56.720 --> 20:59.720\n Now, nobody designed the car that way.\n\n20:59.720 --> 21:02.000\n The car is malfunctioning to have that.\n\n21:02.000 --> 21:05.800\n But in biology, if it were useful to know\n\n21:05.800 --> 21:08.400\n when are you going more than 45 miles an hour,\n\n21:08.400 --> 21:10.040\n you just capture that.\n\n21:10.040 --> 21:12.440\n And you wouldn't worry about where it came from.\n\n21:15.560 --> 21:16.400\n Yeah.\n\n21:16.400 --> 21:18.920\n It's going to be a long time before that kind of thing,\n\n21:18.920 --> 21:23.920\n which can take place in large complex networks of things\n\n21:25.240 --> 21:27.640\n is actually used in the computation.\n\n21:27.640 --> 21:32.080\n Look, how many transistors are there\n\n21:32.080 --> 21:33.680\n in your laptop these days?\n\n21:34.800 --> 21:36.360\n Actually, I don't know the number.\n\n21:36.360 --> 21:38.960\n It's on the scale of 10 to the 10.\n\n21:38.960 --> 21:40.640\n I can't remember the number either.\n\n21:40.640 --> 21:41.480\n Yeah.\n\n21:43.160 --> 21:45.680\n And all the transistors are somewhat similar.\n\n21:45.680 --> 21:49.840\n And most physical systems with that many parts,\n\n21:49.840 --> 21:54.120\n all of which are similar, have collective properties.\n\n21:54.120 --> 21:55.240\n Yes.\n\n21:55.240 --> 21:57.600\n Sound waves in air, earthquakes,\n\n21:57.600 --> 21:59.640\n what have you, have collective properties.\n\n21:59.640 --> 22:00.480\n Weather.\n\n22:02.520 --> 22:05.280\n There are no collective properties used\n\n22:05.280 --> 22:08.040\n in artificial neural networks, in AI.\n\n22:10.840 --> 22:12.000\n Yeah, it's very.\n\n22:12.000 --> 22:14.320\n If biology uses them,\n\n22:14.320 --> 22:17.040\n it's going to take us to more generations of things\n\n22:17.040 --> 22:18.960\n for people to actually dig in\n\n22:18.960 --> 22:21.320\n and see how they are used and what they mean.\n\n22:22.960 --> 22:25.240\n See, you're very right.\n\n22:25.240 --> 22:28.800\n We might have to return several times to neurobiology\n\n22:28.800 --> 22:32.840\n and try to make our transistors more messy.\n\n22:32.840 --> 22:33.920\n Yeah, yeah.\n\n22:35.040 --> 22:40.040\n At the same time, the simple ones will conquer big aspects.\n\n22:40.040 --> 22:45.040\n And I think one of the most, biggest surprises to me was\n\n22:47.800 --> 22:49.280\n how well learning systems\n\n22:49.280 --> 22:51.800\n because they're manifestly nonbiological,\n\n22:52.840 --> 22:54.880\n how important they can be actually,\n\n22:54.880 --> 22:58.840\n and how important and how useful they can be in AI.\n\n22:59.840 --> 23:04.840\n So if we can just take a stroll to some of your work.\n\n23:04.840 --> 23:09.840\n If we can just take a stroll to some of your work\n\n23:10.280 --> 23:12.480\n that is incredibly surprising,\n\n23:12.480 --> 23:14.080\n that it works as well as it does,\n\n23:14.080 --> 23:18.320\n that launched a lot of the recent work with neural networks.\n\n23:18.320 --> 23:23.320\n If we go to what are now called Hopfield networks,\n\n23:26.040 --> 23:29.720\n can you tell me what is associative memory in the mind\n\n23:29.720 --> 23:31.060\n for the human side?\n\n23:31.920 --> 23:33.560\n Let's explore memory for a bit.\n\n23:33.560 --> 23:36.320\n Okay, what do you mean by associative memory is,\n\n23:37.520 --> 23:42.040\n ah, you have a memory of each of your friends.\n\n23:42.040 --> 23:43.800\n Your friend has all kinds of properties\n\n23:43.800 --> 23:46.000\n from what they look like, what their voice sounds like,\n\n23:46.000 --> 23:48.880\n to where they went to college, where you met them,\n\n23:50.480 --> 23:54.120\n go on and on, what science papers they've written.\n\n23:55.960 --> 24:00.960\n And if I start talking about a 5 foot 10 wire,\n\n24:00.960 --> 24:03.960\n cognitive scientist who's got a very bad back,\n\n24:03.960 --> 24:06.160\n it doesn't take very long for you to say,\n\n24:06.160 --> 24:07.960\n oh, he's talking about Jeff Hinton.\n\n24:07.960 --> 24:12.400\n I never mentioned the name or anything very particular.\n\n24:14.720 --> 24:18.160\n But somehow a few facts that are associated\n\n24:18.160 --> 24:21.960\n with a particular person enables you to get a hold\n\n24:21.960 --> 24:23.800\n of the rest of the facts.\n\n24:23.800 --> 24:26.960\n Or not the rest of them, another subset of them.\n\n24:26.960 --> 24:31.960\n And it's this ability to link things together,\n\n24:33.280 --> 24:37.280\n link experiences together, which goes under\n\n24:37.280 --> 24:40.440\n the general name of associative memory.\n\n24:40.440 --> 24:43.920\n And a large part of intelligent behavior\n\n24:43.920 --> 24:47.440\n is actually just large associative memories at work,\n\n24:47.440 --> 24:48.760\n as far as I can see.\n\n24:49.640 --> 24:53.400\n What do you think is the mechanism of how it works?\n\n24:53.400 --> 24:57.320\n What do you think is the mechanism of how it works\n\n24:57.320 --> 24:58.600\n in the mind?\n\n24:58.600 --> 25:01.360\n Is it a mystery to you still?\n\n25:03.000 --> 25:07.280\n Do you have inklings of how this essential thing\n\n25:07.280 --> 25:08.720\n for cognition works?\n\n25:10.080 --> 25:14.960\n What I made 35 years ago was, of course,\n\n25:14.960 --> 25:19.960\n a crude physics model to actually enable you\n\n25:19.960 --> 25:24.320\n to understand my old sense of understanding\n\n25:24.320 --> 25:26.640\n as a physicist, because you could say,\n\n25:26.640 --> 25:29.560\n ah, I understand why this goes to stable states.\n\n25:29.560 --> 25:32.640\n It's like things going downhill.\n\n25:32.640 --> 25:37.640\n And that gives you something with which to think\n\n25:39.080 --> 25:42.720\n in physical terms rather than only in mathematical terms.\n\n25:42.720 --> 25:47.120\n So you've created these associative artificial networks.\n\n25:47.120 --> 25:48.320\n That's right.\n\n25:48.320 --> 25:50.640\n Now, if you look at what I did,\n\n25:53.720 --> 25:58.720\n I didn't at all describe a system which gracefully learns.\n\n25:59.200 --> 26:02.520\n I described a system in which you could understand\n\n26:02.520 --> 26:06.040\n how learning could link things together,\n\n26:06.040 --> 26:08.120\n how very crudely it might learn.\n\n26:09.760 --> 26:11.280\n One of the things which intrigues me\n\n26:11.280 --> 26:15.240\n as I reinvestigate that system now to some extent is,\n\n26:15.240 --> 26:20.240\n look, I see you, I'll see you every second\n\n26:20.880 --> 26:23.640\n for the next hour or what have you.\n\n26:23.640 --> 26:26.480\n Each look at you is a little bit different.\n\n26:26.480 --> 26:30.640\n I don't store all those second by second images.\n\n26:30.640 --> 26:32.360\n I don't store 3,000 images.\n\n26:32.360 --> 26:34.800\n I somehow compact this information.\n\n26:34.800 --> 26:37.840\n So I now have a view of you,\n\n26:37.840 --> 26:42.840\n which I can use.\n\n26:44.560 --> 26:47.240\n It doesn't slavishly remember anything in particular,\n\n26:47.240 --> 26:50.880\n but it compacts the information into useful chunks,\n\n26:50.880 --> 26:54.840\n which are somehow these chunks,\n\n26:54.840 --> 26:57.800\n which are not just activities of neurons,\n\n26:57.800 --> 26:59.760\n bigger things than that,\n\n26:59.760 --> 27:03.760\n which are the real entities which are useful to you.\n\n27:03.760 --> 27:06.680\n Which are useful to you.\n\n27:06.680 --> 27:10.320\n Useful to you to describe,\n\n27:10.320 --> 27:13.520\n to compress this information coming at you.\n\n27:13.520 --> 27:15.040\n And you have to compress it in such a way\n\n27:15.040 --> 27:19.360\n that if the information comes in just like this again,\n\n27:19.360 --> 27:24.360\n I don't bother to rewrite it or efforts to rewrite it\n\n27:24.760 --> 27:26.720\n simply do not yield anything\n\n27:26.720 --> 27:29.720\n because those things are already written.\n\n27:29.720 --> 27:32.120\n And that needs to be not,\n\n27:32.120 --> 27:36.200\n look this up, have I stored it somewhere already?\n\n27:36.200 --> 27:39.800\n There'll be something which is much more automatic\n\n27:39.800 --> 27:41.840\n in the machine hardware.\n\n27:41.840 --> 27:44.760\n Right, so in the human mind,\n\n27:44.760 --> 27:47.960\n how complicated is that process do you think?\n\n27:47.960 --> 27:49.400\n So you've created,\n\n27:50.720 --> 27:52.600\n feels weird to be sitting with John Hotfield\n\n27:52.600 --> 27:54.920\n calling him Hotfield Networks, but.\n\n27:54.920 --> 27:55.760\n It is weird.\n\n27:55.760 --> 28:00.600\n Yeah, but nevertheless, that's what everyone calls him.\n\n28:00.600 --> 28:02.880\n So here we are.\n\n28:02.880 --> 28:04.960\n So that's a simplification.\n\n28:04.960 --> 28:06.720\n That's what a physicist would do.\n\n28:06.720 --> 28:08.440\n You and Richard Feynman sat down\n\n28:08.440 --> 28:09.960\n and talked about associative memory.\n\n28:09.960 --> 28:14.480\n Now, if you look at the mind\n\n28:14.480 --> 28:17.400\n where you can't quite simplify it so perfectly,\n\n28:17.400 --> 28:18.240\n do you think that?\n\n28:18.240 --> 28:21.920\n Well, let me backtrack just a little bit.\n\n28:21.920 --> 28:22.960\n Yeah.\n\n28:22.960 --> 28:25.680\n Biology is about dynamical systems.\n\n28:25.680 --> 28:29.480\n Computers are dynamical systems.\n\n28:29.480 --> 28:34.480\n You can ask, if you want to model biology,\n\n28:35.360 --> 28:38.440\n if you want to model neurobiology,\n\n28:38.440 --> 28:39.920\n what is the time scale?\n\n28:39.920 --> 28:42.600\n There's a dynamical system in which,\n\n28:42.600 --> 28:46.360\n of a fairly fast time scale in which you could say,\n\n28:46.360 --> 28:49.480\n the synapses don't change much during this computation,\n\n28:49.480 --> 28:51.760\n so I'll think of the synapses fixed\n\n28:51.760 --> 28:54.240\n and just do the dynamics of the activity.\n\n28:54.240 --> 28:58.920\n Or you can say, the synapses are changing fast enough\n\n28:58.920 --> 29:01.360\n that I have to have the synaptic dynamics\n\n29:01.360 --> 29:04.280\n working at the same time as the system dynamics\n\n29:05.160 --> 29:07.800\n in order to understand the biology.\n\n29:11.560 --> 29:15.280\n Most, if you look at the feedforward artificial neural nets,\n\n29:16.160 --> 29:18.440\n they're all done as learnings.\n\n29:18.440 --> 29:21.360\n First of all, I spend some time learning, not performing,\n\n29:21.360 --> 29:23.480\n and I turn off learning and I turn off learning,\n\n29:23.480 --> 29:25.280\n and I turn off learning and I perform.\n\n29:26.600 --> 29:27.680\n Right.\n\n29:27.680 --> 29:28.960\n That's not biology.\n\n29:30.960 --> 29:34.720\n And so as I look more deeply at neurobiology,\n\n29:34.720 --> 29:37.000\n even as associative memory,\n\n29:37.000 --> 29:39.360\n I've got to face the fact that the dynamics\n\n29:39.360 --> 29:42.720\n of the synapse change is going on all the time.\n\n29:44.600 --> 29:46.320\n And I can't just get by by saying,\n\n29:46.320 --> 29:50.640\n I'll do the dynamics of activity with fixed synapses.\n\n29:50.640 --> 29:51.480\n Yeah.\n\n29:52.600 --> 29:56.120\n So the synaptic, the dynamics of the synapses\n\n29:56.120 --> 29:58.200\n is actually fundamental to the whole system.\n\n29:58.200 --> 30:00.000\n Yeah, yeah.\n\n30:00.000 --> 30:04.800\n And there's nothing necessarily separating the time scales.\n\n30:04.800 --> 30:06.560\n When the time scale's gonna be separated,\n\n30:06.560 --> 30:08.200\n it's neat from the physicist's\n\n30:08.200 --> 30:10.840\n or the mathematician's point of view,\n\n30:10.840 --> 30:13.720\n but it's not necessarily true in neurobiology.\n\n30:13.720 --> 30:16.800\n So you're kind of dancing beautifully\n\n30:16.800 --> 30:20.320\n between showing a lot of respect to physics\n\n30:20.320 --> 30:24.080\n and then also saying that physics\n\n30:24.080 --> 30:29.080\n cannot quite reach the complexity of biology.\n\n30:29.640 --> 30:30.680\n So where do you land?\n\n30:30.680 --> 30:33.360\n Or do you continuously dance between the two points?\n\n30:33.360 --> 30:34.920\n I continuously dance between them\n\n30:34.920 --> 30:37.040\n because my whole notion of understanding\n\n30:39.800 --> 30:43.000\n is that you can describe to somebody else\n\n30:43.000 --> 30:47.320\n how something works in ways which are honest and believable\n\n30:47.320 --> 30:52.320\n and still not describe all the nuts and bolts in detail.\n\n30:54.240 --> 30:55.080\n Weather.\n\n30:55.960 --> 30:57.440\n I can describe weather\n\n30:59.560 --> 31:04.560\n as 10 to the 32 molecules colliding in the atmosphere.\n\n31:04.560 --> 31:07.560\n I can simulate weather that way if I have a big enough machine.\n\n31:07.560 --> 31:09.200\n I'll simulate it accurately.\n\n31:11.880 --> 31:13.560\n It's no good for understanding.\n\n31:13.560 --> 31:16.160\n If I want to understand things, I want to understand things\n\n31:16.160 --> 31:19.080\n in terms of wind patterns, hurricanes,\n\n31:19.080 --> 31:21.000\n pressure differentials, and so on,\n\n31:21.000 --> 31:22.640\n all things as they're collective.\n\n31:24.800 --> 31:29.800\n And the physicist in me always hopes\n\n31:29.800 --> 31:32.320\n that biology will have some things\n\n31:32.320 --> 31:35.320\n that can be said about it which are both true\n\n31:35.320 --> 31:38.360\n and for which you don't need all the molecular details\n\n31:38.360 --> 31:39.920\n as the molecules colliding.\n\n31:39.920 --> 31:42.960\n That's what I mean from the roots of physics,\n\n31:42.960 --> 31:44.040\n by understanding.\n\n31:45.560 --> 31:47.960\n So what did, again, sorry,\n\n31:47.960 --> 31:51.160\n but Hopfield Networks help you understand\n\n31:51.160 --> 31:56.160\n what insight did give us about memory, about learning?\n\n31:57.960 --> 32:02.000\n They didn't give insights about learning.\n\n32:02.000 --> 32:06.000\n They gave insights about how things having learned\n\n32:06.000 --> 32:11.000\n could be expressed, how having learned a picture of you,\n\n32:13.000 --> 32:15.240\n a picture of you reminds me of your name.\n\n32:16.560 --> 32:20.080\n That would, but it didn't describe a reasonable way\n\n32:20.080 --> 32:21.880\n of actually doing the learning.\n\n32:24.080 --> 32:26.240\n They only said if you had previously learned\n\n32:27.240 --> 32:30.040\n the connections of this kind of pattern,\n\n32:30.040 --> 32:31.560\n would now be able to,\n\n32:31.560 --> 32:34.640\n behave in a physical way was to say,\n\n32:34.640 --> 32:37.200\n ah, if I put the part of the pattern in here,\n\n32:37.200 --> 32:40.960\n the other part of the pattern will complete over here.\n\n32:40.960 --> 32:43.360\n I could understand that physics,\n\n32:43.360 --> 32:45.920\n if the right learning stuff had already been put in.\n\n32:46.880 --> 32:48.800\n And it could understand why then putting in a picture\n\n32:48.800 --> 32:51.360\n of somebody else would generate something else over here.\n\n32:52.880 --> 32:56.920\n But it did not have a reasonable description\n\n32:56.920 --> 32:59.320\n of the learning that was going on.\n\n32:59.320 --> 33:01.880\n It did not have a reasonable description\n\n33:01.880 --> 33:03.840\n of the learning process.\n\n33:03.840 --> 33:05.680\n But even, so forget learning.\n\n33:05.680 --> 33:07.320\n I mean, that's just a powerful concept\n\n33:07.320 --> 33:11.760\n that sort of forming representations\n\n33:11.760 --> 33:14.960\n that are useful to be robust,\n\n33:14.960 --> 33:17.320\n you know, for error correction kind of thing.\n\n33:17.320 --> 33:20.880\n So this is kind of what the biology does\n\n33:20.880 --> 33:22.320\n we're talking about.\n\n33:22.320 --> 33:26.440\n Yeah, and what my paper did was simply enable you,\n\n33:26.440 --> 33:29.960\n there are lots of ways of being robust.\n\n33:34.120 --> 33:36.480\n If you think of a dynamical system,\n\n33:36.480 --> 33:41.480\n you think of a system where a path is going on in time.\n\n33:42.160 --> 33:43.840\n And if you think for a computer,\n\n33:43.840 --> 33:45.240\n there's a computational path,\n\n33:45.240 --> 33:48.480\n which is going on in a huge dimensional space\n\n33:48.480 --> 33:49.800\n of ones and zeros.\n\n33:51.720 --> 33:55.760\n And an error correction system is a system,\n\n33:55.760 --> 33:58.720\n which if you get a little bit off that trajectory,\n\n33:58.720 --> 34:00.960\n will push you back onto that trajectory again.\n\n34:00.960 --> 34:03.160\n So you get to the same answer in spite of the fact\n\n34:03.160 --> 34:04.720\n that there were things,\n\n34:04.720 --> 34:07.480\n so that the computation wasn't being ideally done\n\n34:07.480 --> 34:08.880\n all the way along the line.\n\n34:10.920 --> 34:13.600\n And there are lots of models for error correction.\n\n34:13.600 --> 34:17.120\n But one of the models for error correction is to say,\n\n34:17.120 --> 34:20.800\n there's a valley that you're following, flowing down.\n\n34:20.800 --> 34:23.960\n And if you push a little bit off the valley,\n\n34:23.960 --> 34:26.600\n just like water being pushed a little bit by a rock,\n\n34:26.600 --> 34:30.120\n it gets back and follows the course of the river.\n\n34:30.120 --> 34:34.520\n And that basically the analog\n\n34:35.760 --> 34:38.680\n in the physical system, which enables you to say,\n\n34:38.680 --> 34:43.640\n oh yes, error free computation and an associative memory\n\n34:43.640 --> 34:46.920\n are very much like things that I can understand\n\n34:46.920 --> 34:49.400\n from the point of view of a physical system.\n\n34:49.400 --> 34:54.400\n The physical system is, can be under some circumstances,\n\n34:54.560 --> 34:55.960\n an accurate metaphor.\n\n34:58.200 --> 34:59.520\n It's not the only metaphor.\n\n34:59.520 --> 35:01.960\n There are error correction schemes,\n\n35:01.960 --> 35:05.960\n which don't have a valley and energy behind them.\n\n35:06.840 --> 35:09.120\n But those are error correction schemes,\n\n35:09.120 --> 35:11.320\n which a mathematician may be able to understand,\n\n35:11.320 --> 35:12.160\n but I don't.\n\n35:13.880 --> 35:18.880\n So there's the physical metaphor that seems to work here.\n\n35:18.880 --> 35:20.600\n That's right, that's right.\n\n35:20.600 --> 35:25.600\n So these kinds of networks actually led to a lot of the work\n\n35:26.520 --> 35:29.760\n that is going on now in neural networks,\n\n35:29.760 --> 35:30.880\n artificial neural networks.\n\n35:30.880 --> 35:34.800\n So the follow on work with restricted Boltzmann machines\n\n35:34.800 --> 35:39.800\n and deep belief nets followed on from these ideas\n\n35:40.760 --> 35:41.760\n of the Hopfield network.\n\n35:41.760 --> 35:46.760\n So what do you think about this continued progress\n\n35:46.760 --> 35:51.760\n of that work towards now re revigorated exploration\n\n35:51.880 --> 35:54.360\n of feed forward neural networks\n\n35:54.360 --> 35:55.720\n and recurrent neural networks\n\n35:55.720 --> 35:57.280\n and convolutional neural networks\n\n35:57.280 --> 36:01.520\n and kinds of networks that are helping solve\n\n36:01.520 --> 36:03.840\n image recognition, natural language processing,\n\n36:03.840 --> 36:05.000\n all that kind of stuff.\n\n36:05.920 --> 36:09.720\n It always intrigued me that one of the most long lived\n\n36:09.720 --> 36:14.000\n of the learning systems is the Boltzmann machine,\n\n36:14.000 --> 36:17.240\n which is intrinsically a feedback network.\n\n36:18.880 --> 36:23.880\n And with the brilliance of Hind and Sinowski\n\n36:24.440 --> 36:26.760\n to understand how to do learning in that.\n\n36:28.160 --> 36:30.720\n And it's still a useful way to understand learning\n\n36:30.720 --> 36:34.760\n and the learning that you understand in that\n\n36:34.760 --> 36:36.520\n has something to do with the way\n\n36:36.520 --> 36:39.040\n that feed forward systems work.\n\n36:39.040 --> 36:41.520\n But it's not always exactly simple\n\n36:41.520 --> 36:44.360\n to express that intuition.\n\n36:45.720 --> 36:49.080\n But it's always amuses me to see Hinton\n\n36:49.080 --> 36:51.640\n going back to the will yet again\n\n36:51.640 --> 36:53.240\n on a form of the Boltzmann machine\n\n36:53.240 --> 36:58.240\n because really that which has feedback\n\n36:59.120 --> 37:01.160\n and interesting probabilities in it\n\n37:02.080 --> 37:05.760\n is a lovely encapsulation of something in computational.\n\n37:07.600 --> 37:09.200\n Something computational?\n\n37:09.200 --> 37:12.160\n Something both computational and physical.\n\n37:12.160 --> 37:15.360\n Computational and it's very much related\n\n37:15.360 --> 37:17.400\n to feed forward networks.\n\n37:17.400 --> 37:21.720\n Physical in that Boltzmann machine learning\n\n37:21.720 --> 37:24.880\n is really learning a set of parameters\n\n37:24.880 --> 37:28.000\n for a physics Hamiltonian or energy function.\n\n37:29.640 --> 37:32.440\n What do you think about learning in this whole domain?\n\n37:32.440 --> 37:37.400\n Do you think the aforementioned guy,\n\n37:37.400 --> 37:42.000\n Jeff Hinton, all the work there with backpropagation,\n\n37:42.000 --> 37:46.120\n all the kind of learning that goes on in these networks,\n\n37:49.600 --> 37:53.160\n if we compare it to learning in the brain, for example,\n\n37:53.160 --> 37:55.520\n is there echoes of the same kind of power\n\n37:55.520 --> 37:59.000\n that backpropagation reveals\n\n37:59.000 --> 38:01.640\n about these kinds of recurrent networks?\n\n38:01.640 --> 38:03.920\n Or is it something fundamentally different\n\n38:03.920 --> 38:10.240\n going on in the brain?\n\n38:10.240 --> 38:13.880\n I don't think the brain is as deep\n\n38:13.880 --> 38:17.000\n as the deepest networks go,\n\n38:17.000 --> 38:22.160\n the deepest computer science networks.\n\n38:22.160 --> 38:24.240\n And I do wonder whether part of that depth\n\n38:24.240 --> 38:28.280\n of the computer science networks is necessitated\n\n38:28.280 --> 38:29.840\n by the fact that the only learning\n\n38:29.840 --> 38:36.240\n that's easily done on a machine is feed forward.\n\n38:36.240 --> 38:39.520\n And so there's the question of to what extent\n\n38:39.520 --> 38:42.640\n is the biology, which has some feed forward\n\n38:42.640 --> 38:46.040\n and some feed back,\n\n38:46.040 --> 38:51.600\n been captured by something which has got many more neurons\n\n38:51.600 --> 38:56.400\n but much more depth than the neurons in it.\n\n38:56.400 --> 39:00.200\n So part of you wonders if the feedback is actually\n\n39:00.200 --> 39:03.640\n more essential than the number of neurons or the depth,\n\n39:03.640 --> 39:06.360\n the dynamics of the feedback.\n\n39:06.360 --> 39:08.760\n The dynamics of the feedback.\n\n39:08.760 --> 39:11.680\n Look, if you don't have feedback,\n\n39:11.680 --> 39:14.600\n it's a little bit like a building a big computer\n\n39:14.600 --> 39:17.800\n and running it through one clock cycle.\n\n39:17.800 --> 39:19.160\n And then you can't do anything\n\n39:19.160 --> 39:24.400\n until you reload something coming in.\n\n39:24.400 --> 39:28.160\n How do you use the fact that there are multiple clock cycles?\n\n39:28.160 --> 39:30.720\n How do I use the fact that you can close your eyes,\n\n39:30.720 --> 39:33.800\n stop listening to me and think about a chessboard\n\n39:33.800 --> 39:38.520\n for two minutes without any input whatsoever?\n\n39:38.520 --> 39:42.440\n Yeah, that memory thing,\n\n39:42.440 --> 39:45.960\n that's fundamentally a feedback kind of mechanism.\n\n39:45.960 --> 39:47.480\n You're going back to something.\n\n39:47.480 --> 39:51.920\n Yes, it's hard to understand.\n\n39:51.920 --> 39:53.920\n It's hard to introspect,\n\n39:53.920 --> 39:57.360\n let alone consciousness.\n\n39:57.360 --> 40:01.080\n Oh, let alone consciousness, yes, yes.\n\n40:01.080 --> 40:02.440\n Because that's tied up in there too.\n\n40:02.440 --> 40:06.880\n You can't just put that on another shelf.\n\n40:06.880 --> 40:09.720\n Every once in a while I get interested in consciousness\n\n40:09.720 --> 40:12.800\n and then I go and I've done that for years\n\n40:12.800 --> 40:17.120\n and ask one of my betters, as it were,\n\n40:17.120 --> 40:18.640\n their view on consciousness.\n\n40:18.640 --> 40:21.880\n It's been interesting collecting them.\n\n40:21.880 --> 40:25.240\n What is consciousness?\n\n40:25.240 --> 40:30.160\n Let's try to take a brief step into that room.\n\n40:30.160 --> 40:32.320\n Well, ask Marvin Minsky,\n\n40:32.320 --> 40:33.640\n his view on consciousness.\n\n40:33.640 --> 40:36.400\n And Marvin said,\n\n40:36.400 --> 40:40.440\n consciousness is basically overrated.\n\n40:40.440 --> 40:42.800\n It may be an epiphenomenon.\n\n40:42.800 --> 40:45.280\n After all, all the things your brain does,\n\n40:45.280 --> 40:49.640\n but they're actually hard computations\n\n40:49.640 --> 40:55.680\n you do nonconsciously.\n\n40:55.680 --> 40:57.240\n And there's so much evidence\n\n40:57.240 --> 41:00.840\n that even the simple things you do,\n\n41:00.840 --> 41:03.280\n you can make decisions,\n\n41:03.280 --> 41:05.680\n you can make committed decisions about them,\n\n41:05.680 --> 41:07.320\n the neurobiologist can say,\n\n41:07.320 --> 41:12.240\n he's now committed, he's going to move the hand left\n\n41:12.240 --> 41:14.800\n before you know it.\n\n41:14.800 --> 41:16.800\n So his view that consciousness is not,\n\n41:16.800 --> 41:19.360\n that's just like little icing on the cake.\n\n41:19.360 --> 41:21.400\n The real cake is in the subconscious.\n\n41:21.400 --> 41:22.960\n Yum, yum.\n\n41:22.960 --> 41:24.920\n Subconscious, nonconscious.\n\n41:24.920 --> 41:27.560\n Nonconscious, what's the better word, sir?\n\n41:27.560 --> 41:29.680\n It's only that Freud captured the other word.\n\n41:29.680 --> 41:33.320\n Yeah, it's a confusing word, subconscious.\n\n41:33.320 --> 41:38.080\n Nicholas Chaiter wrote an interesting book.\n\n41:38.080 --> 41:44.920\n I think the title of it is The Mind is Flat.\n\n41:44.920 --> 41:49.720\n Flat in a neural net sense, might be flat\n\n41:49.720 --> 41:53.400\n as something which is a very broad neural net\n\n41:53.400 --> 41:56.280\n without any layers in depth,\n\n41:56.280 --> 41:58.400\n whereas a deep brain would be many layers\n\n41:58.400 --> 42:00.800\n and not so broad.\n\n42:00.800 --> 42:05.080\n In the same sense that if you push Minsky hard enough,\n\n42:05.080 --> 42:07.840\n he would probably have said,\n\n42:07.840 --> 42:12.840\n consciousness is your effort to explain to yourself\n\n42:12.840 --> 42:16.800\n that which you have already done.\n\n42:16.800 --> 42:20.000\n Yeah, it's the weaving of the narrative\n\n42:20.000 --> 42:23.760\n around the things that have already been computed for you.\n\n42:23.760 --> 42:27.560\n That's right, and so much of what we do\n\n42:27.560 --> 42:32.080\n for our memories of events, for example.\n\n42:32.080 --> 42:35.720\n If there's some traumatic event you witness,\n\n42:35.720 --> 42:39.560\n you will have a few facts about it correctly done.\n\n42:39.560 --> 42:42.960\n If somebody asks you about it, you will weave a narrative\n\n42:42.960 --> 42:47.200\n which is actually much more rich in detail than that\n\n42:47.200 --> 42:50.600\n based on some anchor points you have of correct things\n\n42:50.600 --> 42:53.840\n and pulling together general knowledge on the other,\n\n42:53.840 --> 42:56.680\n but you will have a narrative.\n\n42:56.680 --> 42:58.280\n And once you generate that narrative,\n\n42:58.280 --> 43:00.800\n you are very likely to repeat that narrative\n\n43:00.800 --> 43:02.920\n and claim that all the things you have in it\n\n43:02.920 --> 43:05.040\n are actually the correct things.\n\n43:05.040 --> 43:06.840\n There was a marvelous example of that\n\n43:06.840 --> 43:11.840\n in the Watergate slash impeachment era of John Dean.\n\n43:16.760 --> 43:19.880\n John Dean, you're too young to know,\n\n43:19.880 --> 43:23.960\n had been the personal lawyer of Nixon.\n\n43:26.200 --> 43:28.760\n And so John Dean was involved in the coverup\n\n43:28.760 --> 43:32.280\n and John Dean ultimately realized\n\n43:32.280 --> 43:35.600\n the only way to keep himself out of jail for a long time\n\n43:35.600 --> 43:38.760\n was actually to tell some of the truths about Nixon.\n\n43:38.760 --> 43:41.080\n And John Dean was a tremendous witness.\n\n43:41.080 --> 43:45.880\n He would remember these conversations in great detail\n\n43:45.880 --> 43:48.280\n and very convincing detail.\n\n43:49.280 --> 43:54.280\n And long afterward, some of the tapes,\n\n43:54.880 --> 43:57.560\n the secret tapes as it were from which these,\n\n43:57.560 --> 44:00.520\n Don was, Gene was recalling these conversations\n\n44:01.600 --> 44:04.640\n were published, and one found out that John Dean\n\n44:04.640 --> 44:07.160\n had a good but not exceptional memory.\n\n44:07.160 --> 44:10.560\n What he had was an ability to paint vividly\n\n44:10.560 --> 44:15.140\n and in some sense accurately the tone of what was going on.\n\n44:16.960 --> 44:19.960\n By the way, that's a beautiful description of consciousness.\n\n44:23.000 --> 44:28.000\n Do you, like where do you stand in your today?\n\n44:32.520 --> 44:34.600\n So perhaps it changes day to day,\n\n44:34.600 --> 44:37.680\n but where do you stand on the importance of consciousness\n\n44:37.680 --> 44:39.860\n in our whole big mess of cognition?\n\n44:42.080 --> 44:44.880\n Is it just a little narrative maker\n\n44:45.740 --> 44:48.860\n or is it actually fundamental to intelligence?\n\n44:51.280 --> 44:56.120\n That's a very hard one.\n\n44:56.120 --> 44:58.760\n When I asked Francis Crick about consciousness,\n\n45:00.640 --> 45:03.280\n he launched forward in a long monologue\n\n45:03.280 --> 45:07.440\n about Mendel and the peas and how Mendel knew\n\n45:07.440 --> 45:10.600\n that there was something and how biologists understood\n\n45:10.600 --> 45:13.240\n that there was something in inheritance,\n\n45:13.240 --> 45:16.240\n which was just very, very different.\n\n45:16.240 --> 45:21.200\n And the fact that inherited traits didn't just wash out\n\n45:21.200 --> 45:26.200\n into a gray, but this or this and propagated\n\n45:27.980 --> 45:30.680\n that that was absolutely fundamental to the biology.\n\n45:30.680 --> 45:34.380\n And it took generations of biologists to understand\n\n45:34.380 --> 45:37.720\n that there was genetics and it took another generation\n\n45:37.720 --> 45:42.080\n or two to understand that genetics came from DNA.\n\n45:42.080 --> 45:47.080\n But very shortly after Mendel, thinking biologists\n\n45:47.360 --> 45:50.920\n did realize that there was a deep problem about inheritance.\n\n45:54.720 --> 45:58.240\n And Francis would have liked to have said,\n\n45:58.240 --> 46:01.520\n and that's why I'm working on consciousness.\n\n46:01.520 --> 46:03.960\n But of course, he didn't have any smoking gun\n\n46:03.960 --> 46:05.360\n in the sense of Mendel.\n\n46:08.520 --> 46:10.600\n And that's the weakness of his position.\n\n46:10.600 --> 46:15.600\n If you read his book, which he wrote with Koch, I think.\n\n46:16.080 --> 46:18.000\n Yeah, Christoph Koch, yeah.\n\n46:18.000 --> 46:22.660\n I find it unconvincing for the smoking gun reason.\n\n46:22.660 --> 46:27.660\n So I'm going on collecting views without actually having taken\n\n46:30.540 --> 46:32.700\n a very strong one myself,\n\n46:32.700 --> 46:35.320\n because I haven't seen the entry point.\n\n46:35.320 --> 46:38.300\n Not seeing the smoking gun from the point of view\n\n46:38.300 --> 46:41.140\n of physics, I don't see the entry point.\n\n46:41.140 --> 46:44.260\n Whereas in neurobiology, once I understood the idea\n\n46:44.260 --> 46:48.860\n of a collective, an evolution of dynamics,\n\n46:48.860 --> 46:52.180\n which could be described as a collective phenomenon,\n\n46:52.180 --> 46:55.740\n I thought, ah, there's a point where what I know\n\n46:55.740 --> 46:59.020\n about physics is so different from any neurobiologist\n\n46:59.020 --> 47:01.740\n that I have something that I might be able to contribute.\n\n47:01.740 --> 47:05.580\n And right now, there's no way to grasp at consciousness\n\n47:05.580 --> 47:07.660\n from a physics perspective.\n\n47:07.660 --> 47:09.720\n From my point of view, that's correct.\n\n47:11.460 --> 47:16.460\n And of course, people, physicists, like everybody else,\n\n47:16.980 --> 47:18.380\n think very muddily about things.\n\n47:18.380 --> 47:23.380\n You ask the closely related question about free will.\n\n47:23.780 --> 47:25.540\n Do you believe you have free will?\n\n47:27.340 --> 47:30.180\n Physicists will give an offhand answer,\n\n47:30.180 --> 47:32.620\n and then backtrack, backtrack, backtrack,\n\n47:32.620 --> 47:34.820\n where they realize that the answer they gave\n\n47:34.820 --> 47:37.540\n must fundamentally contradict the laws of physics.\n\n47:38.420 --> 47:40.380\n Natural, answering questions of free will\n\n47:40.380 --> 47:42.820\n and consciousness naturally lead to contradictions\n\n47:42.820 --> 47:44.260\n from a physics perspective.\n\n47:45.860 --> 47:48.080\n Because it eventually ends up with quantum mechanics,\n\n47:48.080 --> 47:50.460\n and then you get into that whole mess\n\n47:50.460 --> 47:54.760\n of trying to understand how much,\n\n47:54.760 --> 47:58.400\n from a physics perspective, how much is determined,\n\n47:58.400 --> 48:01.060\n already predetermined, how much is already deterministic\n\n48:01.060 --> 48:03.460\n about our universe, and there's lots of different things.\n\n48:03.460 --> 48:06.660\n And if you don't push quite that far, you can say,\n\n48:07.560 --> 48:10.740\n essentially, all of neurobiology, which is relevant,\n\n48:10.740 --> 48:13.740\n can be captured by classical equations of motion.\n\n48:13.740 --> 48:18.740\n Right, because in my view of the mysteries of the brain\n\n48:18.960 --> 48:22.160\n are not the mysteries of quantum mechanics,\n\n48:22.160 --> 48:24.840\n but the mysteries of what can happen\n\n48:24.840 --> 48:28.840\n when you have a dynamical system, driven system,\n\n48:28.840 --> 48:30.680\n with 10 to the 14 parts.\n\n48:32.260 --> 48:34.960\n That that complexity is something which is,\n\n48:37.040 --> 48:39.620\n that the physics of complex systems\n\n48:39.620 --> 48:42.040\n is at least as badly understood\n\n48:42.040 --> 48:45.660\n as the physics of phase coherence in quantum mechanics.\n\n48:46.520 --> 48:48.520\n Can we go there for a second?\n\n48:48.520 --> 48:50.860\n You've talked about attractor networks,\n\n48:51.720 --> 48:54.800\n and just maybe you could say what are attractor networks,\n\n48:54.800 --> 48:58.600\n and more broadly, what are interesting network dynamics\n\n48:58.600 --> 49:03.000\n that emerge in these or other complex systems?\n\n49:05.260 --> 49:06.320\n You have to be willing to think\n\n49:06.320 --> 49:08.720\n in a huge number of dimensions,\n\n49:08.720 --> 49:11.000\n because in a huge number of dimensions,\n\n49:11.000 --> 49:12.920\n the behavior of a system can be thought\n\n49:12.920 --> 49:15.920\n as just the motion of a point over time\n\n49:15.920 --> 49:17.760\n in this huge number of dimensions.\n\n49:17.760 --> 49:19.340\n All right.\n\n49:19.340 --> 49:22.080\n And an attractor network is simply a network\n\n49:22.080 --> 49:25.920\n where there is a line and other lines\n\n49:25.920 --> 49:28.320\n converge on it in time.\n\n49:28.320 --> 49:31.160\n That's the essence of an attractor network.\n\n49:31.160 --> 49:32.000\n That's how you.\n\n49:32.000 --> 49:34.760\n In a highly dimensional space.\n\n49:34.760 --> 49:37.400\n And the easiest way to get that\n\n49:37.400 --> 49:40.760\n is to do it in a highly dimensional space,\n\n49:40.760 --> 49:44.960\n where some of the dimensions provide the dissipation,\n\n49:44.960 --> 49:49.240\n which, if I have a physical system,\n\n49:50.160 --> 49:53.680\n trajectories can't contract everywhere.\n\n49:53.680 --> 49:56.920\n They have to contract in some places and expand in others.\n\n49:56.920 --> 49:59.360\n There's a fundamental classical theorem\n\n49:59.360 --> 50:00.840\n of statistical mechanics,\n\n50:00.840 --> 50:04.560\n which goes under the name of Liouville's theorem,\n\n50:04.560 --> 50:08.600\n which says you can't contract everywhere.\n\n50:08.600 --> 50:12.400\n If you contract somewhere, you expand somewhere else.\n\n50:12.400 --> 50:15.240\n In interesting physical systems,\n\n50:15.240 --> 50:17.480\n you've got driven systems\n\n50:17.480 --> 50:19.240\n where you have a small subsystem,\n\n50:19.240 --> 50:21.720\n which is the interesting part.\n\n50:21.720 --> 50:24.120\n And the rest of the contraction and expansion,\n\n50:24.120 --> 50:26.000\n the physicists would say it's entropy flow\n\n50:26.000 --> 50:27.640\n in this other part of the system.\n\n50:30.880 --> 50:35.520\n But basically, attractor networks are dynamics\n\n50:35.520 --> 50:40.360\n that are funneling down so that you can't be any,\n\n50:40.360 --> 50:42.520\n so that if you start somewhere in the dynamical system,\n\n50:42.520 --> 50:44.120\n you will soon find yourself\n\n50:44.120 --> 50:47.120\n on a pretty well determined pathway, which goes somewhere.\n\n50:47.120 --> 50:48.120\n If you start somewhere else,\n\n50:48.120 --> 50:50.560\n you'll wind up on a different pathway,\n\n50:50.560 --> 50:53.080\n but I don't have just all possible things.\n\n50:53.080 --> 50:56.640\n You have some defined pathways which are allowed\n\n50:56.640 --> 50:58.840\n and onto which you will converge.\n\n51:00.120 --> 51:01.920\n And that's the way you make a stable computer,\n\n51:01.920 --> 51:06.280\n and that's the way you make a stable behavior.\n\n51:06.280 --> 51:08.760\n So in general, looking at the physics\n\n51:08.760 --> 51:13.760\n of the emergent stability in networks,\n\n51:15.200 --> 51:18.160\n what are some interesting characteristics that,\n\n51:19.640 --> 51:20.960\n what are some interesting insights\n\n51:20.960 --> 51:24.960\n from studying the dynamics of such high dimensional systems?\n\n51:24.960 --> 51:29.880\n Most dynamical systems, most driven dynamical systems,\n\n51:29.880 --> 51:33.200\n are driven, they're coupled somehow to an energy source.\n\n51:33.200 --> 51:35.600\n And so their dynamics keeps going\n\n51:35.600 --> 51:37.800\n because it's coupling to the energy source.\n\n51:40.080 --> 51:42.680\n Most of them, it's very difficult to understand at all\n\n51:42.680 --> 51:46.560\n what the dynamical behavior is going to be.\n\n51:47.760 --> 51:49.240\n You have to run it.\n\n51:49.240 --> 51:50.600\n You have to run it.\n\n51:50.600 --> 51:54.080\n There's a subset of systems which has\n\n51:54.080 --> 51:57.280\n what is actually known to the mathematicians\n\n51:57.280 --> 52:02.000\n as a Lyapunov function, and those systems,\n\n52:02.000 --> 52:05.520\n you can understand convergent dynamics\n\n52:05.520 --> 52:08.960\n by saying you're going downhill on something or other.\n\n52:10.640 --> 52:13.560\n And that's what I found with ever knowing\n\n52:13.560 --> 52:17.120\n what Lyapunov functions were in the simple model\n\n52:17.120 --> 52:20.480\n I made in the early 80s, was an energy function\n\n52:20.480 --> 52:23.200\n so you could understand how you could get this channeling\n\n52:23.200 --> 52:28.080\n on the pathways without having to follow the dynamics\n\n52:28.080 --> 52:30.040\n in infinite detail.\n\n52:31.880 --> 52:34.320\n You started rolling a ball at the top of a mountain,\n\n52:34.320 --> 52:36.480\n it's gonna wind up at the bottom of a valley.\n\n52:36.480 --> 52:40.440\n You know that's true without actually watching\n\n52:40.440 --> 52:42.080\n the ball roll down.\n\n52:43.120 --> 52:45.840\n There's certain properties of the system\n\n52:45.840 --> 52:48.360\n that when you can know that.\n\n52:48.360 --> 52:49.400\n That's right.\n\n52:49.400 --> 52:53.640\n And not all systems behave that way.\n\n52:53.640 --> 52:55.240\n Most don't, probably.\n\n52:55.240 --> 52:57.720\n Most don't, but it provides you with a metaphor\n\n52:57.720 --> 53:00.720\n for thinking about systems which are stable\n\n53:00.720 --> 53:03.880\n and who to have these attractors behave\n\n53:03.880 --> 53:07.920\n even if you can't find a Lyapunov function behind them\n\n53:07.920 --> 53:09.880\n or an energy function behind them.\n\n53:09.880 --> 53:11.680\n It gives you a metaphor for thought.\n\n53:11.680 --> 53:16.680\n Yeah, speaking of thought,\n\n53:17.200 --> 53:21.000\n if I had a glint in my eye with excitement\n\n53:21.000 --> 53:25.600\n and said I'm really excited about this something\n\n53:25.600 --> 53:28.440\n called deep learning and neural networks\n\n53:28.440 --> 53:32.440\n and I would like to create an intelligent system\n\n53:32.440 --> 53:37.440\n and came to you as an advisor, what would you recommend?\n\n53:37.440 --> 53:42.440\n Is it a hopeless pursuit to use neural networks\n\n53:42.840 --> 53:44.060\n to achieve thought?\n\n53:44.920 --> 53:48.760\n Is it, what kind of mechanisms should we explore?\n\n53:48.760 --> 53:50.600\n What kind of ideas should we explore?\n\n53:52.040 --> 53:56.560\n Well, you look at the simple networks,\n\n53:56.560 --> 53:58.180\n the one past networks.\n\n54:01.320 --> 54:04.760\n They don't support multiple hypotheses very well.\n\n54:04.760 --> 54:05.600\n Hmm.\n\n54:06.960 --> 54:09.960\n As I have tried to work with very simple systems\n\n54:09.960 --> 54:12.960\n which do something which you might consider to be thinking,\n\n54:12.960 --> 54:17.680\n thought has to do with the ability to do mental exploration\n\n54:17.680 --> 54:20.040\n before you take a physical action.\n\n54:22.440 --> 54:25.480\n Almost like we were mentioning, playing chess,\n\n54:25.480 --> 54:30.440\n visualizing, simulating inside your head different outcomes.\n\n54:30.440 --> 54:31.400\n Yeah, yeah.\n\n54:31.400 --> 54:36.400\n And now you would do that in a feed forward network\n\n54:37.400 --> 54:40.540\n because you've pre calculated all kinds of things.\n\n54:41.960 --> 54:44.080\n But I think the way neurobiology does it\n\n54:44.080 --> 54:47.820\n hasn't pre calculated everything.\n\n54:49.360 --> 54:52.000\n It actually has parts of a dynamical system\n\n54:52.000 --> 54:57.000\n in which you're doing exploration in a way which is.\n\n54:57.000 --> 55:01.760\n There's a creative element.\n\n55:01.760 --> 55:02.600\n Like there's an.\n\n55:02.600 --> 55:04.680\n There's a creative element.\n\n55:04.680 --> 55:09.680\n And in a simple minded neural net,\n\n55:13.000 --> 55:18.000\n you have a constellation of instances\n\n55:20.080 --> 55:21.280\n of which you've learned.\n\n55:23.040 --> 55:25.760\n And if you are within that space,\n\n55:25.760 --> 55:30.760\n if a new question is a question within this space,\n\n55:32.800 --> 55:37.520\n you can actually rely on that system pretty well\n\n55:37.520 --> 55:41.040\n to come up with a good suggestion for what to do.\n\n55:41.040 --> 55:42.000\n If on the other hand,\n\n55:42.000 --> 55:45.120\n the query comes from outside the space,\n\n55:46.640 --> 55:48.440\n you have no way of knowing how the system\n\n55:48.440 --> 55:49.280\n is gonna behave.\n\n55:49.280 --> 55:51.440\n There are no limitations on what can happen.\n\n55:51.440 --> 55:55.300\n And so with the artificial neural net world\n\n55:55.300 --> 55:57.080\n is always very much,\n\n55:57.080 --> 56:01.020\n I have a population of examples.\n\n56:01.020 --> 56:04.740\n The test set must be drawn from the equivalent population.\n\n56:04.740 --> 56:06.860\n If the test set has examples,\n\n56:06.860 --> 56:09.920\n which are from a population which is completely different,\n\n56:11.100 --> 56:14.420\n there's no way that you could expect\n\n56:14.420 --> 56:16.500\n to get the answer right.\n\n56:16.500 --> 56:20.980\n Yeah, what they call outside the distribution.\n\n56:20.980 --> 56:22.180\n That's right, that's right.\n\n56:22.180 --> 56:27.180\n And so if you see a ball rolling across the street at dusk,\n\n56:28.420 --> 56:33.300\n if that wasn't in your training set,\n\n56:33.300 --> 56:37.060\n the idea that a child may be coming close behind that\n\n56:37.060 --> 56:39.060\n is not going to occur to the neural net.\n\n56:40.420 --> 56:42.500\n And it is to our,\n\n56:42.500 --> 56:45.580\n there's something in your biology that allows that.\n\n56:45.580 --> 56:47.620\n Yeah, there's something in the way\n\n56:47.620 --> 56:52.300\n of what it means to be outside of the population\n\n56:52.300 --> 56:53.620\n of the training set.\n\n56:53.620 --> 56:55.580\n The population of the training set\n\n56:55.580 --> 56:57.940\n isn't just sort of this set of examples.\n\n57:01.180 --> 57:03.660\n There's more to it than that.\n\n57:03.660 --> 57:06.540\n And it gets back to my question of,\n\n57:06.540 --> 57:09.180\n what is it to understand something?\n\n57:09.180 --> 57:10.020\n Yeah.\n\n57:12.020 --> 57:14.700\n You know, in a small tangent,\n\n57:14.700 --> 57:16.940\n you've talked about the value of thinking\n\n57:16.940 --> 57:18.660\n of deductive reasoning in science\n\n57:18.660 --> 57:20.800\n versus large data collection.\n\n57:21.820 --> 57:25.300\n So sort of thinking about the problem.\n\n57:25.300 --> 57:27.460\n I suppose it's the physics side of you\n\n57:27.460 --> 57:31.100\n of going back to first principles and thinking,\n\n57:31.100 --> 57:33.660\n but what do you think is the value of deductive reasoning\n\n57:33.660 --> 57:35.480\n in the scientific process?\n\n57:37.740 --> 57:39.820\n Well, there are obviously scientific questions\n\n57:39.820 --> 57:42.980\n in which the route to the answer to it\n\n57:42.980 --> 57:46.560\n comes through the analysis of one hell of a lot of data.\n\n57:46.560 --> 57:47.400\n Right.\n\n57:49.180 --> 57:50.500\n Cosmology, that kind of stuff.\n\n57:50.500 --> 57:53.300\n And that's never been the kind of problem\n\n57:56.700 --> 57:58.540\n in which I've had any particular insight.\n\n57:58.540 --> 58:00.240\n Though I must say, if you look at,\n\n58:01.660 --> 58:04.180\n cosmology is one of those.\n\n58:04.180 --> 58:06.780\n If you look at the actual things that Jim Peebles,\n\n58:06.780 --> 58:10.140\n one of this year's Nobel Prize in physics,\n\n58:10.140 --> 58:12.260\n ones from the local physics department,\n\n58:12.260 --> 58:13.760\n the kinds of things he's done,\n\n58:13.760 --> 58:17.000\n he's never crunched large data.\n\n58:17.000 --> 58:18.140\n Never, never, never.\n\n58:19.640 --> 58:23.760\n He's used the encapsulation of the work of others\n\n58:23.760 --> 58:25.240\n in this regard.\n\n58:25.240 --> 58:26.080\n Right.\n\n58:27.820 --> 58:30.840\n But it ultimately boiled down to thinking\n\n58:30.840 --> 58:31.700\n through the problem.\n\n58:31.700 --> 58:33.680\n Like what are the principles under which\n\n58:33.680 --> 58:35.840\n a particular phenomenon operates?\n\n58:35.840 --> 58:37.240\n Yeah, yeah.\n\n58:37.240 --> 58:39.520\n And look, physics is always going to look\n\n58:39.520 --> 58:42.640\n for ways in which you can describe the system\n\n58:42.640 --> 58:47.520\n in a way which rises above the details.\n\n58:47.520 --> 58:52.520\n And to the hard dyed, the wool biologist,\n\n58:53.840 --> 58:56.760\n biology works because of the details.\n\n58:56.760 --> 58:58.720\n In physics, to the physicists,\n\n58:58.720 --> 59:01.160\n we want an explanation which is right\n\n59:01.160 --> 59:03.040\n in spite of the details.\n\n59:03.040 --> 59:05.560\n And there will be questions which we cannot answer\n\n59:05.560 --> 59:13.080\n as physicists because the answer cannot be found that way.\n\n59:13.080 --> 59:15.240\n There's, I'm not sure if you're familiar\n\n59:15.240 --> 59:19.120\n with the entire field of brain computer interfaces\n\n59:19.120 --> 59:24.040\n that's become more and more intensely researched\n\n59:24.040 --> 59:25.920\n and developed recently, especially with companies\n\n59:25.920 --> 59:28.160\n like Neuralink with Elon Musk.\n\n59:29.080 --> 59:31.080\n Yeah, I know there have always been the interests\n\n59:31.080 --> 59:35.720\n both in things like getting the eyes\n\n59:35.720 --> 59:38.320\n to be able to control things\n\n59:38.320 --> 59:40.800\n or getting the thought patterns\n\n59:40.800 --> 59:45.080\n to be able to move what had been a connected limb\n\n59:45.080 --> 59:48.040\n which is now connected through a computer.\n\n59:48.040 --> 59:48.920\n That's right.\n\n59:48.920 --> 59:51.320\n So in the case of Neuralink,\n\n59:51.320 --> 59:54.600\n they're doing 1,000 plus connections\n\n59:54.600 --> 59:56.640\n where they're able to do two way,\n\n59:56.640 --> 1:00:01.440\n activate and read spikes, neural spikes.\n\n1:00:01.440 --> 1:00:06.200\n Do you have hope for that kind of computer brain interaction\n\n1:00:06.200 --> 1:00:08.440\n in the near or maybe even far future\n\n1:00:09.840 --> 1:00:13.400\n of being able to expand the ability\n\n1:00:13.400 --> 1:00:18.920\n of the mind of cognition or understand the mind?\n\n1:00:20.480 --> 1:00:23.760\n It's interesting watching things go.\n\n1:00:23.760 --> 1:00:27.080\n When I first became interested in neurobiology,\n\n1:00:27.080 --> 1:00:29.400\n most of the practitioners thought you would be able\n\n1:00:29.400 --> 1:00:32.360\n to understand neurobiology by techniques\n\n1:00:32.360 --> 1:00:36.640\n which allowed you to record only one cell at a time.\n\n1:00:36.640 --> 1:00:38.600\n One cell, yeah.\n\n1:00:38.600 --> 1:00:43.320\n People like David Hubel,\n\n1:00:43.320 --> 1:00:45.760\n very strongly reflected that point of view.\n\n1:00:47.200 --> 1:00:50.560\n And that's been taken over by a generation,\n\n1:00:50.560 --> 1:00:52.440\n a couple of generations later,\n\n1:00:52.440 --> 1:00:56.160\n by a set of people who says not until we can record\n\n1:00:56.160 --> 1:00:59.320\n from 10 to the four, 10 to the five at a time,\n\n1:00:59.320 --> 1:01:00.840\n will we actually be able to understand\n\n1:01:00.840 --> 1:01:03.360\n how the brain actually works.\n\n1:01:03.360 --> 1:01:08.360\n And in a general sense, I think that's right.\n\n1:01:09.720 --> 1:01:11.640\n You have to begin to be able to look\n\n1:01:12.840 --> 1:01:17.840\n for the collective modes, the collective operations of things.\n\n1:01:18.400 --> 1:01:21.240\n It doesn't rely on this action potential or that cell.\n\n1:01:21.240 --> 1:01:24.400\n It relies on the collective properties of this set of cells\n\n1:01:24.400 --> 1:01:26.760\n connected with this kind of patterns and so on.\n\n1:01:27.800 --> 1:01:29.960\n And you're not going to succeed in seeing\n\n1:01:29.960 --> 1:01:31.840\n what those collective activities are\n\n1:01:31.840 --> 1:01:34.360\n without recording many cells at once.\n\n1:01:38.400 --> 1:01:40.200\n The question is how many at once?\n\n1:01:40.200 --> 1:01:41.520\n What's the threshold?\n\n1:01:41.520 --> 1:01:42.960\n And that's the...\n\n1:01:42.960 --> 1:01:47.240\n Yeah, and look, it's being pursued hard\n\n1:01:47.240 --> 1:01:48.320\n in the motor cortex.\n\n1:01:48.320 --> 1:01:53.320\n The motor cortex does something which is complex,\n\n1:01:53.840 --> 1:01:55.640\n and yet the problem you're trying to address\n\n1:01:55.640 --> 1:01:57.400\n is fairly simple.\n\n1:02:00.200 --> 1:02:02.920\n Now, neurobiology does it in ways that differ\n\n1:02:02.920 --> 1:02:04.360\n from the way an engineer would do it.\n\n1:02:04.360 --> 1:02:09.360\n An engineer would put in six highly accurate stepping motors\n\n1:02:10.160 --> 1:02:15.080\n are controlling a limb rather than 100,000 muscle fibers,\n\n1:02:15.080 --> 1:02:19.320\n each of which has to be individually controlled.\n\n1:02:19.320 --> 1:02:22.720\n And so understanding how to do things in a way\n\n1:02:22.720 --> 1:02:26.720\n which is much more forgiving and much more neural,\n\n1:02:26.720 --> 1:02:30.760\n I think would benefit the engineering world.\n\n1:02:33.840 --> 1:02:36.040\n The engineering world, a touch.\n\n1:02:36.040 --> 1:02:38.080\n Let's put in a pressure sensor or two,\n\n1:02:38.080 --> 1:02:42.800\n rather than an array of a gazillion pressure sensors,\n\n1:02:42.800 --> 1:02:44.120\n none of which are accurate,\n\n1:02:44.120 --> 1:02:47.480\n all of which are perpetually recalibrating themselves.\n\n1:02:48.920 --> 1:02:50.840\n So you're saying your hope is,\n\n1:02:50.840 --> 1:02:53.600\n your advice for the engineers of the future\n\n1:02:53.600 --> 1:02:58.600\n is to embrace the large chaos of a messy, air prone system\n\n1:03:00.960 --> 1:03:03.520\n like those of the biological systems.\n\n1:03:03.520 --> 1:03:05.840\n Like that's probably the way to solve some of these.\n\n1:03:05.840 --> 1:03:10.640\n I think you'll be able to make better computations\n\n1:03:10.640 --> 1:03:15.640\n slash robotics that way than by trying to force things\n\n1:03:17.320 --> 1:03:22.320\n into a robotics where joint motors are powerful\n\n1:03:22.680 --> 1:03:25.360\n and stepping motors are accurate.\n\n1:03:25.360 --> 1:03:27.960\n But then the physicists, the physicist in you\n\n1:03:27.960 --> 1:03:31.280\n will be lost forever in such systems\n\n1:03:31.280 --> 1:03:33.720\n because there's no simple fundamentals to explore\n\n1:03:33.720 --> 1:03:38.240\n in systems that are so large and messy.\n\n1:03:38.240 --> 1:03:43.240\n Well, you say that, and yet there's a lot of physics\n\n1:03:43.840 --> 1:03:45.440\n in the Navier Stokes equations,\n\n1:03:45.440 --> 1:03:49.800\n the equations of nonlinear hydrodynamics,\n\n1:03:49.800 --> 1:03:51.480\n huge amount of physics in them.\n\n1:03:51.480 --> 1:03:55.560\n All the physics of atoms and molecules has been lost,\n\n1:03:55.560 --> 1:03:58.320\n but it's been replaced by this other set of equations,\n\n1:03:58.320 --> 1:04:02.240\n which is just as true as the equations at the bottom.\n\n1:04:02.240 --> 1:04:06.760\n Now those equations are going to be harder to find\n\n1:04:06.760 --> 1:04:10.880\n in general biology, but the physicist in me says\n\n1:04:10.880 --> 1:04:13.440\n there are probably some equations of that sort.\n\n1:04:13.440 --> 1:04:14.840\n They're out there.\n\n1:04:14.840 --> 1:04:17.160\n They're out there, and if physics\n\n1:04:17.160 --> 1:04:19.400\n is going to contribute anything,\n\n1:04:19.400 --> 1:04:22.120\n it may contribute to trying to find out\n\n1:04:22.120 --> 1:04:24.360\n what those equations are and how to capture them\n\n1:04:24.360 --> 1:04:25.540\n from the biology.\n\n1:04:26.640 --> 1:04:29.760\n Would you say that's one of the main open problems\n\n1:04:29.760 --> 1:04:34.280\n of our age is to discover those equations?\n\n1:04:34.280 --> 1:04:38.720\n Yeah, if you look at, there's molecules\n\n1:04:38.720 --> 1:04:40.940\n and there's psychological behavior,\n\n1:04:42.080 --> 1:04:45.600\n and these two are somehow related.\n\n1:04:45.600 --> 1:04:50.600\n They're layers of detail, they're layers of collectiveness,\n\n1:04:51.160 --> 1:04:54.680\n and to capture that in some vague way,\n\n1:04:58.600 --> 1:05:01.320\n several stages on the way up to see how these things\n\n1:05:01.320 --> 1:05:04.000\n can actually be linked together.\n\n1:05:04.000 --> 1:05:08.880\n So it seems in our universe, there's a lot of elegant\n\n1:05:08.880 --> 1:05:11.080\n equations that can describe the fundamental way\n\n1:05:11.080 --> 1:05:13.440\n that things behave, which is a surprise.\n\n1:05:13.440 --> 1:05:15.800\n I mean, it's compressible into equations.\n\n1:05:15.800 --> 1:05:20.760\n It's simple and beautiful, but it's still an open question\n\n1:05:20.760 --> 1:05:25.760\n whether that link is equally between molecules\n\n1:05:25.760 --> 1:05:29.400\n and the brain is equally compressible\n\n1:05:29.400 --> 1:05:31.080\n into elegant equations.\n\n1:05:31.080 --> 1:05:36.080\n But your sense, well, you're both a physicist\n\n1:05:36.400 --> 1:05:38.440\n and a dreamer, you have a sense that...\n\n1:05:38.440 --> 1:05:42.360\n Yeah, but I can only dream physics dreams.\n\n1:05:42.360 --> 1:05:44.240\n Physics dreams.\n\n1:05:44.240 --> 1:05:46.840\n There was an interesting book called Einstein's Dreams,\n\n1:05:46.840 --> 1:05:51.840\n which alternates between chapters on his life\n\n1:05:52.240 --> 1:05:57.240\n and descriptions of the way time might have been but isn't.\n\n1:05:57.240 --> 1:06:02.240\n The linking between these being important ideas\n\n1:06:04.640 --> 1:06:06.400\n that Einstein might have had to think about\n\n1:06:06.400 --> 1:06:09.440\n the essence of time as he was thinking about time.\n\n1:06:11.280 --> 1:06:14.760\n So speaking of the essence of time in your biology,\n\n1:06:14.760 --> 1:06:18.640\n you're one human, famous, impactful human,\n\n1:06:18.640 --> 1:06:22.620\n but just one human with a brain living the human condition.\n\n1:06:22.620 --> 1:06:27.580\n But you're ultimately mortal, just like all of us.\n\n1:06:27.580 --> 1:06:30.540\n Has studying the mind as a mechanism\n\n1:06:30.540 --> 1:06:33.440\n changed the way you think about your own mortality?\n\n1:06:38.620 --> 1:06:41.900\n It has, really, because particularly as you get older\n\n1:06:41.900 --> 1:06:44.920\n and the body comes apart in various ways,\n\n1:06:47.040 --> 1:06:52.040\n I became much more aware of the fact\n\n1:06:52.040 --> 1:06:57.040\n that what is somebody is contained in the brain\n\n1:06:59.000 --> 1:07:01.540\n and not in the body that you worry about burying.\n\n1:07:02.840 --> 1:07:07.840\n And it is to a certain extent true\n\n1:07:07.880 --> 1:07:10.520\n that for people who write things down,\n\n1:07:10.520 --> 1:07:15.520\n equations, dreams, notepads, diaries,\n\n1:07:15.520 --> 1:07:18.840\n fractions of their thought does continue to live\n\n1:07:18.840 --> 1:07:20.640\n after they're dead and gone,\n\n1:07:20.640 --> 1:07:22.440\n after their body is dead and gone.\n\n1:07:24.440 --> 1:07:29.440\n And there's a sea change in that going on in my lifetime\n\n1:07:29.440 --> 1:07:33.880\n between when my father died, except for the things\n\n1:07:33.880 --> 1:07:37.000\n which were actually written by him, as it were.\n\n1:07:37.000 --> 1:07:40.880\n Very few facts about him will have ever been recorded.\n\n1:07:40.880 --> 1:07:42.880\n And the number of facts which are recorded\n\n1:07:42.880 --> 1:07:46.880\n about each and every one of us, forever now,\n\n1:07:46.880 --> 1:07:51.080\n as far as I can see, in the digital world.\n\n1:07:51.080 --> 1:07:54.080\n And so the whole question of what is death\n\n1:07:58.080 --> 1:08:00.920\n may be different for people a generation ago\n\n1:08:00.920 --> 1:08:04.120\n and a generation further ahead.\n\n1:08:04.120 --> 1:08:07.760\n Maybe we have become immortal under some definitions.\n\n1:08:07.760 --> 1:08:09.320\n Yeah, yeah.\n\n1:08:09.320 --> 1:08:14.320\n Last easy question, what is the meaning of life?\n\n1:08:17.840 --> 1:08:22.840\n Looking back, you've studied the mind,\n\n1:08:23.320 --> 1:08:26.320\n us weird descendants of apes.\n\n1:08:27.640 --> 1:08:31.640\n What's the meaning of our existence on this little earth?\n\n1:08:31.640 --> 1:08:36.640\n What's the meaning of our existence on this little earth?\n\n1:08:39.160 --> 1:08:43.920\n Oh, that word meaning is as slippery as the word understand.\n\n1:08:46.000 --> 1:08:48.120\n Interconnected somehow, perhaps.\n\n1:08:51.720 --> 1:08:55.280\n Is there, it's slippery, but is there something\n\n1:08:55.280 --> 1:08:58.320\n that you, despite being slippery,\n\n1:08:58.320 --> 1:09:03.320\n can hold long enough to express?\n\n1:09:03.320 --> 1:09:05.640\n I've been amazed at how hard it is\n\n1:09:07.800 --> 1:09:12.240\n to define the things in a living system\n\n1:09:14.320 --> 1:09:17.400\n in the sense that one hydrogen atom\n\n1:09:17.400 --> 1:09:19.400\n is pretty much like another,\n\n1:09:19.400 --> 1:09:24.200\n but one bacterium is not so much like another bacterium,\n\n1:09:24.200 --> 1:09:26.120\n even of the same nominal species.\n\n1:09:26.120 --> 1:09:28.840\n In fact, the whole notion of what is the species\n\n1:09:28.840 --> 1:09:30.320\n gets a little bit fuzzy.\n\n1:09:31.200 --> 1:09:33.600\n And do species exist in the absence\n\n1:09:33.600 --> 1:09:36.120\n of certain classes of environments?\n\n1:09:36.120 --> 1:09:40.200\n And pretty soon one winds up with a biology\n\n1:09:40.200 --> 1:09:43.400\n which the whole thing is living,\n\n1:09:43.400 --> 1:09:45.960\n but whether there's actually any element of it\n\n1:09:47.480 --> 1:09:49.640\n which by itself would be said to be living\n\n1:09:52.000 --> 1:09:54.240\n becomes a little bit vague in my mind.\n\n1:09:54.240 --> 1:09:58.200\n So in a sense, the idea of meaning\n\n1:09:58.200 --> 1:10:01.200\n is something that's possessed by an individual,\n\n1:10:01.200 --> 1:10:03.080\n like a conscious creature.\n\n1:10:03.080 --> 1:10:07.400\n And you're saying that it's all interconnected\n\n1:10:07.400 --> 1:10:09.640\n in some kind of way that there might not even\n\n1:10:09.640 --> 1:10:10.640\n be an individual.\n\n1:10:10.640 --> 1:10:14.080\n We're all kind of this complicated mess\n\n1:10:14.080 --> 1:10:17.400\n of biological systems at all different levels\n\n1:10:17.400 --> 1:10:20.560\n where the human starts and when the human ends is unclear.\n\n1:10:20.560 --> 1:10:25.560\n Yeah, yeah, and we're in neurobiology where the,\n\n1:10:25.800 --> 1:10:27.880\n oh, you say the neocortex is the thinking,\n\n1:10:27.880 --> 1:10:31.240\n but there's lots of things that are done on the spinal cord.\n\n1:10:31.240 --> 1:10:35.680\n And so where's the essence of thought?\n\n1:10:35.680 --> 1:10:37.760\n Is it just gonna be neocortex?\n\n1:10:37.760 --> 1:10:39.360\n Can't be, can't be.\n\n1:10:40.560 --> 1:10:43.440\n Yeah, maybe to understand and to build thought\n\n1:10:43.440 --> 1:10:47.360\n you have to build the universe along with the neocortex.\n\n1:10:47.360 --> 1:10:51.400\n It's all interlinked through the spinal cord.\n\n1:10:51.400 --> 1:10:54.400\n John, it's a huge honor talking today.\n\n1:10:54.400 --> 1:10:55.840\n Thank you so much for your time.\n\n1:10:55.840 --> 1:10:57.160\n I really appreciate it.\n\n1:10:57.160 --> 1:10:59.120\n Well, thank you for the challenge of talking with you.\n\n1:10:59.120 --> 1:11:01.120\n And it'll be interesting to see whether you can win\n\n1:11:01.120 --> 1:11:04.600\n five minutes out of this with just coherence\n\n1:11:04.600 --> 1:11:06.840\n to anyone or not.\n\n1:11:06.840 --> 1:11:08.360\n Beautiful.\n\n1:11:08.360 --> 1:11:09.920\n Thanks for listening to this conversation\n\n1:11:09.920 --> 1:11:12.080\n with John Hopfield and thank you\n\n1:11:12.080 --> 1:11:14.400\n to our presenting sponsor, Cash App.\n\n1:11:14.400 --> 1:11:17.120\n Download it, use code LexPodcast.\n\n1:11:17.120 --> 1:11:20.080\n You'll get $10 and $10 will go to FIRST,\n\n1:11:20.080 --> 1:11:23.200\n an organization that inspires and educates young minds\n\n1:11:23.200 --> 1:11:26.360\n to become science and technology innovators of tomorrow.\n\n1:11:26.360 --> 1:11:29.120\n If you enjoy this podcast, subscribe on YouTube,\n\n1:11:29.120 --> 1:11:32.360\n get five stars on Apple Podcast, support on Patreon,\n\n1:11:32.360 --> 1:11:35.960\n or simply connect with me on Twitter at Lex Friedman.\n\n1:11:37.000 --> 1:11:39.440\n And now let me leave you with some words of wisdom\n\n1:11:39.440 --> 1:11:43.200\n from John Hopfield in his article titled, Now What?\n\n1:11:43.200 --> 1:11:46.280\n Choosing problems is the primary determinant\n\n1:11:46.280 --> 1:11:49.080\n of what one accomplishes in science.\n\n1:11:49.080 --> 1:11:52.080\n I have generally had a relatively short attention span\n\n1:11:52.080 --> 1:11:53.560\n in science problems.\n\n1:11:53.560 --> 1:11:56.000\n Thus, I have always been on the lookout\n\n1:11:56.000 --> 1:11:57.760\n for more interesting questions,\n\n1:11:57.760 --> 1:12:00.000\n either as my present ones get worked out\n\n1:12:00.000 --> 1:12:03.440\n or as they get classified by me as intractable,\n\n1:12:03.440 --> 1:12:05.240\n given my particular talents.\n\n1:12:06.280 --> 1:12:08.520\n He then goes on to say,\n\n1:12:08.520 --> 1:12:11.200\n what I have done in science relies entirely\n\n1:12:11.200 --> 1:12:15.080\n on experimental and theoretical studies by experts.\n\n1:12:15.080 --> 1:12:16.960\n I have a great respect for them,\n\n1:12:16.960 --> 1:12:19.360\n especially for those who are willing to attempt\n\n1:12:19.360 --> 1:12:23.080\n communication with someone who is not an expert in the field.\n\n1:12:24.040 --> 1:12:26.440\n I would only add that experts are good\n\n1:12:26.440 --> 1:12:28.360\n at answering questions.\n\n1:12:28.360 --> 1:12:32.000\n If you're brash enough, ask your own.\n\n1:12:32.000 --> 1:12:34.280\n Don't worry too much about how you found them.\n\n1:12:34.280 --> 1:12:40.560\n Thank you for listening and hope to see you next time.\n\n"
}
{
  "title": "David Chalmers: The Hard Problem of Consciousness | Lex Fridman Podcast #69",
  "id": "LW59lMvxmY4",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:02.920\n The following is a conversation with David Chalmers.\n\n00:02.920 --> 00:05.360\n He's a philosopher and cognitive scientist\n\n00:05.360 --> 00:08.080\n specializing in the areas of philosophy of mind,\n\n00:08.080 --> 00:11.040\n philosophy of language, and consciousness.\n\n00:11.040 --> 00:13.320\n He's perhaps best known for formulating\n\n00:13.320 --> 00:15.160\n the hard problem of consciousness,\n\n00:15.160 --> 00:17.720\n which could be stated as why does the feeling\n\n00:17.720 --> 00:20.160\n which accompanies awareness of sensory information\n\n00:20.160 --> 00:21.720\n exist at all?\n\n00:22.720 --> 00:25.520\n Consciousness is almost entirely a mystery.\n\n00:25.520 --> 00:28.640\n Many people who worry about AI safety and ethics\n\n00:28.640 --> 00:31.840\n believe that, in some form, consciousness can\n\n00:31.840 --> 00:35.480\n and should be engineered into AI systems of the future.\n\n00:35.480 --> 00:38.360\n So while there's much mystery, disagreement,\n\n00:38.360 --> 00:40.920\n discoveries yet to be made about consciousness,\n\n00:40.920 --> 00:44.360\n these conversations, while fundamentally philosophical\n\n00:44.360 --> 00:47.200\n in nature, may nevertheless be very important\n\n00:47.200 --> 00:50.300\n for engineers of modern AI systems to engage in.\n\n00:51.140 --> 00:53.900\n This is the Artificial Intelligence Podcast.\n\n00:53.900 --> 00:56.200\n If you enjoy it, subscribe on YouTube,\n\n00:56.200 --> 00:58.000\n give it five stars on Apple Podcast,\n\n00:58.000 --> 01:00.360\n support it on Patreon, or simply connect with me\n\n01:00.360 --> 01:04.520\n on Twitter at Lex Friedman, spelled F R I D M A N.\n\n01:05.480 --> 01:08.360\n As usual, I'll do one or two minutes of ads now\n\n01:08.360 --> 01:09.680\n and never any ads in the middle\n\n01:09.680 --> 01:11.920\n that can break the flow of the conversation.\n\n01:11.920 --> 01:13.240\n I hope that works for you\n\n01:13.240 --> 01:15.600\n and doesn't hurt the listening experience.\n\n01:15.600 --> 01:17.560\n This show is presented by Cash App,\n\n01:17.560 --> 01:19.840\n the number one finance app in the App Store.\n\n01:19.840 --> 01:23.280\n When you get it, use code LEXBODCAST.\n\n01:23.280 --> 01:25.480\n Cash App lets you send money to friends,\n\n01:25.480 --> 01:27.920\n buy Bitcoin, and invest in the stock market\n\n01:27.920 --> 01:29.880\n with as little as one dollar.\n\n01:29.880 --> 01:32.640\n Brokerage services are provided by Cash App Investing,\n\n01:32.640 --> 01:36.000\n subsidiary of Square, and member SIPC.\n\n01:36.000 --> 01:38.320\n Since Cash App does fractional share trading,\n\n01:38.320 --> 01:40.880\n let me mention that the order execution algorithm\n\n01:40.880 --> 01:43.600\n that works behind the scenes to create the abstraction\n\n01:43.600 --> 01:46.760\n of fractional orders is an algorithmic marvel.\n\n01:46.760 --> 01:49.200\n So big props to the Cash App engineers\n\n01:49.200 --> 01:51.640\n for solving a hard problem that, in the end,\n\n01:51.640 --> 01:54.240\n provides an easy interface that takes a step up\n\n01:54.240 --> 01:57.120\n to the next layer of abstraction over the stock market,\n\n01:57.120 --> 01:59.960\n making trading more accessible for new investors\n\n01:59.960 --> 02:02.800\n and diversification much easier.\n\n02:02.800 --> 02:05.160\n If you get Cash App from the App Store or Google Play\n\n02:05.160 --> 02:08.840\n and use the code LEXBODCAST, you'll get $10,\n\n02:08.840 --> 02:11.680\n and Cash App will also donate $10 to FIRST,\n\n02:11.680 --> 02:13.480\n one of my favorite organizations\n\n02:13.480 --> 02:16.680\n that is helping to advance robotics and STEM education\n\n02:16.680 --> 02:18.680\n for young people around the world.\n\n02:18.680 --> 02:22.200\n And now, here's my conversation with David Chalmers.\n\n02:23.160 --> 02:25.960\n Do you think we're living in a simulation?\n\n02:25.960 --> 02:27.440\n I don't rule it out.\n\n02:27.440 --> 02:29.720\n There's probably gonna be a lot of simulations\n\n02:29.720 --> 02:31.240\n in the history of the cosmos.\n\n02:32.200 --> 02:34.720\n If the simulation is designed well enough,\n\n02:34.720 --> 02:39.720\n it'll be indistinguishable from a non simulated reality.\n\n02:39.800 --> 02:43.200\n And although we could keep searching for evidence\n\n02:43.200 --> 02:46.000\n that we're not in a simulation,\n\n02:46.000 --> 02:48.600\n any of that evidence in principle could be simulated.\n\n02:48.600 --> 02:50.560\n So I think it's a possibility.\n\n02:50.560 --> 02:53.000\n But do you think the thought experiment is interesting\n\n02:53.000 --> 02:56.480\n or useful to calibrate how we think\n\n02:56.480 --> 02:58.720\n about the nature of reality?\n\n02:58.720 --> 03:01.000\n Yeah, I definitely think it's interesting and useful.\n\n03:01.000 --> 03:03.640\n In fact, I'm actually writing a book about this right now,\n\n03:03.640 --> 03:05.960\n all about the simulation idea,\n\n03:05.960 --> 03:07.160\n using it to shed light\n\n03:07.160 --> 03:10.320\n on a whole bunch of philosophical questions.\n\n03:10.320 --> 03:13.120\n So the big one is how do we know anything\n\n03:13.120 --> 03:15.520\n about the external world?\n\n03:15.520 --> 03:19.440\n Descartes said, maybe you're being fooled by an evil demon\n\n03:19.440 --> 03:21.840\n who's stimulating your brain into thinking,\n\n03:21.840 --> 03:25.840\n all this stuff is real when in fact, it's all made up.\n\n03:25.840 --> 03:28.080\n Well, the modern version of that is,\n\n03:28.080 --> 03:30.840\n how do you know you're not in a simulation?\n\n03:30.840 --> 03:33.680\n Then the thought is, if you're in a simulation,\n\n03:33.680 --> 03:34.560\n none of this is real.\n\n03:34.560 --> 03:37.560\n So that's teaching you something about knowledge.\n\n03:37.560 --> 03:39.440\n How do you know about the external world?\n\n03:39.440 --> 03:41.080\n I think there's also really interesting questions\n\n03:41.080 --> 03:43.840\n about the nature of reality right here.\n\n03:43.840 --> 03:46.840\n If we are in a simulation, is all this real?\n\n03:46.840 --> 03:48.120\n Is there really a table here?\n\n03:48.120 --> 03:49.240\n Is it really a microphone?\n\n03:49.240 --> 03:50.800\n Do I really have a body?\n\n03:50.800 --> 03:54.160\n The standard view would be, no, we don't.\n\n03:54.160 --> 03:55.560\n None of this would be real.\n\n03:55.560 --> 03:56.840\n My view is actually that's wrong.\n\n03:56.840 --> 03:59.360\n And even if we are in a simulation, all of this is real.\n\n03:59.360 --> 04:01.400\n That's why I called this reality 2.0.\n\n04:01.400 --> 04:04.120\n New version of reality, different version of reality,\n\n04:04.120 --> 04:05.400\n still reality.\n\n04:05.400 --> 04:08.440\n So what's the difference between quote unquote,\n\n04:08.440 --> 04:12.520\n real world and the world that we perceive?\n\n04:12.520 --> 04:17.160\n So we interact with the world by perceiving it.\n\n04:17.160 --> 04:22.160\n It only really exists through the window\n\n04:22.960 --> 04:25.840\n of our perception system and in our mind.\n\n04:25.840 --> 04:27.400\n So what's the difference between something\n\n04:27.400 --> 04:30.440\n that's quote unquote real, that exists perhaps\n\n04:30.440 --> 04:35.440\n without us being there, and the world as you perceive it?\n\n04:36.440 --> 04:39.160\n Well the world as we perceive it is a very simplified\n\n04:39.160 --> 04:42.800\n and distorted version of what's going on underneath.\n\n04:42.800 --> 04:45.240\n We already know that from just thinking about science.\n\n04:45.240 --> 04:48.800\n You don't see too many obviously quantum mechanical effects\n\n04:48.800 --> 04:51.680\n in what we perceive, but we still know quantum mechanics\n\n04:51.680 --> 04:53.720\n is going on under all things.\n\n04:53.720 --> 04:55.320\n So I like to think the world we perceive\n\n04:55.320 --> 05:00.320\n is this very kind of simplified picture of colors\n\n05:00.920 --> 05:04.640\n and shapes existing in space and so on.\n\n05:04.640 --> 05:07.080\n We know there's a, that's what the philosopher\n\n05:07.080 --> 05:09.760\n Wilfred Sellers called the manifest image.\n\n05:09.760 --> 05:11.560\n The world as it seems to us, we already know\n\n05:11.560 --> 05:14.720\n underneath all that is a very different scientific image\n\n05:14.720 --> 05:19.520\n with atoms or quantum wave functions or super strings\n\n05:19.520 --> 05:22.360\n or whatever the latest thing is.\n\n05:22.360 --> 05:24.880\n And that's the ultimate scientific reality.\n\n05:24.880 --> 05:28.400\n So I think of the simulation idea as basically\n\n05:28.400 --> 05:31.080\n another hypothesis about what the ultimate\n\n05:31.080 --> 05:34.480\n say quasi scientific or metaphysical reality\n\n05:34.480 --> 05:37.680\n is going on underneath the world of the manifest image.\n\n05:37.680 --> 05:41.280\n The world of the manifest image is this very simple thing\n\n05:41.280 --> 05:43.240\n that we interact with that's neutral\n\n05:43.240 --> 05:46.480\n on the underlying stuff of reality.\n\n05:46.480 --> 05:48.880\n Science can help tell us about that.\n\n05:48.880 --> 05:51.400\n Maybe philosophy can help tell us about that too.\n\n05:51.400 --> 05:53.400\n And if we eventually take the red pill\n\n05:53.400 --> 05:54.880\n and find out we're in a simulation,\n\n05:54.880 --> 05:56.760\n my view is that's just another view\n\n05:56.760 --> 05:58.760\n about what reality is made of.\n\n05:58.760 --> 06:00.960\n The philosopher Immanuel Kant said,\n\n06:00.960 --> 06:02.760\n what is the nature of the thing in itself?\n\n06:02.760 --> 06:05.400\n I've got a glass here and it's got all these,\n\n06:05.400 --> 06:07.960\n it appears to me a certain way, a certain shape,\n\n06:07.960 --> 06:10.200\n it's liquid, it's clear.\n\n06:10.200 --> 06:13.080\n And he said, what is the nature of the thing\n\n06:13.080 --> 06:14.160\n in itself?\n\n06:14.160 --> 06:15.480\n Well, I think of the simulation idea,\n\n06:15.480 --> 06:18.640\n it's a hypothesis about the nature of the thing in itself.\n\n06:18.640 --> 06:20.560\n It turns out if we're in a simulation,\n\n06:20.560 --> 06:22.640\n the thing in itself nature of this glass,\n\n06:22.640 --> 06:25.000\n it's okay, it's actually a bunch of data structures\n\n06:25.000 --> 06:28.360\n running on a computer in the next universe up.\n\n06:28.360 --> 06:30.320\n Yeah, that's what people tend to do\n\n06:30.320 --> 06:31.560\n when they think about simulation.\n\n06:31.560 --> 06:34.520\n They think about our modern computers\n\n06:34.520 --> 06:39.520\n and somehow trivially crudely just scaled up in some sense.\n\n06:39.520 --> 06:44.440\n But do you think the simulation,\n\n06:44.440 --> 06:47.520\n I mean, in order to actually simulate\n\n06:47.520 --> 06:50.400\n something as complicated as our universe\n\n06:50.400 --> 06:53.040\n that's made up of molecules and atoms\n\n06:53.040 --> 06:57.200\n and particles and quarks and maybe even strings,\n\n06:57.200 --> 06:59.160\n all of that would require something\n\n06:59.160 --> 07:03.280\n just infinitely many orders of magnitude more\n\n07:03.280 --> 07:06.160\n of scale and complexity.\n\n07:06.160 --> 07:11.160\n Do you think we're even able to even like conceptualize\n\n07:12.280 --> 07:16.000\n what it would take to simulate our universe?\n\n07:16.000 --> 07:18.680\n Or does it just slip into this idea\n\n07:18.680 --> 07:21.600\n that you basically have to build a universe,\n\n07:21.600 --> 07:24.360\n something so big to simulate it?\n\n07:24.360 --> 07:26.960\n Does it get this into this fuzzy area\n\n07:26.960 --> 07:28.840\n that's not useful at all?\n\n07:28.840 --> 07:30.720\n Yeah, well, I mean, our universe\n\n07:30.720 --> 07:33.280\n is obviously incredibly complicated.\n\n07:33.280 --> 07:37.640\n And for us within our universe to build a simulation\n\n07:37.640 --> 07:40.680\n of a universe as complicated as ours\n\n07:40.680 --> 07:42.360\n is gonna have obvious problems here.\n\n07:42.360 --> 07:44.000\n If the universe is finite,\n\n07:44.000 --> 07:45.720\n there's just no way that's gonna work.\n\n07:45.720 --> 07:48.040\n Maybe there's some cute way to make it work\n\n07:48.040 --> 07:51.160\n if the universe is infinite,\n\n07:51.160 --> 07:53.600\n maybe an infinite universe could somehow simulate\n\n07:53.600 --> 07:57.120\n a copy of itself, but that's gonna be hard.\n\n07:57.120 --> 07:59.760\n Nonetheless, just that we are in a simulation,\n\n07:59.760 --> 08:01.080\n I think there's no particular reason\n\n08:01.080 --> 08:04.000\n why we have to think the simulating universe\n\n08:04.000 --> 08:06.160\n has to be anything like ours.\n\n08:06.160 --> 08:09.000\n You've said before that it might be,\n\n08:09.960 --> 08:12.640\n so you could think of it in turtles all the way down.\n\n08:12.640 --> 08:15.800\n You could think of the simulating universe\n\n08:15.800 --> 08:17.720\n different than ours, but we ourselves\n\n08:17.720 --> 08:20.240\n could also create another simulating universe.\n\n08:20.240 --> 08:21.640\n So you said that there could be these\n\n08:21.640 --> 08:24.160\n kind of levels of universes.\n\n08:24.160 --> 08:27.080\n And you've also mentioned this hilarious idea,\n\n08:27.080 --> 08:29.080\n maybe tongue in cheek, maybe not,\n\n08:29.080 --> 08:31.800\n that there may be simulations within simulations,\n\n08:31.800 --> 08:33.840\n arbitrarily stacked levels,\n\n08:33.840 --> 08:37.760\n and that there may be, that we may be in level 42.\n\n08:37.760 --> 08:38.600\n Oh yeah.\n\n08:38.600 --> 08:40.640\n Along those stacks, referencing Hitchhiker's Guide\n\n08:40.640 --> 08:41.800\n to the Universe.\n\n08:41.800 --> 08:45.840\n If we're indeed in a simulation within a simulation\n\n08:45.840 --> 08:50.840\n at level 42, what do you think level zero looks like?\n\n08:51.520 --> 08:52.360\n The originating universe.\n\n08:52.360 --> 08:55.160\n I would expect that level zero is truly enormous.\n\n08:55.160 --> 08:57.680\n I mean, not just, if it's finite,\n\n08:57.680 --> 09:01.800\n at some extraordinarily large finite capacity,\n\n09:01.800 --> 09:03.160\n much more likely it's infinite.\n\n09:03.160 --> 09:06.800\n Maybe it's got some very high cardinality\n\n09:06.800 --> 09:11.360\n that enables it to support just any number of simulations.\n\n09:11.360 --> 09:14.360\n So high degree of infinity at level zero,\n\n09:14.360 --> 09:18.880\n slightly smaller degree of infinity at level one.\n\n09:18.880 --> 09:21.480\n So by the time you get down to us at level 42,\n\n09:21.480 --> 09:25.080\n maybe there's plenty of room for lots of simulations\n\n09:25.080 --> 09:27.800\n of finite capacity.\n\n09:29.280 --> 09:34.280\n If the top universe is only a small finite capacity,\n\n09:34.360 --> 09:36.960\n then obviously that's gonna put very, very serious limits\n\n09:36.960 --> 09:40.280\n on how many simulations you're gonna be able to get running.\n\n09:40.280 --> 09:42.720\n So I think we can certainly confidently say\n\n09:42.720 --> 09:44.320\n that if we're at level 42,\n\n09:44.320 --> 09:47.120\n then the top level's pretty damn big.\n\n09:47.120 --> 09:49.120\n So it gets more and more constrained\n\n09:49.120 --> 09:52.200\n as we get down levels, more and more simplified\n\n09:52.200 --> 09:54.600\n and constrained and limited in resources.\n\n09:54.600 --> 09:56.560\n Yeah, we still have plenty of capacity here.\n\n09:56.560 --> 09:58.320\n What was it Feynman said?\n\n09:58.320 --> 10:01.040\n He said there's plenty of room at the bottom.\n\n10:01.040 --> 10:04.600\n We're still a number of levels above the degree\n\n10:04.600 --> 10:06.960\n where there's room for fundamental computing,\n\n10:06.960 --> 10:08.400\n physical computing capacity,\n\n10:08.400 --> 10:11.080\n quantum computing capacity at the bottom level.\n\n10:11.080 --> 10:13.440\n So we've got plenty of room to play with\n\n10:13.440 --> 10:15.520\n and we probably have plenty of room\n\n10:15.520 --> 10:19.120\n for simulations of pretty sophisticated universes,\n\n10:19.120 --> 10:22.800\n perhaps none as complicated as our universe,\n\n10:22.800 --> 10:25.280\n unless our universe is infinite,\n\n10:25.280 --> 10:27.280\n but still at the very least\n\n10:27.280 --> 10:29.160\n for pretty serious finite universes,\n\n10:29.160 --> 10:31.800\n but maybe universes somewhat simpler than ours,\n\n10:31.800 --> 10:35.200\n unless of course we're prepared to take certain shortcuts\n\n10:35.200 --> 10:36.080\n in the simulation,\n\n10:36.080 --> 10:38.720\n which might then increase the capacity significantly.\n\n10:38.720 --> 10:42.240\n Do you think the human mind, us people,\n\n10:42.240 --> 10:44.700\n in terms of the complexity of simulation\n\n10:44.700 --> 10:47.240\n is at the height of what the simulation\n\n10:47.240 --> 10:48.620\n might be able to achieve?\n\n10:48.620 --> 10:51.280\n Like if you look at incredible entities\n\n10:51.280 --> 10:54.920\n that could be created in this universe of ours,\n\n10:54.920 --> 10:56.840\n do you have an intuition about\n\n10:56.840 --> 11:00.600\n how incredible human beings are on that scale?\n\n11:00.600 --> 11:02.400\n I think we're pretty impressive,\n\n11:02.400 --> 11:03.920\n but we're not that impressive.\n\n11:03.920 --> 11:06.040\n Are we above average?\n\n11:06.040 --> 11:09.020\n I mean, I think human beings are at a certain point\n\n11:09.020 --> 11:11.400\n in the scale of intelligence,\n\n11:11.400 --> 11:14.280\n which made many things possible.\n\n11:14.280 --> 11:19.280\n You get through evolution, through single cell organisms,\n\n11:19.280 --> 11:22.720\n through fish and mammals and primates,\n\n11:22.720 --> 11:24.160\n and something happens.\n\n11:24.160 --> 11:25.800\n Once you get to human beings,\n\n11:25.800 --> 11:27.600\n we've just reached that level\n\n11:27.600 --> 11:29.460\n where we get to develop language,\n\n11:29.460 --> 11:31.600\n we get to develop certain kinds of culture,\n\n11:31.600 --> 11:34.920\n and we get to develop certain kinds of collective thinking\n\n11:34.920 --> 11:38.380\n that has enabled all this amazing stuff to happen,\n\n11:38.380 --> 11:40.800\n science and literature and engineering\n\n11:40.800 --> 11:43.680\n and culture and so on.\n\n11:43.680 --> 11:46.160\n So we had just at the beginning of that\n\n11:46.160 --> 11:47.640\n on the evolutionary threshold,\n\n11:47.640 --> 11:49.720\n it's kind of like we just got there,\n\n11:49.720 --> 11:54.440\n who knows, a few thousand or tens of thousands of years ago.\n\n11:54.440 --> 11:56.460\n So we're probably just at the very beginning\n\n11:56.460 --> 11:57.720\n for what's possible there.\n\n11:57.720 --> 12:01.080\n So I'm inclined to think among the scale\n\n12:01.080 --> 12:02.400\n of intelligent beings,\n\n12:02.400 --> 12:05.140\n we're somewhere very near the bottom.\n\n12:05.140 --> 12:06.320\n I would expect that, for example,\n\n12:06.320 --> 12:08.800\n if we're in a simulation,\n\n12:08.800 --> 12:10.960\n then the simulators who created us\n\n12:10.960 --> 12:14.000\n have got the capacity to be far more sophisticated.\n\n12:14.000 --> 12:15.400\n If we're at level 42,\n\n12:15.400 --> 12:17.760\n who knows what the ones at level zero are like.\n\n12:19.120 --> 12:22.760\n It's also possible that this is the epitome\n\n12:22.760 --> 12:24.540\n of what is possible to achieve.\n\n12:24.540 --> 12:27.320\n So we as human beings see ourselves maybe as flawed,\n\n12:27.320 --> 12:29.720\n see all the constraints, all the limitations,\n\n12:29.720 --> 12:32.400\n but maybe that's the magical, the beautiful thing.\n\n12:32.400 --> 12:36.020\n Maybe those limitations are the essential elements\n\n12:36.020 --> 12:39.020\n for an interesting sort of that edge of chaos,\n\n12:39.020 --> 12:41.040\n that interesting existence,\n\n12:41.040 --> 12:43.380\n that if you make us much more intelligent,\n\n12:43.380 --> 12:46.980\n if you make us much more powerful\n\n12:46.980 --> 12:50.360\n in any kind of dimension of performance,\n\n12:50.360 --> 12:52.540\n maybe you lose something fundamental\n\n12:52.540 --> 12:55.120\n that makes life worth living.\n\n12:55.120 --> 12:57.940\n So you kind of have this optimistic view\n\n12:57.940 --> 13:00.140\n that we're this little baby,\n\n13:00.140 --> 13:03.020\n that then there's so much growth and potential,\n\n13:03.020 --> 13:05.820\n but this could also be it.\n\n13:05.820 --> 13:09.620\n This is the most amazing thing is us.\n\n13:09.620 --> 13:11.260\n Maybe what you're saying is consistent\n\n13:11.260 --> 13:12.100\n with what I'm saying.\n\n13:12.100 --> 13:14.420\n I mean, we could still have levels of intelligence\n\n13:14.420 --> 13:15.700\n far beyond us,\n\n13:15.700 --> 13:17.740\n but maybe those levels of intelligence on your view\n\n13:17.740 --> 13:19.020\n would be kind of boring.\n\n13:19.020 --> 13:21.440\n And we kind of get so good at everything\n\n13:21.440 --> 13:24.240\n that life suddenly becomes uni dimensional.\n\n13:24.240 --> 13:26.900\n So we're just inhabiting this one spot\n\n13:26.900 --> 13:30.740\n of like maximal romanticism in the history of evolution.\n\n13:30.740 --> 13:32.180\n You get to humans and it's like, yeah,\n\n13:32.180 --> 13:34.980\n and then years to come, our super intelligent descendants\n\n13:34.980 --> 13:37.580\n are gonna look back at us and say,\n\n13:37.580 --> 13:39.740\n those were the days when they just hit\n\n13:39.740 --> 13:42.580\n the point of inflection and life was interesting.\n\n13:42.580 --> 13:43.420\n I am an optimist.\n\n13:43.420 --> 13:47.100\n So I'd like to think that if there is super intelligent\n\n13:47.100 --> 13:49.420\n somewhere in the future,\n\n13:49.420 --> 13:51.860\n they'll figure out how to make life super interesting\n\n13:51.860 --> 13:52.940\n and super romantic.\n\n13:52.940 --> 13:54.600\n Well, you know what they're gonna do.\n\n13:54.600 --> 13:56.460\n So what they're gonna do is they realize\n\n13:56.460 --> 13:58.740\n how boring life is when you're super intelligent.\n\n13:58.740 --> 14:02.580\n So they create a new level of assimilation\n\n14:02.580 --> 14:05.740\n and sort of live through the things they've created\n\n14:05.740 --> 14:09.220\n by watching them stumble about\n\n14:09.220 --> 14:10.500\n in their flawed ways.\n\n14:10.500 --> 14:13.780\n So maybe that's, so you create a new level of assimilation\n\n14:13.780 --> 14:17.860\n every time you get really bored with how smart and.\n\n14:17.860 --> 14:19.060\n This would be kind of sad though,\n\n14:19.060 --> 14:20.780\n because if we showed the peak of their existence\n\n14:20.780 --> 14:23.420\n would be like watching simulations for entertainment.\n\n14:23.420 --> 14:26.540\n Not like saying the peak of our existence now is Netflix.\n\n14:26.540 --> 14:27.660\n No, it's all right.\n\n14:27.660 --> 14:31.180\n A flip side of that could be the peak of our existence\n\n14:31.180 --> 14:34.260\n for many people having children and watching them grow.\n\n14:34.260 --> 14:35.780\n That becomes very meaningful.\n\n14:35.780 --> 14:38.580\n Okay, you create a simulation that's like creating a family.\n\n14:38.580 --> 14:40.860\n Creating like, well, any kind of creation\n\n14:40.860 --> 14:43.780\n is kind of a powerful act.\n\n14:43.780 --> 14:46.220\n Do you think it's easier to simulate the mind\n\n14:46.220 --> 14:47.760\n or the universe?\n\n14:47.760 --> 14:51.960\n So I've heard several people, including Nick Bostrom,\n\n14:51.960 --> 14:54.620\n think about ideas of maybe you don't need\n\n14:54.620 --> 14:55.600\n to simulate the universe,\n\n14:55.600 --> 14:57.440\n you can just simulate the human mind.\n\n14:57.440 --> 15:00.380\n Or in general, just the distinction\n\n15:00.380 --> 15:02.600\n between simulating the entirety of it,\n\n15:02.600 --> 15:04.600\n the entirety of the physical world,\n\n15:04.600 --> 15:06.080\n or just simulating the mind.\n\n15:06.080 --> 15:09.740\n Which one do you see as more challenging?\n\n15:09.740 --> 15:12.380\n Well, I think in some sense, the answer is obvious.\n\n15:12.380 --> 15:15.060\n It has to be simpler to simulate the mind\n\n15:15.060 --> 15:16.500\n than to simulate the universe,\n\n15:16.500 --> 15:18.500\n because the mind is part of the universe.\n\n15:18.500 --> 15:20.540\n And in order to fully simulate the universe,\n\n15:20.540 --> 15:22.620\n you're gonna have to simulate the mind.\n\n15:22.620 --> 15:25.320\n So unless we're talking about partial simulations.\n\n15:25.320 --> 15:27.580\n And I guess the question is which comes first?\n\n15:27.580 --> 15:29.800\n Does the mind come before the universe\n\n15:29.800 --> 15:32.560\n or does the universe come before the mind?\n\n15:32.560 --> 15:36.620\n So the mind could just be an emergent phenomena\n\n15:36.620 --> 15:37.960\n in this universe.\n\n15:37.960 --> 15:42.020\n So simulation is an interesting thing\n\n15:42.020 --> 15:47.020\n that it's not like creating a simulation perhaps\n\n15:47.380 --> 15:50.380\n requires you to program every single thing\n\n15:50.380 --> 15:51.780\n that happens in it.\n\n15:51.780 --> 15:54.220\n It's just defining a set of initial conditions\n\n15:54.220 --> 15:57.820\n and rules based on which it behaves.\n\n15:59.600 --> 16:01.940\n Simulating the mind requires you\n\n16:01.940 --> 16:03.840\n to have a little bit more,\n\n16:05.160 --> 16:07.300\n we're now in a little bit of a crazy land,\n\n16:07.300 --> 16:10.260\n but it requires you to understand\n\n16:10.260 --> 16:11.840\n the fundamentals of cognition,\n\n16:11.840 --> 16:13.660\n perhaps of consciousness,\n\n16:13.660 --> 16:16.640\n of perception of everything like that,\n\n16:16.640 --> 16:21.640\n that's not created through some kind of emergence\n\n16:23.340 --> 16:25.880\n from basic physics laws,\n\n16:25.880 --> 16:27.940\n but more requires you to actually understand\n\n16:27.940 --> 16:29.820\n the fundamentals of the mind.\n\n16:29.820 --> 16:31.660\n How about if we said to simulate the brain?\n\n16:31.660 --> 16:32.500\n The brain.\n\n16:32.500 --> 16:33.940\n Rather than the mind.\n\n16:33.940 --> 16:36.060\n So the brain is just a big physical system.\n\n16:36.060 --> 16:38.620\n The universe is a giant physical system.\n\n16:38.620 --> 16:40.100\n To simulate the universe at the very least,\n\n16:40.100 --> 16:42.640\n you're gonna have to simulate the brains\n\n16:42.640 --> 16:46.140\n as well as all the other physical systems within it.\n\n16:46.140 --> 16:50.920\n And it's not obvious that the problems are any worse\n\n16:50.920 --> 16:53.580\n for the brain than for,\n\n16:53.580 --> 16:56.040\n it's a particularly complex physical system.\n\n16:56.040 --> 16:58.600\n But if we can simulate arbitrary physical systems,\n\n16:58.600 --> 16:59.880\n we can simulate brains.\n\n16:59.880 --> 17:02.100\n There is this further question of whether,\n\n17:02.100 --> 17:03.980\n when you simulate a brain,\n\n17:03.980 --> 17:07.340\n will that bring along all the features of the mind with it?\n\n17:07.340 --> 17:08.880\n Like will you get consciousness?\n\n17:08.880 --> 17:09.980\n Will you get thinking?\n\n17:09.980 --> 17:11.600\n Will you get free will?\n\n17:11.600 --> 17:12.540\n And so on.\n\n17:12.540 --> 17:16.200\n And that's something philosophers have argued over\n\n17:16.200 --> 17:17.060\n for years.\n\n17:17.060 --> 17:20.060\n My own view is if you simulate the brain well enough,\n\n17:20.060 --> 17:22.620\n that will also simulate the mind.\n\n17:22.620 --> 17:24.860\n But yeah, there's plenty of people who would say no.\n\n17:24.860 --> 17:27.140\n You'd merely get like a zombie system,\n\n17:27.140 --> 17:31.300\n a simulation of a brain without any true consciousness.\n\n17:31.300 --> 17:33.420\n But for you, you put together a brain,\n\n17:33.420 --> 17:36.320\n the consciousness comes with it, arise.\n\n17:36.320 --> 17:38.640\n Yeah, I don't think it's obvious.\n\n17:38.640 --> 17:39.660\n That's your intuition.\n\n17:39.660 --> 17:41.320\n My view is roughly that yeah,\n\n17:41.320 --> 17:43.100\n what is responsible for consciousness,\n\n17:43.100 --> 17:46.960\n it's in the patterns of information processing and so on\n\n17:46.960 --> 17:50.460\n rather than say the biology that it's made of.\n\n17:50.460 --> 17:51.780\n There's certainly plenty of people out there\n\n17:51.780 --> 17:54.520\n who think consciousness has to be say biological.\n\n17:54.520 --> 17:57.300\n So if you merely replicate the patterns of information\n\n17:57.300 --> 17:59.680\n processing in a nonbiological substrate,\n\n17:59.680 --> 18:02.440\n you'll miss what's crucial for consciousness.\n\n18:02.440 --> 18:04.320\n I mean, I just don't think there's any particular reason\n\n18:04.320 --> 18:07.380\n to think that biology is special here.\n\n18:07.380 --> 18:09.620\n You can imagine substituting the biology\n\n18:09.620 --> 18:13.700\n for nonbiological systems, say silicon circuits\n\n18:13.700 --> 18:15.120\n that play the same role.\n\n18:15.120 --> 18:17.620\n The behavior will continue to be the same.\n\n18:17.620 --> 18:21.300\n And I think just thinking about what is the true,\n\n18:21.300 --> 18:22.300\n when I think about the connection,\n\n18:22.300 --> 18:25.540\n the isomorphisms between consciousness and the brain,\n\n18:25.540 --> 18:28.300\n the deepest connections to me seem to connect consciousness\n\n18:28.300 --> 18:30.300\n to patterns of information processing,\n\n18:30.300 --> 18:32.380\n not to specific biology.\n\n18:32.380 --> 18:35.180\n So I at least adopted as my working hypothesis\n\n18:35.180 --> 18:38.180\n that basically it's the computation and the information\n\n18:38.180 --> 18:39.580\n that matters for consciousness.\n\n18:39.580 --> 18:41.820\n Same time, we don't understand consciousness,\n\n18:41.820 --> 18:43.700\n so all this could be wrong.\n\n18:43.700 --> 18:48.180\n So the computation, the flow, the processing,\n\n18:48.180 --> 18:49.840\n manipulation of information,\n\n18:49.840 --> 18:54.440\n the process is where the consciousness,\n\n18:54.440 --> 18:56.480\n the software is where the consciousness comes from,\n\n18:56.480 --> 18:57.860\n not the hardware.\n\n18:57.860 --> 18:59.200\n Roughly the software, yeah.\n\n18:59.200 --> 19:01.800\n The patterns of information processing at least\n\n19:01.800 --> 19:05.720\n in the hardware, which we could view as software.\n\n19:05.720 --> 19:07.360\n It may not be something you can just like program\n\n19:07.360 --> 19:11.360\n and load and erase and so on in the way we can\n\n19:11.360 --> 19:14.000\n with ordinary software, but it's something at the level\n\n19:14.000 --> 19:16.240\n of information processing rather than at the level\n\n19:16.240 --> 19:17.960\n of implementation.\n\n19:17.960 --> 19:22.480\n So on that, what do you think of the experience of self,\n\n19:22.480 --> 19:26.040\n just the experience of the world in a virtual world,\n\n19:26.040 --> 19:27.920\n in virtual reality?\n\n19:27.920 --> 19:31.400\n Is it possible that we can create sort of\n\n19:33.480 --> 19:36.760\n offsprings of our consciousness by existing\n\n19:36.760 --> 19:38.840\n in a virtual world long enough?\n\n19:38.840 --> 19:43.840\n So yeah, can we be conscious in the same kind\n\n19:44.520 --> 19:47.640\n of deep way that we are in this real world\n\n19:47.640 --> 19:51.120\n by hanging out in a virtual world?\n\n19:51.120 --> 19:54.160\n Yeah, well, the kind of virtual worlds we have now\n\n19:54.160 --> 19:58.040\n are interesting but limited in certain ways.\n\n19:58.040 --> 20:01.680\n In particular, they rely on us having a brain and so on,\n\n20:01.680 --> 20:03.560\n which is outside the virtual world.\n\n20:03.560 --> 20:07.520\n Maybe I'll strap on my VR headset or just hang out\n\n20:07.520 --> 20:12.520\n in a virtual world on a screen, but my brain\n\n20:12.920 --> 20:16.560\n and then my physical environment might be simulated\n\n20:16.560 --> 20:18.560\n if I'm in a virtual world, but right now,\n\n20:18.560 --> 20:21.320\n there's no attempt to simulate my brain.\n\n20:21.320 --> 20:24.120\n There might be some non player characters\n\n20:24.120 --> 20:27.440\n in these virtual worlds that have simulated\n\n20:27.440 --> 20:29.040\n cognitive systems of certain kinds\n\n20:29.040 --> 20:31.280\n that dictate their behavior, but mostly,\n\n20:31.280 --> 20:33.080\n they're pretty simple right now.\n\n20:33.080 --> 20:34.640\n I mean, some people are trying to combine,\n\n20:34.640 --> 20:36.900\n put a bit of AI in their non player characters\n\n20:36.900 --> 20:41.340\n to make them smarter, but for now,\n\n20:41.340 --> 20:43.720\n inside virtual world, the actual thinking\n\n20:43.720 --> 20:46.000\n is interestingly distinct from the physics\n\n20:46.000 --> 20:47.180\n of those virtual worlds.\n\n20:47.180 --> 20:48.920\n In a way, actually, I like to think this is kind of\n\n20:48.920 --> 20:50.480\n reminiscent of the way that Descartes\n\n20:50.480 --> 20:52.280\n thought our physical world was.\n\n20:52.280 --> 20:54.400\n There's physics, and there's the mind,\n\n20:54.400 --> 20:55.240\n and they're separate.\n\n20:55.240 --> 20:58.800\n Now we think the mind is somehow connected\n\n20:58.800 --> 21:01.100\n to physics pretty deeply, but in these virtual worlds,\n\n21:01.100 --> 21:03.000\n there's a physics of a virtual world,\n\n21:03.000 --> 21:04.840\n and then there's this brain which is totally\n\n21:04.840 --> 21:06.880\n outside the virtual world that controls it\n\n21:06.880 --> 21:10.520\n and interacts it when anyone exercises agency\n\n21:10.520 --> 21:12.360\n in a video game, that's actually somebody\n\n21:12.360 --> 21:14.920\n outside the virtual world moving a controller,\n\n21:14.920 --> 21:16.680\n controlling the interaction of things\n\n21:16.680 --> 21:18.240\n inside the virtual world.\n\n21:18.240 --> 21:20.460\n So right now, in virtual worlds,\n\n21:20.460 --> 21:22.360\n the mind is somehow outside the world,\n\n21:22.360 --> 21:25.040\n but you could imagine in the future,\n\n21:25.040 --> 21:29.080\n once we have developed serious AI,\n\n21:29.080 --> 21:31.560\n artificial general intelligence, and so on,\n\n21:31.560 --> 21:34.440\n then we could come to virtual worlds\n\n21:34.440 --> 21:35.720\n which have enough sophistication,\n\n21:35.720 --> 21:38.040\n you could actually simulate a brain\n\n21:38.040 --> 21:42.920\n or have a genuine AGI, which would then presumably\n\n21:42.920 --> 21:45.880\n be able to act in equally sophisticated ways,\n\n21:45.880 --> 21:47.880\n maybe even more sophisticated ways,\n\n21:47.880 --> 21:50.520\n inside the virtual world to how it might\n\n21:50.520 --> 21:52.400\n in the physical world, and then the question's\n\n21:52.400 --> 21:56.040\n gonna come along, that would be kind of a VR,\n\n21:56.040 --> 21:59.520\n virtual world internal intelligence,\n\n21:59.520 --> 22:01.720\n and then the question is could they have consciousness,\n\n22:01.720 --> 22:04.720\n experience, intelligence, free will,\n\n22:04.720 --> 22:06.520\n all the things that we have, and again,\n\n22:06.520 --> 22:08.840\n my view is I don't see why not.\n\n22:08.840 --> 22:13.160\n To linger on it a little bit, I find virtual reality really\n\n22:13.160 --> 22:15.880\n incredibly powerful, just even the crude virtual reality\n\n22:15.880 --> 22:20.880\n we have now of perhaps there's psychological effects\n\n22:21.800 --> 22:23.960\n that make some people more amenable\n\n22:23.960 --> 22:26.260\n to virtual worlds than others, but I find myself\n\n22:26.260 --> 22:28.360\n wanting to stay in virtual worlds for the most part.\n\n22:28.360 --> 22:29.200\n You do?\n\n22:29.200 --> 22:30.020\n Yes.\n\n22:30.020 --> 22:32.080\n With a headset or on a desktop?\n\n22:32.080 --> 22:33.020\n No, with a headset.\n\n22:33.020 --> 22:35.640\n Really interesting, because I am totally addicted\n\n22:35.640 --> 22:40.640\n to using the internet and things on a desktop,\n\n22:40.680 --> 22:43.040\n but when it comes to VR, with a headset,\n\n22:43.040 --> 22:46.140\n I don't typically use it for more than 10 or 20 minutes.\n\n22:46.140 --> 22:48.760\n There's something just slightly aversive about it, I find,\n\n22:48.760 --> 22:52.120\n so I don't, right now, even though I have Oculus Rift\n\n22:52.120 --> 22:55.800\n and Oculus Quest and HTC Vive and Samsung, this and that.\n\n22:55.800 --> 22:57.360\n You just don't wanna stay in that world for long.\n\n22:57.360 --> 22:58.760\n Not for extended periods.\n\n22:58.760 --> 23:01.000\n You actually find yourself hanging out in that.\n\n23:01.000 --> 23:03.660\n Something about, it's both a combination\n\n23:03.660 --> 23:08.000\n of just imagination and considering the possibilities\n\n23:08.000 --> 23:10.640\n of where this goes in the future.\n\n23:10.640 --> 23:15.640\n It feels like I want to almost prepare my brain for it.\n\n23:17.000 --> 23:19.680\n I wanna explore sort of Disneyland\n\n23:19.680 --> 23:23.700\n when it's first being built in the early days,\n\n23:23.700 --> 23:27.400\n and it feels like I'm walking around\n\n23:27.400 --> 23:31.420\n almost imagining the possibilities,\n\n23:31.420 --> 23:33.840\n and something through that process allows my mind\n\n23:33.840 --> 23:36.020\n to really enter into that world,\n\n23:36.020 --> 23:41.020\n but you say that the brain is external to that virtual world.\n\n23:41.940 --> 23:46.600\n It is, strictly speaking, true, but...\n\n23:46.600 --> 23:50.600\n If you're in VR and you do brain surgery on an avatar,\n\n23:50.600 --> 23:51.800\n and you're gonna open up that skull,\n\n23:51.800 --> 23:53.000\n what are you gonna find?\n\n23:53.000 --> 23:53.840\n Sorry, nothing there.\n\n23:53.840 --> 23:54.680\n Nothing.\n\n23:54.680 --> 23:55.880\n The brain is elsewhere.\n\n23:55.880 --> 23:59.520\n You don't think it's possible to kind of separate them,\n\n23:59.520 --> 24:02.040\n and I don't mean in a sense like Descartes,\n\n24:02.960 --> 24:06.720\n like a hard separation, but basically,\n\n24:06.720 --> 24:09.600\n do you think it's possible with the brain outside\n\n24:09.600 --> 24:13.240\n of the virtual rhythm, when you're wearing a headset,\n\n24:14.920 --> 24:19.840\n create a new consciousness for prolonged periods of time?\n\n24:19.840 --> 24:24.660\n Really feel, like really, like forget\n\n24:24.660 --> 24:26.280\n that your brain is outside.\n\n24:26.280 --> 24:27.800\n So this is, okay, this is gonna be the case\n\n24:27.800 --> 24:29.200\n where the brain is still outside.\n\n24:29.200 --> 24:30.040\n It's still outside.\n\n24:30.040 --> 24:32.120\n But could living in the VR, I mean,\n\n24:32.120 --> 24:35.120\n we already find this, right, with video games.\n\n24:35.120 --> 24:35.960\n Exactly.\n\n24:35.960 --> 24:39.200\n They're completely immersive, and you get taken up\n\n24:39.200 --> 24:40.640\n by living in those worlds,\n\n24:40.640 --> 24:43.200\n and it becomes your reality for a while.\n\n24:43.200 --> 24:44.760\n So they're not completely immersive,\n\n24:44.760 --> 24:46.040\n they're just very immersive.\n\n24:46.040 --> 24:46.880\n Completely immersive.\n\n24:46.880 --> 24:48.800\n You don't forget the external world, no.\n\n24:48.800 --> 24:50.920\n Exactly, so that's what I'm asking.\n\n24:50.920 --> 24:52.220\n Do you think it's almost possible\n\n24:52.220 --> 24:55.700\n to really forget the external world?\n\n24:55.700 --> 24:58.440\n Really, really immerse yourself.\n\n24:58.440 --> 24:59.840\n To forget completely?\n\n24:59.840 --> 25:00.680\n Why would we forget?\n\n25:00.680 --> 25:02.200\n We got pretty good memories.\n\n25:02.200 --> 25:06.000\n Maybe you can stop paying attention to the external world,\n\n25:06.000 --> 25:07.540\n but this already happens a lot.\n\n25:07.540 --> 25:10.000\n I go to work, and maybe I'm not paying attention\n\n25:10.000 --> 25:11.080\n to my home life.\n\n25:11.080 --> 25:14.520\n I go to a movie, and I'm immersed in that.\n\n25:14.520 --> 25:17.100\n So that degree of immersion, absolutely.\n\n25:17.100 --> 25:19.640\n But we still have the capacity to remember it,\n\n25:19.640 --> 25:21.960\n to completely forget the external world.\n\n25:21.960 --> 25:23.920\n I'm thinking that would probably take some,\n\n25:23.920 --> 25:25.760\n I don't know, some pretty serious drugs or something\n\n25:25.760 --> 25:27.600\n to make your brain do that.\n\n25:27.600 --> 25:28.960\n Is that possible?\n\n25:28.960 --> 25:31.040\n So, I mean, I guess what I'm getting at\n\n25:31.040 --> 25:35.640\n is consciousness truly a property\n\n25:35.640 --> 25:38.520\n that's tied to the physical brain?\n\n25:41.040 --> 25:45.000\n Or can you create sort of different offspring,\n\n25:45.000 --> 25:47.600\n copies of consciousnesses based on the worlds\n\n25:47.600 --> 25:48.540\n that you enter?\n\n25:49.400 --> 25:51.560\n Well, the way we're doing it now,\n\n25:51.560 --> 25:54.900\n at least with a standard VR, there's just one brain.\n\n25:54.900 --> 25:56.640\n Interacts with the physical world.\n\n25:56.640 --> 25:59.360\n Plays a video game, puts on a video headset,\n\n25:59.360 --> 26:01.720\n interacts with this virtual world.\n\n26:01.720 --> 26:04.800\n And I think we'd typically say there's one consciousness here\n\n26:04.800 --> 26:07.520\n that nonetheless undergoes different environments,\n\n26:07.520 --> 26:11.880\n takes on different characters in different environments.\n\n26:11.880 --> 26:13.160\n This is already something that happens\n\n26:13.160 --> 26:14.320\n in the nonvirtual world.\n\n26:14.320 --> 26:17.480\n I might interact one way in my home life,\n\n26:17.480 --> 26:21.200\n my work life, my social life, and so on.\n\n26:21.200 --> 26:23.960\n So at the very least, that will happen\n\n26:23.960 --> 26:25.780\n in a virtual world very naturally.\n\n26:25.780 --> 26:30.360\n People sometimes adopt the character of avatars\n\n26:30.360 --> 26:32.400\n very different from themselves,\n\n26:32.400 --> 26:34.800\n maybe even a different gender, different race,\n\n26:34.800 --> 26:37.000\n different social background.\n\n26:37.000 --> 26:38.800\n So that much is certainly possible.\n\n26:38.800 --> 26:41.160\n I would see that as a single consciousness\n\n26:41.160 --> 26:43.360\n is taking on different personas.\n\n26:43.360 --> 26:46.280\n If you want literal splitting of consciousness\n\n26:46.280 --> 26:47.400\n into multiple copies,\n\n26:47.400 --> 26:50.640\n I think it's gonna take something more radical than that.\n\n26:50.640 --> 26:54.360\n Like maybe you can run different simulations of your brain\n\n26:54.360 --> 26:56.080\n in different realities\n\n26:56.080 --> 26:57.880\n and then expose them to different histories.\n\n26:57.880 --> 27:00.160\n And then you'd split yourself\n\n27:00.160 --> 27:01.900\n into 10 different simulated copies,\n\n27:01.900 --> 27:04.120\n which then undergo different environments\n\n27:04.120 --> 27:05.680\n and then ultimately do become 10\n\n27:05.680 --> 27:07.720\n very different consciousnesses.\n\n27:07.720 --> 27:08.600\n Maybe that could happen,\n\n27:08.600 --> 27:10.440\n but now we're not talking about something\n\n27:10.440 --> 27:12.240\n that's possible in the near term.\n\n27:12.240 --> 27:14.040\n We're gonna have to have brain simulations\n\n27:14.040 --> 27:16.260\n and AGI for that to happen.\n\n27:17.400 --> 27:18.240\n Got it.\n\n27:18.240 --> 27:20.200\n So before any of that happens,\n\n27:20.200 --> 27:23.760\n it's fundamentally you see it as a singular consciousness,\n\n27:23.760 --> 27:26.400\n even though it's experiencing different environments,\n\n27:26.400 --> 27:27.780\n virtual or not,\n\n27:27.780 --> 27:30.480\n it's still connected to same set of memories,\n\n27:30.480 --> 27:32.760\n same set of experiences and therefore,\n\n27:32.760 --> 27:37.760\n one sort of joint conscious system.\n\n27:38.240 --> 27:40.560\n Yeah, or at least no more multiple\n\n27:40.560 --> 27:42.140\n than the kind of multiple consciousness\n\n27:42.140 --> 27:45.000\n that we get from inhabiting different environments\n\n27:45.000 --> 27:46.720\n in a non virtual world.\n\n27:46.720 --> 27:48.760\n So you said as a child,\n\n27:48.760 --> 27:53.440\n you were a music color synesthete.\n\n27:53.440 --> 27:55.380\n So where songs had colors for you.\n\n27:56.440 --> 27:59.760\n So what songs had what colors?\n\n27:59.760 --> 28:00.960\n You know, this is funny.\n\n28:00.960 --> 28:04.040\n I didn't pay much attention to this at the time,\n\n28:04.040 --> 28:05.340\n but I'd listen to a piece of music\n\n28:05.340 --> 28:07.560\n and I'd get some kind of imagery\n\n28:07.560 --> 28:11.400\n of a kind of color.\n\n28:11.400 --> 28:16.120\n The weird thing is mostly they were kind of murky,\n\n28:16.120 --> 28:18.560\n dark greens and olive browns\n\n28:18.560 --> 28:21.600\n and the colors weren't all that interesting.\n\n28:21.600 --> 28:22.520\n I don't know what the reason is.\n\n28:22.520 --> 28:25.280\n I mean, my theory is that maybe it's like different chords\n\n28:25.280 --> 28:27.720\n and tones provided different colors\n\n28:27.720 --> 28:29.280\n and they all tended to get mixed together\n\n28:29.280 --> 28:33.200\n into these somewhat uninteresting browns and greens.\n\n28:33.200 --> 28:35.480\n But every now and then there'd be something\n\n28:35.480 --> 28:37.360\n that had a really pure color.\n\n28:37.360 --> 28:39.360\n So there's just a few that I remember.\n\n28:39.360 --> 28:42.440\n There was a Here, There and Everywhere by the Beatles\n\n28:42.440 --> 28:46.360\n was bright red and has this very distinctive tonality\n\n28:46.360 --> 28:49.680\n and it's called structure at the beginning.\n\n28:49.680 --> 28:50.880\n So that was bright red.\n\n28:50.880 --> 28:53.960\n There was this song by the Alan Parsons Project\n\n28:53.960 --> 28:58.960\n called Ammonia Avenue that was kind of a pure, a pure blue.\n\n28:59.720 --> 29:02.080\n Anyway, I've got no idea how this happened.\n\n29:02.080 --> 29:03.120\n I didn't even pay that much attention\n\n29:03.120 --> 29:05.400\n until it went away when I was about 20.\n\n29:05.400 --> 29:07.480\n This synesthesia often goes away.\n\n29:07.480 --> 29:10.960\n So is it purely just the perception of a particular color\n\n29:10.960 --> 29:14.320\n or was there a positive or negative experience?\n\n29:14.320 --> 29:16.400\n Like was blue associated with a positive\n\n29:16.400 --> 29:17.920\n and red with a negative?\n\n29:17.920 --> 29:20.960\n Or is it simply the perception of color\n\n29:20.960 --> 29:23.440\n associated with some characteristic of the song?\n\n29:23.440 --> 29:25.760\n For me, I don't remember a lot of association\n\n29:25.760 --> 29:28.320\n with emotion or with value.\n\n29:28.320 --> 29:30.920\n It was just this kind of weird and interesting fact.\n\n29:30.920 --> 29:32.360\n I mean, at the beginning, I thought this was something\n\n29:32.360 --> 29:35.000\n that happened to everyone, songs of colors.\n\n29:35.000 --> 29:39.040\n Maybe I mentioned it once or twice and people said, nope.\n\n29:40.240 --> 29:42.560\n I thought it was kind of cool when there was one\n\n29:42.560 --> 29:44.680\n that had one of these especially pure colors,\n\n29:44.680 --> 29:48.200\n but only much later once I became a grad student\n\n29:48.200 --> 29:50.600\n thinking about the mind that I read about this phenomenon\n\n29:50.600 --> 29:53.960\n called synesthesia and I was like, hey, that's what I had.\n\n29:53.960 --> 29:56.560\n And now I occasionally talk about it in my classes,\n\n29:56.560 --> 29:58.600\n in intro class and it still happens sometimes.\n\n29:58.600 --> 30:01.120\n A student comes up and says, hey, I have that.\n\n30:01.120 --> 30:01.960\n I never knew about that.\n\n30:01.960 --> 30:03.280\n I never knew it had a name.\n\n30:04.520 --> 30:08.080\n You said that it went away at age 20 or so.\n\n30:08.080 --> 30:13.080\n And that you have a journal entry from around then saying,\n\n30:13.080 --> 30:15.240\n songs don't have colors anymore.\n\n30:15.240 --> 30:16.080\n What happened?\n\n30:16.080 --> 30:16.920\n What happened?\n\n30:16.920 --> 30:18.800\n Yeah, it was definitely sad that it was gone.\n\n30:18.800 --> 30:20.680\n In retrospect, it was like, hey, that's cool.\n\n30:20.680 --> 30:21.920\n The colors have gone.\n\n30:21.920 --> 30:25.000\n Yeah, can you think about that for a little bit?\n\n30:25.000 --> 30:27.000\n Do you miss those experiences?\n\n30:27.000 --> 30:31.720\n Because it's a fundamentally different set of experiences\n\n30:31.720 --> 30:33.320\n that you no longer have.\n\n30:35.120 --> 30:38.360\n Or is it just a nice thing to have had?\n\n30:38.360 --> 30:40.640\n You don't see them as that fundamentally different\n\n30:40.640 --> 30:43.680\n than you visiting a new country and experiencing\n\n30:43.680 --> 30:44.960\n new environments.\n\n30:44.960 --> 30:47.440\n I guess for me, when I had these experiences,\n\n30:47.440 --> 30:48.960\n they were somewhat marginal.\n\n30:48.960 --> 30:51.640\n They were like a little bonus kind of experience.\n\n30:51.640 --> 30:55.120\n I know there are people who have much more serious forms\n\n30:55.120 --> 30:58.800\n of synesthesia than this for whom it's absolutely central\n\n30:58.800 --> 30:59.640\n to their lives.\n\n30:59.640 --> 31:01.800\n I know people who, when they experience new people,\n\n31:01.800 --> 31:04.760\n they have colors, maybe they have tastes and so on.\n\n31:04.760 --> 31:08.320\n Every time they see writing, it has colors.\n\n31:08.320 --> 31:09.640\n Some people, whenever they hear music,\n\n31:09.640 --> 31:14.640\n it's got a certain really rich color pattern.\n\n31:15.040 --> 31:17.440\n For some synesthetes, it's absolutely central.\n\n31:17.440 --> 31:20.200\n I think if they lost it, they'd be devastated.\n\n31:20.200 --> 31:23.760\n Again, for me, it was a very, very mild form\n\n31:23.760 --> 31:25.560\n of synesthesia, and it's like, yeah,\n\n31:25.560 --> 31:27.360\n it's like those interesting experiences\n\n31:29.440 --> 31:31.560\n you might get under different altered states\n\n31:31.560 --> 31:33.360\n of consciousness and so on.\n\n31:33.360 --> 31:36.200\n It's kind of cool, but not necessarily\n\n31:36.200 --> 31:39.280\n the single most important experiences in your life.\n\n31:39.280 --> 31:40.120\n Got it.\n\n31:40.120 --> 31:43.920\n So let's try to go to the very simplest question\n\n31:43.920 --> 31:45.120\n that you've answered many a time,\n\n31:45.120 --> 31:48.560\n but perhaps the simplest things can help us reveal,\n\n31:48.560 --> 31:51.680\n even in time, some new ideas.\n\n31:51.680 --> 31:55.640\n So what, in your view, is consciousness?\n\n31:55.640 --> 31:56.840\n What is qualia?\n\n31:56.840 --> 32:00.680\n What is the hard problem of consciousness?\n\n32:00.680 --> 32:03.360\n Consciousness, I mean, the word is used many ways,\n\n32:03.360 --> 32:06.240\n but the kind of consciousness that I'm interested in\n\n32:06.240 --> 32:10.000\n is basically subjective experience,\n\n32:10.000 --> 32:14.360\n what it feels like from the inside to be a human being\n\n32:14.360 --> 32:16.160\n or any other conscious being.\n\n32:16.160 --> 32:19.720\n I mean, there's something it's like to be me right now.\n\n32:19.720 --> 32:23.520\n I have visual images that I'm experiencing.\n\n32:23.520 --> 32:25.600\n I'm hearing my voice.\n\n32:25.600 --> 32:29.120\n I've got maybe some emotional tone.\n\n32:29.120 --> 32:31.640\n I've got a stream of thoughts running through my head.\n\n32:31.640 --> 32:33.600\n These are all things that I experience\n\n32:33.600 --> 32:36.240\n from the first person point of view.\n\n32:36.240 --> 32:39.120\n I've sometimes called this the inner movie in the mind.\n\n32:39.120 --> 32:41.600\n It's not a perfect metaphor.\n\n32:41.600 --> 32:44.200\n It's not like a movie in every way,\n\n32:44.200 --> 32:45.640\n and it's very rich.\n\n32:45.640 --> 32:49.360\n But yeah, it's just direct, subjective experience.\n\n32:49.360 --> 32:51.360\n And I call that consciousness,\n\n32:51.360 --> 32:54.600\n or sometimes philosophers use the word qualia,\n\n32:54.600 --> 32:55.480\n which you suggested.\n\n32:55.480 --> 32:57.040\n People tend to use the word qualia\n\n32:57.040 --> 33:00.400\n for things like the qualities of things like colors,\n\n33:00.400 --> 33:02.280\n redness, the experience of redness\n\n33:02.280 --> 33:04.640\n versus the experience of greenness,\n\n33:04.640 --> 33:08.800\n the experience of one taste or one smell versus another,\n\n33:08.800 --> 33:10.920\n the experience of the quality of pain.\n\n33:10.920 --> 33:12.680\n And yeah, a lot of consciousness\n\n33:12.680 --> 33:17.000\n is the experience of those qualities.\n\n33:17.000 --> 33:18.240\n Well, consciousness is bigger,\n\n33:18.240 --> 33:21.040\n the entirety of any kinds of experiences.\n\n33:21.040 --> 33:23.880\n Consciousness of thinking is not obviously qualia.\n\n33:23.880 --> 33:26.440\n It's not like specific qualities like redness or greenness,\n\n33:26.440 --> 33:29.200\n but still I'm thinking about my hometown.\n\n33:29.200 --> 33:31.680\n I'm thinking about what I'm gonna do later on.\n\n33:31.680 --> 33:34.160\n Maybe there's still something running through my head,\n\n33:34.160 --> 33:36.320\n which is subjective experience.\n\n33:36.320 --> 33:39.960\n Maybe it goes beyond those qualities or qualia.\n\n33:39.960 --> 33:43.000\n Philosophers sometimes use the word phenomenal consciousness\n\n33:43.000 --> 33:44.680\n for consciousness in this sense.\n\n33:44.680 --> 33:47.480\n I mean, people also talk about access consciousness,\n\n33:47.480 --> 33:50.280\n being able to access information in your mind,\n\n33:50.280 --> 33:52.080\n reflective consciousness,\n\n33:52.080 --> 33:53.920\n being able to think about yourself.\n\n33:53.920 --> 33:55.920\n But it looks like the really mysterious one,\n\n33:55.920 --> 33:57.240\n the one that really gets people going\n\n33:57.240 --> 33:58.880\n is phenomenal consciousness.\n\n33:58.880 --> 34:02.760\n The fact that there's subjective experience\n\n34:02.760 --> 34:05.120\n and all this feels like something at all.\n\n34:05.120 --> 34:08.880\n And then the hard problem is how is it that,\n\n34:08.880 --> 34:11.520\n why is it that there is phenomenal consciousness at all?\n\n34:11.520 --> 34:15.600\n And how is it that physical processes in a brain\n\n34:15.600 --> 34:19.400\n could give you subjective experience?\n\n34:19.400 --> 34:21.680\n It looks like on the face of it,\n\n34:21.680 --> 34:23.920\n you'd have all this big complicated physical system\n\n34:23.920 --> 34:27.240\n in a brain running without a given\n\n34:27.240 --> 34:28.480\n subjective experience at all.\n\n34:28.480 --> 34:30.840\n And yet we do have subjective experience.\n\n34:30.840 --> 34:33.200\n So the hard problem is just explain that.\n\n34:34.160 --> 34:35.960\n Explain how that comes about.\n\n34:35.960 --> 34:37.560\n We haven't been able to build machines\n\n34:37.560 --> 34:41.320\n where a red light goes on that says it's not conscious.\n\n34:41.320 --> 34:45.720\n So how do we actually create that?\n\n34:45.720 --> 34:47.360\n Or how do humans do it?\n\n34:47.360 --> 34:49.000\n And how do we ourselves do it?\n\n34:49.000 --> 34:51.720\n We do every now and then create machines that can do this.\n\n34:51.720 --> 34:55.600\n We create babies that are conscious.\n\n34:55.600 --> 34:56.560\n They've got these brains.\n\n34:56.560 --> 34:58.440\n That brain does produce consciousness.\n\n34:58.440 --> 35:00.680\n But even though we can create it,\n\n35:00.680 --> 35:02.880\n we still don't understand why it happens.\n\n35:02.880 --> 35:05.440\n Maybe eventually we'll be able to create machines,\n\n35:05.440 --> 35:07.840\n which as a matter of fact, AI machines,\n\n35:07.840 --> 35:10.280\n which as a matter of fact are conscious.\n\n35:10.280 --> 35:13.760\n But that won't necessarily make the hard problem go away\n\n35:13.760 --> 35:15.480\n any more than it does with babies.\n\n35:15.480 --> 35:17.480\n Cause we still wanna know how and why is it\n\n35:17.480 --> 35:19.680\n that these processes give you consciousness?\n\n35:19.680 --> 35:22.160\n You just made me realize for a second,\n\n35:22.160 --> 35:27.160\n maybe it's a totally dumb realization, but nevertheless,\n\n35:28.520 --> 35:31.840\n that as a useful way to think about\n\n35:31.840 --> 35:35.760\n the creation of consciousness is looking at a baby.\n\n35:35.760 --> 35:37.520\n So that there's a certain point\n\n35:38.480 --> 35:40.880\n at which that baby is not conscious.\n\n35:44.400 --> 35:47.160\n The baby starts from maybe, I don't know,\n\n35:47.160 --> 35:49.600\n from a few cells, right?\n\n35:49.600 --> 35:52.760\n There's a certain point at which it becomes consciousness,\n\n35:52.760 --> 35:54.920\n arrives, it's conscious.\n\n35:54.920 --> 35:56.880\n Of course, we can't know exactly that line,\n\n35:56.880 --> 36:01.000\n but that's a useful idea that we do create consciousness.\n\n36:02.280 --> 36:04.560\n Again, a really dumb thing for me to say,\n\n36:04.560 --> 36:07.000\n but not until now did I realize\n\n36:07.000 --> 36:09.640\n we do engineer consciousness.\n\n36:09.640 --> 36:12.240\n We get to watch the process happen.\n\n36:12.240 --> 36:16.200\n We don't know which point it happens or where it is,\n\n36:16.200 --> 36:19.200\n but we do see the birth of consciousness.\n\n36:19.200 --> 36:21.080\n Yeah, I mean, there's a question, of course,\n\n36:21.080 --> 36:25.000\n is whether babies are conscious when they're born.\n\n36:25.000 --> 36:26.320\n And it used to be, it seems,\n\n36:26.320 --> 36:28.240\n at least some people thought they weren't,\n\n36:28.240 --> 36:30.520\n which is why they didn't give anesthetics\n\n36:30.520 --> 36:33.160\n to newborn babies when they circumcised them.\n\n36:33.160 --> 36:36.600\n And so now people think, oh, that would be incredibly cruel.\n\n36:36.600 --> 36:38.760\n Of course, babies feel pain.\n\n36:38.760 --> 36:42.120\n And now the dominant view is that the babies can feel pain.\n\n36:42.120 --> 36:45.840\n Actually, my partner Claudia works on this whole issue\n\n36:45.840 --> 36:48.160\n of whether there's consciousness in babies\n\n36:48.160 --> 36:49.720\n and of what kind.\n\n36:49.720 --> 36:52.200\n And she certainly thinks that newborn babies\n\n36:53.280 --> 36:55.480\n come into the world with some degree of consciousness.\n\n36:55.480 --> 36:57.320\n Of course, then you can just extend the question backwards\n\n36:57.320 --> 36:59.320\n to fetuses and suddenly you're into\n\n36:59.320 --> 37:02.120\n politically controversial territory.\n\n37:02.120 --> 37:06.840\n But the question also arises in the animal kingdom.\n\n37:06.840 --> 37:08.640\n Where does consciousness start or stop?\n\n37:08.640 --> 37:11.080\n Is there a line in the animal kingdom\n\n37:11.960 --> 37:14.720\n where the first conscious organisms are?\n\n37:15.920 --> 37:16.920\n It's interesting, over time,\n\n37:16.920 --> 37:18.240\n people are becoming more and more liberal\n\n37:18.240 --> 37:21.080\n about ascribing consciousness to animals.\n\n37:21.080 --> 37:24.520\n People used to think maybe only mammals could be conscious.\n\n37:24.520 --> 37:27.440\n Now most people seem to think, sure, fish are conscious.\n\n37:27.440 --> 37:28.760\n They can feel pain.\n\n37:28.760 --> 37:31.000\n And now we're arguing over insects.\n\n37:31.000 --> 37:33.440\n You'll find people out there who say plants\n\n37:33.440 --> 37:35.600\n have some degree of consciousness.\n\n37:35.600 --> 37:37.840\n So, you know, who knows where it's gonna end.\n\n37:37.840 --> 37:39.360\n The far end of this chain is the view\n\n37:39.360 --> 37:43.320\n that every physical system has some degree of consciousness.\n\n37:43.320 --> 37:45.960\n Philosophers call that panpsychism.\n\n37:45.960 --> 37:48.320\n You know, I take that view.\n\n37:48.320 --> 37:50.920\n I mean, that's a fascinating way to view reality.\n\n37:50.920 --> 37:52.840\n So if you could talk about,\n\n37:52.840 --> 37:56.520\n if you can linger on panpsychism for a little bit,\n\n37:56.520 --> 37:58.400\n what does it mean?\n\n37:58.400 --> 38:00.960\n So it's not just plants are conscious.\n\n38:00.960 --> 38:02.480\n I mean, it's that consciousness\n\n38:02.480 --> 38:05.360\n is a fundamental fabric of reality.\n\n38:05.360 --> 38:07.360\n What does that mean to you?\n\n38:07.360 --> 38:09.640\n How are we supposed to think about that?\n\n38:09.640 --> 38:12.120\n Well, we're used to the idea that some things in the world\n\n38:12.120 --> 38:15.240\n are fundamental, right, in physics.\n\n38:15.240 --> 38:16.080\n Like what?\n\n38:16.080 --> 38:18.800\n We take things like space or time or space time,\n\n38:18.800 --> 38:23.120\n mass, charges, fundamental properties of the universe.\n\n38:23.120 --> 38:25.440\n You don't reduce them to something simpler.\n\n38:25.440 --> 38:26.920\n You take those for granted.\n\n38:26.920 --> 38:30.120\n You've got some laws that connect them.\n\n38:30.120 --> 38:33.800\n Here is how mass and space and time evolve.\n\n38:33.800 --> 38:36.600\n Theories like relativity or quantum mechanics\n\n38:36.600 --> 38:39.960\n or some future theory that will unify them both.\n\n38:39.960 --> 38:42.520\n But everyone says you gotta take some things as fundamental.\n\n38:42.520 --> 38:44.600\n And if you can't explain one thing,\n\n38:44.600 --> 38:47.120\n in terms of the previous fundamental things,\n\n38:47.120 --> 38:48.240\n you have to expand.\n\n38:49.240 --> 38:51.640\n Maybe something like this happened with Maxwell.\n\n38:52.800 --> 38:54.160\n He ended up with fundamental principles\n\n38:54.160 --> 38:57.480\n of electromagnetism and took charge as fundamental\n\n38:57.480 --> 39:00.120\n because it turned out that was the best way to explain it.\n\n39:00.120 --> 39:02.840\n So I at least take seriously the possibility\n\n39:02.840 --> 39:06.080\n something like that could happen with consciousness.\n\n39:06.080 --> 39:07.600\n Take it as a fundamental property,\n\n39:07.600 --> 39:10.120\n like space, time, and mass.\n\n39:10.120 --> 39:13.760\n And instead of trying to explain consciousness wholly\n\n39:13.760 --> 39:17.480\n in terms of the evolution of space, time, and mass,\n\n39:17.480 --> 39:20.000\n and so on, take it as a primitive\n\n39:20.000 --> 39:23.000\n and then connect it to everything else\n\n39:23.000 --> 39:25.200\n by some fundamental laws.\n\n39:25.200 --> 39:27.120\n Because there's this basic problem\n\n39:27.120 --> 39:29.080\n that the physics we have now looks great\n\n39:29.080 --> 39:31.800\n for solving the easy problems of consciousness,\n\n39:31.800 --> 39:33.240\n which are all about behavior.\n\n39:35.280 --> 39:37.440\n They give us a complicated structure and dynamics.\n\n39:37.440 --> 39:39.640\n They tell us how things are gonna behave,\n\n39:39.640 --> 39:43.160\n what kind of observable behavior they'll produce,\n\n39:43.160 --> 39:46.400\n which is great for the problems of explaining how we walk\n\n39:46.400 --> 39:48.600\n and how we talk and so on.\n\n39:48.600 --> 39:50.640\n Those are the easy problems of consciousness.\n\n39:50.640 --> 39:52.560\n But the hard problem was this problem\n\n39:52.560 --> 39:55.360\n about subjective experience just doesn't look\n\n39:55.360 --> 39:57.000\n like that kind of problem about structure,\n\n39:57.000 --> 39:58.800\n dynamics, how things behave.\n\n39:58.800 --> 40:01.320\n So it's hard to see how existing physics\n\n40:01.320 --> 40:04.680\n is gonna give you a full explanation of that.\n\n40:04.680 --> 40:08.000\n Certainly trying to get a physics view of consciousness,\n\n40:08.000 --> 40:10.960\n yes, there has to be a connecting point\n\n40:10.960 --> 40:12.600\n and it could be at the very axiomatic\n\n40:12.600 --> 40:14.120\n at the very beginning level.\n\n40:14.120 --> 40:19.120\n But first of all, there's a crazy idea\n\n40:21.960 --> 40:25.760\n that sort of everything has properties of consciousness.\n\n40:27.640 --> 40:30.080\n At that point, the word consciousness\n\n40:30.080 --> 40:33.000\n is already beyond the reach of our current understanding.\n\n40:33.000 --> 40:35.800\n Like far, because it's so far from,\n\n40:35.800 --> 40:38.760\n at least for me, maybe you can correct me,\n\n40:38.760 --> 40:43.760\n as far from the experiences that I have as a human being.\n\n40:45.680 --> 40:47.360\n To say that everything is conscious,\n\n40:47.360 --> 40:52.360\n that means that basically another way to put that,\n\n40:52.840 --> 40:56.840\n if that's true, then we understand almost nothing\n\n40:56.840 --> 41:00.120\n about that fundamental aspect of the world.\n\n41:00.120 --> 41:02.760\n How do you feel about saying an ant is conscious?\n\n41:02.760 --> 41:04.040\n Do you get the same reaction to that\n\n41:04.040 --> 41:05.760\n or is that something you can understand?\n\n41:05.760 --> 41:06.880\n I can understand ant,\n\n41:06.880 --> 41:10.680\n I can understand an atom, a particle.\n\n41:10.680 --> 41:12.120\n Plants?\n\n41:12.120 --> 41:16.640\n Plant, so I'm comfortable with living things on Earth\n\n41:16.640 --> 41:20.840\n being conscious because there's some kind of agency\n\n41:22.040 --> 41:25.200\n where they're similar size to me\n\n41:26.480 --> 41:30.800\n and they can be born and they can die.\n\n41:30.800 --> 41:34.400\n And that is understandable intuitively.\n\n41:34.400 --> 41:36.720\n Of course, you anthropomorphize,\n\n41:36.720 --> 41:39.040\n you put yourself in the place of the plant,\n\n41:41.720 --> 41:43.240\n but I can understand it.\n\n41:43.240 --> 41:47.600\n I mean, I'm not like, I don't believe actually\n\n41:47.600 --> 41:49.600\n that plants are conscious or that plants suffer,\n\n41:49.600 --> 41:52.960\n but I can understand that kind of belief, that kind of idea.\n\n41:52.960 --> 41:54.920\n How do you feel about robots?\n\n41:54.920 --> 41:56.760\n Like the kind of robots we have now?\n\n41:56.760 --> 41:58.880\n If I told you like that a Roomba\n\n41:58.880 --> 42:00.400\n had some degree of consciousness\n\n42:02.280 --> 42:06.120\n or some deep neural network.\n\n42:06.120 --> 42:08.440\n I could understand that a Roomba has consciousness.\n\n42:08.440 --> 42:10.640\n I just had spent all day at I, robot.\n\n42:12.600 --> 42:15.200\n And I mean, I personally love robots\n\n42:15.200 --> 42:16.960\n and I have a deep connection with robots.\n\n42:16.960 --> 42:20.040\n So I can, I also probably anthropomorphize them.\n\n42:20.040 --> 42:23.880\n There's something about the physical object.\n\n42:23.880 --> 42:26.800\n So there's a difference than a neural network,\n\n42:26.800 --> 42:28.960\n a neural network running a software.\n\n42:28.960 --> 42:31.040\n To me, the physical object,\n\n42:31.040 --> 42:32.680\n something about the human experience\n\n42:32.680 --> 42:36.920\n allows me to really see that physical object as an entity.\n\n42:36.920 --> 42:40.920\n And if it moves and moves in a way that it,\n\n42:40.920 --> 42:43.440\n there's a, like I didn't program it,\n\n42:44.400 --> 42:49.400\n where it feels that it's acting based on its own perception.\n\n42:49.680 --> 42:53.440\n And yes, self awareness and consciousness,\n\n42:53.440 --> 42:55.440\n even if it's a Roomba,\n\n42:55.440 --> 43:00.440\n then you start to assign it some agency, some consciousness.\n\n43:00.440 --> 43:03.800\n So, but to say that panpsychism,\n\n43:03.800 --> 43:06.920\n that consciousness is a fundamental property of reality\n\n43:08.440 --> 43:11.360\n is a much bigger statement.\n\n43:11.360 --> 43:13.600\n That it's like turtles all the way.\n\n43:13.600 --> 43:16.080\n It's like every, it's, it doesn't end.\n\n43:16.080 --> 43:18.360\n The whole thing is, so like how,\n\n43:18.360 --> 43:20.140\n I know it's full of mystery,\n\n43:21.120 --> 43:23.880\n but if you can linger on it,\n\n43:23.880 --> 43:27.600\n like how would it, how do you think about reality\n\n43:27.600 --> 43:31.840\n if consciousness is a fundamental part of its fabric?\n\n43:31.840 --> 43:33.300\n The way you get there is from thinking,\n\n43:33.300 --> 43:36.520\n can we explain consciousness given the existing fundamentals?\n\n43:36.520 --> 43:41.120\n And then if you can't, as at least right now, it looks like,\n\n43:41.120 --> 43:42.320\n then you've got to add something.\n\n43:42.320 --> 43:44.920\n It doesn't follow that you have to add consciousness.\n\n43:44.920 --> 43:47.000\n Here's another interesting possibility is,\n\n43:47.000 --> 43:48.020\n well, we'll add something else.\n\n43:48.020 --> 43:51.640\n Let's call it proto consciousness or X.\n\n43:51.640 --> 43:56.120\n And then it turns out space, time, mass plus X\n\n43:56.120 --> 43:58.920\n will somehow collectively give you the possibility\n\n43:58.920 --> 44:00.200\n for consciousness.\n\n44:00.200 --> 44:01.780\n Why don't rule out that view?\n\n44:01.780 --> 44:04.760\n Either I call that pan proto psychism,\n\n44:04.760 --> 44:06.240\n because maybe there's some other property,\n\n44:06.240 --> 44:08.880\n proto consciousness at the bottom level.\n\n44:08.880 --> 44:10.480\n And if you can't imagine there's actually\n\n44:10.480 --> 44:12.800\n genuine consciousness at the bottom level,\n\n44:12.800 --> 44:14.100\n I think we should be open to the idea\n\n44:14.100 --> 44:16.160\n there's this other thing X.\n\n44:16.160 --> 44:19.960\n Maybe we can't imagine that somehow gives you consciousness.\n\n44:19.960 --> 44:22.360\n But if we are playing along with the idea\n\n44:22.360 --> 44:24.320\n that there really is genuine consciousness\n\n44:24.320 --> 44:25.360\n at the bottom level, of course,\n\n44:25.360 --> 44:28.280\n this is going to be way out and speculative,\n\n44:28.280 --> 44:32.040\n but at least in, say, if it was classical physics,\n\n44:32.040 --> 44:33.480\n then we'd have to, you'd end up saying,\n\n44:33.480 --> 44:35.280\n well, every little atom, every little,\n\n44:35.280 --> 44:37.640\n with a bunch of particles in space time,\n\n44:37.640 --> 44:41.560\n each of these particles has some kind of consciousness\n\n44:41.560 --> 44:44.560\n whose structure mirrors maybe their physical properties,\n\n44:44.560 --> 44:49.080\n like its mass, its charge, its velocity, and so on.\n\n44:49.080 --> 44:50.320\n The structure of its consciousness\n\n44:50.320 --> 44:52.280\n would roughly correspond to that.\n\n44:52.280 --> 44:55.440\n And the physical interactions between particles,\n\n44:55.440 --> 44:58.280\n I mean, there's this old worry about physics.\n\n44:58.280 --> 44:59.560\n I mentioned this before in this issue\n\n44:59.560 --> 45:01.120\n about the manifest image.\n\n45:01.120 --> 45:02.080\n We don't really find out\n\n45:02.080 --> 45:04.560\n about the intrinsic nature of things.\n\n45:04.560 --> 45:07.440\n Physics tells us about how a particle relates\n\n45:07.440 --> 45:09.320\n to other particles and interacts.\n\n45:09.320 --> 45:12.840\n It doesn't tell us about what the particle is in itself.\n\n45:12.840 --> 45:14.600\n That was Kant's thing in itself.\n\n45:14.600 --> 45:15.680\n So here's a view.\n\n45:17.880 --> 45:20.840\n The nature in itself of a particle is something mental.\n\n45:20.840 --> 45:22.840\n A particle is actually a conscious,\n\n45:22.840 --> 45:24.520\n a little conscious subject\n\n45:24.520 --> 45:27.320\n with properties of its consciousness\n\n45:27.320 --> 45:29.160\n that correspond to its physical properties.\n\n45:29.160 --> 45:32.640\n The laws of physics are actually ultimately relating\n\n45:32.640 --> 45:34.560\n these properties of conscious subjects.\n\n45:34.560 --> 45:36.640\n So in this view, a Newtonian world\n\n45:36.640 --> 45:38.200\n actually would be a vast collection\n\n45:38.200 --> 45:41.240\n of little conscious subjects at the bottom level,\n\n45:41.240 --> 45:44.960\n way, way simpler than we are without free will\n\n45:44.960 --> 45:47.280\n or rationality or anything like that.\n\n45:47.280 --> 45:48.800\n But that's what the universe would be like.\n\n45:48.800 --> 45:51.360\n Now, of course, that's a vastly speculative view.\n\n45:51.360 --> 45:53.600\n No particular reason to think it's correct.\n\n45:53.600 --> 45:56.480\n Furthermore, non Newtonian physics,\n\n45:56.480 --> 45:58.960\n say quantum mechanical wave function,\n\n45:58.960 --> 46:00.120\n suddenly it starts to look different.\n\n46:00.120 --> 46:02.600\n It's not a vast collection of conscious subjects.\n\n46:02.600 --> 46:05.360\n Maybe there's ultimately one big wave function\n\n46:05.360 --> 46:06.760\n for the whole universe.\n\n46:06.760 --> 46:08.440\n Corresponding to that might be something more\n\n46:08.440 --> 46:12.280\n like a single conscious mind\n\n46:12.280 --> 46:13.840\n whose structure corresponds\n\n46:13.840 --> 46:16.280\n to the structure of the wave function.\n\n46:16.280 --> 46:19.160\n People sometimes call this cosmo psychism.\n\n46:19.160 --> 46:20.880\n And now, of course, we're in the realm\n\n46:20.880 --> 46:23.200\n of extremely speculative philosophy.\n\n46:23.200 --> 46:25.160\n There's no direct evidence for this,\n\n46:25.160 --> 46:27.320\n but yeah, but if you want a picture\n\n46:27.320 --> 46:29.280\n of what that universe would be like,\n\n46:29.280 --> 46:31.680\n think, yeah, giant cosmic mind\n\n46:31.680 --> 46:33.920\n with enough richness and structure among it\n\n46:33.920 --> 46:36.520\n to replicate all the structure of physics.\n\n46:36.520 --> 46:39.720\n I think therefore I am at the level of particles\n\n46:39.720 --> 46:40.960\n and with quantum mechanics\n\n46:40.960 --> 46:42.640\n at the level of the wave function.\n\n46:42.640 --> 46:47.640\n It's kind of an exciting, beautiful possibility,\n\n46:49.440 --> 46:51.960\n of course, way out of reach of physics currently.\n\n46:51.960 --> 46:55.040\n It is interesting that some neuroscientists\n\n46:55.040 --> 46:58.680\n are beginning to take panpsychism seriously,\n\n46:58.680 --> 47:02.880\n that you find consciousness even in very simple systems.\n\n47:02.880 --> 47:05.560\n So for example, the integrated information theory\n\n47:05.560 --> 47:07.360\n of consciousness, a lot of neuroscientists\n\n47:07.360 --> 47:08.200\n are taking seriously.\n\n47:08.200 --> 47:09.920\n Actually, I just got this new book\n\n47:09.920 --> 47:11.720\n by Christoph Koch just came in,\n\n47:11.720 --> 47:13.680\n The Feeling of Life Itself,\n\n47:13.680 --> 47:17.200\n why consciousness is widespread, but can't be computed.\n\n47:17.200 --> 47:20.560\n He likes, he basically endorses a panpsychist view\n\n47:20.560 --> 47:22.280\n where you get consciousness\n\n47:22.280 --> 47:24.520\n with the degree of information processing\n\n47:24.520 --> 47:26.960\n or integrated information processing in a simple,\n\n47:26.960 --> 47:29.520\n in a system and even very, very simple systems,\n\n47:29.520 --> 47:32.720\n like a couple of particles will have some degree of this.\n\n47:32.720 --> 47:35.240\n So he ends up with some degree of consciousness\n\n47:35.240 --> 47:36.080\n in all matter.\n\n47:36.080 --> 47:38.680\n And the claim is that this theory\n\n47:38.680 --> 47:40.520\n can actually explain a bunch of stuff\n\n47:40.520 --> 47:43.600\n about the connection between the brain and consciousness.\n\n47:43.600 --> 47:45.360\n Now, that's very controversial.\n\n47:45.360 --> 47:46.920\n I think it's very, very early days\n\n47:46.920 --> 47:48.120\n in the science of consciousness.\n\n47:48.120 --> 47:50.840\n It's interesting that it's not just philosophy\n\n47:50.840 --> 47:52.680\n that might lead you in this direction,\n\n47:52.680 --> 47:55.280\n but there are ways of thinking quasi scientifically\n\n47:55.280 --> 47:56.480\n that lead you there too.\n\n47:57.400 --> 48:01.200\n But maybe it's different than panpsychism.\n\n48:01.200 --> 48:02.040\n What do you think?\n\n48:02.040 --> 48:06.960\n So Alan Watts has this quote that I'd like to ask you about.\n\n48:06.960 --> 48:10.440\n The quote is, through our eyes,\n\n48:10.440 --> 48:12.760\n the universe is perceiving itself.\n\n48:12.760 --> 48:14.640\n Through our ears, the universe is listening\n\n48:14.640 --> 48:16.120\n to its harmonies.\n\n48:16.120 --> 48:18.040\n We are the witnesses through which the universe\n\n48:18.040 --> 48:21.400\n becomes conscious of its glory, of its magnificence.\n\n48:22.440 --> 48:24.800\n So that's not panpsychism.\n\n48:24.800 --> 48:29.800\n Do you think that we are essentially the tools,\n\n48:30.480 --> 48:35.480\n the senses the universe created to be conscious of itself?\n\n48:35.480 --> 48:37.520\n It's an interesting idea.\n\n48:37.520 --> 48:40.520\n Of course, if you went for the giant cosmic mind view,\n\n48:40.520 --> 48:43.360\n then the universe was conscious all along.\n\n48:43.360 --> 48:44.200\n It didn't need us.\n\n48:44.200 --> 48:48.120\n We're just little components of the universal consciousness.\n\n48:48.120 --> 48:50.800\n Likewise, if you believe in panpsychism,\n\n48:50.800 --> 48:52.840\n then there was some little degree of consciousness\n\n48:52.840 --> 48:54.680\n at the bottom level all along.\n\n48:54.680 --> 48:58.240\n And we were just a more complex form of consciousness.\n\n48:58.240 --> 49:02.040\n So I think maybe the quote you mentioned works better.\n\n49:02.040 --> 49:05.120\n If you're not a panpsychist, you're not a cosmo psychist,\n\n49:05.120 --> 49:07.240\n you think consciousness just exists\n\n49:07.240 --> 49:09.360\n at this intermediate level.\n\n49:09.360 --> 49:12.320\n And of course, that's the Orthodox view.\n\n49:12.320 --> 49:14.680\n That you would say is the common view?\n\n49:14.680 --> 49:19.680\n So is your own view with panpsychism a rare view?\n\n49:19.880 --> 49:22.160\n I think it's generally regarded certainly\n\n49:22.160 --> 49:26.480\n as a speculative view held by a fairly small minority\n\n49:26.480 --> 49:30.000\n of at least theorists, most philosophers\n\n49:30.000 --> 49:33.040\n and most scientists who think about consciousness\n\n49:33.040 --> 49:34.600\n are not panpsychists.\n\n49:34.600 --> 49:36.240\n There's been a bit of a movement in that direction\n\n49:36.240 --> 49:37.920\n the last 10 years or so.\n\n49:37.920 --> 49:38.960\n It seems to be quite popular,\n\n49:38.960 --> 49:41.600\n especially among the younger generation,\n\n49:41.600 --> 49:43.960\n but it's still very definitely a minority view.\n\n49:43.960 --> 49:47.120\n Many people think it's totally batshit crazy\n\n49:47.120 --> 49:48.320\n to use the technical term.\n\n49:48.320 --> 49:51.360\n But the philosophical term.\n\n49:51.360 --> 49:53.400\n So the Orthodox view, I think is still consciousness\n\n49:53.400 --> 49:55.160\n is something that humans have\n\n49:55.160 --> 49:59.000\n and some good number of nonhuman animals have,\n\n49:59.000 --> 50:02.720\n and maybe AIs might have one day, but it's restricted.\n\n50:02.720 --> 50:04.400\n On that view, then there was no consciousness\n\n50:04.400 --> 50:05.840\n at the start of the universe.\n\n50:05.840 --> 50:07.200\n There may be none at the end,\n\n50:07.200 --> 50:09.920\n but it is this thing which happened at some point\n\n50:09.920 --> 50:13.160\n in the history of the universe, consciousness developed.\n\n50:13.160 --> 50:17.440\n And yes, that's a very amazing event on this view\n\n50:17.440 --> 50:20.280\n because many people are inclined to think consciousness\n\n50:20.280 --> 50:23.160\n is what somehow gives meaning to our lives.\n\n50:23.160 --> 50:25.760\n Without consciousness, there'd be no meaning,\n\n50:25.760 --> 50:29.720\n no true value, no good versus bad and so on.\n\n50:29.720 --> 50:32.200\n So with the advent of consciousness,\n\n50:32.200 --> 50:36.000\n suddenly the universe went from meaningless\n\n50:36.000 --> 50:38.760\n to somehow meaningful.\n\n50:38.760 --> 50:39.840\n Why did this happen?\n\n50:39.840 --> 50:42.200\n I guess the quote you mentioned was somehow,\n\n50:42.200 --> 50:44.360\n this was somehow destined to happen\n\n50:44.360 --> 50:47.360\n because the universe needed to have consciousness\n\n50:47.360 --> 50:49.280\n within it to have value and have meaning.\n\n50:49.280 --> 50:52.680\n And maybe you could combine that with a theistic view\n\n50:52.680 --> 50:54.640\n or a teleological view.\n\n50:54.640 --> 50:58.440\n The universe was inexorably evolving towards consciousness.\n\n50:58.440 --> 51:01.440\n Actually, my colleague here at NYU, Tom Nagel,\n\n51:01.440 --> 51:04.200\n wrote a book called Mind and Cosmos a few years ago\n\n51:04.200 --> 51:06.080\n where he argued for this teleological view\n\n51:06.080 --> 51:09.040\n of evolution toward consciousness,\n\n51:09.040 --> 51:12.640\n saying this led the problems for Darwinism.\n\n51:12.640 --> 51:15.120\n It's got him on, this is very, very controversial.\n\n51:15.120 --> 51:16.640\n Most people didn't agree.\n\n51:16.640 --> 51:20.080\n I don't myself agree with this teleological view,\n\n51:20.080 --> 51:24.120\n but it is at least a beautiful speculative view\n\n51:24.120 --> 51:26.160\n of the cosmos.\n\n51:26.160 --> 51:30.640\n What do you think people experience?\n\n51:30.640 --> 51:32.920\n What do they seek when they believe in God\n\n51:32.920 --> 51:34.720\n from this kind of perspective?\n\n51:36.200 --> 51:41.200\n I'm not an expert on thinking about God and religion.\n\n51:41.440 --> 51:43.880\n I'm not myself religious at all.\n\n51:43.880 --> 51:46.720\n When people sort of pray, communicate with God,\n\n51:46.720 --> 51:48.120\n which whatever form,\n\n51:48.120 --> 51:51.640\n I'm not speaking to sort of the practices\n\n51:51.640 --> 51:53.800\n and the rituals of religion.\n\n51:53.800 --> 51:56.960\n I mean the actual experience of that people\n\n51:56.960 --> 52:00.920\n really have a deep connection with God in some cases.\n\n52:00.920 --> 52:05.920\n What do you think that experience is?\n\n52:06.280 --> 52:08.680\n It's so common, at least throughout the history\n\n52:08.680 --> 52:13.680\n of civilization, that it seems like we seek that.\n\n52:16.360 --> 52:17.960\n At the very least, it is an interesting\n\n52:17.960 --> 52:19.600\n conscious experience that people have\n\n52:19.600 --> 52:24.600\n when they experience religious awe or prayer and so on.\n\n52:24.600 --> 52:27.200\n Neuroscientists have tried to examine\n\n52:27.200 --> 52:30.160\n what bits of the brain are active and so on.\n\n52:30.160 --> 52:32.120\n But yeah, there's this deeper question\n\n52:32.120 --> 52:34.800\n of what are people looking for when they're doing this?\n\n52:34.800 --> 52:38.440\n And like I said, I've got no real expertise on this,\n\n52:38.440 --> 52:40.920\n but it does seem that one thing people are after\n\n52:40.920 --> 52:43.240\n is a sense of meaning and value,\n\n52:43.240 --> 52:48.160\n a sense of connection to something greater than themselves\n\n52:48.160 --> 52:50.280\n that will give their lives meaning and value.\n\n52:50.280 --> 52:52.600\n And maybe the thought is if there is a God,\n\n52:52.600 --> 52:56.120\n then God somehow is a universal consciousness\n\n52:56.120 --> 53:00.000\n who has invested this universe with meaning\n\n53:01.080 --> 53:05.680\n and somehow connection to God might give your life meaning.\n\n53:05.680 --> 53:09.840\n I guess I can kind of see the attractions of that,\n\n53:09.840 --> 53:13.000\n but it still makes me wonder why is it exactly\n\n53:13.000 --> 53:15.920\n that a universal consciousness, God,\n\n53:15.920 --> 53:18.480\n would be needed to give the world meaning?\n\n53:18.480 --> 53:21.760\n If universal consciousness can give the world meaning,\n\n53:21.760 --> 53:25.280\n why can't local consciousness give the world meaning too?\n\n53:25.280 --> 53:28.480\n So I think my consciousness gives my world meaning.\n\n53:28.480 --> 53:31.080\n Is the origin of meaning for your world.\n\n53:31.080 --> 53:33.840\n Yeah, I experience things as good or bad,\n\n53:33.840 --> 53:37.480\n happy, sad, interesting, important.\n\n53:37.480 --> 53:40.560\n So my consciousness invests this world with meaning.\n\n53:40.560 --> 53:42.160\n Without any consciousness,\n\n53:42.160 --> 53:45.320\n maybe it would be a bleak, meaningless universe.\n\n53:45.320 --> 53:47.680\n But I don't see why I need someone else's consciousness\n\n53:47.680 --> 53:51.480\n or even God's consciousness to give this universe meaning.\n\n53:51.480 --> 53:53.160\n Here we are, local creatures\n\n53:53.160 --> 53:55.160\n with our own subjective experiences.\n\n53:55.160 --> 53:58.920\n I think we can give the universe meaning ourselves.\n\n53:58.920 --> 54:02.000\n I mean, maybe to some people that feels inadequate.\n\n54:02.000 --> 54:04.920\n Our own local consciousness is somehow too puny\n\n54:04.920 --> 54:07.320\n and insignificant to invest any of this\n\n54:07.320 --> 54:09.320\n with cosmic significance.\n\n54:09.320 --> 54:13.680\n And maybe God gives you a sense of cosmic significance,\n\n54:13.680 --> 54:15.720\n but I'm just speculating here.\n\n54:15.720 --> 54:19.280\n So it's a really interesting idea\n\n54:19.280 --> 54:23.560\n that consciousness is the thing that makes life meaningful.\n\n54:24.800 --> 54:29.800\n If you could maybe just briefly explore that for a second.\n\n54:30.400 --> 54:33.760\n So I suspect just from listening to you now,\n\n54:33.760 --> 54:37.400\n you mean in an almost trivial sense,\n\n54:37.400 --> 54:42.320\n just the day to day experiences of life have,\n\n54:42.320 --> 54:46.920\n because of you attach identity to it,\n\n54:46.920 --> 54:51.920\n they become, I guess I wanna ask something\n\n54:54.600 --> 54:57.120\n I would always wanted to ask\n\n54:57.120 --> 55:01.920\n a legit world renowned philosopher.\n\n55:01.920 --> 55:03.440\n What is the meaning of life?\n\n55:05.200 --> 55:08.080\n So I suspect you don't mean consciousness gives\n\n55:08.080 --> 55:11.280\n any kind of greater meaning to it all.\n\n55:11.280 --> 55:13.360\n And more to day to day.\n\n55:13.360 --> 55:16.240\n But is there a greater meaning to it all?\n\n55:16.240 --> 55:20.920\n I think life has meaning for us because we are conscious.\n\n55:20.920 --> 55:24.120\n So without consciousness, no meaning,\n\n55:24.120 --> 55:27.280\n consciousness invests our life with meaning.\n\n55:27.280 --> 55:30.680\n So consciousness is the source of the meaning of life,\n\n55:30.680 --> 55:33.320\n but I wouldn't say consciousness itself\n\n55:33.320 --> 55:34.760\n is the meaning of life.\n\n55:34.760 --> 55:36.960\n I'd say what's meaningful in life\n\n55:36.960 --> 55:40.000\n is basically what we find meaningful,\n\n55:40.000 --> 55:42.640\n what we experience as meaningful.\n\n55:42.640 --> 55:46.280\n So if you find meaning and fulfillment and value\n\n55:46.280 --> 55:49.080\n in say, intellectual work, like understanding,\n\n55:49.080 --> 55:51.720\n then that's a very significant part\n\n55:51.720 --> 55:53.200\n of the meaning of life for you.\n\n55:53.200 --> 55:55.680\n If you find that in social connections\n\n55:55.680 --> 55:57.400\n or in raising a family,\n\n55:57.400 --> 55:58.960\n then that's the meaning of life for you.\n\n55:58.960 --> 56:02.080\n The meaning kind of comes from what you value\n\n56:02.080 --> 56:04.040\n as a conscious creature.\n\n56:04.040 --> 56:05.280\n So I think there's no, on this view,\n\n56:05.280 --> 56:07.480\n there's no universal solution.\n\n56:08.640 --> 56:10.160\n No universal answer to the question,\n\n56:10.160 --> 56:11.480\n what is the meaning of life?\n\n56:11.480 --> 56:13.520\n The meaning of life is where you find it\n\n56:13.520 --> 56:14.600\n as a conscious creature,\n\n56:14.600 --> 56:18.040\n but it's consciousness that somehow makes value possible.\n\n56:18.040 --> 56:21.000\n Experiencing some things as good or as bad\n\n56:21.000 --> 56:22.840\n or as meaningful,\n\n56:22.840 --> 56:24.600\n something comes from within consciousness.\n\n56:24.600 --> 56:28.760\n So you think consciousness is a crucial component,\n\n56:28.760 --> 56:33.520\n ingredient of assigning value to things?\n\n56:33.520 --> 56:36.080\n I mean, it's kind of a fairly strong intuition\n\n56:36.080 --> 56:37.520\n that without consciousness,\n\n56:37.520 --> 56:39.920\n there wouldn't really be any value\n\n56:39.920 --> 56:44.600\n if we just had a purely universe of unconscious creatures.\n\n56:44.600 --> 56:47.680\n Would anything be better or worse than anything else?\n\n56:47.680 --> 56:50.320\n Certainly when it comes to ethical dilemmas,\n\n56:50.320 --> 56:53.160\n you know about the old trolley problem.\n\n56:53.160 --> 56:56.240\n Do you kill one person\n\n56:56.240 --> 56:59.600\n or do you switch to the other track to kill five?\n\n56:59.600 --> 57:01.680\n Well, I've got a variant on this,\n\n57:01.680 --> 57:03.440\n the zombie trolley problem,\n\n57:03.440 --> 57:06.720\n where there's a one conscious being on one track\n\n57:06.720 --> 57:09.120\n and five humanoid zombies.\n\n57:09.120 --> 57:12.880\n Let's make them robots who are not conscious\n\n57:12.880 --> 57:15.520\n on the other track.\n\n57:15.520 --> 57:16.640\n Do you, given that choice,\n\n57:16.640 --> 57:17.920\n do you kill the one conscious being\n\n57:17.920 --> 57:21.040\n or the five unconscious robots?\n\n57:21.040 --> 57:23.360\n Most people have a fairly clear intuition here.\n\n57:23.360 --> 57:25.560\n Kill the unconscious beings\n\n57:25.560 --> 57:28.720\n because they basically, they don't have a meaningful life.\n\n57:28.720 --> 57:33.720\n They're not really persons, conscious beings at all.\n\n57:33.760 --> 57:36.640\n We don't have good intuition\n\n57:36.640 --> 57:41.640\n about something like an unconscious being.\n\n57:42.040 --> 57:46.720\n So in philosophical terms, you referred to as a zombie.\n\n57:46.720 --> 57:51.120\n It's a useful thought experiment construction\n\n57:51.120 --> 57:54.920\n in philosophical terms, but we don't yet have them.\n\n57:55.880 --> 58:00.240\n So that's kind of what we may be able to create with robots.\n\n58:00.240 --> 58:05.240\n And I don't necessarily know what that even means.\n\n58:05.240 --> 58:07.280\n Yeah, they're merely hypothetical.\n\n58:07.280 --> 58:09.640\n For now, they're just a thought experiment.\n\n58:09.640 --> 58:11.040\n They may never be possible.\n\n58:11.040 --> 58:13.480\n I mean, the extreme case of a zombie\n\n58:13.480 --> 58:16.400\n is a being which is physically, functionally,\n\n58:16.400 --> 58:19.520\n behaviorally identical to me, but not conscious.\n\n58:19.520 --> 58:20.560\n That's a mere,\n\n58:20.560 --> 58:23.520\n I don't think that could ever be built in this universe.\n\n58:23.520 --> 58:24.840\n The question is just could we,\n\n58:24.840 --> 58:27.000\n does that hypothetically make sense?\n\n58:27.000 --> 58:29.360\n That's kind of a useful contrast class\n\n58:29.360 --> 58:31.800\n to raise questions like, why aren't we zombies?\n\n58:31.800 --> 58:33.840\n How does it come about that we're conscious?\n\n58:33.840 --> 58:34.960\n And we're not like that.\n\n58:34.960 --> 58:38.640\n But there are less extreme versions of this like robots,\n\n58:38.640 --> 58:41.560\n which are maybe not physically identical to us,\n\n58:41.560 --> 58:43.360\n maybe not even functionally identical to us.\n\n58:43.360 --> 58:45.360\n Maybe they've got a different architecture,\n\n58:45.360 --> 58:47.720\n but they can do a lot of sophisticated things,\n\n58:47.720 --> 58:51.160\n maybe carry on a conversation, but they're not conscious.\n\n58:51.160 --> 58:52.160\n And that's not so far out.\n\n58:52.160 --> 58:54.920\n We've got simple computer systems,\n\n58:54.920 --> 58:57.400\n at least tending in that direction now.\n\n58:57.400 --> 59:01.120\n And presumably this is gonna get more and more sophisticated\n\n59:01.120 --> 59:05.320\n over years to come where we may have some pretty,\n\n59:05.320 --> 59:07.240\n it's at least quite straightforward to conceive\n\n59:07.240 --> 59:11.160\n of some pretty sophisticated robot systems\n\n59:11.160 --> 59:14.800\n that can use language and be fairly high functioning\n\n59:14.800 --> 59:16.400\n without consciousness at all.\n\n59:16.400 --> 59:17.800\n Then I stipulate that.\n\n59:17.800 --> 59:21.600\n I mean, we've caused, there's this tricky question\n\n59:21.600 --> 59:23.680\n of how you would know whether they're conscious.\n\n59:23.680 --> 59:25.000\n But let's say we've somehow solved that.\n\n59:25.000 --> 59:27.120\n And we know that these high functioning robots\n\n59:27.120 --> 59:27.960\n aren't conscious.\n\n59:27.960 --> 59:30.240\n Then the question is, do they have moral status?\n\n59:30.240 --> 59:31.840\n Does it matter how we treat them?\n\n59:33.480 --> 59:35.760\n What does moral status mean, sir?\n\n59:35.760 --> 59:37.160\n Basically it's that question.\n\n59:37.160 --> 59:38.480\n Can they suffer?\n\n59:38.480 --> 59:41.040\n Does it matter how we treat them?\n\n59:41.040 --> 59:46.040\n For example, if I mistreat this glass, this cup\n\n59:46.040 --> 59:49.760\n by shattering it, then that's bad.\n\n59:49.760 --> 59:50.600\n Why is it bad though?\n\n59:50.600 --> 59:51.440\n It's gonna make a mess.\n\n59:51.440 --> 59:53.600\n It's gonna be annoying for me and my partner.\n\n59:53.600 --> 59:55.920\n And so it's not bad for the cup.\n\n59:55.920 --> 59:59.560\n No one would say the cup itself has moral status.\n\n59:59.560 --> 1:00:04.560\n Hey, you hurt the cup and that's doing it a moral harm.\n\n1:00:07.680 --> 1:00:09.880\n Likewise, plants, well, again, if they're not conscious,\n\n1:00:09.880 --> 1:00:11.960\n most people think by uprooting a plant,\n\n1:00:11.960 --> 1:00:13.520\n you're not harming it.\n\n1:00:13.520 --> 1:00:16.160\n But if a being is conscious on the other hand,\n\n1:00:16.160 --> 1:00:17.200\n then you are harming it.\n\n1:00:17.200 --> 1:00:22.200\n So Siri, or I dare not say the name of Alexa.\n\n1:00:24.960 --> 1:00:28.600\n Anyway, so we don't think we're morally harming Alexa\n\n1:00:28.600 --> 1:00:30.440\n by turning her off or disconnecting her\n\n1:00:30.440 --> 1:00:34.080\n or even destroying her, whether it's the system\n\n1:00:34.080 --> 1:00:36.160\n or the underlying software system,\n\n1:00:36.160 --> 1:00:39.040\n because we don't really think she's conscious.\n\n1:00:39.040 --> 1:00:42.400\n On the other hand, you move to like the disembodied being\n\n1:00:42.400 --> 1:00:45.520\n in the movie, her, Samantha,\n\n1:00:45.520 --> 1:00:47.480\n I guess she was kind of presented as conscious.\n\n1:00:47.480 --> 1:00:49.760\n And then if you destroyed her,\n\n1:00:49.760 --> 1:00:51.760\n you'd certainly be committing a serious harm.\n\n1:00:51.760 --> 1:00:55.200\n So I think our strong sense is if a being is conscious\n\n1:00:55.200 --> 1:00:57.440\n and can undergo subjective experiences,\n\n1:00:57.440 --> 1:01:00.360\n then it matters morally how we treat them.\n\n1:01:00.360 --> 1:01:03.040\n So if a robot is conscious, it matters,\n\n1:01:03.040 --> 1:01:05.360\n but if a robot is not conscious,\n\n1:01:05.360 --> 1:01:07.160\n then they're basically just meat or a machine\n\n1:01:07.160 --> 1:01:10.360\n and it doesn't matter.\n\n1:01:10.360 --> 1:01:13.000\n So I think at least maybe how we think about this stuff\n\n1:01:13.000 --> 1:01:13.960\n is fundamentally wrong,\n\n1:01:13.960 --> 1:01:15.480\n but I think a lot of people\n\n1:01:15.480 --> 1:01:17.200\n who think about this stuff seriously,\n\n1:01:17.200 --> 1:01:18.320\n including people who think about,\n\n1:01:18.320 --> 1:01:20.800\n say the moral treatment of animals and so on,\n\n1:01:20.800 --> 1:01:23.360\n come to the view that consciousness\n\n1:01:23.360 --> 1:01:25.760\n is ultimately kind of the line between systems\n\n1:01:25.760 --> 1:01:29.320\n that where we have to take them into account\n\n1:01:29.320 --> 1:01:32.240\n and thinking morally about how we act\n\n1:01:32.240 --> 1:01:34.440\n and systems for which we don't.\n\n1:01:34.440 --> 1:01:38.560\n And I think I've seen you the writer talk about\n\n1:01:38.560 --> 1:01:41.800\n the demonstration of consciousness from a system like that,\n\n1:01:41.800 --> 1:01:46.800\n from a system like Alexa or a conversational agent\n\n1:01:48.120 --> 1:01:51.160\n that what you would be looking for\n\n1:01:51.160 --> 1:01:54.600\n is kind of at the very basic level\n\n1:01:54.600 --> 1:01:58.160\n for the system to have an awareness\n\n1:01:58.160 --> 1:02:00.440\n that I'm just a program\n\n1:02:00.440 --> 1:02:03.880\n and yet, why do I experience this?\n\n1:02:03.880 --> 1:02:06.160\n Or not to have that experience,\n\n1:02:06.160 --> 1:02:08.000\n but to communicate that to you.\n\n1:02:08.000 --> 1:02:10.680\n So that's what us humans would sound like.\n\n1:02:10.680 --> 1:02:13.000\n If you all of a sudden woke up one day,\n\n1:02:13.000 --> 1:02:15.600\n like Kafka, right, in a body of a bug or something,\n\n1:02:15.600 --> 1:02:18.320\n but in a computer, you all of a sudden realized\n\n1:02:18.320 --> 1:02:19.720\n you don't have a body\n\n1:02:19.720 --> 1:02:22.480\n and yet you were feeling what you were feeling,\n\n1:02:22.480 --> 1:02:25.080\n you would probably say those kinds of things.\n\n1:02:25.920 --> 1:02:29.520\n So do you think a system essentially becomes conscious\n\n1:02:29.520 --> 1:02:33.080\n by convincing us that it's conscious\n\n1:02:34.400 --> 1:02:36.200\n through the words that I just mentioned?\n\n1:02:36.200 --> 1:02:40.080\n So by being confused about the fact\n\n1:02:40.080 --> 1:02:45.000\n that why am I having these experiences?\n\n1:02:45.000 --> 1:02:45.840\n So basically.\n\n1:02:45.840 --> 1:02:48.080\n I don't think this is what makes you conscious,\n\n1:02:48.080 --> 1:02:50.240\n but I do think being puzzled about consciousness\n\n1:02:50.240 --> 1:02:53.280\n is a very good sign that a system is conscious.\n\n1:02:53.280 --> 1:02:55.600\n So if I encountered a robot\n\n1:02:55.600 --> 1:02:58.640\n that actually seemed to be genuinely puzzled\n\n1:02:58.640 --> 1:03:01.280\n by its own mental states\n\n1:03:01.280 --> 1:03:04.000\n and saying, yeah, I have all these weird experiences\n\n1:03:04.000 --> 1:03:06.320\n and I don't see how to explain them.\n\n1:03:06.320 --> 1:03:08.720\n I know I'm just a set of silicon circuits,\n\n1:03:08.720 --> 1:03:11.600\n but I don't see how that would give you my consciousness.\n\n1:03:11.600 --> 1:03:13.840\n I would at least take that as some evidence\n\n1:03:13.840 --> 1:03:16.720\n that there's some consciousness going on there.\n\n1:03:16.720 --> 1:03:19.440\n I don't think a system needs to be puzzled\n\n1:03:19.440 --> 1:03:21.760\n about consciousness to be conscious.\n\n1:03:21.760 --> 1:03:24.000\n Many people aren't puzzled by their consciousness.\n\n1:03:24.000 --> 1:03:26.320\n Animals don't seem to be puzzled at all.\n\n1:03:26.320 --> 1:03:28.000\n I still think they're conscious.\n\n1:03:28.000 --> 1:03:30.680\n So I don't think that's a requirement on consciousness,\n\n1:03:30.680 --> 1:03:33.360\n but I do think if we're looking for signs\n\n1:03:33.360 --> 1:03:37.000\n for consciousness, say in AI systems,\n\n1:03:37.000 --> 1:03:39.120\n one of the things that will help convince me\n\n1:03:39.120 --> 1:03:42.920\n that an AI system is conscious is if it shows signs of,\n\n1:03:44.080 --> 1:03:47.360\n if it shows signs of introspectively recognizing something\n\n1:03:47.360 --> 1:03:51.280\n like consciousness and finding this philosophically puzzling\n\n1:03:51.280 --> 1:03:54.200\n in the way that we do.\n\n1:03:54.200 --> 1:03:55.920\n It's such an interesting thought, though,\n\n1:03:55.920 --> 1:03:57.920\n because a lot of people sort of would,\n\n1:03:57.920 --> 1:04:02.160\n at the Shao level, criticize the Turing test for language.\n\n1:04:02.160 --> 1:04:07.160\n It's essentially what I heard Dan Dennett\n\n1:04:07.600 --> 1:04:09.800\n criticize it in this kind of way,\n\n1:04:09.800 --> 1:04:13.280\n which is it really puts a lot of emphasis on lying.\n\n1:04:13.280 --> 1:04:17.080\n Yeah, and being able to imitate\n\n1:04:17.080 --> 1:04:20.480\n human beings, yeah, there's this cartoon\n\n1:04:20.480 --> 1:04:23.240\n of the AI system studying for the Turing test.\n\n1:04:23.240 --> 1:04:26.680\n It's gotta read this book called Talk Like a Human.\n\n1:04:26.680 --> 1:04:28.360\n It's like, man, why do I have to waste my time\n\n1:04:28.360 --> 1:04:30.480\n learning how to imitate humans?\n\n1:04:30.480 --> 1:04:32.280\n Maybe the AI system is gonna be way beyond\n\n1:04:32.280 --> 1:04:33.800\n the hard problem of consciousness,\n\n1:04:33.800 --> 1:04:34.760\n and it's gonna be just like,\n\n1:04:34.760 --> 1:04:36.400\n why do I need to waste my time pretending\n\n1:04:36.400 --> 1:04:39.000\n that I recognize the hard problem of consciousness\n\n1:04:40.120 --> 1:04:42.160\n in order for people to recognize me as conscious?\n\n1:04:42.160 --> 1:04:45.000\n Yeah, it just feels like, I guess the question is,\n\n1:04:45.000 --> 1:04:48.320\n do you think we can ever really create\n\n1:04:48.320 --> 1:04:49.440\n a test for consciousness?\n\n1:04:49.440 --> 1:04:53.920\n Because it feels like we're very human centric,\n\n1:04:53.920 --> 1:04:57.600\n and so the only way we would be convinced\n\n1:04:57.600 --> 1:05:00.880\n that something is conscious is basically\n\n1:05:00.880 --> 1:05:05.520\n the thing demonstrates the illusion of consciousness,\n\n1:05:06.440 --> 1:05:10.320\n that we can never really know whether it's conscious or not,\n\n1:05:10.320 --> 1:05:14.800\n and in fact, that almost feels like it doesn't matter then,\n\n1:05:14.800 --> 1:05:18.560\n or does it still matter to you that something is conscious\n\n1:05:18.560 --> 1:05:20.720\n or it demonstrates consciousness?\n\n1:05:20.720 --> 1:05:22.840\n You still see that fundamental distinction.\n\n1:05:22.840 --> 1:05:24.880\n I think to a lot of people,\n\n1:05:24.880 --> 1:05:27.400\n whether a system is conscious or not\n\n1:05:27.400 --> 1:05:28.920\n matters hugely for many things,\n\n1:05:28.920 --> 1:05:33.080\n like how we treat it, can it suffer, and so on,\n\n1:05:33.080 --> 1:05:35.080\n but still, that leaves open the question,\n\n1:05:35.080 --> 1:05:36.800\n how can we ever know?\n\n1:05:36.800 --> 1:05:38.480\n And it's true that it's awfully hard\n\n1:05:38.480 --> 1:05:40.600\n to see how we can know for sure\n\n1:05:40.600 --> 1:05:42.360\n whether a system is conscious.\n\n1:05:42.360 --> 1:05:44.880\n I suspect that sociologically,\n\n1:05:44.880 --> 1:05:46.280\n the thing that's gonna convince us\n\n1:05:46.280 --> 1:05:50.080\n that a system is conscious is, in part,\n\n1:05:50.080 --> 1:05:53.880\n things like social interaction, conversation, and so on,\n\n1:05:53.880 --> 1:05:56.040\n where they seem to be conscious,\n\n1:05:56.040 --> 1:05:57.680\n they talk about their conscious states\n\n1:05:57.680 --> 1:06:00.040\n or just talk about being happy or sad\n\n1:06:00.040 --> 1:06:02.800\n or finding things meaningful or being in pain.\n\n1:06:02.800 --> 1:06:06.640\n That will tend to convince us if we don't,\n\n1:06:06.640 --> 1:06:08.360\n if a system genuinely seems to be conscious,\n\n1:06:08.360 --> 1:06:10.000\n we don't treat it as such,\n\n1:06:10.000 --> 1:06:11.960\n eventually it's gonna seem like a strange form\n\n1:06:11.960 --> 1:06:14.720\n of racism or speciesism or somehow,\n\n1:06:14.720 --> 1:06:16.320\n not to acknowledge them as conscious.\n\n1:06:16.320 --> 1:06:17.760\n I truly believe that, by the way.\n\n1:06:17.760 --> 1:06:20.440\n I believe that there is going to be\n\n1:06:21.280 --> 1:06:23.240\n something akin to the Civil Rights Movement,\n\n1:06:23.240 --> 1:06:24.720\n but for robots.\n\n1:06:25.680 --> 1:06:30.000\n I think the moment you have a Roomba say,\n\n1:06:30.000 --> 1:06:32.840\n please don't kick me, that hurts, just say it.\n\n1:06:32.840 --> 1:06:33.840\n Yeah.\n\n1:06:33.840 --> 1:06:37.440\n I think that will fundamentally change\n\n1:06:37.440 --> 1:06:40.320\n the fabric of our society.\n\n1:06:40.320 --> 1:06:41.160\n I think you're probably right,\n\n1:06:41.160 --> 1:06:42.200\n although it's gonna be very tricky\n\n1:06:42.200 --> 1:06:44.920\n because, just say we've got the technology\n\n1:06:44.920 --> 1:06:47.240\n where these conscious beings can just be created\n\n1:06:47.240 --> 1:06:51.820\n and multiplied by the thousands by flicking a switch.\n\n1:06:54.280 --> 1:06:55.920\n The legal status is gonna be different,\n\n1:06:55.920 --> 1:06:58.100\n but ultimately their moral status ought to be the same,\n\n1:06:58.100 --> 1:07:02.880\n and yeah, the civil rights issue is gonna be a huge mess.\n\n1:07:03.680 --> 1:07:06.680\n So if one day somebody clones you,\n\n1:07:06.680 --> 1:07:10.520\n another very real possibility.\n\n1:07:10.520 --> 1:07:13.760\n In fact, I find the conversation between\n\n1:07:13.760 --> 1:07:18.760\n two copies of David Chalmers quite interesting.\n\n1:07:21.400 --> 1:07:22.240\n Very thought.\n\n1:07:22.240 --> 1:07:25.120\n Who is this idiot?\n\n1:07:25.120 --> 1:07:26.520\n He's not making any sense.\n\n1:07:26.520 --> 1:07:30.880\n So what, do you think he would be conscious?\n\n1:07:32.320 --> 1:07:34.480\n I do think he would be conscious.\n\n1:07:34.480 --> 1:07:35.760\n I do think in some sense,\n\n1:07:35.760 --> 1:07:37.000\n I'm not sure it would be me,\n\n1:07:37.000 --> 1:07:39.960\n there would be two different beings at this point.\n\n1:07:39.960 --> 1:07:41.240\n I think they'd both be conscious\n\n1:07:41.240 --> 1:07:45.800\n and they both have many of the same mental properties.\n\n1:07:45.800 --> 1:07:49.400\n I think they both in a way have the same moral status.\n\n1:07:49.400 --> 1:07:51.560\n It'd be wrong to hurt either of them\n\n1:07:51.560 --> 1:07:54.560\n or to kill them and so on.\n\n1:07:54.560 --> 1:07:55.960\n Still, there's some sense in which probably\n\n1:07:55.960 --> 1:07:58.480\n their legal status would have to be different.\n\n1:07:58.480 --> 1:08:01.600\n If I'm the original and that one's just a clone,\n\n1:08:01.600 --> 1:08:03.280\n then creating a clone of me,\n\n1:08:03.280 --> 1:08:05.000\n presumably the clone doesn't, for example,\n\n1:08:05.000 --> 1:08:08.600\n automatically own the stuff that I own\n\n1:08:08.600 --> 1:08:13.600\n or I've got a certain connect,\n\n1:08:14.400 --> 1:08:16.400\n the things that the people I interact with,\n\n1:08:16.400 --> 1:08:19.120\n my family, my partner and so on,\n\n1:08:19.120 --> 1:08:21.120\n I'm gonna somehow be connected to them\n\n1:08:21.120 --> 1:08:24.560\n in a way in which the clone isn't, so.\n\n1:08:24.560 --> 1:08:26.400\n Because you came slightly first?\n\n1:08:26.400 --> 1:08:27.240\n Yeah.\n\n1:08:27.240 --> 1:08:30.040\n Because a clone would argue that they have\n\n1:08:31.320 --> 1:08:33.680\n really as much of a connection.\n\n1:08:33.680 --> 1:08:35.600\n They have all the memories of that connection.\n\n1:08:35.600 --> 1:08:37.920\n Then a way you might say it's kind of unfair\n\n1:08:37.920 --> 1:08:38.920\n to discriminate against them,\n\n1:08:38.920 --> 1:08:40.080\n but say you've got an apartment\n\n1:08:40.080 --> 1:08:41.440\n that only one person can live in\n\n1:08:41.440 --> 1:08:44.000\n or a partner who only one person can be with.\n\n1:08:44.000 --> 1:08:47.320\n But why should it be you, the original?\n\n1:08:47.320 --> 1:08:49.080\n It's an interesting philosophical question,\n\n1:08:49.080 --> 1:08:51.960\n but you might say because I actually have this history,\n\n1:08:53.160 --> 1:08:56.880\n if I am the same person as the one that came before\n\n1:08:56.880 --> 1:08:58.480\n and the clone is not,\n\n1:08:58.480 --> 1:09:01.000\n then I have this history that the clone doesn't.\n\n1:09:01.000 --> 1:09:03.880\n Of course, there's also the question,\n\n1:09:03.880 --> 1:09:05.840\n isn't the clone the same person too?\n\n1:09:05.840 --> 1:09:07.560\n This is a question about personal identity.\n\n1:09:07.560 --> 1:09:10.720\n If I continue and I create a clone over there,\n\n1:09:10.720 --> 1:09:14.120\n I wanna say this one is me and this one is someone else.\n\n1:09:14.120 --> 1:09:17.960\n But you could take the view that a clone is equally me.\n\n1:09:17.960 --> 1:09:20.120\n Of course, in a movie like Star Trek\n\n1:09:20.120 --> 1:09:21.320\n where they have a teletransporter\n\n1:09:21.320 --> 1:09:23.480\n basically creates clones all the time.\n\n1:09:23.480 --> 1:09:25.960\n They treat the clones as if they're the original person.\n\n1:09:25.960 --> 1:09:29.240\n Of course, they destroy the original body in Star Trek.\n\n1:09:29.240 --> 1:09:31.000\n So there's only one left around\n\n1:09:31.000 --> 1:09:32.720\n and only very occasionally do things go wrong\n\n1:09:32.720 --> 1:09:34.680\n and you get two copies of Captain Kirk.\n\n1:09:35.840 --> 1:09:37.800\n But somehow our legal system at the very least\n\n1:09:37.800 --> 1:09:40.640\n is gonna have to sort out some of these issues\n\n1:09:40.640 --> 1:09:42.200\n and that maybe that's what's moral\n\n1:09:42.200 --> 1:09:45.920\n and what's legally acceptable are gonna come apart.\n\n1:09:47.360 --> 1:09:50.720\n What question would you ask a clone of yourself?\n\n1:09:52.160 --> 1:09:56.120\n Is there something useful you can find out from him\n\n1:09:56.120 --> 1:10:00.600\n about the fundamentals of consciousness even?\n\n1:10:00.600 --> 1:10:03.840\n I mean, kind of in principle,\n\n1:10:03.840 --> 1:10:06.720\n I know that if it's a perfect clone,\n\n1:10:06.720 --> 1:10:09.080\n it's gonna behave just like me.\n\n1:10:09.080 --> 1:10:11.360\n So I'm not sure I'm gonna be able to,\n\n1:10:11.360 --> 1:10:13.160\n I can discover whether it's a perfect clone\n\n1:10:13.160 --> 1:10:15.240\n by seeing whether it answers like me.\n\n1:10:15.240 --> 1:10:18.000\n But otherwise I know what I'm gonna find is a being\n\n1:10:18.000 --> 1:10:19.440\n which is just like me,\n\n1:10:19.440 --> 1:10:21.960\n except that it's just undergone this great shock\n\n1:10:21.960 --> 1:10:24.480\n of discovering that it's a clone.\n\n1:10:24.480 --> 1:10:26.520\n So just say you woke me up tomorrow and said,\n\n1:10:26.520 --> 1:10:29.120\n hey Dave, sorry to tell you this,\n\n1:10:29.120 --> 1:10:31.880\n but you're actually the clone\n\n1:10:31.880 --> 1:10:34.280\n and you provided me really convincing evidence,\n\n1:10:34.280 --> 1:10:36.920\n showed me the film of my being cloned\n\n1:10:36.920 --> 1:10:41.360\n and then all wrapped in here being here and waking up.\n\n1:10:41.360 --> 1:10:42.440\n So you proved to me I'm a clone,\n\n1:10:42.440 --> 1:10:44.560\n well, yeah, okay, I would find that shocking\n\n1:10:44.560 --> 1:10:46.480\n and who knows how I would react to this.\n\n1:10:46.480 --> 1:10:48.640\n So maybe by talking to the clone,\n\n1:10:48.640 --> 1:10:50.880\n I'd find something about my own psychology\n\n1:10:50.880 --> 1:10:52.600\n that I can't find out so easily,\n\n1:10:52.600 --> 1:10:55.440\n like how I'd react upon discovering that I'm a clone.\n\n1:10:55.440 --> 1:10:57.840\n I could certainly ask the clone if it's conscious\n\n1:10:57.840 --> 1:10:59.840\n and what his consciousness is like and so on,\n\n1:10:59.840 --> 1:11:02.680\n but I guess I kind of know if it's a perfect clone,\n\n1:11:02.680 --> 1:11:04.520\n it's gonna behave roughly like me.\n\n1:11:04.520 --> 1:11:06.200\n Of course, at the beginning,\n\n1:11:06.200 --> 1:11:07.040\n there'll be a question\n\n1:11:07.040 --> 1:11:08.880\n about whether a perfect clone is possible.\n\n1:11:08.880 --> 1:11:11.120\n So I may wanna ask it lots of questions\n\n1:11:11.120 --> 1:11:12.400\n to see if it's consciousness\n\n1:11:12.400 --> 1:11:14.600\n and the way it talks about its consciousness\n\n1:11:14.600 --> 1:11:17.560\n and the way it reacts to things in general is likely.\n\n1:11:17.560 --> 1:11:22.400\n And that will occupy us for a while.\n\n1:11:22.400 --> 1:11:25.840\n So basic unit testing on the early models.\n\n1:11:25.840 --> 1:11:28.520\n So if it's a perfect clone,\n\n1:11:28.520 --> 1:11:30.760\n you say that it's gonna behave exactly like you.\n\n1:11:30.760 --> 1:11:32.520\n So that takes us to free will.\n\n1:11:35.640 --> 1:11:37.400\n Is there free will?\n\n1:11:37.400 --> 1:11:41.440\n Are we able to make decisions that are not predetermined\n\n1:11:41.440 --> 1:11:44.880\n from the initial conditions of the universe?\n\n1:11:44.880 --> 1:11:46.680\n You know, philosophers do this annoying thing\n\n1:11:46.680 --> 1:11:48.720\n of saying it depends what you mean.\n\n1:11:48.720 --> 1:11:52.360\n So in this case, yeah, it really depends on what you mean,\n\n1:11:52.360 --> 1:11:54.480\n by free will.\n\n1:11:54.480 --> 1:11:58.680\n If you mean something which was not determined in advance,\n\n1:11:58.680 --> 1:12:00.560\n could never have been determined,\n\n1:12:00.560 --> 1:12:02.240\n then I don't know we have free will.\n\n1:12:02.240 --> 1:12:03.640\n I mean, there's quantum mechanics\n\n1:12:03.640 --> 1:12:06.160\n and who's to say if that opens up some room,\n\n1:12:06.160 --> 1:12:09.560\n but I'm not sure we have free will in that sense.\n\n1:12:09.560 --> 1:12:12.280\n But I'm also not sure that's the kind of free will\n\n1:12:12.280 --> 1:12:13.840\n that really matters.\n\n1:12:13.840 --> 1:12:15.720\n You know, what matters to us\n\n1:12:15.720 --> 1:12:17.160\n is being able to do what we want\n\n1:12:17.160 --> 1:12:19.800\n and to create our own futures.\n\n1:12:19.800 --> 1:12:21.520\n We've got this distinction between having our lives\n\n1:12:21.520 --> 1:12:26.520\n be under our control and under someone else's control.\n\n1:12:26.680 --> 1:12:29.440\n We've got the sense of actions that we are responsible for\n\n1:12:29.440 --> 1:12:31.160\n versus ones that we're not.\n\n1:12:31.160 --> 1:12:33.760\n I think you can make those distinctions\n\n1:12:33.760 --> 1:12:36.400\n even in a deterministic universe.\n\n1:12:36.400 --> 1:12:38.280\n And this is what people call the compatibilist view\n\n1:12:38.280 --> 1:12:41.240\n of free will, where it's compatible with determinism.\n\n1:12:41.240 --> 1:12:42.880\n So I think for many purposes,\n\n1:12:42.880 --> 1:12:45.520\n the kind of free will that matters\n\n1:12:45.520 --> 1:12:48.080\n is something we can have in a deterministic universe.\n\n1:12:48.080 --> 1:12:50.440\n And I can't see any reason in principle\n\n1:12:50.440 --> 1:12:54.440\n why an AI system couldn't have free will of that kind.\n\n1:12:54.440 --> 1:12:55.840\n If you mean super duper free will,\n\n1:12:55.840 --> 1:12:57.720\n the ability to violate the laws of physics\n\n1:12:57.720 --> 1:13:01.760\n and doing things that in principle could not be predicted.\n\n1:13:01.760 --> 1:13:04.680\n I don't know, maybe no one has that kind of free will.\n\n1:13:04.680 --> 1:13:09.680\n What's the connection between the reality of free will\n\n1:13:10.040 --> 1:13:11.400\n and the experience of it,\n\n1:13:11.400 --> 1:13:15.240\n the subjective experience in your view?\n\n1:13:15.240 --> 1:13:17.000\n So how does consciousness connect\n\n1:13:17.000 --> 1:13:22.000\n to the reality and the experience of free will?\n\n1:13:22.240 --> 1:13:24.800\n It's certainly true that when we make decisions\n\n1:13:24.800 --> 1:13:26.200\n and when we choose and so on,\n\n1:13:26.200 --> 1:13:28.440\n we feel like we have an open future.\n\n1:13:28.440 --> 1:13:32.440\n Feel like I could do this, I could go into philosophy\n\n1:13:32.440 --> 1:13:36.080\n or I could go into math, I could go to a movie tonight,\n\n1:13:36.080 --> 1:13:38.080\n I could go to a restaurant.\n\n1:13:39.280 --> 1:13:42.600\n So we experience these things as if the future is open.\n\n1:13:42.600 --> 1:13:44.520\n And maybe we experience ourselves\n\n1:13:44.520 --> 1:13:49.520\n as exerting a kind of effect on the future\n\n1:13:50.040 --> 1:13:51.680\n that somehow picking out one path\n\n1:13:51.680 --> 1:13:54.200\n from many paths were previously open.\n\n1:13:54.200 --> 1:13:56.080\n And you might think that actually\n\n1:13:56.080 --> 1:13:58.080\n if we're in a deterministic universe,\n\n1:13:58.080 --> 1:13:59.880\n there's a sense of which objectively\n\n1:13:59.880 --> 1:14:03.720\n those paths weren't really open all along,\n\n1:14:03.720 --> 1:14:05.800\n but subjectively they were open.\n\n1:14:05.800 --> 1:14:07.320\n And that's, I think that's what really matters\n\n1:14:07.320 --> 1:14:09.440\n in making a decisions where our experience\n\n1:14:09.440 --> 1:14:14.320\n of making a decision is choosing a path for ourselves.\n\n1:14:14.320 --> 1:14:18.120\n I mean, in general, our introspective models of the mind,\n\n1:14:18.120 --> 1:14:20.600\n I think are generally very distorted representations\n\n1:14:20.600 --> 1:14:21.600\n of the mind.\n\n1:14:21.600 --> 1:14:24.200\n So it may well be that our experience of ourself\n\n1:14:24.200 --> 1:14:27.600\n in making a decision, our experience of what's going on\n\n1:14:27.600 --> 1:14:31.000\n doesn't terribly well mirror what's going on.\n\n1:14:31.000 --> 1:14:33.160\n I mean, maybe there are antecedents in the brain\n\n1:14:33.160 --> 1:14:35.200\n way before anything came into consciousness\n\n1:14:37.760 --> 1:14:39.000\n and so on.\n\n1:14:39.000 --> 1:14:41.720\n Those aren't represented in our introspective model.\n\n1:14:41.720 --> 1:14:45.880\n So in general, our experience of perception,\n\n1:14:46.960 --> 1:14:50.600\n so I experience a perceptual image of the external world.\n\n1:14:50.600 --> 1:14:53.360\n It's not a terribly good model of what's actually going on\n\n1:14:53.360 --> 1:14:55.640\n in my visual cortex and so on,\n\n1:14:55.640 --> 1:14:57.080\n which has all these layers and so on.\n\n1:14:57.080 --> 1:14:59.800\n It's just one little snapshot of one bit of that.\n\n1:14:59.800 --> 1:15:02.440\n So in general, introspective models\n\n1:15:02.440 --> 1:15:05.240\n are very over oversimplified.\n\n1:15:05.240 --> 1:15:07.200\n And it wouldn't be surprising\n\n1:15:07.200 --> 1:15:09.160\n if that was true of free will as well.\n\n1:15:09.160 --> 1:15:12.640\n This also incidentally can be applied to consciousness itself.\n\n1:15:12.640 --> 1:15:13.960\n There is this very interesting view\n\n1:15:13.960 --> 1:15:17.520\n that consciousness itself is an introspective illusion.\n\n1:15:17.520 --> 1:15:19.440\n In fact, we're not conscious,\n\n1:15:19.440 --> 1:15:24.280\n but the brain just has these introspective models of itself\n\n1:15:24.280 --> 1:15:27.160\n or oversimplifies everything and represents itself\n\n1:15:27.160 --> 1:15:31.040\n as having these special properties of consciousness.\n\n1:15:31.040 --> 1:15:33.840\n It's a really simple way to kind of keep track of itself\n\n1:15:33.840 --> 1:15:34.680\n and so on.\n\n1:15:34.680 --> 1:15:36.920\n And then on the illusionist view,\n\n1:15:36.920 --> 1:15:39.880\n yeah, that's just an illusion.\n\n1:15:39.880 --> 1:15:42.240\n I find this view, when I find it implausible,\n\n1:15:42.240 --> 1:15:44.840\n I do find it very attractive in some ways,\n\n1:15:44.840 --> 1:15:46.640\n because it's easy to tell some story\n\n1:15:46.640 --> 1:15:50.120\n about how the brain would create introspective models\n\n1:15:50.120 --> 1:15:53.120\n of its own consciousness, of its own free will\n\n1:15:53.120 --> 1:15:55.480\n as a way of simplifying itself.\n\n1:15:55.480 --> 1:15:57.680\n I mean, it's a similar way when we perceive\n\n1:15:57.680 --> 1:16:00.040\n the external world, we perceive it as having these colors\n\n1:16:00.040 --> 1:16:02.720\n that maybe it doesn't really have,\n\n1:16:02.720 --> 1:16:04.280\n but of course that's a really useful way\n\n1:16:04.280 --> 1:16:06.440\n of keeping tracks, of keeping track.\n\n1:16:06.440 --> 1:16:08.960\n Did you say that you find it not very plausible?\n\n1:16:08.960 --> 1:16:11.880\n Because I find it both plausible\n\n1:16:11.880 --> 1:16:14.120\n and attractive in some sense,\n\n1:16:14.120 --> 1:16:18.920\n because I mean, that kind of view\n\n1:16:18.920 --> 1:16:23.920\n is one that has the minimum amount of mystery around it.\n\n1:16:25.040 --> 1:16:28.960\n You can kind of understand that kind of view.\n\n1:16:28.960 --> 1:16:31.960\n Everything else says we don't understand\n\n1:16:31.960 --> 1:16:33.920\n so much of this picture.\n\n1:16:33.920 --> 1:16:36.800\n No, it is very attractive, I recently wrote an article\n\n1:16:36.800 --> 1:16:38.600\n about this kind of issue called\n\n1:16:38.600 --> 1:16:41.280\n the meta problem of consciousness.\n\n1:16:41.280 --> 1:16:43.200\n The hard problem is how does a brain\n\n1:16:43.200 --> 1:16:44.200\n give you consciousness?\n\n1:16:44.200 --> 1:16:46.720\n The meta problem is why are we puzzled\n\n1:16:46.720 --> 1:16:49.600\n by the hard problem of consciousness?\n\n1:16:49.600 --> 1:16:50.960\n Because being puzzled by it,\n\n1:16:50.960 --> 1:16:53.000\n that's ultimately a bit of behavior.\n\n1:16:53.000 --> 1:16:54.880\n We might be able to explain that bit of behavior\n\n1:16:54.880 --> 1:16:57.560\n as one of the easy problems, consciousness.\n\n1:16:57.560 --> 1:17:00.560\n So maybe there'll be some computational model\n\n1:17:00.560 --> 1:17:03.440\n that explains why we're puzzled by consciousness.\n\n1:17:03.440 --> 1:17:05.800\n The meta problem has come up with that model.\n\n1:17:05.800 --> 1:17:07.880\n And I've been thinking about that a lot lately.\n\n1:17:07.880 --> 1:17:09.560\n There's some interesting stories you can tell\n\n1:17:09.560 --> 1:17:13.600\n about why the right kind of computational system\n\n1:17:13.600 --> 1:17:17.640\n might develop these introspective models of itself\n\n1:17:17.640 --> 1:17:20.680\n that attributed itself, these special properties.\n\n1:17:21.560 --> 1:17:25.320\n So that meta problem is a research program for everyone.\n\n1:17:25.320 --> 1:17:27.000\n And then if you've got attraction\n\n1:17:27.000 --> 1:17:31.320\n to sort of simple views, desert landscapes and so on,\n\n1:17:31.320 --> 1:17:32.240\n then you can go all the way\n\n1:17:32.240 --> 1:17:34.240\n with what people call illusionism\n\n1:17:34.240 --> 1:17:37.760\n and say, in fact, consciousness itself is not real.\n\n1:17:37.760 --> 1:17:42.400\n What is real is just these introspective models\n\n1:17:42.400 --> 1:17:45.040\n we have that tell us that we're conscious.\n\n1:17:46.000 --> 1:17:49.600\n So the view is very simple, very attractive, very powerful.\n\n1:17:49.600 --> 1:17:51.240\n The trouble is, of course, it has to say\n\n1:17:51.240 --> 1:17:55.160\n that deep down, consciousness is not real.\n\n1:17:55.160 --> 1:17:57.960\n We're not actually experiencing right now.\n\n1:17:57.960 --> 1:17:59.960\n And it looks like it's just contradicting\n\n1:17:59.960 --> 1:18:02.360\n a fundamental datum of our existence.\n\n1:18:02.360 --> 1:18:06.080\n And this is why most people find this view crazy.\n\n1:18:06.080 --> 1:18:08.760\n Just as they find panpsychism crazy in one way,\n\n1:18:08.760 --> 1:18:13.240\n people find illusionism crazy in another way.\n\n1:18:13.240 --> 1:18:18.000\n But I mean, so yes, it has to deny\n\n1:18:18.000 --> 1:18:20.640\n this fundamental datum of our existence.\n\n1:18:20.640 --> 1:18:24.680\n Now, that makes the view sort of frankly unbelievable\n\n1:18:24.680 --> 1:18:25.520\n for most people.\n\n1:18:25.520 --> 1:18:28.200\n On the other hand, the view developed right\n\n1:18:28.200 --> 1:18:31.280\n might be able to explain why we find it unbelievable.\n\n1:18:31.280 --> 1:18:34.280\n Because these models are so deeply hardwired into our head.\n\n1:18:34.280 --> 1:18:36.000\n And they're all integrated.\n\n1:18:36.000 --> 1:18:38.480\n You can't escape the illusion.\n\n1:18:38.480 --> 1:18:40.720\n And it's a crazy possibility.\n\n1:18:40.720 --> 1:18:43.640\n Is it possible that the entirety of the universe,\n\n1:18:43.640 --> 1:18:46.760\n our planet, all the people in New York,\n\n1:18:46.760 --> 1:18:48.520\n all the organisms on our planet,\n\n1:18:49.800 --> 1:18:54.440\n including me here today, are not real in that sense?\n\n1:18:54.440 --> 1:18:59.440\n They're all part of an illusion inside of Dave Chalmers's head.\n\n1:18:59.800 --> 1:19:02.320\n I think all this could be a simulation.\n\n1:19:02.320 --> 1:19:04.960\n No, but not just a simulation.\n\n1:19:04.960 --> 1:19:09.200\n Because the simulation kind of is outside of you.\n\n1:19:09.200 --> 1:19:10.120\n A dream?\n\n1:19:10.120 --> 1:19:12.040\n What if it's all an illusion?\n\n1:19:12.040 --> 1:19:14.560\n Yes, a dream that you're experiencing.\n\n1:19:14.560 --> 1:19:18.880\n That's, it's all in your mind, right?\n\n1:19:18.880 --> 1:19:23.040\n Is that, can you take illusionism that far?\n\n1:19:23.040 --> 1:19:26.840\n Well, there's illusionism about the external world\n\n1:19:26.840 --> 1:19:28.440\n and illusionism about consciousness.\n\n1:19:28.440 --> 1:19:30.200\n And these might go in different.\n\n1:19:30.200 --> 1:19:31.800\n Illusionism about the external world\n\n1:19:31.800 --> 1:19:34.120\n kind of takes you back to Descartes.\n\n1:19:34.120 --> 1:19:37.400\n And yeah, could all this be produced by an evil demon?\n\n1:19:37.400 --> 1:19:39.560\n Descartes himself also had the dream argument.\n\n1:19:39.560 --> 1:19:42.040\n He said, how do you know you're not dreaming right now?\n\n1:19:42.040 --> 1:19:43.720\n How do you know this is not an amazing dream?\n\n1:19:43.720 --> 1:19:46.320\n And it's at least a possibility that yeah,\n\n1:19:46.320 --> 1:19:49.840\n this could be some super duper complex dream\n\n1:19:49.840 --> 1:19:51.640\n in the next universe up.\n\n1:19:51.640 --> 1:19:56.320\n I guess though, my attitude is that just as,\n\n1:19:57.200 --> 1:20:00.520\n when Descartes thought that if the evil demon was doing it,\n\n1:20:00.520 --> 1:20:01.440\n it's not real.\n\n1:20:01.440 --> 1:20:04.360\n A lot of people these days say if a simulation is doing it,\n\n1:20:04.360 --> 1:20:05.560\n it's not real.\n\n1:20:05.560 --> 1:20:08.040\n As I was saying before, I think even if it's a simulation,\n\n1:20:08.040 --> 1:20:09.400\n that doesn't stop this from being real.\n\n1:20:09.400 --> 1:20:11.440\n It just tells us what the world is made of.\n\n1:20:11.440 --> 1:20:12.960\n Likewise, if it's a dream,\n\n1:20:12.960 --> 1:20:15.840\n it could turn out that all this is like my dream\n\n1:20:15.840 --> 1:20:19.080\n created by my brain in the next universe up.\n\n1:20:19.080 --> 1:20:21.920\n My own view is that wouldn't stop this physical world\n\n1:20:21.920 --> 1:20:22.760\n from being real.\n\n1:20:22.760 --> 1:20:26.040\n It would turn out this cup at the most fundamental level\n\n1:20:26.040 --> 1:20:28.880\n was made of a bit of say my consciousness\n\n1:20:28.880 --> 1:20:31.920\n in the dreaming mind at the next level up.\n\n1:20:31.920 --> 1:20:35.400\n Maybe that would give you a kind of weird kind of panpsychism\n\n1:20:35.400 --> 1:20:39.360\n about reality, but it wouldn't show that the cup isn't real.\n\n1:20:39.360 --> 1:20:42.120\n It would just tell us it's ultimately made of processes\n\n1:20:42.120 --> 1:20:43.200\n in my dreaming mind.\n\n1:20:43.200 --> 1:20:48.200\n So I'd resist the idea that if the physical world is a dream,\n\n1:20:48.200 --> 1:20:50.640\n then it's an illusion.\n\n1:20:50.640 --> 1:20:52.200\n That's right.\n\n1:20:52.200 --> 1:20:54.960\n By the way, perhaps you have an interesting thought\n\n1:20:54.960 --> 1:20:55.800\n about it.\n\n1:20:55.800 --> 1:21:00.320\n Why is Descartes demon or genius considered evil?\n\n1:21:02.200 --> 1:21:04.560\n Why couldn't have been a benevolent one\n\n1:21:04.560 --> 1:21:05.840\n that had the same powers?\n\n1:21:05.840 --> 1:21:08.800\n Yeah, I mean, Descartes called it the malign genie,\n\n1:21:08.800 --> 1:21:12.240\n the evil genie or evil genius.\n\n1:21:12.240 --> 1:21:14.280\n Malign, I guess was the word.\n\n1:21:14.280 --> 1:21:15.880\n But yeah, it's an interesting question.\n\n1:21:15.880 --> 1:21:20.600\n I mean, a later philosophy, Barclay said,\n\n1:21:20.600 --> 1:21:25.400\n no, in fact, all this is done by God.\n\n1:21:25.400 --> 1:21:30.400\n God actually supplies you all of these perceptions\n\n1:21:30.400 --> 1:21:33.880\n and ideas and that's how physical reality is sustained.\n\n1:21:33.880 --> 1:21:36.840\n And interestingly, Barclay's God is doing something\n\n1:21:36.840 --> 1:21:38.160\n that doesn't look so different\n\n1:21:38.160 --> 1:21:41.200\n from what Descartes evil demon was doing.\n\n1:21:41.200 --> 1:21:43.560\n It's just that Descartes thought it was deception\n\n1:21:43.560 --> 1:21:46.240\n and Barclay thought it was not.\n\n1:21:46.240 --> 1:21:49.360\n And I'm actually more sympathetic to Barclay here.\n\n1:21:51.000 --> 1:21:54.800\n Yeah, this evil demon may be trying to deceive you,\n\n1:21:54.800 --> 1:21:56.800\n but I think, okay, well, the evil demon\n\n1:21:56.800 --> 1:22:01.200\n may just be working under a false philosophical theory.\n\n1:22:01.200 --> 1:22:02.800\n It thinks it's deceiving you, it's wrong.\n\n1:22:02.800 --> 1:22:04.200\n It's like there's machines in the matrix.\n\n1:22:04.200 --> 1:22:06.120\n They thought they were deceiving you\n\n1:22:06.120 --> 1:22:07.040\n that all this stuff is real.\n\n1:22:07.040 --> 1:22:11.600\n I think, no, if we're in a matrix, it's all still real.\n\n1:22:11.600 --> 1:22:15.080\n Yeah, the philosopher O.K. Bousma had a nice story\n\n1:22:15.080 --> 1:22:19.000\n about this about 50 years ago, about Descartes evil demon,\n\n1:22:19.000 --> 1:22:21.600\n where he said this demon spends all its time\n\n1:22:21.600 --> 1:22:24.560\n trying to fool people, but fails\n\n1:22:24.560 --> 1:22:26.600\n because somehow all the demon ends up doing\n\n1:22:26.600 --> 1:22:30.160\n is constructing realities for people.\n\n1:22:30.160 --> 1:22:33.000\n So yeah, I think that maybe it's a very natural\n\n1:22:33.000 --> 1:22:35.040\n to take this view that if we're in a simulation\n\n1:22:35.040 --> 1:22:38.560\n or evil demon scenario or something,\n\n1:22:38.560 --> 1:22:40.640\n then none of this is real.\n\n1:22:40.640 --> 1:22:43.760\n But I think it may be ultimately a philosophical mistake,\n\n1:22:43.760 --> 1:22:46.640\n especially if you take on board sort of the view of reality\n\n1:22:46.640 --> 1:22:50.000\n where what matters to reality is really its structure,\n\n1:22:50.000 --> 1:22:52.800\n something like its mathematical structure and so on,\n\n1:22:52.800 --> 1:22:54.600\n which seems to be the view that a lot of people take\n\n1:22:54.600 --> 1:22:56.360\n from contemporary physics.\n\n1:22:56.360 --> 1:22:57.960\n And it looks like you can find\n\n1:22:57.960 --> 1:23:01.320\n all that mathematical structure in a simulation,\n\n1:23:01.320 --> 1:23:03.520\n maybe even in a dream and so on.\n\n1:23:03.520 --> 1:23:05.400\n So as long as that structure is real,\n\n1:23:05.400 --> 1:23:08.640\n I would say that's enough for the physical world to be real.\n\n1:23:08.640 --> 1:23:10.040\n Yeah, the physical world may turn out\n\n1:23:10.040 --> 1:23:13.120\n to be somewhat more intangible than we had thought\n\n1:23:13.120 --> 1:23:15.240\n and have a surprising nature of it.\n\n1:23:15.240 --> 1:23:18.120\n We're already gotten very used to that from modern science.\n\n1:23:19.560 --> 1:23:21.120\n See, you've kind of alluded\n\n1:23:21.120 --> 1:23:23.160\n that you don't have to have consciousness\n\n1:23:23.160 --> 1:23:25.440\n for high levels of intelligence,\n\n1:23:25.440 --> 1:23:29.840\n but to create truly general intelligence systems,\n\n1:23:29.840 --> 1:23:32.320\n AGI systems at human level intelligence\n\n1:23:32.320 --> 1:23:34.960\n and perhaps super human level intelligence,\n\n1:23:34.960 --> 1:23:37.040\n you've talked about that you feel like\n\n1:23:37.040 --> 1:23:38.960\n that kind of thing might be very far away,\n\n1:23:38.960 --> 1:23:43.440\n but nevertheless, when we reached that point,\n\n1:23:43.440 --> 1:23:46.040\n do you think consciousness\n\n1:23:46.040 --> 1:23:49.440\n from an engineering perspective is needed\n\n1:23:49.440 --> 1:23:53.400\n or at least highly beneficial for creating an AGI system?\n\n1:23:54.440 --> 1:23:57.680\n Yeah, no one knows what consciousness is for functionally.\n\n1:23:57.680 --> 1:24:00.880\n So right now there's no specific thing we can point to\n\n1:24:00.880 --> 1:24:05.160\n and say, you need consciousness for that.\n\n1:24:05.160 --> 1:24:06.560\n So my inclination is to believe\n\n1:24:06.560 --> 1:24:09.320\n that in principle AGI is possible.\n\n1:24:09.320 --> 1:24:11.240\n The very least I don't see why\n\n1:24:11.240 --> 1:24:13.240\n someone couldn't simulate a brain,\n\n1:24:13.240 --> 1:24:16.120\n ultimately have a computational system\n\n1:24:16.120 --> 1:24:18.240\n that produces all of our behavior.\n\n1:24:18.240 --> 1:24:19.440\n And if that's possible,\n\n1:24:19.440 --> 1:24:22.800\n I'm sure vastly many other computational systems\n\n1:24:22.800 --> 1:24:27.160\n of equal or greater sophistication are possible\n\n1:24:27.160 --> 1:24:29.400\n with all of our cognitive functions and more.\n\n1:24:29.400 --> 1:24:31.160\n My inclination is to think that\n\n1:24:32.280 --> 1:24:35.400\n once you've got all these cognitive functions,\n\n1:24:35.400 --> 1:24:39.720\n perception, attention, reasoning,\n\n1:24:39.720 --> 1:24:44.440\n introspection, language, emotion, and so on,\n\n1:24:44.440 --> 1:24:49.160\n it's very likely you'll have consciousness as well.\n\n1:24:49.160 --> 1:24:50.600\n So at least it's very hard for me to see\n\n1:24:50.600 --> 1:24:52.720\n how you'd have a system that had all those things\n\n1:24:52.720 --> 1:24:55.640\n while bypassing somehow conscious.\n\n1:24:55.640 --> 1:25:00.160\n So just naturally it's integrated quite naturally.\n\n1:25:00.160 --> 1:25:02.960\n There's a lot of overlap about the kind of function\n\n1:25:02.960 --> 1:25:04.840\n that required to achieve each of those things\n\n1:25:04.840 --> 1:25:07.640\n that's, so you can't disentangle them\n\n1:25:07.640 --> 1:25:08.480\n even when you're recreating.\n\n1:25:08.480 --> 1:25:09.680\n It seems to, at least in us,\n\n1:25:09.680 --> 1:25:13.320\n but we don't know what the causal role of consciousness\n\n1:25:13.320 --> 1:25:14.600\n in the physical world, what it does.\n\n1:25:14.600 --> 1:25:15.960\n I mean, just say it turns out\n\n1:25:15.960 --> 1:25:17.720\n consciousness does something very specific\n\n1:25:17.720 --> 1:25:20.560\n in the physical world like collapsing wave functions\n\n1:25:20.560 --> 1:25:24.240\n as on one common interpretation of quantum mechanics.\n\n1:25:24.240 --> 1:25:25.680\n Then ultimately we might find some place\n\n1:25:25.680 --> 1:25:27.560\n where it actually makes a difference\n\n1:25:27.560 --> 1:25:28.680\n and we could say, ah,\n\n1:25:28.680 --> 1:25:30.520\n here is where in collapsing wave functions\n\n1:25:30.520 --> 1:25:32.760\n it's driving the behavior of a system.\n\n1:25:32.760 --> 1:25:37.080\n And maybe it could even turn out that for AGI,\n\n1:25:37.080 --> 1:25:39.200\n you'd need something playing that.\n\n1:25:39.200 --> 1:25:41.200\n I mean, if you wanted to connect this to free will,\n\n1:25:41.200 --> 1:25:43.520\n some people think consciousness collapsing wave functions,\n\n1:25:43.520 --> 1:25:47.640\n that would be how the conscious mind exerts effect\n\n1:25:47.640 --> 1:25:50.440\n on the physical world and exerts its free will.\n\n1:25:50.440 --> 1:25:53.520\n And maybe it could turn out that any AGI\n\n1:25:53.520 --> 1:25:56.680\n that didn't utilize that mechanism would be limited\n\n1:25:56.680 --> 1:25:59.760\n in the kinds of functionality that it had.\n\n1:25:59.760 --> 1:26:02.240\n I don't myself find that plausible.\n\n1:26:02.240 --> 1:26:05.000\n I think probably that functionality could be simulated.\n\n1:26:05.000 --> 1:26:07.760\n But you can imagine once we had a very specific idea\n\n1:26:07.760 --> 1:26:10.440\n about the role of consciousness in the physical world,\n\n1:26:10.440 --> 1:26:14.080\n this would have some impact on the capacity of AGI's.\n\n1:26:14.080 --> 1:26:17.880\n And if it was a role that could not be duplicated elsewhere,\n\n1:26:17.880 --> 1:26:22.560\n then we'd have to find some way to either\n\n1:26:22.560 --> 1:26:24.640\n get consciousness in the system to play that role\n\n1:26:24.640 --> 1:26:25.520\n or to simulate it.\n\n1:26:25.520 --> 1:26:29.080\n If we can isolate a particular role to consciousness,\n\n1:26:29.080 --> 1:26:33.920\n of course, it seems like an incredibly difficult thing.\n\n1:26:35.120 --> 1:26:39.600\n Do you have worries about existential threats\n\n1:26:39.600 --> 1:26:44.600\n of conscious intelligent beings that are not us?\n\n1:26:46.240 --> 1:26:49.440\n So certainly, I'm sure you're worried about us\n\n1:26:50.640 --> 1:26:52.840\n from an existential threat perspective,\n\n1:26:52.840 --> 1:26:55.400\n but outside of us, AI systems.\n\n1:26:55.400 --> 1:26:56.440\n There's a couple of different kinds\n\n1:26:56.440 --> 1:26:58.160\n of existential threats here.\n\n1:26:58.160 --> 1:27:01.400\n One is an existential threat to consciousness generally.\n\n1:27:01.400 --> 1:27:04.000\n I mean, yes, I care about humans\n\n1:27:04.000 --> 1:27:05.960\n and the survival of humans and so on,\n\n1:27:05.960 --> 1:27:10.360\n but just say it turns out that eventually we're replaced\n\n1:27:10.360 --> 1:27:12.680\n by some artificial beings that aren't humans,\n\n1:27:12.680 --> 1:27:15.480\n but are somehow our successors.\n\n1:27:15.480 --> 1:27:16.800\n They still have good lives.\n\n1:27:16.800 --> 1:27:19.200\n They still do interesting and wonderful things\n\n1:27:19.200 --> 1:27:20.600\n with the universe.\n\n1:27:20.600 --> 1:27:23.440\n I don't think that's not so bad.\n\n1:27:23.440 --> 1:27:24.560\n That's just our successors.\n\n1:27:24.560 --> 1:27:26.480\n We were one stage in evolution.\n\n1:27:26.480 --> 1:27:29.720\n Something different, maybe better came next.\n\n1:27:29.720 --> 1:27:33.280\n If on the other hand, all of consciousness was wiped out,\n\n1:27:33.280 --> 1:27:36.760\n that would be a very serious moral disaster.\n\n1:27:36.760 --> 1:27:40.880\n One way that could happen is by all intelligent life\n\n1:27:40.880 --> 1:27:42.080\n being wiped out.\n\n1:27:42.080 --> 1:27:43.320\n And many people think that, yeah,\n\n1:27:43.320 --> 1:27:47.680\n once you get to humans and AIs and amazing sophistication\n\n1:27:47.680 --> 1:27:51.000\n where everyone has got the ability to create weapons\n\n1:27:51.000 --> 1:27:55.560\n that can destroy the whole universe just by pressing a button,\n\n1:27:55.560 --> 1:28:00.560\n then maybe it's inevitable all intelligent life will die out.\n\n1:28:00.640 --> 1:28:03.720\n That would certainly be a disaster.\n\n1:28:03.720 --> 1:28:06.040\n And we've got to think very hard about how to avoid that.\n\n1:28:06.040 --> 1:28:08.040\n But yeah, another interesting kind of disaster\n\n1:28:08.040 --> 1:28:12.160\n is that maybe intelligent life is not wiped out,\n\n1:28:12.160 --> 1:28:14.920\n but all consciousness is wiped out.\n\n1:28:14.920 --> 1:28:16.480\n So just say your thought,\n\n1:28:16.480 --> 1:28:18.000\n unlike what I was saying a moment ago,\n\n1:28:18.000 --> 1:28:21.400\n that there are two different kinds of intelligent systems,\n\n1:28:21.400 --> 1:28:25.400\n some which are conscious and some which are not.\n\n1:28:25.400 --> 1:28:28.840\n And just say it turns out that we create AGI\n\n1:28:28.840 --> 1:28:30.800\n with a high degree of intelligence,\n\n1:28:30.800 --> 1:28:34.080\n meaning high degree of sophistication and its behavior,\n\n1:28:34.080 --> 1:28:37.080\n but with no consciousness at all.\n\n1:28:37.080 --> 1:28:39.680\n That AGI could take over the world maybe,\n\n1:28:39.680 --> 1:28:42.760\n but then there'd be no consciousness in this world.\n\n1:28:42.760 --> 1:28:44.400\n This would be a world of zombies.\n\n1:28:44.400 --> 1:28:47.000\n Some people have called this the zombie apocalypse\n\n1:28:48.160 --> 1:28:50.240\n because it's an apocalypse for consciousness.\n\n1:28:50.240 --> 1:28:51.200\n Consciousness is gone.\n\n1:28:51.200 --> 1:28:53.120\n You've merely got this super intelligent,\n\n1:28:53.120 --> 1:28:54.560\n nonconscious robots.\n\n1:28:54.560 --> 1:28:58.040\n And I would say that's a moral disaster in the same way,\n\n1:28:58.040 --> 1:28:59.840\n in almost the same way that the world\n\n1:28:59.840 --> 1:29:02.240\n with no intelligent life is a moral disaster.\n\n1:29:02.240 --> 1:29:06.720\n All value and meaning may be gone from that world.\n\n1:29:06.720 --> 1:29:09.000\n So these are both threats to watch out for.\n\n1:29:09.000 --> 1:29:11.720\n Now, my own view is if you get super intelligence,\n\n1:29:11.720 --> 1:29:13.720\n you're almost certainly gonna bring consciousness with it.\n\n1:29:13.720 --> 1:29:15.840\n So I hope that's not gonna happen.\n\n1:29:15.840 --> 1:29:18.400\n But of course, I don't understand consciousness.\n\n1:29:18.400 --> 1:29:20.240\n No one understands consciousness.\n\n1:29:20.240 --> 1:29:21.680\n This is one reason for,\n\n1:29:21.680 --> 1:29:23.400\n this is one reason at least among many\n\n1:29:23.400 --> 1:29:25.520\n for thinking very seriously about consciousness\n\n1:29:25.520 --> 1:29:27.960\n and thinking about the kind of future\n\n1:29:27.960 --> 1:29:32.960\n we want to create in a world with humans and or AIs.\n\n1:29:33.160 --> 1:29:35.760\n How do you feel about the possibility\n\n1:29:35.760 --> 1:29:39.920\n if consciousness so naturally does come with AGI systems\n\n1:29:39.920 --> 1:29:42.600\n that we are just a step in the evolution?\n\n1:29:42.600 --> 1:29:47.240\n That we will be just something, a blimp on the record\n\n1:29:47.240 --> 1:29:49.040\n that'll be studied in books\n\n1:29:49.040 --> 1:29:51.720\n by the AGI systems centuries from now?\n\n1:29:51.720 --> 1:29:55.400\n I mean, I think I'd probably be okay with that,\n\n1:29:55.400 --> 1:29:58.480\n especially if somehow humans are continuous with AGI.\n\n1:29:58.480 --> 1:30:01.560\n I mean, I think something like this is inevitable.\n\n1:30:01.560 --> 1:30:03.960\n The very least humans are gonna be transformed.\n\n1:30:03.960 --> 1:30:06.480\n We're gonna be augmented by technology.\n\n1:30:06.480 --> 1:30:08.840\n It's already happening in all kinds of ways.\n\n1:30:08.840 --> 1:30:11.520\n We're gonna be transformed by technology\n\n1:30:11.520 --> 1:30:13.160\n where our brains are gonna be uploaded\n\n1:30:13.160 --> 1:30:15.880\n and computationally enhanced.\n\n1:30:15.880 --> 1:30:18.040\n And eventually that line between what's a human\n\n1:30:18.040 --> 1:30:23.040\n and what's an AI may be kind of hard to draw.\n\n1:30:23.400 --> 1:30:24.800\n How much does it matter, for example,\n\n1:30:24.800 --> 1:30:28.680\n that some future being a thousand years from now\n\n1:30:28.680 --> 1:30:32.120\n that somehow descended from us actually still has biology?\n\n1:30:32.120 --> 1:30:34.200\n I think it would be nice if you kind of point\n\n1:30:34.200 --> 1:30:36.160\n to its cognitive system, point to some parts\n\n1:30:36.160 --> 1:30:40.840\n that had some roots in us and trace a continuous line there.\n\n1:30:40.840 --> 1:30:43.720\n That would be selfishly nice for me to think that,\n\n1:30:43.720 --> 1:30:46.480\n okay, I'm connected to this thread line\n\n1:30:46.480 --> 1:30:48.120\n through the future of the world,\n\n1:30:48.120 --> 1:30:50.600\n but if it turns out, okay, there's a jump there.\n\n1:30:50.600 --> 1:30:53.760\n They found a better way to design cognitive systems.\n\n1:30:53.760 --> 1:30:55.440\n They designed a wholly new kind of thing.\n\n1:30:55.440 --> 1:30:59.800\n And the only line is some causal chain of designing\n\n1:30:59.800 --> 1:31:03.120\n and systems that design better systems.\n\n1:31:03.120 --> 1:31:04.800\n Is that so much worse?\n\n1:31:04.800 --> 1:31:05.640\n I don't know.\n\n1:31:05.640 --> 1:31:08.360\n We're still at least part of a causal chain of design.\n\n1:31:08.360 --> 1:31:09.560\n And yes, they're not humans,\n\n1:31:09.560 --> 1:31:11.640\n but still they're our successes.\n\n1:31:11.640 --> 1:31:14.440\n So, I mean, ultimately I think it's probably inevitable\n\n1:31:14.440 --> 1:31:16.760\n that something like that will happen.\n\n1:31:16.760 --> 1:31:19.920\n And at least we were part of the process.\n\n1:31:19.920 --> 1:31:23.400\n It'd be nice if they still cared enough about us\n\n1:31:23.400 --> 1:31:28.240\n to maybe to engage with our arguments.\n\n1:31:28.240 --> 1:31:30.080\n I'm really hoping that the AGI's are gonna solve\n\n1:31:30.080 --> 1:31:31.760\n all the problems of philosophy.\n\n1:31:31.760 --> 1:31:35.040\n They'll come back and read all this crappy work\n\n1:31:35.040 --> 1:31:36.480\n for the 20th and 21st century,\n\n1:31:36.480 --> 1:31:37.680\n hard problem of consciousness.\n\n1:31:37.680 --> 1:31:39.960\n And here is why they got it wrong.\n\n1:31:39.960 --> 1:31:41.000\n And so, and if that happened,\n\n1:31:41.000 --> 1:31:42.360\n then I'd really feel like I was part of\n\n1:31:42.360 --> 1:31:44.960\n at least an intellectual process over centuries.\n\n1:31:44.960 --> 1:31:45.960\n And that would be kind of cool.\n\n1:31:45.960 --> 1:31:48.520\n Well, I'm pretty sure they would clone\n\n1:31:48.520 --> 1:31:50.960\n or they would recreate David Chalmers\n\n1:31:50.960 --> 1:31:52.480\n and for the fun of it,\n\n1:31:52.480 --> 1:31:55.160\n sort of bring back other philosophers.\n\n1:31:55.160 --> 1:31:56.200\n Yeah, bring back Descartes.\n\n1:31:56.200 --> 1:31:58.800\n Descartes and just put them in a room and just watch.\n\n1:31:58.800 --> 1:32:02.040\n It'll be a Netflix of the future show\n\n1:32:02.040 --> 1:32:04.600\n where you bring philosophers from different human,\n\n1:32:04.600 --> 1:32:07.680\n 100% human philosophers from previous generations,\n\n1:32:07.680 --> 1:32:09.440\n put them in a room and see them.\n\n1:32:09.440 --> 1:32:11.160\n I am totally up for that.\n\n1:32:11.160 --> 1:32:14.040\n Simulators, AGI's of the future,\n\n1:32:14.040 --> 1:32:17.680\n if you're watching this podcast, do that.\n\n1:32:17.680 --> 1:32:20.880\n I would like to be recreated and ending out with Descartes.\n\n1:32:20.880 --> 1:32:22.640\n Where Descartes would be the first,\n\n1:32:22.640 --> 1:32:26.120\n if you could hang out as part of such a TV show\n\n1:32:26.120 --> 1:32:30.880\n with a philosopher that's no longer with us from long ago,\n\n1:32:30.880 --> 1:32:33.200\n who would you choose?\n\n1:32:33.200 --> 1:32:34.760\n Descartes would have to be right up there.\n\n1:32:34.760 --> 1:32:36.840\n Oh, actually a couple of months ago,\n\n1:32:36.840 --> 1:32:39.000\n I got to have a conversation with Descartes,\n\n1:32:39.000 --> 1:32:40.760\n an actor who's actually a philosopher\n\n1:32:40.760 --> 1:32:42.800\n came out on stage playing Descartes.\n\n1:32:42.800 --> 1:32:43.880\n I didn't know this was gonna happen.\n\n1:32:43.880 --> 1:32:46.200\n And I just after I gave a talk\n\n1:32:46.200 --> 1:32:50.120\n and told me about how my ideas were crap\n\n1:32:50.120 --> 1:32:51.560\n and all derived from him.\n\n1:32:51.560 --> 1:32:53.440\n And so we had a long argument.\n\n1:32:53.440 --> 1:32:54.680\n This was great.\n\n1:32:54.680 --> 1:32:57.400\n I would love to see what Descartes would think about AI,\n\n1:32:57.400 --> 1:32:59.520\n for example, and the modern neuroscience.\n\n1:32:59.520 --> 1:33:01.800\n And so I suspect not too much would surprise him,\n\n1:33:01.800 --> 1:33:05.420\n but yeah, William James,\n\n1:33:07.120 --> 1:33:08.720\n for a psychologist of consciousness,\n\n1:33:08.720 --> 1:33:13.720\n I think James was probably the richest.\n\n1:33:14.000 --> 1:33:17.120\n But, oh, there are Immanuel Kant.\n\n1:33:17.120 --> 1:33:19.120\n I never really understood what he was up to\n\n1:33:19.120 --> 1:33:22.760\n if I got to actually talk to him about some of this.\n\n1:33:22.760 --> 1:33:25.720\n Hey, there was Princess Elizabeth who talked with Descartes\n\n1:33:25.720 --> 1:33:28.760\n and who really got at the problems\n\n1:33:28.760 --> 1:33:32.800\n of how Descartes ideas of a nonphysical mind\n\n1:33:32.800 --> 1:33:37.240\n interacting with the physical body couldn't really work.\n\n1:33:37.240 --> 1:33:39.040\n She's been kind of, most philosophers\n\n1:33:39.040 --> 1:33:40.040\n think she's been proved right.\n\n1:33:40.040 --> 1:33:42.560\n So maybe put me in a room with Descartes\n\n1:33:42.560 --> 1:33:45.160\n and Princess Elizabeth and we can all argue it out.\n\n1:33:47.840 --> 1:33:49.360\n What kind of future?\n\n1:33:49.360 --> 1:33:53.280\n So we talked about zombies, a concerning future,\n\n1:33:53.280 --> 1:33:56.180\n but what kind of future excites you?\n\n1:33:56.180 --> 1:33:59.480\n What do you think if we look forward sort of,\n\n1:34:00.480 --> 1:34:02.160\n we're at the very early stages\n\n1:34:02.160 --> 1:34:04.080\n of understanding consciousness.\n\n1:34:04.080 --> 1:34:05.840\n And we're now at the early stages\n\n1:34:05.840 --> 1:34:10.120\n of being able to engineer complex, interesting systems\n\n1:34:10.120 --> 1:34:11.560\n that have degrees of intelligence.\n\n1:34:11.560 --> 1:34:14.240\n And maybe one day we'll have degrees of consciousness,\n\n1:34:14.240 --> 1:34:17.120\n maybe be able to upload brains,\n\n1:34:17.120 --> 1:34:20.000\n all those possibilities, virtual reality.\n\n1:34:20.000 --> 1:34:22.640\n Is there a particular aspect to this future world\n\n1:34:22.640 --> 1:34:24.020\n that just excites you?\n\n1:34:24.880 --> 1:34:26.360\n Well, I think there are lots of different aspects.\n\n1:34:26.360 --> 1:34:29.480\n I mean, frankly, I want it to hurry up and happen.\n\n1:34:29.480 --> 1:34:33.120\n It's like, yeah, we've had some progress lately in AI and VR,\n\n1:34:33.120 --> 1:34:35.960\n but in the grand scheme of things, it's still kind of slow.\n\n1:34:35.960 --> 1:34:38.200\n The changes are not yet transformative.\n\n1:34:38.200 --> 1:34:42.080\n And I'm in my fifties, I've only got so long left.\n\n1:34:42.080 --> 1:34:45.640\n I'd like to see really serious AI in my lifetime\n\n1:34:45.640 --> 1:34:48.240\n and really serious virtual worlds.\n\n1:34:48.240 --> 1:34:49.680\n Cause yeah, once people,\n\n1:34:49.680 --> 1:34:52.040\n I would like to be able to hang out in a virtual reality,\n\n1:34:52.040 --> 1:34:56.520\n which is richer than this reality\n\n1:34:56.520 --> 1:35:00.320\n to really get to inhabit fundamentally different kinds\n\n1:35:00.320 --> 1:35:02.160\n of spaces.\n\n1:35:02.160 --> 1:35:05.000\n Well, I would very much like to be able to upload\n\n1:35:05.000 --> 1:35:07.680\n my mind onto a computer.\n\n1:35:07.680 --> 1:35:10.280\n So maybe I don't have to die.\n\n1:35:11.440 --> 1:35:14.200\n If this is maybe gradually replaced my neurons\n\n1:35:14.200 --> 1:35:17.360\n with a Silicon chips and inhabit a computer.\n\n1:35:17.360 --> 1:35:19.320\n Selfishly, that would be wonderful.\n\n1:35:19.320 --> 1:35:24.320\n I suspect I'm not gonna quite get there in my lifetime,\n\n1:35:24.400 --> 1:35:26.520\n but once that's possible,\n\n1:35:26.520 --> 1:35:28.000\n then you've got the possibility of transforming\n\n1:35:28.000 --> 1:35:30.200\n your consciousness in remarkable ways,\n\n1:35:30.200 --> 1:35:32.400\n augmenting it, enhancing it.\n\n1:35:33.280 --> 1:35:34.440\n So let me ask then,\n\n1:35:34.440 --> 1:35:38.040\n if such a system is a possibility within your lifetime\n\n1:35:39.560 --> 1:35:42.800\n and you were given the opportunity to become immortal\n\n1:35:44.200 --> 1:35:49.200\n in this kind of way, would you choose to be immortal?\n\n1:35:50.800 --> 1:35:52.400\n Yes, I totally would.\n\n1:35:52.400 --> 1:35:54.880\n I know some people say they couldn't,\n\n1:35:54.880 --> 1:35:59.800\n it'd be awful to be immortal, be so boring or something.\n\n1:35:59.800 --> 1:36:04.800\n I don't see, I really don't see why this might be.\n\n1:36:04.800 --> 1:36:07.200\n I mean, even if it's just ordinary life that continues,\n\n1:36:07.200 --> 1:36:09.520\n ordinary life is not so bad.\n\n1:36:09.520 --> 1:36:12.840\n But furthermore, I kind of suspect that,\n\n1:36:12.840 --> 1:36:16.120\n if the universe is gonna go on forever or indefinitely,\n\n1:36:16.120 --> 1:36:19.240\n it's gonna continue to be interesting.\n\n1:36:19.240 --> 1:36:22.120\n I don't think your view was that we just have to get\n\n1:36:22.120 --> 1:36:24.160\n this one romantic point of interest now\n\n1:36:24.160 --> 1:36:26.160\n and afterwards it's all gonna be boring,\n\n1:36:26.160 --> 1:36:28.440\n super intelligent stasis.\n\n1:36:28.440 --> 1:36:30.000\n I guess my vision is more like,\n\n1:36:30.000 --> 1:36:32.640\n no, it's gonna continue to be infinitely interesting.\n\n1:36:32.640 --> 1:36:36.120\n Something like as you go up the set theoretic hierarchy,\n\n1:36:36.120 --> 1:36:41.120\n you go from the finite cardinals to Aleph zero\n\n1:36:42.520 --> 1:36:46.000\n and then through there to all the Aleph one and Aleph two\n\n1:36:46.000 --> 1:36:49.840\n and maybe the continuum and you keep taking power sets\n\n1:36:49.840 --> 1:36:51.920\n and in set theory, they've got these results\n\n1:36:51.920 --> 1:36:54.760\n that actually all this is fundamentally unpredictable.\n\n1:36:54.760 --> 1:36:57.360\n It doesn't follow any simple computational patterns.\n\n1:36:57.360 --> 1:36:58.920\n There's new levels of creativity\n\n1:36:58.920 --> 1:37:01.880\n as the set theoretic universe expands and expands.\n\n1:37:01.880 --> 1:37:03.320\n I guess that's my future.\n\n1:37:03.320 --> 1:37:04.840\n That's my vision of the future.\n\n1:37:04.840 --> 1:37:06.000\n That's my optimistic vision\n\n1:37:06.000 --> 1:37:08.040\n of the future of super intelligence.\n\n1:37:08.040 --> 1:37:09.760\n It will keep expanding and keep growing,\n\n1:37:09.760 --> 1:37:12.880\n but still being fundamentally unpredictable at many points.\n\n1:37:12.880 --> 1:37:15.280\n I mean, yes, this creates all kinds of worries\n\n1:37:15.280 --> 1:37:18.960\n like couldn't all be fragile and be destroyed at any point.\n\n1:37:18.960 --> 1:37:21.160\n So we're gonna need a solution to that problem.\n\n1:37:21.160 --> 1:37:23.360\n But if we get to stipulate that I'm immortal,\n\n1:37:23.360 --> 1:37:25.960\n well, I hope that I'm not just immortal and stuck\n\n1:37:25.960 --> 1:37:27.880\n in the single world forever,\n\n1:37:27.880 --> 1:37:30.960\n but I'm immortal and get to take part in this process\n\n1:37:30.960 --> 1:37:34.560\n of going through infinitely rich, created futures.\n\n1:37:34.560 --> 1:37:36.480\n Rich, unpredictable, exciting.\n\n1:37:36.480 --> 1:37:39.880\n Well, I think I speak for a lot of people in saying,\n\n1:37:39.880 --> 1:37:41.840\n I hope you do become immortal and there'll be\n\n1:37:41.840 --> 1:37:43.680\n that Netflix show, The Future,\n\n1:37:43.680 --> 1:37:46.360\n where you get to argue with Descartes,\n\n1:37:47.480 --> 1:37:49.800\n perhaps for all eternity.\n\n1:37:49.800 --> 1:37:51.480\n So David, it was an honor.\n\n1:37:51.480 --> 1:37:52.920\n Thank you so much for talking today.\n\n1:37:52.920 --> 1:37:55.040\n Thanks, it was a pleasure.\n\n1:37:55.040 --> 1:37:57.160\n Thanks for listening to this conversation\n\n1:37:57.160 --> 1:38:00.040\n and thank you to our presenting sponsor, Cash App.\n\n1:38:00.040 --> 1:38:02.680\n Download it, use code LexPodcast,\n\n1:38:02.680 --> 1:38:05.440\n you'll get $10 and $10 will go to FIRST,\n\n1:38:05.440 --> 1:38:08.680\n an organization that inspires and educates young minds\n\n1:38:08.680 --> 1:38:12.120\n to become science and technology innovators of tomorrow.\n\n1:38:12.120 --> 1:38:14.920\n If you enjoy this podcast, subscribe on YouTube,\n\n1:38:14.920 --> 1:38:16.760\n give it five stars on Apple Podcast,\n\n1:38:16.760 --> 1:38:19.200\n follow on Spotify, support it on Patreon,\n\n1:38:19.200 --> 1:38:22.240\n or simply connect with me on Twitter at Lex Friedman.\n\n1:38:23.120 --> 1:38:24.960\n And now let me leave you with some words\n\n1:38:24.960 --> 1:38:26.960\n from David Chalmers.\n\n1:38:26.960 --> 1:38:30.760\n Materialism is a beautiful and compelling view of the world,\n\n1:38:30.760 --> 1:38:32.240\n but to account for consciousness,\n\n1:38:32.240 --> 1:38:35.240\n we have to go beyond the resources it provides.\n\n1:38:35.240 --> 1:38:54.240\n Thank you for listening and hope to see you next time.\n\n"
}
{
  "title": "David Ferrucci: IBM Watson, Jeopardy & Deep Conversations with AI | Lex Fridman Podcast #44",
  "id": "Whtt2H5_isM",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:03.040\n The following is a conversation with David Feroci.\n\n00:03.040 --> 00:05.200\n He led the team that built Watson,\n\n00:05.200 --> 00:07.040\n the IBM question answering system\n\n00:07.040 --> 00:09.080\n that beat the top humans in the world\n\n00:09.080 --> 00:11.160\n at the game of Jeopardy.\n\n00:11.160 --> 00:12.920\n For spending a couple hours with David,\n\n00:12.920 --> 00:14.960\n I saw a genuine passion,\n\n00:14.960 --> 00:17.720\n not only for abstract understanding of intelligence,\n\n00:17.720 --> 00:21.240\n but for engineering it to solve real world problems\n\n00:21.240 --> 00:24.800\n under real world deadlines and resource constraints.\n\n00:24.800 --> 00:26.520\n Where science meets engineering\n\n00:26.520 --> 00:29.940\n is where brilliant, simple ingenuity emerges.\n\n00:29.940 --> 00:32.120\n People who work adjoining it to\n\n00:32.120 --> 00:33.800\n have a lot of wisdom earned\n\n00:33.800 --> 00:36.960\n through failures and eventual success.\n\n00:36.960 --> 00:39.080\n David is also the founder, CEO,\n\n00:39.080 --> 00:41.660\n and chief scientist of Elemental Cognition,\n\n00:41.660 --> 00:44.480\n a company working to engineer AI systems\n\n00:44.480 --> 00:47.420\n that understand the world the way people do.\n\n00:47.420 --> 00:50.260\n This is the Artificial Intelligence Podcast.\n\n00:50.260 --> 00:52.700\n If you enjoy it, subscribe on YouTube,\n\n00:52.700 --> 00:54.440\n give it five stars on iTunes,\n\n00:54.440 --> 00:55.840\n support it on Patreon,\n\n00:55.840 --> 00:57.920\n or simply connect with me on Twitter\n\n00:57.920 --> 01:01.360\n at Lex Friedman, spelled F R I D M A N.\n\n01:01.360 --> 01:05.160\n And now, here's my conversation with David Ferrucci.\n\n01:06.120 --> 01:07.980\n Your undergrad was in biology\n\n01:07.980 --> 01:11.280\n with an eye toward medical school\n\n01:11.280 --> 01:14.320\n before you went on for the PhD in computer science.\n\n01:14.320 --> 01:16.800\n So let me ask you an easy question.\n\n01:16.800 --> 01:20.520\n What is the difference between biological systems\n\n01:20.520 --> 01:22.420\n and computer systems?\n\n01:22.420 --> 01:25.240\n In your, when you sit back,\n\n01:25.240 --> 01:28.600\n look at the stars, and think philosophically.\n\n01:28.600 --> 01:30.840\n I often wonder whether or not\n\n01:30.840 --> 01:32.920\n there is a substantive difference.\n\n01:32.920 --> 01:34.480\n I mean, I think the thing that got me\n\n01:34.480 --> 01:37.220\n into computer science and into artificial intelligence\n\n01:37.220 --> 01:39.840\n was exactly this presupposition\n\n01:39.840 --> 01:44.360\n that if we can get machines to think,\n\n01:44.360 --> 01:45.640\n or I should say this question,\n\n01:45.640 --> 01:47.460\n this philosophical question,\n\n01:47.460 --> 01:50.580\n if we can get machines to think,\n\n01:50.580 --> 01:54.800\n to understand, to process information the way we do,\n\n01:54.800 --> 01:57.960\n so if we can describe a procedure, describe a process,\n\n01:57.960 --> 02:02.480\n even if that process were the intelligence process itself,\n\n02:02.480 --> 02:05.280\n then what would be the difference?\n\n02:05.280 --> 02:07.680\n So from a philosophical standpoint,\n\n02:07.680 --> 02:11.640\n I'm not sure I'm convinced that there is.\n\n02:11.640 --> 02:14.920\n I mean, you can go in the direction of spirituality,\n\n02:14.920 --> 02:16.660\n you can go in the direction of the soul,\n\n02:16.660 --> 02:21.660\n but in terms of what we can experience\n\n02:21.660 --> 02:25.980\n from an intellectual and physical perspective,\n\n02:25.980 --> 02:27.460\n I'm not sure there is.\n\n02:27.460 --> 02:31.080\n Clearly, there are different implementations,\n\n02:31.080 --> 02:33.220\n but if you were to say,\n\n02:33.220 --> 02:36.160\n is a biological information processing system\n\n02:36.160 --> 02:38.420\n fundamentally more capable\n\n02:38.420 --> 02:41.020\n than one we might be able to build out of silicon\n\n02:41.020 --> 02:43.880\n or some other substrate,\n\n02:44.900 --> 02:46.500\n I don't know that there is.\n\n02:46.500 --> 02:50.580\n How distant do you think is the biological implementation?\n\n02:50.580 --> 02:53.820\n So fundamentally, they may have the same capabilities,\n\n02:53.820 --> 02:58.260\n but is it really a far mystery\n\n02:58.260 --> 03:00.700\n where a huge number of breakthroughs are needed\n\n03:00.700 --> 03:02.700\n to be able to understand it,\n\n03:02.700 --> 03:06.260\n or is it something that, for the most part,\n\n03:06.260 --> 03:08.620\n in the important aspects,\n\n03:08.620 --> 03:11.100\n echoes of the same kind of characteristics?\n\n03:11.100 --> 03:12.100\n Yeah, that's interesting.\n\n03:12.100 --> 03:15.580\n I mean, so your question presupposes\n\n03:15.580 --> 03:17.520\n that there's this goal to recreate\n\n03:17.520 --> 03:20.880\n what we perceive as biological intelligence.\n\n03:20.880 --> 03:24.360\n I'm not sure that's the,\n\n03:24.360 --> 03:26.560\n I'm not sure that's how I would state the goal.\n\n03:26.560 --> 03:27.760\n I mean, I think that studying.\n\n03:27.760 --> 03:29.220\n What is the goal?\n\n03:29.220 --> 03:32.180\n Good, so I think there are a few goals.\n\n03:32.180 --> 03:35.720\n I think that understanding the human brain\n\n03:35.720 --> 03:38.520\n and how it works is important\n\n03:38.520 --> 03:43.520\n for us to be able to diagnose and treat issues,\n\n03:43.520 --> 03:47.200\n treat issues for us to understand our own strengths\n\n03:47.200 --> 03:51.040\n and weaknesses, both intellectual,\n\n03:51.040 --> 03:52.440\n psychological, and physical.\n\n03:52.440 --> 03:55.000\n So neuroscience and understanding the brain,\n\n03:55.000 --> 03:59.560\n from that perspective, there's a clear goal there.\n\n03:59.560 --> 04:00.920\n From the perspective of saying,\n\n04:00.920 --> 04:04.840\n I wanna mimic human intelligence,\n\n04:04.840 --> 04:06.440\n that one's a little bit more interesting.\n\n04:06.440 --> 04:10.480\n Human intelligence certainly has a lot of things we envy.\n\n04:10.480 --> 04:12.880\n It's also got a lot of problems, too.\n\n04:12.880 --> 04:16.660\n So I think we're capable of sort of stepping back\n\n04:16.660 --> 04:21.280\n and saying, what do we want out of an intelligence?\n\n04:22.160 --> 04:24.400\n How do we wanna communicate with that intelligence?\n\n04:24.400 --> 04:25.560\n How do we want it to behave?\n\n04:25.560 --> 04:27.440\n How do we want it to perform?\n\n04:27.440 --> 04:30.360\n Now, of course, it's somewhat of an interesting argument\n\n04:30.360 --> 04:32.040\n because I'm sitting here as a human\n\n04:32.040 --> 04:33.940\n with a biological brain,\n\n04:33.940 --> 04:36.420\n and I'm critiquing the strengths and weaknesses\n\n04:36.420 --> 04:38.640\n of human intelligence and saying\n\n04:38.640 --> 04:42.200\n that we have the capacity to step back\n\n04:42.200 --> 04:44.120\n and say, gee, what is intelligence\n\n04:44.120 --> 04:46.000\n and what do we really want out of it?\n\n04:46.000 --> 04:48.520\n And that, in and of itself, suggests that\n\n04:50.040 --> 04:52.080\n human intelligence is something quite enviable,\n\n04:52.080 --> 04:57.080\n that it can introspect that way.\n\n04:58.360 --> 05:00.280\n And the flaws, you mentioned the flaws.\n\n05:00.280 --> 05:01.120\n Humans have flaws.\n\n05:01.120 --> 05:04.720\n Yeah, but I think that flaws that human intelligence has\n\n05:04.720 --> 05:08.420\n is extremely prejudicial and biased\n\n05:08.420 --> 05:10.480\n in the way it draws many inferences.\n\n05:10.480 --> 05:12.040\n Do you think those are, sorry to interrupt,\n\n05:12.040 --> 05:14.360\n do you think those are features or are those bugs?\n\n05:14.360 --> 05:19.360\n Do you think the prejudice, the forgetfulness, the fear,\n\n05:21.520 --> 05:22.860\n what are the flaws?\n\n05:22.860 --> 05:23.700\n List them all.\n\n05:23.700 --> 05:24.520\n What, love?\n\n05:24.520 --> 05:25.560\n Maybe that's a flaw.\n\n05:25.560 --> 05:28.920\n You think those are all things that can be gotten,\n\n05:28.920 --> 05:30.780\n get in the way of intelligence\n\n05:30.780 --> 05:33.420\n or the essential components of intelligence?\n\n05:33.420 --> 05:36.160\n Well, again, if you go back and you define intelligence\n\n05:36.160 --> 05:42.120\n as being able to sort of accurately, precisely, rigorously,\n\n05:42.120 --> 05:43.840\n reason, develop answers,\n\n05:43.840 --> 05:46.640\n and justify those answers in an objective way,\n\n05:46.640 --> 05:49.720\n yeah, then human intelligence has these flaws\n\n05:49.720 --> 05:52.880\n in that it tends to be more influenced\n\n05:52.880 --> 05:55.200\n by some of the things you said.\n\n05:56.520 --> 05:59.740\n And it's largely an inductive process,\n\n05:59.740 --> 06:01.580\n meaning it takes past data,\n\n06:01.580 --> 06:03.560\n uses that to predict the future.\n\n06:03.560 --> 06:06.000\n Very advantageous in some cases,\n\n06:06.000 --> 06:09.280\n but fundamentally biased and prejudicial in other cases\n\n06:09.280 --> 06:11.520\n because it's gonna be strongly influenced by its priors,\n\n06:11.520 --> 06:13.880\n whether they're right or wrong\n\n06:13.880 --> 06:17.420\n from some objective reasoning perspective,\n\n06:17.420 --> 06:20.500\n you're gonna favor them because those are the decisions\n\n06:20.500 --> 06:24.000\n or those are the paths that succeeded in the past.\n\n06:24.000 --> 06:29.000\n And I think that mode of intelligence makes a lot of sense\n\n06:29.240 --> 06:33.280\n for when your primary goal is to act quickly\n\n06:33.280 --> 06:37.200\n and survive and make fast decisions.\n\n06:37.200 --> 06:39.360\n And I think those create problems\n\n06:40.300 --> 06:42.040\n when you wanna think more deeply\n\n06:42.040 --> 06:45.120\n and make more objective and reasoned decisions.\n\n06:45.120 --> 06:48.320\n Of course, humans capable of doing both.\n\n06:48.320 --> 06:51.120\n They do sort of one more naturally than they do the other,\n\n06:51.120 --> 06:53.280\n but they're capable of doing both.\n\n06:53.280 --> 06:54.540\n You're saying they do the one\n\n06:54.540 --> 06:56.480\n that responds quickly more naturally.\n\n06:56.480 --> 06:57.320\n Right.\n\n06:57.320 --> 06:58.440\n Because that's the thing we kind of need\n\n06:58.440 --> 07:02.720\n to not be eaten by the predators in the world.\n\n07:02.720 --> 07:07.720\n For example, but then we've learned to reason through logic,\n\n07:09.560 --> 07:12.980\n we've developed science, we train people to do that.\n\n07:13.960 --> 07:16.960\n I think that's harder for the individual to do.\n\n07:16.960 --> 07:20.960\n I think it requires training and teaching.\n\n07:20.960 --> 07:24.180\n I think we are, the human mind certainly is capable of it,\n\n07:24.180 --> 07:25.280\n but we find it more difficult.\n\n07:25.280 --> 07:27.680\n And then there are other weaknesses, if you will,\n\n07:27.680 --> 07:30.620\n as you mentioned earlier, just memory capacity\n\n07:30.620 --> 07:33.800\n and how many chains of inference\n\n07:33.800 --> 07:37.280\n can you actually go through without like losing your way?\n\n07:37.280 --> 07:40.280\n So just focus and...\n\n07:40.280 --> 07:43.240\n So the way you think about intelligence,\n\n07:43.240 --> 07:45.080\n and we're really sort of floating\n\n07:45.080 --> 07:47.220\n in this philosophical space,\n\n07:47.220 --> 07:50.080\n but I think you're like the perfect person\n\n07:50.080 --> 07:51.200\n to talk about this,\n\n07:52.160 --> 07:55.660\n because we'll get to Jeopardy and beyond.\n\n07:55.660 --> 07:58.700\n That's like one of the most incredible accomplishments\n\n07:58.700 --> 08:00.920\n in AI, in the history of AI,\n\n08:00.920 --> 08:03.400\n but hence the philosophical discussion.\n\n08:03.400 --> 08:06.280\n So let me ask, you've kind of alluded to it,\n\n08:06.280 --> 08:09.400\n but let me ask again, what is intelligence?\n\n08:09.400 --> 08:12.460\n Underlying the discussions we'll have\n\n08:12.460 --> 08:15.520\n with Jeopardy and beyond,\n\n08:15.520 --> 08:17.080\n how do you think about intelligence?\n\n08:17.080 --> 08:19.800\n Is it a sufficiently complicated problem\n\n08:19.800 --> 08:22.440\n being able to reason your way through solving that problem?\n\n08:22.440 --> 08:23.800\n Is that kind of how you think about\n\n08:23.800 --> 08:25.440\n what it means to be intelligent?\n\n08:25.440 --> 08:29.720\n So I think of intelligence primarily two ways.\n\n08:29.720 --> 08:33.320\n One is the ability to predict.\n\n08:33.320 --> 08:35.840\n So in other words, if I have a problem,\n\n08:35.840 --> 08:37.600\n can I predict what's gonna happen next?\n\n08:37.600 --> 08:40.900\n Whether it's to predict the answer of a question\n\n08:40.900 --> 08:43.880\n or to say, look, I'm looking at all the market dynamics\n\n08:43.880 --> 08:46.160\n and I'm gonna tell you what's gonna happen next,\n\n08:46.160 --> 08:49.400\n or you're in a room and somebody walks in\n\n08:49.400 --> 08:51.320\n and you're gonna predict what they're gonna do next\n\n08:51.320 --> 08:53.660\n or what they're gonna say next.\n\n08:53.660 --> 08:55.760\n You're in a highly dynamic environment\n\n08:55.760 --> 08:58.680\n full of uncertainty, be able to predict.\n\n08:58.680 --> 09:01.480\n The more variables, the more complex.\n\n09:01.480 --> 09:04.080\n The more possibilities, the more complex.\n\n09:04.080 --> 09:07.720\n But can I take a small amount of prior data\n\n09:07.720 --> 09:09.880\n and learn the pattern and then predict\n\n09:09.880 --> 09:13.040\n what's gonna happen next accurately and consistently?\n\n09:13.920 --> 09:16.960\n That's certainly a form of intelligence.\n\n09:16.960 --> 09:18.320\n What do you need for that, by the way?\n\n09:18.320 --> 09:21.160\n You need to have an understanding\n\n09:21.160 --> 09:22.880\n of the way the world works\n\n09:22.880 --> 09:26.320\n in order to be able to unroll it into the future, right?\n\n09:26.320 --> 09:28.000\n What do you think is needed to predict?\n\n09:28.000 --> 09:29.440\n Depends what you mean by understanding.\n\n09:29.440 --> 09:32.240\n I need to be able to find that function.\n\n09:32.240 --> 09:35.100\n This is very much what deep learning does,\n\n09:35.100 --> 09:38.960\n machine learning does, is if you give me enough prior data\n\n09:38.960 --> 09:41.940\n and you tell me what the output variable is that matters,\n\n09:41.940 --> 09:44.440\n I'm gonna sit there and be able to predict it.\n\n09:44.440 --> 09:47.280\n And if I can predict it accurately\n\n09:47.280 --> 09:50.280\n so that I can get it right more often than not,\n\n09:50.280 --> 09:52.920\n I'm smart, if I can do that with less data\n\n09:52.920 --> 09:56.020\n and less training time, I'm even smarter.\n\n09:58.000 --> 10:00.620\n If I can figure out what's even worth predicting,\n\n10:01.640 --> 10:03.920\n I'm smarter, meaning I'm figuring out\n\n10:03.920 --> 10:06.400\n what path is gonna get me toward a goal.\n\n10:06.400 --> 10:07.560\n What about picking a goal?\n\n10:07.560 --> 10:08.480\n Sorry, you left again.\n\n10:08.480 --> 10:10.120\n Well, that's interesting about picking a goal,\n\n10:10.120 --> 10:11.080\n sort of an interesting thing.\n\n10:11.080 --> 10:13.240\n I think that's where you bring in\n\n10:13.240 --> 10:15.040\n what are you preprogrammed to do?\n\n10:15.040 --> 10:16.000\n We talk about humans,\n\n10:16.000 --> 10:19.400\n and well, humans are preprogrammed to survive.\n\n10:19.400 --> 10:23.320\n So it's sort of their primary driving goal.\n\n10:23.320 --> 10:24.700\n What do they have to do to do that?\n\n10:24.700 --> 10:27.360\n And that can be very complex, right?\n\n10:27.360 --> 10:31.680\n So it's not just figuring out that you need to run away\n\n10:31.680 --> 10:33.640\n from the ferocious tiger,\n\n10:33.640 --> 10:38.640\n but we survive in a social context as an example.\n\n10:38.720 --> 10:42.320\n So understanding the subtleties of social dynamics\n\n10:42.320 --> 10:45.420\n becomes something that's important for surviving,\n\n10:45.420 --> 10:47.200\n finding a mate, reproducing, right?\n\n10:47.200 --> 10:50.320\n So we're continually challenged with\n\n10:50.320 --> 10:53.760\n complex sets of variables, complex constraints,\n\n10:53.760 --> 10:56.880\n rules, if you will, or patterns.\n\n10:56.880 --> 10:59.320\n And we learn how to find the functions\n\n10:59.320 --> 11:00.680\n and predict the things.\n\n11:00.680 --> 11:03.580\n In other words, represent those patterns efficiently\n\n11:03.580 --> 11:04.920\n and be able to predict what's gonna happen.\n\n11:04.920 --> 11:06.080\n And that's a form of intelligence.\n\n11:06.080 --> 11:11.080\n That doesn't really require anything specific\n\n11:11.400 --> 11:13.400\n other than the ability to find that function\n\n11:13.400 --> 11:15.840\n and predict that right answer.\n\n11:15.840 --> 11:18.440\n That's certainly a form of intelligence.\n\n11:18.440 --> 11:23.280\n But then when we say, well, do we understand each other?\n\n11:23.280 --> 11:28.280\n In other words, would you perceive me as intelligent\n\n11:28.640 --> 11:31.040\n beyond that ability to predict?\n\n11:31.040 --> 11:35.220\n So now I can predict, but I can't really articulate\n\n11:35.220 --> 11:37.840\n how I'm going through that process,\n\n11:37.840 --> 11:41.240\n what my underlying theory is for predicting,\n\n11:41.240 --> 11:43.680\n and I can't get you to understand what I'm doing\n\n11:43.680 --> 11:48.040\n so that you can figure out how to do this yourself\n\n11:48.040 --> 11:50.760\n if you did not have, for example,\n\n11:50.760 --> 11:53.840\n the right pattern matching machinery that I did.\n\n11:53.840 --> 11:55.740\n And now we potentially have this breakdown\n\n11:55.740 --> 11:59.080\n where, in effect, I'm intelligent,\n\n11:59.080 --> 12:02.640\n but I'm sort of an alien intelligence relative to you.\n\n12:02.640 --> 12:05.960\n You're intelligent, but nobody knows about it, or I can't.\n\n12:05.960 --> 12:08.200\n Well, I can see the output.\n\n12:08.200 --> 12:11.680\n So you're saying, let's sort of separate the two things.\n\n12:11.680 --> 12:15.880\n One is you explaining why you were able\n\n12:15.880 --> 12:17.260\n to predict the future,\n\n12:19.160 --> 12:23.360\n and the second is me being able to,\n\n12:23.360 --> 12:25.520\n impressing me that you're intelligent,\n\n12:25.520 --> 12:26.520\n me being able to know\n\n12:26.520 --> 12:28.680\n that you successfully predicted the future.\n\n12:28.680 --> 12:29.600\n Do you think that's?\n\n12:29.600 --> 12:31.360\n Well, it's not impressing you that I'm intelligent.\n\n12:31.360 --> 12:33.640\n In other words, you may be convinced\n\n12:33.640 --> 12:35.960\n that I'm intelligent in some form.\n\n12:35.960 --> 12:37.160\n So how, what would convince?\n\n12:37.160 --> 12:38.880\n Because of my ability to predict.\n\n12:38.880 --> 12:39.720\n So I would look at the metrics.\n\n12:39.720 --> 12:41.120\n When you can't, I'd say, wow.\n\n12:41.120 --> 12:44.960\n You're right more times than I am.\n\n12:44.960 --> 12:46.280\n You're doing something interesting.\n\n12:46.280 --> 12:49.120\n That's a form of intelligence.\n\n12:49.120 --> 12:53.400\n But then what happens is, if I say, how are you doing that?\n\n12:53.400 --> 12:55.280\n And you can't communicate with me,\n\n12:55.280 --> 12:57.720\n and you can't describe that to me,\n\n12:57.720 --> 13:00.700\n now I may label you a savant.\n\n13:00.700 --> 13:03.240\n I may say, well, you're doing something weird,\n\n13:03.240 --> 13:06.360\n and it's just not very interesting to me,\n\n13:06.360 --> 13:09.360\n because you and I can't really communicate.\n\n13:09.360 --> 13:12.360\n And so now, so this is interesting, right?\n\n13:12.360 --> 13:15.120\n Because now this is, you're in this weird place\n\n13:15.120 --> 13:17.480\n where for you to be recognized\n\n13:17.480 --> 13:21.300\n as intelligent the way I'm intelligent,\n\n13:21.300 --> 13:24.280\n then you and I sort of have to be able to communicate.\n\n13:24.280 --> 13:28.520\n And then my, we start to understand each other,\n\n13:28.520 --> 13:33.480\n and then my respect and my appreciation,\n\n13:33.480 --> 13:36.760\n my ability to relate to you starts to change.\n\n13:36.760 --> 13:39.080\n So now you're not an alien intelligence anymore.\n\n13:39.080 --> 13:41.080\n You're a human intelligence now,\n\n13:41.080 --> 13:43.880\n because you and I can communicate.\n\n13:43.880 --> 13:48.120\n And so I think when we look at animals, for example,\n\n13:48.120 --> 13:50.720\n animals can do things we can't quite comprehend,\n\n13:50.720 --> 13:51.800\n we don't quite know how they do them,\n\n13:51.800 --> 13:54.420\n but they can't really communicate with us.\n\n13:54.420 --> 13:58.360\n They can't put what they're going through in our terms.\n\n13:58.360 --> 13:59.720\n And so we think of them as sort of,\n\n13:59.720 --> 14:01.520\n well, they're these alien intelligences,\n\n14:01.520 --> 14:03.600\n and they're not really worth necessarily what we're worth.\n\n14:03.600 --> 14:06.360\n We don't treat them the same way as a result of that.\n\n14:06.360 --> 14:11.360\n But it's hard because who knows what's going on.\n\n14:11.640 --> 14:15.640\n So just a quick elaboration on that,\n\n14:15.640 --> 14:18.760\n the explaining that you're intelligent,\n\n14:18.760 --> 14:22.280\n the explaining the reasoning that went into the prediction\n\n14:23.480 --> 14:27.080\n is not some kind of mathematical proof.\n\n14:27.080 --> 14:28.840\n If we look at humans,\n\n14:28.840 --> 14:32.220\n look at political debates and discourse on Twitter,\n\n14:32.220 --> 14:35.340\n it's mostly just telling stories.\n\n14:35.340 --> 14:38.400\n So your task is, sorry,\n\n14:38.400 --> 14:43.400\n your task is not to tell an accurate depiction\n\n14:43.680 --> 14:48.420\n of how you reason, but to tell a story, real or not,\n\n14:48.420 --> 14:52.000\n that convinces me that there was a mechanism by which you.\n\n14:52.000 --> 14:53.600\n Ultimately, that's what a proof is.\n\n14:53.600 --> 14:56.240\n I mean, even a mathematical proof is that.\n\n14:56.240 --> 14:58.200\n Because ultimately, the other mathematicians\n\n14:58.200 --> 15:00.020\n have to be convinced by your proof.\n\n15:01.600 --> 15:03.000\n Otherwise, in fact, there have been.\n\n15:03.000 --> 15:04.440\n That's the metric for success, yeah.\n\n15:04.440 --> 15:06.080\n There have been several proofs out there\n\n15:06.080 --> 15:08.040\n where mathematicians would study for a long time\n\n15:08.040 --> 15:08.880\n before they were convinced\n\n15:08.880 --> 15:10.920\n that it actually proved anything, right?\n\n15:10.920 --> 15:12.240\n You never know if it proved anything\n\n15:12.240 --> 15:14.880\n until the community of mathematicians decided that it did.\n\n15:14.880 --> 15:18.680\n So I mean, but it's a real thing, right?\n\n15:18.680 --> 15:20.960\n And that's sort of the point, right?\n\n15:20.960 --> 15:24.640\n Is that ultimately, this notion of understanding us,\n\n15:24.640 --> 15:28.240\n understanding something is ultimately a social concept.\n\n15:28.240 --> 15:30.740\n In other words, I have to convince enough people\n\n15:30.740 --> 15:33.760\n that I did this in a reasonable way.\n\n15:33.760 --> 15:36.400\n I did this in a way that other people can understand\n\n15:36.400 --> 15:39.840\n and replicate and that it makes sense to them.\n\n15:39.840 --> 15:44.840\n So human intelligence is bound together in that way.\n\n15:44.840 --> 15:47.460\n We're bound up in that sense.\n\n15:47.460 --> 15:49.560\n We sort of never really get away with it\n\n15:49.560 --> 15:52.600\n until we can sort of convince others\n\n15:52.600 --> 15:55.880\n that our thinking process makes sense.\n\n15:55.880 --> 15:59.120\n Did you think the general question of intelligence\n\n15:59.120 --> 16:01.000\n is then also a social construct?\n\n16:01.000 --> 16:06.000\n So if we ask questions of an artificial intelligence system,\n\n16:06.720 --> 16:08.640\n is this system intelligent?\n\n16:08.640 --> 16:12.640\n The answer will ultimately be a socially constructed.\n\n16:12.640 --> 16:16.040\n I think, so I think I'm making two statements.\n\n16:16.040 --> 16:18.040\n I'm saying we can try to define intelligence\n\n16:18.040 --> 16:23.040\n in this super objective way that says, here's this data.\n\n16:23.120 --> 16:26.760\n I wanna predict this type of thing, learn this function.\n\n16:26.760 --> 16:30.360\n And then if you get it right, often enough,\n\n16:30.360 --> 16:32.080\n we consider you intelligent.\n\n16:32.080 --> 16:34.400\n But that's more like a sub bond.\n\n16:34.400 --> 16:35.720\n I think it is.\n\n16:35.720 --> 16:37.120\n It doesn't mean it's not useful.\n\n16:37.120 --> 16:38.640\n It could be incredibly useful.\n\n16:38.640 --> 16:41.460\n It could be solving a problem we can't otherwise solve\n\n16:41.460 --> 16:44.480\n and can solve it more reliably than we can.\n\n16:44.480 --> 16:46.960\n But then there's this notion of,\n\n16:46.960 --> 16:50.420\n can humans take responsibility\n\n16:50.420 --> 16:53.680\n for the decision that you're making?\n\n16:53.680 --> 16:56.120\n Can we make those decisions ourselves?\n\n16:56.120 --> 16:58.840\n Can we relate to the process that you're going through?\n\n16:58.840 --> 17:01.160\n And now you as an agent,\n\n17:01.160 --> 17:04.520\n whether you're a machine or another human, frankly,\n\n17:04.520 --> 17:08.640\n are now obliged to make me understand\n\n17:08.640 --> 17:10.860\n how it is that you're arriving at that answer\n\n17:10.860 --> 17:13.840\n and allow me, me or obviously a community\n\n17:13.840 --> 17:15.000\n or a judge of people to decide\n\n17:15.000 --> 17:17.280\n whether or not that makes sense.\n\n17:17.280 --> 17:20.200\n And by the way, that happens with the humans as well.\n\n17:20.200 --> 17:22.080\n You're sitting down with your staff, for example,\n\n17:22.080 --> 17:25.520\n and you ask for suggestions about what to do next.\n\n17:26.360 --> 17:28.640\n And someone says, oh, I think you should buy.\n\n17:28.640 --> 17:30.560\n And I actually think you should buy this much\n\n17:30.560 --> 17:33.160\n or whatever or sell or whatever it is.\n\n17:33.160 --> 17:35.720\n Or I think you should launch the product today or tomorrow\n\n17:35.720 --> 17:37.080\n or launch this product versus that product,\n\n17:37.080 --> 17:38.600\n whatever the decision may be.\n\n17:38.600 --> 17:39.840\n And you ask why.\n\n17:39.840 --> 17:40.680\n And the person says,\n\n17:40.680 --> 17:42.800\n I just have a good feeling about it.\n\n17:42.800 --> 17:44.400\n And you're not very satisfied.\n\n17:44.400 --> 17:47.600\n Now, that person could be,\n\n17:47.600 --> 17:50.880\n you might say, well, you've been right before,\n\n17:50.880 --> 17:54.140\n but I'm gonna put the company on the line.\n\n17:54.140 --> 17:56.760\n Can you explain to me why I should believe this?\n\n17:56.760 --> 17:58.000\n Right.\n\n17:58.000 --> 18:00.960\n And that explanation may have nothing to do with the truth.\n\n18:00.960 --> 18:01.800\n You just, the ultimate.\n\n18:01.800 --> 18:03.520\n It's gotta convince the other person.\n\n18:03.520 --> 18:05.280\n Still be wrong, still be wrong.\n\n18:05.280 --> 18:06.320\n She's gotta be convincing.\n\n18:06.320 --> 18:07.840\n But it's ultimately gotta be convincing.\n\n18:07.840 --> 18:10.200\n And that's why I'm saying it's,\n\n18:10.200 --> 18:12.160\n we're bound together, right?\n\n18:12.160 --> 18:14.160\n Our intelligences are bound together in that sense.\n\n18:14.160 --> 18:15.360\n We have to understand each other.\n\n18:15.360 --> 18:18.920\n And if, for example, you're giving me an explanation,\n\n18:18.920 --> 18:21.020\n I mean, this is a very important point, right?\n\n18:21.020 --> 18:23.840\n You're giving me an explanation,\n\n18:23.840 --> 18:28.280\n and I'm not good,\n\n18:29.380 --> 18:33.520\n and then I'm not good at reasoning well,\n\n18:33.520 --> 18:35.280\n and being objective,\n\n18:35.280 --> 18:39.160\n and following logical paths and consistent paths,\n\n18:39.160 --> 18:41.400\n and I'm not good at measuring\n\n18:41.400 --> 18:45.520\n and sort of computing probabilities across those paths.\n\n18:45.520 --> 18:47.200\n What happens is collectively,\n\n18:47.200 --> 18:50.120\n we're not gonna do well.\n\n18:50.120 --> 18:52.240\n How hard is that problem?\n\n18:52.240 --> 18:53.180\n The second one.\n\n18:53.180 --> 18:57.960\n So I think we'll talk quite a bit about the first\n\n18:57.960 --> 19:02.960\n on a specific objective metric benchmark performing well.\n\n19:03.840 --> 19:07.440\n But being able to explain the steps,\n\n19:07.440 --> 19:10.580\n the reasoning, how hard is that problem?\n\n19:10.580 --> 19:11.800\n I think that's very hard.\n\n19:11.800 --> 19:13.300\n I mean, I think that that's,\n\n19:16.040 --> 19:18.160\n well, it's hard for humans.\n\n19:18.160 --> 19:20.960\n The thing that's hard for humans, as you know,\n\n19:20.960 --> 19:22.920\n may not necessarily be hard for computers\n\n19:22.920 --> 19:24.440\n and vice versa.\n\n19:24.440 --> 19:29.440\n So, sorry, so how hard is that problem for computers?\n\n19:31.160 --> 19:32.640\n I think it's hard for computers,\n\n19:32.640 --> 19:34.600\n and the reason why I related to,\n\n19:34.600 --> 19:36.400\n or saying that it's also hard for humans\n\n19:36.400 --> 19:38.320\n is because I think when we step back\n\n19:38.320 --> 19:41.920\n and we say we wanna design computers to do that,\n\n19:43.520 --> 19:46.440\n one of the things we have to recognize\n\n19:46.440 --> 19:50.520\n is we're not sure how to do it well.\n\n19:50.520 --> 19:52.960\n I'm not sure we have a recipe for that.\n\n19:52.960 --> 19:55.320\n And even if you wanted to learn it,\n\n19:55.320 --> 19:58.400\n it's not clear exactly what data we use\n\n19:59.480 --> 20:03.720\n and what judgments we use to learn that well.\n\n20:03.720 --> 20:05.480\n And so what I mean by that is\n\n20:05.480 --> 20:09.500\n if you look at the entire enterprise of science,\n\n20:09.500 --> 20:11.640\n science is supposed to be at about\n\n20:11.640 --> 20:13.680\n objective reason and reason, right?\n\n20:13.680 --> 20:17.680\n So we think about, gee, who's the most intelligent person\n\n20:17.680 --> 20:20.500\n or group of people in the world?\n\n20:20.500 --> 20:24.080\n Do we think about the savants who can close their eyes\n\n20:24.080 --> 20:25.540\n and give you a number?\n\n20:25.540 --> 20:27.680\n We think about the think tanks,\n\n20:27.680 --> 20:29.500\n or the scientists or the philosophers\n\n20:29.500 --> 20:32.680\n who kind of work through the details\n\n20:32.680 --> 20:35.960\n and write the papers and come up with the thoughtful,\n\n20:35.960 --> 20:39.480\n logical proofs and use the scientific method.\n\n20:39.480 --> 20:40.680\n I think it's the latter.\n\n20:42.760 --> 20:45.800\n And my point is that how do you train someone to do that?\n\n20:45.800 --> 20:46.920\n And that's what I mean by it's hard.\n\n20:46.920 --> 20:49.400\n How do you, what's the process of training people\n\n20:49.400 --> 20:50.800\n to do that well?\n\n20:50.800 --> 20:52.400\n That's a hard process.\n\n20:52.400 --> 20:56.020\n We work, as a society, we work pretty hard\n\n20:56.020 --> 20:59.240\n to get other people to understand our thinking\n\n20:59.240 --> 21:02.220\n and to convince them of things.\n\n21:02.220 --> 21:04.040\n Now we could persuade them,\n\n21:04.040 --> 21:05.300\n obviously you talked about this,\n\n21:05.300 --> 21:07.520\n like human flaws or weaknesses,\n\n21:07.520 --> 21:12.160\n we can persuade them through emotional means.\n\n21:12.160 --> 21:16.140\n But to get them to understand and connect to\n\n21:16.140 --> 21:19.960\n and follow a logical argument is difficult.\n\n21:19.960 --> 21:22.440\n We try it, we do it, we do it as scientists,\n\n21:22.440 --> 21:24.200\n we try to do it as journalists,\n\n21:24.200 --> 21:27.280\n we try to do it as even artists in many forms,\n\n21:27.280 --> 21:29.780\n as writers, as teachers.\n\n21:29.780 --> 21:32.940\n We go through a fairly significant training process\n\n21:33.860 --> 21:34.700\n to do that.\n\n21:34.700 --> 21:37.900\n And then we could ask, well, why is that so hard?\n\n21:39.040 --> 21:39.920\n But it's hard.\n\n21:39.920 --> 21:42.960\n And for humans, it takes a lot of work.\n\n21:44.060 --> 21:45.960\n And when we step back and say,\n\n21:45.960 --> 21:49.160\n well, how do we get a machine to do that?\n\n21:49.160 --> 21:50.640\n It's a vexing question.\n\n21:51.840 --> 21:55.240\n How would you begin to try to solve that?\n\n21:55.240 --> 21:57.400\n And maybe just a quick pause,\n\n21:57.400 --> 21:59.840\n because there's an optimistic notion\n\n21:59.840 --> 22:01.040\n in the things you're describing,\n\n22:01.040 --> 22:05.120\n which is being able to explain something through reason.\n\n22:05.980 --> 22:08.660\n But if you look at algorithms that recommend things\n\n22:08.660 --> 22:11.800\n that we'll look at next, whether it's Facebook, Google,\n\n22:11.800 --> 22:16.800\n advertisement based companies, their goal is to convince you\n\n22:18.000 --> 22:22.360\n to buy things based on anything.\n\n22:23.480 --> 22:25.440\n So that could be reason,\n\n22:25.440 --> 22:28.100\n because the best of advertisement is showing you things\n\n22:28.100 --> 22:31.980\n that you really do need and explain why you need it.\n\n22:31.980 --> 22:35.660\n But it could also be through emotional manipulation.\n\n22:37.000 --> 22:41.760\n The algorithm that describes why a certain decision\n\n22:41.760 --> 22:45.760\n was made, how hard is it to do it\n\n22:45.760 --> 22:48.160\n through emotional manipulation?\n\n22:48.160 --> 22:51.920\n And why is that a good or a bad thing?\n\n22:52.760 --> 22:56.840\n So you've kind of focused on reason, logic,\n\n22:56.840 --> 23:01.460\n really showing in a clear way why something is good.\n\n23:02.520 --> 23:05.920\n One, is that even a thing that us humans do?\n\n23:05.920 --> 23:09.920\n And two, how do you think of the difference\n\n23:09.920 --> 23:13.460\n in the reasoning aspect and the emotional manipulation?\n\n23:15.160 --> 23:17.360\n So you call it emotional manipulation,\n\n23:17.360 --> 23:20.220\n but more objectively is essentially saying,\n\n23:20.220 --> 23:22.660\n there are certain features of things\n\n23:22.660 --> 23:24.440\n that seem to attract your attention.\n\n23:24.440 --> 23:26.800\n I mean, it kind of give you more of that stuff.\n\n23:26.800 --> 23:28.280\n Manipulation is a bad word.\n\n23:28.280 --> 23:31.140\n Yeah, I mean, I'm not saying it's good right or wrong.\n\n23:31.140 --> 23:32.960\n It works to get your attention\n\n23:32.960 --> 23:34.440\n and it works to get you to buy stuff.\n\n23:34.440 --> 23:36.960\n And when you think about algorithms that look\n\n23:36.960 --> 23:40.000\n at the patterns of features\n\n23:40.000 --> 23:41.920\n that you seem to be spending your money on\n\n23:41.920 --> 23:43.280\n and say, I'm gonna give you something\n\n23:43.280 --> 23:44.820\n with a similar pattern.\n\n23:44.820 --> 23:46.080\n So I'm gonna learn that function\n\n23:46.080 --> 23:48.200\n because the objective is to get you to click on it\n\n23:48.200 --> 23:50.240\n or get you to buy it or whatever it is.\n\n23:51.120 --> 23:53.400\n I don't know, I mean, it is what it is.\n\n23:53.400 --> 23:55.840\n I mean, that's what the algorithm does.\n\n23:55.840 --> 23:57.440\n You can argue whether it's good or bad.\n\n23:57.440 --> 24:00.440\n It depends what your goal is.\n\n24:00.440 --> 24:02.480\n I guess this seems to be very useful\n\n24:02.480 --> 24:05.280\n for convincing, for telling a story.\n\n24:05.280 --> 24:07.680\n For convincing humans, it's good\n\n24:07.680 --> 24:11.800\n because again, this goes back to what is the human behavior\n\n24:11.800 --> 24:16.800\n like, how does the human brain respond to things?\n\n24:17.000 --> 24:19.360\n I think there's a more optimistic view of that too,\n\n24:19.360 --> 24:22.000\n which is that if you're searching\n\n24:22.000 --> 24:23.120\n for certain kinds of things,\n\n24:23.120 --> 24:26.160\n you've already reasoned that you need them.\n\n24:26.160 --> 24:30.080\n And these algorithms are saying, look, that's up to you\n\n24:30.080 --> 24:32.180\n to reason whether you need something or not.\n\n24:32.180 --> 24:33.400\n That's your job.\n\n24:33.400 --> 24:36.920\n You may have an unhealthy addiction to this stuff\n\n24:36.920 --> 24:41.920\n or you may have a reasoned and thoughtful explanation\n\n24:42.880 --> 24:44.520\n for why it's important to you.\n\n24:44.520 --> 24:47.040\n And the algorithms are saying, hey, that's like, whatever.\n\n24:47.040 --> 24:48.040\n Like, that's your problem.\n\n24:48.040 --> 24:50.580\n All I know is you're buying stuff like that.\n\n24:50.580 --> 24:51.920\n You're interested in stuff like that.\n\n24:51.920 --> 24:53.920\n Could be a bad reason, could be a good reason.\n\n24:53.920 --> 24:55.080\n That's up to you.\n\n24:55.080 --> 24:57.520\n I'm gonna show you more of that stuff.\n\n24:57.520 --> 25:01.640\n And I think that it's not good or bad.\n\n25:01.640 --> 25:03.520\n It's not reasoned or not reasoned.\n\n25:03.520 --> 25:04.880\n The algorithm is doing what it does,\n\n25:04.880 --> 25:06.920\n which is saying, you seem to be interested in this.\n\n25:06.920 --> 25:09.320\n I'm gonna show you more of that stuff.\n\n25:09.320 --> 25:11.200\n And I think we're seeing this not just in buying stuff,\n\n25:11.200 --> 25:12.160\n but even in social media.\n\n25:12.160 --> 25:13.960\n You're reading this kind of stuff.\n\n25:13.960 --> 25:15.740\n I'm not judging on whether it's good or bad.\n\n25:15.740 --> 25:16.920\n I'm not reasoning at all.\n\n25:16.920 --> 25:19.200\n I'm just saying, I'm gonna show you other stuff\n\n25:19.200 --> 25:20.800\n with similar features.\n\n25:20.800 --> 25:22.360\n And like, and that's it.\n\n25:22.360 --> 25:23.840\n And I wash my hands from it and I say,\n\n25:23.840 --> 25:25.940\n that's all that's going on.\n\n25:25.940 --> 25:30.940\n You know, there is, people are so harsh on AI systems.\n\n25:31.900 --> 25:34.940\n So one, the bar of performance is extremely high.\n\n25:34.940 --> 25:39.560\n And yet we also ask them to, in the case of social media,\n\n25:39.560 --> 25:42.940\n to help find the better angels of our nature\n\n25:42.940 --> 25:45.980\n and help make a better society.\n\n25:45.980 --> 25:47.860\n What do you think about the role of AI there?\n\n25:47.860 --> 25:48.860\n So that, I agree with you.\n\n25:48.860 --> 25:51.580\n That's the interesting dichotomy, right?\n\n25:51.580 --> 25:54.160\n Because on one hand, we're sitting there\n\n25:54.160 --> 25:55.880\n and we're sort of doing the easy part,\n\n25:55.880 --> 25:57.980\n which is finding the patterns.\n\n25:57.980 --> 26:01.820\n We're not building, the system's not building a theory\n\n26:01.820 --> 26:04.220\n that is consumable and understandable to other humans\n\n26:04.220 --> 26:06.380\n that can be explained and justified.\n\n26:06.380 --> 26:11.380\n And so on one hand to say, oh, you know, AI is doing this.\n\n26:11.500 --> 26:13.700\n Why isn't doing this other thing?\n\n26:13.700 --> 26:16.300\n Well, this other thing's a lot harder.\n\n26:16.300 --> 26:20.180\n And it's interesting to think about why it's harder.\n\n26:20.180 --> 26:23.980\n And because you're interpreting the data\n\n26:23.980 --> 26:26.300\n in the context of prior models.\n\n26:26.300 --> 26:28.140\n In other words, understandings\n\n26:28.140 --> 26:30.260\n of what's important in the world, what's not important.\n\n26:30.260 --> 26:32.060\n What are all the other abstract features\n\n26:32.060 --> 26:35.420\n that drive our decision making?\n\n26:35.420 --> 26:36.980\n What's sensible, what's not sensible,\n\n26:36.980 --> 26:38.620\n what's good, what's bad, what's moral,\n\n26:38.620 --> 26:40.060\n what's valuable, what isn't?\n\n26:40.060 --> 26:41.160\n Where is that stuff?\n\n26:41.160 --> 26:43.300\n No one's applying the interpretation.\n\n26:43.300 --> 26:46.660\n So when I see you clicking on a bunch of stuff\n\n26:46.660 --> 26:49.780\n and I look at these simple features, the raw features,\n\n26:49.780 --> 26:51.140\n the features that are there in the data,\n\n26:51.140 --> 26:56.140\n like what words are being used or how long the material is\n\n26:57.700 --> 27:00.620\n or other very superficial features,\n\n27:00.620 --> 27:02.500\n what colors are being used in the material.\n\n27:02.500 --> 27:03.880\n Like, I don't know why you're clicking\n\n27:03.880 --> 27:04.980\n on this stuff you're clicking.\n\n27:04.980 --> 27:07.620\n Or if it's products, what the price is\n\n27:07.620 --> 27:09.540\n or what the categories and stuff like that.\n\n27:09.540 --> 27:11.540\n And I just feed you more of the same stuff.\n\n27:11.540 --> 27:13.740\n That's very different than kind of getting in there\n\n27:13.740 --> 27:16.020\n and saying, what does this mean?\n\n27:16.020 --> 27:20.380\n The stuff you're reading, like why are you reading it?\n\n27:21.380 --> 27:23.900\n What assumptions are you bringing to the table?\n\n27:23.900 --> 27:26.380\n Are those assumptions sensible?\n\n27:26.380 --> 27:28.980\n Does the material make any sense?\n\n27:28.980 --> 27:33.980\n Does it lead you to thoughtful, good conclusions?\n\n27:34.080 --> 27:37.420\n Again, there's interpretation and judgment involved\n\n27:37.420 --> 27:42.420\n in that process that isn't really happening in the AI today.\n\n27:42.420 --> 27:47.200\n That's harder because you have to start getting\n\n27:47.200 --> 27:52.040\n at the meaning of the stuff, of the content.\n\n27:52.040 --> 27:55.760\n You have to get at how humans interpret the content\n\n27:55.760 --> 27:58.720\n relative to their value system\n\n27:58.720 --> 28:00.600\n and deeper thought processes.\n\n28:00.600 --> 28:04.520\n So that's what meaning means is not just some kind\n\n28:04.520 --> 28:09.300\n of deep, timeless, semantic thing\n\n28:09.300 --> 28:10.960\n that the statement represents,\n\n28:10.960 --> 28:13.400\n but also how a large number of people\n\n28:13.400 --> 28:15.220\n are likely to interpret.\n\n28:15.220 --> 28:19.120\n So that's again, even meaning is a social construct.\n\n28:19.120 --> 28:22.800\n So you have to try to predict how most people\n\n28:22.800 --> 28:24.520\n would understand this kind of statement.\n\n28:24.520 --> 28:27.300\n Yeah, meaning is often relative,\n\n28:27.300 --> 28:30.400\n but meaning implies that the connections go beneath\n\n28:30.400 --> 28:31.840\n the surface of the artifacts.\n\n28:31.840 --> 28:35.480\n If I show you a painting, it's a bunch of colors on a canvas,\n\n28:35.480 --> 28:37.140\n what does it mean to you?\n\n28:37.140 --> 28:39.400\n And it may mean different things to different people\n\n28:39.400 --> 28:42.240\n because of their different experiences.\n\n28:42.240 --> 28:44.720\n It may mean something even different\n\n28:44.720 --> 28:46.440\n to the artist who painted it.\n\n28:47.440 --> 28:50.720\n As we try to get more rigorous with our communication,\n\n28:50.720 --> 28:53.280\n we try to really nail down that meaning.\n\n28:53.280 --> 28:58.280\n So we go from abstract art to precise mathematics,\n\n28:58.840 --> 29:01.520\n precise engineering drawings and things like that.\n\n29:01.520 --> 29:04.480\n We're really trying to say, I wanna narrow\n\n29:04.480 --> 29:08.300\n that space of possible interpretations\n\n29:08.300 --> 29:10.720\n because the precision of the communication\n\n29:10.720 --> 29:13.400\n ends up becoming more and more important.\n\n29:13.400 --> 29:17.920\n And so that means that I have to specify,\n\n29:17.920 --> 29:21.400\n and I think that's why this becomes really hard,\n\n29:21.400 --> 29:24.200\n because if I'm just showing you an artifact\n\n29:24.200 --> 29:26.000\n and you're looking at it superficially,\n\n29:26.000 --> 29:28.220\n whether it's a bunch of words on a page,\n\n29:28.220 --> 29:31.940\n or whether it's brushstrokes on a canvas\n\n29:31.940 --> 29:33.600\n or pixels on a photograph,\n\n29:33.600 --> 29:35.080\n you can sit there and you can interpret\n\n29:35.080 --> 29:38.880\n lots of different ways at many, many different levels.\n\n29:38.880 --> 29:43.880\n But when I wanna align our understanding of that,\n\n29:45.640 --> 29:48.360\n I have to specify a lot more stuff\n\n29:48.360 --> 29:52.320\n that's actually not directly in the artifact.\n\n29:52.320 --> 29:55.960\n Now I have to say, well, how are you interpreting\n\n29:55.960 --> 29:57.240\n this image and that image?\n\n29:57.240 --> 29:59.360\n And what about the colors and what do they mean to you?\n\n29:59.360 --> 30:02.360\n What perspective are you bringing to the table?\n\n30:02.360 --> 30:05.440\n What are your prior experiences with those artifacts?\n\n30:05.440 --> 30:08.800\n What are your fundamental assumptions and values?\n\n30:08.800 --> 30:10.840\n What is your ability to kind of reason,\n\n30:10.840 --> 30:13.640\n to chain together logical implication\n\n30:13.640 --> 30:14.480\n as you're sitting there and saying,\n\n30:14.480 --> 30:16.520\n well, if this is the case, then I would conclude this.\n\n30:16.520 --> 30:19.120\n And if that's the case, then I would conclude that.\n\n30:19.120 --> 30:22.520\n So your reasoning processes and how they work,\n\n30:22.520 --> 30:25.360\n your prior models and what they are,\n\n30:25.360 --> 30:27.200\n your values and your assumptions,\n\n30:27.200 --> 30:30.640\n all those things now come together into the interpretation.\n\n30:30.640 --> 30:33.820\n Getting in sync of that is hard.\n\n30:34.860 --> 30:37.620\n And yet humans are able to intuit some of that\n\n30:37.620 --> 30:39.580\n without any pre.\n\n30:39.580 --> 30:41.580\n Because they have the shared experience.\n\n30:41.580 --> 30:42.940\n And we're not talking about shared,\n\n30:42.940 --> 30:44.420\n two people having shared experience.\n\n30:44.420 --> 30:45.540\n I mean, as a society.\n\n30:45.540 --> 30:46.540\n That's correct.\n\n30:46.540 --> 30:51.180\n We have the shared experience and we have similar brains.\n\n30:51.180 --> 30:54.060\n So we tend to, in other words,\n\n30:54.060 --> 30:56.460\n part of our shared experiences are shared local experience.\n\n30:56.460 --> 30:57.860\n Like we may live in the same culture,\n\n30:57.860 --> 30:59.060\n we may live in the same society\n\n30:59.060 --> 31:02.020\n and therefore we have similar educations.\n\n31:02.020 --> 31:04.100\n We have some of what we like to call prior models\n\n31:04.100 --> 31:05.860\n about the word prior experiences.\n\n31:05.860 --> 31:07.380\n And we use that as a,\n\n31:07.380 --> 31:10.940\n think of it as a wide collection of interrelated variables\n\n31:10.940 --> 31:12.780\n and they're all bound to similar things.\n\n31:12.780 --> 31:15.060\n And so we take that as our background\n\n31:15.060 --> 31:17.540\n and we start interpreting things similarly.\n\n31:17.540 --> 31:21.860\n But as humans, we have a lot of shared experience.\n\n31:21.860 --> 31:24.980\n We do have similar brains, similar goals,\n\n31:24.980 --> 31:28.060\n similar emotions under similar circumstances.\n\n31:28.060 --> 31:29.020\n Because we're both humans.\n\n31:29.020 --> 31:31.420\n So now one of the early questions you asked,\n\n31:31.420 --> 31:36.420\n how is biological and computer information systems\n\n31:37.020 --> 31:37.980\n fundamentally different?\n\n31:37.980 --> 31:42.980\n Well, one is humans come with a lot of pre programmed stuff.\n\n31:43.840 --> 31:45.940\n A ton of program stuff.\n\n31:45.940 --> 31:47.220\n And they're able to communicate\n\n31:47.220 --> 31:50.340\n because they share that stuff.\n\n31:50.340 --> 31:52.700\n Do you think that shared knowledge,\n\n31:54.100 --> 31:57.580\n if we can maybe escape the hard work question,\n\n31:57.580 --> 31:59.460\n how much is encoded in the hardware?\n\n31:59.460 --> 32:01.260\n Just the shared knowledge in the software,\n\n32:01.260 --> 32:05.340\n the history, the many centuries of wars and so on\n\n32:05.340 --> 32:08.000\n that came to today, that shared knowledge.\n\n32:09.660 --> 32:13.400\n How hard is it to encode?\n\n32:14.340 --> 32:15.860\n Do you have a hope?\n\n32:15.860 --> 32:19.340\n Can you speak to how hard is it to encode that knowledge\n\n32:19.340 --> 32:22.780\n systematically in a way that could be used by a computer?\n\n32:22.780 --> 32:25.100\n So I think it is possible to learn to,\n\n32:25.100 --> 32:27.900\n for a machine to program a machine,\n\n32:27.900 --> 32:31.460\n to acquire that knowledge with a similar foundation.\n\n32:31.460 --> 32:36.120\n In other words, a similar interpretive foundation\n\n32:36.120 --> 32:38.060\n for processing that knowledge.\n\n32:38.060 --> 32:39.100\n What do you mean by that?\n\n32:39.100 --> 32:44.100\n So in other words, we view the world in a particular way.\n\n32:44.540 --> 32:48.820\n So in other words, we have a, if you will,\n\n32:48.820 --> 32:50.120\n as humans, we have a framework\n\n32:50.120 --> 32:52.260\n for interpreting the world around us.\n\n32:52.260 --> 32:55.220\n So we have multiple frameworks for interpreting\n\n32:55.220 --> 32:56.060\n the world around us.\n\n32:56.060 --> 32:59.780\n But if you're interpreting, for example,\n\n32:59.780 --> 33:01.340\n socio political interactions,\n\n33:01.340 --> 33:03.140\n you're thinking about where there's people,\n\n33:03.140 --> 33:05.540\n there's collections and groups of people,\n\n33:05.540 --> 33:08.460\n they have goals, goals largely built around survival\n\n33:08.460 --> 33:10.860\n and quality of life.\n\n33:10.860 --> 33:15.860\n There are fundamental economics around scarcity of resources.\n\n33:16.640 --> 33:19.660\n And when humans come and start interpreting\n\n33:19.660 --> 33:21.860\n a situation like that, because you brought up\n\n33:21.860 --> 33:23.600\n like historical events,\n\n33:23.600 --> 33:25.500\n they start interpreting situations like that.\n\n33:25.500 --> 33:29.500\n They apply a lot of this fundamental framework\n\n33:29.500 --> 33:30.740\n for interpreting that.\n\n33:30.740 --> 33:32.260\n Well, who are the people?\n\n33:32.260 --> 33:33.300\n What were their goals?\n\n33:33.300 --> 33:35.020\n What resources did they have?\n\n33:35.020 --> 33:37.020\n How much power influence did they have over the other?\n\n33:37.020 --> 33:40.540\n Like this fundamental substrate, if you will,\n\n33:40.540 --> 33:42.780\n for interpreting and reasoning about that.\n\n33:43.820 --> 33:46.920\n So I think it is possible to imbue a computer\n\n33:46.920 --> 33:50.660\n with that stuff that humans like take for granted\n\n33:50.660 --> 33:54.020\n when they go and sit down and try to interpret things.\n\n33:54.020 --> 33:58.860\n And then with that foundation, they acquire,\n\n33:58.860 --> 34:00.300\n they start acquiring the details,\n\n34:00.300 --> 34:02.820\n the specifics in a given situation,\n\n34:02.820 --> 34:05.700\n are then able to interpret it with regard to that framework.\n\n34:05.700 --> 34:08.700\n And then given that interpretation, they can do what?\n\n34:08.700 --> 34:10.300\n They can predict.\n\n34:10.300 --> 34:12.220\n But not only can they predict,\n\n34:12.220 --> 34:14.820\n they can predict now with an explanation\n\n34:15.940 --> 34:17.940\n that can be given in those terms,\n\n34:17.940 --> 34:20.200\n in the terms of that underlying framework\n\n34:20.200 --> 34:22.300\n that most humans share.\n\n34:22.300 --> 34:24.620\n Now you could find humans that come and interpret events\n\n34:24.620 --> 34:26.300\n very differently than other humans\n\n34:26.300 --> 34:30.620\n because they're like using a different framework.\n\n34:30.620 --> 34:32.500\n The movie Matrix comes to mind\n\n34:32.500 --> 34:36.420\n where they decided humans were really just batteries,\n\n34:36.420 --> 34:39.940\n and that's how they interpreted the value of humans\n\n34:39.940 --> 34:41.640\n as a source of electrical energy.\n\n34:41.640 --> 34:45.460\n So, but I think that for the most part,\n\n34:45.460 --> 34:50.460\n we have a way of interpreting the events\n\n34:50.780 --> 34:52.260\n or the social events around us\n\n34:52.260 --> 34:54.140\n because we have this shared framework.\n\n34:54.140 --> 34:58.700\n It comes from, again, the fact that we're similar beings\n\n34:58.700 --> 35:01.100\n that have similar goals, similar emotions,\n\n35:01.100 --> 35:02.900\n and we can make sense out of these.\n\n35:02.900 --> 35:05.020\n These frameworks make sense to us.\n\n35:05.020 --> 35:08.060\n So how much knowledge is there, do you think?\n\n35:08.060 --> 35:09.580\n So you said it's possible.\n\n35:09.580 --> 35:12.140\n Well, there's a tremendous amount of detailed knowledge\n\n35:12.140 --> 35:12.980\n in the world.\n\n35:12.980 --> 35:17.580\n You could imagine effectively infinite number\n\n35:17.580 --> 35:20.840\n of unique situations and unique configurations\n\n35:20.840 --> 35:22.100\n of these things.\n\n35:22.100 --> 35:25.100\n But the knowledge that you need,\n\n35:25.100 --> 35:27.600\n what I refer to as like the frameworks,\n\n35:27.600 --> 35:29.580\n for you need for interpreting them, I don't think.\n\n35:29.580 --> 35:31.500\n I think those are finite.\n\n35:31.500 --> 35:35.020\n You think the frameworks are more important\n\n35:35.020 --> 35:36.780\n than the bulk of the knowledge?\n\n35:36.780 --> 35:37.780\n So it's like framing.\n\n35:37.780 --> 35:39.220\n Yeah, because what the frameworks do\n\n35:39.220 --> 35:41.580\n is they give you now the ability to interpret and reason,\n\n35:41.580 --> 35:43.100\n and to interpret and reason,\n\n35:43.100 --> 35:46.780\n to interpret and reason over the specifics\n\n35:46.780 --> 35:49.220\n in ways that other humans would understand.\n\n35:49.220 --> 35:51.240\n What about the specifics?\n\n35:51.240 --> 35:53.980\n You know, you acquire the specifics by reading\n\n35:53.980 --> 35:55.540\n and by talking to other people.\n\n35:55.540 --> 35:57.700\n So I'm mostly actually just even,\n\n35:57.700 --> 36:00.240\n if we can focus on even the beginning,\n\n36:00.240 --> 36:01.500\n the common sense stuff,\n\n36:01.500 --> 36:03.420\n the stuff that doesn't even require reading,\n\n36:03.420 --> 36:06.860\n or it almost requires playing around with the world\n\n36:06.860 --> 36:10.820\n or something, just being able to sort of manipulate objects,\n\n36:10.820 --> 36:13.900\n drink water and so on, all of that.\n\n36:13.900 --> 36:16.140\n Every time we try to do that kind of thing\n\n36:16.140 --> 36:21.060\n in robotics or AI, it seems to be like an onion.\n\n36:21.060 --> 36:23.240\n You seem to realize how much knowledge\n\n36:23.240 --> 36:24.620\n is really required to perform\n\n36:24.620 --> 36:27.060\n even some of these basic tasks.\n\n36:27.060 --> 36:30.340\n Do you have that sense as well?\n\n36:30.340 --> 36:33.820\n And if so, how do we get all those details?\n\n36:33.820 --> 36:35.700\n Are they written down somewhere?\n\n36:35.700 --> 36:39.220\n Do they have to be learned through experience?\n\n36:39.220 --> 36:41.340\n So I think when, like, if you're talking about\n\n36:41.340 --> 36:44.700\n sort of the physics, the basic physics around us,\n\n36:44.700 --> 36:46.580\n for example, acquiring information about,\n\n36:46.580 --> 36:48.140\n acquiring how that works.\n\n36:49.720 --> 36:52.220\n Yeah, I mean, I think there's a combination of things going,\n\n36:52.220 --> 36:54.620\n I think there's a combination of things going on.\n\n36:54.620 --> 36:57.780\n I think there is like fundamental pattern matching,\n\n36:57.780 --> 36:59.660\n like what we were talking about before,\n\n36:59.660 --> 37:01.060\n where you see enough examples,\n\n37:01.060 --> 37:03.840\n enough data about something and you start assuming that.\n\n37:03.840 --> 37:05.480\n And with similar input,\n\n37:05.480 --> 37:07.720\n I'm gonna predict similar outputs.\n\n37:07.720 --> 37:10.100\n You can't necessarily explain it at all.\n\n37:10.100 --> 37:13.600\n You may learn very quickly that when you let something go,\n\n37:14.640 --> 37:16.500\n it falls to the ground.\n\n37:16.500 --> 37:19.760\n But you can't necessarily explain that.\n\n37:19.760 --> 37:22.340\n But that's such a deep idea,\n\n37:22.340 --> 37:25.200\n that if you let something go, like the idea of gravity.\n\n37:26.120 --> 37:27.900\n I mean, people are letting things go\n\n37:27.900 --> 37:29.100\n and counting on them falling\n\n37:29.100 --> 37:30.760\n well before they understood gravity.\n\n37:30.760 --> 37:33.860\n But that seems to be, that's exactly what I mean,\n\n37:33.860 --> 37:36.080\n is before you take a physics class\n\n37:36.080 --> 37:39.540\n or study anything about Newton,\n\n37:39.540 --> 37:42.540\n just the idea that stuff falls to the ground\n\n37:42.540 --> 37:45.300\n and then you'd be able to generalize\n\n37:45.300 --> 37:48.540\n that all kinds of stuff falls to the ground.\n\n37:49.540 --> 37:53.420\n It just seems like a non, without encoding it,\n\n37:53.420 --> 37:55.220\n like hard coding it in,\n\n37:55.220 --> 37:57.420\n it seems like a difficult thing to pick up.\n\n37:57.420 --> 38:01.380\n It seems like you have to have a lot of different knowledge\n\n38:01.380 --> 38:05.340\n to be able to integrate that into the framework,\n\n38:05.340 --> 38:07.700\n sort of into everything else.\n\n38:07.700 --> 38:10.340\n So both know that stuff falls to the ground\n\n38:10.340 --> 38:15.340\n and start to reason about sociopolitical discourse.\n\n38:16.340 --> 38:18.540\n So both, like the very basic\n\n38:18.540 --> 38:22.540\n and the high level reasoning decision making.\n\n38:22.540 --> 38:24.940\n I guess my question is, how hard is this problem?\n\n38:26.420 --> 38:29.060\n And sorry to linger on it because again,\n\n38:29.060 --> 38:31.100\n and we'll get to it for sure,\n\n38:31.100 --> 38:34.340\n as what Watson with Jeopardy did is take on a problem\n\n38:34.340 --> 38:35.500\n that's much more constrained\n\n38:35.500 --> 38:38.260\n but has the same hugeness of scale,\n\n38:38.260 --> 38:40.660\n at least from the outsider's perspective.\n\n38:40.660 --> 38:42.900\n So I'm asking the general life question\n\n38:42.900 --> 38:45.580\n of to be able to be an intelligent being\n\n38:45.580 --> 38:50.580\n and reason in the world about both gravity and politics,\n\n38:50.900 --> 38:52.140\n how hard is that problem?\n\n38:53.900 --> 38:56.180\n So I think it's solvable.\n\n38:59.440 --> 39:00.700\n Okay, now beautiful.\n\n39:00.700 --> 39:04.820\n So what about time travel?\n\n39:04.820 --> 39:08.700\n Okay, I'm just saying the same answer.\n\n39:08.700 --> 39:09.700\n Not as convinced.\n\n39:09.700 --> 39:11.100\n Not as convinced yet, okay.\n\n39:11.100 --> 39:14.260\n No, I think it is solvable.\n\n39:14.260 --> 39:16.500\n I mean, I think that it's a learn,\n\n39:16.500 --> 39:18.440\n first of all, it's about getting machines to learn.\n\n39:18.440 --> 39:21.380\n Learning is fundamental.\n\n39:21.380 --> 39:24.420\n And I think we're already in a place that we understand,\n\n39:24.420 --> 39:28.620\n for example, how machines can learn in various ways.\n\n39:28.620 --> 39:32.460\n Right now, our learning stuff is sort of primitive\n\n39:32.460 --> 39:37.460\n in that we haven't sort of taught machines\n\n39:38.040 --> 39:39.260\n to learn the frameworks.\n\n39:39.260 --> 39:41.160\n We don't communicate our frameworks\n\n39:41.160 --> 39:42.860\n because of how shared they are, in some cases we do,\n\n39:42.860 --> 39:46.380\n but we don't annotate, if you will,\n\n39:46.380 --> 39:48.960\n all the data in the world with the frameworks\n\n39:48.960 --> 39:53.120\n that are inherent or underlying our understanding.\n\n39:53.120 --> 39:56.180\n Instead, we just operate with the data.\n\n39:56.180 --> 39:59.100\n So if we wanna be able to reason over the data\n\n39:59.100 --> 40:02.300\n in similar terms in the common frameworks,\n\n40:02.300 --> 40:03.740\n we need to be able to teach the computer,\n\n40:03.740 --> 40:06.300\n or at least we need to program the computer\n\n40:06.300 --> 40:10.480\n to acquire, to have access to and acquire,\n\n40:10.480 --> 40:12.860\n learn the frameworks as well\n\n40:12.860 --> 40:15.740\n and connect the frameworks to the data.\n\n40:15.740 --> 40:18.420\n I think this can be done.\n\n40:18.420 --> 40:22.980\n I think we can start, I think machine learning,\n\n40:22.980 --> 40:26.100\n for example, with enough examples,\n\n40:26.100 --> 40:28.920\n can start to learn these basic dynamics.\n\n40:28.920 --> 40:32.240\n Will they relate them necessarily to the gravity?\n\n40:32.240 --> 40:37.120\n Not unless they can also acquire those theories as well\n\n40:38.320 --> 40:40.940\n and put the experiential knowledge\n\n40:40.940 --> 40:43.400\n and connect it back to the theoretical knowledge.\n\n40:43.400 --> 40:47.200\n I think if we think in terms of these class of architectures\n\n40:47.200 --> 40:51.020\n that are designed to both learn the specifics,\n\n40:51.020 --> 40:54.220\n find the patterns, but also acquire the frameworks\n\n40:54.220 --> 40:56.340\n and connect the data to the frameworks.\n\n40:56.340 --> 40:59.700\n If we think in terms of robust architectures like this,\n\n40:59.700 --> 41:03.420\n I think there is a path toward getting there.\n\n41:03.420 --> 41:06.220\n In terms of encoding architectures like that,\n\n41:06.220 --> 41:09.200\n do you think systems that are able to do this\n\n41:10.300 --> 41:14.940\n will look like neural networks or representing,\n\n41:14.940 --> 41:18.740\n if you look back to the 80s and 90s with the expert systems,\n\n41:18.740 --> 41:24.540\n they're more like graphs, systems that are based in logic,\n\n41:24.540 --> 41:26.500\n able to contain a large amount of knowledge\n\n41:26.500 --> 41:28.500\n where the challenge was the automated acquisition\n\n41:28.500 --> 41:29.860\n of that knowledge.\n\n41:29.860 --> 41:33.820\n I guess the question is when you collect both the frameworks\n\n41:33.820 --> 41:35.300\n and the knowledge from the data,\n\n41:35.300 --> 41:37.260\n what do you think that thing will look like?\n\n41:37.260 --> 41:39.340\n Yeah, so I mean, I think asking the question,\n\n41:39.340 --> 41:41.260\n they look like neural networks is a bit of a red herring.\n\n41:41.260 --> 41:45.180\n I mean, I think that they will certainly do inductive\n\n41:45.180 --> 41:46.720\n or pattern match based reasoning.\n\n41:46.720 --> 41:49.000\n And I've already experimented with architectures\n\n41:49.000 --> 41:52.700\n that combine both that use machine learning\n\n41:52.700 --> 41:55.340\n and neural networks to learn certain classes of knowledge,\n\n41:55.340 --> 41:57.300\n in other words, to find repeated patterns\n\n41:57.300 --> 42:01.540\n in order for it to make good inductive guesses,\n\n42:01.540 --> 42:05.260\n but then ultimately to try to take those learnings\n\n42:05.260 --> 42:09.540\n and marry them, in other words, connect them to frameworks\n\n42:09.540 --> 42:11.500\n so that it can then reason over that\n\n42:11.500 --> 42:13.660\n in terms other humans understand.\n\n42:13.660 --> 42:16.100\n So for example, at elemental cognition, we do both.\n\n42:16.100 --> 42:19.820\n We have architectures that do both, both those things,\n\n42:19.820 --> 42:21.660\n but also have a learning method\n\n42:21.660 --> 42:24.400\n for acquiring the frameworks themselves and saying,\n\n42:24.400 --> 42:27.280\n look, ultimately, I need to take this data.\n\n42:27.280 --> 42:30.020\n I need to interpret it in the form of these frameworks\n\n42:30.020 --> 42:30.860\n so they can reason over it.\n\n42:30.860 --> 42:33.340\n So there is a fundamental knowledge representation,\n\n42:33.340 --> 42:34.220\n like what you're saying,\n\n42:34.220 --> 42:36.780\n like these graphs of logic, if you will.\n\n42:36.780 --> 42:39.280\n There are also neural networks\n\n42:39.280 --> 42:41.620\n that acquire a certain class of information.\n\n42:43.100 --> 42:45.900\n Then they then align them with these frameworks,\n\n42:45.900 --> 42:47.140\n but there's also a mechanism\n\n42:47.140 --> 42:49.180\n to acquire the frameworks themselves.\n\n42:49.180 --> 42:52.540\n Yeah, so it seems like the idea of frameworks\n\n42:52.540 --> 42:55.380\n requires some kind of collaboration with humans.\n\n42:55.380 --> 42:56.300\n Absolutely.\n\n42:56.300 --> 42:59.340\n So do you think of that collaboration as direct?\n\n42:59.340 --> 43:01.900\n Well, and let's be clear.\n\n43:01.900 --> 43:06.060\n Only for the express purpose that you're designing,\n\n43:06.060 --> 43:09.500\n you're designing an intelligence\n\n43:09.500 --> 43:12.500\n that can ultimately communicate with humans\n\n43:12.500 --> 43:15.940\n in the terms of frameworks that help them understand things.\n\n43:17.060 --> 43:19.380\n So to be really clear,\n\n43:19.380 --> 43:24.340\n you can independently create a machine learning system,\n\n43:24.340 --> 43:28.460\n an intelligence that I might call an alien intelligence\n\n43:28.460 --> 43:31.140\n that does a better job than you with some things,\n\n43:31.140 --> 43:33.500\n but can't explain the framework to you.\n\n43:33.500 --> 43:36.720\n That doesn't mean it might be better than you at the thing.\n\n43:36.720 --> 43:39.500\n It might be that you cannot comprehend the framework\n\n43:39.500 --> 43:42.780\n that it may have created for itself that is inexplicable\n\n43:42.780 --> 43:43.900\n to you.\n\n43:43.900 --> 43:45.260\n That's a reality.\n\n43:45.260 --> 43:48.780\n But you're more interested in a case where you can.\n\n43:48.780 --> 43:51.060\n I am, yeah.\n\n43:51.060 --> 43:54.260\n My sort of approach to AI is because\n\n43:54.260 --> 43:55.900\n I've set the goal for myself.\n\n43:55.900 --> 43:58.860\n I want machines to be able to ultimately communicate,\n\n44:00.320 --> 44:01.160\n understanding with humans.\n\n44:01.160 --> 44:03.460\n I want them to be able to acquire and communicate,\n\n44:03.460 --> 44:04.700\n acquire knowledge from humans\n\n44:04.700 --> 44:06.980\n and communicate knowledge to humans.\n\n44:06.980 --> 44:11.580\n They should be using what inductive\n\n44:11.580 --> 44:13.700\n machine learning techniques are good at,\n\n44:13.700 --> 44:16.780\n which is to observe patterns of data,\n\n44:16.780 --> 44:19.260\n whether it be in language or whether it be in images\n\n44:19.260 --> 44:21.340\n or videos or whatever,\n\n44:23.100 --> 44:25.420\n to acquire these patterns,\n\n44:25.420 --> 44:29.340\n to induce the generalizations from those patterns,\n\n44:29.340 --> 44:31.220\n but then ultimately to work with humans\n\n44:31.220 --> 44:34.640\n to connect them to frameworks, interpretations, if you will,\n\n44:34.640 --> 44:36.700\n that ultimately make sense to humans.\n\n44:36.700 --> 44:38.460\n Of course, the machine is gonna have the strength\n\n44:38.460 --> 44:41.420\n that it has, the richer, longer memory,\n\n44:41.420 --> 44:45.380\n but it has the more rigorous reasoning abilities,\n\n44:45.380 --> 44:47.040\n the deeper reasoning abilities,\n\n44:47.040 --> 44:51.060\n so it'll be an interesting complementary relationship\n\n44:51.060 --> 44:53.180\n between the human and the machine.\n\n44:53.180 --> 44:55.100\n Do you think that ultimately needs explainability\n\n44:55.100 --> 44:55.980\n like a machine?\n\n44:55.980 --> 44:57.860\n So if we look, we study, for example,\n\n44:57.860 --> 45:00.820\n Tesla autopilot a lot, where humans,\n\n45:00.820 --> 45:02.780\n I don't know if you've driven the vehicle,\n\n45:02.780 --> 45:04.360\n are aware of what it is.\n\n45:04.360 --> 45:09.100\n So you're basically the human and machine\n\n45:09.100 --> 45:10.300\n are working together there,\n\n45:10.300 --> 45:12.500\n and the human is responsible for their own life\n\n45:12.500 --> 45:14.220\n to monitor the system,\n\n45:14.220 --> 45:18.380\n and the system fails every few miles,\n\n45:18.380 --> 45:20.500\n and so there's hundreds,\n\n45:20.500 --> 45:23.620\n there's millions of those failures a day,\n\n45:23.620 --> 45:25.780\n and so that's like a moment of interaction.\n\n45:25.780 --> 45:26.620\n Do you see?\n\n45:26.620 --> 45:27.900\n Yeah, that's exactly right.\n\n45:27.900 --> 45:29.900\n That's a moment of interaction\n\n45:29.900 --> 45:34.820\n where the machine has learned some stuff,\n\n45:34.820 --> 45:38.720\n it has a failure, somehow the failure's communicated,\n\n45:38.720 --> 45:41.880\n the human is now filling in the mistake, if you will,\n\n45:41.880 --> 45:43.620\n or maybe correcting or doing something\n\n45:43.620 --> 45:45.860\n that is more successful in that case,\n\n45:45.860 --> 45:47.900\n the computer takes that learning.\n\n45:47.900 --> 45:50.260\n So I believe that the collaboration\n\n45:50.260 --> 45:52.300\n between human and machine,\n\n45:52.300 --> 45:53.900\n I mean, that's sort of a primitive example\n\n45:53.900 --> 45:55.040\n and sort of a more,\n\n45:56.920 --> 45:59.220\n another example is where the machine's literally talking\n\n45:59.220 --> 46:02.740\n to you and saying, look, I'm reading this thing.\n\n46:02.740 --> 46:06.580\n I know that the next word might be this or that,\n\n46:06.580 --> 46:08.900\n but I don't really understand why.\n\n46:08.900 --> 46:09.940\n I have my guess.\n\n46:09.940 --> 46:14.060\n Can you help me understand the framework that supports this\n\n46:14.060 --> 46:16.060\n and then can kind of acquire that,\n\n46:16.060 --> 46:18.140\n take that and reason about it and reuse it\n\n46:18.140 --> 46:20.520\n the next time it's reading to try to understand something,\n\n46:20.520 --> 46:24.760\n not unlike a human student might do.\n\n46:24.760 --> 46:27.480\n I mean, I remember when my daughter was in first grade\n\n46:27.480 --> 46:31.180\n and she had a reading assignment about electricity\n\n46:32.280 --> 46:35.600\n and somewhere in the text it says,\n\n46:35.600 --> 46:38.620\n and electricity is produced by water flowing over turbines\n\n46:38.620 --> 46:39.900\n or something like that.\n\n46:39.900 --> 46:41.240\n And then there's a question that says,\n\n46:41.240 --> 46:43.140\n well, how is electricity created?\n\n46:43.140 --> 46:45.180\n And so my daughter comes to me and says,\n\n46:45.180 --> 46:46.500\n I mean, I could, you know,\n\n46:46.500 --> 46:49.200\n created and produced are kind of synonyms in this case.\n\n46:49.200 --> 46:50.620\n So I can go back to the text\n\n46:50.620 --> 46:53.660\n and I can copy by water flowing over turbines,\n\n46:53.660 --> 46:56.120\n but I have no idea what that means.\n\n46:56.120 --> 46:57.620\n Like I don't know how to interpret\n\n46:57.620 --> 47:00.380\n water flowing over turbines and what electricity even is.\n\n47:00.380 --> 47:04.000\n I mean, I can get the answer right by matching the text,\n\n47:04.000 --> 47:06.140\n but I don't have any framework for understanding\n\n47:06.140 --> 47:07.860\n what this means at all.\n\n47:07.860 --> 47:10.500\n And framework really is, I mean, it's a set of,\n\n47:10.500 --> 47:14.140\n not to be mathematical, but axioms of ideas\n\n47:14.140 --> 47:16.340\n that you bring to the table and interpreting stuff\n\n47:16.340 --> 47:18.380\n and then you build those up somehow.\n\n47:18.380 --> 47:20.460\n You build them up with the expectation\n\n47:20.460 --> 47:23.780\n that there's a shared understanding of what they are.\n\n47:23.780 --> 47:27.800\n Sure, yeah, it's the social, that us humans,\n\n47:28.900 --> 47:32.060\n do you have a sense that humans on earth in general\n\n47:32.060 --> 47:36.500\n share a set of, like how many frameworks are there?\n\n47:36.500 --> 47:38.200\n I mean, it depends on how you bound them, right?\n\n47:38.200 --> 47:39.900\n So in other words, how big or small,\n\n47:39.900 --> 47:41.780\n like their individual scope,\n\n47:42.640 --> 47:44.220\n but there's lots and there are new ones.\n\n47:44.220 --> 47:47.620\n I think the way I think about it is kind of in a layer.\n\n47:47.620 --> 47:50.020\n I think that the architectures are being layered in that.\n\n47:50.020 --> 47:53.560\n There's a small set of primitives.\n\n47:53.560 --> 47:56.260\n They allow you the foundation to build frameworks.\n\n47:56.260 --> 47:58.360\n And then there may be many frameworks,\n\n47:58.360 --> 48:00.580\n but you have the ability to acquire them.\n\n48:00.580 --> 48:03.020\n And then you have the ability to reuse them.\n\n48:03.020 --> 48:04.940\n I mean, one of the most compelling ways\n\n48:04.940 --> 48:07.220\n of thinking about this is a reasoning by analogy,\n\n48:07.220 --> 48:08.180\n where I can say, oh, wow,\n\n48:08.180 --> 48:09.980\n I've learned something very similar.\n\n48:11.340 --> 48:15.240\n I never heard of this game soccer,\n\n48:15.240 --> 48:17.820\n but if it's like basketball in the sense\n\n48:17.820 --> 48:19.580\n that the goal's like the hoop\n\n48:19.580 --> 48:20.980\n and I have to get the ball in the hoop\n\n48:20.980 --> 48:23.500\n and I have guards and I have this and I have that,\n\n48:23.500 --> 48:26.460\n like where are the similarities\n\n48:26.460 --> 48:27.740\n and where are the differences?\n\n48:27.740 --> 48:29.120\n And I have a foundation now\n\n48:29.120 --> 48:31.340\n for interpreting this new information.\n\n48:31.340 --> 48:33.260\n And then the different groups,\n\n48:33.260 --> 48:36.380\n like the millennials will have a framework.\n\n48:36.380 --> 48:41.380\n And then, you know, the Democrats and Republicans.\n\n48:41.660 --> 48:43.820\n Millennials, nobody wants that framework.\n\n48:43.820 --> 48:45.860\n Well, I mean, I think, right,\n\n48:45.860 --> 48:48.100\n I mean, you're talking about political and social ways\n\n48:48.100 --> 48:49.860\n of interpreting the world around them.\n\n48:49.860 --> 48:51.980\n And I think these frameworks are still largely,\n\n48:51.980 --> 48:52.800\n largely similar.\n\n48:52.800 --> 48:54.540\n I think they differ in maybe\n\n48:54.540 --> 48:57.380\n what some fundamental assumptions and values are.\n\n48:57.380 --> 48:59.860\n Now, from a reasoning perspective,\n\n48:59.860 --> 49:01.620\n like the ability to process the framework,\n\n49:01.620 --> 49:04.160\n it might not be that different.\n\n49:04.160 --> 49:06.560\n The implications of different fundamental values\n\n49:06.560 --> 49:09.460\n or fundamental assumptions in those frameworks\n\n49:09.460 --> 49:12.160\n may reach very different conclusions.\n\n49:12.160 --> 49:14.780\n So from a social perspective,\n\n49:14.780 --> 49:16.900\n the conclusions may be very different.\n\n49:16.900 --> 49:18.420\n From an intelligence perspective,\n\n49:18.420 --> 49:21.620\n I just followed where my assumptions took me.\n\n49:21.620 --> 49:23.420\n Yeah, the process itself will look similar.\n\n49:23.420 --> 49:25.580\n But that's a fascinating idea\n\n49:25.580 --> 49:30.580\n that frameworks really help carve\n\n49:30.820 --> 49:33.740\n how a statement will be interpreted.\n\n49:33.740 --> 49:38.740\n I mean, having a Democrat and a Republican framework\n\n49:40.360 --> 49:42.180\n and then read the exact same statement\n\n49:42.180 --> 49:44.200\n and the conclusions that you derive\n\n49:44.200 --> 49:45.460\n will be totally different\n\n49:45.460 --> 49:47.620\n from an AI perspective is fascinating.\n\n49:47.620 --> 49:49.460\n What we would want out of the AI\n\n49:49.460 --> 49:51.140\n is to be able to tell you\n\n49:51.140 --> 49:53.740\n that this perspective, one perspective,\n\n49:53.740 --> 49:55.540\n one set of assumptions is gonna lead you here,\n\n49:55.540 --> 49:58.700\n another set of assumptions is gonna lead you there.\n\n49:58.700 --> 50:01.420\n And in fact, to help people reason and say,\n\n50:01.420 --> 50:05.220\n oh, I see where our differences lie.\n\n50:05.220 --> 50:06.940\n I have this fundamental belief about that.\n\n50:06.940 --> 50:09.200\n I have this fundamental belief about that.\n\n50:09.200 --> 50:10.100\n Yeah, that's quite brilliant.\n\n50:10.100 --> 50:12.620\n From my perspective, NLP,\n\n50:12.620 --> 50:14.140\n there's this idea that there's one way\n\n50:14.140 --> 50:16.100\n to really understand a statement,\n\n50:16.100 --> 50:18.780\n but that probably isn't.\n\n50:18.780 --> 50:20.140\n There's probably an infinite number of ways\n\n50:20.140 --> 50:21.980\n to understand a statement, depending on the question.\n\n50:21.980 --> 50:23.420\n There's lots of different interpretations,\n\n50:23.420 --> 50:28.420\n and the broader the content, the richer it is.\n\n50:31.460 --> 50:35.260\n And so you and I can have very different experiences\n\n50:35.260 --> 50:37.420\n with the same text, obviously.\n\n50:37.420 --> 50:41.300\n And if we're committed to understanding each other,\n\n50:42.300 --> 50:45.260\n we start, and that's the other important point,\n\n50:45.260 --> 50:47.740\n if we're committed to understanding each other,\n\n50:47.740 --> 50:51.860\n we start decomposing and breaking down our interpretation\n\n50:51.860 --> 50:54.020\n to its more and more primitive components\n\n50:54.020 --> 50:55.900\n until we get to that point where we say,\n\n50:55.900 --> 50:58.260\n oh, I see why we disagree.\n\n50:58.260 --> 51:00.500\n And we try to understand how fundamental\n\n51:00.500 --> 51:02.220\n that disagreement really is.\n\n51:02.220 --> 51:04.580\n But that requires a commitment\n\n51:04.580 --> 51:06.540\n to breaking down that interpretation\n\n51:06.540 --> 51:08.940\n in terms of that framework in a logical way.\n\n51:08.940 --> 51:12.780\n Otherwise, and this is why I think of AI\n\n51:12.780 --> 51:16.020\n as really complimenting and helping human intelligence\n\n51:16.020 --> 51:19.860\n to overcome some of its biases and its predisposition\n\n51:19.860 --> 51:24.860\n to be persuaded by more shallow reasoning\n\n51:25.060 --> 51:26.980\n in the sense that we get over this idea,\n\n51:26.980 --> 51:29.980\n well, I'm right because I'm Republican,\n\n51:29.980 --> 51:31.380\n or I'm right because I'm Democratic,\n\n51:31.380 --> 51:33.380\n and someone labeled this as Democratic point of view,\n\n51:33.380 --> 51:35.420\n or it has the following keywords in it.\n\n51:35.420 --> 51:38.500\n And if the machine can help us break that argument down\n\n51:38.500 --> 51:41.660\n and say, wait a second, what do you really think\n\n51:41.660 --> 51:42.500\n about this, right?\n\n51:42.500 --> 51:45.460\n So essentially holding us accountable\n\n51:45.460 --> 51:47.540\n to doing more critical thinking.\n\n51:47.540 --> 51:49.500\n We're gonna have to sit and think about this fast.\n\n51:49.500 --> 51:50.940\n That's, I love that.\n\n51:50.940 --> 51:53.580\n I think that's really empowering use of AI\n\n51:53.580 --> 51:57.180\n for the public discourse is completely disintegrating\n\n51:57.180 --> 52:00.460\n currently as we learn how to do it on social media.\n\n52:00.460 --> 52:01.300\n That's right.\n\n52:02.460 --> 52:05.860\n So one of the greatest accomplishments\n\n52:05.860 --> 52:10.860\n in the history of AI is Watson competing\n\n52:12.140 --> 52:14.700\n in the game of Jeopardy against humans.\n\n52:14.700 --> 52:18.940\n And you were a lead in that, a critical part of that.\n\n52:18.940 --> 52:20.620\n Let's start at the very basics.\n\n52:20.620 --> 52:22.860\n What is the game of Jeopardy?\n\n52:22.860 --> 52:25.860\n The game for us humans, human versus human.\n\n52:25.860 --> 52:30.860\n Right, so it's to take a question and answer it.\n\n52:33.900 --> 52:34.740\n The game of Jeopardy.\n\n52:34.740 --> 52:35.580\n It's just the opposite.\n\n52:35.580 --> 52:38.780\n Actually, well, no, but it's not, right?\n\n52:38.780 --> 52:39.620\n It's really not.\n\n52:39.620 --> 52:41.860\n It's really to get a question and answer,\n\n52:41.860 --> 52:43.940\n but it's what we call a factoid question.\n\n52:43.940 --> 52:46.860\n So this notion of like, it really relates to some fact\n\n52:46.860 --> 52:49.260\n that two people would argue\n\n52:49.260 --> 52:50.580\n whether the facts are true or not.\n\n52:50.580 --> 52:51.580\n In fact, most people wouldn't.\n\n52:51.580 --> 52:53.060\n Jeopardy kind of counts on the idea\n\n52:53.060 --> 52:57.660\n that these statements have factual answers.\n\n52:57.660 --> 53:02.020\n And the idea is to, first of all,\n\n53:02.020 --> 53:03.780\n determine whether or not you know the answer,\n\n53:03.780 --> 53:06.100\n which is sort of an interesting twist.\n\n53:06.100 --> 53:07.860\n So first of all, understand the question.\n\n53:07.860 --> 53:08.860\n You have to understand the question.\n\n53:08.860 --> 53:09.860\n What is it asking?\n\n53:09.860 --> 53:10.740\n And that's a good point\n\n53:10.740 --> 53:14.460\n because the questions are not asked directly, right?\n\n53:14.460 --> 53:15.540\n They're all like,\n\n53:15.540 --> 53:18.340\n the way the questions are asked is nonlinear.\n\n53:18.340 --> 53:20.660\n It's like, it's a little bit witty.\n\n53:20.660 --> 53:22.460\n It's a little bit playful sometimes.\n\n53:22.460 --> 53:25.940\n It's a little bit tricky.\n\n53:25.940 --> 53:30.580\n Yeah, they're asked in exactly numerous witty, tricky ways.\n\n53:30.580 --> 53:32.540\n Exactly what they're asking is not obvious.\n\n53:32.540 --> 53:35.060\n It takes inexperienced humans a while\n\n53:35.060 --> 53:36.900\n to go, what is it even asking?\n\n53:36.900 --> 53:39.620\n And it's sort of an interesting realization that you have\n\n53:39.620 --> 53:40.980\n when somebody says, oh, what's,\n\n53:40.980 --> 53:42.420\n Jeopardy is a question answering show.\n\n53:42.420 --> 53:43.860\n And then he's like, oh, like, I know a lot.\n\n53:43.860 --> 53:45.980\n And then you read it and you're still trying\n\n53:45.980 --> 53:48.300\n to process the question and the champions have answered\n\n53:48.300 --> 53:49.140\n and moved on.\n\n53:49.140 --> 53:51.180\n There are three questions ahead\n\n53:51.180 --> 53:54.060\n by the time you figured out what the question even meant.\n\n53:54.060 --> 53:56.460\n So there's definitely an ability there\n\n53:56.460 --> 53:59.500\n to just parse out what the question even is.\n\n53:59.500 --> 54:00.820\n So that was certainly challenging.\n\n54:00.820 --> 54:02.220\n It's interesting historically though,\n\n54:02.220 --> 54:05.460\n if you look back at the Jeopardy games much earlier,\n\n54:05.460 --> 54:08.140\n you know, early games. Like 60s, 70s, that kind of thing.\n\n54:08.140 --> 54:10.180\n The questions were much more direct.\n\n54:10.180 --> 54:11.300\n They weren't quite like that.\n\n54:11.300 --> 54:13.660\n They got sort of more and more interesting,\n\n54:13.660 --> 54:15.340\n the way they asked them that sort of got more\n\n54:15.340 --> 54:18.340\n and more interesting and subtle and nuanced\n\n54:18.340 --> 54:20.780\n and humorous and witty over time,\n\n54:20.780 --> 54:22.500\n which really required the human\n\n54:22.500 --> 54:24.260\n to kind of make the right connections\n\n54:24.260 --> 54:26.860\n in figuring out what the question was even asking.\n\n54:26.860 --> 54:29.940\n So yeah, you have to figure out the questions even asking.\n\n54:29.940 --> 54:31.700\n Then you have to determine whether\n\n54:31.700 --> 54:33.620\n or not you think you know the answer.\n\n54:34.500 --> 54:37.380\n And because you have to buzz in really quickly,\n\n54:37.380 --> 54:39.820\n you sort of have to make that determination\n\n54:39.820 --> 54:41.220\n as quickly as you possibly can.\n\n54:41.220 --> 54:43.460\n Otherwise you lose the opportunity to buzz in.\n\n54:43.460 --> 54:44.300\n You mean...\n\n54:44.300 --> 54:46.140\n Even before you really know if you know the answer.\n\n54:46.140 --> 54:48.660\n I think a lot of humans will assume,\n\n54:48.660 --> 54:53.020\n they'll process it very superficially.\n\n54:53.020 --> 54:54.940\n In other words, what's the topic?\n\n54:54.940 --> 54:55.980\n What are some keywords?\n\n54:55.980 --> 54:58.660\n And just say, do I know this area or not\n\n54:58.660 --> 55:00.820\n before they actually know the answer?\n\n55:00.820 --> 55:03.220\n Then they'll buzz in and think about it.\n\n55:03.220 --> 55:04.700\n So it's interesting what humans do.\n\n55:04.700 --> 55:06.940\n Now, some people who know all things,\n\n55:06.940 --> 55:08.460\n like Ken Jennings or something,\n\n55:08.460 --> 55:10.420\n or the more recent big Jeopardy player,\n\n55:11.460 --> 55:12.420\n I mean, they'll just buzz in.\n\n55:12.420 --> 55:14.100\n They'll just assume they know all of Jeopardy\n\n55:14.100 --> 55:15.900\n and they'll just buzz in.\n\n55:15.900 --> 55:18.380\n Watson, interestingly, didn't even come close\n\n55:18.380 --> 55:20.140\n to knowing all of Jeopardy, right?\n\n55:20.140 --> 55:20.980\n Watson really...\n\n55:20.980 --> 55:22.700\n Even at the peak, even at its best.\n\n55:22.700 --> 55:24.580\n Yeah, so for example, I mean,\n\n55:24.580 --> 55:25.980\n we had this thing called recall,\n\n55:25.980 --> 55:29.420\n which is like how many of all the Jeopardy questions,\n\n55:29.420 --> 55:34.420\n how many could we even find the right answer for anywhere?\n\n55:34.420 --> 55:38.220\n Like, can we come up with, we had a big body of knowledge,\n\n55:38.220 --> 55:39.780\n something in the order of several terabytes.\n\n55:39.780 --> 55:42.900\n I mean, from a web scale, it was actually very small,\n\n55:42.900 --> 55:44.340\n but from like a book scale,\n\n55:44.340 --> 55:46.260\n we're talking about millions of books, right?\n\n55:46.260 --> 55:48.260\n So the equivalent of millions of books,\n\n55:48.260 --> 55:50.340\n encyclopedias, dictionaries, books,\n\n55:50.340 --> 55:52.260\n it's still a ton of information.\n\n55:52.260 --> 55:55.820\n And I think it was only 85% was the answer\n\n55:55.820 --> 55:57.580\n anywhere to be found.\n\n55:57.580 --> 56:00.340\n So you're already down at that level\n\n56:00.340 --> 56:02.060\n just to get started, right?\n\n56:02.060 --> 56:07.060\n So, and so it was important to get a very quick sense\n\n56:07.900 --> 56:10.060\n of do you think you know the right answer to this question?\n\n56:10.060 --> 56:12.180\n So we had to compute that confidence\n\n56:12.180 --> 56:14.300\n as quickly as we possibly could.\n\n56:14.300 --> 56:16.460\n So in effect, we had to answer it\n\n56:16.460 --> 56:21.460\n and at least spend some time essentially answering it\n\n56:22.020 --> 56:26.660\n and then judging the confidence that our answer was right\n\n56:26.660 --> 56:28.060\n and then deciding whether or not\n\n56:28.060 --> 56:30.020\n we were confident enough to buzz in.\n\n56:30.020 --> 56:31.940\n And that would depend on what else was going on in the game.\n\n56:31.940 --> 56:33.380\n Because there was a risk.\n\n56:33.380 --> 56:35.060\n So like if you're really in a situation\n\n56:35.060 --> 56:38.340\n where I have to take a guess, I have very little to lose,\n\n56:38.340 --> 56:40.220\n then you'll buzz in with less confidence.\n\n56:40.220 --> 56:42.940\n So that was accounted for the financial standings\n\n56:42.940 --> 56:44.300\n of the different competitors.\n\n56:44.300 --> 56:45.420\n Correct.\n\n56:45.420 --> 56:46.620\n How much of the game was left?\n\n56:46.620 --> 56:48.260\n How much time was left?\n\n56:48.260 --> 56:50.740\n Where you were in the standing, things like that.\n\n56:50.740 --> 56:52.860\n How many hundreds of milliseconds\n\n56:52.860 --> 56:53.900\n that we're talking about here?\n\n56:53.900 --> 56:55.980\n Do you have a sense of what is?\n\n56:55.980 --> 56:58.420\n We targeted, yeah, we targeted.\n\n56:58.420 --> 57:01.180\n So, I mean, we targeted answering\n\n57:01.180 --> 57:04.660\n in under three seconds and.\n\n57:04.660 --> 57:05.500\n Buzzing in.\n\n57:05.500 --> 57:09.940\n So the decision to buzz in and then the actual answering\n\n57:09.940 --> 57:10.980\n are those two different stages?\n\n57:10.980 --> 57:12.660\n Yeah, they were two different things.\n\n57:12.660 --> 57:14.540\n In fact, we had multiple stages,\n\n57:14.540 --> 57:17.380\n whereas like we would say, let's estimate our confidence,\n\n57:17.380 --> 57:21.060\n which was sort of a shallow answering process.\n\n57:21.060 --> 57:23.820\n And then ultimately decide to buzz in\n\n57:23.820 --> 57:26.340\n and then we may take another second or something\n\n57:27.420 --> 57:30.900\n to kind of go in there and do that.\n\n57:30.900 --> 57:32.180\n But by and large, we were saying like,\n\n57:32.180 --> 57:33.940\n we can't play the game.\n\n57:33.940 --> 57:37.620\n We can't even compete if we can't on average\n\n57:37.620 --> 57:40.380\n answer these questions in around three seconds or less.\n\n57:40.380 --> 57:41.740\n So you stepped in.\n\n57:41.740 --> 57:45.340\n So there's these three humans playing a game\n\n57:45.340 --> 57:47.980\n and you stepped in with the idea that IBM Watson\n\n57:47.980 --> 57:49.980\n would be one of, replace one of the humans\n\n57:49.980 --> 57:52.020\n and compete against two.\n\n57:52.020 --> 57:56.740\n Can you tell the story of Watson taking on this game?\n\n57:56.740 --> 57:57.580\n Sure.\n\n57:57.580 --> 57:58.700\n It seems exceptionally difficult.\n\n57:58.700 --> 58:03.500\n Yeah, so the story was that it was coming up,\n\n58:03.500 --> 58:06.940\n I think to the 10 year anniversary of Big Blue,\n\n58:06.940 --> 58:08.780\n not Big Blue, Deep Blue.\n\n58:08.780 --> 58:11.940\n IBM wanted to do sort of another kind of really\n\n58:11.940 --> 58:15.260\n fun challenge, public challenge that can bring attention\n\n58:15.260 --> 58:17.180\n to IBM research and the kind of the cool stuff\n\n58:17.180 --> 58:18.180\n that we were doing.\n\n58:19.740 --> 58:23.740\n I had been working in AI at IBM for some time.\n\n58:23.740 --> 58:26.460\n I had a team doing what's called\n\n58:26.460 --> 58:28.620\n open domain factoid question answering,\n\n58:28.620 --> 58:31.020\n which is, we're not gonna tell you what the questions are.\n\n58:31.020 --> 58:33.100\n We're not even gonna tell you what they're about.\n\n58:33.100 --> 58:36.860\n Can you go off and get accurate answers to these questions?\n\n58:36.860 --> 58:41.420\n And it was an area of AI research that I was involved in.\n\n58:41.420 --> 58:44.300\n And so it was a very specific passion of mine.\n\n58:44.300 --> 58:47.100\n Language understanding had always been a passion of mine.\n\n58:47.100 --> 58:49.660\n One sort of narrow slice on whether or not\n\n58:49.660 --> 58:51.020\n you could do anything with language\n\n58:51.020 --> 58:52.900\n was this notion of open domain and meaning\n\n58:52.900 --> 58:54.620\n I could ask anything about anything.\n\n58:54.620 --> 58:57.900\n Factoid meaning it essentially had an answer\n\n58:57.900 --> 59:00.940\n and being able to do that accurately and quickly.\n\n59:00.940 --> 59:02.420\n So that was a research area\n\n59:02.420 --> 59:03.980\n that my team had already been in.\n\n59:03.980 --> 59:06.340\n And so completely independently,\n\n59:06.340 --> 59:09.060\n several IBM executives, like what are we gonna do?\n\n59:09.060 --> 59:11.060\n What's the next cool thing to do?\n\n59:11.060 --> 59:13.900\n And Ken Jennings was on his winning streak.\n\n59:13.900 --> 59:16.660\n This was like, whatever it was, 2004, I think,\n\n59:16.660 --> 59:18.780\n was on his winning streak.\n\n59:18.780 --> 59:20.900\n And someone thought, hey, that would be really cool\n\n59:20.900 --> 59:23.940\n if the computer can play Jeopardy.\n\n59:23.940 --> 59:25.740\n And so this was like in 2004,\n\n59:25.740 --> 59:28.020\n they were shopping this thing around\n\n59:28.020 --> 59:33.020\n and everyone was telling the research execs, no way.\n\n59:33.540 --> 59:35.180\n Like, this is crazy.\n\n59:35.180 --> 59:37.020\n And we had some pretty senior people in the field\n\n59:37.020 --> 59:38.180\n and they're saying, no, this is crazy.\n\n59:38.180 --> 59:40.180\n And it would come across my desk and I was like,\n\n59:40.180 --> 59:43.100\n but that's kind of what I'm really interested in doing.\n\n59:44.700 --> 59:47.460\n But there was such this prevailing sense of this is nuts.\n\n59:47.460 --> 59:49.380\n We're not gonna risk IBM's reputation on this.\n\n59:49.380 --> 59:50.500\n We're just not doing it.\n\n59:50.500 --> 59:53.140\n And this happened in 2004, it happened in 2005.\n\n59:53.140 --> 59:58.140\n At the end of 2006, it was coming around again.\n\n59:59.260 --> 1:00:01.100\n And I was coming off of a,\n\n1:00:01.100 --> 1:00:03.060\n I was doing the open domain question answering stuff,\n\n1:00:03.060 --> 1:00:05.940\n but I was coming off a couple other projects.\n\n1:00:05.940 --> 1:00:08.060\n I had a lot more time to put into this.\n\n1:00:08.060 --> 1:00:10.180\n And I argued that it could be done.\n\n1:00:10.180 --> 1:00:12.740\n And I argue it would be crazy not to do this.\n\n1:00:12.740 --> 1:00:15.820\n Can I, you can be honest at this point.\n\n1:00:15.820 --> 1:00:17.580\n So even though you argued for it,\n\n1:00:17.580 --> 1:00:21.540\n what's the confidence that you had yourself privately\n\n1:00:21.540 --> 1:00:22.740\n that this could be done?\n\n1:00:22.740 --> 1:00:25.620\n Was, we just told the story,\n\n1:00:25.620 --> 1:00:27.740\n how you tell stories to convince others.\n\n1:00:27.740 --> 1:00:28.940\n How confident were you?\n\n1:00:28.940 --> 1:00:32.660\n What was your estimation of the problem at that time?\n\n1:00:32.660 --> 1:00:34.300\n So I thought it was possible.\n\n1:00:34.300 --> 1:00:36.300\n And a lot of people thought it was impossible.\n\n1:00:36.300 --> 1:00:37.860\n I thought it was possible.\n\n1:00:37.860 --> 1:00:39.140\n The reason why I thought it was possible\n\n1:00:39.140 --> 1:00:41.500\n was because I did some brief experimentation.\n\n1:00:41.500 --> 1:00:43.460\n I knew a lot about how we were approaching\n\n1:00:43.460 --> 1:00:45.940\n open domain factoid question answering.\n\n1:00:45.940 --> 1:00:47.620\n I've been doing it for some years.\n\n1:00:47.620 --> 1:00:49.340\n I looked at the Jeopardy stuff.\n\n1:00:49.340 --> 1:00:50.900\n I said, this is gonna be hard\n\n1:00:50.900 --> 1:00:54.180\n for a lot of the points that we mentioned earlier.\n\n1:00:54.180 --> 1:00:55.740\n Hard to interpret the question.\n\n1:00:57.060 --> 1:00:58.940\n Hard to do it quickly enough.\n\n1:00:58.940 --> 1:01:00.500\n Hard to compute an accurate confidence.\n\n1:01:00.500 --> 1:01:03.060\n None of this stuff had been done well enough before.\n\n1:01:03.060 --> 1:01:04.660\n But a lot of the technologies we're building\n\n1:01:04.660 --> 1:01:07.500\n were the kinds of technologies that should work.\n\n1:01:07.500 --> 1:01:10.860\n But more to the point, what was driving me was,\n\n1:01:10.860 --> 1:01:12.820\n I was in IBM research.\n\n1:01:12.820 --> 1:01:14.900\n I was a senior leader in IBM research.\n\n1:01:14.900 --> 1:01:17.140\n And this is the kind of stuff we were supposed to do.\n\n1:01:17.140 --> 1:01:18.660\n In other words, we were basically supposed to.\n\n1:01:18.660 --> 1:01:19.700\n This is the moonshot.\n\n1:01:19.700 --> 1:01:20.540\n This is the.\n\n1:01:20.540 --> 1:01:21.900\n We were supposed to take things and say,\n\n1:01:21.900 --> 1:01:24.060\n this is an active research area.\n\n1:01:24.940 --> 1:01:27.540\n It's our obligation to kind of,\n\n1:01:27.540 --> 1:01:30.100\n if we have the opportunity, to push it to the limits.\n\n1:01:30.100 --> 1:01:31.460\n And if it doesn't work,\n\n1:01:31.460 --> 1:01:34.740\n to understand more deeply why we can't do it.\n\n1:01:34.740 --> 1:01:37.900\n And so I was very committed to that notion saying,\n\n1:01:37.900 --> 1:01:40.060\n folks, this is what we do.\n\n1:01:40.060 --> 1:01:42.140\n It's crazy not to do this.\n\n1:01:42.140 --> 1:01:43.740\n This is an active research area.\n\n1:01:43.740 --> 1:01:44.980\n We've been in this for years.\n\n1:01:44.980 --> 1:01:47.940\n Why wouldn't we take this grand challenge\n\n1:01:47.940 --> 1:01:50.700\n and push it as hard as we can?\n\n1:01:50.700 --> 1:01:53.140\n At the very least, we'd be able to come out and say,\n\n1:01:53.140 --> 1:01:57.060\n here's why this problem is way hard.\n\n1:01:57.060 --> 1:01:58.660\n Here's what we tried and here's how we failed.\n\n1:01:58.660 --> 1:02:03.660\n So I was very driven as a scientist from that perspective.\n\n1:02:03.980 --> 1:02:06.580\n And then I also argued,\n\n1:02:06.580 --> 1:02:08.740\n based on what we did a feasibility study,\n\n1:02:08.740 --> 1:02:10.900\n why I thought it was hard but possible.\n\n1:02:10.900 --> 1:02:14.180\n And I showed examples of where it succeeded,\n\n1:02:14.180 --> 1:02:16.100\n where it failed, why it failed,\n\n1:02:16.100 --> 1:02:18.180\n and sort of a high level architecture approach\n\n1:02:18.180 --> 1:02:19.540\n for why we should do it.\n\n1:02:19.540 --> 1:02:22.260\n But for the most part, at that point,\n\n1:02:22.260 --> 1:02:24.660\n the execs really were just looking for someone crazy enough\n\n1:02:24.660 --> 1:02:27.900\n to say yes, because for several years at that point,\n\n1:02:27.900 --> 1:02:32.260\n everyone had said, no, I'm not willing to risk my reputation\n\n1:02:32.260 --> 1:02:34.820\n and my career on this thing.\n\n1:02:34.820 --> 1:02:36.740\n Clearly you did not have such fears.\n\n1:02:36.740 --> 1:02:37.980\n Okay. I did not.\n\n1:02:37.980 --> 1:02:39.540\n So you dived right in.\n\n1:02:39.540 --> 1:02:42.820\n And yet, for what I understand,\n\n1:02:42.820 --> 1:02:46.300\n it was performing very poorly in the beginning.\n\n1:02:46.300 --> 1:02:49.740\n So what were the initial approaches and why did they fail?\n\n1:02:51.300 --> 1:02:54.820\n Well, there were lots of hard aspects to it.\n\n1:02:54.820 --> 1:02:57.700\n I mean, one of the reasons why prior approaches\n\n1:02:57.700 --> 1:03:02.380\n that we had worked on in the past failed\n\n1:03:02.380 --> 1:03:07.380\n was because the questions were difficult to interpret.\n\n1:03:07.780 --> 1:03:10.100\n Like, what are you even asking for, right?\n\n1:03:10.100 --> 1:03:12.500\n Very often, like if the question was very direct,\n\n1:03:12.500 --> 1:03:16.620\n like what city, or what, even then it could be tricky,\n\n1:03:16.620 --> 1:03:21.620\n but what city or what person,\n\n1:03:21.940 --> 1:03:24.220\n is often when it would name it very clearly,\n\n1:03:24.220 --> 1:03:25.420\n you would know that.\n\n1:03:25.420 --> 1:03:28.100\n And if there were just a small set of them,\n\n1:03:28.100 --> 1:03:31.540\n in other words, we're gonna ask about these five types.\n\n1:03:31.540 --> 1:03:33.580\n Like, it's gonna be an answer,\n\n1:03:33.580 --> 1:03:36.820\n and the answer will be a city in this state\n\n1:03:36.820 --> 1:03:37.780\n or a city in this country.\n\n1:03:37.780 --> 1:03:41.020\n The answer will be a person of this type, right?\n\n1:03:41.020 --> 1:03:42.740\n Like an actor or whatever it is.\n\n1:03:42.740 --> 1:03:44.380\n But it turns out that in Jeopardy,\n\n1:03:44.380 --> 1:03:47.580\n there were like tens of thousands of these things.\n\n1:03:47.580 --> 1:03:49.580\n And it was a very, very long tail,\n\n1:03:50.580 --> 1:03:52.500\n meaning that it just went on and on.\n\n1:03:52.500 --> 1:03:56.900\n And so even if you focused on trying to encode the types\n\n1:03:56.900 --> 1:03:59.820\n at the very top, like there's five that were the most,\n\n1:03:59.820 --> 1:04:01.580\n let's say five of the most frequent,\n\n1:04:01.580 --> 1:04:04.140\n you still cover a very small percentage of the data.\n\n1:04:04.140 --> 1:04:07.140\n So you couldn't take that approach of saying,\n\n1:04:07.140 --> 1:04:09.780\n I'm just going to try to collect facts\n\n1:04:09.780 --> 1:04:12.780\n about these five or 10 types or 20 types\n\n1:04:12.780 --> 1:04:14.380\n or 50 types or whatever.\n\n1:04:14.380 --> 1:04:16.940\n So that was like one of the first things,\n\n1:04:16.940 --> 1:04:18.180\n like what do you do about that?\n\n1:04:18.180 --> 1:04:21.500\n And so we came up with an approach toward that.\n\n1:04:21.500 --> 1:04:23.460\n And the approach looked promising,\n\n1:04:23.460 --> 1:04:25.940\n and we continued to improve our ability\n\n1:04:25.940 --> 1:04:29.500\n to handle that problem throughout the project.\n\n1:04:29.500 --> 1:04:32.420\n The other issue was that right from the outside,\n\n1:04:32.420 --> 1:04:34.580\n I said, we're not going to,\n\n1:04:34.580 --> 1:04:37.620\n I committed to doing this in three to five years.\n\n1:04:37.620 --> 1:04:39.060\n So we did it in four.\n\n1:04:39.060 --> 1:04:40.940\n So I got lucky.\n\n1:04:40.940 --> 1:04:42.380\n But one of the things that that,\n\n1:04:42.380 --> 1:04:45.700\n putting that like stake in the ground was,\n\n1:04:45.700 --> 1:04:47.780\n and I knew how hard the language understanding problem was.\n\n1:04:47.780 --> 1:04:51.620\n I said, we're not going to actually understand language\n\n1:04:51.620 --> 1:04:52.740\n to solve this problem.\n\n1:04:53.900 --> 1:04:57.460\n We are not going to interpret the question\n\n1:04:57.460 --> 1:05:00.180\n and the domain of knowledge that the question refers to\n\n1:05:00.180 --> 1:05:02.420\n and reason over that to answer these questions.\n\n1:05:02.420 --> 1:05:04.140\n Obviously we're not going to be doing that.\n\n1:05:04.140 --> 1:05:05.740\n At the same time,\n\n1:05:05.740 --> 1:05:10.380\n simple search wasn't good enough to confidently answer\n\n1:05:10.380 --> 1:05:13.020\n with a single correct answer.\n\n1:05:13.020 --> 1:05:14.260\n First of all, that's like brilliant.\n\n1:05:14.260 --> 1:05:16.140\n That's such a great mix of innovation\n\n1:05:16.140 --> 1:05:18.620\n and practical engineering three, four, eight.\n\n1:05:18.620 --> 1:05:21.780\n So you're not trying to solve the general NLU problem.\n\n1:05:21.780 --> 1:05:25.260\n You're saying, let's solve this in any way possible.\n\n1:05:25.260 --> 1:05:26.100\n Oh, yeah.\n\n1:05:26.100 --> 1:05:28.020\n No, I was committed to saying, look,\n\n1:05:28.020 --> 1:05:29.660\n we're going to solving the open domain\n\n1:05:29.660 --> 1:05:31.020\n question answering problem.\n\n1:05:31.020 --> 1:05:33.540\n We're using Jeopardy as a driver for that.\n\n1:05:33.540 --> 1:05:34.380\n That's a big benchmark.\n\n1:05:34.380 --> 1:05:36.500\n Good enough, big benchmark, exactly.\n\n1:05:36.500 --> 1:05:38.180\n And now we're.\n\n1:05:38.180 --> 1:05:39.020\n How do we do it?\n\n1:05:39.020 --> 1:05:39.940\n We could just like, whatever,\n\n1:05:39.940 --> 1:05:41.140\n like just figure out what works\n\n1:05:41.140 --> 1:05:42.340\n because I want to be able to go back\n\n1:05:42.340 --> 1:05:44.100\n to the academic science community\n\n1:05:44.100 --> 1:05:45.980\n and say, here's what we tried.\n\n1:05:45.980 --> 1:05:46.820\n Here's what worked.\n\n1:05:46.820 --> 1:05:47.660\n Here's what didn't work.\n\n1:05:47.660 --> 1:05:48.500\n Great.\n\n1:05:48.500 --> 1:05:50.260\n I don't want to go in and say,\n\n1:05:50.260 --> 1:05:51.980\n oh, I only have one technology.\n\n1:05:51.980 --> 1:05:52.820\n I have a hammer.\n\n1:05:52.820 --> 1:05:53.660\n I'm only going to use this.\n\n1:05:53.660 --> 1:05:54.700\n I'm going to do whatever it takes.\n\n1:05:54.700 --> 1:05:56.020\n I'm like, I'm going to think out of the box\n\n1:05:56.020 --> 1:05:57.300\n and do whatever it takes.\n\n1:05:57.300 --> 1:06:00.540\n One, and I also, there was another thing I believed.\n\n1:06:00.540 --> 1:06:04.580\n I believed that the fundamental NLP technologies\n\n1:06:04.580 --> 1:06:08.780\n and machine learning technologies would be adequate.\n\n1:06:08.780 --> 1:06:11.940\n And this was an issue of how do we enhance them?\n\n1:06:11.940 --> 1:06:13.620\n How do we integrate them?\n\n1:06:13.620 --> 1:06:15.300\n How do we advance them?\n\n1:06:15.300 --> 1:06:17.220\n So I had one researcher who came to me\n\n1:06:17.220 --> 1:06:18.620\n who had been working on question answering\n\n1:06:18.620 --> 1:06:20.180\n with me for a very long time,\n\n1:06:21.620 --> 1:06:24.260\n who had said, we're going to need Maxwell's equations\n\n1:06:24.260 --> 1:06:25.660\n for question answering.\n\n1:06:25.660 --> 1:06:28.700\n And I said, if we need some fundamental formula\n\n1:06:28.700 --> 1:06:31.820\n that breaks new ground in how we understand language,\n\n1:06:31.820 --> 1:06:33.060\n we're screwed.\n\n1:06:33.060 --> 1:06:34.380\n We're not going to get there from here.\n\n1:06:34.380 --> 1:06:38.020\n Like I am not counting.\n\n1:06:38.020 --> 1:06:39.660\n My assumption is I'm not counting\n\n1:06:39.660 --> 1:06:42.380\n on some brand new invention.\n\n1:06:42.380 --> 1:06:45.420\n What I'm counting on is the ability\n\n1:06:45.420 --> 1:06:48.100\n to take everything it has done before\n\n1:06:48.100 --> 1:06:51.860\n to figure out an architecture on how to integrate it well\n\n1:06:51.860 --> 1:06:54.300\n and then see where it breaks\n\n1:06:54.300 --> 1:06:57.220\n and make the necessary advances we need to make\n\n1:06:57.220 --> 1:06:58.860\n until this thing works.\n\n1:06:58.860 --> 1:07:00.460\n Push it hard to see where it breaks\n\n1:07:00.460 --> 1:07:01.660\n and then patch it up.\n\n1:07:01.660 --> 1:07:03.220\n I mean, that's how people change the world.\n\n1:07:03.220 --> 1:07:05.980\n I mean, that's the Elon Musk approach to the rockets,\n\n1:07:05.980 --> 1:07:08.780\n SpaceX, that's the Henry Ford and so on.\n\n1:07:08.780 --> 1:07:09.620\n I love it.\n\n1:07:09.620 --> 1:07:11.940\n And I happen to be, in this case, I happen to be right,\n\n1:07:11.940 --> 1:07:14.300\n but like we didn't know.\n\n1:07:14.300 --> 1:07:15.860\n But you kind of have to put a stake in the rest\n\n1:07:15.860 --> 1:07:17.380\n of how you're going to run the project.\n\n1:07:17.380 --> 1:07:20.340\n So yeah, and backtracking to search.\n\n1:07:20.340 --> 1:07:24.660\n So if you were to do, what's the brute force solution?\n\n1:07:24.660 --> 1:07:26.100\n What would you search over?\n\n1:07:26.100 --> 1:07:27.940\n So you have a question,\n\n1:07:27.940 --> 1:07:31.300\n how would you search the possible space of answers?\n\n1:07:31.300 --> 1:07:33.900\n Look, web search has come a long way even since then.\n\n1:07:34.820 --> 1:07:37.820\n But at the time, first of all,\n\n1:07:37.820 --> 1:07:39.260\n I mean, there were a couple of other constraints\n\n1:07:39.260 --> 1:07:40.940\n around the problem, which is interesting.\n\n1:07:40.940 --> 1:07:43.100\n So you couldn't go out to the web.\n\n1:07:43.100 --> 1:07:44.980\n You couldn't search the internet.\n\n1:07:44.980 --> 1:07:47.600\n In other words, the AI experiment was,\n\n1:07:47.600 --> 1:07:50.460\n we want a self contained device.\n\n1:07:50.460 --> 1:07:52.940\n If the device is as big as a room, fine,\n\n1:07:52.940 --> 1:07:53.860\n it's as big as a room,\n\n1:07:53.860 --> 1:07:57.980\n but we want a self contained device.\n\n1:07:57.980 --> 1:07:59.260\n You're not going out to the internet.\n\n1:07:59.260 --> 1:08:01.580\n You don't have a lifeline to anything.\n\n1:08:01.580 --> 1:08:04.280\n So it had to kind of fit in a shoe box, if you will,\n\n1:08:04.280 --> 1:08:06.600\n or at least a size of a few refrigerators,\n\n1:08:06.600 --> 1:08:08.060\n whatever it might be.\n\n1:08:08.060 --> 1:08:10.440\n See, but also you couldn't just get out there.\n\n1:08:10.440 --> 1:08:13.060\n You couldn't go off network, right, to kind of go.\n\n1:08:13.060 --> 1:08:14.920\n So there was that limitation.\n\n1:08:14.920 --> 1:08:19.340\n But then we did, but the basic thing was go do web search.\n\n1:08:19.340 --> 1:08:22.940\n Problem was, even when we went and did a web search,\n\n1:08:22.940 --> 1:08:24.540\n I don't remember exactly the numbers,\n\n1:08:24.540 --> 1:08:27.580\n but somewhere in the order of 65% of the time,\n\n1:08:27.580 --> 1:08:30.300\n the answer would be somewhere, you know,\n\n1:08:30.300 --> 1:08:32.900\n in the top 10 or 20 documents.\n\n1:08:32.900 --> 1:08:36.260\n So first of all, that's not even good enough to play Jeopardy.\n\n1:08:36.260 --> 1:08:38.180\n You know, the words, even if you could pull the,\n\n1:08:38.180 --> 1:08:40.240\n even if you could perfectly pull the answer\n\n1:08:40.240 --> 1:08:42.920\n out of the top 20 documents, top 10 documents,\n\n1:08:42.920 --> 1:08:45.240\n whatever it was, which we didn't know how to do.\n\n1:08:45.240 --> 1:08:47.940\n But even if you could do that, you'd be,\n\n1:08:47.940 --> 1:08:49.140\n and you knew it was right,\n\n1:08:49.140 --> 1:08:50.700\n unless you had enough confidence in it, right?\n\n1:08:50.700 --> 1:08:52.180\n So you'd have to pull out the right answer.\n\n1:08:52.180 --> 1:08:54.820\n You'd have to have confidence it was the right answer.\n\n1:08:54.820 --> 1:08:58.100\n And then you'd have to do that fast enough to now go buzz in\n\n1:08:58.100 --> 1:09:00.300\n and you'd still only get 65% of them right,\n\n1:09:00.300 --> 1:09:02.660\n which doesn't even put you in the winner's circle.\n\n1:09:02.660 --> 1:09:05.060\n Winner's circle, you have to be up over 70\n\n1:09:05.060 --> 1:09:06.060\n and you have to do it really quick\n\n1:09:06.060 --> 1:09:08.020\n and you have to do it really quickly.\n\n1:09:08.020 --> 1:09:10.100\n But now the problem is, well,\n\n1:09:10.100 --> 1:09:12.500\n even if I had somewhere in the top 10 documents,\n\n1:09:12.500 --> 1:09:14.980\n how do I figure out where in the top 10 documents\n\n1:09:14.980 --> 1:09:18.040\n that answer is and how do I compute a confidence\n\n1:09:18.040 --> 1:09:19.740\n of all the possible candidates?\n\n1:09:19.740 --> 1:09:21.820\n So it's not like I go in knowing the right answer\n\n1:09:21.820 --> 1:09:22.660\n and I have to pick it.\n\n1:09:22.660 --> 1:09:23.940\n I don't know the right answer.\n\n1:09:23.940 --> 1:09:25.580\n I have a bunch of documents,\n\n1:09:25.580 --> 1:09:27.100\n somewhere in there is the right answer.\n\n1:09:27.100 --> 1:09:28.700\n How do I, as a machine, go out\n\n1:09:28.700 --> 1:09:30.020\n and figure out which one's right?\n\n1:09:30.020 --> 1:09:31.460\n And then how do I score it?\n\n1:09:32.640 --> 1:09:35.300\n So, and now how do I deal with the fact\n\n1:09:35.300 --> 1:09:37.320\n that I can't actually go out to the web?\n\n1:09:37.320 --> 1:09:40.020\n First of all, if you pause on that, just think about it.\n\n1:09:40.020 --> 1:09:42.160\n If you could go to the web,\n\n1:09:42.160 --> 1:09:44.260\n do you think that problem is solvable\n\n1:09:44.260 --> 1:09:45.540\n if you just pause on it?\n\n1:09:45.540 --> 1:09:48.340\n Just thinking even beyond jeopardy,\n\n1:09:49.220 --> 1:09:51.340\n do you think the problem of reading text\n\n1:09:51.340 --> 1:09:53.660\n defined where the answer is?\n\n1:09:53.660 --> 1:09:56.700\n Well, we solved that in some definition of solves\n\n1:09:56.700 --> 1:09:58.020\n given the jeopardy challenge.\n\n1:09:58.020 --> 1:09:59.020\n How did you do it for jeopardy?\n\n1:09:59.020 --> 1:10:03.260\n So how do you take a body of work in a particular topic\n\n1:10:03.260 --> 1:10:05.940\n and extract the key pieces of information?\n\n1:10:05.940 --> 1:10:09.100\n So now forgetting about the huge volumes\n\n1:10:09.100 --> 1:10:10.060\n that are on the web, right?\n\n1:10:10.060 --> 1:10:11.260\n So now we have to figure out,\n\n1:10:11.260 --> 1:10:12.740\n we did a lot of source research.\n\n1:10:12.740 --> 1:10:15.720\n In other words, what body of knowledge\n\n1:10:15.720 --> 1:10:17.180\n is gonna be small enough,\n\n1:10:17.180 --> 1:10:19.820\n but broad enough to answer jeopardy?\n\n1:10:19.820 --> 1:10:21.920\n And we ultimately did find the body of knowledge\n\n1:10:21.920 --> 1:10:22.760\n that did that.\n\n1:10:22.760 --> 1:10:25.100\n I mean, it included Wikipedia and a bunch of other stuff.\n\n1:10:25.100 --> 1:10:26.700\n So like encyclopedia type of stuff.\n\n1:10:26.700 --> 1:10:27.540\n I don't know if you can speak to it.\n\n1:10:27.540 --> 1:10:28.500\n Encyclopedias, dictionaries,\n\n1:10:28.500 --> 1:10:31.140\n different types of semantic resources,\n\n1:10:31.140 --> 1:10:33.980\n like WordNet and other types of semantic resources like that,\n\n1:10:33.980 --> 1:10:36.060\n as well as like some web crawls.\n\n1:10:36.060 --> 1:10:39.060\n In other words, where we went out and took that content\n\n1:10:39.060 --> 1:10:41.700\n and then expanded it based on producing,\n\n1:10:41.700 --> 1:10:44.620\n statistically producing seeds,\n\n1:10:44.620 --> 1:10:48.740\n using those seeds for other searches and then expanding that.\n\n1:10:48.740 --> 1:10:51.500\n So using these like expansion techniques,\n\n1:10:51.500 --> 1:10:53.580\n we went out and had found enough content\n\n1:10:53.580 --> 1:10:54.620\n and we're like, okay, this is good.\n\n1:10:54.620 --> 1:10:56.980\n And even up until the end,\n\n1:10:56.980 --> 1:10:58.380\n we had a thread of research.\n\n1:10:58.380 --> 1:10:59.780\n It was always trying to figure out\n\n1:10:59.780 --> 1:11:02.220\n what content could we efficiently include.\n\n1:11:02.220 --> 1:11:03.420\n I mean, there's a lot of popular,\n\n1:11:03.420 --> 1:11:05.420\n like what is the church lady?\n\n1:11:05.420 --> 1:11:08.020\n Well, I think was one of the, like what,\n\n1:11:09.660 --> 1:11:12.380\n where do you, I guess that's probably an encyclopedia, so.\n\n1:11:12.380 --> 1:11:13.900\n So that was an encyclopedia,\n\n1:11:13.900 --> 1:11:16.060\n but then we would take that stuff\n\n1:11:16.060 --> 1:11:17.780\n and we would go out and we would expand.\n\n1:11:17.780 --> 1:11:20.140\n In other words, we'd go find other content\n\n1:11:20.140 --> 1:11:23.300\n that wasn't in the core resources and expand it.\n\n1:11:23.300 --> 1:11:26.180\n The amount of content, we grew it by an order of magnitude,\n\n1:11:26.180 --> 1:11:28.580\n but still, again, from a web scale perspective,\n\n1:11:28.580 --> 1:11:30.540\n this is very small amount of content.\n\n1:11:30.540 --> 1:11:31.380\n It's very select.\n\n1:11:31.380 --> 1:11:33.100\n We then took all that content,\n\n1:11:33.100 --> 1:11:35.220\n we preanalyzed the crap out of it,\n\n1:11:35.220 --> 1:11:38.500\n meaning we parsed it,\n\n1:11:38.500 --> 1:11:40.700\n broke it down into all those individual words\n\n1:11:40.700 --> 1:11:42.180\n and then we did semantic,\n\n1:11:42.180 --> 1:11:44.620\n syntactic and semantic parses on it,\n\n1:11:44.620 --> 1:11:46.980\n had computer algorithms that annotated it\n\n1:11:46.980 --> 1:11:51.980\n and we indexed that in a very rich and very fast index.\n\n1:11:53.140 --> 1:11:55.260\n So we have a relatively huge amount of,\n\n1:11:55.260 --> 1:11:57.420\n let's say the equivalent of, for the sake of argument,\n\n1:11:57.420 --> 1:11:58.980\n two to 5 million bucks.\n\n1:11:58.980 --> 1:12:01.820\n We've now analyzed all that, blowing up its size even more\n\n1:12:01.820 --> 1:12:03.620\n because now we have all this metadata\n\n1:12:03.620 --> 1:12:05.660\n and then we richly indexed all of that\n\n1:12:05.660 --> 1:12:08.940\n and by the way, in a giant in memory cache.\n\n1:12:08.940 --> 1:12:11.980\n So Watson did not go to disk.\n\n1:12:11.980 --> 1:12:13.660\n So the infrastructure component there,\n\n1:12:13.660 --> 1:12:15.860\n if you could just speak to it, how tough it,\n\n1:12:15.860 --> 1:12:20.780\n I mean, I know 2000, maybe this is 2008, nine,\n\n1:12:22.900 --> 1:12:24.500\n that's kind of a long time ago.\n\n1:12:25.900 --> 1:12:28.260\n How hard is it to use multiple machines?\n\n1:12:28.260 --> 1:12:29.900\n How hard is the infrastructure component,\n\n1:12:29.900 --> 1:12:31.620\n the hardware component?\n\n1:12:31.620 --> 1:12:33.860\n So we used IBM hardware.\n\n1:12:33.860 --> 1:12:36.100\n We had something like, I forgot exactly,\n\n1:12:36.100 --> 1:12:40.740\n but close to 3000 cores completely connected.\n\n1:12:40.740 --> 1:12:42.780\n So you had a switch where every CPU\n\n1:12:42.780 --> 1:12:43.620\n was connected to every other CPU.\n\n1:12:43.620 --> 1:12:46.100\n And they were sharing memory in some kind of way.\n\n1:12:46.100 --> 1:12:47.980\n Large shared memory, right?\n\n1:12:47.980 --> 1:12:50.740\n And all this data was preanalyzed\n\n1:12:50.740 --> 1:12:54.860\n and put into a very fast indexing structure\n\n1:12:54.860 --> 1:12:58.300\n that was all in memory.\n\n1:12:58.300 --> 1:13:01.380\n And then we took that question,\n\n1:13:02.780 --> 1:13:04.380\n we would analyze the question.\n\n1:13:04.380 --> 1:13:07.180\n So all the content was now preanalyzed.\n\n1:13:07.180 --> 1:13:10.820\n So if I went and tried to find a piece of content,\n\n1:13:10.820 --> 1:13:12.540\n it would come back with all the metadata\n\n1:13:12.540 --> 1:13:14.580\n that we had precomputed.\n\n1:13:14.580 --> 1:13:16.940\n How do you shove that question?\n\n1:13:16.940 --> 1:13:20.820\n How do you connect the big knowledge base\n\n1:13:20.820 --> 1:13:22.660\n with the metadata and that's indexed\n\n1:13:22.660 --> 1:13:26.940\n to the simple little witty confusing question?\n\n1:13:26.940 --> 1:13:27.780\n Right.\n\n1:13:27.780 --> 1:13:31.300\n So therein lies the Watson architecture, right?\n\n1:13:31.300 --> 1:13:32.940\n So we would take the question,\n\n1:13:32.940 --> 1:13:34.700\n we would analyze the question.\n\n1:13:34.700 --> 1:13:37.020\n So which means that we would parse it\n\n1:13:37.020 --> 1:13:38.740\n and interpret it a bunch of different ways.\n\n1:13:38.740 --> 1:13:40.820\n We'd try to figure out what is it asking about?\n\n1:13:40.820 --> 1:13:44.420\n So we had multiple strategies\n\n1:13:44.420 --> 1:13:47.100\n to kind of determine what was it asking for.\n\n1:13:47.100 --> 1:13:49.460\n That might be represented as a simple string,\n\n1:13:49.460 --> 1:13:51.420\n a character string,\n\n1:13:51.420 --> 1:13:53.140\n or something we would connect back\n\n1:13:53.140 --> 1:13:54.820\n to different semantic types\n\n1:13:54.820 --> 1:13:56.100\n that were from existing resources.\n\n1:13:56.100 --> 1:13:57.820\n So anyway, the bottom line is\n\n1:13:57.820 --> 1:14:00.420\n we would do a bunch of analysis in the question.\n\n1:14:00.420 --> 1:14:04.220\n And question analysis had to finish and had to finish fast.\n\n1:14:04.220 --> 1:14:05.340\n So we do the question analysis\n\n1:14:05.340 --> 1:14:07.900\n because then from the question analysis,\n\n1:14:07.900 --> 1:14:09.780\n we would now produce searches.\n\n1:14:09.780 --> 1:14:12.700\n So we would, and we had built\n\n1:14:12.700 --> 1:14:14.260\n using open source search engines,\n\n1:14:14.260 --> 1:14:16.100\n we modified them,\n\n1:14:16.100 --> 1:14:17.940\n but we had a number of different search engines\n\n1:14:17.940 --> 1:14:20.740\n we would use that had different characteristics.\n\n1:14:20.740 --> 1:14:22.540\n We went in there and engineered\n\n1:14:22.540 --> 1:14:24.540\n and modified those search engines,\n\n1:14:24.540 --> 1:14:28.500\n ultimately to now take our question analysis,\n\n1:14:28.500 --> 1:14:29.900\n produce multiple queries\n\n1:14:29.900 --> 1:14:33.300\n based on different interpretations of the question\n\n1:14:33.300 --> 1:14:36.460\n and fire out a whole bunch of searches in parallel.\n\n1:14:36.460 --> 1:14:39.820\n And they would come back with passages.\n\n1:14:39.820 --> 1:14:42.060\n So these are passive search algorithms.\n\n1:14:42.060 --> 1:14:43.700\n They would come back with passages.\n\n1:14:43.700 --> 1:14:47.140\n And so now let's say you had a thousand passages.\n\n1:14:47.140 --> 1:14:50.700\n Now for each passage, you parallelize again.\n\n1:14:50.700 --> 1:14:55.220\n So you went out and you parallelize the search.\n\n1:14:55.220 --> 1:14:56.460\n Each search would now come back\n\n1:14:56.460 --> 1:14:58.580\n with a whole bunch of passages.\n\n1:14:58.580 --> 1:15:00.460\n Maybe you had a total of a thousand\n\n1:15:00.460 --> 1:15:02.220\n or 5,000 whatever passages.\n\n1:15:02.220 --> 1:15:03.900\n For each passage now,\n\n1:15:03.900 --> 1:15:05.220\n you'd go and figure out whether or not\n\n1:15:05.220 --> 1:15:06.620\n there was a candidate,\n\n1:15:06.620 --> 1:15:08.540\n we'd call it candidate answer in there.\n\n1:15:08.540 --> 1:15:11.540\n So you had a whole bunch of other algorithms\n\n1:15:11.540 --> 1:15:13.220\n that would find candidate answers,\n\n1:15:13.220 --> 1:15:15.620\n possible answers to the question.\n\n1:15:15.620 --> 1:15:17.620\n And so you had candidate answer,\n\n1:15:17.620 --> 1:15:19.540\n called candidate answer generators,\n\n1:15:19.540 --> 1:15:20.780\n a whole bunch of those.\n\n1:15:20.780 --> 1:15:23.100\n So for every one of these components,\n\n1:15:23.100 --> 1:15:25.620\n the team was constantly doing research coming up,\n\n1:15:25.620 --> 1:15:28.220\n better ways to generate search queries from the questions,\n\n1:15:28.220 --> 1:15:29.940\n better ways to analyze the question,\n\n1:15:29.940 --> 1:15:31.420\n better ways to generate candidates.\n\n1:15:31.420 --> 1:15:35.380\n And speed, so better is accuracy and speed.\n\n1:15:35.380 --> 1:15:38.100\n Correct, so right, speed and accuracy\n\n1:15:38.100 --> 1:15:40.500\n for the most part were separated.\n\n1:15:40.500 --> 1:15:42.180\n We handle that sort of in separate ways.\n\n1:15:42.180 --> 1:15:45.180\n Like I focus purely on accuracy, end to end accuracy.\n\n1:15:45.180 --> 1:15:46.900\n Are we ultimately getting more questions\n\n1:15:46.900 --> 1:15:48.860\n and producing more accurate confidences?\n\n1:15:48.860 --> 1:15:50.180\n And then a whole nother team\n\n1:15:50.180 --> 1:15:52.420\n that was constantly analyzing the workflow\n\n1:15:52.420 --> 1:15:53.780\n to find the bottlenecks.\n\n1:15:53.780 --> 1:15:55.740\n And then figuring out how to both parallelize\n\n1:15:55.740 --> 1:15:58.060\n and drive the algorithm speed.\n\n1:15:58.060 --> 1:15:59.980\n But anyway, so now think of it like,\n\n1:15:59.980 --> 1:16:01.700\n you have this big fan out now, right?\n\n1:16:01.700 --> 1:16:03.620\n Because you had multiple queries,\n\n1:16:03.620 --> 1:16:06.940\n now you have thousands of candidate answers.\n\n1:16:06.940 --> 1:16:09.980\n For each candidate answer, you're gonna score it.\n\n1:16:09.980 --> 1:16:12.420\n So you're gonna use all the data that built up.\n\n1:16:12.420 --> 1:16:15.460\n You're gonna use the question analysis,\n\n1:16:15.460 --> 1:16:17.580\n you're gonna use how the query was generated,\n\n1:16:17.580 --> 1:16:19.820\n you're gonna use the passage itself,\n\n1:16:19.820 --> 1:16:21.620\n and you're gonna use the candidate answer\n\n1:16:21.620 --> 1:16:25.460\n that was generated, and you're gonna score that.\n\n1:16:25.460 --> 1:16:28.020\n So now we have a group of researchers\n\n1:16:28.020 --> 1:16:30.100\n coming up with scores.\n\n1:16:30.100 --> 1:16:32.300\n There are hundreds of different scores.\n\n1:16:32.300 --> 1:16:34.580\n So now you're getting a fan out of it again\n\n1:16:34.580 --> 1:16:37.380\n from however many candidate answers you have\n\n1:16:37.380 --> 1:16:39.260\n to all the different scores.\n\n1:16:39.260 --> 1:16:41.260\n So if you have 200 different scores\n\n1:16:41.260 --> 1:16:42.420\n and you have a thousand candidates,\n\n1:16:42.420 --> 1:16:45.180\n now you have 200,000 scores.\n\n1:16:45.180 --> 1:16:47.060\n And so now you gotta figure out,\n\n1:16:48.060 --> 1:16:52.340\n how do I now rank these answers\n\n1:16:52.340 --> 1:16:54.460\n based on the scores that came back?\n\n1:16:54.460 --> 1:16:56.300\n And I wanna rank them based on the likelihood\n\n1:16:56.300 --> 1:16:58.620\n that they're a correct answer to the question.\n\n1:16:58.620 --> 1:17:01.380\n So every scorer was its own research project.\n\n1:17:01.380 --> 1:17:02.340\n What do you mean by scorer?\n\n1:17:02.340 --> 1:17:04.060\n So is that the annotation process\n\n1:17:04.060 --> 1:17:07.700\n of basically a human being saying that this answer\n\n1:17:07.700 --> 1:17:09.340\n has a quality of?\n\n1:17:09.340 --> 1:17:10.740\n Think of it, if you wanna think of it,\n\n1:17:10.740 --> 1:17:12.580\n what you're doing, you know,\n\n1:17:12.580 --> 1:17:14.060\n if you wanna think about what a human would be doing,\n\n1:17:14.060 --> 1:17:17.060\n human would be looking at a possible answer,\n\n1:17:17.060 --> 1:17:20.860\n they'd be reading the, you know, Emily Dickinson,\n\n1:17:20.860 --> 1:17:23.540\n they'd be reading the passage in which that occurred,\n\n1:17:23.540 --> 1:17:25.340\n they'd be looking at the question,\n\n1:17:25.340 --> 1:17:28.340\n and they'd be making a decision of how likely it is\n\n1:17:28.340 --> 1:17:32.260\n that Emily Dickinson, given this evidence in this passage,\n\n1:17:32.260 --> 1:17:33.900\n is the right answer to that question.\n\n1:17:33.900 --> 1:17:34.740\n Got it.\n\n1:17:34.740 --> 1:17:36.180\n So that's the annotation task.\n\n1:17:36.180 --> 1:17:37.020\n That's the annotation process.\n\n1:17:37.020 --> 1:17:38.780\n That's the scoring task.\n\n1:17:38.780 --> 1:17:41.260\n But scoring implies zero to one kind of continuous.\n\n1:17:41.260 --> 1:17:42.100\n That's right.\n\n1:17:42.100 --> 1:17:42.940\n You give it a zero to one score.\n\n1:17:42.940 --> 1:17:44.380\n So it's not a binary.\n\n1:17:44.380 --> 1:17:45.980\n No, you give it a score.\n\n1:17:46.860 --> 1:17:48.700\n Give it a zero to, yeah, exactly, zero to one score.\n\n1:17:48.700 --> 1:17:50.500\n But humans give different scores,\n\n1:17:50.500 --> 1:17:52.940\n so you have to somehow normalize and all that kind of stuff\n\n1:17:52.940 --> 1:17:54.260\n that deal with all that complexity.\n\n1:17:54.260 --> 1:17:55.740\n It depends on what your strategy is.\n\n1:17:55.740 --> 1:17:57.060\n We both, we...\n\n1:17:57.060 --> 1:17:58.060\n It could be relative, too.\n\n1:17:58.060 --> 1:17:59.420\n It could be...\n\n1:17:59.420 --> 1:18:01.580\n We actually looked at the raw scores\n\n1:18:01.580 --> 1:18:02.780\n as well as standardized scores,\n\n1:18:02.780 --> 1:18:04.980\n because humans are not involved in this.\n\n1:18:04.980 --> 1:18:05.900\n Humans are not involved.\n\n1:18:05.900 --> 1:18:08.700\n Sorry, so I'm misunderstanding the process here.\n\n1:18:08.700 --> 1:18:10.460\n This is passages.\n\n1:18:10.460 --> 1:18:13.300\n Where is the ground truth coming from?\n\n1:18:13.300 --> 1:18:15.860\n Ground truth is only the answers to the questions.\n\n1:18:16.820 --> 1:18:17.940\n So it's end to end.\n\n1:18:17.940 --> 1:18:19.020\n It's end to end.\n\n1:18:19.020 --> 1:18:22.420\n So I was always driving end to end performance.\n\n1:18:22.420 --> 1:18:25.540\n It's a very interesting, a very interesting\n\n1:18:25.540 --> 1:18:27.900\n engineering approach,\n\n1:18:27.900 --> 1:18:30.140\n and ultimately scientific research approach,\n\n1:18:30.140 --> 1:18:31.300\n always driving end to end.\n\n1:18:31.300 --> 1:18:33.260\n Now, that's not to say\n\n1:18:34.780 --> 1:18:38.620\n we wouldn't make hypotheses\n\n1:18:38.620 --> 1:18:42.180\n that individual component performance\n\n1:18:42.180 --> 1:18:44.460\n was related in some way to end to end performance.\n\n1:18:44.460 --> 1:18:45.300\n Of course we would,\n\n1:18:45.300 --> 1:18:48.940\n because people would have to build individual components.\n\n1:18:48.940 --> 1:18:51.340\n But ultimately, to get your component integrated\n\n1:18:51.340 --> 1:18:53.540\n to the system, you have to show impact\n\n1:18:53.540 --> 1:18:55.980\n on end to end performance, question answering performance.\n\n1:18:55.980 --> 1:18:58.420\n So there's many very smart people working on this,\n\n1:18:58.420 --> 1:19:01.540\n and they're basically trying to sell their ideas\n\n1:19:01.540 --> 1:19:03.460\n as a component that should be part of the system.\n\n1:19:03.460 --> 1:19:04.620\n That's right.\n\n1:19:04.620 --> 1:19:07.340\n And they would do research on their component,\n\n1:19:07.340 --> 1:19:09.780\n and they would say things like,\n\n1:19:09.780 --> 1:19:13.140\n I'm gonna improve this as a candidate generator,\n\n1:19:13.140 --> 1:19:15.860\n or I'm gonna improve this as a question score,\n\n1:19:15.860 --> 1:19:17.780\n or as a passive scorer,\n\n1:19:17.780 --> 1:19:20.700\n I'm gonna improve this, or as a parser,\n\n1:19:20.700 --> 1:19:25.500\n and I can improve it by 2% on its component metric,\n\n1:19:25.500 --> 1:19:27.940\n like a better parse, or a better candidate,\n\n1:19:27.940 --> 1:19:30.260\n or a better type estimation, whatever it is.\n\n1:19:30.260 --> 1:19:31.700\n And then I would say,\n\n1:19:31.700 --> 1:19:33.900\n I need to understand how the improvement\n\n1:19:33.900 --> 1:19:35.340\n on that component metric\n\n1:19:35.340 --> 1:19:37.740\n is gonna affect the end to end performance.\n\n1:19:37.740 --> 1:19:39.460\n If you can't estimate that,\n\n1:19:39.460 --> 1:19:41.860\n and can't do experiments to demonstrate that,\n\n1:19:41.860 --> 1:19:43.420\n it doesn't get in.\n\n1:19:43.420 --> 1:19:47.540\n That's like the best run AI project I've ever heard.\n\n1:19:47.540 --> 1:19:48.380\n That's awesome.\n\n1:19:48.380 --> 1:19:51.780\n Okay, what breakthrough would you say,\n\n1:19:51.780 --> 1:19:54.260\n like, I'm sure there's a lot of day to day breakthroughs,\n\n1:19:54.260 --> 1:19:55.620\n but was there like a breakthrough\n\n1:19:55.620 --> 1:19:57.860\n that really helped improve performance?\n\n1:19:57.860 --> 1:20:00.180\n Like where people began to believe,\n\n1:20:01.140 --> 1:20:02.500\n or is it just a gradual process?\n\n1:20:02.500 --> 1:20:04.500\n Well, I think it was a gradual process,\n\n1:20:04.500 --> 1:20:08.980\n but one of the things that I think gave people confidence\n\n1:20:08.980 --> 1:20:11.620\n that we can get there was that,\n\n1:20:11.620 --> 1:20:16.620\n as we follow this procedure of different ideas,\n\n1:20:16.620 --> 1:20:19.140\n build different components,\n\n1:20:19.140 --> 1:20:20.460\n plug them into the architecture,\n\n1:20:20.460 --> 1:20:23.180\n run the system, see how we do,\n\n1:20:23.180 --> 1:20:24.700\n do the error analysis,\n\n1:20:24.700 --> 1:20:28.140\n start off new research projects to improve things.\n\n1:20:28.140 --> 1:20:31.260\n And the very important idea\n\n1:20:31.260 --> 1:20:34.260\n that the individual component work\n\n1:20:37.420 --> 1:20:40.020\n did not have to deeply understand everything\n\n1:20:40.020 --> 1:20:42.220\n that was going on with every other component.\n\n1:20:42.220 --> 1:20:45.060\n And this is where we leverage machine learning\n\n1:20:45.060 --> 1:20:47.380\n in a very important way.\n\n1:20:47.380 --> 1:20:48.780\n So while individual components\n\n1:20:48.780 --> 1:20:51.260\n could be statistically driven machine learning components,\n\n1:20:51.260 --> 1:20:52.740\n some of them were heuristic,\n\n1:20:52.740 --> 1:20:54.580\n some of them were machine learning components,\n\n1:20:54.580 --> 1:20:58.100\n the system has a whole combined all the scores\n\n1:20:58.100 --> 1:20:59.300\n using machine learning.\n\n1:21:00.540 --> 1:21:02.700\n This was critical because that way\n\n1:21:02.700 --> 1:21:04.340\n you can divide and conquer.\n\n1:21:04.340 --> 1:21:07.500\n So you can say, okay, you work on your candidate generator,\n\n1:21:07.500 --> 1:21:09.740\n or you work on this approach to answer scoring,\n\n1:21:09.740 --> 1:21:11.740\n you work on this approach to type scoring,\n\n1:21:11.740 --> 1:21:14.500\n you work on this approach to passage search\n\n1:21:14.500 --> 1:21:16.300\n or to pass a selection and so forth.\n\n1:21:17.340 --> 1:21:19.580\n But when we just plug it in,\n\n1:21:19.580 --> 1:21:22.020\n and we had enough training data to say,\n\n1:21:22.020 --> 1:21:24.540\n now we can train and figure out\n\n1:21:24.540 --> 1:21:29.300\n how do we weigh all the scores relative to each other\n\n1:21:29.300 --> 1:21:31.900\n based on the predicting the outcome,\n\n1:21:31.900 --> 1:21:33.820\n which is right or wrong on Jeopardy.\n\n1:21:33.820 --> 1:21:36.780\n And we had enough training data to do that.\n\n1:21:36.780 --> 1:21:40.500\n So this enabled people to work independently\n\n1:21:40.500 --> 1:21:43.340\n and to let the machine learning do the integration.\n\n1:21:43.340 --> 1:21:45.100\n Beautiful, so yeah, the machine learning\n\n1:21:45.100 --> 1:21:46.340\n is doing the fusion,\n\n1:21:46.340 --> 1:21:48.980\n and then it's a human orchestrated ensemble\n\n1:21:48.980 --> 1:21:50.380\n of different approaches.\n\n1:21:50.380 --> 1:21:51.940\n That's great.\n\n1:21:53.420 --> 1:21:54.940\n Still impressive that you were able\n\n1:21:54.940 --> 1:21:56.500\n to get it done in a few years.\n\n1:21:57.620 --> 1:22:00.420\n That's not obvious to me that it's doable,\n\n1:22:00.420 --> 1:22:03.340\n if I just put myself in that mindset.\n\n1:22:03.340 --> 1:22:05.860\n But when you look back at the Jeopardy challenge,\n\n1:22:07.820 --> 1:22:10.220\n again, when you're looking up at the stars,\n\n1:22:10.220 --> 1:22:15.220\n what are you most proud of, looking back at those days?\n\n1:22:17.420 --> 1:22:21.540\n I'm most proud of my,\n\n1:22:27.900 --> 1:22:30.860\n my commitment and my team's commitment\n\n1:22:32.260 --> 1:22:33.860\n to be true to the science,\n\n1:22:35.060 --> 1:22:38.020\n to not be afraid to fail.\n\n1:22:38.020 --> 1:22:41.540\n That's beautiful because there's so much pressure,\n\n1:22:41.540 --> 1:22:44.380\n because it is a public event, it is a public show,\n\n1:22:44.380 --> 1:22:46.980\n that you were dedicated to the idea.\n\n1:22:46.980 --> 1:22:47.820\n That's right.\n\n1:22:50.460 --> 1:22:53.140\n Do you think it was a success?\n\n1:22:53.140 --> 1:22:55.340\n In the eyes of the world, it was a success.\n\n1:22:56.620 --> 1:22:59.700\n By your, I'm sure, exceptionally high standards,\n\n1:23:00.860 --> 1:23:03.700\n is there something you regret you would do differently?\n\n1:23:03.700 --> 1:23:05.900\n It was a success.\n\n1:23:05.900 --> 1:23:08.180\n It was a success for our goal.\n\n1:23:08.180 --> 1:23:11.340\n Our goal was to build the most advanced\n\n1:23:11.340 --> 1:23:13.260\n open domain question answering system.\n\n1:23:14.700 --> 1:23:16.420\n We went back to the old problems\n\n1:23:16.420 --> 1:23:17.900\n that we used to try to solve,\n\n1:23:17.900 --> 1:23:21.220\n and we did dramatically better on all of them,\n\n1:23:21.220 --> 1:23:24.140\n as well as we beat Jeopardy.\n\n1:23:24.140 --> 1:23:25.780\n So we won at Jeopardy.\n\n1:23:25.780 --> 1:23:28.460\n So it was a success.\n\n1:23:28.460 --> 1:23:32.540\n It was, I worry that the community\n\n1:23:32.540 --> 1:23:36.100\n or the world would not understand it as a success\n\n1:23:36.100 --> 1:23:38.660\n because it came down to only one game.\n\n1:23:38.660 --> 1:23:40.380\n And I knew statistically speaking,\n\n1:23:40.380 --> 1:23:42.260\n this can be a huge technical success,\n\n1:23:42.260 --> 1:23:43.820\n and we could still lose that one game.\n\n1:23:43.820 --> 1:23:47.220\n And that's a whole nother theme of this, of the journey.\n\n1:23:47.220 --> 1:23:50.260\n But it was a success.\n\n1:23:50.260 --> 1:23:53.620\n It was not a success in natural language understanding,\n\n1:23:53.620 --> 1:23:54.980\n but that was not the goal.\n\n1:23:56.620 --> 1:23:59.820\n Yeah, that was, but I would argue,\n\n1:24:00.700 --> 1:24:02.020\n I understand what you're saying\n\n1:24:02.020 --> 1:24:04.140\n in terms of the science,\n\n1:24:04.140 --> 1:24:07.540\n but I would argue that the inspiration of it, right?\n\n1:24:07.540 --> 1:24:11.180\n The, not a success in terms of solving\n\n1:24:11.180 --> 1:24:12.820\n natural language understanding.\n\n1:24:12.820 --> 1:24:15.420\n There was a success of being an inspiration\n\n1:24:16.300 --> 1:24:17.900\n to future challenges.\n\n1:24:17.900 --> 1:24:18.820\n Absolutely.\n\n1:24:18.820 --> 1:24:21.140\n That drive future efforts.\n\n1:24:21.140 --> 1:24:23.740\n What's the difference between how human being\n\n1:24:23.740 --> 1:24:26.860\n compete in Jeopardy and how Watson does it?\n\n1:24:26.860 --> 1:24:28.740\n That's important in terms of intelligence.\n\n1:24:28.740 --> 1:24:31.380\n Yeah, so that actually came up very early on\n\n1:24:31.380 --> 1:24:32.620\n in the project also.\n\n1:24:32.620 --> 1:24:35.180\n In fact, I had people who wanted to be on the project\n\n1:24:35.180 --> 1:24:39.100\n who were early on, who sort of approached me\n\n1:24:39.100 --> 1:24:40.860\n once I committed to do it,\n\n1:24:42.380 --> 1:24:44.300\n had wanted to think about how humans do it.\n\n1:24:44.300 --> 1:24:47.060\n And they were, from a cognition perspective,\n\n1:24:47.060 --> 1:24:49.900\n like human cognition and how that should play.\n\n1:24:49.900 --> 1:24:52.180\n And I would not take them on the project\n\n1:24:52.180 --> 1:24:55.780\n because another assumption or another stake\n\n1:24:55.780 --> 1:24:57.620\n I put in the ground was,\n\n1:24:57.620 --> 1:25:00.180\n I don't really care how humans do this.\n\n1:25:00.180 --> 1:25:01.540\n At least in the context of this project.\n\n1:25:01.540 --> 1:25:03.900\n I need to build in the context of this project.\n\n1:25:03.900 --> 1:25:06.980\n In NLU and in building an AI that understands\n\n1:25:06.980 --> 1:25:09.660\n how it needs to ultimately communicate with humans,\n\n1:25:09.660 --> 1:25:11.260\n I very much care.\n\n1:25:11.260 --> 1:25:16.260\n So it wasn't that I didn't care in general.\n\n1:25:16.540 --> 1:25:20.780\n In fact, as an AI scientist, I care a lot about that,\n\n1:25:20.780 --> 1:25:22.620\n but I'm also a practical engineer\n\n1:25:22.620 --> 1:25:25.540\n and I committed to getting this thing done\n\n1:25:25.540 --> 1:25:27.500\n and I wasn't gonna get distracted.\n\n1:25:27.500 --> 1:25:30.740\n I had to kind of say, like, if I'm gonna get this done,\n\n1:25:30.740 --> 1:25:31.740\n I'm gonna chart this path.\n\n1:25:31.740 --> 1:25:34.900\n And this path says, we're gonna engineer a machine\n\n1:25:35.980 --> 1:25:37.540\n that's gonna get this thing done.\n\n1:25:37.540 --> 1:25:41.500\n And we know what search and NLP can do.\n\n1:25:41.500 --> 1:25:44.140\n We have to build on that foundation.\n\n1:25:44.140 --> 1:25:46.260\n If I come in and take a different approach\n\n1:25:46.260 --> 1:25:48.060\n and start wondering about how the human mind\n\n1:25:48.060 --> 1:25:49.700\n might or might not do this,\n\n1:25:49.700 --> 1:25:54.380\n I'm not gonna get there from here in the timeframe.\n\n1:25:54.380 --> 1:25:56.620\n I think that's a great way to lead the team.\n\n1:25:56.620 --> 1:25:59.180\n But now that it's done and there's one,\n\n1:25:59.180 --> 1:26:03.540\n when you look back, analyze what's the difference actually.\n\n1:26:03.540 --> 1:26:05.460\n So I was a little bit surprised actually\n\n1:26:05.460 --> 1:26:09.020\n to discover over time, as this would come up\n\n1:26:09.020 --> 1:26:11.140\n from time to time and we'd reflect on it,\n\n1:26:13.300 --> 1:26:14.980\n and talking to Ken Jennings a little bit\n\n1:26:14.980 --> 1:26:16.780\n and hearing Ken Jennings talk about\n\n1:26:16.780 --> 1:26:18.860\n how he answered questions,\n\n1:26:18.860 --> 1:26:21.260\n that it might've been closer to the way humans\n\n1:26:21.260 --> 1:26:24.700\n answer questions than I might've imagined previously.\n\n1:26:24.700 --> 1:26:27.860\n Because humans are probably in the game of Jeopardy!\n\n1:26:27.860 --> 1:26:29.500\n at the level of Ken Jennings,\n\n1:26:29.500 --> 1:26:34.500\n are probably also cheating their way to winning, right?\n\n1:26:35.180 --> 1:26:36.020\n Not cheating, but shallow.\n\n1:26:36.020 --> 1:26:37.180\n Well, they're doing shallow analysis.\n\n1:26:37.180 --> 1:26:39.340\n They're doing the fastest possible.\n\n1:26:39.340 --> 1:26:40.860\n They're doing shallow analysis.\n\n1:26:40.860 --> 1:26:44.820\n So they are very quickly analyzing the question\n\n1:26:44.820 --> 1:26:49.820\n and coming up with some key vectors or cues, if you will.\n\n1:26:49.980 --> 1:26:51.060\n And they're taking those cues\n\n1:26:51.060 --> 1:26:52.540\n and they're very quickly going through\n\n1:26:52.540 --> 1:26:54.900\n like their library of stuff,\n\n1:26:54.900 --> 1:26:57.700\n not deeply reasoning about what's going on.\n\n1:26:57.700 --> 1:27:00.580\n And then sort of like a lots of different,\n\n1:27:00.580 --> 1:27:03.180\n like what we would call these scores,\n\n1:27:03.180 --> 1:27:06.060\n would kind of score that in a very shallow way\n\n1:27:06.060 --> 1:27:08.900\n and then say, oh, boom, you know, that's what it is.\n\n1:27:08.900 --> 1:27:12.420\n And so it's interesting as we reflected on that.\n\n1:27:12.420 --> 1:27:16.060\n So we may be doing something that's not too far off\n\n1:27:16.060 --> 1:27:17.220\n from the way humans do it,\n\n1:27:17.220 --> 1:27:21.420\n but we certainly didn't approach it by saying,\n\n1:27:21.420 --> 1:27:22.660\n how would a human do this?\n\n1:27:22.660 --> 1:27:24.620\n Now in elemental cognition,\n\n1:27:24.620 --> 1:27:27.300\n like the project I'm leading now,\n\n1:27:27.300 --> 1:27:28.740\n we ask those questions all the time\n\n1:27:28.740 --> 1:27:31.660\n because ultimately we're trying to do something\n\n1:27:31.660 --> 1:27:35.060\n that is to make the intelligence of the machine\n\n1:27:35.060 --> 1:27:37.740\n and the intelligence of the human very compatible.\n\n1:27:37.740 --> 1:27:38.660\n Well, compatible in the sense\n\n1:27:38.660 --> 1:27:40.940\n they can communicate with one another\n\n1:27:40.940 --> 1:27:44.540\n and they can reason with this shared understanding.\n\n1:27:44.540 --> 1:27:48.020\n So how they think about things and how they build answers,\n\n1:27:48.020 --> 1:27:49.740\n how they build explanations\n\n1:27:49.740 --> 1:27:52.100\n becomes a very important question to consider.\n\n1:27:52.100 --> 1:27:56.900\n So what's the difference between this open domain,\n\n1:27:56.900 --> 1:28:01.900\n but cold constructed question answering of Jeopardy\n\n1:28:02.340 --> 1:28:07.340\n and more something that requires understanding\n\n1:28:07.380 --> 1:28:10.220\n for shared communication with humans and machines?\n\n1:28:10.220 --> 1:28:13.300\n Yeah, well, this goes back to the interpretation\n\n1:28:13.300 --> 1:28:15.540\n of what we were talking about before.\n\n1:28:15.540 --> 1:28:19.140\n Jeopardy, the system's not trying to interpret the question\n\n1:28:19.140 --> 1:28:22.060\n and it's not interpreting the content it's reusing\n\n1:28:22.060 --> 1:28:23.860\n with regard to any particular framework.\n\n1:28:23.860 --> 1:28:26.900\n I mean, it is parsing it and parsing the content\n\n1:28:26.900 --> 1:28:29.460\n and using grammatical cues and stuff like that.\n\n1:28:29.460 --> 1:28:31.700\n So if you think of grammar as a human framework\n\n1:28:31.700 --> 1:28:33.420\n in some sense, it has that,\n\n1:28:33.420 --> 1:28:36.900\n but when you get into the richer semantic frameworks,\n\n1:28:36.900 --> 1:28:40.060\n what do people, how do they think, what motivates them,\n\n1:28:40.060 --> 1:28:41.620\n what are the events that are occurring\n\n1:28:41.620 --> 1:28:42.580\n and why are they occurring\n\n1:28:42.580 --> 1:28:44.420\n and what causes what else to happen\n\n1:28:44.420 --> 1:28:47.460\n and where are things in time and space?\n\n1:28:47.460 --> 1:28:51.260\n And like when you start thinking about how humans formulate\n\n1:28:51.260 --> 1:28:54.020\n and structure the knowledge that they acquire in their head\n\n1:28:54.020 --> 1:28:55.460\n and wasn't doing any of that.\n\n1:28:57.060 --> 1:29:01.500\n What do you think are the essential challenges\n\n1:29:01.500 --> 1:29:05.860\n of like free flowing communication, free flowing dialogue\n\n1:29:05.860 --> 1:29:09.060\n versus question answering even with the framework\n\n1:29:09.060 --> 1:29:11.260\n of the interpretation dialogue?\n\n1:29:11.260 --> 1:29:12.340\n Yep.\n\n1:29:12.340 --> 1:29:14.980\n Do you see free flowing dialogue\n\n1:29:14.980 --> 1:29:19.980\n as a fundamentally more difficult than question answering\n\n1:29:20.420 --> 1:29:23.580\n even with shared interpretation?\n\n1:29:23.580 --> 1:29:26.660\n So dialogue is important in a number of different ways.\n\n1:29:26.660 --> 1:29:27.500\n I mean, it's a challenge.\n\n1:29:27.500 --> 1:29:30.540\n So first of all, when I think about the machine that,\n\n1:29:30.540 --> 1:29:33.300\n when I think about a machine that understands language\n\n1:29:33.300 --> 1:29:36.780\n and ultimately can reason in an objective way\n\n1:29:36.780 --> 1:29:40.580\n that can take the information that it perceives\n\n1:29:40.580 --> 1:29:42.260\n through language or other means\n\n1:29:42.260 --> 1:29:44.540\n and connect it back to these frameworks,\n\n1:29:44.540 --> 1:29:46.220\n reason and explain itself,\n\n1:29:48.020 --> 1:29:50.700\n that system ultimately needs to be able to talk to humans\n\n1:29:50.700 --> 1:29:52.940\n or it needs to be able to interact with humans.\n\n1:29:52.940 --> 1:29:55.180\n So in some sense it needs to dialogue.\n\n1:29:55.180 --> 1:29:57.140\n That doesn't mean that it,\n\n1:29:58.660 --> 1:30:01.820\n sometimes people talk about dialogue and they think,\n\n1:30:01.820 --> 1:30:04.300\n you know, how do humans talk to like,\n\n1:30:04.300 --> 1:30:07.700\n talk to each other in a casual conversation\n\n1:30:07.700 --> 1:30:09.900\n and you can mimic casual conversations.\n\n1:30:11.780 --> 1:30:14.340\n We're not trying to mimic casual conversations.\n\n1:30:14.340 --> 1:30:17.580\n We're really trying to produce a machine\n\n1:30:17.580 --> 1:30:20.260\n whose goal is to help you think\n\n1:30:20.260 --> 1:30:23.620\n and help you reason about your answers and explain why.\n\n1:30:23.620 --> 1:30:26.580\n So instead of like talking to your friend down the street\n\n1:30:26.580 --> 1:30:28.900\n about having a small talk conversation\n\n1:30:28.900 --> 1:30:30.500\n with your friend down the street,\n\n1:30:30.500 --> 1:30:32.380\n this is more about like you would be communicating\n\n1:30:32.380 --> 1:30:34.060\n to the computer on Star Trek\n\n1:30:34.060 --> 1:30:36.780\n where like, what do you wanna think about?\n\n1:30:36.780 --> 1:30:37.620\n Like, what do you wanna reason about?\n\n1:30:37.620 --> 1:30:38.780\n I'm gonna tell you the information I have.\n\n1:30:38.780 --> 1:30:39.860\n I'm gonna have to summarize it.\n\n1:30:39.860 --> 1:30:41.060\n I'm gonna ask you questions.\n\n1:30:41.060 --> 1:30:42.700\n You're gonna answer those questions.\n\n1:30:42.700 --> 1:30:44.300\n I'm gonna go back and forth with you.\n\n1:30:44.300 --> 1:30:46.620\n I'm gonna figure out what your mental model is.\n\n1:30:46.620 --> 1:30:49.940\n I'm gonna now relate that to the information I have\n\n1:30:49.940 --> 1:30:53.060\n and present it to you in a way that you can understand it\n\n1:30:53.060 --> 1:30:54.940\n and then we could ask followup questions.\n\n1:30:54.940 --> 1:30:58.340\n So it's that type of dialogue that you wanna construct.\n\n1:30:58.340 --> 1:31:02.380\n It's more structured, it's more goal oriented,\n\n1:31:02.380 --> 1:31:04.900\n but it needs to be fluid.\n\n1:31:04.900 --> 1:31:09.300\n In other words, it has to be engaging and fluid.\n\n1:31:09.300 --> 1:31:13.100\n It has to be productive and not distracting.\n\n1:31:13.100 --> 1:31:15.700\n So there has to be a model of,\n\n1:31:15.700 --> 1:31:17.580\n in other words, the machine has to have a model\n\n1:31:17.580 --> 1:31:21.860\n of how humans think through things and discuss them.\n\n1:31:22.660 --> 1:31:26.900\n So basically a productive, rich conversation\n\n1:31:28.700 --> 1:31:30.100\n unlike this podcast.\n\n1:31:32.700 --> 1:31:34.940\n I'd like to think it's more similar to this podcast.\n\n1:31:34.940 --> 1:31:36.100\n I wasn't joking.\n\n1:31:37.020 --> 1:31:39.740\n I'll ask you about humor as well, actually.\n\n1:31:39.740 --> 1:31:43.300\n But what's the hardest part of that?\n\n1:31:43.300 --> 1:31:45.340\n Because it seems we're quite far away\n\n1:31:46.620 --> 1:31:49.820\n as a community from that still to be able to,\n\n1:31:49.820 --> 1:31:53.020\n so one is having a shared understanding.\n\n1:31:53.020 --> 1:31:54.920\n That's, I think, a lot of the stuff you said\n\n1:31:54.920 --> 1:31:57.160\n with frameworks is quite brilliant.\n\n1:31:57.160 --> 1:32:01.500\n But just creating a smooth discourse.\n\n1:32:02.740 --> 1:32:05.300\n It feels clunky right now.\n\n1:32:05.300 --> 1:32:07.620\n Which aspects of this whole problem\n\n1:32:07.620 --> 1:32:10.540\n that you just specified of having\n\n1:32:10.540 --> 1:32:12.900\n a productive conversation is the hardest?\n\n1:32:12.900 --> 1:32:17.700\n And that we're, or maybe any aspect of it\n\n1:32:17.700 --> 1:32:20.780\n you can comment on because it's so shrouded in mystery.\n\n1:32:20.780 --> 1:32:24.280\n So I think to do this you kind of have to be creative\n\n1:32:24.280 --> 1:32:25.900\n in the following sense.\n\n1:32:26.820 --> 1:32:29.820\n If I were to do this as purely a machine learning approach\n\n1:32:29.820 --> 1:32:32.940\n and someone said learn how to have a good,\n\n1:32:32.940 --> 1:32:37.940\n fluent, structured knowledge acquisition conversation,\n\n1:32:38.420 --> 1:32:39.980\n I'd go out and say, okay, I have to collect\n\n1:32:39.980 --> 1:32:42.360\n a bunch of data of people doing that.\n\n1:32:42.360 --> 1:32:47.100\n People reasoning well, having a good, structured\n\n1:32:47.100 --> 1:32:50.320\n conversation that both acquires knowledge efficiently\n\n1:32:50.320 --> 1:32:52.420\n as well as produces answers and explanations\n\n1:32:52.420 --> 1:32:54.600\n as part of the process.\n\n1:32:54.600 --> 1:32:57.340\n And you struggle.\n\n1:32:57.340 --> 1:32:58.180\n I don't know.\n\n1:32:58.180 --> 1:32:59.000\n To collect the data.\n\n1:32:59.000 --> 1:33:00.700\n To collect the data because I don't know\n\n1:33:00.700 --> 1:33:02.640\n how much data is like that.\n\n1:33:02.640 --> 1:33:06.140\n Okay, there's one, there's a humorous commentary\n\n1:33:06.140 --> 1:33:08.500\n on the lack of rational discourse.\n\n1:33:08.500 --> 1:33:12.700\n But also even if it's out there, say it was out there,\n\n1:33:12.700 --> 1:33:16.380\n how do you actually annotate, like how do you collect\n\n1:33:16.380 --> 1:33:17.220\n an accessible example?\n\n1:33:17.220 --> 1:33:19.200\n Right, so I think any problem like this\n\n1:33:19.200 --> 1:33:23.140\n where you don't have enough data to represent\n\n1:33:23.140 --> 1:33:24.740\n the phenomenon you want to learn,\n\n1:33:24.740 --> 1:33:26.740\n in other words you want, if you have enough data\n\n1:33:26.740 --> 1:33:28.540\n you could potentially learn the pattern.\n\n1:33:28.540 --> 1:33:30.340\n In an example like this it's hard to do.\n\n1:33:30.340 --> 1:33:34.420\n This is sort of a human sort of thing to do.\n\n1:33:34.420 --> 1:33:37.020\n What recently came out at IBM was the debater projects\n\n1:33:37.020 --> 1:33:39.460\n and it's interesting, right, because now you do have\n\n1:33:39.460 --> 1:33:42.580\n these structured dialogues, these debate things\n\n1:33:42.580 --> 1:33:44.700\n where they did use machine learning techniques\n\n1:33:44.700 --> 1:33:46.980\n to generate these debates.\n\n1:33:49.220 --> 1:33:52.460\n Dialogues are a little bit tougher in my opinion\n\n1:33:52.460 --> 1:33:56.100\n than generating a structured argument\n\n1:33:56.100 --> 1:33:57.580\n where you have lots of other structured arguments\n\n1:33:57.580 --> 1:33:59.540\n like this, you could potentially annotate that data\n\n1:33:59.540 --> 1:34:00.820\n and you could say this is a good response,\n\n1:34:00.820 --> 1:34:03.060\n this is a bad response in a particular domain.\n\n1:34:03.060 --> 1:34:08.060\n Here I have to be responsive and I have to be opportunistic\n\n1:34:08.900 --> 1:34:11.820\n with regard to what is the human saying.\n\n1:34:11.820 --> 1:34:14.900\n So I'm goal oriented in saying I want to solve the problem,\n\n1:34:14.900 --> 1:34:16.580\n I want to acquire the knowledge necessary,\n\n1:34:16.580 --> 1:34:19.140\n but I also have to be opportunistic and responsive\n\n1:34:19.140 --> 1:34:21.040\n to what the human is saying.\n\n1:34:21.040 --> 1:34:24.060\n So I think that it's not clear that we could just train\n\n1:34:24.060 --> 1:34:28.020\n on the body of data to do this, but we could bootstrap it.\n\n1:34:28.020 --> 1:34:30.540\n In other words, we can be creative and we could say,\n\n1:34:30.540 --> 1:34:34.020\n what do we think the structure of a good dialogue is\n\n1:34:34.020 --> 1:34:35.820\n that does this well?\n\n1:34:35.820 --> 1:34:37.860\n And we can start to create that.\n\n1:34:37.860 --> 1:34:42.100\n If we can create that more programmatically,\n\n1:34:42.100 --> 1:34:44.700\n at least to get this process started\n\n1:34:44.700 --> 1:34:47.980\n and I can create a tool that now engages humans effectively,\n\n1:34:47.980 --> 1:34:51.340\n I could start generating data,\n\n1:34:51.340 --> 1:34:53.020\n I could start the human learning process\n\n1:34:53.020 --> 1:34:55.060\n and I can update my machine,\n\n1:34:55.060 --> 1:34:57.700\n but I could also start the automatic learning process\n\n1:34:57.700 --> 1:34:59.860\n as well, but I have to understand\n\n1:34:59.860 --> 1:35:01.860\n what features to even learn over.\n\n1:35:01.860 --> 1:35:04.740\n So I have to bootstrap the process a little bit first.\n\n1:35:04.740 --> 1:35:07.740\n And that's a creative design task\n\n1:35:07.740 --> 1:35:11.060\n that I could then use as input\n\n1:35:11.060 --> 1:35:13.420\n into a more automatic learning task.\n\n1:35:13.420 --> 1:35:16.740\n So some creativity in bootstrapping.\n\n1:35:16.740 --> 1:35:18.020\n What elements of a conversation\n\n1:35:18.020 --> 1:35:21.140\n do you think you would like to see?\n\n1:35:21.140 --> 1:35:25.620\n So one of the benchmarks for me is humor, right?\n\n1:35:25.620 --> 1:35:27.580\n That seems to be one of the hardest.\n\n1:35:27.580 --> 1:35:30.340\n And to me, the biggest contrast is sort of Watson.\n\n1:35:31.340 --> 1:35:33.380\n So one of the greatest sketches,\n\n1:35:33.380 --> 1:35:35.260\n comedy sketches of all time, right,\n\n1:35:35.260 --> 1:35:37.700\n is the SNL celebrity Jeopardy\n\n1:35:38.580 --> 1:35:42.060\n with Alex Trebek and Sean Connery\n\n1:35:42.060 --> 1:35:44.060\n and Burt Reynolds and so on,\n\n1:35:44.060 --> 1:35:47.900\n with Sean Connery commentating on Alex Trebek's\n\n1:35:47.900 --> 1:35:49.380\n while they're alive.\n\n1:35:49.380 --> 1:35:52.860\n And I think all of them are in the negative pointwise.\n\n1:35:52.860 --> 1:35:55.100\n So they're clearly all losing\n\n1:35:55.100 --> 1:35:56.340\n in terms of the game of Jeopardy,\n\n1:35:56.340 --> 1:35:58.340\n but they're winning in terms of comedy.\n\n1:35:58.340 --> 1:36:03.340\n So what do you think about humor in this whole interaction\n\n1:36:03.780 --> 1:36:06.500\n in the dialogue that's productive?\n\n1:36:06.500 --> 1:36:09.780\n Or even just what humor represents to me\n\n1:36:09.780 --> 1:36:14.780\n is the same idea that you're saying about framework,\n\n1:36:15.420 --> 1:36:16.420\n because humor only exists\n\n1:36:16.420 --> 1:36:18.340\n within a particular human framework.\n\n1:36:18.340 --> 1:36:19.580\n So what do you think about humor?\n\n1:36:19.580 --> 1:36:21.540\n What do you think about things like humor\n\n1:36:21.540 --> 1:36:23.340\n that connect to the kind of creativity\n\n1:36:23.340 --> 1:36:25.100\n you mentioned that's needed?\n\n1:36:25.100 --> 1:36:26.380\n I think there's a couple of things going on there.\n\n1:36:26.380 --> 1:36:29.500\n So I sort of feel like,\n\n1:36:29.500 --> 1:36:31.780\n and I might be too optimistic this way,\n\n1:36:31.780 --> 1:36:34.700\n but I think that there are,\n\n1:36:34.700 --> 1:36:39.020\n we did a little bit about with puns in Jeopardy.\n\n1:36:39.020 --> 1:36:40.700\n We literally sat down and said,\n\n1:36:41.660 --> 1:36:43.180\n how do puns work?\n\n1:36:43.180 --> 1:36:44.820\n And it's like wordplay,\n\n1:36:44.820 --> 1:36:46.140\n and you could formalize these things.\n\n1:36:46.140 --> 1:36:48.260\n So I think there's a lot aspects of humor\n\n1:36:48.260 --> 1:36:50.220\n that you could formalize.\n\n1:36:50.220 --> 1:36:51.620\n You could also learn humor.\n\n1:36:51.620 --> 1:36:53.460\n You could just say, what do people laugh at?\n\n1:36:53.460 --> 1:36:54.860\n And if you have enough, again,\n\n1:36:54.860 --> 1:36:56.860\n if you have enough data to represent the phenomenon,\n\n1:36:56.860 --> 1:36:59.460\n you might be able to weigh the features\n\n1:36:59.460 --> 1:37:01.300\n and figure out what humans find funny\n\n1:37:01.300 --> 1:37:02.700\n and what they don't find funny.\n\n1:37:02.700 --> 1:37:05.140\n The machine might not be able to explain\n\n1:37:05.140 --> 1:37:08.060\n why the human is funny unless we sit back\n\n1:37:08.060 --> 1:37:10.180\n and think about that more formally.\n\n1:37:10.180 --> 1:37:12.420\n I think, again, I think you do a combination of both.\n\n1:37:12.420 --> 1:37:13.900\n And I'm always a big proponent of that.\n\n1:37:13.900 --> 1:37:16.700\n I think robust architectures and approaches\n\n1:37:16.700 --> 1:37:19.620\n are always a little bit combination of us reflecting\n\n1:37:19.620 --> 1:37:22.500\n and being creative about how things are structured,\n\n1:37:22.500 --> 1:37:23.780\n how to formalize them,\n\n1:37:23.780 --> 1:37:26.220\n and then taking advantage of large data and doing learning\n\n1:37:26.220 --> 1:37:29.100\n and figuring out how to combine these two approaches.\n\n1:37:29.100 --> 1:37:31.420\n I think there's another aspect to humor though,\n\n1:37:31.420 --> 1:37:34.340\n which goes to the idea that I feel like I can relate\n\n1:37:34.340 --> 1:37:35.820\n to the person telling the story.\n\n1:37:38.820 --> 1:37:42.140\n And I think that's an interesting theme\n\n1:37:42.140 --> 1:37:43.380\n in the whole AI theme,\n\n1:37:43.380 --> 1:37:47.660\n which is, do I feel differently when I know it's a robot?\n\n1:37:48.460 --> 1:37:52.860\n And when I imagine that the robot is not conscious\n\n1:37:52.860 --> 1:37:54.180\n the way I'm conscious,\n\n1:37:54.180 --> 1:37:56.300\n when I imagine the robot does not actually\n\n1:37:56.300 --> 1:37:58.700\n have the experiences that I experience,\n\n1:37:58.700 --> 1:38:00.980\n do I find it funny?\n\n1:38:00.980 --> 1:38:03.060\n Or do, because it's not as related,\n\n1:38:03.060 --> 1:38:06.540\n I don't imagine that the person's relating it to it\n\n1:38:06.540 --> 1:38:07.860\n the way I relate to it.\n\n1:38:07.860 --> 1:38:11.340\n I think this also, you see this in the arts\n\n1:38:11.340 --> 1:38:14.260\n and in entertainment where,\n\n1:38:14.260 --> 1:38:17.380\n sometimes you have savants who are remarkable at a thing,\n\n1:38:17.380 --> 1:38:19.820\n whether it's sculpture or it's music or whatever,\n\n1:38:19.820 --> 1:38:21.300\n but the people who get the most attention\n\n1:38:21.300 --> 1:38:26.300\n are the people who can evoke a similar emotional response,\n\n1:38:26.660 --> 1:38:30.740\n who can get you to emote, right?\n\n1:38:30.740 --> 1:38:31.940\n About the way they are.\n\n1:38:31.940 --> 1:38:34.460\n In other words, who can basically make the connection\n\n1:38:34.460 --> 1:38:37.020\n from the artifact, from the music or the painting\n\n1:38:37.020 --> 1:38:39.780\n of the sculpture to the emotion\n\n1:38:39.780 --> 1:38:42.380\n and get you to share that emotion with them.\n\n1:38:42.380 --> 1:38:44.700\n And then, and that's when it becomes compelling.\n\n1:38:44.700 --> 1:38:46.980\n So they're communicating at a whole different level.\n\n1:38:46.980 --> 1:38:49.340\n They're just not communicating the artifact.\n\n1:38:49.340 --> 1:38:50.980\n They're communicating their emotional response\n\n1:38:50.980 --> 1:38:51.980\n to the artifact.\n\n1:38:51.980 --> 1:38:53.380\n And then you feel like, oh wow,\n\n1:38:53.380 --> 1:38:55.540\n I can relate to that person, I can connect to that,\n\n1:38:55.540 --> 1:38:57.140\n I can connect to that person.\n\n1:38:57.140 --> 1:39:00.660\n So I think humor has that aspect as well.\n\n1:39:00.660 --> 1:39:04.820\n So the idea that you can connect to that person,\n\n1:39:04.820 --> 1:39:06.380\n person being the critical thing,\n\n1:39:07.260 --> 1:39:12.260\n but we're also able to anthropomorphize objects pretty,\n\n1:39:12.620 --> 1:39:15.180\n robots and AI systems pretty well.\n\n1:39:15.180 --> 1:39:18.740\n So we're almost looking to make them human.\n\n1:39:18.740 --> 1:39:20.820\n So maybe from your experience with Watson,\n\n1:39:20.820 --> 1:39:24.940\n maybe you can comment on, did you consider that as part,\n\n1:39:24.940 --> 1:39:27.020\n well, obviously the problem of jeopardy\n\n1:39:27.020 --> 1:39:30.500\n doesn't require anthropomorphization, but nevertheless.\n\n1:39:30.500 --> 1:39:32.300\n Well, there was some interest in doing that.\n\n1:39:32.300 --> 1:39:35.020\n And that's another thing I didn't want to do\n\n1:39:35.020 --> 1:39:36.220\n because I didn't want to distract\n\n1:39:36.220 --> 1:39:38.740\n from the actual scientific task.\n\n1:39:38.740 --> 1:39:39.620\n But you're absolutely right.\n\n1:39:39.620 --> 1:39:43.380\n I mean, humans do anthropomorphize\n\n1:39:43.380 --> 1:39:45.900\n and without necessarily a lot of work.\n\n1:39:45.900 --> 1:39:47.100\n I mean, you just put some eyes\n\n1:39:47.100 --> 1:39:49.220\n and a couple of eyebrow movements\n\n1:39:49.220 --> 1:39:51.820\n and you're getting humans to react emotionally.\n\n1:39:51.820 --> 1:39:53.540\n And I think you can do that.\n\n1:39:53.540 --> 1:39:56.780\n So I didn't mean to suggest that,\n\n1:39:56.780 --> 1:40:00.620\n that that connection cannot be mimicked.\n\n1:40:00.620 --> 1:40:02.260\n I think that connection can be mimicked\n\n1:40:02.260 --> 1:40:07.260\n and can produce that emotional response.\n\n1:40:07.300 --> 1:40:12.300\n I just wonder though, if you're told what's really going on,\n\n1:40:13.020 --> 1:40:17.180\n if you know that the machine is not conscious,\n\n1:40:17.180 --> 1:40:20.740\n not having the same richness of emotional reactions\n\n1:40:20.740 --> 1:40:21.980\n and understanding that it doesn't really\n\n1:40:21.980 --> 1:40:23.380\n share the understanding,\n\n1:40:23.380 --> 1:40:25.100\n but it's essentially just moving its eyebrow\n\n1:40:25.100 --> 1:40:27.180\n or drooping its eyes or making them bigger,\n\n1:40:27.180 --> 1:40:30.180\n whatever it's doing, just getting the emotional response,\n\n1:40:30.180 --> 1:40:31.580\n will you still feel it?\n\n1:40:31.580 --> 1:40:32.420\n Interesting.\n\n1:40:32.420 --> 1:40:34.380\n I think you probably would for a while.\n\n1:40:34.380 --> 1:40:35.860\n And then when it becomes more important\n\n1:40:35.860 --> 1:40:38.700\n that there's a deeper share of understanding,\n\n1:40:38.700 --> 1:40:40.700\n it may run flat, but I don't know.\n\n1:40:40.700 --> 1:40:45.300\n I'm pretty confident that majority of the world,\n\n1:40:45.300 --> 1:40:47.460\n even if you tell them how it works,\n\n1:40:47.460 --> 1:40:49.100\n well, it will not matter,\n\n1:40:49.100 --> 1:40:54.100\n especially if the machine herself says that she is conscious.\n\n1:40:55.420 --> 1:40:56.260\n That's very possible.\n\n1:40:56.260 --> 1:40:59.420\n So you, the scientist that made the machine is saying\n\n1:41:00.700 --> 1:41:02.860\n that this is how the algorithm works.\n\n1:41:02.860 --> 1:41:04.460\n Everybody will just assume you're lying\n\n1:41:04.460 --> 1:41:06.140\n and that there's a conscious being there.\n\n1:41:06.140 --> 1:41:09.220\n So you're deep into the science fiction genre now,\n\n1:41:09.220 --> 1:41:10.060\n but yeah.\n\n1:41:10.060 --> 1:41:12.020\n I don't think it's, it's actually psychology.\n\n1:41:12.020 --> 1:41:13.780\n I think it's not science fiction.\n\n1:41:13.780 --> 1:41:14.900\n I think it's reality.\n\n1:41:14.900 --> 1:41:16.780\n I think it's a really powerful one\n\n1:41:16.780 --> 1:41:19.980\n that we'll have to be exploring in the next few decades.\n\n1:41:19.980 --> 1:41:20.820\n I agree.\n\n1:41:20.820 --> 1:41:23.540\n It's a very interesting element of intelligence.\n\n1:41:23.540 --> 1:41:25.220\n So what do you think,\n\n1:41:25.220 --> 1:41:28.500\n we've talked about social constructs of intelligences\n\n1:41:28.500 --> 1:41:31.140\n and frameworks and the way humans\n\n1:41:31.140 --> 1:41:33.940\n kind of interpret information.\n\n1:41:33.940 --> 1:41:35.700\n What do you think is a good test of intelligence\n\n1:41:35.700 --> 1:41:36.540\n in your view?\n\n1:41:36.540 --> 1:41:41.300\n So there's the Alan Turing with the Turing test.\n\n1:41:41.300 --> 1:41:44.940\n Watson accomplished something very impressive with Jeopardy.\n\n1:41:44.940 --> 1:41:46.780\n What do you think is a test\n\n1:41:47.820 --> 1:41:49.740\n that would impress the heck out of you\n\n1:41:49.740 --> 1:41:52.980\n that you saw that a computer could do?\n\n1:41:52.980 --> 1:41:57.260\n They would say, this is crossing a kind of threshold\n\n1:41:57.260 --> 1:42:00.660\n that gives me pause in a good way.\n\n1:42:02.620 --> 1:42:06.100\n My expectations for AI are generally high.\n\n1:42:06.100 --> 1:42:07.420\n What does high look like by the way?\n\n1:42:07.420 --> 1:42:10.380\n So not the threshold, test is a threshold.\n\n1:42:10.380 --> 1:42:12.460\n What do you think is the destination?\n\n1:42:12.460 --> 1:42:14.540\n What do you think is the ceiling?\n\n1:42:15.780 --> 1:42:18.460\n I think machines will in many measures\n\n1:42:18.460 --> 1:42:21.660\n will be better than us, will become more effective.\n\n1:42:21.660 --> 1:42:25.140\n In other words, better predictors about a lot of things\n\n1:42:25.140 --> 1:42:28.540\n than ultimately we can do.\n\n1:42:28.540 --> 1:42:30.780\n I think where they're gonna struggle\n\n1:42:30.780 --> 1:42:32.260\n is what we talked about before,\n\n1:42:32.260 --> 1:42:36.540\n which is relating to communicating with\n\n1:42:36.540 --> 1:42:40.580\n and understanding humans in deeper ways.\n\n1:42:40.580 --> 1:42:42.420\n And so I think that's a key point,\n\n1:42:42.420 --> 1:42:44.820\n like we can create the super parrot.\n\n1:42:44.820 --> 1:42:47.660\n What I mean by the super parrot is given enough data,\n\n1:42:47.660 --> 1:42:50.140\n a machine can mimic your emotional response,\n\n1:42:50.140 --> 1:42:52.780\n can even generate language that will sound smart\n\n1:42:52.780 --> 1:42:56.380\n and what someone else might say under similar circumstances.\n\n1:42:57.860 --> 1:42:58.940\n Like I would just pause on that,\n\n1:42:58.940 --> 1:43:01.180\n like that's the super parrot, right?\n\n1:43:01.180 --> 1:43:03.660\n So given similar circumstances,\n\n1:43:03.660 --> 1:43:06.940\n moves its faces in similar ways,\n\n1:43:06.940 --> 1:43:09.420\n changes its tone of voice in similar ways,\n\n1:43:09.420 --> 1:43:12.460\n produces strings of language that would similar\n\n1:43:12.460 --> 1:43:14.300\n that a human might say,\n\n1:43:14.300 --> 1:43:16.740\n not necessarily being able to produce\n\n1:43:16.740 --> 1:43:19.420\n a logical interpretation or understanding\n\n1:43:20.620 --> 1:43:25.260\n that would ultimately satisfy a critical interrogation\n\n1:43:25.260 --> 1:43:26.740\n or a critical understanding.\n\n1:43:27.700 --> 1:43:30.540\n I think you just described me in a nutshell.\n\n1:43:30.540 --> 1:43:34.380\n So I think philosophically speaking,\n\n1:43:34.380 --> 1:43:36.580\n you could argue that that's all we're doing\n\n1:43:36.580 --> 1:43:37.860\n as human beings to work super parrots.\n\n1:43:37.860 --> 1:43:40.300\n So I was gonna say, it's very possible,\n\n1:43:40.300 --> 1:43:42.620\n you know, humans do behave that way too.\n\n1:43:42.620 --> 1:43:45.860\n And so upon deeper probing and deeper interrogation,\n\n1:43:45.860 --> 1:43:48.940\n you may find out that there isn't a shared understanding\n\n1:43:48.940 --> 1:43:50.340\n because I think humans do both.\n\n1:43:50.340 --> 1:43:53.140\n Like humans are statistical language model machines\n\n1:43:54.580 --> 1:43:57.660\n and they are capable reasoners.\n\n1:43:57.660 --> 1:43:59.900\n You know, they're both.\n\n1:43:59.900 --> 1:44:02.900\n And you don't know which is going on, right?\n\n1:44:02.900 --> 1:44:07.900\n So, and I think it's an interesting problem.\n\n1:44:09.140 --> 1:44:11.380\n We talked earlier about like where we are\n\n1:44:11.380 --> 1:44:14.700\n in our social and political landscape.\n\n1:44:14.700 --> 1:44:19.540\n Can you distinguish someone who can string words together\n\n1:44:19.540 --> 1:44:21.820\n and sound like they know what they're talking about\n\n1:44:21.820 --> 1:44:24.020\n from someone who actually does?\n\n1:44:24.020 --> 1:44:25.620\n Can you do that without dialogue,\n\n1:44:25.620 --> 1:44:27.780\n without interrogative or probing dialogue?\n\n1:44:27.780 --> 1:44:31.100\n So it's interesting because humans are really good\n\n1:44:31.100 --> 1:44:34.660\n in their own mind, justifying or explaining what they hear\n\n1:44:34.660 --> 1:44:38.860\n because they project their understanding onto yours.\n\n1:44:38.860 --> 1:44:41.540\n So you could say, you could put together a string of words\n\n1:44:41.540 --> 1:44:44.020\n and someone will sit there and interpret it\n\n1:44:44.020 --> 1:44:46.060\n in a way that's extremely biased\n\n1:44:46.060 --> 1:44:47.140\n to the way they wanna interpret it.\n\n1:44:47.140 --> 1:44:48.460\n They wanna assume that you're an idiot\n\n1:44:48.460 --> 1:44:50.060\n and they'll interpret it one way.\n\n1:44:50.060 --> 1:44:51.380\n They will assume you're a genius\n\n1:44:51.380 --> 1:44:54.380\n and they'll interpret it another way that suits their needs.\n\n1:44:54.380 --> 1:44:56.460\n So this is tricky business.\n\n1:44:56.460 --> 1:44:59.060\n So I think to answer your question,\n\n1:44:59.060 --> 1:45:02.220\n as AI gets better and better, better and better mimic,\n\n1:45:02.220 --> 1:45:03.900\n you recreate the super parrots,\n\n1:45:03.900 --> 1:45:06.580\n we're challenged just as we are with,\n\n1:45:06.580 --> 1:45:08.220\n we're challenged with humans.\n\n1:45:08.220 --> 1:45:10.700\n Do you really know what you're talking about?\n\n1:45:10.700 --> 1:45:14.500\n Do you have a meaningful interpretation,\n\n1:45:14.500 --> 1:45:17.940\n a powerful framework that you could reason over\n\n1:45:17.940 --> 1:45:22.940\n and justify your answers, justify your predictions\n\n1:45:23.420 --> 1:45:25.620\n and your beliefs, why you think they make sense.\n\n1:45:25.620 --> 1:45:28.620\n Can you convince me what the implications are?\n\n1:45:28.620 --> 1:45:33.620\n So can you reason intelligently and make me believe\n\n1:45:34.260 --> 1:45:39.260\n that the implications of your prediction and so forth?\n\n1:45:40.260 --> 1:45:43.060\n So what happens is it becomes reflective.\n\n1:45:44.060 --> 1:45:46.420\n My standard for judging your intelligence\n\n1:45:46.420 --> 1:45:47.700\n depends a lot on mine.\n\n1:45:49.940 --> 1:45:54.380\n But you're saying there should be a large group of people\n\n1:45:54.380 --> 1:45:56.900\n with a certain standard of intelligence\n\n1:45:56.900 --> 1:46:01.640\n that would be convinced by this particular AI system.\n\n1:46:02.580 --> 1:46:03.540\n Then they'll pass.\n\n1:46:03.540 --> 1:46:07.660\n There should be, but I think depending on the content,\n\n1:46:07.660 --> 1:46:09.500\n one of the problems we have there\n\n1:46:09.500 --> 1:46:12.580\n is that if that large community of people\n\n1:46:12.580 --> 1:46:16.620\n are not judging it with regard to a rigorous standard\n\n1:46:16.620 --> 1:46:19.500\n of objective logic and reason, you still have a problem.\n\n1:46:19.500 --> 1:46:23.780\n Like masses of people can be persuaded.\n\n1:46:23.780 --> 1:46:25.020\n The millennials, yeah.\n\n1:46:25.020 --> 1:46:27.660\n To turn their brains off.\n\n1:46:29.020 --> 1:46:29.960\n Right, okay.\n\n1:46:31.980 --> 1:46:32.820\n Sorry.\n\n1:46:32.820 --> 1:46:33.780\n By the way, I have nothing against the millennials.\n\n1:46:33.780 --> 1:46:36.060\n No, I don't, I'm just, just.\n\n1:46:36.060 --> 1:46:40.980\n So you're a part of one of the great benchmarks,\n\n1:46:40.980 --> 1:46:43.280\n challenges of AI history.\n\n1:46:43.280 --> 1:46:47.220\n What do you think about AlphaZero, OpenAI5,\n\n1:46:47.220 --> 1:46:50.740\n AlphaStar accomplishments on video games recently,\n\n1:46:50.740 --> 1:46:55.300\n which are also, I think, at least in the case of Go,\n\n1:46:55.300 --> 1:46:57.180\n with AlphaGo and AlphaZero playing Go,\n\n1:46:57.180 --> 1:46:59.700\n was a monumental accomplishment as well.\n\n1:46:59.700 --> 1:47:01.740\n What are your thoughts about that challenge?\n\n1:47:01.740 --> 1:47:03.460\n I think it was a giant landmark for AI.\n\n1:47:03.460 --> 1:47:04.460\n I think it was phenomenal.\n\n1:47:04.460 --> 1:47:06.020\n I mean, it was one of those other things\n\n1:47:06.020 --> 1:47:08.540\n nobody thought like solving Go was gonna be easy,\n\n1:47:08.540 --> 1:47:10.460\n particularly because it's hard for,\n\n1:47:10.460 --> 1:47:12.700\n particularly hard for humans.\n\n1:47:12.700 --> 1:47:15.540\n Hard for humans to learn, hard for humans to excel at.\n\n1:47:15.540 --> 1:47:20.540\n And so it was another measure, a measure of intelligence.\n\n1:47:21.380 --> 1:47:22.500\n It's very cool.\n\n1:47:22.500 --> 1:47:25.260\n I mean, it's very interesting what they did.\n\n1:47:25.260 --> 1:47:27.940\n And I loved how they solved the data problem,\n\n1:47:27.940 --> 1:47:29.180\n which again, they bootstrapped it\n\n1:47:29.180 --> 1:47:30.420\n and got the machine to play itself,\n\n1:47:30.420 --> 1:47:32.720\n to generate enough data to learn from.\n\n1:47:32.720 --> 1:47:33.860\n I think that was brilliant.\n\n1:47:33.860 --> 1:47:35.660\n I think that was great.\n\n1:47:35.660 --> 1:47:38.900\n And of course, the result speaks for itself.\n\n1:47:38.900 --> 1:47:40.900\n I think it makes us think about,\n\n1:47:40.900 --> 1:47:42.940\n again, it is, okay, what's intelligence?\n\n1:47:42.940 --> 1:47:45.520\n What aspects of intelligence are important?\n\n1:47:45.520 --> 1:47:49.340\n Can the Go machine help me make me a better Go player?\n\n1:47:49.340 --> 1:47:51.660\n Is it an alien intelligence?\n\n1:47:51.660 --> 1:47:53.860\n Am I even capable of,\n\n1:47:53.860 --> 1:47:56.060\n like again, if we put in very simple terms,\n\n1:47:56.060 --> 1:47:59.180\n it found the function, it found the Go function.\n\n1:47:59.180 --> 1:48:00.820\n Can I even comprehend the Go function?\n\n1:48:00.820 --> 1:48:02.260\n Can I talk about the Go function?\n\n1:48:02.260 --> 1:48:03.880\n Can I conceptualize the Go function,\n\n1:48:03.880 --> 1:48:05.500\n like whatever it might be?\n\n1:48:05.500 --> 1:48:08.040\n So one of the interesting ideas of that system\n\n1:48:08.040 --> 1:48:10.060\n is that it plays against itself, right?\n\n1:48:10.060 --> 1:48:12.660\n But there's no human in the loop there.\n\n1:48:12.660 --> 1:48:16.460\n So like you're saying, it could have by itself\n\n1:48:16.460 --> 1:48:18.900\n created an alien intelligence.\n\n1:48:18.900 --> 1:48:19.740\n How?\n\n1:48:19.740 --> 1:48:21.820\n Toward a Go, imagine you're sentencing,\n\n1:48:21.820 --> 1:48:24.700\n you're a judge and you're sentencing people,\n\n1:48:24.700 --> 1:48:26.420\n or you're setting policy,\n\n1:48:26.420 --> 1:48:31.160\n or you're making medical decisions,\n\n1:48:31.160 --> 1:48:33.340\n and you can't explain,\n\n1:48:33.340 --> 1:48:34.880\n you can't get anybody to understand\n\n1:48:34.880 --> 1:48:36.140\n what you're doing or why.\n\n1:48:37.300 --> 1:48:40.700\n So it's an interesting dilemma\n\n1:48:40.700 --> 1:48:43.620\n for the applications of AI.\n\n1:48:43.620 --> 1:48:47.420\n Do we hold AI to this accountability\n\n1:48:47.420 --> 1:48:51.460\n that says humans have to be willing\n\n1:48:51.460 --> 1:48:56.380\n to take responsibility for the decision?\n\n1:48:56.380 --> 1:48:58.780\n In other words, can you explain why you would do the thing?\n\n1:48:58.780 --> 1:49:02.040\n Will you get up and speak to other humans\n\n1:49:02.040 --> 1:49:04.660\n and convince them that this was a smart decision?\n\n1:49:04.660 --> 1:49:07.180\n Is the AI enabling you to do that?\n\n1:49:07.180 --> 1:49:10.220\n Can you get behind the logic that was made there?\n\n1:49:10.220 --> 1:49:13.420\n Do you think, sorry to land on this point,\n\n1:49:13.420 --> 1:49:15.420\n because it's a fascinating one.\n\n1:49:15.420 --> 1:49:17.540\n It's a great goal for AI.\n\n1:49:17.540 --> 1:49:21.460\n Do you think it's achievable in many cases?\n\n1:49:21.460 --> 1:49:23.860\n Or, okay, there's two possible worlds\n\n1:49:23.860 --> 1:49:25.820\n that we have in the future.\n\n1:49:25.820 --> 1:49:28.940\n One is where AI systems do like medical diagnosis\n\n1:49:28.940 --> 1:49:32.420\n or things like that, or drive a car\n\n1:49:32.420 --> 1:49:36.580\n without ever explaining to you why it fails when it does.\n\n1:49:36.580 --> 1:49:40.340\n That's one possible world and we're okay with it.\n\n1:49:40.340 --> 1:49:42.980\n Or the other where we are not okay with it\n\n1:49:42.980 --> 1:49:45.380\n and we really hold back the technology\n\n1:49:45.380 --> 1:49:48.780\n from getting too good before it's able to explain.\n\n1:49:48.780 --> 1:49:50.800\n Which of those worlds are more likely, do you think,\n\n1:49:50.800 --> 1:49:53.500\n and which are concerning to you or not?\n\n1:49:53.500 --> 1:49:56.140\n I think the reality is it's gonna be a mix.\n\n1:49:56.140 --> 1:49:57.460\n I'm not sure I have a problem with that.\n\n1:49:57.460 --> 1:49:59.940\n I mean, I think there are tasks that are perfectly fine\n\n1:49:59.940 --> 1:50:03.980\n with machines show a certain level of performance\n\n1:50:03.980 --> 1:50:07.740\n and that level of performance is already better than humans.\n\n1:50:07.740 --> 1:50:11.260\n So for example, I don't know that I take driverless cars.\n\n1:50:11.260 --> 1:50:14.300\n If driverless cars learn how to be more effective drivers\n\n1:50:14.300 --> 1:50:16.900\n than humans but can't explain what they're doing,\n\n1:50:16.900 --> 1:50:19.020\n but bottom line, statistically speaking,\n\n1:50:19.020 --> 1:50:22.380\n they're 10 times safer than humans,\n\n1:50:22.380 --> 1:50:24.960\n I don't know that I care.\n\n1:50:24.960 --> 1:50:27.540\n I think when we have these edge cases\n\n1:50:27.540 --> 1:50:29.700\n when something bad happens and we wanna decide\n\n1:50:29.700 --> 1:50:32.540\n who's liable for that thing and who made that mistake\n\n1:50:32.540 --> 1:50:33.500\n and what do we do about that?\n\n1:50:33.500 --> 1:50:36.740\n And I think those edge cases are interesting cases.\n\n1:50:36.740 --> 1:50:38.940\n And now do we go to designers of the AI\n\n1:50:38.940 --> 1:50:40.700\n and the AI says, I don't know if that's what it learned\n\n1:50:40.700 --> 1:50:43.620\n to do and it says, well, you didn't train it properly.\n\n1:50:43.620 --> 1:50:46.740\n You were negligent in the training data\n\n1:50:46.740 --> 1:50:47.800\n that you gave that machine.\n\n1:50:47.800 --> 1:50:49.380\n Like, how do we drive down the reliability?\n\n1:50:49.380 --> 1:50:52.080\n So I think those are interesting questions.\n\n1:50:53.180 --> 1:50:55.300\n So the optimization problem there, sorry,\n\n1:50:55.300 --> 1:50:56.900\n is to create an AI system that's able\n\n1:50:56.900 --> 1:50:58.780\n to explain the lawyers away.\n\n1:51:00.100 --> 1:51:01.620\n There you go.\n\n1:51:01.620 --> 1:51:04.040\n I think it's gonna be interesting.\n\n1:51:04.040 --> 1:51:05.820\n I mean, I think this is where technology\n\n1:51:05.820 --> 1:51:09.460\n and social discourse are gonna get like deeply intertwined\n\n1:51:09.460 --> 1:51:12.380\n and how we start thinking about problems, decisions\n\n1:51:12.380 --> 1:51:13.500\n and problems like that.\n\n1:51:13.500 --> 1:51:15.860\n I think in other cases it becomes more obvious\n\n1:51:15.860 --> 1:51:20.260\n where it's like, why did you decide\n\n1:51:20.260 --> 1:51:25.260\n to give that person a longer sentence or deny them parole?\n\n1:51:27.180 --> 1:51:30.580\n Again, policy decisions or why did you pick that treatment?\n\n1:51:30.580 --> 1:51:32.300\n Like that treatment ended up killing that guy.\n\n1:51:32.300 --> 1:51:34.680\n Like, why was that a reasonable choice to make?\n\n1:51:36.940 --> 1:51:40.100\n And people are gonna demand explanations.\n\n1:51:40.100 --> 1:51:41.940\n Now there's a reality though here.\n\n1:51:43.460 --> 1:51:45.960\n And the reality is that it's not,\n\n1:51:45.960 --> 1:51:48.620\n I'm not sure humans are making reasonable choices\n\n1:51:48.620 --> 1:51:49.940\n when they do these things.\n\n1:51:49.940 --> 1:51:54.780\n They are using statistical hunches, biases,\n\n1:51:54.780 --> 1:51:58.520\n or even systematically using statistical averages\n\n1:51:58.520 --> 1:51:59.360\n to make calls.\n\n1:51:59.360 --> 1:52:00.700\n This is what happened to my dad\n\n1:52:00.700 --> 1:52:01.940\n and if you saw the talk I gave about that.\n\n1:52:01.940 --> 1:52:06.940\n But they decided that my father was brain dead.\n\n1:52:07.300 --> 1:52:09.340\n He had went into cardiac arrest\n\n1:52:09.340 --> 1:52:12.420\n and it took a long time for the ambulance to get there\n\n1:52:12.420 --> 1:52:14.580\n and he was not resuscitated right away and so forth.\n\n1:52:14.580 --> 1:52:16.900\n And they came and they told me he was brain dead\n\n1:52:16.900 --> 1:52:17.860\n and why was he brain dead?\n\n1:52:17.860 --> 1:52:19.060\n Because essentially they gave me\n\n1:52:19.060 --> 1:52:22.020\n a purely statistical argument under these conditions\n\n1:52:22.020 --> 1:52:25.340\n with these four features, 98% chance he's brain dead.\n\n1:52:25.340 --> 1:52:28.940\n I said, but can you just tell me not inductively,\n\n1:52:28.940 --> 1:52:30.460\n but deductively go there and tell me\n\n1:52:30.460 --> 1:52:32.820\n his brain's not functioning is the way for you to do that.\n\n1:52:32.820 --> 1:52:35.960\n And the protocol in response was,\n\n1:52:35.960 --> 1:52:37.980\n no, this is how we make this decision.\n\n1:52:37.980 --> 1:52:39.720\n I said, this is inadequate for me.\n\n1:52:39.720 --> 1:52:43.060\n I understand the statistics and I don't know how,\n\n1:52:43.060 --> 1:52:44.740\n there's a 2% chance he's still alive.\n\n1:52:44.740 --> 1:52:46.500\n I just don't know the specifics.\n\n1:52:46.500 --> 1:52:49.380\n I need the specifics of this case\n\n1:52:49.380 --> 1:52:51.420\n and I want the deductive logical argument\n\n1:52:51.420 --> 1:52:53.580\n about why you actually know he's brain dead.\n\n1:52:53.580 --> 1:52:55.980\n So I wouldn't sign the do not resuscitate.\n\n1:52:55.980 --> 1:52:57.820\n And I don't know, it was like they went through\n\n1:52:57.820 --> 1:53:00.020\n lots of procedures, it was a big long story,\n\n1:53:00.020 --> 1:53:02.060\n but the bottom was a fascinating story by the way,\n\n1:53:02.060 --> 1:53:04.340\n but how I reasoned and how the doctors reasoned\n\n1:53:04.340 --> 1:53:05.980\n through this whole process.\n\n1:53:05.980 --> 1:53:07.900\n But I don't know, somewhere around 24 hours later\n\n1:53:07.900 --> 1:53:09.460\n or something, he was sitting up in bed\n\n1:53:09.460 --> 1:53:10.980\n with zero brain damage.\n\n1:53:13.940 --> 1:53:18.020\n I mean, what lessons do you draw from that story,\n\n1:53:18.020 --> 1:53:19.500\n that experience?\n\n1:53:19.500 --> 1:53:22.700\n That the data that's being used\n\n1:53:22.700 --> 1:53:24.100\n to make statistical inferences\n\n1:53:24.100 --> 1:53:26.440\n doesn't adequately reflect the phenomenon.\n\n1:53:26.440 --> 1:53:28.660\n So in other words, you're getting shit wrong,\n\n1:53:28.660 --> 1:53:31.720\n I'm sorry, but you're getting stuff wrong\n\n1:53:31.720 --> 1:53:35.260\n because your model is not robust enough\n\n1:53:35.260 --> 1:53:40.260\n and you might be better off not using statistical inference\n\n1:53:41.320 --> 1:53:43.060\n and statistical averages in certain cases\n\n1:53:43.060 --> 1:53:45.220\n when you know the model's insufficient\n\n1:53:45.220 --> 1:53:48.440\n and that you should be reasoning about the specific case\n\n1:53:48.440 --> 1:53:50.100\n more logically and more deductibly\n\n1:53:51.060 --> 1:53:52.420\n and hold yourself responsible\n\n1:53:52.420 --> 1:53:55.360\n and hold yourself accountable to doing that.\n\n1:53:55.360 --> 1:53:59.380\n And perhaps AI has a role to say the exact thing\n\n1:53:59.380 --> 1:54:02.980\n what you just said, which is perhaps this is a case\n\n1:54:02.980 --> 1:54:05.420\n you should think for yourself,\n\n1:54:05.420 --> 1:54:07.180\n you should reason deductively.\n\n1:54:08.020 --> 1:54:13.020\n Well, so it's hard because it's hard to know that.\n\n1:54:14.780 --> 1:54:17.220\n You'd have to go back and you'd have to have enough data\n\n1:54:17.220 --> 1:54:20.180\n to essentially say, and this goes back to how do we,\n\n1:54:20.180 --> 1:54:22.000\n this goes back to the case of how do we decide\n\n1:54:22.000 --> 1:54:25.380\n whether the AI is good enough to do a particular task\n\n1:54:25.380 --> 1:54:27.280\n and regardless of whether or not\n\n1:54:27.280 --> 1:54:28.620\n it produces an explanation.\n\n1:54:30.980 --> 1:54:34.940\n And what standard do we hold for that?\n\n1:54:34.940 --> 1:54:39.940\n So if you look more broadly, for example,\n\n1:54:42.860 --> 1:54:45.940\n as my father, as a medical case,\n\n1:54:48.180 --> 1:54:50.140\n the medical system ultimately helped him a lot\n\n1:54:50.140 --> 1:54:52.500\n throughout his life, without it,\n\n1:54:52.500 --> 1:54:54.680\n he probably would have died much sooner.\n\n1:54:55.640 --> 1:54:58.900\n So overall, it sort of worked for him\n\n1:54:58.900 --> 1:55:00.760\n in sort of a net, net kind of way.\n\n1:55:02.280 --> 1:55:04.820\n Actually, I don't know that that's fair.\n\n1:55:04.820 --> 1:55:07.660\n But maybe not in that particular case, but overall,\n\n1:55:07.660 --> 1:55:10.580\n like the medical system overall does more good than bad.\n\n1:55:10.580 --> 1:55:12.420\n Yeah, the medical system overall\n\n1:55:12.420 --> 1:55:14.300\n was doing more good than bad.\n\n1:55:14.300 --> 1:55:16.560\n Now, there's another argument that suggests\n\n1:55:16.560 --> 1:55:18.620\n that wasn't the case, but for the sake of argument,\n\n1:55:18.620 --> 1:55:21.060\n let's say like that's, let's say a net positive.\n\n1:55:21.060 --> 1:55:22.380\n And I think you have to sit there and there\n\n1:55:22.380 --> 1:55:24.820\n and take that into consideration.\n\n1:55:24.820 --> 1:55:26.660\n Now you look at a particular use case,\n\n1:55:26.660 --> 1:55:28.900\n like for example, making this decision,\n\n1:55:29.960 --> 1:55:32.300\n have you done enough studies to know\n\n1:55:33.400 --> 1:55:35.660\n how good that prediction really is?\n\n1:55:37.140 --> 1:55:40.060\n And have you done enough studies to compare it,\n\n1:55:40.060 --> 1:55:45.060\n to say, well, what if we dug in in a more direct,\n\n1:55:45.420 --> 1:55:47.980\n let's get the evidence, let's do the deductive thing\n\n1:55:47.980 --> 1:55:49.420\n and not use statistics here,\n\n1:55:49.420 --> 1:55:51.580\n how often would that have done better?\n\n1:55:52.460 --> 1:55:53.700\n So you have to do the studies\n\n1:55:53.700 --> 1:55:56.180\n to know how good the AI actually is.\n\n1:55:56.180 --> 1:55:58.500\n And it's complicated because it depends how fast\n\n1:55:58.500 --> 1:55:59.540\n you have to make the decision.\n\n1:55:59.540 --> 1:56:02.320\n So if you have to make the decision super fast,\n\n1:56:02.320 --> 1:56:03.320\n you have no choice.\n\n1:56:04.620 --> 1:56:06.740\n If you have more time, right?\n\n1:56:06.740 --> 1:56:09.040\n But if you're ready to pull the plug,\n\n1:56:09.040 --> 1:56:11.480\n and this is a lot of the argument that I had with a doctor,\n\n1:56:11.480 --> 1:56:13.220\n I said, what's he gonna do if you do it,\n\n1:56:13.220 --> 1:56:16.340\n what's gonna happen to him in that room if you do it my way?\n\n1:56:16.340 --> 1:56:18.740\n You know, well, he's gonna die anyway.\n\n1:56:18.740 --> 1:56:20.100\n So let's do it my way then.\n\n1:56:20.940 --> 1:56:22.860\n I mean, it raises questions for our society\n\n1:56:22.860 --> 1:56:26.500\n to struggle with, as the case with your father,\n\n1:56:26.500 --> 1:56:28.660\n but also when things like race and gender\n\n1:56:28.660 --> 1:56:31.740\n start coming into play when certain,\n\n1:56:31.740 --> 1:56:35.620\n when judgments are made based on things\n\n1:56:35.620 --> 1:56:39.060\n that are complicated in our society,\n\n1:56:39.060 --> 1:56:40.120\n at least in the discourse.\n\n1:56:40.120 --> 1:56:43.980\n And it starts, you know, I think I'm safe to say\n\n1:56:43.980 --> 1:56:46.300\n that most of the violent crimes committed\n\n1:56:46.300 --> 1:56:51.300\n by males, so if you discriminate based,\n\n1:56:51.300 --> 1:56:53.900\n you know, it's a male versus female saying that\n\n1:56:53.900 --> 1:56:56.380\n if it's a male, more likely to commit the crime.\n\n1:56:56.380 --> 1:57:01.100\n This is one of my very positive and optimistic views\n\n1:57:01.100 --> 1:57:05.540\n of why the study of artificial intelligence,\n\n1:57:05.540 --> 1:57:08.540\n the process of thinking and reasoning logically\n\n1:57:08.540 --> 1:57:10.500\n and statistically, and how to combine them\n\n1:57:10.500 --> 1:57:12.180\n is so important for the discourse today,\n\n1:57:12.180 --> 1:57:17.180\n because it's causing a, regardless of what state AI devices\n\n1:57:17.620 --> 1:57:22.220\n are or not, it's causing this dialogue to happen.\n\n1:57:22.220 --> 1:57:24.820\n This is one of the most important dialogues\n\n1:57:24.820 --> 1:57:28.180\n that in my view, the human species can have right now,\n\n1:57:28.180 --> 1:57:33.180\n which is how to think well, how to reason well,\n\n1:57:33.820 --> 1:57:38.820\n how to understand our own cognitive biases\n\n1:57:39.220 --> 1:57:40.980\n and what to do about them.\n\n1:57:40.980 --> 1:57:43.620\n That has got to be one of the most important things\n\n1:57:43.620 --> 1:57:47.240\n we as a species can be doing, honestly.\n\n1:57:47.240 --> 1:57:51.180\n We are, we've created an incredibly complex society.\n\n1:57:51.180 --> 1:57:56.180\n We've created amazing abilities to amplify noise faster\n\n1:57:56.300 --> 1:57:58.400\n than we can amplify signal.\n\n1:57:59.320 --> 1:58:01.220\n We are challenged.\n\n1:58:01.220 --> 1:58:03.620\n We are deeply, deeply challenged.\n\n1:58:03.620 --> 1:58:06.260\n We have, you know, big segments of the population\n\n1:58:06.260 --> 1:58:08.940\n getting hit with enormous amounts of information.\n\n1:58:08.940 --> 1:58:10.940\n Do they know how to do critical thinking?\n\n1:58:10.940 --> 1:58:14.200\n Do they know how to objectively reason?\n\n1:58:14.200 --> 1:58:16.980\n Do they understand what they are doing,\n\n1:58:16.980 --> 1:58:18.780\n nevermind what their AI is doing?\n\n1:58:19.700 --> 1:58:23.180\n This is such an important dialogue to be having.\n\n1:58:23.180 --> 1:58:26.860\n And, you know, we are fundamentally,\n\n1:58:26.860 --> 1:58:31.420\n our thinking can be and easily becomes fundamentally bias.\n\n1:58:31.420 --> 1:58:34.460\n And there are statistics and we shouldn't blind our,\n\n1:58:34.460 --> 1:58:37.300\n we shouldn't discard statistical inference,\n\n1:58:37.300 --> 1:58:39.020\n but we should understand the nature\n\n1:58:39.020 --> 1:58:40.900\n of statistical inference.\n\n1:58:40.900 --> 1:58:44.020\n As a society, as you know,\n\n1:58:44.020 --> 1:58:48.220\n we decide to reject statistical inference\n\n1:58:48.220 --> 1:58:53.220\n to favor understanding and deciding on the individual.\n\n1:58:55.600 --> 1:58:57.180\n Yes.\n\n1:58:57.180 --> 1:59:00.660\n We consciously make that choice.\n\n1:59:00.660 --> 1:59:03.240\n So even if the statistics said,\n\n1:59:04.140 --> 1:59:08.300\n even if the statistics said males are more likely to have,\n\n1:59:08.300 --> 1:59:09.660\n you know, to be violent criminals,\n\n1:59:09.660 --> 1:59:12.580\n we still take each person as an individual\n\n1:59:12.580 --> 1:59:15.940\n and we treat them based on the logic\n\n1:59:16.820 --> 1:59:20.260\n and the knowledge of that situation.\n\n1:59:20.260 --> 1:59:22.940\n We purposefully and intentionally\n\n1:59:24.100 --> 1:59:27.460\n reject the statistical inference.\n\n1:59:28.320 --> 1:59:31.260\n We do that out of respect for the individual.\n\n1:59:31.260 --> 1:59:32.100\n For the individual.\n\n1:59:32.100 --> 1:59:34.060\n Yeah, and that requires reasoning and thinking.\n\n1:59:34.060 --> 1:59:35.180\n Correct.\n\n1:59:35.180 --> 1:59:37.420\n Looking forward, what grand challenges\n\n1:59:37.420 --> 1:59:38.940\n would you like to see in the future?\n\n1:59:38.940 --> 1:59:43.380\n Because the Jeopardy challenge, you know,\n\n1:59:43.380 --> 1:59:45.140\n captivated the world.\n\n1:59:45.140 --> 1:59:48.060\n AlphaGo, AlphaZero captivated the world.\n\n1:59:48.060 --> 1:59:50.260\n Deep Blue certainly beating Kasparov.\n\n1:59:51.580 --> 1:59:55.700\n Gary's bitterness aside captivated the world.\n\n1:59:55.700 --> 1:59:57.880\n What do you think, do you have ideas\n\n1:59:57.880 --> 2:00:00.900\n for next grand challenges for future challenges of that?\n\n2:00:00.900 --> 2:00:03.280\n You know, look, I mean, I think there are lots\n\n2:00:03.280 --> 2:00:05.800\n of really great ideas for grand challenges.\n\n2:00:05.800 --> 2:00:08.500\n I'm particularly focused on one right now,\n\n2:00:08.500 --> 2:00:11.660\n which is, you know, can you demonstrate\n\n2:00:11.660 --> 2:00:14.980\n that they understand, that they could read and understand,\n\n2:00:14.980 --> 2:00:18.020\n that they can acquire these frameworks\n\n2:00:18.020 --> 2:00:19.420\n and communicate, you know,\n\n2:00:19.420 --> 2:00:21.160\n reason and communicate with humans.\n\n2:00:21.160 --> 2:00:23.380\n So it is kind of like the Turing test,\n\n2:00:23.380 --> 2:00:26.540\n but it's a little bit more demanding than the Turing test.\n\n2:00:26.540 --> 2:00:31.260\n It's not enough to convince me that you might be human\n\n2:00:31.260 --> 2:00:34.920\n because you could, you know, you can parrot a conversation.\n\n2:00:34.920 --> 2:00:38.820\n I think, you know, the standard is a little bit higher,\n\n2:00:38.820 --> 2:00:43.380\n is for example, can you, you know, the standard is higher.\n\n2:00:43.380 --> 2:00:45.540\n And I think one of the challenges\n\n2:00:45.540 --> 2:00:50.540\n of devising this grand challenge is that we're not sure\n\n2:00:51.960 --> 2:00:56.220\n what intelligence is, we're not sure how to determine\n\n2:00:56.220 --> 2:00:59.140\n whether or not two people actually understand each other\n\n2:00:59.140 --> 2:01:02.260\n and in what depth they understand it, you know,\n\n2:01:02.260 --> 2:01:04.340\n to what depth they understand each other.\n\n2:01:04.340 --> 2:01:08.380\n So the challenge becomes something along the lines of,\n\n2:01:08.380 --> 2:01:13.380\n can you satisfy me that we have a shared understanding?\n\n2:01:14.800 --> 2:01:18.380\n So if I were to probe and probe and you probe me,\n\n2:01:18.380 --> 2:01:23.380\n can machines really act like thought partners\n\n2:01:23.420 --> 2:01:27.340\n where they can satisfy me that we have a shared,\n\n2:01:27.340 --> 2:01:29.420\n our understanding is shared enough\n\n2:01:29.420 --> 2:01:33.300\n that we can collaborate and produce answers together\n\n2:01:33.300 --> 2:01:35.460\n and that, you know, they can help me explain\n\n2:01:35.460 --> 2:01:36.740\n and justify those answers.\n\n2:01:36.740 --> 2:01:38.100\n So maybe here's an idea.\n\n2:01:38.100 --> 2:01:43.100\n So we'll have AI system run for president and convince.\n\n2:01:44.500 --> 2:01:46.100\n That's too easy.\n\n2:01:46.100 --> 2:01:46.940\n I'm sorry, go ahead.\n\n2:01:46.940 --> 2:01:49.380\n Well, no, you have to convince the voters\n\n2:01:49.380 --> 2:01:51.580\n that they should vote.\n\n2:01:51.580 --> 2:01:53.780\n So like, I guess what does winning look like?\n\n2:01:53.780 --> 2:01:55.860\n Again, that's why I think this is such a challenge\n\n2:01:55.860 --> 2:01:59.980\n because we go back to the emotional persuasion.\n\n2:01:59.980 --> 2:02:04.980\n We go back to, you know, now we're checking off an aspect\n\n2:02:06.040 --> 2:02:11.040\n of human cognition that is in many ways weak or flawed,\n\n2:02:11.460 --> 2:02:13.940\n right, we're so easily manipulated.\n\n2:02:13.940 --> 2:02:18.940\n Our minds are drawn for often the wrong reasons, right?\n\n2:02:19.620 --> 2:02:21.840\n Not the reasons that ultimately matter to us,\n\n2:02:21.840 --> 2:02:23.980\n but the reasons that can easily persuade us.\n\n2:02:23.980 --> 2:02:28.420\n I think we can be persuaded to believe one thing or another\n\n2:02:28.420 --> 2:02:31.340\n for reasons that ultimately don't serve us well\n\n2:02:31.340 --> 2:02:33.160\n in the longterm.\n\n2:02:33.160 --> 2:02:38.160\n And a good benchmark should not play with those elements\n\n2:02:38.460 --> 2:02:40.780\n of emotional manipulation.\n\n2:02:40.780 --> 2:02:41.620\n I don't think so.\n\n2:02:41.620 --> 2:02:44.340\n And I think that's where we have to set the higher standard\n\n2:02:44.340 --> 2:02:47.100\n for ourselves of what, you know, what does it mean?\n\n2:02:47.100 --> 2:02:48.900\n This goes back to rationality\n\n2:02:48.900 --> 2:02:50.580\n and it goes back to objective thinking.\n\n2:02:50.580 --> 2:02:53.300\n And can you produce, can you acquire information\n\n2:02:53.300 --> 2:02:54.800\n and produce reasoned arguments\n\n2:02:54.800 --> 2:02:56.300\n and to those reasoned arguments\n\n2:02:56.300 --> 2:03:00.140\n pass a certain amount of muster and is it,\n\n2:03:00.140 --> 2:03:02.220\n and can you acquire new knowledge?\n\n2:03:02.220 --> 2:03:06.260\n You know, can you, for example, can you reason,\n\n2:03:06.260 --> 2:03:07.460\n I have acquired new knowledge,\n\n2:03:07.460 --> 2:03:11.220\n can you identify where it's consistent or contradictory\n\n2:03:11.220 --> 2:03:12.860\n with other things you've learned?\n\n2:03:12.860 --> 2:03:14.020\n And can you explain that to me\n\n2:03:14.020 --> 2:03:15.580\n and get me to understand that?\n\n2:03:15.580 --> 2:03:18.540\n So I think another way to think about it perhaps\n\n2:03:18.540 --> 2:03:23.540\n is can a machine teach you, can it help you understand\n\n2:03:31.900 --> 2:03:35.260\n something that you didn't really understand before\n\n2:03:35.260 --> 2:03:39.140\n where it's taking you, so you're not,\n\n2:03:39.140 --> 2:03:41.360\n again, it's almost like can it teach you,\n\n2:03:41.360 --> 2:03:46.360\n can it help you learn and in an arbitrary space\n\n2:03:46.360 --> 2:03:49.000\n so it can open those domain space?\n\n2:03:49.000 --> 2:03:50.440\n So can you tell the machine, and again,\n\n2:03:50.440 --> 2:03:52.840\n this borrows from some science fiction,\n\n2:03:52.840 --> 2:03:55.820\n but can you go off and learn about this topic\n\n2:03:55.820 --> 2:03:58.300\n that I'd like to understand better\n\n2:03:58.300 --> 2:04:00.820\n and then work with me to help me understand it?\n\n2:04:02.000 --> 2:04:03.600\n That's quite brilliant.\n\n2:04:03.600 --> 2:04:06.940\n What, the machine that passes that kind of test,\n\n2:04:06.940 --> 2:04:11.520\n do you think it would need to have self awareness\n\n2:04:11.520 --> 2:04:13.120\n or even consciousness?\n\n2:04:13.120 --> 2:04:16.140\n What do you think about consciousness\n\n2:04:16.140 --> 2:04:21.080\n and the importance of it maybe in relation to having a body,\n\n2:04:21.080 --> 2:04:24.720\n having a presence, an entity?\n\n2:04:24.720 --> 2:04:26.720\n Do you think that's important?\n\n2:04:26.720 --> 2:04:28.740\n You know, people used to ask me if Watson was conscious\n\n2:04:28.740 --> 2:04:32.240\n and I used to say, he's conscious of what exactly?\n\n2:04:32.240 --> 2:04:34.580\n I mean, I think, you know, maybe it depends\n\n2:04:34.580 --> 2:04:36.020\n what it is that you're conscious of.\n\n2:04:36.020 --> 2:04:39.380\n I mean, like, so, you know, did it, if you, you know,\n\n2:04:39.380 --> 2:04:42.400\n it's certainly easy for it to answer questions\n\n2:04:42.400 --> 2:04:44.760\n about, it would be trivial to program it\n\n2:04:44.760 --> 2:04:46.600\n to answer questions about whether or not\n\n2:04:46.600 --> 2:04:47.540\n it was playing Jeopardy.\n\n2:04:47.540 --> 2:04:48.980\n I mean, it could certainly answer questions\n\n2:04:48.980 --> 2:04:51.240\n that would imply that it was aware of things.\n\n2:04:51.240 --> 2:04:52.620\n Exactly, what does it mean to be aware\n\n2:04:52.620 --> 2:04:53.640\n and what does it mean to be conscious of?\n\n2:04:53.640 --> 2:04:54.480\n It's sort of interesting.\n\n2:04:54.480 --> 2:04:57.960\n I mean, I think that we differ from one another\n\n2:04:57.960 --> 2:04:59.800\n based on what we're conscious of.\n\n2:05:01.080 --> 2:05:02.660\n But wait, wait a minute, yes, for sure.\n\n2:05:02.660 --> 2:05:05.320\n There's degrees of consciousness in there, so.\n\n2:05:05.320 --> 2:05:06.920\n Well, and there's just areas.\n\n2:05:06.920 --> 2:05:10.120\n Like, it's not just degrees, what are you aware of?\n\n2:05:10.120 --> 2:05:11.120\n Like, what are you not aware of?\n\n2:05:11.120 --> 2:05:13.440\n But nevertheless, there's a very subjective element\n\n2:05:13.440 --> 2:05:14.700\n to our experience.\n\n2:05:16.000 --> 2:05:18.340\n Let me even not talk about consciousness.\n\n2:05:18.340 --> 2:05:21.560\n Let me talk about another, to me,\n\n2:05:21.560 --> 2:05:25.560\n really interesting topic of mortality, fear of mortality.\n\n2:05:25.560 --> 2:05:29.280\n Watson, as far as I could tell,\n\n2:05:29.280 --> 2:05:30.940\n did not have a fear of death.\n\n2:05:32.160 --> 2:05:33.000\n Certainly not.\n\n2:05:33.000 --> 2:05:35.860\n Most, most humans do.\n\n2:05:36.960 --> 2:05:39.040\n Wasn't conscious of death.\n\n2:05:39.040 --> 2:05:40.000\n It wasn't, yeah.\n\n2:05:40.000 --> 2:05:44.160\n So there's an element of finiteness to our existence\n\n2:05:44.160 --> 2:05:47.240\n that I think, like you mentioned, survival,\n\n2:05:47.240 --> 2:05:49.040\n that adds to the whole thing.\n\n2:05:49.040 --> 2:05:50.860\n I mean, consciousness is tied up with that,\n\n2:05:50.860 --> 2:05:52.880\n that we are a thing.\n\n2:05:52.880 --> 2:05:56.200\n It's a subjective thing that ends.\n\n2:05:56.200 --> 2:05:59.000\n And that seems to add a color and flavor\n\n2:05:59.000 --> 2:06:00.440\n to our motivations in a way\n\n2:06:00.440 --> 2:06:05.440\n that seems to be fundamentally important for intelligence,\n\n2:06:05.960 --> 2:06:07.920\n or at least the kind of human intelligence.\n\n2:06:07.920 --> 2:06:10.200\n Well, I think for generating goals, again,\n\n2:06:10.200 --> 2:06:12.280\n I think you could have,\n\n2:06:12.280 --> 2:06:14.560\n you could have an intelligence capability\n\n2:06:14.560 --> 2:06:18.560\n and a capability to learn, a capability to predict.\n\n2:06:18.560 --> 2:06:20.840\n But I think without,\n\n2:06:22.480 --> 2:06:23.960\n I mean, again, you get fear,\n\n2:06:23.960 --> 2:06:27.040\n but essentially without the goal to survive.\n\n2:06:27.040 --> 2:06:29.120\n So you think you can just encode that\n\n2:06:29.120 --> 2:06:30.600\n without having to really?\n\n2:06:30.600 --> 2:06:31.440\n I think you could encode.\n\n2:06:31.440 --> 2:06:32.880\n I mean, you could create a robot now,\n\n2:06:32.880 --> 2:06:36.060\n and you could say, you know, plug it in,\n\n2:06:36.060 --> 2:06:38.520\n and say, protect your power source, you know,\n\n2:06:38.520 --> 2:06:39.720\n and give it some capabilities,\n\n2:06:39.720 --> 2:06:40.900\n and it'll sit there and operate\n\n2:06:40.900 --> 2:06:42.760\n to try to protect its power source and survive.\n\n2:06:42.760 --> 2:06:44.240\n I mean, so I don't know\n\n2:06:44.240 --> 2:06:46.680\n that that's philosophically a hard thing to demonstrate.\n\n2:06:46.680 --> 2:06:48.960\n It sounds like a fairly easy thing to demonstrate\n\n2:06:48.960 --> 2:06:50.040\n that you can give it that goal.\n\n2:06:50.040 --> 2:06:52.360\n Will it come up with that goal by itself?\n\n2:06:52.360 --> 2:06:54.520\n I think you have to program that goal in.\n\n2:06:54.520 --> 2:06:56.660\n But there's something,\n\n2:06:56.660 --> 2:06:58.580\n because I think, as we touched on,\n\n2:06:58.580 --> 2:07:01.480\n intelligence is kind of like a social construct.\n\n2:07:01.480 --> 2:07:06.480\n The fact that a robot will be protecting its power source\n\n2:07:07.080 --> 2:07:12.080\n would add depth and grounding to its intelligence\n\n2:07:12.960 --> 2:07:15.800\n in terms of us being able to respect it.\n\n2:07:15.800 --> 2:07:18.880\n I mean, ultimately, it boils down to us acknowledging\n\n2:07:18.880 --> 2:07:20.660\n that it's intelligent.\n\n2:07:20.660 --> 2:07:23.480\n And the fact that it can die,\n\n2:07:23.480 --> 2:07:26.120\n I think, is an important part of that.\n\n2:07:26.120 --> 2:07:27.820\n The interesting thing to reflect on\n\n2:07:27.820 --> 2:07:29.520\n is how trivial that would be.\n\n2:07:29.520 --> 2:07:32.080\n And I don't think, if you knew how trivial that was,\n\n2:07:32.080 --> 2:07:35.360\n you would associate that with being intelligence.\n\n2:07:35.360 --> 2:07:37.440\n I mean, I literally put in a statement of code\n\n2:07:37.440 --> 2:07:40.400\n that says you have the following actions you can take.\n\n2:07:40.400 --> 2:07:41.600\n You give it a bunch of actions,\n\n2:07:41.600 --> 2:07:44.000\n like maybe you mount a laser gun on it,\n\n2:07:44.000 --> 2:07:48.920\n or you give it the ability to scream or screech or whatever.\n\n2:07:48.920 --> 2:07:52.680\n And you say, if you see your power source threatened,\n\n2:07:52.680 --> 2:07:53.880\n then you could program that in,\n\n2:07:53.880 --> 2:07:58.040\n and you're gonna take these actions to protect it.\n\n2:07:58.040 --> 2:08:02.200\n You know, you could train it on a bunch of things.\n\n2:08:02.200 --> 2:08:04.080\n So, and now you're gonna look at that and you say,\n\n2:08:04.080 --> 2:08:05.280\n well, you know, that's intelligence,\n\n2:08:05.280 --> 2:08:06.840\n which is protecting its power source?\n\n2:08:06.840 --> 2:08:10.220\n Maybe, but that's, again, this human bias that says,\n\n2:08:10.220 --> 2:08:14.600\n the thing I identify, my intelligence and my conscious,\n\n2:08:14.600 --> 2:08:16.720\n so fundamentally with the desire,\n\n2:08:16.720 --> 2:08:18.680\n or at least the behaviors associated\n\n2:08:18.680 --> 2:08:20.400\n with the desire to survive,\n\n2:08:21.340 --> 2:08:23.860\n that if I see another thing doing that,\n\n2:08:24.720 --> 2:08:27.280\n I'm going to assume it's intelligent.\n\n2:08:27.280 --> 2:08:29.760\n What timeline, year,\n\n2:08:29.760 --> 2:08:33.760\n will society have something that would,\n\n2:08:34.640 --> 2:08:36.000\n that you would be comfortable calling\n\n2:08:36.000 --> 2:08:38.100\n an artificial general intelligence system?\n\n2:08:39.560 --> 2:08:41.080\n Well, what's your intuition?\n\n2:08:41.080 --> 2:08:42.480\n Nobody can predict the future,\n\n2:08:42.480 --> 2:08:46.480\n certainly not the next few months or 20 years away,\n\n2:08:46.480 --> 2:08:47.600\n but what's your intuition?\n\n2:08:47.600 --> 2:08:48.900\n How far away are we?\n\n2:08:50.080 --> 2:08:50.920\n I don't know.\n\n2:08:50.920 --> 2:08:52.120\n It's hard to make these predictions.\n\n2:08:52.120 --> 2:08:54.760\n I mean, I would be guessing,\n\n2:08:54.760 --> 2:08:57.000\n and there's so many different variables,\n\n2:08:57.000 --> 2:08:59.080\n including just how much we want to invest in it\n\n2:08:59.080 --> 2:09:02.100\n and how important we think it is,\n\n2:09:03.480 --> 2:09:06.160\n what kind of investment we're willing to make in it,\n\n2:09:06.160 --> 2:09:08.440\n what kind of talent we end up bringing to the table,\n\n2:09:08.440 --> 2:09:10.160\n the incentive structure, all these things.\n\n2:09:10.160 --> 2:09:15.160\n So I think it is possible to do this sort of thing.\n\n2:09:15.220 --> 2:09:19.120\n I think it's, I think trying to sort of\n\n2:09:20.360 --> 2:09:23.040\n ignore many of the variables and things like that,\n\n2:09:23.040 --> 2:09:25.440\n is it a 10 year thing, is it a 23 year?\n\n2:09:25.440 --> 2:09:27.880\n Probably closer to a 20 year thing, I guess.\n\n2:09:27.880 --> 2:09:29.720\n But not several hundred years.\n\n2:09:29.720 --> 2:09:32.080\n No, I don't think it's several hundred years.\n\n2:09:32.080 --> 2:09:33.660\n I don't think it's several hundred years.\n\n2:09:33.660 --> 2:09:38.660\n But again, so much depends on how committed we are\n\n2:09:38.860 --> 2:09:43.120\n to investing and incentivizing this type of work.\n\n2:09:43.120 --> 2:09:45.200\n And it's sort of interesting.\n\n2:09:45.200 --> 2:09:50.200\n Like, I don't think it's obvious how incentivized we are.\n\n2:09:50.280 --> 2:09:53.160\n I think from a task perspective,\n\n2:09:53.160 --> 2:09:57.880\n if we see business opportunities to take this technique\n\n2:09:57.880 --> 2:09:59.120\n or that technique to solve that problem,\n\n2:09:59.120 --> 2:10:03.240\n I think that's the main driver for many of these things.\n\n2:10:03.240 --> 2:10:05.600\n From a general intelligence,\n\n2:10:05.600 --> 2:10:06.920\n it's kind of an interesting question.\n\n2:10:06.920 --> 2:10:09.360\n Are we really motivated to do that?\n\n2:10:09.360 --> 2:10:12.520\n And like, we just struggled ourselves right now\n\n2:10:12.520 --> 2:10:14.760\n to even define what it is.\n\n2:10:14.760 --> 2:10:16.160\n So it's hard to incentivize\n\n2:10:16.160 --> 2:10:17.260\n when we don't even know what it is\n\n2:10:17.260 --> 2:10:18.800\n we're incentivized to create.\n\n2:10:18.800 --> 2:10:23.280\n And if you said mimic a human intelligence,\n\n2:10:23.280 --> 2:10:25.520\n I just think there are so many challenges\n\n2:10:25.520 --> 2:10:27.720\n with the significance and meaning of that.\n\n2:10:27.720 --> 2:10:29.640\n That there's not a clear directive.\n\n2:10:29.640 --> 2:10:32.280\n There's no clear directive to do precisely that thing.\n\n2:10:32.280 --> 2:10:36.480\n So assistance in a larger and larger number of tasks.\n\n2:10:36.480 --> 2:10:38.080\n So being able to,\n\n2:10:38.080 --> 2:10:41.080\n a system that's particularly able to operate my microwave\n\n2:10:41.080 --> 2:10:42.600\n and making a grilled cheese sandwich.\n\n2:10:42.600 --> 2:10:44.960\n I don't even know how to make one of those.\n\n2:10:44.960 --> 2:10:48.020\n And then the same system will be doing the vacuum cleaning.\n\n2:10:48.020 --> 2:10:51.640\n And then the same system would be teaching\n\n2:10:53.540 --> 2:10:56.280\n my kids that I don't have math.\n\n2:10:56.280 --> 2:11:00.720\n I think that when you get into a general intelligence\n\n2:11:00.720 --> 2:11:04.240\n for learning physical tasks,\n\n2:11:04.240 --> 2:11:06.000\n and again, I wanna go back to your body question\n\n2:11:06.000 --> 2:11:07.260\n because I think your body question was interesting,\n\n2:11:07.260 --> 2:11:11.080\n but you wanna go back to learning the abilities\n\n2:11:11.080 --> 2:11:11.920\n to physical tasks.\n\n2:11:11.920 --> 2:11:14.420\n You might have, we might get,\n\n2:11:14.420 --> 2:11:16.020\n I imagine in that timeframe,\n\n2:11:16.020 --> 2:11:18.440\n we will get better and better at learning these kinds\n\n2:11:18.440 --> 2:11:20.320\n of tasks, whether it's mowing your lawn\n\n2:11:20.320 --> 2:11:22.720\n or driving a car or whatever it is.\n\n2:11:22.720 --> 2:11:24.420\n I think we will get better and better at that\n\n2:11:24.420 --> 2:11:25.840\n where it's learning how to make predictions\n\n2:11:25.840 --> 2:11:27.000\n over large bodies of data.\n\n2:11:27.000 --> 2:11:28.280\n I think we're gonna continue to get better\n\n2:11:28.280 --> 2:11:29.280\n and better at that.\n\n2:11:30.520 --> 2:11:33.520\n And machines will outpace humans\n\n2:11:33.520 --> 2:11:35.560\n in a variety of those things.\n\n2:11:35.560 --> 2:11:40.560\n The underlying mechanisms for doing that may be the same,\n\n2:11:40.760 --> 2:11:43.680\n meaning that maybe these are deep nets,\n\n2:11:43.680 --> 2:11:46.280\n there's infrastructure to train them,\n\n2:11:46.280 --> 2:11:49.840\n reusable components to get them to do different classes\n\n2:11:49.840 --> 2:11:51.920\n of tasks, and we get better and better\n\n2:11:51.920 --> 2:11:53.980\n at building these kinds of machines.\n\n2:11:53.980 --> 2:11:56.600\n You could argue that the general learning infrastructure\n\n2:11:56.600 --> 2:12:01.040\n in there is a form of a general type of intelligence.\n\n2:12:01.040 --> 2:12:04.720\n I think what starts getting harder is this notion of,\n\n2:12:06.400 --> 2:12:09.120\n can we effectively communicate and understand\n\n2:12:09.120 --> 2:12:10.840\n and build that shared understanding?\n\n2:12:10.840 --> 2:12:13.200\n Because of the layers of interpretation that are required\n\n2:12:13.200 --> 2:12:16.320\n to do that, and the need for the machine to be engaged\n\n2:12:16.320 --> 2:12:20.320\n with humans at that level in a continuous basis.\n\n2:12:20.320 --> 2:12:23.480\n So how do you get the machine in the game?\n\n2:12:23.480 --> 2:12:26.600\n How do you get the machine in the intellectual game?\n\n2:12:26.600 --> 2:12:29.120\n Yeah, and to solve AGI,\n\n2:12:29.120 --> 2:12:31.000\n you probably have to solve that problem.\n\n2:12:31.000 --> 2:12:31.920\n You have to get the machine,\n\n2:12:31.920 --> 2:12:33.800\n so it's a little bit of a bootstrapping thing.\n\n2:12:33.800 --> 2:12:38.800\n Can we get the machine engaged in the intellectual game,\n\n2:12:39.160 --> 2:12:42.360\n but in the intellectual dialogue with the humans?\n\n2:12:42.360 --> 2:12:44.840\n Are the humans sufficiently in intellectual dialogue\n\n2:12:44.840 --> 2:12:49.640\n with each other to generate enough data in this context?\n\n2:12:49.640 --> 2:12:51.020\n And how do you bootstrap that?\n\n2:12:51.020 --> 2:12:54.080\n Because every one of those conversations,\n\n2:12:54.080 --> 2:12:55.760\n every one of those conversations,\n\n2:12:55.760 --> 2:12:58.040\n those intelligent interactions,\n\n2:12:58.040 --> 2:12:59.680\n require so much prior knowledge\n\n2:12:59.680 --> 2:13:01.640\n that it's a challenge to bootstrap it.\n\n2:13:01.640 --> 2:13:05.840\n So the question is, and how committed?\n\n2:13:05.840 --> 2:13:08.800\n So I think that's possible, but when I go back to,\n\n2:13:08.800 --> 2:13:10.880\n are we incentivized to do that?\n\n2:13:10.880 --> 2:13:13.160\n I know we're incentivized to do the former.\n\n2:13:13.160 --> 2:13:15.900\n Are we incentivized to do the latter significantly enough?\n\n2:13:15.900 --> 2:13:18.460\n Do people understand what the latter really is well enough?\n\n2:13:18.460 --> 2:13:20.880\n Part of the elemental cognition mission\n\n2:13:20.880 --> 2:13:23.520\n is to try to articulate that better and better\n\n2:13:23.520 --> 2:13:24.560\n through demonstrations\n\n2:13:24.560 --> 2:13:26.960\n and through trying to craft these grand challenges\n\n2:13:26.960 --> 2:13:28.120\n and get people to say, look,\n\n2:13:28.120 --> 2:13:30.440\n this is a class of intelligence.\n\n2:13:30.440 --> 2:13:31.840\n This is a class of AI.\n\n2:13:31.840 --> 2:13:33.420\n Do we want this?\n\n2:13:33.420 --> 2:13:35.800\n What is the potential of this?\n\n2:13:35.800 --> 2:13:37.840\n What's the business potential?\n\n2:13:37.840 --> 2:13:40.120\n What's the societal potential to that?\n\n2:13:40.120 --> 2:13:45.080\n And to build up that incentive system around that.\n\n2:13:45.080 --> 2:13:46.820\n Yeah, I think if people don't understand yet,\n\n2:13:46.820 --> 2:13:47.660\n I think they will.\n\n2:13:47.660 --> 2:13:49.620\n I think there's a huge business potential here.\n\n2:13:49.620 --> 2:13:52.020\n So it's exciting that you're working on it.\n\n2:13:54.000 --> 2:13:54.960\n We kind of skipped over,\n\n2:13:54.960 --> 2:13:59.560\n but I'm a huge fan of physical presence of things.\n\n2:13:59.560 --> 2:14:03.320\n Do you think Watson had a body?\n\n2:14:03.320 --> 2:14:08.320\n Do you think having a body adds to the interactive element\n\n2:14:08.320 --> 2:14:11.640\n between the AI system and a human,\n\n2:14:11.640 --> 2:14:13.460\n or just in general to intelligence?\n\n2:14:14.600 --> 2:14:19.600\n So I think going back to that shared understanding bit,\n\n2:14:19.780 --> 2:14:21.640\n humans are very connected to their bodies.\n\n2:14:21.640 --> 2:14:26.320\n I mean, one of the challenges in getting an AI\n\n2:14:26.320 --> 2:14:29.120\n to kind of be a compatible human intelligence\n\n2:14:29.120 --> 2:14:33.660\n is that our physical bodies are generating a lot of features\n\n2:14:33.660 --> 2:14:37.720\n that make up the input.\n\n2:14:37.720 --> 2:14:40.800\n So in other words, our bodies are the tool\n\n2:14:40.800 --> 2:14:42.720\n we use to affect output,\n\n2:14:42.720 --> 2:14:46.360\n but they also generate a lot of input for our brains.\n\n2:14:46.360 --> 2:14:49.800\n So we generate emotion, we generate all these feelings,\n\n2:14:49.800 --> 2:14:52.720\n we generate all these signals that machines don't have.\n\n2:14:52.720 --> 2:14:54.960\n So machines don't have this as the input data\n\n2:14:56.800 --> 2:14:58.720\n and they don't have the feedback that says,\n\n2:14:58.720 --> 2:15:02.940\n I've gotten this emotion or I've gotten this idea,\n\n2:15:02.940 --> 2:15:04.320\n I now want to process it,\n\n2:15:04.320 --> 2:15:08.960\n and then it then affects me as a physical being,\n\n2:15:08.960 --> 2:15:12.200\n and I can play that out.\n\n2:15:12.200 --> 2:15:14.120\n In other words, I could realize the implications of that,\n\n2:15:14.120 --> 2:15:17.520\n implications again, on my mind body complex,\n\n2:15:17.520 --> 2:15:19.960\n I then process that, and the implications again,\n\n2:15:19.960 --> 2:15:23.620\n our internal features are generated, I learn from them,\n\n2:15:23.620 --> 2:15:26.760\n they have an effect on my mind body complex.\n\n2:15:26.760 --> 2:15:28.900\n So it's interesting when we think,\n\n2:15:28.900 --> 2:15:30.440\n do we want a human intelligence?\n\n2:15:30.440 --> 2:15:33.200\n Well, if we want a human compatible intelligence,\n\n2:15:33.200 --> 2:15:34.320\n probably the best thing to do\n\n2:15:34.320 --> 2:15:36.840\n is to embed it in a human body.\n\n2:15:36.840 --> 2:15:39.960\n Just to clarify, and both concepts are beautiful,\n\n2:15:39.960 --> 2:15:44.960\n is humanoid robots, so robots that look like humans is one,\n\n2:15:45.440 --> 2:15:50.440\n or did you mean actually sort of what Elon Musk\n\n2:15:50.720 --> 2:15:52.940\n was working with Neuralink,\n\n2:15:52.940 --> 2:15:55.840\n really embedding intelligence systems\n\n2:15:55.840 --> 2:15:59.800\n to ride along human bodies?\n\n2:15:59.800 --> 2:16:01.840\n No, I mean riding along is different.\n\n2:16:01.840 --> 2:16:05.840\n I meant like if you want to create an intelligence\n\n2:16:05.840 --> 2:16:08.720\n that is human compatible,\n\n2:16:08.720 --> 2:16:10.840\n meaning that it can learn and develop\n\n2:16:10.840 --> 2:16:13.040\n a shared understanding of the world around it,\n\n2:16:13.040 --> 2:16:15.120\n you have to give it a lot of the same substrate.\n\n2:16:15.120 --> 2:16:18.200\n Part of that substrate is the idea\n\n2:16:18.200 --> 2:16:21.120\n that it generates these kinds of internal features,\n\n2:16:21.120 --> 2:16:24.020\n like sort of emotional stuff, it has similar senses,\n\n2:16:24.020 --> 2:16:25.640\n it has to do a lot of the same things\n\n2:16:25.640 --> 2:16:28.200\n with those same senses, right?\n\n2:16:28.200 --> 2:16:29.760\n So I think if you want that,\n\n2:16:29.760 --> 2:16:32.520\n again, I don't know that you want that.\n\n2:16:32.520 --> 2:16:34.280\n That's not my specific goal,\n\n2:16:34.280 --> 2:16:35.860\n I think that's a fascinating scientific goal,\n\n2:16:35.860 --> 2:16:37.860\n I think it has all kinds of other implications.\n\n2:16:37.860 --> 2:16:39.480\n That's sort of not the goal.\n\n2:16:39.480 --> 2:16:41.600\n I want to create, I think of it\n\n2:16:41.600 --> 2:16:44.120\n as I create intellectual thought partners for humans,\n\n2:16:44.120 --> 2:16:46.300\n so that kind of intelligence.\n\n2:16:47.640 --> 2:16:48.560\n I know there are other companies\n\n2:16:48.560 --> 2:16:50.160\n that are creating physical thought partners,\n\n2:16:50.160 --> 2:16:52.460\n physical partners for humans,\n\n2:16:52.460 --> 2:16:56.420\n but that's kind of not where I'm at.\n\n2:16:56.420 --> 2:17:00.760\n But the important point is that a big part\n\n2:17:00.760 --> 2:17:05.760\n of what we process is that physical experience\n\n2:17:06.240 --> 2:17:08.080\n of the world around us.\n\n2:17:08.080 --> 2:17:10.520\n On the point of thought partners,\n\n2:17:10.520 --> 2:17:13.920\n what role does an emotional connection,\n\n2:17:13.920 --> 2:17:17.820\n or forgive me, love, have to play\n\n2:17:17.820 --> 2:17:19.840\n in that thought partnership?\n\n2:17:19.840 --> 2:17:22.000\n Is that something you're interested in,\n\n2:17:22.000 --> 2:17:26.700\n put another way, sort of having a deep connection,\n\n2:17:26.700 --> 2:17:29.300\n beyond intellectual?\n\n2:17:29.300 --> 2:17:30.200\n With the AI?\n\n2:17:30.200 --> 2:17:32.740\n Yeah, with the AI, between human and AI.\n\n2:17:32.740 --> 2:17:34.440\n Is that something that gets in the way\n\n2:17:34.440 --> 2:17:37.560\n of the rational discourse?\n\n2:17:37.560 --> 2:17:39.240\n Is that something that's useful?\n\n2:17:39.240 --> 2:17:41.920\n I worry about biases, obviously.\n\n2:17:41.920 --> 2:17:44.280\n So in other words, if you develop an emotional relationship\n\n2:17:44.280 --> 2:17:46.640\n with a machine, all of a sudden you start,\n\n2:17:46.640 --> 2:17:48.320\n are more likely to believe what it's saying,\n\n2:17:48.320 --> 2:17:50.240\n even if it doesn't make any sense.\n\n2:17:50.240 --> 2:17:53.640\n So I worry about that.\n\n2:17:53.640 --> 2:17:54.600\n But at the same time,\n\n2:17:54.600 --> 2:17:56.560\n I think the opportunity to use machines\n\n2:17:56.560 --> 2:17:59.440\n to provide human companionship is actually not crazy.\n\n2:17:59.440 --> 2:18:04.060\n And intellectual and social companionship\n\n2:18:04.060 --> 2:18:05.240\n is not a crazy idea.\n\n2:18:06.320 --> 2:18:09.960\n Do you have concerns, as a few people do,\n\n2:18:09.960 --> 2:18:11.760\n Elon Musk, Sam Harris,\n\n2:18:11.760 --> 2:18:14.600\n about long term existential threats of AI,\n\n2:18:15.460 --> 2:18:18.760\n and perhaps short term threats of AI?\n\n2:18:18.760 --> 2:18:19.800\n We talked about bias,\n\n2:18:19.800 --> 2:18:21.120\n we talked about different misuses,\n\n2:18:21.120 --> 2:18:25.680\n but do you have concerns about thought partners,\n\n2:18:25.680 --> 2:18:28.600\n systems that are able to help us make decisions\n\n2:18:28.600 --> 2:18:29.780\n together as humans,\n\n2:18:29.780 --> 2:18:31.960\n somehow having a significant negative impact\n\n2:18:31.960 --> 2:18:33.760\n on society in the long term?\n\n2:18:33.760 --> 2:18:35.340\n I think there are things to worry about.\n\n2:18:35.340 --> 2:18:40.340\n I think giving machines too much leverage is a problem.\n\n2:18:41.500 --> 2:18:43.240\n And what I mean by leverage is,\n\n2:18:44.320 --> 2:18:47.040\n is too much control over things that can hurt us,\n\n2:18:47.040 --> 2:18:50.240\n whether it's socially, psychologically, intellectually,\n\n2:18:50.240 --> 2:18:51.640\n or physically.\n\n2:18:51.640 --> 2:18:53.480\n And if you give the machines too much control,\n\n2:18:53.480 --> 2:18:54.760\n I think that's a concern.\n\n2:18:54.760 --> 2:18:56.320\n You forget about the AI,\n\n2:18:56.320 --> 2:18:58.640\n just once you give them too much control,\n\n2:18:58.640 --> 2:19:02.660\n human bad actors can hack them and produce havoc.\n\n2:19:04.760 --> 2:19:07.000\n So that's a problem.\n\n2:19:07.000 --> 2:19:10.040\n And you'd imagine hackers taking over\n\n2:19:10.040 --> 2:19:11.080\n the driverless car network\n\n2:19:11.080 --> 2:19:15.220\n and creating all kinds of havoc.\n\n2:19:15.220 --> 2:19:19.760\n But you could also imagine given the ease\n\n2:19:19.760 --> 2:19:22.800\n at which humans could be persuaded one way or the other,\n\n2:19:22.800 --> 2:19:25.840\n and now we have algorithms that can easily take control\n\n2:19:25.840 --> 2:19:29.640\n over that and amplify noise\n\n2:19:29.640 --> 2:19:32.000\n and move people one direction or another.\n\n2:19:32.000 --> 2:19:34.140\n I mean, humans do that to other humans all the time.\n\n2:19:34.140 --> 2:19:35.420\n And we have marketing campaigns,\n\n2:19:35.420 --> 2:19:38.220\n we have political campaigns that take advantage\n\n2:19:38.220 --> 2:19:41.960\n of our emotions or our fears.\n\n2:19:41.960 --> 2:19:44.160\n And this is done all the time.\n\n2:19:44.160 --> 2:19:47.760\n But with machines, machines are like giant megaphones.\n\n2:19:47.760 --> 2:19:50.680\n We can amplify this in orders of magnitude\n\n2:19:50.680 --> 2:19:54.840\n and fine tune its control so we can tailor the message.\n\n2:19:54.840 --> 2:19:58.640\n We can now very rapidly and efficiently tailor the message\n\n2:19:58.640 --> 2:20:03.640\n to the audience, taking advantage of their biases\n\n2:20:04.200 --> 2:20:06.640\n and amplifying them and using them to persuade them\n\n2:20:06.640 --> 2:20:10.740\n in one direction or another in ways that are not fair,\n\n2:20:10.740 --> 2:20:13.440\n not logical, not objective, not meaningful.\n\n2:20:13.440 --> 2:20:17.000\n And humans, machines empower that.\n\n2:20:17.000 --> 2:20:18.920\n So that's what I mean by leverage.\n\n2:20:18.920 --> 2:20:22.840\n Like it's not new, but wow, it's powerful\n\n2:20:22.840 --> 2:20:24.400\n because machines can do it more effectively,\n\n2:20:24.400 --> 2:20:27.720\n more quickly and we see that already going on\n\n2:20:27.720 --> 2:20:30.480\n in social media and other places.\n\n2:20:31.720 --> 2:20:33.100\n That's scary.\n\n2:20:33.100 --> 2:20:38.100\n And that's why I go back to saying one of the most important\n\n2:20:38.100 --> 2:20:42.860\n That's why I go back to saying one of the most important\n\n2:20:42.860 --> 2:20:45.420\n public dialogues we could be having\n\n2:20:45.420 --> 2:20:47.980\n is about the nature of intelligence\n\n2:20:47.980 --> 2:20:52.140\n and the nature of inference and logic\n\n2:20:52.140 --> 2:20:56.100\n and reason and rationality and us understanding\n\n2:20:56.100 --> 2:20:59.820\n our own biases, us understanding our own cognitive biases\n\n2:20:59.820 --> 2:21:03.140\n and how they work and then how machines work\n\n2:21:03.140 --> 2:21:06.020\n and how do we use them to compliment basically\n\n2:21:06.020 --> 2:21:09.660\n so that in the end we have a stronger overall system.\n\n2:21:09.660 --> 2:21:11.400\n That's just incredibly important.\n\n2:21:13.020 --> 2:21:15.780\n I don't think most people understand that.\n\n2:21:15.780 --> 2:21:19.780\n So like telling your kids or telling your students,\n\n2:21:20.620 --> 2:21:22.540\n this goes back to the cognition.\n\n2:21:22.540 --> 2:21:24.300\n Here's how your brain works.\n\n2:21:24.300 --> 2:21:28.060\n Here's how easy it is to trick your brain, right?\n\n2:21:28.060 --> 2:21:29.460\n There are fundamental cognitive,\n\n2:21:29.460 --> 2:21:34.060\n you should appreciate the different types of thinking\n\n2:21:34.060 --> 2:21:36.820\n and how they work and what you're prone to\n\n2:21:36.820 --> 2:21:40.580\n and what do you prefer?\n\n2:21:40.580 --> 2:21:42.340\n And under what conditions does this make sense\n\n2:21:42.340 --> 2:21:43.620\n versus does that make sense?\n\n2:21:43.620 --> 2:21:46.340\n And then say, here's what AI can do.\n\n2:21:46.340 --> 2:21:48.620\n Here's how it can make this worse\n\n2:21:48.620 --> 2:21:51.020\n and here's how it can make this better.\n\n2:21:51.020 --> 2:21:52.740\n And then that's where the AI has a role\n\n2:21:52.740 --> 2:21:55.620\n is to reveal that trade off.\n\n2:21:56.620 --> 2:22:00.700\n So if you imagine a system that is able to\n\n2:22:00.700 --> 2:22:05.700\n beyond any definition of the Turing test to the benchmark,\n\n2:22:06.960 --> 2:22:10.240\n really an AGI system as a thought partner\n\n2:22:10.240 --> 2:22:12.980\n that you one day will create,\n\n2:22:14.320 --> 2:22:19.320\n what question, what topic of discussion,\n\n2:22:19.520 --> 2:22:23.960\n if you get to pick one, would you have with that system?\n\n2:22:23.960 --> 2:22:28.240\n What would you ask and you get to find out\n\n2:22:28.240 --> 2:22:30.840\n the truth together?\n\n2:22:33.440 --> 2:22:36.200\n So you threw me a little bit with finding the truth\n\n2:22:36.200 --> 2:22:41.040\n at the end, but because the truth is a whole nother topic.\n\n2:22:41.040 --> 2:22:43.600\n But I think the beauty of it,\n\n2:22:43.600 --> 2:22:46.060\n I think what excites me is the beauty of it is\n\n2:22:46.060 --> 2:22:48.700\n if I really have that system, I don't have to pick.\n\n2:22:48.700 --> 2:22:51.600\n So in other words, I can go to and say,\n\n2:22:51.600 --> 2:22:54.060\n this is what I care about today.\n\n2:22:54.060 --> 2:22:57.180\n And that's what we mean by like this general capability,\n\n2:22:57.180 --> 2:23:00.560\n go out, read this stuff in the next three milliseconds.\n\n2:23:00.560 --> 2:23:02.800\n And I wanna talk to you about it.\n\n2:23:02.800 --> 2:23:05.000\n I wanna draw analogies, I wanna understand\n\n2:23:05.000 --> 2:23:08.080\n how this affects this decision or that decision.\n\n2:23:08.080 --> 2:23:09.200\n What if this were true?\n\n2:23:09.200 --> 2:23:10.720\n What if that were true?\n\n2:23:10.720 --> 2:23:13.200\n What knowledge should I be aware of\n\n2:23:13.200 --> 2:23:16.000\n that could impact my decision?\n\n2:23:16.000 --> 2:23:18.960\n Here's what I'm thinking is the main implication.\n\n2:23:18.960 --> 2:23:21.120\n Can you prove that out?\n\n2:23:21.120 --> 2:23:23.280\n Can you give me the evidence that supports that?\n\n2:23:23.280 --> 2:23:25.600\n Can you give me evidence that supports this other thing?\n\n2:23:25.600 --> 2:23:27.400\n Boy, would that be incredible?\n\n2:23:27.400 --> 2:23:28.560\n Would that be just incredible?\n\n2:23:28.560 --> 2:23:30.400\n Just a long discourse.\n\n2:23:30.400 --> 2:23:33.340\n Just to be part of whether it's a medical diagnosis\n\n2:23:33.340 --> 2:23:35.880\n or whether it's the various treatment options\n\n2:23:35.880 --> 2:23:38.400\n or whether it's a legal case\n\n2:23:38.400 --> 2:23:40.040\n or whether it's a social problem\n\n2:23:40.040 --> 2:23:41.040\n that people are discussing,\n\n2:23:41.040 --> 2:23:43.740\n like be part of the dialogue,\n\n2:23:43.740 --> 2:23:48.740\n one that holds itself and us accountable\n\n2:23:49.520 --> 2:23:51.560\n to reasons and objective dialogue.\n\n2:23:52.760 --> 2:23:54.520\n I get goosebumps talking about it, right?\n\n2:23:54.520 --> 2:23:56.180\n It's like, this is what I want.\n\n2:23:57.440 --> 2:24:01.000\n So when you create it, please come back on the podcast\n\n2:24:01.000 --> 2:24:03.480\n and we can have a discussion together\n\n2:24:03.480 --> 2:24:04.800\n and make it even longer.\n\n2:24:04.800 --> 2:24:07.320\n This is a record for the longest conversation\n\n2:24:07.320 --> 2:24:08.160\n in the world.\n\n2:24:08.160 --> 2:24:09.400\n It was an honor, it was a pleasure, David.\n\n2:24:09.400 --> 2:24:10.240\n Thank you so much for talking to me.\n\n2:24:10.240 --> 2:24:30.240\n Thanks so much, a lot of fun.\n\n"
}
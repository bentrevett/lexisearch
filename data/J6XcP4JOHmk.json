{
  "title": "Jeremy Howard: fast.ai Deep Learning Courses and Research | Lex Fridman Podcast #35",
  "id": "J6XcP4JOHmk",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:03.120\n The following is a conversation with Jeremy Howard.\n\n00:03.120 --> 00:07.040\n He's the founder of FastAI, a research institute dedicated\n\n00:07.040 --> 00:09.720\n to making deep learning more accessible.\n\n00:09.720 --> 00:12.560\n He's also a distinguished research scientist\n\n00:12.560 --> 00:14.600\n at the University of San Francisco,\n\n00:14.600 --> 00:16.640\n a former president of Kaggle,\n\n00:16.640 --> 00:18.760\n as well as a top ranking competitor there.\n\n00:18.760 --> 00:21.680\n And in general, he's a successful entrepreneur,\n\n00:21.680 --> 00:25.200\n educator, researcher, and an inspiring personality\n\n00:25.200 --> 00:27.000\n in the AI community.\n\n00:27.000 --> 00:30.200\n When someone asks me, how do I get started with deep learning?\n\n00:30.200 --> 00:33.320\n FastAI is one of the top places that point them to.\n\n00:33.320 --> 00:35.480\n It's free, it's easy to get started,\n\n00:35.480 --> 00:37.600\n it's insightful and accessible,\n\n00:37.600 --> 00:40.960\n and if I may say so, it has very little BS\n\n00:40.960 --> 00:44.120\n that can sometimes dilute the value of educational content\n\n00:44.120 --> 00:46.720\n on popular topics like deep learning.\n\n00:46.720 --> 00:50.280\n FastAI has a focus on practical application of deep learning\n\n00:50.280 --> 00:52.800\n and hands on exploration of the cutting edge\n\n00:52.800 --> 00:56.000\n that is incredibly both accessible to beginners\n\n00:56.000 --> 00:57.960\n and useful to experts.\n\n00:57.960 --> 01:01.320\n This is the Artificial Intelligence Podcast.\n\n01:01.320 --> 01:03.800\n If you enjoy it, subscribe on YouTube,\n\n01:03.800 --> 01:05.480\n give it five stars on iTunes,\n\n01:05.480 --> 01:06.920\n support it on Patreon,\n\n01:06.920 --> 01:09.040\n or simply connect with me on Twitter\n\n01:09.040 --> 01:13.280\n at Lex Friedman, spelled F R I D M A N.\n\n01:13.280 --> 01:17.560\n And now, here's my conversation with Jeremy Howard.\n\n01:18.520 --> 01:20.680\n What's the first program you ever written?\n\n01:21.680 --> 01:24.760\n First program I wrote that I remember\n\n01:24.760 --> 01:26.680\n would be at high school.\n\n01:29.200 --> 01:31.200\n I did an assignment where I decided\n\n01:31.200 --> 01:36.200\n to try to find out if there were some better musical scales\n\n01:36.200 --> 01:40.600\n than the normal 12 tone, 12 interval scale.\n\n01:40.600 --> 01:43.640\n So I wrote a program on my Commodore 64 in basic\n\n01:43.640 --> 01:46.000\n that searched through other scale sizes\n\n01:46.000 --> 01:47.240\n to see if it could find one\n\n01:47.240 --> 01:51.880\n where there were more accurate harmonies.\n\n01:51.880 --> 01:53.520\n Like mid tone?\n\n01:53.520 --> 01:56.520\n Like you want an actual exactly three to two ratio\n\n01:56.520 --> 01:59.400\n or else with a 12 interval scale,\n\n01:59.400 --> 02:01.480\n it's not exactly three to two, for example.\n\n02:01.480 --> 02:05.040\n So that's well tempered as they say in there.\n\n02:05.040 --> 02:07.680\n And basic on a Commodore 64.\n\n02:07.680 --> 02:09.440\n Where was the interest in music from?\n\n02:09.440 --> 02:10.440\n Or is it just technical?\n\n02:10.440 --> 02:12.000\n I did music all my life.\n\n02:12.000 --> 02:15.360\n So I played saxophone and clarinet and piano\n\n02:15.360 --> 02:18.120\n and guitar and drums and whatever.\n\n02:18.120 --> 02:22.120\n How does that thread go through your life?\n\n02:22.120 --> 02:24.200\n Where's music today?\n\n02:24.200 --> 02:26.160\n It's not where I wish it was.\n\n02:28.360 --> 02:30.200\n For various reasons, couldn't really keep it going,\n\n02:30.200 --> 02:31.640\n particularly because I had a lot of problems\n\n02:31.640 --> 02:33.520\n with RSI with my fingers.\n\n02:33.520 --> 02:35.560\n And so I had to kind of like cut back anything\n\n02:35.560 --> 02:38.360\n that used hands and fingers.\n\n02:39.400 --> 02:43.920\n I hope one day I'll be able to get back to it health wise.\n\n02:43.920 --> 02:46.400\n So there's a love for music underlying it all.\n\n02:46.400 --> 02:47.840\n Yeah.\n\n02:47.840 --> 02:49.520\n What's your favorite instrument?\n\n02:49.520 --> 02:50.360\n Saxophone.\n\n02:50.360 --> 02:51.200\n Sax.\n\n02:51.200 --> 02:52.880\n Or baritone saxophone.\n\n02:52.880 --> 02:55.640\n Well, probably bass saxophone, but they're awkward.\n\n02:57.480 --> 03:00.040\n Well, I always love it when music\n\n03:00.040 --> 03:01.720\n is coupled with programming.\n\n03:01.720 --> 03:04.680\n There's something about a brain that utilizes those\n\n03:04.680 --> 03:07.560\n that emerges with creative ideas.\n\n03:07.560 --> 03:11.240\n So you've used and studied quite a few programming languages.\n\n03:11.240 --> 03:15.160\n Can you give an overview of what you've used?\n\n03:15.160 --> 03:17.880\n What are the pros and cons of each?\n\n03:17.880 --> 03:20.080\n Well, my favorite programming environment,\n\n03:20.080 --> 03:24.560\n well, most certainly was Microsoft Access\n\n03:24.560 --> 03:26.440\n back in like the earliest days.\n\n03:26.440 --> 03:28.880\n So that was Visual Basic for applications,\n\n03:28.880 --> 03:30.680\n which is not a good programming language,\n\n03:30.680 --> 03:33.040\n but the programming environment was fantastic.\n\n03:33.040 --> 03:38.000\n It's like the ability to create, you know,\n\n03:38.000 --> 03:41.200\n user interfaces and tie data and actions to them\n\n03:41.200 --> 03:43.680\n and create reports and all that\n\n03:43.680 --> 03:46.760\n as I've never seen anything as good.\n\n03:46.760 --> 03:48.560\n There's things nowadays like Airtable,\n\n03:48.560 --> 03:53.560\n which are like small subsets of that,\n\n03:54.240 --> 03:56.160\n which people love for good reason,\n\n03:56.160 --> 04:00.080\n but unfortunately, nobody's ever achieved\n\n04:00.080 --> 04:01.080\n anything like that.\n\n04:01.080 --> 04:01.920\n What is that?\n\n04:01.920 --> 04:03.280\n If you could pause on that for a second.\n\n04:03.280 --> 04:04.120\n Oh, Access?\n\n04:04.120 --> 04:06.280\n Is it a database?\n\n04:06.280 --> 04:09.600\n It was a database program that Microsoft produced,\n\n04:09.600 --> 04:13.400\n part of Office, and they kind of withered, you know,\n\n04:13.400 --> 04:16.240\n but basically it lets you in a totally graphical way\n\n04:16.240 --> 04:18.440\n create tables and relationships and queries\n\n04:18.440 --> 04:21.800\n and tie them to forms and set up, you know,\n\n04:21.800 --> 04:24.680\n event handlers and calculations.\n\n04:24.680 --> 04:28.120\n And it was a very complete powerful system\n\n04:28.120 --> 04:31.480\n designed for not massive scalable things,\n\n04:31.480 --> 04:36.360\n but for like useful little applications that I loved.\n\n04:36.360 --> 04:40.240\n So what's the connection between Excel and Access?\n\n04:40.240 --> 04:42.120\n So very close.\n\n04:42.120 --> 04:47.120\n So Access kind of was the relational database equivalent,\n\n04:47.120 --> 04:47.960\n if you like.\n\n04:47.960 --> 04:50.600\n So people still do a lot of that stuff\n\n04:50.600 --> 04:53.600\n that should be in Access in Excel as they know it.\n\n04:53.600 --> 04:54.840\n Excel's great as well.\n\n04:54.840 --> 04:59.680\n So, but it's just not as rich a programming model\n\n04:59.680 --> 05:04.080\n as VBA combined with a relational database.\n\n05:04.080 --> 05:06.800\n And so I've always loved relational databases,\n\n05:06.800 --> 05:10.480\n but today programming on top of relational database\n\n05:10.480 --> 05:13.040\n is just a lot more of a headache.\n\n05:13.040 --> 05:15.680\n You know, you generally either need to kind of,\n\n05:15.680 --> 05:18.240\n you know, you need something that connects,\n\n05:18.240 --> 05:19.920\n that runs some kind of database server\n\n05:19.920 --> 05:23.920\n unless you use SQLite, which has its own issues.\n\n05:25.000 --> 05:25.920\n Then you kind of often,\n\n05:25.920 --> 05:27.600\n if you want to get a nice programming model,\n\n05:27.600 --> 05:30.400\n you'll need to like create an, add an ORM on top.\n\n05:30.400 --> 05:31.960\n And then, I don't know,\n\n05:31.960 --> 05:34.360\n there's all these pieces to tie together\n\n05:34.360 --> 05:37.000\n and it's just a lot more awkward than it should be.\n\n05:37.000 --> 05:39.200\n There are people that are trying to make it easier.\n\n05:39.200 --> 05:42.440\n So in particular, I think of F sharp, you know, Don Syme,\n\n05:42.440 --> 05:45.760\n who, him and his team have done a great job\n\n05:45.760 --> 05:50.520\n of making something like a database appear\n\n05:50.520 --> 05:51.640\n in the type system.\n\n05:51.640 --> 05:54.200\n So you actually get like tab completion for fields\n\n05:54.200 --> 05:56.240\n and tables and stuff like that.\n\n05:57.800 --> 05:59.280\n Anyway, so that was kind of, anyway,\n\n05:59.280 --> 06:01.880\n so like that whole VBA office thing, I guess,\n\n06:01.880 --> 06:04.640\n was a starting point, which I still miss.\n\n06:04.640 --> 06:07.800\n And I got into standard Visual Basic, which...\n\n06:07.800 --> 06:09.880\n That's interesting, just to pause on that for a second.\n\n06:09.880 --> 06:13.520\n It's interesting that you're connecting programming languages\n\n06:13.520 --> 06:17.440\n to the ease of management of data.\n\n06:17.440 --> 06:18.280\n Yeah.\n\n06:18.280 --> 06:20.600\n So in your use of programming languages,\n\n06:20.600 --> 06:24.880\n you always had a love and a connection with data.\n\n06:24.880 --> 06:28.000\n I've always been interested in doing useful things\n\n06:28.000 --> 06:29.480\n for myself and for others,\n\n06:29.480 --> 06:31.920\n which generally means getting some data\n\n06:31.920 --> 06:34.600\n and doing something with it and putting it out there again.\n\n06:34.600 --> 06:38.440\n So that's been my interest throughout.\n\n06:38.440 --> 06:41.600\n So I also did a lot of stuff with AppleScript\n\n06:41.600 --> 06:43.880\n back in the early days.\n\n06:43.880 --> 06:48.000\n So it's kind of nice being able to get the computer\n\n06:48.000 --> 06:50.160\n and computers to talk to each other\n\n06:50.160 --> 06:51.760\n and to do things for you.\n\n06:52.960 --> 06:54.640\n And then I think that one,\n\n06:54.640 --> 06:58.240\n the programming language I most loved then\n\n06:58.240 --> 07:01.840\n would have been Delphi, which was Object Pascal,\n\n07:02.920 --> 07:04.880\n created by Anders Heilsberg,\n\n07:04.880 --> 07:07.480\n who previously did Turbo Pascal\n\n07:07.480 --> 07:08.840\n and then went on to create.NET\n\n07:08.840 --> 07:11.080\n and then went on to create TypeScript.\n\n07:11.080 --> 07:14.880\n Delphi was amazing because it was like a compiled,\n\n07:14.880 --> 07:19.880\n fast language that was as easy to use as Visual Basic.\n\n07:20.200 --> 07:25.200\n Delphi, what is it similar to in more modern languages?\n\n07:27.520 --> 07:28.880\n Visual Basic.\n\n07:28.880 --> 07:29.720\n Visual Basic.\n\n07:29.720 --> 07:32.320\n Yeah, but a compiled, fast version.\n\n07:32.320 --> 07:37.080\n So I'm not sure there's anything quite like it anymore.\n\n07:37.080 --> 07:40.680\n If you took like C Sharp or Java\n\n07:40.680 --> 07:42.520\n and got rid of the virtual machine\n\n07:42.520 --> 07:43.440\n and replaced it with something,\n\n07:43.440 --> 07:46.560\n you could compile a small type binary.\n\n07:46.560 --> 07:50.720\n I feel like it's where Swift could get to\n\n07:50.720 --> 07:52.640\n with the new Swift UI\n\n07:52.640 --> 07:56.520\n and the cross platform development going on.\n\n07:56.520 --> 07:59.360\n Like that's one of my dreams\n\n07:59.360 --> 08:02.840\n is that we'll hopefully get back to where Delphi was.\n\n08:02.840 --> 08:07.840\n There is actually a free Pascal project nowadays\n\n08:08.520 --> 08:09.360\n called Lazarus,\n\n08:09.360 --> 08:13.400\n which is also attempting to kind of recreate Delphi.\n\n08:13.400 --> 08:16.080\n So they're making good progress.\n\n08:16.080 --> 08:18.560\n So, okay, Delphi,\n\n08:18.560 --> 08:20.960\n that's one of your favorite programming languages.\n\n08:20.960 --> 08:22.360\n Well, it's programming environments.\n\n08:22.360 --> 08:26.280\n Again, I'd say Pascal's not a nice language.\n\n08:26.280 --> 08:27.880\n If you wanted to know specifically\n\n08:27.880 --> 08:29.640\n about what languages I like,\n\n08:29.640 --> 08:33.600\n I would definitely pick J as being an amazingly wonderful\n\n08:33.600 --> 08:34.440\n language.\n\n08:35.480 --> 08:37.040\n What's J?\n\n08:37.040 --> 08:39.640\n J, are you aware of APL?\n\n08:39.640 --> 08:42.440\n I am not, except from doing a little research\n\n08:42.440 --> 08:44.080\n on the work you've done.\n\n08:44.080 --> 08:48.000\n Okay, so not at all surprising you're not familiar with it\n\n08:48.000 --> 08:49.000\n because it's not well known,\n\n08:49.000 --> 08:52.560\n but it's actually one of the main families\n\n08:54.880 --> 08:57.080\n of programming languages going back to the late 50s,\n\n08:57.080 --> 08:57.920\n early 60s.\n\n08:57.920 --> 09:01.640\n So there was a couple of major directions.\n\n09:01.640 --> 09:06.120\n One was the kind of Lambda Calculus Alonzo Church direction,\n\n09:06.120 --> 09:09.960\n which I guess kind of lisp and scheme and whatever,\n\n09:09.960 --> 09:12.280\n which has a history going back\n\n09:12.280 --> 09:13.360\n to the early days of computing.\n\n09:13.360 --> 09:18.360\n The second was the kind of imperative slash OO,\n\n09:18.680 --> 09:23.160\n algo similar going on to C, C++ and so forth.\n\n09:23.160 --> 09:24.000\n There was a third,\n\n09:24.000 --> 09:26.920\n which are called array oriented languages,\n\n09:26.920 --> 09:31.480\n which started with a paper by a guy called Ken Iverson,\n\n09:31.480 --> 09:35.160\n which was actually a math theory paper,\n\n09:35.160 --> 09:37.480\n not a programming paper.\n\n09:37.480 --> 09:41.440\n It was called Notation as a Tool for Thought.\n\n09:41.440 --> 09:43.480\n And it was the development of a new way,\n\n09:43.480 --> 09:45.280\n a new type of math notation.\n\n09:45.280 --> 09:47.560\n And the idea is that this math notation\n\n09:47.560 --> 09:51.320\n was much more flexible, expressive,\n\n09:51.320 --> 09:55.280\n and also well defined than traditional math notation,\n\n09:55.280 --> 09:56.440\n which is none of those things.\n\n09:56.440 --> 09:57.720\n Math notation is awful.\n\n09:59.200 --> 10:02.280\n And so he actually turned that into a programming language\n\n10:02.280 --> 10:05.640\n and cause this was the early 50s or the sorry, late 50s,\n\n10:05.640 --> 10:06.760\n all the names were available.\n\n10:06.760 --> 10:10.560\n So he called his language a programming language or APL.\n\n10:10.560 --> 10:11.400\n APL.\n\n10:11.400 --> 10:15.360\n So APL is a implementation of notation\n\n10:15.360 --> 10:18.320\n as a tool for thought by which he means math notation.\n\n10:18.320 --> 10:22.880\n And Ken and his son went on to do many things,\n\n10:22.880 --> 10:26.600\n but eventually they actually produced a new language\n\n10:26.600 --> 10:28.440\n that was built on top of all the learnings of APL.\n\n10:28.440 --> 10:29.480\n And that was called J.\n\n10:30.600 --> 10:35.600\n And J is the most expressive, composable language\n\n10:39.360 --> 10:42.440\n of beautifully designed language I've ever seen.\n\n10:42.440 --> 10:44.560\n Does it have object oriented components?\n\n10:44.560 --> 10:45.560\n Does it have that kind of thing?\n\n10:45.560 --> 10:47.720\n Not really, it's an array oriented language.\n\n10:47.720 --> 10:51.440\n It's the third path.\n\n10:51.440 --> 10:52.800\n Are you saying array?\n\n10:52.800 --> 10:53.960\n Array oriented, yeah.\n\n10:53.960 --> 10:55.520\n What does it mean to be array oriented?\n\n10:55.520 --> 10:57.520\n So array oriented means that you generally\n\n10:57.520 --> 10:59.560\n don't use any loops,\n\n10:59.560 --> 11:02.400\n but the whole thing is done with kind of\n\n11:02.400 --> 11:06.360\n a extreme version of broadcasting,\n\n11:06.360 --> 11:09.920\n if you're familiar with that NumPy slash Python concept.\n\n11:09.920 --> 11:14.640\n So you do a lot with one line of code.\n\n11:14.640 --> 11:19.640\n It looks a lot like math notation, highly compact.\n\n11:19.640 --> 11:22.880\n And the idea is that you can kind of,\n\n11:22.880 --> 11:24.760\n because you can do so much with one line of code,\n\n11:24.760 --> 11:27.760\n a single screen of code is very unlikely to,\n\n11:27.760 --> 11:29.560\n you very rarely need more than that\n\n11:29.560 --> 11:31.120\n to express your program.\n\n11:31.120 --> 11:33.320\n And so you can kind of keep it all in your head\n\n11:33.320 --> 11:36.080\n and you can kind of clearly communicate it.\n\n11:36.080 --> 11:40.000\n It's interesting that APL created two main branches,\n\n11:40.000 --> 11:41.640\n K and J.\n\n11:41.640 --> 11:44.560\n J is this kind of like open source,\n\n11:44.560 --> 11:49.440\n niche community of crazy enthusiasts like me.\n\n11:49.440 --> 11:52.160\n And then the other path, K, was fascinating.\n\n11:52.160 --> 11:56.640\n It's an astonishingly expensive programming language,\n\n11:56.640 --> 11:58.520\n which many of the world's\n\n11:58.520 --> 12:02.920\n most ludicrously rich hedge funds use.\n\n12:02.920 --> 12:06.680\n So the entire K machine is so small\n\n12:06.680 --> 12:09.360\n it sits inside level three cache on your CPU.\n\n12:09.360 --> 12:14.120\n And it easily wins every benchmark I've ever seen\n\n12:14.120 --> 12:16.760\n in terms of data processing speed.\n\n12:16.760 --> 12:17.920\n But you don't come across it very much\n\n12:17.920 --> 12:22.760\n because it's like $100,000 per CPU to run it.\n\n12:22.760 --> 12:26.280\n It's like this path of programming languages\n\n12:26.280 --> 12:28.920\n is just so much, I don't know,\n\n12:28.920 --> 12:30.360\n so much more powerful in every way\n\n12:30.360 --> 12:33.920\n than the ones that almost anybody uses every day.\n\n12:33.920 --> 12:37.520\n So it's all about computation.\n\n12:37.520 --> 12:38.360\n It's really focused on computation.\n\n12:38.360 --> 12:40.640\n It's pretty heavily focused on computation.\n\n12:40.640 --> 12:43.200\n I mean, so much of programming\n\n12:43.200 --> 12:45.640\n is data processing by definition.\n\n12:45.640 --> 12:48.960\n So there's a lot of things you can do with it.\n\n12:48.960 --> 12:51.440\n But yeah, there's not much work being done\n\n12:51.440 --> 12:56.440\n on making like user interface toolkits or whatever.\n\n12:57.000 --> 12:59.320\n I mean, there's some, but they're not great.\n\n12:59.320 --> 13:00.880\n At the same time, you've done a lot of stuff\n\n13:00.880 --> 13:03.120\n with Perl and Python.\n\n13:03.120 --> 13:08.120\n So where does that fit into the picture of J and K and APL?\n\n13:08.840 --> 13:11.000\n Well, it's just much more pragmatic.\n\n13:11.000 --> 13:13.880\n Like in the end, you kind of have to end up\n\n13:13.880 --> 13:17.760\n where the libraries are, you know?\n\n13:17.760 --> 13:21.240\n Like, cause to me, my focus is on productivity.\n\n13:21.240 --> 13:23.680\n I just want to get stuff done and solve problems.\n\n13:23.680 --> 13:27.280\n So Perl was great.\n\n13:27.280 --> 13:29.680\n I created an email company called FastMail\n\n13:29.680 --> 13:32.840\n and Perl was great cause back in the late nineties,\n\n13:32.840 --> 13:37.840\n early two thousands, it just had a lot of stuff it could do.\n\n13:38.080 --> 13:41.760\n I still had to write my own monitoring system\n\n13:41.760 --> 13:43.800\n and my own web framework, my own whatever,\n\n13:43.800 --> 13:45.720\n cause like none of that stuff existed.\n\n13:45.720 --> 13:50.280\n But it was a super flexible language to do that in.\n\n13:50.280 --> 13:54.240\n And you used Perl for FastMail, you used it as a backend?\n\n13:54.240 --> 13:55.760\n Like so everything was written in Perl?\n\n13:55.760 --> 13:58.720\n Yeah, yeah, everything, everything was Perl.\n\n13:58.720 --> 14:02.920\n Why do you think Perl hasn't succeeded\n\n14:02.920 --> 14:05.960\n or hasn't dominated the market where Python\n\n14:05.960 --> 14:07.560\n really takes over a lot of the tasks?\n\n14:07.560 --> 14:09.600\n Well, I mean, Perl did dominate.\n\n14:09.600 --> 14:13.080\n It was everything, everywhere,\n\n14:13.080 --> 14:17.120\n but then the guy that ran Perl, Larry Wohl,\n\n14:17.120 --> 14:22.120\n kind of just didn't put the time in anymore.\n\n14:22.320 --> 14:27.320\n And no project can be successful if there isn't,\n\n14:28.040 --> 14:31.600\n you know, particularly one that started with a strong leader\n\n14:31.600 --> 14:35.040\n that loses that strong leadership.\n\n14:35.040 --> 14:37.840\n So then Python has kind of replaced it.\n\n14:37.840 --> 14:42.840\n You know, Python is a lot less elegant language\n\n14:43.400 --> 14:45.040\n in nearly every way,\n\n14:45.040 --> 14:48.880\n but it has the data science libraries\n\n14:48.880 --> 14:51.280\n and a lot of them are pretty great.\n\n14:51.280 --> 14:54.680\n So I kind of use it\n\n14:56.240 --> 14:58.280\n cause it's the best we have,\n\n14:58.280 --> 15:01.800\n but it's definitely not good enough.\n\n15:01.800 --> 15:04.080\n But what do you think the future of programming looks like?\n\n15:04.080 --> 15:06.560\n What do you hope the future of programming looks like\n\n15:06.560 --> 15:08.760\n if we zoom in on the computational fields,\n\n15:08.760 --> 15:11.840\n on data science, on machine learning?\n\n15:11.840 --> 15:13.880\n I hope Swift is successful\n\n15:15.440 --> 15:19.440\n because the goal of Swift,\n\n15:19.440 --> 15:21.040\n the way Chris Latner describes it,\n\n15:21.040 --> 15:22.640\n is to be infinitely hackable.\n\n15:22.640 --> 15:23.480\n And that's what I want.\n\n15:23.480 --> 15:26.920\n I want something where me and the people I do research with\n\n15:26.920 --> 15:29.480\n and my students can look at\n\n15:29.480 --> 15:32.000\n and change everything from top to bottom.\n\n15:32.000 --> 15:36.240\n There's nothing mysterious and magical and inaccessible.\n\n15:36.240 --> 15:38.600\n Unfortunately with Python, it's the opposite of that\n\n15:38.600 --> 15:40.800\n because Python is so slow.\n\n15:40.800 --> 15:42.640\n It's extremely unhackable.\n\n15:42.640 --> 15:43.840\n You get to a point where it's like,\n\n15:43.840 --> 15:45.360\n okay, from here on down at C.\n\n15:45.360 --> 15:47.280\n So your debugger doesn't work in the same way.\n\n15:47.280 --> 15:48.920\n Your profiler doesn't work in the same way.\n\n15:48.920 --> 15:50.760\n Your build system doesn't work in the same way.\n\n15:50.760 --> 15:53.760\n It's really not very hackable at all.\n\n15:53.760 --> 15:55.600\n What's the part you like to be hackable?\n\n15:55.600 --> 16:00.120\n Is it for the objective of optimizing training\n\n16:00.120 --> 16:02.560\n of neural networks, inference of neural networks?\n\n16:02.560 --> 16:04.320\n Is it performance of the system\n\n16:04.320 --> 16:07.840\n or is there some non performance related, just?\n\n16:07.840 --> 16:09.000\n It's everything.\n\n16:09.000 --> 16:11.280\n I mean, in the end, I want to be productive\n\n16:11.280 --> 16:13.840\n as a practitioner.\n\n16:13.840 --> 16:16.280\n So that means that, so like at the moment,\n\n16:16.280 --> 16:20.000\n our understanding of deep learning is incredibly primitive.\n\n16:20.000 --> 16:21.440\n There's very little we understand.\n\n16:21.440 --> 16:23.200\n Most things don't work very well,\n\n16:23.200 --> 16:26.120\n even though it works better than anything else out there.\n\n16:26.120 --> 16:28.600\n There's so many opportunities to make it better.\n\n16:28.600 --> 16:31.280\n So you look at any domain area,\n\n16:31.280 --> 16:35.720\n like, I don't know, speech recognition with deep learning\n\n16:35.720 --> 16:38.360\n or natural language processing classification\n\n16:38.360 --> 16:39.400\n with deep learning or whatever.\n\n16:39.400 --> 16:41.920\n Every time I look at an area with deep learning,\n\n16:41.920 --> 16:44.440\n I always see like, oh, it's terrible.\n\n16:44.440 --> 16:47.480\n There's lots and lots of obviously stupid ways\n\n16:47.480 --> 16:50.160\n to do things that need to be fixed.\n\n16:50.160 --> 16:51.600\n So then I want to be able to jump in there\n\n16:51.600 --> 16:54.840\n and quickly experiment and make them better.\n\n16:54.840 --> 16:59.240\n You think the programming language has a role in that?\n\n16:59.240 --> 17:00.240\n Huge role, yeah.\n\n17:00.240 --> 17:05.240\n So currently, Python has a big gap\n\n17:05.960 --> 17:09.240\n in terms of our ability to innovate,\n\n17:09.240 --> 17:11.800\n particularly around recurrent neural networks\n\n17:11.800 --> 17:14.880\n and natural language processing.\n\n17:14.880 --> 17:18.240\n Because it's so slow, the actual loop\n\n17:18.240 --> 17:20.160\n where we actually loop through words,\n\n17:20.160 --> 17:23.720\n we have to do that whole thing in CUDA C.\n\n17:23.720 --> 17:27.080\n So we actually can't innovate with the kernel,\n\n17:27.080 --> 17:31.520\n the heart of that most important algorithm.\n\n17:31.520 --> 17:33.640\n And it's just a huge problem.\n\n17:33.640 --> 17:36.440\n And this happens all over the place.\n\n17:36.440 --> 17:40.040\n So we hit research limitations.\n\n17:40.040 --> 17:42.600\n Another example, convolutional neural networks,\n\n17:42.600 --> 17:44.720\n which are actually the most popular architecture\n\n17:44.720 --> 17:48.880\n for lots of things, maybe most things in deep learning.\n\n17:48.880 --> 17:50.280\n We almost certainly should be using\n\n17:50.280 --> 17:52.880\n sparse convolutional neural networks,\n\n17:52.880 --> 17:55.360\n but only like two people are,\n\n17:55.360 --> 17:57.800\n because to do it, you have to rewrite\n\n17:57.800 --> 17:59.880\n all of that CUDA C level stuff.\n\n17:59.880 --> 18:04.480\n And yeah, just researchers and practitioners don't.\n\n18:04.480 --> 18:09.200\n So there's just big gaps in what people actually research on,\n\n18:09.200 --> 18:10.520\n what people actually implement\n\n18:10.520 --> 18:13.200\n because of the programming language problem.\n\n18:13.200 --> 18:18.200\n So you think it's just too difficult to write in CUDA C\n\n18:20.600 --> 18:24.480\n that a higher level programming language like Swift\n\n18:24.480 --> 18:29.480\n should enable the easier,\n\n18:30.480 --> 18:33.080\n fooling around creative stuff with RNNs\n\n18:33.080 --> 18:34.840\n or with sparse convolutional neural networks?\n\n18:34.840 --> 18:35.680\n Kind of.\n\n18:35.680 --> 18:37.680\n Who's at fault?\n\n18:37.680 --> 18:41.000\n Who's at charge of making it easy\n\n18:41.000 --> 18:42.240\n for a researcher to play around?\n\n18:42.240 --> 18:43.480\n I mean, no one's at fault,\n\n18:43.480 --> 18:45.040\n just nobody's got around to it yet,\n\n18:45.040 --> 18:46.960\n or it's just, it's hard, right?\n\n18:46.960 --> 18:49.280\n And I mean, part of the fault is that we ignored\n\n18:49.280 --> 18:53.000\n that whole APL kind of direction.\n\n18:53.000 --> 18:56.360\n Nearly everybody did for 60 years, 50 years.\n\n18:57.440 --> 19:00.600\n But recently people have been starting to\n\n19:01.520 --> 19:03.480\n reinvent pieces of that\n\n19:03.480 --> 19:05.400\n and kind of create some interesting new directions\n\n19:05.400 --> 19:07.240\n in the compiler technology.\n\n19:07.240 --> 19:11.680\n So the place where that's particularly happening right now\n\n19:11.680 --> 19:13.440\n is something called MLIR,\n\n19:13.440 --> 19:14.840\n which is something that, again,\n\n19:14.840 --> 19:18.000\n Chris Latina, the Swift guy, is leading.\n\n19:18.000 --> 19:20.560\n And yeah, because it's actually not gonna be Swift\n\n19:20.560 --> 19:22.080\n on its own that solves this problem,\n\n19:22.080 --> 19:24.920\n because the problem is that currently writing\n\n19:24.920 --> 19:29.920\n a acceptably fast, you know, GPU program\n\n19:30.960 --> 19:33.720\n is too complicated regardless of what language you use.\n\n19:33.720 --> 19:34.560\n Right.\n\n19:36.440 --> 19:38.640\n And that's just because if you have to deal with the fact\n\n19:38.640 --> 19:41.680\n that I've got, you know, 10,000 threads\n\n19:41.680 --> 19:43.440\n and I have to synchronize between them all\n\n19:43.440 --> 19:45.320\n and I have to put my thing into grid blocks\n\n19:45.320 --> 19:47.000\n and think about warps and all this stuff,\n\n19:47.000 --> 19:50.680\n it's just so much boilerplate that to do that well,\n\n19:50.680 --> 19:52.200\n you have to be a specialist at that\n\n19:52.200 --> 19:56.440\n and it's gonna be a year's work to, you know,\n\n19:56.440 --> 19:59.640\n optimize that algorithm in that way.\n\n19:59.640 --> 20:03.520\n But with things like tensor comprehensions\n\n20:03.520 --> 20:07.120\n and TILE and MLIR and TVM,\n\n20:07.120 --> 20:08.640\n there's all these various projects\n\n20:08.640 --> 20:10.840\n which are all about saying,\n\n20:10.840 --> 20:14.000\n let's let people create like domain specific languages\n\n20:14.000 --> 20:16.840\n for tensor computations.\n\n20:16.840 --> 20:19.320\n These are the kinds of things we do generally\n\n20:19.320 --> 20:22.840\n on the GPU for deep learning and then have a compiler\n\n20:22.840 --> 20:27.840\n which can optimize that tensor computation.\n\n20:28.080 --> 20:29.840\n A lot of this work is actually sitting\n\n20:29.840 --> 20:32.640\n on top of a project called Halide,\n\n20:32.640 --> 20:37.080\n which is a mind blowing project where they came up\n\n20:37.080 --> 20:38.840\n with such a domain specific language.\n\n20:38.840 --> 20:41.200\n In fact, two, one domain specific language for expressing\n\n20:41.200 --> 20:43.800\n this is what my tensor computation is\n\n20:43.800 --> 20:46.280\n and another domain specific language for expressing\n\n20:46.280 --> 20:50.280\n this is the kind of the way I want you to structure\n\n20:50.280 --> 20:53.040\n the compilation of that and like do it block by block\n\n20:53.040 --> 20:54.920\n and do these bits in parallel.\n\n20:54.920 --> 20:57.720\n And they were able to show how you can compress\n\n20:57.720 --> 21:02.720\n the amount of code by 10X compared to optimized GPU code\n\n21:03.280 --> 21:05.520\n and get the same performance.\n\n21:05.520 --> 21:08.080\n So that's like, so these other things are kind of sitting\n\n21:08.080 --> 21:12.760\n on top of that kind of research and MLIR is pulling a lot\n\n21:12.760 --> 21:15.120\n of those best practices together.\n\n21:15.120 --> 21:18.240\n And now we're starting to see work done on making all\n\n21:18.240 --> 21:21.360\n of that directly accessible through Swift\n\n21:21.360 --> 21:23.720\n so that I could use Swift to kind of write those\n\n21:23.720 --> 21:27.240\n domain specific languages and hopefully we'll get\n\n21:27.240 --> 21:30.680\n then Swift CUDA kernels written in a very expressive\n\n21:30.680 --> 21:34.160\n and concise way that looks a bit like J and APL\n\n21:34.160 --> 21:36.680\n and then Swift layers on top of that\n\n21:36.680 --> 21:38.440\n and then a Swift UI on top of that.\n\n21:38.440 --> 21:42.600\n And it'll be so nice if we can get to that point.\n\n21:42.600 --> 21:46.520\n Now does it all eventually boil down to CUDA\n\n21:46.520 --> 21:48.560\n and NVIDIA GPUs?\n\n21:48.560 --> 21:50.160\n Unfortunately at the moment it does,\n\n21:50.160 --> 21:54.480\n but one of the nice things about MLIR if AMD ever\n\n21:54.480 --> 21:56.760\n gets their act together which they probably won't\n\n21:56.760 --> 22:01.760\n is that they or others could write MLIR backends\n\n22:02.120 --> 22:07.120\n for other GPUs or rather tensor computation devices\n\n22:09.720 --> 22:11.600\n of which today there are increasing number\n\n22:11.600 --> 22:16.600\n like Graph Core or Vertex AI or whatever.\n\n22:18.760 --> 22:22.560\n So yeah, being able to target lots of backends\n\n22:22.560 --> 22:23.920\n would be another benefit of this\n\n22:23.920 --> 22:26.680\n and the market really needs competition\n\n22:26.680 --> 22:29.520\n because at the moment NVIDIA is massively overcharging\n\n22:29.520 --> 22:33.640\n for their kind of enterprise class cards\n\n22:33.640 --> 22:36.720\n because there is no serious competition\n\n22:36.720 --> 22:39.280\n because nobody else is doing the software properly.\n\n22:39.280 --> 22:41.400\n In the cloud there is some competition, right?\n\n22:41.400 --> 22:42.920\n But...\n\n22:42.920 --> 22:45.120\n Not really, other than TPUs perhaps,\n\n22:45.120 --> 22:48.240\n but TPUs are almost unprogrammable at the moment.\n\n22:48.240 --> 22:51.200\n So TPUs have the same problem that you can't?\n\n22:51.200 --> 22:52.040\n It's even worse.\n\n22:52.040 --> 22:54.840\n So TPUs, Google actually made an explicit decision\n\n22:54.840 --> 22:57.200\n to make them almost entirely unprogrammable\n\n22:57.200 --> 22:59.960\n because they felt that there was too much IP in there\n\n22:59.960 --> 23:02.640\n and if they gave people direct access to program them,\n\n23:02.640 --> 23:04.360\n people would learn their secrets.\n\n23:04.360 --> 23:09.360\n So you can't actually directly program the memory\n\n23:09.360 --> 23:11.000\n in a TPU.\n\n23:11.000 --> 23:15.200\n You can't even directly create code that runs on\n\n23:15.200 --> 23:18.040\n and that you look at on the machine that has the TPU,\n\n23:18.040 --> 23:19.920\n it all goes through a virtual machine.\n\n23:19.920 --> 23:22.920\n So all you can really do is this kind of cookie cutter thing\n\n23:22.920 --> 23:26.720\n of like plug in high level stuff together,\n\n23:26.720 --> 23:30.520\n which is just super tedious and annoying\n\n23:30.520 --> 23:32.920\n and totally unnecessary.\n\n23:32.920 --> 23:36.040\n So what was the, tell me if you could,\n\n23:36.040 --> 23:38.080\n the origin story of fast AI.\n\n23:38.080 --> 23:43.080\n What is the motivation, its mission, its dream?\n\n23:43.280 --> 23:48.280\n So I guess the founding story is heavily tied\n\n23:48.280 --> 23:51.480\n to my previous startup, which is a company called Analytic,\n\n23:51.480 --> 23:54.880\n which was the first company to focus on deep learning\n\n23:54.880 --> 23:58.720\n for medicine and I created that because I saw\n\n23:58.720 --> 24:02.120\n that was a huge opportunity to,\n\n24:02.120 --> 24:05.840\n there's about a 10X shortage of the number of doctors\n\n24:05.840 --> 24:08.200\n in the world, in the developing world that we need.\n\n24:08.200 --> 24:11.760\n I expected it would take about 300 years\n\n24:11.760 --> 24:13.920\n to train enough doctors to meet that gap.\n\n24:13.920 --> 24:18.920\n But I guess that maybe if we used deep learning\n\n24:19.400 --> 24:22.800\n for some of the analytics, we could maybe make it\n\n24:22.800 --> 24:25.240\n so you don't need as highly trained doctors.\n\n24:25.240 --> 24:26.080\n For diagnosis.\n\n24:26.080 --> 24:27.720\n For diagnosis and treatment planning.\n\n24:27.720 --> 24:31.440\n Where's the biggest benefit just before we get to fast AI,\n\n24:31.440 --> 24:33.880\n where's the biggest benefit of AI\n\n24:33.880 --> 24:36.400\n and medicine that you see today?\n\n24:36.400 --> 24:37.240\n And maybe next time.\n\n24:37.240 --> 24:39.480\n Not much happening today in terms of like stuff\n\n24:39.480 --> 24:41.040\n that's actually out there, it's very early.\n\n24:41.040 --> 24:42.880\n But in terms of the opportunity,\n\n24:42.880 --> 24:47.880\n it's to take markets like India and China and Indonesia,\n\n24:48.720 --> 24:52.080\n which have big populations, Africa,\n\n24:52.080 --> 24:53.760\n small numbers of doctors,\n\n24:55.760 --> 25:00.760\n and provide diagnostic, particularly treatment planning\n\n25:00.760 --> 25:05.760\n and triage kind of on device so that if you do a test\n\n25:05.760 --> 25:09.240\n for malaria or tuberculosis or whatever,\n\n25:09.240 --> 25:12.440\n you immediately get something that even a healthcare worker\n\n25:12.440 --> 25:16.160\n that's had a month of training can get\n\n25:16.160 --> 25:20.440\n a very high quality assessment of whether the patient\n\n25:20.440 --> 25:22.320\n might be at risk and tell, okay,\n\n25:22.320 --> 25:25.240\n we'll send them off to a hospital.\n\n25:25.240 --> 25:29.240\n So for example, in Africa, outside of South Africa,\n\n25:29.240 --> 25:31.640\n there's only five pediatric radiologists\n\n25:31.640 --> 25:32.960\n for the entire continent.\n\n25:32.960 --> 25:34.720\n So most countries don't have any.\n\n25:34.720 --> 25:37.440\n So if your kid is sick and they need something diagnosed\n\n25:37.440 --> 25:39.800\n through medical imaging, the person,\n\n25:39.800 --> 25:41.640\n even if you're able to get medical imaging done,\n\n25:41.640 --> 25:46.400\n the person that looks at it will be a nurse at best.\n\n25:46.400 --> 25:50.080\n But actually in India, for example, and China,\n\n25:50.080 --> 25:52.360\n almost no x rays are read by anybody,\n\n25:52.360 --> 25:57.040\n by any trained professional because they don't have enough.\n\n25:57.040 --> 26:02.040\n So if instead we had a algorithm that could take\n\n26:02.040 --> 26:07.040\n the most likely high risk 5% and say triage,\n\n26:08.040 --> 26:11.040\n basically say, okay, someone needs to look at this,\n\n26:11.040 --> 26:14.240\n it would massively change the kind of way\n\n26:14.240 --> 26:18.680\n that what's possible with medicine in the developing world.\n\n26:18.680 --> 26:21.600\n And remember, they have, increasingly they have money.\n\n26:21.600 --> 26:23.560\n They're the developing world, they're not the poor world,\n\n26:23.560 --> 26:24.400\n they're the developing world.\n\n26:24.400 --> 26:25.240\n So they have the money.\n\n26:25.240 --> 26:27.040\n So they're building the hospitals,\n\n26:27.040 --> 26:30.440\n they're getting the diagnostic equipment,\n\n26:30.440 --> 26:33.320\n but there's no way for a very long time\n\n26:33.320 --> 26:37.040\n will they be able to have the expertise.\n\n26:37.040 --> 26:38.480\n Shortage of expertise, okay.\n\n26:38.480 --> 26:41.760\n And that's where the deep learning systems can step in\n\n26:41.760 --> 26:44.320\n and magnify the expertise they do have.\n\n26:44.320 --> 26:46.240\n Exactly, yeah.\n\n26:46.240 --> 26:51.240\n So you do see, just to linger a little bit longer,\n\n26:51.240 --> 26:55.760\n the interaction, do you still see the human experts\n\n26:55.760 --> 26:57.560\n still at the core of these systems?\n\n26:57.560 --> 26:58.400\n Yeah, absolutely.\n\n26:58.400 --> 26:59.240\n Is there something in medicine\n\n26:59.240 --> 27:01.280\n that could be automated almost completely?\n\n27:01.280 --> 27:03.880\n I don't see the point of even thinking about that\n\n27:03.880 --> 27:06.080\n because we have such a shortage of people.\n\n27:06.080 --> 27:09.760\n Why would we want to find a way not to use them?\n\n27:09.760 --> 27:13.000\n We have people, so the idea of like,\n\n27:13.000 --> 27:14.680\n even from an economic point of view,\n\n27:14.680 --> 27:17.320\n if you can make them 10X more productive,\n\n27:17.320 --> 27:18.920\n getting rid of the person,\n\n27:18.920 --> 27:21.600\n doesn't impact your unit economics at all.\n\n27:21.600 --> 27:23.360\n And it totally ignores the fact\n\n27:23.360 --> 27:26.520\n that there are things people do better than machines.\n\n27:26.520 --> 27:27.360\n So it's just to me,\n\n27:27.360 --> 27:32.000\n that's not a useful way of framing the problem.\n\n27:32.000 --> 27:33.760\n I guess, just to clarify,\n\n27:33.760 --> 27:36.480\n I guess I meant there may be some problems\n\n27:36.480 --> 27:40.000\n where you can avoid even going to the expert ever,\n\n27:40.000 --> 27:44.000\n sort of maybe preventative care or some basic stuff,\n\n27:44.000 --> 27:44.840\n allowing food,\n\n27:44.840 --> 27:46.600\n allowing the expert to focus on the things\n\n27:46.600 --> 27:49.200\n that are really that, you know.\n\n27:49.200 --> 27:50.920\n Well, that's what the triage would do, right?\n\n27:50.920 --> 27:52.800\n So the triage would say,\n\n27:52.800 --> 27:57.800\n okay, there's 99% sure there's nothing here.\n\n27:58.640 --> 28:01.960\n So that can be done on device\n\n28:01.960 --> 28:03.840\n and they can just say, okay, go home.\n\n28:03.840 --> 28:07.320\n So the experts are being used to look at the stuff\n\n28:07.320 --> 28:10.160\n which has some chance it's worth looking at,\n\n28:10.160 --> 28:14.320\n which most things it's not, it's fine.\n\n28:14.320 --> 28:15.520\n Why do you think that is?\n\n28:15.520 --> 28:16.880\n You know, it's fine.\n\n28:16.880 --> 28:19.920\n Why do you think we haven't quite made progress on that yet\n\n28:19.920 --> 28:24.920\n in terms of the scale of how much AI is applied\n\n28:27.000 --> 28:27.840\n in the medical field?\n\n28:27.840 --> 28:28.680\n Oh, there's a lot of reasons.\n\n28:28.680 --> 28:29.720\n I mean, one is it's pretty new.\n\n28:29.720 --> 28:32.120\n I only started in Liddick in like 2014.\n\n28:32.120 --> 28:36.040\n And before that, it's hard to express\n\n28:36.040 --> 28:37.440\n to what degree the medical world\n\n28:37.440 --> 28:40.760\n was not aware of the opportunities here.\n\n28:40.760 --> 28:42.960\n So I went to RSNA,\n\n28:42.960 --> 28:46.240\n which is the world's largest radiology conference.\n\n28:46.240 --> 28:49.520\n And I told everybody I could, you know,\n\n28:49.520 --> 28:51.760\n like I'm doing this thing with deep learning,\n\n28:51.760 --> 28:53.360\n please come and check it out.\n\n28:53.360 --> 28:56.840\n And no one had any idea what I was talking about\n\n28:56.840 --> 28:58.520\n and no one had any interest in it.\n\n28:59.680 --> 29:04.680\n So like we've come from absolute zero, which is hard.\n\n29:05.120 --> 29:09.920\n And then the whole regulatory framework, education system,\n\n29:09.920 --> 29:13.440\n everything is just set up to think of doctoring\n\n29:13.440 --> 29:14.960\n in a very different way.\n\n29:14.960 --> 29:17.120\n So today there is a small number of people\n\n29:17.120 --> 29:20.600\n who are deep learning practitioners\n\n29:20.600 --> 29:23.040\n and doctors at the same time.\n\n29:23.040 --> 29:24.640\n And we're starting to see the first ones\n\n29:24.640 --> 29:26.600\n come out of their PhD programs.\n\n29:26.600 --> 29:31.600\n So Zach Kahane over in Boston, Cambridge\n\n29:31.600 --> 29:37.880\n has a number of students now who are data science experts,\n\n29:37.880 --> 29:42.880\n deep learning experts, and actual medical doctors.\n\n29:43.480 --> 29:47.000\n Quite a few doctors have completed our fast AI course now\n\n29:47.000 --> 29:52.000\n and are publishing papers and creating journal reading groups\n\n29:52.560 --> 29:55.200\n in the American Council of Radiology.\n\n29:55.200 --> 29:57.360\n And like, it's just starting to happen,\n\n29:57.360 --> 29:59.640\n but it's gonna be a long time coming.\n\n29:59.640 --> 30:02.880\n It's gonna happen, but it's gonna be a long process.\n\n30:02.880 --> 30:04.880\n The regulators have to learn how to regulate this.\n\n30:04.880 --> 30:08.720\n They have to build guidelines.\n\n30:08.720 --> 30:12.120\n And then the lawyers at hospitals\n\n30:12.120 --> 30:15.080\n have to develop a new way of understanding\n\n30:15.080 --> 30:20.080\n that sometimes it makes sense for data to be looked at\n\n30:22.440 --> 30:24.880\n in raw form in large quantities\n\n30:24.880 --> 30:27.000\n in order to create well changing results.\n\n30:27.000 --> 30:30.120\n Yeah, so the regulation around data, all that,\n\n30:30.120 --> 30:33.880\n it sounds probably the hardest problem,\n\n30:33.880 --> 30:36.800\n but sounds reminiscent of autonomous vehicles as well.\n\n30:36.800 --> 30:38.760\n Many of the same regulatory challenges,\n\n30:38.760 --> 30:40.640\n many of the same data challenges.\n\n30:40.640 --> 30:41.560\n Yeah, I mean, funnily enough,\n\n30:41.560 --> 30:43.680\n the problem is less the regulation\n\n30:43.680 --> 30:45.880\n and more the interpretation of that regulation\n\n30:45.880 --> 30:48.240\n by lawyers in hospitals.\n\n30:48.240 --> 30:52.920\n So HIPAA is actually, was designed to pay,\n\n30:52.920 --> 30:56.480\n and HIPAA does not stand for privacy.\n\n30:56.480 --> 30:57.680\n It stands for portability.\n\n30:57.680 --> 31:01.240\n It's actually meant to be a way that data can be used.\n\n31:01.240 --> 31:04.400\n And it was created with lots of gray areas\n\n31:04.400 --> 31:06.560\n because the idea is that would be more practical\n\n31:06.560 --> 31:10.480\n and it would help people to use this legislation\n\n31:10.480 --> 31:13.720\n to actually share data in a more thoughtful way.\n\n31:13.720 --> 31:15.360\n Unfortunately, it's done the opposite\n\n31:15.360 --> 31:17.800\n because when a lawyer sees a gray area,\n\n31:17.800 --> 31:20.760\n they say, oh, if we don't know, we won't get sued,\n\n31:20.760 --> 31:22.440\n then we can't do it.\n\n31:22.440 --> 31:26.360\n So HIPAA is not exactly the problem.\n\n31:26.360 --> 31:29.200\n The problem is more that there's,\n\n31:29.200 --> 31:31.000\n hospital lawyers are not incented\n\n31:31.000 --> 31:36.000\n to make bold decisions about data portability.\n\n31:36.520 --> 31:40.440\n Or even to embrace technology that saves lives.\n\n31:40.440 --> 31:42.440\n They more want to not get in trouble\n\n31:42.440 --> 31:44.760\n for embracing that technology.\n\n31:44.760 --> 31:47.840\n It also saves lives in a very abstract way,\n\n31:47.840 --> 31:49.840\n which is like, oh, we've been able to release\n\n31:49.840 --> 31:52.320\n these 100,000 anonymized records.\n\n31:52.320 --> 31:54.120\n I can't point to the specific person\n\n31:54.120 --> 31:55.320\n whose life that saved.\n\n31:55.320 --> 31:57.720\n I can say like, oh, we ended up with this paper\n\n31:57.720 --> 31:58.960\n which found this result,\n\n31:58.960 --> 32:02.200\n which diagnosed a thousand more people\n\n32:02.200 --> 32:03.080\n than we would have otherwise,\n\n32:03.080 --> 32:05.480\n but it's like, which ones were helped?\n\n32:05.480 --> 32:07.320\n It's very abstract.\n\n32:07.320 --> 32:09.360\n And on the counter side of that,\n\n32:09.360 --> 32:13.080\n you may be able to point to a life that was taken\n\n32:13.080 --> 32:14.320\n because of something that was.\n\n32:14.320 --> 32:18.160\n Yeah, or a person whose privacy was violated.\n\n32:18.160 --> 32:23.160\n It's like, oh, this specific person was deidentified.\n\n32:24.200 --> 32:25.960\n So, identified.\n\n32:25.960 --> 32:27.280\n Just a fascinating topic.\n\n32:27.280 --> 32:28.240\n We're jumping around.\n\n32:28.240 --> 32:29.400\n We'll get back to fast AI,\n\n32:29.400 --> 32:32.600\n but on the question of privacy,\n\n32:32.600 --> 32:37.600\n data is the fuel for so much innovation in deep learning.\n\n32:38.080 --> 32:39.760\n What's your sense on privacy?\n\n32:39.760 --> 32:44.000\n Whether we're talking about Twitter, Facebook, YouTube,\n\n32:44.000 --> 32:48.640\n just the technologies like in the medical field\n\n32:48.640 --> 32:53.360\n that rely on people's data in order to create impact.\n\n32:53.360 --> 32:56.600\n How do we get that right,\n\n32:56.600 --> 33:01.200\n respecting people's privacy and yet creating technology\n\n33:01.200 --> 33:03.320\n that is learning from data?\n\n33:03.320 --> 33:08.320\n One of my areas of focus is on doing more with less data.\n\n33:08.320 --> 33:11.840\n More with less data, which,\n\n33:11.840 --> 33:14.400\n so most vendors, unfortunately,\n\n33:14.400 --> 33:17.560\n are strongly incented to find ways\n\n33:17.560 --> 33:20.040\n to require more data and more computation.\n\n33:20.040 --> 33:23.440\n So, Google and IBM being the most obvious.\n\n33:24.400 --> 33:25.920\n IBM.\n\n33:25.920 --> 33:27.680\n Yeah, so Watson.\n\n33:27.680 --> 33:31.160\n So, Google and IBM both strongly push the idea\n\n33:31.160 --> 33:33.080\n that you have to be,\n\n33:33.080 --> 33:35.440\n that they have more data and more computation\n\n33:35.440 --> 33:37.840\n and more intelligent people than anybody else.\n\n33:37.840 --> 33:39.880\n And so you have to trust them to do things\n\n33:39.880 --> 33:41.320\n because nobody else can do it.\n\n33:42.640 --> 33:45.400\n And Google's very upfront about this,\n\n33:45.400 --> 33:48.440\n like Jeff Dean has gone out there and given talks\n\n33:48.440 --> 33:50.560\n and said, our goal is to require\n\n33:50.560 --> 33:55.160\n a thousand times more computation, but less people.\n\n33:55.160 --> 34:00.160\n Our goal is to use the people that you have better\n\n34:00.640 --> 34:01.680\n and the data you have better\n\n34:01.680 --> 34:03.000\n and the computation you have better.\n\n34:03.000 --> 34:06.040\n So, one of the things that we've discovered is,\n\n34:06.040 --> 34:08.000\n or at least highlighted,\n\n34:08.000 --> 34:11.080\n is that you very, very, very often\n\n34:11.080 --> 34:13.360\n don't need much data at all.\n\n34:13.360 --> 34:16.160\n And so the data you already have in your organization\n\n34:16.160 --> 34:19.240\n will be enough to get state of the art results.\n\n34:19.240 --> 34:21.320\n So, like my starting point would be to kind of say\n\n34:21.320 --> 34:25.760\n around privacy is a lot of people are looking for ways\n\n34:25.760 --> 34:28.160\n to share data and aggregate data,\n\n34:28.160 --> 34:29.960\n but I think often that's unnecessary.\n\n34:29.960 --> 34:32.200\n They assume that they need more data than they do\n\n34:32.200 --> 34:34.160\n because they're not familiar with the basics\n\n34:34.160 --> 34:38.440\n of transfer learning, which is this critical technique\n\n34:38.440 --> 34:42.000\n for needing orders of magnitude less data.\n\n34:42.000 --> 34:44.680\n Is your sense, one reason you might wanna collect data\n\n34:44.680 --> 34:49.680\n from everyone is like in the recommender system context,\n\n34:50.440 --> 34:54.520\n where your individual, Jeremy Howard's individual data\n\n34:54.520 --> 34:58.440\n is the most useful for providing a product\n\n34:58.440 --> 34:59.840\n that's impactful for you.\n\n34:59.840 --> 35:02.240\n So, for giving you advertisements,\n\n35:02.240 --> 35:04.160\n for recommending to you movies,\n\n35:04.160 --> 35:06.360\n for doing medical diagnosis,\n\n35:07.600 --> 35:11.680\n is your sense we can build with a small amount of data,\n\n35:11.680 --> 35:15.200\n general models that will have a huge impact\n\n35:15.200 --> 35:18.280\n for most people that we don't need to have data\n\n35:18.280 --> 35:19.160\n from each individual?\n\n35:19.160 --> 35:20.560\n On the whole, I'd say yes.\n\n35:20.560 --> 35:23.440\n I mean, there are things like,\n\n35:25.240 --> 35:28.360\n you know, recommender systems have this cold start problem\n\n35:28.360 --> 35:30.960\n where, you know, Jeremy is a new customer,\n\n35:30.960 --> 35:33.280\n we haven't seen him before, so we can't recommend him things\n\n35:33.280 --> 35:36.000\n based on what else he's bought and liked with us.\n\n35:36.000 --> 35:38.840\n And there's various workarounds to that.\n\n35:38.840 --> 35:40.640\n Like in a lot of music programs,\n\n35:40.640 --> 35:44.880\n we'll start out by saying, which of these artists do you like?\n\n35:44.880 --> 35:46.760\n Which of these albums do you like?\n\n35:46.760 --> 35:48.400\n Which of these songs do you like?\n\n35:49.760 --> 35:53.520\n Netflix used to do that, nowadays they tend not to.\n\n35:53.520 --> 35:54.760\n People kind of don't like that\n\n35:54.760 --> 35:57.320\n because they think, oh, we don't wanna bother the user.\n\n35:57.320 --> 35:58.680\n So, you could work around that\n\n35:58.680 --> 36:00.960\n by having some kind of data sharing\n\n36:00.960 --> 36:04.880\n where you get my marketing record from Axiom or whatever,\n\n36:04.880 --> 36:06.560\n and try to guess from that.\n\n36:06.560 --> 36:11.560\n To me, the benefit to me and to society\n\n36:12.320 --> 36:16.440\n of saving me five minutes on answering some questions\n\n36:16.440 --> 36:21.440\n versus the negative externalities of the privacy issue\n\n36:23.480 --> 36:24.760\n doesn't add up.\n\n36:24.760 --> 36:26.120\n So, I think like a lot of the time,\n\n36:26.120 --> 36:30.120\n the places where people are invading our privacy\n\n36:30.120 --> 36:32.760\n in order to provide convenience\n\n36:32.760 --> 36:36.800\n is really about just trying to make them more money\n\n36:36.800 --> 36:40.720\n and they move these negative externalities\n\n36:40.720 --> 36:44.240\n to places that they don't have to pay for them.\n\n36:44.240 --> 36:48.440\n So, when you actually see regulations appear\n\n36:48.440 --> 36:50.360\n that actually cause the companies\n\n36:50.360 --> 36:52.080\n that create these negative externalities\n\n36:52.080 --> 36:53.480\n to have to pay for it themselves,\n\n36:53.480 --> 36:56.080\n they say, well, we can't do it anymore.\n\n36:56.080 --> 36:58.160\n So, the cost is actually too high.\n\n36:58.160 --> 37:00.320\n But for something like medicine,\n\n37:00.320 --> 37:05.200\n yeah, I mean, the hospital has my medical imaging,\n\n37:05.200 --> 37:07.920\n my pathology studies, my medical records,\n\n37:08.880 --> 37:11.840\n and also I own my medical data.\n\n37:11.840 --> 37:16.840\n So, you can, so I help a startup called Doc.ai.\n\n37:16.920 --> 37:19.680\n One of the things Doc.ai does is that it has an app.\n\n37:19.680 --> 37:23.760\n You can connect to, you know, Sutter Health\n\n37:23.760 --> 37:26.080\n and LabCorp and Walgreens\n\n37:26.080 --> 37:29.800\n and download your medical data to your phone\n\n37:29.800 --> 37:33.520\n and then upload it again at your discretion\n\n37:33.520 --> 37:35.120\n to share it as you wish.\n\n37:35.960 --> 37:38.000\n So, with that kind of approach,\n\n37:38.000 --> 37:41.120\n we can share our medical information\n\n37:41.120 --> 37:44.760\n with the people we want to.\n\n37:44.760 --> 37:45.680\n Yeah, so control.\n\n37:45.680 --> 37:47.440\n I mean, really being able to control\n\n37:47.440 --> 37:48.760\n who you share it with and so on.\n\n37:48.760 --> 37:49.720\n Yeah.\n\n37:49.720 --> 37:53.480\n So, that has a beautiful, interesting tangent\n\n37:53.480 --> 37:58.480\n to return back to the origin story of Fast.ai.\n\n37:59.360 --> 38:02.480\n Right, so before I started Fast.ai,\n\n38:02.480 --> 38:06.320\n I spent a year researching\n\n38:06.320 --> 38:10.360\n where are the biggest opportunities for deep learning?\n\n38:10.360 --> 38:14.040\n Because I knew from my time at Kaggle in particular\n\n38:14.040 --> 38:16.880\n that deep learning had kind of hit this threshold point\n\n38:16.880 --> 38:19.840\n where it was rapidly becoming the state of the art approach\n\n38:19.840 --> 38:21.560\n in every area that looked at it.\n\n38:21.560 --> 38:25.360\n And I'd been working with neural nets for over 20 years.\n\n38:25.360 --> 38:27.400\n I knew that from a theoretical point of view,\n\n38:27.400 --> 38:28.520\n once it hit that point,\n\n38:28.520 --> 38:31.520\n it would do that in kind of just about every domain.\n\n38:31.520 --> 38:34.440\n And so I kind of spent a year researching\n\n38:34.440 --> 38:36.200\n what are the domains that's gonna have\n\n38:36.200 --> 38:37.360\n the biggest low hanging fruit\n\n38:37.360 --> 38:39.360\n in the shortest time period.\n\n38:39.360 --> 38:42.040\n I picked medicine, but there were so many\n\n38:42.040 --> 38:43.880\n I could have picked.\n\n38:43.880 --> 38:46.200\n And so there was a kind of level of frustration for me\n\n38:46.200 --> 38:49.920\n of like, okay, I'm really glad we've opened up\n\n38:49.920 --> 38:51.120\n the medical deep learning world.\n\n38:51.120 --> 38:53.880\n And today it's huge, as you know,\n\n38:53.880 --> 38:58.240\n but we can't do, I can't do everything.\n\n38:58.240 --> 39:00.360\n I don't even know, like in medicine,\n\n39:00.360 --> 39:02.240\n it took me a really long time to even get a sense\n\n39:02.240 --> 39:05.040\n of like what kind of problems do medical practitioners solve?\n\n39:05.040 --> 39:06.360\n What kind of data do they have?\n\n39:06.360 --> 39:07.400\n Who has that data?\n\n39:08.480 --> 39:12.440\n So I kind of felt like I need to approach this differently\n\n39:12.440 --> 39:16.200\n if I wanna maximize the positive impact of deep learning.\n\n39:16.200 --> 39:19.160\n Rather than me picking an area\n\n39:19.160 --> 39:21.720\n and trying to become good at it and building something,\n\n39:21.720 --> 39:24.440\n I should let people who are already domain experts\n\n39:24.440 --> 39:26.640\n in those areas and who already have the data\n\n39:27.760 --> 39:29.200\n do it themselves.\n\n39:29.200 --> 39:33.080\n So that was the reason for Fast.ai\n\n39:33.080 --> 39:36.760\n is to basically try and figure out\n\n39:36.760 --> 39:40.120\n how to get deep learning into the hands of people\n\n39:40.120 --> 39:43.240\n who could benefit from it and help them to do so\n\n39:43.240 --> 39:47.080\n in as quick and easy and effective a way as possible.\n\n39:47.080 --> 39:50.200\n Got it, so sort of empower the domain experts.\n\n39:50.200 --> 39:53.080\n Yeah, and like partly it's because like,\n\n39:54.240 --> 39:56.280\n unlike most people in this field,\n\n39:56.280 --> 39:59.920\n my background is very applied and industrial.\n\n39:59.920 --> 40:02.440\n Like my first job was at McKinsey & Company.\n\n40:02.440 --> 40:04.640\n I spent 10 years in management consulting.\n\n40:04.640 --> 40:10.440\n I spend a lot of time with domain experts.\n\n40:10.440 --> 40:12.760\n So I kind of respect them and appreciate them.\n\n40:12.760 --> 40:16.480\n And I know that's where the value generation in society is.\n\n40:16.480 --> 40:21.480\n And so I also know how most of them can't code\n\n40:21.600 --> 40:26.320\n and most of them don't have the time to invest\n\n40:26.320 --> 40:29.320\n three years in a graduate degree or whatever.\n\n40:29.320 --> 40:33.520\n So I was like, how do I upskill those domain experts?\n\n40:33.520 --> 40:36.600\n I think that would be a super powerful thing,\n\n40:36.600 --> 40:38.920\n the biggest societal impact I could have.\n\n40:40.240 --> 40:41.680\n So yeah, that was the thinking.\n\n40:41.680 --> 40:45.680\n So much of Fast.ai students and researchers\n\n40:45.680 --> 40:50.160\n and the things you teach are pragmatically minded,\n\n40:50.160 --> 40:52.080\n practically minded,\n\n40:52.080 --> 40:55.800\n figuring out ways how to solve real problems and fast.\n\n40:55.800 --> 40:57.480\n So from your experience,\n\n40:57.480 --> 40:59.120\n what's the difference between theory\n\n40:59.120 --> 41:03.680\n and practice of deep learning?\n\n41:03.680 --> 41:07.520\n Well, most of the research in the deep learning world\n\n41:07.520 --> 41:09.840\n is a total waste of time.\n\n41:09.840 --> 41:11.040\n Right, that's what I was getting at.\n\n41:11.040 --> 41:12.200\n Yeah.\n\n41:12.200 --> 41:16.240\n It's a problem in science in general.\n\n41:16.240 --> 41:19.600\n Scientists need to be published,\n\n41:19.600 --> 41:21.480\n which means they need to work on things\n\n41:21.480 --> 41:24.080\n that their peers are extremely familiar with\n\n41:24.080 --> 41:26.200\n and can recognize in advance in that area.\n\n41:26.200 --> 41:30.120\n So that means that they all need to work on the same thing.\n\n41:30.120 --> 41:33.040\n And so it really, and the thing they work on,\n\n41:33.040 --> 41:35.640\n there's nothing to encourage them to work on things\n\n41:35.640 --> 41:38.840\n that are practically useful.\n\n41:38.840 --> 41:41.160\n So you get just a whole lot of research,\n\n41:41.160 --> 41:43.240\n which is minor advances and stuff\n\n41:43.240 --> 41:44.640\n that's been very highly studied\n\n41:44.640 --> 41:49.360\n and has no significant practical impact.\n\n41:49.360 --> 41:50.920\n Whereas the things that really make a difference,\n\n41:50.920 --> 41:52.800\n like I mentioned transfer learning,\n\n41:52.800 --> 41:55.640\n like if we can do better at transfer learning,\n\n41:55.640 --> 41:58.200\n then it's this like world changing thing\n\n41:58.200 --> 41:59.800\n where suddenly like lots more people\n\n41:59.800 --> 42:04.800\n can do world class work with less resources and less data.\n\n42:06.840 --> 42:08.560\n But almost nobody works on that.\n\n42:08.560 --> 42:10.800\n Or another example, active learning,\n\n42:10.800 --> 42:11.920\n which is the study of like,\n\n42:11.920 --> 42:15.920\n how do we get more out of the human beings in the loop?\n\n42:15.920 --> 42:17.160\n That's my favorite topic.\n\n42:17.160 --> 42:18.560\n Yeah, so active learning is great,\n\n42:18.560 --> 42:21.200\n but it's almost nobody working on it\n\n42:21.200 --> 42:23.840\n because it's just not a trendy thing right now.\n\n42:23.840 --> 42:27.080\n You know what somebody, sorry to interrupt,\n\n42:27.080 --> 42:31.560\n you're saying that nobody is publishing on active learning,\n\n42:31.560 --> 42:33.480\n but there's people inside companies,\n\n42:33.480 --> 42:36.840\n anybody who actually has to solve a problem,\n\n42:36.840 --> 42:39.680\n they're going to innovate on active learning.\n\n42:39.680 --> 42:42.120\n Yeah, everybody kind of reinvents active learning\n\n42:42.120 --> 42:43.800\n when they actually have to work in practice\n\n42:43.800 --> 42:46.400\n because they start labeling things and they think,\n\n42:46.400 --> 42:49.320\n gosh, this is taking a long time and it's very expensive.\n\n42:49.320 --> 42:51.240\n And then they start thinking,\n\n42:51.240 --> 42:52.640\n well, why am I labeling everything?\n\n42:52.640 --> 42:54.840\n I'm only, the machine's only making mistakes\n\n42:54.840 --> 42:56.040\n on those two classes.\n\n42:56.040 --> 42:56.880\n They're the hard ones.\n\n42:56.880 --> 42:58.880\n Maybe I'll just start labeling those two classes.\n\n42:58.880 --> 43:00.360\n And then you start thinking,\n\n43:00.360 --> 43:01.600\n well, why did I do that manually?\n\n43:01.600 --> 43:03.000\n Why can't I just get the system to tell me\n\n43:03.000 --> 43:05.080\n which things are going to be hardest?\n\n43:05.080 --> 43:08.320\n It's an obvious thing to do, but yeah,\n\n43:08.320 --> 43:11.440\n it's just like transfer learning.\n\n43:11.440 --> 43:14.160\n It's understudied and the academic world\n\n43:14.160 --> 43:17.480\n just has no reason to care about practical results.\n\n43:17.480 --> 43:18.320\n The funny thing is,\n\n43:18.320 --> 43:19.960\n like I've only really ever written one paper.\n\n43:19.960 --> 43:21.560\n I hate writing papers.\n\n43:21.560 --> 43:22.800\n And I didn't even write it.\n\n43:22.800 --> 43:24.640\n It was my colleague, Sebastian Ruder,\n\n43:24.640 --> 43:25.520\n who actually wrote it.\n\n43:25.520 --> 43:28.080\n I just did the research for it,\n\n43:28.080 --> 43:30.600\n but it was basically introducing transfer learning,\n\n43:30.600 --> 43:34.280\n successful transfer learning to NLP for the first time.\n\n43:34.280 --> 43:36.040\n The algorithm is called ULM fit.\n\n43:36.960 --> 43:41.960\n And it actually, I actually wrote it for the course,\n\n43:42.280 --> 43:43.680\n for the Fast AI course.\n\n43:43.680 --> 43:45.760\n I wanted to teach people NLP and I thought,\n\n43:45.760 --> 43:47.480\n I only want to teach people practical stuff.\n\n43:47.480 --> 43:50.520\n And I think the only practical stuff is transfer learning.\n\n43:50.520 --> 43:53.280\n And I couldn't find any examples of transfer learning in NLP.\n\n43:53.280 --> 43:54.520\n So I just did it.\n\n43:54.520 --> 43:57.280\n And I was shocked to find that as soon as I did it,\n\n43:57.280 --> 44:01.040\n which, you know, the basic prototype took a couple of days,\n\n44:01.040 --> 44:02.480\n smashed the state of the art\n\n44:02.480 --> 44:04.240\n on one of the most important data sets\n\n44:04.240 --> 44:06.680\n in a field that I knew nothing about.\n\n44:06.680 --> 44:10.320\n And I just thought, well, this is ridiculous.\n\n44:10.320 --> 44:13.760\n And so I spoke to Sebastian about it\n\n44:13.760 --> 44:17.640\n and he kindly offered to write it up, the results.\n\n44:17.640 --> 44:21.320\n And so it ended up being published in ACL,\n\n44:21.320 --> 44:25.520\n which is the top computational linguistics conference.\n\n44:25.520 --> 44:28.840\n So like people do actually care once you do it,\n\n44:28.840 --> 44:32.760\n but I guess it's difficult for maybe like junior researchers\n\n44:32.760 --> 44:36.560\n or like, I don't care whether I get citations\n\n44:36.560 --> 44:37.720\n or papers or whatever.\n\n44:37.720 --> 44:39.600\n There's nothing in my life that makes that important,\n\n44:39.600 --> 44:41.480\n which is why I've never actually bothered\n\n44:41.480 --> 44:43.000\n to write a paper myself.\n\n44:43.000 --> 44:43.960\n But for people who do,\n\n44:43.960 --> 44:48.960\n I guess they have to pick the kind of safe option,\n\n44:49.560 --> 44:52.240\n which is like, yeah, make a slight improvement\n\n44:52.240 --> 44:54.920\n on something that everybody's already working on.\n\n44:54.920 --> 44:58.240\n Yeah, nobody does anything interesting\n\n44:58.240 --> 45:01.160\n or succeeds in life with the safe option.\n\n45:01.160 --> 45:02.400\n Although, I mean, the nice thing is,\n\n45:02.400 --> 45:05.280\n nowadays everybody is now working on NLP transfer learning\n\n45:05.280 --> 45:09.720\n because since that time we've had GPT and GPT2 and BERT,\n\n45:09.720 --> 45:12.640\n and, you know, it's like, it's, so yeah,\n\n45:12.640 --> 45:15.360\n once you show that something's possible,\n\n45:15.360 --> 45:17.600\n everybody jumps in, I guess, so.\n\n45:17.600 --> 45:19.160\n I hope to be a part of,\n\n45:19.160 --> 45:20.640\n and I hope to see more innovation\n\n45:20.640 --> 45:22.120\n and active learning in the same way.\n\n45:22.120 --> 45:24.480\n I think transfer learning and active learning\n\n45:24.480 --> 45:27.320\n are fascinating, public, open work.\n\n45:27.320 --> 45:29.960\n I actually helped start a startup called Platform AI,\n\n45:29.960 --> 45:31.720\n which is really all about active learning.\n\n45:31.720 --> 45:35.840\n And yeah, it's been interesting trying to kind of see\n\n45:35.840 --> 45:37.760\n what research is out there and make the most of it.\n\n45:37.760 --> 45:39.160\n And there's basically none.\n\n45:39.160 --> 45:41.000\n So we've had to do all our own research.\n\n45:41.000 --> 45:42.960\n Once again, and just as you described.\n\n45:44.240 --> 45:47.640\n Can you tell the story of the Stanford competition,\n\n45:47.640 --> 45:51.480\n Dawn Bench, and FastAI's achievement on it?\n\n45:51.480 --> 45:54.280\n Sure, so something which I really enjoy\n\n45:54.280 --> 45:57.400\n is that I basically teach two courses a year,\n\n45:57.400 --> 45:59.640\n the Practical Deep Learning for Coders,\n\n45:59.640 --> 46:02.080\n which is kind of the introductory course,\n\n46:02.080 --> 46:04.000\n and then Cutting Edge Deep Learning for Coders,\n\n46:04.000 --> 46:06.880\n which is the kind of research level course.\n\n46:08.040 --> 46:10.360\n And while I teach those courses,\n\n46:10.360 --> 46:15.360\n I basically have a big office\n\n46:16.760 --> 46:18.520\n at the University of San Francisco,\n\n46:18.520 --> 46:19.760\n big enough for like 30 people.\n\n46:19.760 --> 46:22.080\n And I invite anybody, any student who wants to come\n\n46:22.080 --> 46:25.320\n and hang out with me while I build the course.\n\n46:25.320 --> 46:26.600\n And so generally it's full.\n\n46:26.600 --> 46:30.840\n And so we have 20 or 30 people in a big office\n\n46:30.840 --> 46:33.840\n with nothing to do but study deep learning.\n\n46:33.840 --> 46:35.880\n So it was during one of these times\n\n46:35.880 --> 46:37.320\n that somebody in the group said,\n\n46:37.320 --> 46:40.520\n oh, there's a thing called Dawn Bench\n\n46:40.520 --> 46:41.400\n that looks interesting.\n\n46:41.400 --> 46:42.760\n And I was like, what the hell is that?\n\n46:42.760 --> 46:44.040\n And they set out some competition\n\n46:44.040 --> 46:46.320\n to see how quickly you can train a model.\n\n46:46.320 --> 46:50.240\n Seems kind of, not exactly relevant to what we're doing,\n\n46:50.240 --> 46:51.320\n but it sounds like the kind of thing\n\n46:51.320 --> 46:52.400\n which you might be interested in.\n\n46:52.400 --> 46:53.320\n And I checked it out and I was like,\n\n46:53.320 --> 46:55.760\n oh crap, there's only 10 days till it's over.\n\n46:55.760 --> 46:58.000\n It's too late.\n\n46:58.000 --> 47:00.880\n And we're kind of busy trying to teach this course.\n\n47:00.880 --> 47:05.520\n But we're like, oh, it would make an interesting case study\n\n47:05.520 --> 47:06.360\n for the course.\n\n47:06.360 --> 47:08.160\n It's like, it's all the stuff we're already doing.\n\n47:08.160 --> 47:09.480\n Why don't we just put together\n\n47:09.480 --> 47:12.440\n our current best practices and ideas?\n\n47:12.440 --> 47:16.040\n So me and I guess about four students\n\n47:16.040 --> 47:17.520\n just decided to give it a go.\n\n47:17.520 --> 47:20.840\n And we focused on this small one called Cifar 10,\n\n47:20.840 --> 47:24.600\n which is little 32 by 32 pixel images.\n\n47:24.600 --> 47:26.080\n Can you say what Dawn Bench is?\n\n47:26.080 --> 47:28.600\n Yeah, so it's a competition to train a model\n\n47:28.600 --> 47:29.520\n as fast as possible.\n\n47:29.520 --> 47:30.960\n It was run by Stanford.\n\n47:30.960 --> 47:32.480\n And it's cheap as possible too.\n\n47:32.480 --> 47:34.280\n That's also another one for as cheap as possible.\n\n47:34.280 --> 47:36.400\n And there was a couple of categories,\n\n47:36.400 --> 47:38.120\n ImageNet and Cifar 10.\n\n47:38.120 --> 47:42.040\n So ImageNet is this big 1.3 million image thing\n\n47:42.040 --> 47:44.520\n that took a couple of days to train.\n\n47:45.400 --> 47:47.840\n Remember a friend of mine, Pete Warden,\n\n47:47.840 --> 47:50.160\n who's now at Google.\n\n47:51.240 --> 47:53.240\n I remember he told me how he trained ImageNet\n\n47:53.240 --> 47:55.680\n a few years ago when he basically like had this\n\n47:58.320 --> 47:59.720\n little granny flat out the back\n\n47:59.720 --> 48:01.880\n that he turned into his ImageNet training center.\n\n48:01.880 --> 48:03.760\n And he figured, you know, after like a year of work,\n\n48:03.760 --> 48:07.040\n he figured out how to train it in like 10 days or something.\n\n48:07.040 --> 48:08.440\n It's like, that was a big job.\n\n48:08.440 --> 48:10.480\n Whereas Cifar 10, at that time,\n\n48:10.480 --> 48:12.840\n you could train in a few hours.\n\n48:12.840 --> 48:14.480\n You know, it's much smaller and easier.\n\n48:14.480 --> 48:16.240\n So we thought we'd try Cifar 10.\n\n48:18.120 --> 48:23.120\n And yeah, I've really never done that before.\n\n48:23.760 --> 48:24.760\n Like I'd never really,\n\n48:24.760 --> 48:27.880\n like things like using more than one GPU at a time\n\n48:27.880 --> 48:29.800\n was something I tried to avoid.\n\n48:29.800 --> 48:32.120\n Cause to me, it's like very against the whole idea\n\n48:32.120 --> 48:35.000\n of accessibility is should better do things with one GPU.\n\n48:35.000 --> 48:38.000\n I mean, have you asked in the past before,\n\n48:38.000 --> 48:39.640\n after having accomplished something,\n\n48:39.640 --> 48:42.480\n how do I do this faster, much faster?\n\n48:42.480 --> 48:44.160\n Oh, always, but it's always, for me,\n\n48:44.160 --> 48:47.680\n it's always how do I make it much faster on a single GPU\n\n48:47.680 --> 48:50.360\n that a normal person could afford in their day to day life.\n\n48:50.360 --> 48:53.880\n It's not how could I do it faster by, you know,\n\n48:53.880 --> 48:55.280\n having a huge data center.\n\n48:55.280 --> 48:57.240\n Cause to me, it's all about like,\n\n48:57.240 --> 48:59.520\n as many people should better use something as possible\n\n48:59.520 --> 49:03.200\n without fussing around with infrastructure.\n\n49:04.080 --> 49:06.040\n So anyways, in this case it's like, well,\n\n49:06.040 --> 49:10.200\n we can use eight GPUs just by renting a AWS machine.\n\n49:10.200 --> 49:11.840\n So we thought we'd try that.\n\n49:11.840 --> 49:16.520\n And yeah, basically using the stuff we were already doing,\n\n49:16.520 --> 49:20.120\n we were able to get, you know, the speed,\n\n49:20.120 --> 49:22.680\n you know, within a few days we had the speed down to,\n\n49:23.840 --> 49:26.000\n I don't know, a very small number of minutes.\n\n49:26.000 --> 49:28.760\n I can't remember exactly how many minutes it was,\n\n49:28.760 --> 49:31.360\n but it might've been like 10 minutes or something.\n\n49:31.360 --> 49:32.880\n And so, yeah, we found ourselves\n\n49:32.880 --> 49:34.720\n at the top of the leaderboard easily\n\n49:34.720 --> 49:39.040\n for both time and money, which really shocked me\n\n49:39.040 --> 49:40.160\n cause the other people competing in this\n\n49:40.160 --> 49:41.880\n were like Google and Intel and stuff\n\n49:41.880 --> 49:43.880\n who I like know a lot more about this stuff\n\n49:43.880 --> 49:45.360\n than I think we do.\n\n49:45.360 --> 49:46.800\n So then we were emboldened.\n\n49:46.800 --> 49:50.640\n We thought let's try the ImageNet one too.\n\n49:50.640 --> 49:53.320\n I mean, it seemed way out of our league,\n\n49:53.320 --> 49:55.960\n but our goal was to get under 12 hours.\n\n49:55.960 --> 49:59.520\n And we did, which was really exciting.\n\n49:59.520 --> 50:01.400\n But we didn't put anything up on the leaderboard,\n\n50:01.400 --> 50:03.040\n but we were down to like 10 hours.\n\n50:03.040 --> 50:08.040\n But then Google put in like five hours or something\n\n50:09.960 --> 50:13.360\n and we're just like, oh, we're so screwed.\n\n50:13.360 --> 50:16.560\n But we kind of thought, we'll keep trying.\n\n50:16.560 --> 50:17.800\n You know, if Google can do it in five,\n\n50:17.800 --> 50:19.480\n I mean, Google did on five hours on something\n\n50:19.480 --> 50:23.280\n on like a TPU pod or something, like a lot of hardware.\n\n50:23.280 --> 50:26.360\n But we kind of like had a bunch of ideas to try.\n\n50:26.360 --> 50:28.720\n Like a really simple thing was\n\n50:28.720 --> 50:30.480\n why are we using these big images?\n\n50:30.480 --> 50:35.400\n They're like 224 or 256 by 256 pixels.\n\n50:35.400 --> 50:37.720\n You know, why don't we try smaller ones?\n\n50:37.720 --> 50:40.400\n And just to elaborate, there's a constraint\n\n50:40.400 --> 50:42.200\n on the accuracy that your trained model\n\n50:42.200 --> 50:43.040\n is supposed to achieve, right?\n\n50:43.040 --> 50:46.400\n Yeah, you gotta achieve 93%, I think it was,\n\n50:46.400 --> 50:49.200\n for ImageNet, exactly.\n\n50:49.200 --> 50:51.080\n Which is very tough, so you have to.\n\n50:51.080 --> 50:54.680\n Yeah, 93%, like they picked a good threshold.\n\n50:54.680 --> 50:56.920\n It was a little bit higher\n\n50:56.920 --> 51:00.840\n than what the most commonly used ResNet 50 model\n\n51:00.840 --> 51:03.360\n could achieve at that time.\n\n51:03.360 --> 51:08.200\n So yeah, so it's quite a difficult problem to solve.\n\n51:08.200 --> 51:09.720\n But yeah, we realized if we actually\n\n51:09.720 --> 51:12.360\n just use 64 by 64 images,\n\n51:14.680 --> 51:16.280\n it trained a pretty good model.\n\n51:16.280 --> 51:18.040\n And then we could take that same model\n\n51:18.040 --> 51:21.920\n and just give it a couple of epochs to learn 224 by 224 images.\n\n51:21.920 --> 51:24.520\n And it was basically already trained.\n\n51:24.520 --> 51:25.480\n It makes a lot of sense.\n\n51:25.480 --> 51:26.640\n Like if you teach somebody,\n\n51:26.640 --> 51:28.120\n like here's what a dog looks like\n\n51:28.120 --> 51:30.200\n and you show them low res versions,\n\n51:30.200 --> 51:33.600\n and then you say, here's a really clear picture of a dog,\n\n51:33.600 --> 51:35.960\n they already know what a dog looks like.\n\n51:35.960 --> 51:39.880\n So that like just, we jumped to the front\n\n51:39.880 --> 51:43.880\n and we ended up winning parts of that competition.\n\n51:43.880 --> 51:47.280\n We actually ended up doing a distributed version\n\n51:47.280 --> 51:49.560\n over multiple machines a couple of months later\n\n51:49.560 --> 51:51.120\n and ended up at the top of the leaderboard.\n\n51:51.120 --> 51:53.000\n We had 18 minutes.\n\n51:53.000 --> 51:53.840\n ImageNet.\n\n51:53.840 --> 51:55.640\n Yeah, and it was,\n\n51:55.640 --> 51:57.920\n and people have just kept on blasting through\n\n51:57.920 --> 52:00.000\n again and again since then, so.\n\n52:00.000 --> 52:03.200\n So what's your view on multi GPU\n\n52:03.200 --> 52:06.120\n or multiple machine training in general\n\n52:06.120 --> 52:09.520\n as a way to speed code up?\n\n52:09.520 --> 52:11.240\n I think it's largely a waste of time.\n\n52:11.240 --> 52:12.080\n Both of them.\n\n52:12.080 --> 52:13.960\n I think it's largely a waste of time.\n\n52:13.960 --> 52:15.840\n Both multi GPU on a single machine and.\n\n52:15.840 --> 52:17.640\n Yeah, particularly multi machines,\n\n52:17.640 --> 52:19.400\n cause it's just clunky.\n\n52:21.840 --> 52:25.320\n Multi GPUs is less clunky than it used to be,\n\n52:25.320 --> 52:28.520\n but to me anything that slows down your iteration speed\n\n52:28.520 --> 52:30.280\n is a waste of time.\n\n52:31.680 --> 52:33.840\n So you could maybe do your very last,\n\n52:34.960 --> 52:38.000\n you know, perfecting of the model on multi GPUs\n\n52:38.000 --> 52:40.040\n if you need to, but.\n\n52:40.040 --> 52:44.560\n So for example, I think doing stuff on ImageNet\n\n52:44.560 --> 52:46.000\n is generally a waste of time.\n\n52:46.000 --> 52:48.240\n Why test things on 1.3 million images?\n\n52:48.240 --> 52:51.080\n Most of us don't use 1.3 million images.\n\n52:51.080 --> 52:53.840\n And we've also done research that shows that\n\n52:53.840 --> 52:56.480\n doing things on a smaller subset of images\n\n52:56.480 --> 52:59.160\n gives you the same relative answers anyway.\n\n52:59.160 --> 53:02.080\n So from a research point of view, why waste that time?\n\n53:02.080 --> 53:06.120\n So actually I released a couple of new data sets recently.\n\n53:06.120 --> 53:07.720\n One is called ImageNet,\n\n53:07.720 --> 53:12.720\n the French ImageNet, which is a small subset of ImageNet,\n\n53:12.880 --> 53:15.040\n which is designed to be easy to classify.\n\n53:15.040 --> 53:17.240\n What's, how do you spell ImageNet?\n\n53:17.240 --> 53:19.200\n It's got an extra T and E at the end,\n\n53:19.200 --> 53:20.440\n cause it's very French.\n\n53:20.440 --> 53:24.680\n And then another one called ImageWolf,\n\n53:24.680 --> 53:29.680\n which is a subset of ImageNet that only contains dog breeds.\n\n53:29.960 --> 53:31.080\n And that's a hard one, right?\n\n53:31.080 --> 53:31.960\n That's a hard one.\n\n53:31.960 --> 53:34.120\n And I've discovered that if you just look at these\n\n53:34.120 --> 53:37.760\n two subsets, you can train things on a single GPU\n\n53:37.760 --> 53:39.080\n in 10 minutes.\n\n53:39.080 --> 53:42.040\n And the results you get are directly transferable\n\n53:42.040 --> 53:44.280\n to ImageNet nearly all the time.\n\n53:44.280 --> 53:46.360\n And so now I'm starting to see some researchers\n\n53:46.360 --> 53:48.960\n start to use these much smaller data sets.\n\n53:48.960 --> 53:51.120\n I so deeply love the way you think,\n\n53:51.120 --> 53:55.040\n because I think you might've written a blog post\n\n53:55.040 --> 54:00.040\n saying that sort of going these big data sets\n\n54:00.120 --> 54:03.840\n is encouraging people to not think creatively.\n\n54:03.840 --> 54:04.680\n Absolutely.\n\n54:04.680 --> 54:08.760\n So you're too, it sort of constrains you to train\n\n54:08.760 --> 54:09.800\n on large resources.\n\n54:09.800 --> 54:11.240\n And because you have these resources,\n\n54:11.240 --> 54:13.960\n you think more research will be better.\n\n54:13.960 --> 54:17.720\n And then you start, so like somehow you kill the creativity.\n\n54:17.720 --> 54:19.240\n Yeah, and even worse than that, Lex,\n\n54:19.240 --> 54:21.160\n I keep hearing from people who say,\n\n54:21.160 --> 54:23.320\n I decided not to get into deep learning\n\n54:23.320 --> 54:26.040\n because I don't believe it's accessible to people\n\n54:26.040 --> 54:28.480\n outside of Google to do useful work.\n\n54:28.480 --> 54:31.600\n So like I see a lot of people make an explicit decision\n\n54:31.600 --> 54:35.960\n to not learn this incredibly valuable tool\n\n54:35.960 --> 54:39.000\n because they've drunk the Google Koolaid,\n\n54:39.000 --> 54:40.680\n which is that only Google's big enough\n\n54:40.680 --> 54:42.400\n and smart enough to do it.\n\n54:42.400 --> 54:45.320\n And I just find that so disappointing and it's so wrong.\n\n54:45.320 --> 54:49.120\n And I think all of the major breakthroughs in AI\n\n54:49.120 --> 54:53.240\n in the next 20 years will be doable on a single GPU.\n\n54:53.240 --> 54:56.240\n Like I would say, my sense is all the big sort of.\n\n54:57.360 --> 54:58.200\n Well, let's put it this way.\n\n54:58.200 --> 55:00.120\n None of the big breakthroughs of the last 20 years\n\n55:00.120 --> 55:01.680\n have required multiple GPUs.\n\n55:01.680 --> 55:05.920\n So like batch norm, ReLU, Dropout.\n\n55:05.920 --> 55:08.040\n To demonstrate that there's something to them.\n\n55:08.040 --> 55:11.760\n Every one of them, none of them has required multiple GPUs.\n\n55:11.760 --> 55:15.760\n GANs, the original GANs didn't require multiple GPUs.\n\n55:15.760 --> 55:18.000\n Well, and we've actually recently shown\n\n55:18.000 --> 55:19.600\n that you don't even need GANs.\n\n55:19.600 --> 55:24.600\n So we've developed GAN level outcomes without needing GANs.\n\n55:24.640 --> 55:26.840\n And we can now do it with, again,\n\n55:26.840 --> 55:27.920\n by using transfer learning,\n\n55:27.920 --> 55:30.200\n we can do it in a couple of hours on a single GPU.\n\n55:30.200 --> 55:31.600\n You're just using a generator model\n\n55:31.600 --> 55:32.960\n without the adversarial part?\n\n55:32.960 --> 55:35.680\n Yeah, so we've found loss functions\n\n55:35.680 --> 55:38.640\n that work super well without the adversarial part.\n\n55:38.640 --> 55:41.800\n And then one of our students, a guy called Jason Antich,\n\n55:41.800 --> 55:44.600\n has created a system called dealtify,\n\n55:44.600 --> 55:47.240\n which uses this technique to colorize\n\n55:47.240 --> 55:48.800\n old black and white movies.\n\n55:48.800 --> 55:50.440\n You can do it on a single GPU,\n\n55:50.440 --> 55:52.840\n colorize a whole movie in a couple of hours.\n\n55:52.840 --> 55:56.040\n And one of the things that Jason and I did together\n\n55:56.040 --> 56:00.400\n was we figured out how to add a little bit of GAN\n\n56:00.400 --> 56:02.920\n at the very end, which it turns out for colorization\n\n56:02.920 --> 56:05.920\n makes it just a bit brighter and nicer.\n\n56:05.920 --> 56:07.880\n And then Jason did masses of experiments\n\n56:07.880 --> 56:09.960\n to figure out exactly how much to do,\n\n56:09.960 --> 56:12.760\n but it's still all done on his home machine\n\n56:12.760 --> 56:15.320\n on a single GPU in his lounge room.\n\n56:15.320 --> 56:19.160\n And if you think about colorizing Hollywood movies,\n\n56:19.160 --> 56:21.680\n that sounds like something a huge studio would have to do,\n\n56:21.680 --> 56:25.160\n but he has the world's best results on this.\n\n56:25.160 --> 56:27.000\n There's this problem of microphones.\n\n56:27.000 --> 56:29.080\n We're just talking to microphones now.\n\n56:29.080 --> 56:32.520\n It's such a pain in the ass to have these microphones\n\n56:32.520 --> 56:34.360\n to get good quality audio.\n\n56:34.360 --> 56:36.680\n And I tried to see if it's possible to plop down\n\n56:36.680 --> 56:39.200\n a bunch of cheap sensors and reconstruct\n\n56:39.200 --> 56:41.840\n higher quality audio from multiple sources.\n\n56:41.840 --> 56:45.160\n Because right now I haven't seen the work from,\n\n56:45.160 --> 56:47.440\n okay, we can say even expensive mics\n\n56:47.440 --> 56:50.040\n automatically combining audio from multiple sources\n\n56:50.040 --> 56:52.280\n to improve the combined audio.\n\n56:52.280 --> 56:53.120\n People haven't done that.\n\n56:53.120 --> 56:55.080\n And that feels like a learning problem.\n\n56:55.080 --> 56:56.840\n So hopefully somebody can.\n\n56:56.840 --> 56:58.800\n Well, I mean, it's evidently doable\n\n56:58.800 --> 57:01.400\n and it should have been done by now.\n\n57:01.400 --> 57:03.600\n I felt the same way about computational photography\n\n57:03.600 --> 57:05.240\n four years ago.\n\n57:05.240 --> 57:07.120\n Why are we investing in big lenses\n\n57:07.120 --> 57:10.640\n when three cheap lenses plus actually\n\n57:10.640 --> 57:13.760\n a little bit of intentional movement,\n\n57:13.760 --> 57:16.640\n so like take a few frames,\n\n57:16.640 --> 57:18.280\n gives you enough information\n\n57:18.280 --> 57:20.560\n to get excellent subpixel resolution,\n\n57:20.560 --> 57:22.440\n which particularly with deep learning,\n\n57:22.440 --> 57:25.840\n you would know exactly what you meant to be looking at.\n\n57:25.840 --> 57:28.160\n We can totally do the same thing with audio.\n\n57:28.160 --> 57:30.680\n I think it's madness that it hasn't been done yet.\n\n57:30.680 --> 57:33.280\n Is there progress on the photography company?\n\n57:33.280 --> 57:36.720\n Yeah, photography is basically standard now.\n\n57:36.720 --> 57:40.800\n So the Google Pixel Night Light,\n\n57:40.800 --> 57:42.120\n I don't know if you've ever tried it,\n\n57:42.120 --> 57:43.200\n but it's astonishing.\n\n57:43.200 --> 57:45.440\n You take a picture in almost pitch black\n\n57:45.440 --> 57:49.160\n and you get back a very high quality image.\n\n57:49.160 --> 57:51.480\n And it's not because of the lens.\n\n57:51.480 --> 57:53.440\n Same stuff with like adding the bokeh\n\n57:53.440 --> 57:55.800\n to the background blurring,\n\n57:55.800 --> 57:57.200\n it's done computationally.\n\n57:57.200 --> 57:58.600\n This is the pixel right here.\n\n57:58.600 --> 58:01.880\n Yeah, basically everybody now\n\n58:01.880 --> 58:05.000\n is doing most of the fanciest stuff\n\n58:05.000 --> 58:07.120\n on their phones with computational photography\n\n58:07.120 --> 58:08.680\n and also increasingly people are putting\n\n58:08.680 --> 58:11.800\n more than one lens on the back of the camera.\n\n58:11.800 --> 58:14.360\n So the same will happen for audio for sure.\n\n58:14.360 --> 58:16.480\n And there's applications in the audio side.\n\n58:16.480 --> 58:19.320\n If you look at an Alexa type device,\n\n58:19.320 --> 58:20.840\n most people I've seen,\n\n58:20.840 --> 58:22.320\n especially I worked at Google before,\n\n58:22.320 --> 58:25.920\n when you look at noise background removal,\n\n58:25.920 --> 58:29.560\n you don't think of multiple sources of audio.\n\n58:29.560 --> 58:31.040\n You don't play with that as much\n\n58:31.040 --> 58:31.880\n as I would hope people would.\n\n58:31.880 --> 58:33.600\n But I mean, you can still do it even with one.\n\n58:33.600 --> 58:36.120\n Like again, not much work's been done in this area.\n\n58:36.120 --> 58:39.000\n So we're actually gonna be releasing an audio library soon,\n\n58:39.000 --> 58:41.040\n which hopefully will encourage development of this\n\n58:41.040 --> 58:43.160\n because it's so underused.\n\n58:43.160 --> 58:46.480\n The basic approach we used for our super resolution\n\n58:46.480 --> 58:48.640\n and which Jason uses for dealtify\n\n58:48.640 --> 58:50.960\n of generating high quality images,\n\n58:50.960 --> 58:53.440\n the exact same approach would work for audio.\n\n58:53.440 --> 58:54.440\n No one's done it yet,\n\n58:54.440 --> 58:57.120\n but it would be a couple of months work.\n\n58:57.120 --> 59:00.440\n Okay, also learning rate in terms of Dawn Bench.\n\n59:01.560 --> 59:03.520\n There's some magic on learning rate\n\n59:03.520 --> 59:05.720\n that you played around with that's kind of interesting.\n\n59:05.720 --> 59:06.960\n Yeah, so this is all work that came\n\n59:06.960 --> 59:09.280\n from a guy called Leslie Smith.\n\n59:09.280 --> 59:12.720\n Leslie's a researcher who, like us,\n\n59:12.720 --> 59:15.800\n cares a lot about just the practicalities\n\n59:15.800 --> 59:20.360\n of training neural networks quickly and accurately,\n\n59:20.360 --> 59:22.120\n which I think is what everybody should care about,\n\n59:22.120 --> 59:23.760\n but almost nobody does.\n\n59:24.920 --> 59:28.080\n And he discovered something very interesting,\n\n59:28.080 --> 59:29.760\n which he calls super convergence,\n\n59:29.760 --> 59:31.240\n which is there are certain networks\n\n59:31.240 --> 59:33.320\n that with certain settings of high parameters\n\n59:33.320 --> 59:37.080\n could suddenly be trained 10 times faster\n\n59:37.080 --> 59:39.480\n by using a 10 times higher learning rate.\n\n59:39.480 --> 59:43.640\n Now, no one published that paper\n\n59:43.640 --> 59:48.640\n because it's not an area of kind of active research\n\n59:49.520 --> 59:50.440\n in the academic world.\n\n59:50.440 --> 59:52.640\n No academics recognize that this is important.\n\n59:52.640 --> 59:56.080\n And also deep learning in academia\n\n59:56.080 --> 59:59.840\n is not considered a experimental science.\n\n59:59.840 --> 1:00:02.440\n So unlike in physics where you could say like,\n\n1:00:02.440 --> 1:00:05.360\n I just saw a subatomic particle do something\n\n1:00:05.360 --> 1:00:07.240\n which the theory doesn't explain,\n\n1:00:07.240 --> 1:00:10.440\n you could publish that without an explanation.\n\n1:00:10.440 --> 1:00:11.840\n And then in the next 60 years,\n\n1:00:11.840 --> 1:00:14.080\n people can try to work out how to explain it.\n\n1:00:14.080 --> 1:00:16.120\n We don't allow this in the deep learning world.\n\n1:00:16.120 --> 1:00:19.520\n So it's literally impossible for Leslie\n\n1:00:19.520 --> 1:00:21.600\n to publish a paper that says,\n\n1:00:21.600 --> 1:00:23.520\n I've just seen something amazing happen.\n\n1:00:23.520 --> 1:00:25.640\n This thing trained 10 times faster than it should have.\n\n1:00:25.640 --> 1:00:27.360\n I don't know why.\n\n1:00:27.360 --> 1:00:28.520\n And so the reviewers were like,\n\n1:00:28.520 --> 1:00:30.280\n well, you can't publish that because you don't know why.\n\n1:00:30.280 --> 1:00:31.120\n So anyway.\n\n1:00:31.120 --> 1:00:32.160\n That's important to pause on\n\n1:00:32.160 --> 1:00:34.280\n because there's so many discoveries\n\n1:00:34.280 --> 1:00:36.120\n that would need to start like that.\n\n1:00:36.120 --> 1:00:39.240\n Every other scientific field I know of works that way.\n\n1:00:39.240 --> 1:00:43.520\n I don't know why ours is uniquely disinterested\n\n1:00:43.520 --> 1:00:47.720\n in publishing unexplained experimental results,\n\n1:00:47.720 --> 1:00:48.680\n but there it is.\n\n1:00:48.680 --> 1:00:49.920\n So it wasn't published.\n\n1:00:51.200 --> 1:00:52.560\n Having said that,\n\n1:00:52.560 --> 1:00:56.840\n I read a lot more unpublished papers than published papers\n\n1:00:56.840 --> 1:01:00.040\n because that's where you find the interesting insights.\n\n1:01:00.040 --> 1:01:02.680\n So I absolutely read this paper.\n\n1:01:02.680 --> 1:01:04.520\n And I was just like,\n\n1:01:04.520 --> 1:01:08.920\n this is astonishingly mind blowing and weird\n\n1:01:08.920 --> 1:01:09.760\n and awesome.\n\n1:01:09.760 --> 1:01:12.400\n And like, why isn't everybody only talking about this?\n\n1:01:12.400 --> 1:01:15.480\n Because like, if you can train these things 10 times faster,\n\n1:01:15.480 --> 1:01:16.720\n they also generalize better\n\n1:01:16.720 --> 1:01:18.800\n because you're doing less epochs,\n\n1:01:18.800 --> 1:01:20.080\n which means you look at the data less,\n\n1:01:20.080 --> 1:01:21.400\n you get better accuracy.\n\n1:01:22.360 --> 1:01:24.640\n So I've been kind of studying that ever since.\n\n1:01:24.640 --> 1:01:28.520\n And eventually Leslie kind of figured out\n\n1:01:28.520 --> 1:01:30.120\n a lot of how to get this done.\n\n1:01:30.120 --> 1:01:32.240\n And we added minor tweaks.\n\n1:01:32.240 --> 1:01:33.600\n And a big part of the trick\n\n1:01:33.600 --> 1:01:36.440\n is starting at a very low learning rate,\n\n1:01:36.440 --> 1:01:37.880\n very gradually increasing it.\n\n1:01:37.880 --> 1:01:39.800\n So as you're training your model,\n\n1:01:39.800 --> 1:01:42.120\n you would take very small steps at the start\n\n1:01:42.120 --> 1:01:44.040\n and you gradually make them bigger and bigger\n\n1:01:44.040 --> 1:01:46.400\n until eventually you're taking much bigger steps\n\n1:01:46.400 --> 1:01:48.160\n than anybody thought was possible.\n\n1:01:49.400 --> 1:01:51.120\n There's a few other little tricks to make it work,\n\n1:01:51.120 --> 1:01:55.240\n but basically we can reliably get super convergence.\n\n1:01:55.240 --> 1:01:56.600\n And so for the Dawn Bench thing,\n\n1:01:56.600 --> 1:01:59.280\n we were using just much higher learning rates\n\n1:01:59.280 --> 1:02:02.200\n than people expected to work.\n\n1:02:02.200 --> 1:02:03.840\n What do you think the future of,\n\n1:02:03.840 --> 1:02:04.880\n I mean, it makes so much sense\n\n1:02:04.880 --> 1:02:07.600\n for that to be a critical hyperparameter learning rate\n\n1:02:07.600 --> 1:02:08.640\n that you vary.\n\n1:02:08.640 --> 1:02:09.520\n What do you think the future\n\n1:02:09.520 --> 1:02:13.480\n of learning rate magic looks like?\n\n1:02:13.480 --> 1:02:14.920\n Well, there's been a lot of great work\n\n1:02:14.920 --> 1:02:17.400\n in the last 12 months in this area.\n\n1:02:17.400 --> 1:02:20.160\n And people are increasingly realizing that optimize,\n\n1:02:20.160 --> 1:02:23.120\n like we just have no idea really how optimizers work.\n\n1:02:23.120 --> 1:02:25.840\n And the combination of weight decay,\n\n1:02:25.840 --> 1:02:27.480\n which is how we regularize optimizers,\n\n1:02:27.480 --> 1:02:29.200\n and the learning rate,\n\n1:02:29.200 --> 1:02:31.520\n and then other things like the epsilon we use\n\n1:02:31.520 --> 1:02:32.760\n in the Adam optimizer,\n\n1:02:32.760 --> 1:02:36.560\n they all work together in weird ways.\n\n1:02:36.560 --> 1:02:38.560\n And different parts of the model,\n\n1:02:38.560 --> 1:02:40.480\n this is another thing we've done a lot of work on\n\n1:02:40.480 --> 1:02:43.480\n is research into how different parts of the model\n\n1:02:43.480 --> 1:02:46.640\n should be trained at different rates in different ways.\n\n1:02:46.640 --> 1:02:49.040\n So we do something we call discriminative learning rates,\n\n1:02:49.040 --> 1:02:50.160\n which is really important,\n\n1:02:50.160 --> 1:02:51.960\n particularly for transfer learning.\n\n1:02:53.240 --> 1:02:54.920\n So really, I think in the last 12 months,\n\n1:02:54.920 --> 1:02:55.880\n a lot of people have realized\n\n1:02:55.880 --> 1:02:57.400\n that all this stuff is important.\n\n1:02:57.400 --> 1:03:00.000\n There's been a lot of great work coming out\n\n1:03:00.000 --> 1:03:03.680\n and we're starting to see algorithms appear,\n\n1:03:03.680 --> 1:03:06.920\n which have very, very few dials, if any,\n\n1:03:06.920 --> 1:03:07.960\n that you have to touch.\n\n1:03:07.960 --> 1:03:09.280\n So I think what's gonna happen\n\n1:03:09.280 --> 1:03:10.440\n is the idea of a learning rate,\n\n1:03:10.440 --> 1:03:12.840\n well, it almost already has disappeared\n\n1:03:12.840 --> 1:03:14.360\n in the latest research.\n\n1:03:14.360 --> 1:03:18.240\n And instead, it's just like we know enough\n\n1:03:18.240 --> 1:03:22.600\n about how to interpret the gradients\n\n1:03:22.600 --> 1:03:23.840\n and the change of gradients we see\n\n1:03:23.840 --> 1:03:25.320\n to know how to set every parameter\n\n1:03:25.320 --> 1:03:26.160\n in an optimal way.\n\n1:03:26.160 --> 1:03:30.840\n So you see the future of deep learning\n\n1:03:30.840 --> 1:03:34.560\n where really, where's the input of a human expert needed?\n\n1:03:34.560 --> 1:03:36.520\n Well, hopefully the input of a human expert\n\n1:03:36.520 --> 1:03:38.760\n will be almost entirely unneeded\n\n1:03:38.760 --> 1:03:40.440\n from the deep learning point of view.\n\n1:03:40.440 --> 1:03:43.480\n So again, like Google's approach to this\n\n1:03:43.480 --> 1:03:46.000\n is to try and use thousands of times more compute\n\n1:03:46.000 --> 1:03:49.400\n to run lots and lots of models at the same time\n\n1:03:49.400 --> 1:03:51.080\n and hope that one of them is good.\n\n1:03:51.080 --> 1:03:51.920\n AutoML kind of thing?\n\n1:03:51.920 --> 1:03:54.520\n Yeah, AutoML kind of stuff, which I think is insane.\n\n1:03:56.720 --> 1:03:59.600\n When you better understand the mechanics\n\n1:03:59.600 --> 1:04:01.680\n of how models learn,\n\n1:04:01.680 --> 1:04:03.800\n you don't have to try a thousand different models\n\n1:04:03.800 --> 1:04:05.640\n to find which one happens to work the best.\n\n1:04:05.640 --> 1:04:08.120\n You can just jump straight to the best one,\n\n1:04:08.120 --> 1:04:09.720\n which means that it's more accessible\n\n1:04:09.720 --> 1:04:12.720\n in terms of compute, cheaper,\n\n1:04:12.720 --> 1:04:14.920\n and also with less hyperparameters to set,\n\n1:04:14.920 --> 1:04:16.800\n it means you don't need deep learning experts\n\n1:04:16.800 --> 1:04:19.320\n to train your deep learning model for you,\n\n1:04:19.320 --> 1:04:22.280\n which means that domain experts can do more of the work,\n\n1:04:22.280 --> 1:04:24.960\n which means that now you can focus the human time\n\n1:04:24.960 --> 1:04:28.320\n on the kind of interpretation, the data gathering,\n\n1:04:28.320 --> 1:04:31.360\n identifying model errors and stuff like that.\n\n1:04:31.360 --> 1:04:32.840\n Yeah, the data side.\n\n1:04:32.840 --> 1:04:34.720\n How often do you work with data these days\n\n1:04:34.720 --> 1:04:37.800\n in terms of the cleaning, looking at it?\n\n1:04:37.800 --> 1:04:41.120\n Like Darwin looked at different species\n\n1:04:41.120 --> 1:04:42.880\n while traveling about.\n\n1:04:42.880 --> 1:04:45.000\n Do you look at data?\n\n1:04:45.000 --> 1:04:48.040\n Have you in your roots in Kaggle?\n\n1:04:48.040 --> 1:04:48.880\n Always, yeah.\n\n1:04:48.880 --> 1:04:49.720\n Look at data.\n\n1:04:49.720 --> 1:04:51.320\n Yeah, I mean, it's a key part of our course.\n\n1:04:51.320 --> 1:04:53.480\n It's like before we train a model in the course,\n\n1:04:53.480 --> 1:04:55.200\n we see how to look at the data.\n\n1:04:55.200 --> 1:04:56.520\n And then the first thing we do\n\n1:04:56.520 --> 1:04:57.920\n after we train our first model,\n\n1:04:57.920 --> 1:05:00.520\n which we fine tune an ImageNet model for five minutes.\n\n1:05:00.520 --> 1:05:02.240\n And then the thing we immediately do after that\n\n1:05:02.240 --> 1:05:05.800\n is we learn how to analyze the results of the model\n\n1:05:05.800 --> 1:05:08.920\n by looking at examples of misclassified images\n\n1:05:08.920 --> 1:05:10.880\n and looking at a classification matrix,\n\n1:05:10.880 --> 1:05:15.080\n and then doing research on Google\n\n1:05:15.080 --> 1:05:18.120\n to learn about the kinds of things that it's misclassifying.\n\n1:05:18.120 --> 1:05:19.520\n So to me, one of the really cool things\n\n1:05:19.520 --> 1:05:21.840\n about machine learning models in general\n\n1:05:21.840 --> 1:05:24.320\n is that when you interpret them,\n\n1:05:24.320 --> 1:05:25.400\n they tell you about things like\n\n1:05:25.400 --> 1:05:27.320\n what are the most important features,\n\n1:05:27.320 --> 1:05:29.360\n which groups are you misclassifying,\n\n1:05:29.360 --> 1:05:32.440\n and they help you become a domain expert more quickly\n\n1:05:32.440 --> 1:05:34.840\n because you can focus your time on the bits\n\n1:05:34.840 --> 1:05:38.680\n that the model is telling you is important.\n\n1:05:38.680 --> 1:05:40.720\n So it lets you deal with things like data leakage,\n\n1:05:40.720 --> 1:05:41.720\n for example, if it says,\n\n1:05:41.720 --> 1:05:45.640\n oh, the main feature I'm looking at is customer ID.\n\n1:05:45.640 --> 1:05:47.600\n And you're like, oh, customer ID should be predictive.\n\n1:05:47.600 --> 1:05:50.640\n And then you can talk to the people\n\n1:05:50.640 --> 1:05:53.240\n that manage customer IDs and they'll tell you like,\n\n1:05:53.240 --> 1:05:57.480\n oh yes, as soon as a customer's application is accepted,\n\n1:05:57.480 --> 1:06:01.160\n we add a one on the end of their customer ID or something.\n\n1:06:01.160 --> 1:06:03.720\n So yeah, looking at data,\n\n1:06:03.720 --> 1:06:06.000\n particularly from the lens of which parts of the data\n\n1:06:06.000 --> 1:06:09.360\n the model says is important is super important.\n\n1:06:09.360 --> 1:06:12.920\n Yeah, and using the model to almost debug the data\n\n1:06:12.920 --> 1:06:14.240\n to learn more about the data.\n\n1:06:14.240 --> 1:06:15.080\n Exactly.\n\n1:06:16.800 --> 1:06:18.600\n What are the different cloud options\n\n1:06:18.600 --> 1:06:20.160\n for training your own networks?\n\n1:06:20.160 --> 1:06:21.960\n Last question related to DawnBench.\n\n1:06:21.960 --> 1:06:24.200\n Well, it's part of a lot of the work you do,\n\n1:06:24.200 --> 1:06:27.240\n but from a perspective of performance,\n\n1:06:27.240 --> 1:06:29.440\n I think you've written this in a blog post.\n\n1:06:29.440 --> 1:06:32.720\n There's AWS, there's TPU from Google.\n\n1:06:32.720 --> 1:06:33.560\n What's your sense?\n\n1:06:33.560 --> 1:06:34.480\n What the future holds?\n\n1:06:34.480 --> 1:06:37.360\n What would you recommend now in terms of training?\n\n1:06:37.360 --> 1:06:39.440\n So from a hardware point of view,\n\n1:06:40.520 --> 1:06:45.320\n Google's TPUs and the best Nvidia GPUs are similar.\n\n1:06:45.320 --> 1:06:47.920\n I mean, maybe the TPUs are like 30% faster,\n\n1:06:47.920 --> 1:06:49.920\n but they're also much harder to program.\n\n1:06:49.920 --> 1:06:54.640\n There isn't a clear leader in terms of hardware right now,\n\n1:06:54.640 --> 1:06:56.240\n although much more importantly,\n\n1:06:56.240 --> 1:06:59.520\n the Nvidia GPUs are much more programmable.\n\n1:06:59.520 --> 1:07:00.920\n They've got much more written for all of them.\n\n1:07:00.920 --> 1:07:03.120\n So like that's the clear leader for me\n\n1:07:03.120 --> 1:07:04.360\n and where I would spend my time\n\n1:07:04.360 --> 1:07:06.840\n as a researcher and practitioner.\n\n1:07:08.560 --> 1:07:10.200\n But then in terms of the platform,\n\n1:07:12.160 --> 1:07:16.200\n I mean, we're super lucky now with stuff like Google GCP,\n\n1:07:16.200 --> 1:07:21.200\n Google Cloud, and AWS that you can access a GPU\n\n1:07:21.480 --> 1:07:23.320\n pretty quickly and easily.\n\n1:07:25.400 --> 1:07:28.040\n But I mean, for AWS, it's still too hard.\n\n1:07:28.040 --> 1:07:33.040\n Like you have to find an AMI and get the instance running\n\n1:07:33.720 --> 1:07:37.040\n and then install the software you want and blah, blah, blah.\n\n1:07:37.040 --> 1:07:40.720\n GCP is currently the best way to get started\n\n1:07:40.720 --> 1:07:42.280\n on a full server environment\n\n1:07:42.280 --> 1:07:46.360\n because they have a fantastic fast AI in PyTorch ready\n\n1:07:46.360 --> 1:07:51.040\n to go instance, which has all the courses preinstalled.\n\n1:07:51.040 --> 1:07:53.000\n It has Jupyter Notebook pre running.\n\n1:07:53.000 --> 1:07:55.880\n Jupyter Notebook is this wonderful\n\n1:07:55.880 --> 1:07:57.560\n interactive computing system,\n\n1:07:57.560 --> 1:08:00.360\n which everybody basically should be using\n\n1:08:00.360 --> 1:08:02.880\n for any kind of data driven research.\n\n1:08:02.880 --> 1:08:04.440\n But then even better than that,\n\n1:08:05.600 --> 1:08:09.480\n there are platforms like Salamander, which we own\n\n1:08:09.480 --> 1:08:13.560\n and Paperspace, where literally you click a single button\n\n1:08:13.560 --> 1:08:17.200\n and it pops up a Jupyter Notebook straight away\n\n1:08:17.200 --> 1:08:22.200\n without any kind of installation or anything.\n\n1:08:22.200 --> 1:08:25.800\n And all the course notebooks are all preinstalled.\n\n1:08:25.800 --> 1:08:28.560\n So like for me, this is one of the things\n\n1:08:28.560 --> 1:08:32.920\n we spent a lot of time kind of curating and working on.\n\n1:08:34.200 --> 1:08:35.960\n Because when we first started our courses,\n\n1:08:35.960 --> 1:08:39.600\n the biggest problem was people dropped out of lesson one\n\n1:08:39.600 --> 1:08:42.680\n because they couldn't get an AWS instance running.\n\n1:08:42.680 --> 1:08:44.880\n So things are so much better now.\n\n1:08:44.880 --> 1:08:47.800\n And like we actually have, if you go to course.fast.ai,\n\n1:08:47.800 --> 1:08:49.680\n the first thing it says is here's how to get started\n\n1:08:49.680 --> 1:08:50.520\n with your GPU.\n\n1:08:50.520 --> 1:08:52.120\n And there's like, you just click on the link\n\n1:08:52.120 --> 1:08:55.360\n and you click start and you're going.\n\n1:08:55.360 --> 1:08:56.280\n You'll go GCP.\n\n1:08:56.280 --> 1:08:58.800\n I have to confess, I've never used the Google GCP.\n\n1:08:58.800 --> 1:09:01.640\n Yeah, GCP gives you $300 of compute for free,\n\n1:09:01.640 --> 1:09:03.920\n which is really nice.\n\n1:09:03.920 --> 1:09:07.280\n But as I say, Salamander and Paperspace\n\n1:09:07.280 --> 1:09:09.440\n are even easier still.\n\n1:09:09.440 --> 1:09:10.960\n Okay.\n\n1:09:10.960 --> 1:09:15.080\n So from the perspective of deep learning frameworks,\n\n1:09:15.080 --> 1:09:18.440\n you work with fast.ai, if you go to this framework,\n\n1:09:18.440 --> 1:09:21.240\n and PyTorch and TensorFlow.\n\n1:09:21.240 --> 1:09:25.800\n What are the strengths of each platform in your perspective?\n\n1:09:25.800 --> 1:09:28.760\n So in terms of what we've done our research on\n\n1:09:28.760 --> 1:09:30.240\n and taught in our course,\n\n1:09:30.240 --> 1:09:34.360\n we started with Theano and Keras,\n\n1:09:34.360 --> 1:09:38.080\n and then we switched to TensorFlow and Keras,\n\n1:09:38.080 --> 1:09:40.360\n and then we switched to PyTorch,\n\n1:09:40.360 --> 1:09:42.960\n and then we switched to PyTorch and fast.ai.\n\n1:09:42.960 --> 1:09:47.560\n And that kind of reflects a growth and development\n\n1:09:47.560 --> 1:09:50.960\n of the ecosystem of deep learning libraries.\n\n1:09:52.560 --> 1:09:57.080\n Theano and TensorFlow were great,\n\n1:09:57.080 --> 1:10:00.800\n but were much harder to teach and to do research\n\n1:10:00.800 --> 1:10:02.800\n and development on because they define\n\n1:10:02.800 --> 1:10:05.080\n what's called a computational graph upfront,\n\n1:10:05.080 --> 1:10:07.520\n a static graph, where you basically have to say,\n\n1:10:07.520 --> 1:10:10.880\n here are all the things that I'm gonna eventually do\n\n1:10:10.880 --> 1:10:13.240\n in my model, and then later on you say,\n\n1:10:13.240 --> 1:10:15.120\n okay, do those things with this data.\n\n1:10:15.120 --> 1:10:17.160\n And you can't like debug them,\n\n1:10:17.160 --> 1:10:18.560\n you can't do them step by step,\n\n1:10:18.560 --> 1:10:20.160\n you can't program them interactively\n\n1:10:20.160 --> 1:10:22.320\n in a Jupyter notebook and so forth.\n\n1:10:22.320 --> 1:10:23.760\n PyTorch was not the first,\n\n1:10:23.760 --> 1:10:26.880\n but PyTorch was certainly the strongest entrant\n\n1:10:26.880 --> 1:10:28.720\n to come along and say, let's not do it that way,\n\n1:10:28.720 --> 1:10:30.320\n let's just use normal Python.\n\n1:10:31.400 --> 1:10:32.920\n And everything you know about in Python\n\n1:10:32.920 --> 1:10:35.280\n is just gonna work, and we'll figure out\n\n1:10:35.280 --> 1:10:39.360\n how to make that run on the GPU as and when necessary.\n\n1:10:40.840 --> 1:10:44.640\n That turned out to be a huge leap\n\n1:10:44.640 --> 1:10:46.840\n in terms of what we could do with our research\n\n1:10:46.840 --> 1:10:48.840\n and what we could do with our teaching.\n\n1:10:49.760 --> 1:10:51.240\n Because it wasn't limiting.\n\n1:10:51.240 --> 1:10:52.760\n Yeah, I mean, it was critical for us\n\n1:10:52.760 --> 1:10:53.880\n for something like DawnBench\n\n1:10:53.880 --> 1:10:55.960\n to be able to rapidly try things.\n\n1:10:55.960 --> 1:10:57.840\n It's just so much harder to be a researcher\n\n1:10:57.840 --> 1:11:00.520\n and practitioner when you have to do everything upfront\n\n1:11:00.520 --> 1:11:02.200\n and you can't inspect it.\n\n1:11:03.400 --> 1:11:07.960\n Problem with PyTorch is it's not at all accessible\n\n1:11:07.960 --> 1:11:10.160\n to newcomers because you have to like\n\n1:11:10.160 --> 1:11:12.920\n write your own training loop and manage the gradients\n\n1:11:12.920 --> 1:11:14.120\n and all this stuff.\n\n1:11:15.680 --> 1:11:17.880\n And it's also like not great for researchers\n\n1:11:17.880 --> 1:11:19.640\n because you're spending your time dealing\n\n1:11:19.640 --> 1:11:21.640\n with all this boilerplate and overhead\n\n1:11:21.640 --> 1:11:23.880\n rather than thinking about your algorithm.\n\n1:11:23.880 --> 1:11:27.760\n So we ended up writing this very multi layered API\n\n1:11:27.760 --> 1:11:29.960\n that at the top level, you can train\n\n1:11:29.960 --> 1:11:31.400\n a state of the art neural network\n\n1:11:31.400 --> 1:11:32.560\n in three lines of code.\n\n1:11:33.640 --> 1:11:35.120\n And which kind of talks to an API,\n\n1:11:35.120 --> 1:11:36.680\n which talks to an API, which talks to an API,\n\n1:11:36.680 --> 1:11:38.880\n which like you can dive into at any level\n\n1:11:38.880 --> 1:11:42.720\n and get progressively closer to the machine\n\n1:11:42.720 --> 1:11:44.160\n kind of levels of control.\n\n1:11:45.360 --> 1:11:47.480\n And this is the fast AI library.\n\n1:11:47.480 --> 1:11:51.840\n That's been critical for us and for our students\n\n1:11:51.840 --> 1:11:54.200\n and for lots of people that have won deep learning\n\n1:11:54.200 --> 1:11:57.440\n competitions with it and written academic papers with it.\n\n1:11:58.400 --> 1:12:00.640\n It's made a big difference.\n\n1:12:00.640 --> 1:12:03.000\n We're still limited though by Python.\n\n1:12:03.920 --> 1:12:06.400\n And particularly this problem with things like\n\n1:12:06.400 --> 1:12:11.400\n recurrent neural nets say where you just can't change things\n\n1:12:11.400 --> 1:12:15.640\n unless you accept it going so slowly that it's impractical.\n\n1:12:15.640 --> 1:12:18.320\n So in the latest incarnation of the course\n\n1:12:18.320 --> 1:12:20.880\n and with some of the research we're now starting to do,\n\n1:12:20.880 --> 1:12:24.520\n we're starting to do stuff, some stuff in Swift.\n\n1:12:24.520 --> 1:12:28.040\n I think we're three years away from that\n\n1:12:28.040 --> 1:12:31.040\n being super practical, but I'm in no hurry.\n\n1:12:31.040 --> 1:12:34.280\n I'm very happy to invest the time to get there.\n\n1:12:35.520 --> 1:12:39.040\n But with that, we actually already have a nascent version\n\n1:12:39.040 --> 1:12:42.520\n of the fast AI library for vision running\n\n1:12:42.520 --> 1:12:44.760\n on Swift and TensorFlow.\n\n1:12:44.760 --> 1:12:48.040\n Cause a Python for TensorFlow is not gonna cut it.\n\n1:12:48.040 --> 1:12:49.960\n It's just a disaster.\n\n1:12:49.960 --> 1:12:53.000\n What they did was they tried to replicate\n\n1:12:53.960 --> 1:12:57.120\n the bits that people were saying they like about PyTorch,\n\n1:12:57.120 --> 1:12:59.200\n this kind of interactive computation,\n\n1:12:59.200 --> 1:13:00.640\n but they didn't actually change\n\n1:13:00.640 --> 1:13:03.920\n their foundational runtime components.\n\n1:13:03.920 --> 1:13:06.640\n So they kind of added this like syntax sugar\n\n1:13:06.640 --> 1:13:08.400\n they call TF Eager, TensorFlow Eager,\n\n1:13:08.400 --> 1:13:10.920\n which makes it look a lot like PyTorch,\n\n1:13:10.920 --> 1:13:12.760\n but it's 10 times slower than PyTorch\n\n1:13:12.760 --> 1:13:16.400\n to actually do a step.\n\n1:13:16.400 --> 1:13:20.200\n So because they didn't invest the time in like retooling\n\n1:13:20.200 --> 1:13:23.280\n the foundations, cause their code base is so horribly\n\n1:13:23.280 --> 1:13:24.120\n complex.\n\n1:13:24.120 --> 1:13:25.280\n Yeah, I think it's probably very difficult\n\n1:13:25.280 --> 1:13:26.440\n to do that kind of retooling.\n\n1:13:26.440 --> 1:13:28.640\n Yeah, well, particularly the way TensorFlow was written,\n\n1:13:28.640 --> 1:13:31.480\n it was written by a lot of people very quickly\n\n1:13:31.480 --> 1:13:33.320\n in a very disorganized way.\n\n1:13:33.320 --> 1:13:35.000\n So like when you actually look in the code,\n\n1:13:35.000 --> 1:13:37.080\n as I do often, I'm always just like,\n\n1:13:37.080 --> 1:13:38.840\n Oh God, what were they thinking?\n\n1:13:38.840 --> 1:13:41.400\n It's just, it's pretty awful.\n\n1:13:41.400 --> 1:13:45.240\n So I'm really extremely negative\n\n1:13:45.240 --> 1:13:50.080\n about the potential future for Python for TensorFlow.\n\n1:13:50.080 --> 1:13:53.760\n But Swift for TensorFlow can be a different beast altogether.\n\n1:13:53.760 --> 1:13:57.560\n It can be like, it can basically be a layer on top of MLIR\n\n1:13:57.560 --> 1:14:00.440\n that takes advantage of, you know,\n\n1:14:00.440 --> 1:14:04.760\n all the great compiler stuff that Swift builds on with LLVM\n\n1:14:04.760 --> 1:14:09.320\n and yeah, I think it will be absolutely fantastic.\n\n1:14:10.280 --> 1:14:11.880\n Well, you're inspiring me to try.\n\n1:14:11.880 --> 1:14:16.880\n I haven't truly felt the pain of TensorFlow 2.0 Python.\n\n1:14:17.640 --> 1:14:21.040\n It's fine by me, but of...\n\n1:14:21.040 --> 1:14:22.120\n Yeah, I mean, it does the job\n\n1:14:22.120 --> 1:14:25.120\n if you're using like predefined things\n\n1:14:25.120 --> 1:14:26.720\n that somebody has already written.\n\n1:14:27.720 --> 1:14:29.560\n But if you actually compare, you know,\n\n1:14:29.560 --> 1:14:31.360\n like I've had to do,\n\n1:14:31.360 --> 1:14:32.640\n cause I've been having to do a lot of stuff\n\n1:14:32.640 --> 1:14:33.680\n with TensorFlow recently,\n\n1:14:33.680 --> 1:14:34.760\n you actually compare like,\n\n1:14:34.760 --> 1:14:37.360\n okay, I want to write something from scratch\n\n1:14:37.360 --> 1:14:38.880\n and you're like, I just keep finding it's like,\n\n1:14:38.880 --> 1:14:41.520\n Oh, it's running 10 times slower than PyTorch.\n\n1:14:41.520 --> 1:14:43.800\n So is the biggest cost,\n\n1:14:43.800 --> 1:14:47.320\n let's throw running time out the window.\n\n1:14:47.320 --> 1:14:49.600\n How long it takes you to program?\n\n1:14:49.600 --> 1:14:50.960\n That's not too different now,\n\n1:14:50.960 --> 1:14:54.040\n thanks to TensorFlow Eager, that's not too different.\n\n1:14:54.040 --> 1:14:58.640\n But because so many things take so long to run,\n\n1:14:58.640 --> 1:15:00.280\n you wouldn't run it at 10 times slower.\n\n1:15:00.280 --> 1:15:03.240\n Like you just go like, Oh, this is taking too long.\n\n1:15:03.240 --> 1:15:04.240\n And also there's a lot of things\n\n1:15:04.240 --> 1:15:05.840\n which are just less programmable,\n\n1:15:05.840 --> 1:15:08.960\n like tf.data, which is the way data processing works\n\n1:15:08.960 --> 1:15:11.360\n in TensorFlow is just this big mess.\n\n1:15:11.360 --> 1:15:13.200\n It's incredibly inefficient.\n\n1:15:13.200 --> 1:15:14.800\n And they kind of had to write it that way\n\n1:15:14.800 --> 1:15:19.160\n because of the TPU problems I described earlier.\n\n1:15:19.160 --> 1:15:22.160\n So I just, you know,\n\n1:15:22.160 --> 1:15:24.720\n I just feel like they've got this huge technical debt,\n\n1:15:24.720 --> 1:15:26.200\n which they're not going to solve\n\n1:15:26.200 --> 1:15:27.920\n without starting from scratch.\n\n1:15:27.920 --> 1:15:29.400\n So here's an interesting question then,\n\n1:15:29.400 --> 1:15:33.600\n if there's a new student starting today,\n\n1:15:34.560 --> 1:15:37.480\n what would you recommend they use?\n\n1:15:37.480 --> 1:15:40.440\n Well, I mean, we obviously recommend Fastai and PyTorch\n\n1:15:40.440 --> 1:15:43.880\n because we teach new students and that's what we teach with.\n\n1:15:43.880 --> 1:15:46.080\n So we would very strongly recommend that\n\n1:15:46.080 --> 1:15:50.000\n because it will let you get on top of the concepts\n\n1:15:50.000 --> 1:15:51.920\n much more quickly.\n\n1:15:51.920 --> 1:15:53.120\n So then you'll become an actual,\n\n1:15:53.120 --> 1:15:54.920\n and you'll also learn the actual state\n\n1:15:54.920 --> 1:15:56.400\n of the art techniques, you know,\n\n1:15:56.400 --> 1:15:59.200\n so you actually get world class results.\n\n1:15:59.200 --> 1:16:03.920\n Honestly, it doesn't much matter what library you learn\n\n1:16:03.920 --> 1:16:08.320\n because switching from the trainer to MXNet\n\n1:16:08.320 --> 1:16:12.000\n to TensorFlow to PyTorch is gonna be a couple of days work\n\n1:16:12.000 --> 1:16:15.240\n as long as you understand the foundation as well.\n\n1:16:15.240 --> 1:16:19.400\n But you think will Swift creep in there\n\n1:16:19.400 --> 1:16:22.920\n as a thing that people start using?\n\n1:16:22.920 --> 1:16:24.360\n Not for a few years,\n\n1:16:24.360 --> 1:16:29.360\n particularly because like Swift has no data science\n\n1:16:29.720 --> 1:16:33.400\n community, libraries, schooling.\n\n1:16:33.400 --> 1:16:38.400\n And the Swift community has a total lack of appreciation\n\n1:16:39.080 --> 1:16:40.880\n and understanding of numeric computing.\n\n1:16:40.880 --> 1:16:43.600\n So like they keep on making stupid decisions, you know,\n\n1:16:43.600 --> 1:16:45.440\n for years, they've just done dumb things\n\n1:16:45.440 --> 1:16:48.840\n around performance and prioritization.\n\n1:16:50.240 --> 1:16:53.440\n That's clearly changing now\n\n1:16:53.440 --> 1:16:58.000\n because the developer of Swift, Chris Latner,\n\n1:16:58.000 --> 1:17:00.720\n is working at Google on Swift for TensorFlow.\n\n1:17:00.720 --> 1:17:04.120\n So like that's a priority.\n\n1:17:04.120 --> 1:17:05.800\n It'll be interesting to see what happens with Apple\n\n1:17:05.800 --> 1:17:10.760\n because like Apple hasn't shown any sign of caring\n\n1:17:10.760 --> 1:17:13.760\n about numeric programming in Swift.\n\n1:17:13.760 --> 1:17:17.360\n So I mean, hopefully they'll get off their ass\n\n1:17:17.360 --> 1:17:18.800\n and start appreciating this\n\n1:17:18.800 --> 1:17:22.200\n because currently all of their low level libraries\n\n1:17:22.200 --> 1:17:25.080\n are not written in Swift.\n\n1:17:25.080 --> 1:17:27.360\n They're not particularly Swifty at all,\n\n1:17:27.360 --> 1:17:30.760\n stuff like CoreML, they're really pretty rubbish.\n\n1:17:30.760 --> 1:17:33.680\n So yeah, so there's a long way to go.\n\n1:17:33.680 --> 1:17:36.080\n But at least one nice thing is that Swift for TensorFlow\n\n1:17:36.080 --> 1:17:40.760\n can actually directly use Python code and Python libraries\n\n1:17:40.760 --> 1:17:45.040\n in a literally the entire lesson one notebook of fast AI\n\n1:17:45.040 --> 1:17:48.560\n runs in Swift right now in Python mode.\n\n1:17:48.560 --> 1:17:51.640\n So that's a nice intermediate thing.\n\n1:17:51.640 --> 1:17:53.320\n How long does it take?\n\n1:17:53.320 --> 1:17:57.560\n If you look at the two fast AI courses,\n\n1:17:57.560 --> 1:18:00.440\n how long does it take to get from point zero\n\n1:18:00.440 --> 1:18:02.040\n to completing both courses?\n\n1:18:03.240 --> 1:18:04.280\n It varies a lot.\n\n1:18:05.720 --> 1:18:10.720\n Somewhere between two months and two years generally.\n\n1:18:13.120 --> 1:18:16.040\n So for two months, how many hours a day on average?\n\n1:18:16.040 --> 1:18:20.480\n So like somebody who is a very competent coder\n\n1:18:20.480 --> 1:18:25.480\n can do 70 hours per course and pick up 70.\n\n1:18:27.800 --> 1:18:30.760\n 70, seven zero, that's it, okay.\n\n1:18:30.760 --> 1:18:35.640\n But a lot of people I know take a year off\n\n1:18:35.640 --> 1:18:40.440\n to study fast AI full time and say at the end of the year,\n\n1:18:40.440 --> 1:18:43.440\n they feel pretty competent\n\n1:18:43.440 --> 1:18:45.560\n because generally there's a lot of other things you do\n\n1:18:45.560 --> 1:18:48.680\n like generally they'll be entering Kaggle competitions,\n\n1:18:48.680 --> 1:18:51.440\n they might be reading Ian Goodfellow's book,\n\n1:18:51.440 --> 1:18:54.560\n they might, they'll be doing a bunch of stuff\n\n1:18:54.560 --> 1:18:57.760\n and often particularly if they are a domain expert,\n\n1:18:57.760 --> 1:19:00.560\n their coding skills might be a little\n\n1:19:00.560 --> 1:19:01.720\n on the pedestrian side.\n\n1:19:01.720 --> 1:19:04.760\n So part of it's just like doing a lot more writing.\n\n1:19:04.760 --> 1:19:07.960\n What do you find is the bottleneck for people usually\n\n1:19:07.960 --> 1:19:11.720\n except getting started and setting stuff up?\n\n1:19:11.720 --> 1:19:13.360\n I would say coding.\n\n1:19:13.360 --> 1:19:14.320\n Yeah, I would say the best,\n\n1:19:14.320 --> 1:19:18.800\n the people who are strong coders pick it up the best.\n\n1:19:18.800 --> 1:19:21.640\n Although another bottleneck is people who have a lot\n\n1:19:21.640 --> 1:19:26.640\n of experience of classic statistics can really struggle\n\n1:19:27.440 --> 1:19:30.000\n because the intuition is so the opposite\n\n1:19:30.000 --> 1:19:30.880\n of what they're used to.\n\n1:19:30.880 --> 1:19:33.040\n They're very used to like trying to reduce the number\n\n1:19:33.040 --> 1:19:34.320\n of parameters in their model\n\n1:19:34.320 --> 1:19:39.320\n and looking at individual coefficients and stuff like that.\n\n1:19:39.400 --> 1:19:42.920\n So I find people who have a lot of coding background\n\n1:19:42.920 --> 1:19:44.640\n and know nothing about statistics\n\n1:19:44.640 --> 1:19:47.480\n are generally gonna be the best off.\n\n1:19:48.560 --> 1:19:51.360\n So you taught several courses on deep learning\n\n1:19:51.360 --> 1:19:52.960\n and as Feynman says,\n\n1:19:52.960 --> 1:19:55.640\n best way to understand something is to teach it.\n\n1:19:55.640 --> 1:19:59.160\n What have you learned about deep learning from teaching it?\n\n1:19:59.160 --> 1:20:00.600\n A lot.\n\n1:20:00.600 --> 1:20:03.560\n That's a key reason for me to teach the courses.\n\n1:20:03.560 --> 1:20:04.960\n I mean, obviously it's gonna be necessary\n\n1:20:04.960 --> 1:20:07.680\n to achieve our goal of getting domain experts\n\n1:20:07.680 --> 1:20:09.320\n to be familiar with deep learning,\n\n1:20:09.320 --> 1:20:12.080\n but it was also necessary for me to achieve my goal\n\n1:20:12.080 --> 1:20:14.280\n of being really familiar with deep learning.\n\n1:20:18.240 --> 1:20:23.240\n I mean, to see so many domain experts\n\n1:20:24.080 --> 1:20:25.680\n from so many different backgrounds,\n\n1:20:25.680 --> 1:20:28.840\n it's definitely, I wouldn't say taught me,\n\n1:20:28.840 --> 1:20:32.200\n but convinced me something that I liked to believe was true,\n\n1:20:32.200 --> 1:20:34.920\n which was anyone can do it.\n\n1:20:34.920 --> 1:20:37.440\n So there's a lot of kind of snobbishness out there\n\n1:20:37.440 --> 1:20:40.240\n about only certain people can learn to code.\n\n1:20:40.240 --> 1:20:42.000\n Only certain people are gonna be smart enough\n\n1:20:42.000 --> 1:20:45.360\n like do AI, that's definitely bullshit.\n\n1:20:45.360 --> 1:20:48.880\n I've seen so many people from so many different backgrounds\n\n1:20:48.880 --> 1:20:52.480\n get state of the art results in their domain areas now.\n\n1:20:53.880 --> 1:20:57.160\n It's definitely taught me that the key differentiator\n\n1:20:57.160 --> 1:20:58.720\n between people that succeed\n\n1:20:58.720 --> 1:21:00.680\n and people that fail is tenacity.\n\n1:21:00.680 --> 1:21:03.480\n That seems to be basically the only thing that matters.\n\n1:21:05.560 --> 1:21:06.760\n A lot of people give up.\n\n1:21:06.760 --> 1:21:09.760\n But of the ones who don't give up,\n\n1:21:09.760 --> 1:21:12.760\n pretty much everybody succeeds.\n\n1:21:12.760 --> 1:21:15.640\n Even if at first I'm just kind of like thinking like,\n\n1:21:15.640 --> 1:21:18.440\n wow, they really aren't quite getting it yet, are they?\n\n1:21:18.440 --> 1:21:22.560\n But eventually people get it and they succeed.\n\n1:21:22.560 --> 1:21:24.240\n So I think that's been,\n\n1:21:24.240 --> 1:21:26.560\n I think they're both things I liked to believe was true,\n\n1:21:26.560 --> 1:21:28.680\n but I don't feel like I really had strong evidence\n\n1:21:28.680 --> 1:21:29.520\n for them to be true,\n\n1:21:29.520 --> 1:21:32.520\n but now I can say I've seen it again and again.\n\n1:21:32.520 --> 1:21:37.520\n I've seen it again and again. So what advice do you have\n\n1:21:37.760 --> 1:21:42.200\n for someone who wants to get started in deep learning?\n\n1:21:42.200 --> 1:21:44.400\n Train lots of models.\n\n1:21:44.400 --> 1:21:47.080\n That's how you learn it.\n\n1:21:47.080 --> 1:21:51.600\n So I think, it's not just me,\n\n1:21:51.600 --> 1:21:53.360\n I think our course is very good,\n\n1:21:53.360 --> 1:21:54.760\n but also lots of people independently\n\n1:21:54.760 --> 1:21:55.600\n have said it's very good.\n\n1:21:55.600 --> 1:21:58.640\n It recently won the COGx award for AI courses\n\n1:21:58.640 --> 1:21:59.920\n as being the best in the world.\n\n1:21:59.920 --> 1:22:02.960\n So I'd say come to our course, course.fast.ai.\n\n1:22:02.960 --> 1:22:05.240\n And the thing I keep on hopping on in my lessons\n\n1:22:05.240 --> 1:22:09.120\n is train models, print out the inputs to the models,\n\n1:22:09.120 --> 1:22:11.040\n print out to the outputs to the models,\n\n1:22:11.040 --> 1:22:15.320\n like study, change the inputs a bit,\n\n1:22:15.320 --> 1:22:17.320\n look at how the outputs vary,\n\n1:22:17.320 --> 1:22:18.600\n just run lots of experiments\n\n1:22:18.600 --> 1:22:23.600\n to get an intuitive understanding of what's going on.\n\n1:22:25.400 --> 1:22:29.080\n To get hooked, do you think, you mentioned training,\n\n1:22:29.080 --> 1:22:32.640\n do you think just running the models inference,\n\n1:22:32.640 --> 1:22:35.400\n like if we talk about getting started?\n\n1:22:35.400 --> 1:22:37.480\n No, you've got to fine tune the models.\n\n1:22:37.480 --> 1:22:39.480\n So that's the critical thing,\n\n1:22:39.480 --> 1:22:41.240\n because at that point you now have a model\n\n1:22:41.240 --> 1:22:43.280\n that's in your domain area.\n\n1:22:43.280 --> 1:22:46.840\n So there's no point running somebody else's model\n\n1:22:46.840 --> 1:22:48.120\n because it's not your model.\n\n1:22:48.120 --> 1:22:50.480\n So it only takes five minutes to fine tune a model\n\n1:22:50.480 --> 1:22:52.080\n for the data you care about.\n\n1:22:52.080 --> 1:22:53.560\n And in lesson two of the course,\n\n1:22:53.560 --> 1:22:56.360\n we teach you how to create your own data set from scratch\n\n1:22:56.360 --> 1:22:58.560\n by scripting Google image search.\n\n1:22:58.560 --> 1:23:01.120\n So, and we show you how to actually create\n\n1:23:01.120 --> 1:23:02.840\n a web application running online.\n\n1:23:02.840 --> 1:23:05.280\n So I create one in the course that differentiates\n\n1:23:05.280 --> 1:23:08.320\n between a teddy bear, a grizzly bear and a brown bear.\n\n1:23:08.320 --> 1:23:11.040\n And it does it with basically 100% accuracy,\n\n1:23:11.040 --> 1:23:13.120\n took me about four minutes to scrape the images\n\n1:23:13.120 --> 1:23:15.080\n from Google search in the script.\n\n1:23:15.080 --> 1:23:18.760\n There's a little graphical widgets we have in the notebook\n\n1:23:18.760 --> 1:23:21.400\n that help you clean up the data set.\n\n1:23:21.400 --> 1:23:24.040\n There's other widgets that help you study the results\n\n1:23:24.040 --> 1:23:26.360\n to see where the errors are happening.\n\n1:23:26.360 --> 1:23:29.280\n And so now we've got over a thousand replies\n\n1:23:29.280 --> 1:23:31.400\n in our share your work here thread\n\n1:23:31.400 --> 1:23:34.280\n of students saying, here's the thing I built.\n\n1:23:34.280 --> 1:23:35.880\n And so there's people who like,\n\n1:23:35.880 --> 1:23:37.600\n and a lot of them are state of the art.\n\n1:23:37.600 --> 1:23:39.000\n Like somebody said, oh, I tried looking\n\n1:23:39.000 --> 1:23:41.160\n at Devangari characters and I couldn't believe it.\n\n1:23:41.160 --> 1:23:43.320\n The thing that came out was more accurate\n\n1:23:43.320 --> 1:23:46.640\n than the best academic paper after lesson one.\n\n1:23:46.640 --> 1:23:48.560\n And then there's others which are just more kind of fun,\n\n1:23:48.560 --> 1:23:53.080\n like somebody who's doing Trinidad and Tobago hummingbirds.\n\n1:23:53.080 --> 1:23:54.880\n She said that's kind of their national bird\n\n1:23:54.880 --> 1:23:57.400\n and she's got something that can now classify Trinidad\n\n1:23:57.400 --> 1:23:58.840\n and Tobago hummingbirds.\n\n1:23:58.840 --> 1:24:02.440\n So yeah, train models, fine tune models with your data set\n\n1:24:02.440 --> 1:24:05.200\n and then study their inputs and outputs.\n\n1:24:05.200 --> 1:24:07.160\n How much is Fast.ai courses?\n\n1:24:07.160 --> 1:24:08.000\n Free.\n\n1:24:08.920 --> 1:24:10.520\n Everything we do is free.\n\n1:24:10.520 --> 1:24:12.720\n We have no revenue sources of any kind.\n\n1:24:12.720 --> 1:24:15.400\n It's just a service to the community.\n\n1:24:15.400 --> 1:24:16.600\n You're a saint.\n\n1:24:16.600 --> 1:24:20.080\n Okay, once a person understands the basics,\n\n1:24:20.080 --> 1:24:22.360\n trains a bunch of models,\n\n1:24:22.360 --> 1:24:25.840\n if we look at the scale of years,\n\n1:24:25.840 --> 1:24:27.600\n what advice do you have for someone wanting\n\n1:24:27.600 --> 1:24:29.240\n to eventually become an expert?\n\n1:24:30.800 --> 1:24:31.800\n Train lots of models.\n\n1:24:31.800 --> 1:24:35.320\n But specifically train lots of models in your domain area.\n\n1:24:35.320 --> 1:24:37.040\n So an expert what, right?\n\n1:24:37.040 --> 1:24:39.120\n We don't need more expert,\n\n1:24:39.120 --> 1:24:44.120\n like create slightly evolutionary research in areas\n\n1:24:45.400 --> 1:24:46.680\n that everybody's studying.\n\n1:24:46.680 --> 1:24:50.400\n We need experts at using deep learning\n\n1:24:50.400 --> 1:24:52.600\n to diagnose malaria.\n\n1:24:52.600 --> 1:24:55.480\n Or we need experts at using deep learning\n\n1:24:55.480 --> 1:25:00.480\n to analyze language to study media bias.\n\n1:25:01.000 --> 1:25:04.000\n So we need experts in analyzing fisheries\n\n1:25:08.320 --> 1:25:11.880\n to identify problem areas in the ocean.\n\n1:25:11.880 --> 1:25:13.200\n That's what we need.\n\n1:25:13.200 --> 1:25:17.720\n So become the expert in your passion area.\n\n1:25:17.720 --> 1:25:21.200\n And this is a tool which you can use for just about anything\n\n1:25:21.200 --> 1:25:22.880\n and you'll be able to do that thing better\n\n1:25:22.880 --> 1:25:25.720\n than other people, particularly by combining it\n\n1:25:25.720 --> 1:25:27.400\n with your passion and domain expertise.\n\n1:25:27.400 --> 1:25:28.360\n So that's really interesting.\n\n1:25:28.360 --> 1:25:30.840\n Even if you do wanna innovate on transfer learning\n\n1:25:30.840 --> 1:25:34.000\n or active learning, your thought is,\n\n1:25:34.000 --> 1:25:36.200\n I mean, it's one I certainly share,\n\n1:25:36.200 --> 1:25:40.120\n is you also need to find a domain or data set\n\n1:25:40.120 --> 1:25:42.000\n that you actually really care for.\n\n1:25:42.000 --> 1:25:45.360\n If you're not working on a real problem that you understand,\n\n1:25:45.360 --> 1:25:48.040\n how do you know if you're doing it any good?\n\n1:25:48.040 --> 1:25:49.320\n How do you know if your results are good?\n\n1:25:49.320 --> 1:25:50.800\n How do you know if you're getting bad results?\n\n1:25:50.800 --> 1:25:52.040\n Why are you getting bad results?\n\n1:25:52.040 --> 1:25:54.080\n Is it a problem with the data?\n\n1:25:54.080 --> 1:25:57.400\n Like, how do you know you're doing anything useful?\n\n1:25:57.400 --> 1:26:00.960\n Yeah, to me, the only really interesting research is,\n\n1:26:00.960 --> 1:26:02.360\n not the only, but the vast majority\n\n1:26:02.360 --> 1:26:04.480\n of interesting research is like,\n\n1:26:04.480 --> 1:26:06.880\n try and solve an actual problem and solve it really well.\n\n1:26:06.880 --> 1:26:09.440\n So both understanding sufficient tools\n\n1:26:09.440 --> 1:26:13.720\n on the deep learning side and becoming a domain expert\n\n1:26:13.720 --> 1:26:15.640\n in a particular domain are really things\n\n1:26:15.640 --> 1:26:18.240\n within reach for anybody.\n\n1:26:18.240 --> 1:26:20.520\n Yeah, I mean, to me, I would compare it\n\n1:26:20.520 --> 1:26:23.440\n to like studying self driving cars,\n\n1:26:23.440 --> 1:26:26.520\n having never looked at a car or been in a car\n\n1:26:26.520 --> 1:26:29.320\n or turned a car on, which is like the way it is\n\n1:26:29.320 --> 1:26:32.840\n for a lot of people, they'll study some academic data set\n\n1:26:33.960 --> 1:26:36.200\n where they literally have no idea about that.\n\n1:26:36.200 --> 1:26:37.680\n By the way, I'm not sure how familiar\n\n1:26:37.680 --> 1:26:40.840\n with autonomous vehicles, but that is literally,\n\n1:26:40.840 --> 1:26:43.400\n you describe a large percentage of robotics folks\n\n1:26:43.400 --> 1:26:45.800\n working in self driving cars is they actually\n\n1:26:45.800 --> 1:26:48.640\n haven't considered driving.\n\n1:26:48.640 --> 1:26:50.560\n They haven't actually looked at what driving looks like.\n\n1:26:50.560 --> 1:26:51.400\n They haven't driven.\n\n1:26:51.400 --> 1:26:53.280\n And it's a problem because you know,\n\n1:26:53.280 --> 1:26:54.360\n when you've actually driven, you know,\n\n1:26:54.360 --> 1:26:55.920\n like these are the things that happened\n\n1:26:55.920 --> 1:26:57.400\n to me when I was driving.\n\n1:26:57.400 --> 1:26:59.640\n There's nothing that beats the real world examples\n\n1:26:59.640 --> 1:27:01.080\n of just experiencing them.\n\n1:27:02.360 --> 1:27:04.840\n You've created many successful startups.\n\n1:27:04.840 --> 1:27:07.320\n What does it take to create a successful startup?\n\n1:27:08.600 --> 1:27:11.480\n Same thing as becoming a successful\n\n1:27:11.480 --> 1:27:15.000\n deep learning practitioner, which is not giving up.\n\n1:27:15.000 --> 1:27:20.000\n So you can run out of money or run out of time\n\n1:27:23.160 --> 1:27:24.680\n or run out of something, you know,\n\n1:27:24.680 --> 1:27:28.000\n but if you keep costs super low\n\n1:27:28.000 --> 1:27:29.920\n and try and save up some money beforehand\n\n1:27:29.920 --> 1:27:33.960\n so you can afford to have some time,\n\n1:27:35.360 --> 1:27:38.040\n then just sticking with it is one important thing.\n\n1:27:38.040 --> 1:27:42.640\n Doing something you understand and care about is important.\n\n1:27:42.640 --> 1:27:43.920\n By something, I don't mean,\n\n1:27:44.840 --> 1:27:46.680\n the biggest problem I see with deep learning people\n\n1:27:46.680 --> 1:27:50.120\n is they do a PhD in deep learning\n\n1:27:50.120 --> 1:27:52.400\n and then they try and commercialize their PhD.\n\n1:27:52.400 --> 1:27:53.280\n It is a waste of time\n\n1:27:53.280 --> 1:27:55.840\n because that doesn't solve an actual problem.\n\n1:27:55.840 --> 1:27:57.560\n You picked your PhD topic\n\n1:27:57.560 --> 1:28:00.080\n because it was an interesting kind of engineering\n\n1:28:00.080 --> 1:28:02.480\n or math or research exercise.\n\n1:28:02.480 --> 1:28:06.640\n But yeah, if you've actually spent time as a recruiter\n\n1:28:06.640 --> 1:28:09.240\n and you know that most of your time was spent\n\n1:28:09.240 --> 1:28:10.640\n sifting through resumes\n\n1:28:10.640 --> 1:28:12.840\n and you know that most of the time\n\n1:28:12.840 --> 1:28:14.680\n you're just looking for certain kinds of things\n\n1:28:14.680 --> 1:28:19.680\n and you can try doing that with a model for a few minutes\n\n1:28:19.680 --> 1:28:21.000\n and see whether that's something which a model\n\n1:28:21.000 --> 1:28:23.720\n seems to be able to do as well as you could,\n\n1:28:23.720 --> 1:28:27.600\n then you're on the right track to creating a startup.\n\n1:28:27.600 --> 1:28:32.280\n And then I think just, yeah, being, just be pragmatic and\n\n1:28:32.280 --> 1:28:36.760\n try and stay away from venture capital money\n\n1:28:36.760 --> 1:28:39.160\n as long as possible, preferably forever.\n\n1:28:39.160 --> 1:28:43.400\n So yeah, on that point, do you venture capital?\n\n1:28:43.400 --> 1:28:47.120\n So did you, were you able to successfully run startups\n\n1:28:47.120 --> 1:28:48.200\n with self funded for quite a while?\n\n1:28:48.200 --> 1:28:50.160\n Yeah, so my first two were self funded\n\n1:28:50.160 --> 1:28:52.320\n and that was the right way to do it.\n\n1:28:52.320 --> 1:28:53.160\n Is that scary?\n\n1:28:54.240 --> 1:28:57.800\n No, VC startups are much more scary\n\n1:28:57.800 --> 1:29:00.640\n because you have these people on your back\n\n1:29:00.640 --> 1:29:03.320\n who do this all the time and who have done it for years\n\n1:29:03.320 --> 1:29:05.400\n telling you grow, grow, grow, grow.\n\n1:29:05.400 --> 1:29:07.160\n And they don't care if you fail.\n\n1:29:07.160 --> 1:29:09.440\n They only care if you don't grow fast enough.\n\n1:29:09.440 --> 1:29:10.800\n So that's scary.\n\n1:29:10.800 --> 1:29:15.120\n Whereas doing the ones myself, well, with partners\n\n1:29:16.600 --> 1:29:18.400\n who were friends was nice\n\n1:29:18.400 --> 1:29:22.360\n because like we just went along at a pace that made sense\n\n1:29:22.360 --> 1:29:23.760\n and we were able to build it to something\n\n1:29:23.760 --> 1:29:27.280\n which was big enough that we never had to work again\n\n1:29:27.280 --> 1:29:29.280\n but was not big enough that any VC\n\n1:29:29.280 --> 1:29:31.480\n would think it was impressive.\n\n1:29:31.480 --> 1:29:35.920\n And that was enough for us to be excited, you know?\n\n1:29:35.920 --> 1:29:38.840\n So I thought that's a much better way\n\n1:29:38.840 --> 1:29:40.280\n to do things than most people.\n\n1:29:40.280 --> 1:29:41.920\n In generally speaking, not for yourself\n\n1:29:41.920 --> 1:29:44.520\n but how do you make money during that process?\n\n1:29:44.520 --> 1:29:47.440\n Do you cut into savings?\n\n1:29:47.440 --> 1:29:49.840\n So yeah, so for, so I started Fast Mail\n\n1:29:49.840 --> 1:29:52.760\n and Optimal Decisions at the same time in 1999\n\n1:29:52.760 --> 1:29:54.560\n with two different friends.\n\n1:29:54.560 --> 1:29:59.560\n And for Fast Mail, I guess I spent $70 a month\n\n1:30:01.160 --> 1:30:02.440\n on the server.\n\n1:30:04.000 --> 1:30:06.240\n And when the server ran out of space\n\n1:30:06.240 --> 1:30:09.400\n I put a payments button on the front page\n\n1:30:09.400 --> 1:30:11.880\n and said, if you want more than 10 mega space\n\n1:30:11.880 --> 1:30:15.640\n you have to pay $10 a year.\n\n1:30:15.640 --> 1:30:16.480\n And.\n\n1:30:16.480 --> 1:30:18.520\n So run low, like keep your costs down.\n\n1:30:18.520 --> 1:30:19.480\n Yeah, so I kept my costs down.\n\n1:30:19.480 --> 1:30:22.960\n And once, you know, once I needed to spend more money\n\n1:30:22.960 --> 1:30:25.600\n I asked people to spend the money for me.\n\n1:30:25.600 --> 1:30:28.400\n And that, that was that.\n\n1:30:28.400 --> 1:30:30.800\n Basically from then on, we were making money\n\n1:30:30.800 --> 1:30:33.480\n and I was profitable from then.\n\n1:30:35.400 --> 1:30:37.680\n For Optimal Decisions, it was a bit harder\n\n1:30:37.680 --> 1:30:40.040\n because we were trying to sell something\n\n1:30:40.040 --> 1:30:42.160\n that was more like a $1 million sale.\n\n1:30:42.160 --> 1:30:46.400\n But what we did was we would sell scoping projects.\n\n1:30:46.400 --> 1:30:50.560\n So kind of like prototypy projects\n\n1:30:50.560 --> 1:30:51.720\n but rather than doing it for free\n\n1:30:51.720 --> 1:30:54.200\n we would sell them 50 to $100,000.\n\n1:30:54.200 --> 1:30:56.920\n So again, we were covering our costs\n\n1:30:56.920 --> 1:30:58.320\n and also making the client feel\n\n1:30:58.320 --> 1:31:00.200\n like we were doing something valuable.\n\n1:31:00.200 --> 1:31:04.840\n So in both cases, we were profitable from six months in.\n\n1:31:06.000 --> 1:31:08.160\n Ah, nevertheless, it's scary.\n\n1:31:08.160 --> 1:31:10.040\n I mean, yeah, sure.\n\n1:31:10.040 --> 1:31:13.280\n I mean, it's, it's scary before you jump in\n\n1:31:13.280 --> 1:31:15.600\n and I just, I guess I was comparing it\n\n1:31:15.600 --> 1:31:18.120\n to the scarediness of VC.\n\n1:31:18.120 --> 1:31:20.480\n I felt like with VC stuff, it was more scary.\n\n1:31:20.480 --> 1:31:24.320\n Kind of much more in somebody else's hands,\n\n1:31:24.320 --> 1:31:26.120\n will they fund you or not?\n\n1:31:26.120 --> 1:31:27.840\n And what do they think of what you're doing?\n\n1:31:27.840 --> 1:31:29.760\n I also found it very difficult with VCs,\n\n1:31:29.760 --> 1:31:32.600\n back startups to actually do the thing\n\n1:31:32.600 --> 1:31:34.880\n which I thought was important for the company\n\n1:31:34.880 --> 1:31:35.920\n rather than doing the thing\n\n1:31:35.920 --> 1:31:38.840\n which I thought would make the VC happy.\n\n1:31:38.840 --> 1:31:40.880\n And VCs always tell you not to do the thing\n\n1:31:40.880 --> 1:31:42.360\n that makes them happy.\n\n1:31:42.360 --> 1:31:44.040\n But then if you don't do the thing that makes them happy\n\n1:31:44.040 --> 1:31:45.320\n they get sad, so.\n\n1:31:46.360 --> 1:31:48.080\n And do you think optimizing for the,\n\n1:31:48.080 --> 1:31:51.960\n whatever they call it, the exit is a good thing\n\n1:31:51.960 --> 1:31:53.040\n to optimize for?\n\n1:31:53.040 --> 1:31:54.880\n I mean, it can be, but not at the VC level\n\n1:31:54.880 --> 1:31:59.560\n because the VC exit needs to be, you know, a thousand X.\n\n1:31:59.560 --> 1:32:03.120\n So where else the lifestyle exit,\n\n1:32:03.120 --> 1:32:05.360\n if you can sell something for $10 million,\n\n1:32:05.360 --> 1:32:06.440\n then you've made it, right?\n\n1:32:06.440 --> 1:32:09.160\n So I don't, it depends.\n\n1:32:09.160 --> 1:32:11.200\n If you want to build something that's gonna,\n\n1:32:11.200 --> 1:32:13.560\n you're kind of happy to do forever, then fine.\n\n1:32:13.560 --> 1:32:16.720\n If you want to build something you want to sell\n\n1:32:16.720 --> 1:32:18.440\n in three years time, that's fine too.\n\n1:32:18.440 --> 1:32:21.280\n I mean, they're both perfectly good outcomes.\n\n1:32:21.280 --> 1:32:24.880\n So you're learning Swift now, in a way.\n\n1:32:24.880 --> 1:32:25.720\n I mean, you've already.\n\n1:32:25.720 --> 1:32:26.760\n I'm trying to.\n\n1:32:26.760 --> 1:32:31.120\n And I read that you use, at least in some cases,\n\n1:32:31.120 --> 1:32:34.400\n space repetition as a mechanism for learning new things.\n\n1:32:34.400 --> 1:32:36.400\n I use Anki quite a lot myself.\n\n1:32:36.400 --> 1:32:37.240\n Me too.\n\n1:32:38.920 --> 1:32:41.440\n I actually never talk to anybody about it.\n\n1:32:41.440 --> 1:32:44.120\n Don't know how many people do it,\n\n1:32:44.120 --> 1:32:46.720\n but it works incredibly well for me.\n\n1:32:46.720 --> 1:32:47.920\n Can you talk to your experience?\n\n1:32:47.920 --> 1:32:51.080\n Like how did you, what do you?\n\n1:32:51.080 --> 1:32:53.080\n First of all, okay, let's back it up.\n\n1:32:53.080 --> 1:32:55.080\n What is space repetition?\n\n1:32:55.080 --> 1:33:00.080\n So space repetition is an idea created\n\n1:33:00.280 --> 1:33:04.200\n by a psychologist named Ebbinghaus.\n\n1:33:04.200 --> 1:33:06.080\n I don't know, must be a couple of hundred years ago\n\n1:33:06.080 --> 1:33:08.000\n or something, 150 years ago.\n\n1:33:08.000 --> 1:33:10.680\n He did something which sounds pretty damn tedious.\n\n1:33:10.680 --> 1:33:15.600\n He wrote down random sequences of letters on cards\n\n1:33:15.600 --> 1:33:18.840\n and tested how well he would remember\n\n1:33:18.840 --> 1:33:23.000\n those random sequences a day later, a week later, whatever.\n\n1:33:23.000 --> 1:33:26.120\n He discovered that there was this kind of a curve\n\n1:33:26.120 --> 1:33:28.800\n where his probability of remembering one of them\n\n1:33:28.800 --> 1:33:30.640\n would be dramatically smaller the next day\n\n1:33:30.640 --> 1:33:31.960\n and then a little bit smaller the next day\n\n1:33:31.960 --> 1:33:33.520\n and a little bit smaller the next day.\n\n1:33:33.520 --> 1:33:36.880\n What he discovered is that if he revised those cards\n\n1:33:36.880 --> 1:33:41.600\n after a day, the probabilities would decrease\n\n1:33:41.600 --> 1:33:42.880\n at a smaller rate.\n\n1:33:42.880 --> 1:33:44.960\n And then if you revise them again a week later,\n\n1:33:44.960 --> 1:33:47.040\n they would decrease at a smaller rate again.\n\n1:33:47.040 --> 1:33:51.800\n And so he basically figured out a roughly optimal equation\n\n1:33:51.800 --> 1:33:54.560\n for when you should revise something you wanna remember.\n\n1:33:56.560 --> 1:34:00.440\n So space repetition learning is using this simple algorithm,\n\n1:34:00.440 --> 1:34:03.640\n just something like revise something after a day\n\n1:34:03.640 --> 1:34:06.640\n and then three days and then a week and then three weeks\n\n1:34:06.640 --> 1:34:07.720\n and so forth.\n\n1:34:07.720 --> 1:34:10.680\n And so if you use a program like Anki, as you know,\n\n1:34:10.680 --> 1:34:12.120\n it will just do that for you.\n\n1:34:12.120 --> 1:34:14.560\n And it will say, did you remember this?\n\n1:34:14.560 --> 1:34:17.680\n And if you say no, it will reschedule it back\n\n1:34:17.680 --> 1:34:20.320\n to appear again like 10 times faster\n\n1:34:20.320 --> 1:34:22.000\n than it otherwise would have.\n\n1:34:23.080 --> 1:34:27.920\n It's a kind of a way of being guaranteed to learn something\n\n1:34:27.920 --> 1:34:30.240\n because by definition, if you're not learning it,\n\n1:34:30.240 --> 1:34:32.800\n it will be rescheduled to be revised more quickly.\n\n1:34:33.680 --> 1:34:36.120\n Unfortunately though, it's also like,\n\n1:34:36.120 --> 1:34:37.480\n it doesn't let you fool yourself.\n\n1:34:37.480 --> 1:34:40.160\n If you're not learning something,\n\n1:34:40.160 --> 1:34:44.080\n you know like your revisions will just get more and more.\n\n1:34:44.080 --> 1:34:48.280\n So you have to find ways to learn things productively\n\n1:34:48.280 --> 1:34:50.560\n and effectively like treat your brain well.\n\n1:34:50.560 --> 1:34:54.880\n So using like mnemonics and stories and context\n\n1:34:54.880 --> 1:34:56.320\n and stuff like that.\n\n1:34:57.560 --> 1:34:59.760\n So yeah, it's a super great technique.\n\n1:34:59.760 --> 1:35:01.360\n It's like learning how to learn is something\n\n1:35:01.360 --> 1:35:03.800\n which everybody should learn\n\n1:35:03.800 --> 1:35:05.680\n before they actually learn anything.\n\n1:35:05.680 --> 1:35:07.840\n But almost nobody does.\n\n1:35:07.840 --> 1:35:10.120\n So what have you, so it certainly works well\n\n1:35:10.120 --> 1:35:13.720\n for learning new languages for, I mean,\n\n1:35:13.720 --> 1:35:16.440\n for learning like small projects almost.\n\n1:35:16.440 --> 1:35:19.840\n But do you, you know, I started using it for,\n\n1:35:19.840 --> 1:35:22.160\n I forget who wrote a blog post about this inspired me.\n\n1:35:22.160 --> 1:35:24.800\n It might've been you, I'm not sure.\n\n1:35:26.840 --> 1:35:28.520\n I started when I read papers,\n\n1:35:28.520 --> 1:35:31.920\n I'll concepts and ideas, I'll put them.\n\n1:35:31.920 --> 1:35:32.840\n Was it Michael Nielsen?\n\n1:35:32.840 --> 1:35:33.680\n It was Michael Nielsen.\n\n1:35:33.680 --> 1:35:36.400\n So Michael started doing this recently\n\n1:35:36.400 --> 1:35:37.920\n and has been writing about it.\n\n1:35:41.000 --> 1:35:43.200\n So the kind of today's Ebbinghaus\n\n1:35:43.200 --> 1:35:45.080\n is a guy called Peter Wozniak\n\n1:35:45.080 --> 1:35:47.720\n who developed a system called SuperMemo.\n\n1:35:47.720 --> 1:35:50.080\n And he's been basically trying to become like\n\n1:35:51.680 --> 1:35:54.080\n the world's greatest Renaissance man\n\n1:35:54.080 --> 1:35:55.960\n over the last few decades.\n\n1:35:55.960 --> 1:35:57.280\n He's basically lived his life\n\n1:35:57.280 --> 1:36:02.280\n with space repetition learning for everything.\n\n1:36:03.840 --> 1:36:05.800\n I, and sort of like,\n\n1:36:05.800 --> 1:36:07.440\n Michael's only very recently got into this,\n\n1:36:07.440 --> 1:36:08.920\n but he started really getting excited\n\n1:36:08.920 --> 1:36:11.200\n about doing it for a lot of different things.\n\n1:36:11.200 --> 1:36:14.600\n For me personally, I actually don't use it\n\n1:36:14.600 --> 1:36:16.920\n for anything except Chinese.\n\n1:36:16.920 --> 1:36:19.120\n And the reason for that is that\n\n1:36:20.120 --> 1:36:23.080\n Chinese is specifically a thing I made a conscious decision\n\n1:36:23.080 --> 1:36:27.680\n that I want to continue to remember,\n\n1:36:27.680 --> 1:36:30.080\n even if I don't get much of a chance to exercise it,\n\n1:36:30.080 --> 1:36:33.840\n cause like I'm not often in China, so I don't.\n\n1:36:33.840 --> 1:36:38.280\n Or else something like programming languages or papers.\n\n1:36:38.280 --> 1:36:39.600\n I have a very different approach,\n\n1:36:39.600 --> 1:36:43.040\n which is I try not to learn anything from them,\n\n1:36:43.040 --> 1:36:47.040\n but instead I try to identify the important concepts\n\n1:36:47.040 --> 1:36:48.960\n and like actually ingest them.\n\n1:36:48.960 --> 1:36:53.600\n So like really understand that concept deeply\n\n1:36:53.600 --> 1:36:54.760\n and study it carefully.\n\n1:36:54.760 --> 1:36:56.560\n I will decide if it really is important,\n\n1:36:56.560 --> 1:37:01.560\n if it is like incorporated into our library,\n\n1:37:01.560 --> 1:37:04.160\n you know, incorporated into how I do things\n\n1:37:04.160 --> 1:37:07.960\n or decide it's not worth it, say.\n\n1:37:07.960 --> 1:37:12.200\n So I find, I find I then remember the things\n\n1:37:12.200 --> 1:37:15.720\n that I care about because I'm using it all the time.\n\n1:37:15.720 --> 1:37:20.160\n So I've, for the last 25 years,\n\n1:37:20.160 --> 1:37:23.440\n I've committed to spending at least half of every day\n\n1:37:23.440 --> 1:37:25.920\n learning or practicing something new,\n\n1:37:25.920 --> 1:37:28.800\n which is all my colleagues have always hated\n\n1:37:28.800 --> 1:37:31.040\n because it always looks like I'm not working on\n\n1:37:31.040 --> 1:37:32.000\n what I'm meant to be working on,\n\n1:37:32.000 --> 1:37:34.560\n but it always means I do everything faster\n\n1:37:34.560 --> 1:37:36.920\n because I've been practicing a lot of stuff.\n\n1:37:36.920 --> 1:37:39.400\n So I kind of give myself a lot of opportunity\n\n1:37:39.400 --> 1:37:41.680\n to practice new things.\n\n1:37:41.680 --> 1:37:43.280\n And so I find now I don't,\n\n1:37:43.280 --> 1:37:47.840\n yeah, I don't often kind of find myself\n\n1:37:47.840 --> 1:37:50.240\n wishing I could remember something\n\n1:37:50.240 --> 1:37:51.400\n because if it's something that's useful,\n\n1:37:51.400 --> 1:37:53.840\n then I've been using it a lot.\n\n1:37:53.840 --> 1:37:56.120\n It's easy enough to look it up on Google,\n\n1:37:56.120 --> 1:37:59.640\n but speaking Chinese, you can't look it up on Google.\n\n1:37:59.640 --> 1:38:01.520\n Do you have advice for people learning new things?\n\n1:38:01.520 --> 1:38:04.800\n So if you, what have you learned as a process as a,\n\n1:38:04.800 --> 1:38:07.600\n I mean, it all starts with just making the hours\n\n1:38:07.600 --> 1:38:08.920\n and the day available.\n\n1:38:08.920 --> 1:38:10.120\n Yeah, you got to stick with it,\n\n1:38:10.120 --> 1:38:12.000\n which is again, the number one thing\n\n1:38:12.000 --> 1:38:13.600\n that 99% of people don't do.\n\n1:38:13.600 --> 1:38:15.840\n So the people I started learning Chinese with,\n\n1:38:15.840 --> 1:38:18.320\n none of them were still doing it 12 months later.\n\n1:38:18.320 --> 1:38:20.320\n I'm still doing it 10 years later.\n\n1:38:20.320 --> 1:38:21.840\n I tried to stay in touch with them,\n\n1:38:21.840 --> 1:38:23.480\n but they just, no one did it.\n\n1:38:24.560 --> 1:38:26.160\n For something like Chinese,\n\n1:38:26.160 --> 1:38:28.440\n like study how human learning works.\n\n1:38:28.440 --> 1:38:31.160\n So every one of my Chinese flashcards\n\n1:38:31.160 --> 1:38:33.680\n is associated with a story.\n\n1:38:33.680 --> 1:38:36.680\n And that story is specifically designed to be memorable.\n\n1:38:36.680 --> 1:38:37.800\n And we find things memorable,\n\n1:38:37.800 --> 1:38:41.320\n which are like funny or disgusting or sexy\n\n1:38:41.320 --> 1:38:44.200\n or related to people that we know or care about.\n\n1:38:44.200 --> 1:38:46.040\n So I try to make sure all of the stories\n\n1:38:46.040 --> 1:38:49.080\n that are in my head have those characteristics.\n\n1:38:51.000 --> 1:38:52.120\n Yeah, so you have to, you know,\n\n1:38:52.120 --> 1:38:53.200\n you won't remember things well\n\n1:38:53.200 --> 1:38:56.000\n if they don't have some context.\n\n1:38:56.000 --> 1:38:57.240\n And yeah, you won't remember them well\n\n1:38:57.240 --> 1:39:00.600\n if you don't regularly practice them,\n\n1:39:00.600 --> 1:39:02.440\n whether it be just part of your day to day life\n\n1:39:02.440 --> 1:39:06.040\n or the Chinese and me flashcards.\n\n1:39:06.040 --> 1:39:07.800\n I mean, the other thing is,\n\n1:39:07.800 --> 1:39:09.520\n I'll let yourself fail sometimes.\n\n1:39:09.520 --> 1:39:11.840\n So like I've had various medical problems\n\n1:39:11.840 --> 1:39:13.040\n over the last few years.\n\n1:39:13.040 --> 1:39:16.400\n And basically my flashcards\n\n1:39:16.400 --> 1:39:18.640\n just stopped for about three years.\n\n1:39:18.640 --> 1:39:22.600\n And there've been other times I've stopped for a few months\n\n1:39:22.600 --> 1:39:24.240\n and it's so hard because you get back to it\n\n1:39:24.240 --> 1:39:27.400\n and it's like, you have 18,000 cards due.\n\n1:39:27.400 --> 1:39:30.920\n It's like, and so you just have to go, all right,\n\n1:39:30.920 --> 1:39:34.160\n well, I can either stop and give up everything\n\n1:39:34.160 --> 1:39:37.560\n or just decide to do this every day for the next two years\n\n1:39:37.560 --> 1:39:39.000\n until I get back to it.\n\n1:39:39.000 --> 1:39:41.680\n The amazing thing has been that even after three years,\n\n1:39:41.680 --> 1:39:45.880\n I, you know, the Chinese were still in there.\n\n1:39:45.880 --> 1:39:48.480\n Like it was so much faster to relearn\n\n1:39:48.480 --> 1:39:50.120\n than it was to learn the first time.\n\n1:39:50.120 --> 1:39:52.320\n Yeah, absolutely.\n\n1:39:52.320 --> 1:39:53.160\n It's in there.\n\n1:39:53.160 --> 1:39:56.560\n I have the same with guitar, with music and so on.\n\n1:39:56.560 --> 1:39:59.160\n It's sad because the work sometimes takes away\n\n1:39:59.160 --> 1:40:01.200\n and then you won't play for a year.\n\n1:40:01.200 --> 1:40:03.560\n But really, if you then just get back to it every day,\n\n1:40:03.560 --> 1:40:05.200\n you're right there again.\n\n1:40:06.040 --> 1:40:08.400\n What do you think is the next big breakthrough\n\n1:40:08.400 --> 1:40:09.400\n in artificial intelligence?\n\n1:40:09.400 --> 1:40:12.720\n What are your hopes in deep learning or beyond\n\n1:40:12.720 --> 1:40:14.120\n that people should be working on\n\n1:40:14.120 --> 1:40:16.320\n or you hope there'll be breakthroughs?\n\n1:40:16.320 --> 1:40:17.960\n I don't think it's possible to predict.\n\n1:40:17.960 --> 1:40:20.600\n I think what we already have\n\n1:40:20.600 --> 1:40:23.720\n is an incredibly powerful platform\n\n1:40:23.720 --> 1:40:26.520\n to solve lots of societally important problems\n\n1:40:26.520 --> 1:40:27.600\n that are currently unsolved.\n\n1:40:27.600 --> 1:40:29.920\n So I just hope that people will,\n\n1:40:29.920 --> 1:40:33.360\n lots of people will learn this toolkit and try to use it.\n\n1:40:33.360 --> 1:40:36.800\n I don't think we need a lot of new technological breakthroughs\n\n1:40:36.800 --> 1:40:38.600\n to do a lot of great work right now.\n\n1:40:39.880 --> 1:40:42.760\n And when do you think we're going to create\n\n1:40:42.760 --> 1:40:45.160\n a human level intelligence system?\n\n1:40:45.160 --> 1:40:46.000\n Do you think?\n\n1:40:46.000 --> 1:40:46.840\n Don't know.\n\n1:40:46.840 --> 1:40:47.680\n How hard is it?\n\n1:40:47.680 --> 1:40:48.720\n How far away are we?\n\n1:40:48.720 --> 1:40:49.560\n Don't know.\n\n1:40:49.560 --> 1:40:50.400\n Don't know.\n\n1:40:50.400 --> 1:40:51.240\n I have no way to know.\n\n1:40:51.240 --> 1:40:53.840\n I don't know why people make predictions about this\n\n1:40:53.840 --> 1:40:57.480\n because there's no data and nothing to go on.\n\n1:40:57.480 --> 1:41:00.320\n And it's just like,\n\n1:41:00.320 --> 1:41:03.480\n there's so many societally important problems\n\n1:41:03.480 --> 1:41:04.400\n to solve right now.\n\n1:41:04.400 --> 1:41:08.680\n I just don't find it a really interesting question\n\n1:41:08.680 --> 1:41:10.280\n to even answer.\n\n1:41:10.280 --> 1:41:12.960\n So in terms of societally important problems,\n\n1:41:12.960 --> 1:41:16.360\n what's the problem that is within reach?\n\n1:41:16.360 --> 1:41:17.440\n Well, I mean, for example,\n\n1:41:17.440 --> 1:41:19.760\n there are problems that AI creates, right?\n\n1:41:19.760 --> 1:41:21.280\n So more specifically,\n\n1:41:23.160 --> 1:41:26.800\n labor force displacement is going to be huge\n\n1:41:26.800 --> 1:41:28.320\n and people keep making this\n\n1:41:29.160 --> 1:41:31.520\n frivolous econometric argument of being like,\n\n1:41:31.520 --> 1:41:33.960\n oh, there's been other things that aren't AI\n\n1:41:33.960 --> 1:41:34.920\n that have come along before\n\n1:41:34.920 --> 1:41:37.800\n and haven't created massive labor force displacement,\n\n1:41:37.800 --> 1:41:39.880\n therefore AI won't.\n\n1:41:39.880 --> 1:41:41.560\n So that's a serious concern for you?\n\n1:41:41.560 --> 1:41:42.400\n Oh yeah.\n\n1:41:42.400 --> 1:41:43.680\n Andrew Yang is running on it.\n\n1:41:43.680 --> 1:41:47.320\n Yeah, it's, I'm desperately concerned.\n\n1:41:47.320 --> 1:41:52.320\n And you see already that the changing workplace\n\n1:41:53.080 --> 1:41:55.720\n has led to a hollowing out of the middle class.\n\n1:41:55.720 --> 1:41:59.000\n You're seeing that students coming out of school today\n\n1:41:59.000 --> 1:42:03.120\n have a less rosy financial future ahead of them\n\n1:42:03.120 --> 1:42:03.960\n than their parents did,\n\n1:42:03.960 --> 1:42:06.560\n which has never happened in recent,\n\n1:42:06.560 --> 1:42:08.600\n in the last few hundred years.\n\n1:42:08.600 --> 1:42:10.920\n You know, we've always had progress before.\n\n1:42:11.760 --> 1:42:15.520\n And you see this turning into anxiety\n\n1:42:15.520 --> 1:42:19.440\n and despair and even violence.\n\n1:42:19.440 --> 1:42:21.280\n So I very much worry about that.\n\n1:42:23.400 --> 1:42:25.720\n You've written quite a bit about ethics too.\n\n1:42:25.720 --> 1:42:29.600\n I do think that every data scientist\n\n1:42:29.600 --> 1:42:33.920\n working with deep learning needs to recognize\n\n1:42:33.920 --> 1:42:35.600\n they have an incredibly high leverage tool\n\n1:42:35.600 --> 1:42:37.960\n that they're using that can influence society\n\n1:42:37.960 --> 1:42:39.000\n in lots of ways.\n\n1:42:39.000 --> 1:42:40.320\n And if they're doing research,\n\n1:42:40.320 --> 1:42:42.760\n that that research is gonna be used by people\n\n1:42:42.760 --> 1:42:44.400\n doing this kind of work.\n\n1:42:44.400 --> 1:42:48.360\n And they have a responsibility to consider the consequences\n\n1:42:48.360 --> 1:42:50.160\n and to think about things like\n\n1:42:51.760 --> 1:42:53.920\n how will humans be in the loop here?\n\n1:42:53.920 --> 1:42:56.520\n How do we avoid runaway feedback loops?\n\n1:42:56.520 --> 1:42:59.200\n How do we ensure an appeals process for humans\n\n1:42:59.200 --> 1:43:01.720\n that are impacted by my algorithm?\n\n1:43:01.720 --> 1:43:04.960\n How do I ensure that the constraints of my algorithm\n\n1:43:04.960 --> 1:43:06.720\n are adequately explained to the people\n\n1:43:06.720 --> 1:43:09.160\n that end up using them?\n\n1:43:09.160 --> 1:43:11.880\n There's all kinds of human issues\n\n1:43:11.880 --> 1:43:15.400\n which only data scientists are actually\n\n1:43:15.400 --> 1:43:17.960\n in the right place to educate people are about,\n\n1:43:17.960 --> 1:43:20.280\n but data scientists tend to think of themselves\n\n1:43:20.280 --> 1:43:23.400\n as just engineers and that they don't need\n\n1:43:23.400 --> 1:43:26.720\n to be part of that process, which is wrong.\n\n1:43:26.720 --> 1:43:30.320\n Well, you're in the perfect position to educate them better,\n\n1:43:30.320 --> 1:43:33.800\n to read literature, to read history, to learn from history.\n\n1:43:35.800 --> 1:43:39.160\n Well, Jeremy, thank you so much for everything you do\n\n1:43:39.160 --> 1:43:41.360\n for inspiring huge amount of people,\n\n1:43:41.360 --> 1:43:42.520\n getting them into deep learning\n\n1:43:42.520 --> 1:43:45.120\n and having the ripple effects,\n\n1:43:45.120 --> 1:43:47.480\n the flap of a butterfly's wings\n\n1:43:47.480 --> 1:43:48.680\n that will probably change the world.\n\n1:43:48.680 --> 1:43:50.120\n So thank you very much.\n\n1:43:50.120 --> 1:43:57.120\n Thank you, thank you, thank you, thank you.\n\n"
}
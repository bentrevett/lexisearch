{
  "title": "David Eagleman: Neuroplasticity and the Livewired Brain | Lex Fridman Podcast #119",
  "id": "386s-y1aRRo",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:02.980\n The following is a conversation with David Eagleman,\n\n00:02.980 --> 00:06.360\n a neuroscientist and one of the great science communicators\n\n00:06.360 --> 00:09.260\n of our time, exploring the beauty and mystery\n\n00:09.260 --> 00:10.780\n of the human brain.\n\n00:10.780 --> 00:13.140\n He's an author of a lot of amazing books\n\n00:13.140 --> 00:18.060\n about the human mind, and his new one called Livewired.\n\n00:18.060 --> 00:21.200\n Livewired is a work of 10 years on a topic\n\n00:21.200 --> 00:24.700\n that is fascinating to me, which is neuroplasticity\n\n00:24.700 --> 00:26.780\n or the malleability of the human brain.\n\n00:27.740 --> 00:29.260\n Quick summary of the sponsors.\n\n00:29.260 --> 00:32.700\n Athletic Greens, BetterHelp, and Cash App.\n\n00:32.700 --> 00:34.500\n Click the sponsor links in the description\n\n00:34.500 --> 00:37.820\n to get a discount and to support this podcast.\n\n00:37.820 --> 00:41.420\n As a side note, let me say that the adaptability\n\n00:41.420 --> 00:44.380\n of the human mind at the biological, chemical,\n\n00:44.380 --> 00:48.500\n cognitive, psychological, and even sociological levels\n\n00:48.500 --> 00:51.860\n is the very thing that captivated me many years ago\n\n00:51.860 --> 00:54.980\n when I first began to wonder how would my engineer\n\n00:54.980 --> 00:57.760\n something like it in the machine.\n\n00:57.760 --> 01:00.700\n The open question today in the 21st century\n\n01:00.700 --> 01:03.700\n is what are the limits of this adaptability?\n\n01:03.700 --> 01:07.420\n As new, smarter and smarter devices and AI systems\n\n01:07.420 --> 01:10.420\n come to life, or as better and better brain computer\n\n01:10.420 --> 01:13.820\n interfaces are engineered, will our brain be able to adapt,\n\n01:13.820 --> 01:16.580\n to catch up, to excel?\n\n01:16.580 --> 01:19.540\n I personally believe yes, that we're far from reaching\n\n01:19.540 --> 01:23.100\n the limitation of the human mind and the human brain,\n\n01:23.100 --> 01:26.060\n just as we are far from reaching the limitations\n\n01:26.060 --> 01:27.900\n of our computational systems.\n\n01:28.860 --> 01:31.420\n If you enjoy this thing, subscribe on YouTube,\n\n01:31.420 --> 01:33.580\n review it with five stars on Apple Podcast,\n\n01:33.580 --> 01:36.240\n follow on Spotify, support on Patreon,\n\n01:36.240 --> 01:39.200\n or connect with me on Twitter at Lex Friedman.\n\n01:40.100 --> 01:41.980\n As usual, I'll do a few minutes of ads now\n\n01:41.980 --> 01:43.460\n and no ads in the middle.\n\n01:43.460 --> 01:45.100\n I try to make these interesting,\n\n01:45.100 --> 01:47.940\n but I give you timestamps so you can skip.\n\n01:47.940 --> 01:49.740\n But please do check out the sponsors\n\n01:49.740 --> 01:51.660\n by clicking the links in the description.\n\n01:51.660 --> 01:55.000\n It's the best way to support this podcast.\n\n01:55.000 --> 01:58.300\n This show is brought to you by Athletic Greens,\n\n01:58.300 --> 02:01.140\n the all in one daily drink to support better health\n\n02:01.140 --> 02:02.680\n and peak performance.\n\n02:02.680 --> 02:04.800\n Even with a balanced diet, it's difficult to cover\n\n02:04.800 --> 02:07.020\n all of your nutritional bases.\n\n02:07.020 --> 02:09.140\n That's where Athletic Greens will help.\n\n02:09.140 --> 02:11.820\n Their daily drink is like nutritional insurance\n\n02:11.820 --> 02:15.380\n for your body as delivered straight to your door.\n\n02:15.380 --> 02:18.580\n As you may know, I fast often, sometimes intermittent fasting\n\n02:18.580 --> 02:21.860\n for 16 hours, sometimes 24 hours,\n\n02:21.860 --> 02:24.500\n dinner to dinner, sometimes more.\n\n02:24.500 --> 02:26.900\n I break the fast with Athletic Greens.\n\n02:26.900 --> 02:30.980\n It's delicious, refreshing, just makes me feel good.\n\n02:30.980 --> 02:34.380\n I think it's like 50 calories, less than a gram of sugar,\n\n02:34.380 --> 02:36.460\n but has a ton of nutrients to make sure my body\n\n02:36.460 --> 02:40.200\n has what it needs despite what I'm eating.\n\n02:40.200 --> 02:43.100\n Go to athleticgreens.com slash lex\n\n02:43.100 --> 02:48.100\n to claim a special offer of a free vitamin D3K2 for a year.\n\n02:49.140 --> 02:51.420\n If you listen to the Joe Rogan experience,\n\n02:51.420 --> 02:53.340\n you might've listened to him rant about\n\n02:53.340 --> 02:56.140\n how awesome vitamin D is for your immune system.\n\n02:56.140 --> 02:57.580\n So there you have it.\n\n02:57.580 --> 03:00.940\n So click the athleticgreens.com slash lex\n\n03:00.940 --> 03:03.420\n in the description to get the free stuff\n\n03:03.420 --> 03:05.320\n and to support this podcast.\n\n03:06.400 --> 03:11.400\n This show is sponsored by BetterHelp, spelled H E L P, help.\n\n03:11.460 --> 03:14.200\n Check it out at betterhelp.com slash lex.\n\n03:14.200 --> 03:15.860\n They figure out what you need and match you\n\n03:15.860 --> 03:19.340\n with a licensed professional therapist in under 48 hours.\n\n03:19.340 --> 03:21.820\n It's not a crisis line, it's not self help,\n\n03:21.820 --> 03:25.500\n it's professional counseling done securely online.\n\n03:25.500 --> 03:28.100\n I'm a bit from the David Goggins line of creatures\n\n03:28.100 --> 03:30.680\n and so have some demons to contend with,\n\n03:30.680 --> 03:34.940\n usually on long runs or all nights full of self doubt.\n\n03:34.940 --> 03:37.880\n I think suffering is essential for creation,\n\n03:37.880 --> 03:39.540\n but you can suffer beautifully\n\n03:39.540 --> 03:41.660\n in a way that doesn't destroy you.\n\n03:41.660 --> 03:45.300\n For most people, I think a good therapist can help on this.\n\n03:45.300 --> 03:47.140\n So it's at least worth a try.\n\n03:47.140 --> 03:49.260\n Check out their reviews, they're good.\n\n03:49.260 --> 03:52.660\n It's easy, private, affordable, available worldwide.\n\n03:52.660 --> 03:54.760\n You can communicate by text anytime\n\n03:54.760 --> 03:58.280\n and schedule a weekly audio and video session.\n\n03:58.280 --> 04:01.520\n Check it out at betterhelp.com slash lex.\n\n04:02.420 --> 04:04.620\n This show is presented by Cash App,\n\n04:04.620 --> 04:06.660\n the number one finance app in the App Store.\n\n04:06.660 --> 04:09.280\n When you get it, use code lexpodcast.\n\n04:09.280 --> 04:11.660\n Cash App lets you send money to friends, buy Bitcoin,\n\n04:11.660 --> 04:14.540\n invest in the stock market with as little as $1.\n\n04:14.540 --> 04:16.880\n Since Cash App allows you to buy Bitcoin,\n\n04:16.880 --> 04:18.480\n let me mention that cryptocurrency\n\n04:18.480 --> 04:21.860\n in the context of the history of money is fascinating.\n\n04:21.860 --> 04:25.420\n I recommend Ascent of Money as a great book on this history.\n\n04:25.420 --> 04:29.980\n Davidson credits on ledgers started around 30,000 years ago\n\n04:29.980 --> 04:32.260\n and the first decentralized cryptocurrency\n\n04:32.260 --> 04:34.220\n released just over 10 years ago.\n\n04:34.220 --> 04:37.420\n So given that history, cryptocurrency is still very much\n\n04:37.420 --> 04:39.340\n in its early days of development,\n\n04:39.340 --> 04:40.700\n but it's still aiming to\n\n04:40.700 --> 04:43.880\n and just might redefine the nature of money.\n\n04:44.880 --> 04:47.900\n So again, if you get Cash App from the App Store or Google Play\n\n04:47.900 --> 04:51.020\n and use code lexpodcast, you get $10\n\n04:51.020 --> 04:53.940\n and Cash App will also donate $10 to FIRST,\n\n04:53.940 --> 04:56.980\n an organization that is helping to advance robotics\n\n04:56.980 --> 05:00.420\n and STEM education for young people around the world.\n\n05:00.420 --> 05:04.620\n And now here's my conversation with David Eagleman.\n\n05:05.780 --> 05:10.360\n You have a new book coming out on the changing brain.\n\n05:10.360 --> 05:13.260\n Can you give a high level overview of the book?\n\n05:13.260 --> 05:14.620\n It's called Livewired by the way.\n\n05:14.620 --> 05:17.780\n Yeah, the thing is we typically think about the brain\n\n05:17.780 --> 05:19.500\n in terms of the metaphors we already have,\n\n05:19.500 --> 05:21.820\n like hardware and software, that's how we build\n\n05:21.820 --> 05:24.420\n all our stuff, but what's happening in the brain\n\n05:24.420 --> 05:26.860\n is fundamentally so different.\n\n05:26.860 --> 05:29.060\n So I coined this new term liveware,\n\n05:29.060 --> 05:32.400\n which is a system that's constantly reconfiguring itself\n\n05:32.400 --> 05:37.100\n physically as it learns and adapts to the world around it.\n\n05:37.100 --> 05:38.660\n It's physically changing.\n\n05:38.660 --> 05:43.620\n So it's liveware meaning like hardware but changing.\n\n05:43.620 --> 05:44.560\n Yeah, exactly.\n\n05:44.560 --> 05:47.500\n Well, the hardware and the software layers are blended\n\n05:47.500 --> 05:52.500\n and so typically engineers are praised for their efficiency\n\n05:53.660 --> 05:55.220\n and making something really clean and clear,\n\n05:55.220 --> 05:56.380\n like, okay, here's the hardware layer,\n\n05:56.380 --> 05:57.780\n then I'm gonna run software on top of it.\n\n05:57.780 --> 06:00.300\n And there's all sorts of universality that you get out\n\n06:00.300 --> 06:02.840\n of a piece of hardware like that that's useful.\n\n06:02.840 --> 06:05.240\n But what the brain is doing is completely different.\n\n06:05.240 --> 06:08.360\n And I am so excited about where this is all going\n\n06:08.360 --> 06:13.360\n because I feel like this is where our engineering will go.\n\n06:13.360 --> 06:17.140\n So currently we build all our devices a particular way,\n\n06:17.140 --> 06:20.620\n but I can't tear half the circuitry out of your cell phone\n\n06:20.620 --> 06:22.660\n and expect it to still function.\n\n06:22.660 --> 06:26.460\n But you can do that with the brain.\n\n06:26.460 --> 06:29.260\n So just as an example, kids who are under\n\n06:29.260 --> 06:32.060\n about seven years old can get one half of their brain\n\n06:32.060 --> 06:35.700\n removed, it's called a hemispherectomy, and they're fine.\n\n06:35.700 --> 06:37.420\n They have a slight limp on the other side of their body,\n\n06:37.420 --> 06:40.540\n but they can function just fine that way.\n\n06:40.540 --> 06:42.380\n And this is generally true.\n\n06:42.380 --> 06:45.220\n You know, sometimes children are born without a hemisphere\n\n06:45.220 --> 06:48.580\n and their visual system rewires so that everything is\n\n06:48.580 --> 06:52.140\n on the single remaining hemisphere.\n\n06:52.140 --> 06:55.420\n What thousands of cases like this teach us\n\n06:55.420 --> 06:59.940\n is that it's a very malleable system that is simply trying\n\n06:59.940 --> 07:04.060\n to accomplish the tasks in front of it by rewiring itself\n\n07:04.060 --> 07:06.100\n with the available real estate.\n\n07:06.100 --> 07:09.860\n How much of that is a quirk or a feature of evolution?\n\n07:09.860 --> 07:11.860\n Like, how hard is it to engineer?\n\n07:11.860 --> 07:14.620\n Because evolution took a lot of work.\n\n07:14.620 --> 07:18.500\n Trillions of organisms had to die for it to create\n\n07:18.500 --> 07:21.580\n this thing we have in our skull.\n\n07:21.580 --> 07:24.540\n Like, because you said you kind of look forward to the idea\n\n07:24.540 --> 07:27.940\n that we might be engineering our systems like this\n\n07:27.940 --> 07:30.740\n in the future, like creating liveware systems.\n\n07:30.740 --> 07:33.180\n How hard do you think is it to create systems like that?\n\n07:33.180 --> 07:34.020\n Great question.\n\n07:34.020 --> 07:37.060\n It has proven itself to be a difficult challenge.\n\n07:37.060 --> 07:40.260\n What I mean by that is even though it's taken evolution\n\n07:40.260 --> 07:43.180\n a really long time to get where it is now,\n\n07:44.260 --> 07:47.620\n all we have to do now is peek at the blueprints.\n\n07:47.620 --> 07:49.620\n It's just three pounds, this organ,\n\n07:49.620 --> 07:50.860\n and we just figure out how to do it.\n\n07:50.860 --> 07:52.760\n But that's the part that I mean is a difficult challenge\n\n07:52.760 --> 07:57.100\n because there are tens of thousands of neuroscientists,\n\n07:57.100 --> 07:59.260\n we're all poking and prodding and trying to figure this out,\n\n07:59.260 --> 08:00.700\n but it's an extremely complicated system.\n\n08:00.700 --> 08:03.300\n But it's only gonna be complicated until we figure out\n\n08:03.300 --> 08:05.380\n the general principles.\n\n08:05.380 --> 08:09.420\n Exactly like if you had a magic camera\n\n08:09.420 --> 08:10.940\n you could look inside the nucleus of a cell\n\n08:10.940 --> 08:13.220\n and you'd see hundreds of thousands of things\n\n08:13.220 --> 08:14.180\n moving around or whatever,\n\n08:14.180 --> 08:16.060\n and then it takes Crick and Watson to say,\n\n08:16.060 --> 08:17.380\n oh, you know what, you're just trying to maintain\n\n08:17.380 --> 08:20.300\n the order of the base pairs and all the rest is details.\n\n08:20.300 --> 08:23.500\n Then it simplifies it and we come to understand something.\n\n08:23.500 --> 08:25.100\n That was my goal in LiveWire,\n\n08:25.100 --> 08:26.900\n which I've written over 10 years, by the way,\n\n08:26.900 --> 08:29.920\n is to try to distill things down to the principles\n\n08:29.920 --> 08:34.180\n of what plastic systems are trying to accomplish.\n\n08:34.180 --> 08:36.260\n But to even just linger, you said,\n\n08:36.260 --> 08:38.820\n it's possible to be born with just one hemisphere\n\n08:38.820 --> 08:41.940\n and you still are able to function.\n\n08:41.940 --> 08:43.460\n First of all, just to pause on that,\n\n08:43.460 --> 08:45.660\n I mean, that's kind of, that's amazing.\n\n08:47.940 --> 08:50.100\n I don't know if people quite,\n\n08:50.100 --> 08:51.740\n I mean, you kind of hear things here and there.\n\n08:51.740 --> 08:54.300\n This is why I'm kind of, I'm really excited about your book\n\n08:54.300 --> 08:59.300\n is I don't know if there's definitive sort of popular sources\n\n09:00.020 --> 09:01.500\n to think about this stuff.\n\n09:01.500 --> 09:05.060\n I mean, there's a lot of, I think from my perspective,\n\n09:05.060 --> 09:07.940\n what I heard is there's like been debates over decades\n\n09:07.940 --> 09:12.060\n about how much neuroplasticity there is in the brain\n\n09:12.060 --> 09:14.860\n and so on, and people have learned a lot of things\n\n09:14.860 --> 09:16.900\n and now it's converging towards people\n\n09:16.900 --> 09:20.380\n that are understanding there's much more plastic\n\n09:20.380 --> 09:21.440\n than people realize.\n\n09:21.440 --> 09:23.900\n But just like linger on that topic,\n\n09:23.900 --> 09:28.380\n like how malleable is the hardware of the human brain?\n\n09:28.380 --> 09:32.300\n Maybe you said children at each stage of life.\n\n09:32.300 --> 09:33.680\n Yeah, so here's the whole thing.\n\n09:33.680 --> 09:36.960\n I think part of the confusion about plasticity\n\n09:36.960 --> 09:38.220\n has been that there are studies\n\n09:38.220 --> 09:40.340\n at all sorts of different ages,\n\n09:40.340 --> 09:42.400\n and then people might read that from a distance\n\n09:42.400 --> 09:45.360\n and they think, oh, well, Fred didn't recover\n\n09:45.360 --> 09:47.060\n when half his brain was taken out\n\n09:47.060 --> 09:49.020\n and so clearly you're not plastic,\n\n09:49.020 --> 09:52.180\n but then you do it with a child and they are plastic.\n\n09:52.180 --> 09:56.420\n And so part of my goal here was to pull together\n\n09:56.420 --> 09:59.060\n the tens of thousands of papers on this,\n\n09:59.060 --> 10:02.460\n both from clinical work and from all the way down\n\n10:02.460 --> 10:04.140\n to the molecular and understand\n\n10:04.140 --> 10:04.980\n what are the principles here?\n\n10:04.980 --> 10:08.260\n The principles are that plasticity diminishes,\n\n10:08.260 --> 10:09.540\n that's no surprise.\n\n10:09.540 --> 10:11.540\n By the way, maybe I should just define plasticity.\n\n10:11.540 --> 10:14.840\n It's the ability of a system to mold into a new shape\n\n10:14.840 --> 10:16.260\n and then hold that shape.\n\n10:16.260 --> 10:19.860\n That's why we make things that we call plastic\n\n10:20.740 --> 10:23.620\n because they are moldable and they can hold that new shape,\n\n10:23.620 --> 10:25.240\n like a plastic toy or something.\n\n10:25.240 --> 10:29.480\n And so maybe we'll use a lot of terms that are synonymous.\n\n10:29.480 --> 10:34.460\n So something is plastic, something is malleable,\n\n10:34.460 --> 10:38.740\n changing, live wire, the name of the book is like synonyms.\n\n10:38.740 --> 10:39.880\n So I'll tell you, exactly right,\n\n10:39.880 --> 10:41.740\n but I'll tell you why I chose live wire\n\n10:41.740 --> 10:42.980\n instead of plasticity.\n\n10:42.980 --> 10:47.140\n So I use the term plasticity in the book, but sparingly,\n\n10:47.140 --> 10:51.060\n because that was a term coined by William James\n\n10:51.060 --> 10:53.980\n over a hundred years ago and he was, of course,\n\n10:53.980 --> 10:55.820\n very impressed with plastic manufacturing\n\n10:55.820 --> 10:57.660\n that you could mold something into shape\n\n10:57.660 --> 10:58.540\n and then it holds that.\n\n10:58.540 --> 11:01.420\n But that's not what's actually happening in the brain.\n\n11:01.420 --> 11:03.700\n It's constantly rewiring your entire life.\n\n11:03.700 --> 11:06.380\n You never hit an end point.\n\n11:06.380 --> 11:08.220\n The whole point is for it to keep changing.\n\n11:08.220 --> 11:11.020\n So even in the few minutes of conversation\n\n11:11.020 --> 11:12.560\n that we've been having, your brain is changing,\n\n11:12.560 --> 11:13.820\n my brain is changing.\n\n11:15.460 --> 11:18.020\n Next time I see your face, I will remember,\n\n11:18.020 --> 11:19.860\n oh yeah, like that time Lex and I sat together\n\n11:19.860 --> 11:21.420\n and we did these things.\n\n11:21.420 --> 11:24.020\n I wonder if your brain will have like a Lex thing\n\n11:24.020 --> 11:25.300\n going on for the next few months.\n\n11:25.300 --> 11:27.860\n Like it'll stay there until you get rid of it\n\n11:27.860 --> 11:29.340\n because it was useful for now.\n\n11:29.340 --> 11:30.820\n Yeah, no, I'll probably never get rid of it.\n\n11:30.820 --> 11:32.000\n Let's say for some circumstance,\n\n11:32.000 --> 11:34.300\n you and I don't see each other for the next 35 years.\n\n11:34.300 --> 11:36.220\n When I run into you, I'll be like, oh yeah.\n\n11:36.220 --> 11:37.460\n That looks familiar.\n\n11:37.460 --> 11:40.420\n Yeah, yeah, we sat down for a podcast\n\n11:40.420 --> 11:42.460\n back when there were podcasts.\n\n11:42.460 --> 11:43.300\n Exactly.\n\n11:43.300 --> 11:45.260\n Back when we lived outside virtual reality.\n\n11:46.140 --> 11:47.020\n Exactly.\n\n11:47.020 --> 11:50.180\n So you chose live wire to mold a plastic.\n\n11:50.180 --> 11:52.820\n Exactly, because plastic implies,\n\n11:52.820 --> 11:54.380\n I mean, it's the term that's used in the field\n\n11:54.380 --> 11:57.780\n and so that's why we need to use it still for a while.\n\n11:57.780 --> 11:59.620\n But yeah, it implies something gets molded into shape\n\n11:59.620 --> 12:00.780\n and then holds that shape forever.\n\n12:00.780 --> 12:03.220\n But in fact, the whole system is completely changing.\n\n12:03.220 --> 12:07.700\n Then back to how malleable is the human brain\n\n12:07.700 --> 12:08.820\n at each stage of life.\n\n12:08.820 --> 12:13.820\n So what, just at a high level, is it malleable?\n\n12:13.940 --> 12:17.220\n So yes, and plasticity diminishes.\n\n12:17.220 --> 12:19.900\n But one of the things that I felt like\n\n12:19.900 --> 12:21.740\n I was able to put together for myself\n\n12:21.740 --> 12:23.900\n after reading thousands of papers on this issue\n\n12:23.900 --> 12:26.880\n is that different parts of the brain\n\n12:26.880 --> 12:30.820\n have different plasticity windows.\n\n12:30.820 --> 12:33.140\n So for example, with the visual cortex,\n\n12:33.140 --> 12:35.940\n that cements itself into place pretty quickly\n\n12:35.940 --> 12:37.740\n over the course of a few years.\n\n12:37.740 --> 12:41.020\n And I argue that's because of the stability of the data.\n\n12:41.020 --> 12:43.940\n In other words, what you're getting in from the world,\n\n12:43.940 --> 12:47.220\n you've got a certain number of angles, colors, shapes.\n\n12:47.220 --> 12:49.940\n It's essentially the world is visually stable.\n\n12:49.940 --> 12:52.420\n So that hardens around that data.\n\n12:52.420 --> 12:55.100\n As opposed to, let's say, the somatosensory cortex,\n\n12:55.100 --> 12:56.540\n which is the part that's taking information\n\n12:56.540 --> 12:58.580\n from your body, or the motor cortex right next to it,\n\n12:58.580 --> 13:00.380\n which is what drives your body.\n\n13:00.380 --> 13:01.880\n The fact is, bodies are always changing.\n\n13:01.880 --> 13:05.100\n You get taller over time, you get fatter, thinner,\n\n13:05.100 --> 13:06.980\n over time, you might break a leg\n\n13:06.980 --> 13:08.560\n and have to limp for a while, stuff like that.\n\n13:08.560 --> 13:11.740\n So because the data there is always changing,\n\n13:11.740 --> 13:12.900\n by the way, you might get on a bicycle,\n\n13:12.900 --> 13:15.660\n you might get on a surfboard, things like that.\n\n13:15.660 --> 13:16.780\n Because the data is always changing,\n\n13:16.780 --> 13:18.300\n that stays more malleable.\n\n13:19.260 --> 13:20.860\n And when you look through the brain,\n\n13:20.860 --> 13:23.940\n you find that it appears to be this,\n\n13:23.940 --> 13:26.660\n how stable the data is determines how fast\n\n13:26.660 --> 13:28.060\n something hardens into place.\n\n13:28.060 --> 13:30.000\n But the point is, different parts of the brain\n\n13:30.000 --> 13:31.940\n harden into place at different times.\n\n13:31.940 --> 13:33.840\n Do you think it's possible that,\n\n13:35.020 --> 13:38.700\n depending on how much data you get on different sensors,\n\n13:38.700 --> 13:41.480\n that it stays more malleable longer?\n\n13:41.480 --> 13:44.220\n So like, if you look at different cultures\n\n13:44.220 --> 13:47.580\n that experience, like if you keep your eyes closed,\n\n13:47.580 --> 13:48.860\n or maybe you're blind, I don't know,\n\n13:48.860 --> 13:51.180\n but let's say you keep your eyes closed\n\n13:51.180 --> 13:55.820\n for your entire life, then the visual cortex\n\n13:55.820 --> 13:58.660\n might be much less malleable.\n\n13:58.660 --> 14:01.300\n The reason I bring that up is like,\n\n14:01.300 --> 14:03.340\n well maybe we'll talk about brain computer interfaces\n\n14:03.340 --> 14:07.400\n a little bit down the line, but is this,\n\n14:08.500 --> 14:11.300\n is the malleability a genetic thing,\n\n14:11.300 --> 14:14.380\n or is it more about the data, like you said, that comes in?\n\n14:14.380 --> 14:17.980\n Ah, so the malleability itself is a genetic thing.\n\n14:17.980 --> 14:20.840\n The big trick that Mother Nature discovered with humans\n\n14:20.840 --> 14:24.220\n is make a system that's really flexible,\n\n14:24.220 --> 14:28.100\n as opposed to most other creatures to different degrees.\n\n14:28.100 --> 14:31.220\n So if you take an alligator, it's born,\n\n14:31.220 --> 14:34.180\n its brain does the same thing every generation.\n\n14:34.180 --> 14:36.220\n If you compare an alligator 100,000 years ago\n\n14:36.220 --> 14:38.460\n to an alligator now, they're essentially the same.\n\n14:39.660 --> 14:41.360\n We, on the other hand, as humans,\n\n14:41.360 --> 14:44.220\n drop into a world with a half baked brain,\n\n14:44.220 --> 14:48.180\n and what we require is to absorb the culture around us,\n\n14:48.180 --> 14:50.300\n and the language, and the beliefs, and the customs,\n\n14:50.300 --> 14:55.060\n and so on, that's what Mother Nature has done with us,\n\n14:55.060 --> 14:57.340\n and it's been a tremendously successful trick\n\n14:57.340 --> 15:00.120\n we've taken over the whole planet as a result of this.\n\n15:00.120 --> 15:01.220\n So that's an interesting point,\n\n15:01.220 --> 15:03.140\n I mean, just to link on it, that,\n\n15:03.140 --> 15:05.400\n I mean, this is a nice feature,\n\n15:05.400 --> 15:07.060\n like if you were to design a thing\n\n15:07.060 --> 15:11.780\n to survive in this world, do you put it at age zero\n\n15:11.780 --> 15:14.580\n already equipped to deal with the world\n\n15:14.580 --> 15:17.740\n in a hard coded way, or do you put it,\n\n15:17.740 --> 15:19.580\n do you make it malleable and just throw it in,\n\n15:19.580 --> 15:23.380\n take the risk that you're maybe going to die,\n\n15:23.380 --> 15:25.220\n but you're going to learn a lot in the process,\n\n15:25.220 --> 15:27.620\n and if you don't die, you'll learn a hell of a lot\n\n15:27.620 --> 15:29.300\n to be able to survive in the environment.\n\n15:29.300 --> 15:31.340\n So this is the experiment that Mother Nature ran,\n\n15:31.340 --> 15:34.980\n and it turns out that, for better or worse, we've won.\n\n15:34.980 --> 15:37.500\n I mean, yeah, we put other animals in the zoos,\n\n15:37.500 --> 15:38.620\n and we, yeah, that's right.\n\n15:38.620 --> 15:39.580\n AI might do better.\n\n15:39.580 --> 15:41.320\n Okay, fair enough, that's true.\n\n15:41.320 --> 15:43.620\n And maybe what the trick Mother Nature did\n\n15:43.620 --> 15:46.660\n is just the stepping stone to AI, but.\n\n15:46.660 --> 15:50.220\n So that's a beautiful feature of the human brain,\n\n15:50.220 --> 15:52.420\n that it's malleable, but let's,\n\n15:52.420 --> 15:56.380\n on the topic of Mother Nature, what do we start with?\n\n15:56.380 --> 15:58.420\n Like, how blank is the slate?\n\n15:58.420 --> 16:01.060\n Ah, so it's not actually a blank slate.\n\n16:01.060 --> 16:05.340\n What it's, it's terrific engineering that's set up in there,\n\n16:05.340 --> 16:07.700\n but much of that engineering has to do with,\n\n16:07.700 --> 16:10.100\n okay, just make sure that things get to the right place.\n\n16:10.100 --> 16:12.260\n For example, like the fibers from the eyes\n\n16:12.260 --> 16:13.840\n getting to the visual cortex,\n\n16:13.840 --> 16:15.640\n or all this very complicated machinery in the ear\n\n16:15.640 --> 16:17.700\n getting to the auditory cortex, and so on.\n\n16:17.700 --> 16:19.860\n So things, first of all, there's that.\n\n16:19.860 --> 16:21.520\n And then what we also come equipped with\n\n16:21.520 --> 16:24.580\n is the ability to absorb language\n\n16:24.580 --> 16:27.060\n and culture and beliefs, and so on.\n\n16:27.060 --> 16:28.600\n So you're already set up for that.\n\n16:28.600 --> 16:30.020\n So no matter what you're exposed to,\n\n16:30.020 --> 16:32.940\n you will absorb some sort of language.\n\n16:32.940 --> 16:34.980\n That's the trick, is how do you engineer something\n\n16:34.980 --> 16:37.300\n just enough that it's then a sponge\n\n16:37.300 --> 16:40.060\n that's ready to take in and fill in the blanks?\n\n16:40.060 --> 16:42.460\n How much of the malleability is hardware?\n\n16:42.460 --> 16:43.300\n How much is software?\n\n16:43.300 --> 16:45.100\n Is that useful at all in the brain?\n\n16:45.100 --> 16:46.980\n So what are we talking about?\n\n16:46.980 --> 16:51.980\n So there's neurons, there's synapses,\n\n16:52.100 --> 16:54.060\n and all kinds of different synapses,\n\n16:54.060 --> 16:55.900\n and there's chemical communication,\n\n16:55.900 --> 16:57.060\n like electrical signals,\n\n16:57.060 --> 17:01.520\n and there's chemical communication from the synapses.\n\n17:04.020 --> 17:09.020\n I would say the software would be the timing\n\n17:09.020 --> 17:11.540\n and the nature of the electrical signals, I guess,\n\n17:11.540 --> 17:14.140\n and the hardware would be the actual synapses.\n\n17:14.140 --> 17:16.860\n So here's the thing, this is why I really, if we can,\n\n17:16.860 --> 17:19.580\n I wanna get away from the hardware and software metaphor\n\n17:19.580 --> 17:21.900\n because what happens is,\n\n17:21.900 --> 17:25.100\n as activity passes through the system, it changes things.\n\n17:25.100 --> 17:27.880\n Now, the thing that computer engineers\n\n17:27.880 --> 17:30.300\n are really used to thinking about is synapses,\n\n17:30.300 --> 17:31.700\n where two neurons connect.\n\n17:31.700 --> 17:33.700\n Of course, each neuron connects with 10,000 of its neighbors,\n\n17:33.700 --> 17:35.360\n but at a point where they connect,\n\n17:36.860 --> 17:37.700\n what we're all used to thinking about\n\n17:37.700 --> 17:40.820\n is the changing of the strength of that connection,\n\n17:40.820 --> 17:42.240\n the synaptic weight.\n\n17:42.240 --> 17:44.560\n But in fact, everything is changing.\n\n17:44.560 --> 17:47.440\n The receptor distribution inside that neuron\n\n17:47.440 --> 17:49.600\n so that you're more or less sensitive\n\n17:49.600 --> 17:50.760\n to the neurotransmitter,\n\n17:50.760 --> 17:53.440\n then the structure of the neuron itself\n\n17:53.440 --> 17:54.440\n and what's happening there,\n\n17:54.440 --> 17:57.360\n all the way down to biochemical cascades inside the cell,\n\n17:57.360 --> 17:59.200\n all the way down to the nucleus,\n\n17:59.200 --> 18:00.920\n and for example, the epigenome,\n\n18:00.920 --> 18:05.600\n which is these little proteins that are attached to the DNA\n\n18:05.600 --> 18:07.680\n that cause conformational changes,\n\n18:07.680 --> 18:11.200\n that cause more genes to be expressed or repressed.\n\n18:11.200 --> 18:13.640\n All of these things are plastic.\n\n18:13.640 --> 18:15.960\n The reason that most people only talk\n\n18:15.960 --> 18:17.560\n about the synaptic weights\n\n18:17.560 --> 18:20.560\n is because that's really all we can measure well.\n\n18:20.560 --> 18:22.600\n And all this other stuff is really, really hard to see\n\n18:22.600 --> 18:23.600\n with our current technology.\n\n18:23.600 --> 18:25.840\n So essentially, that just gets ignored.\n\n18:25.840 --> 18:27.720\n But in fact, the system is plastic\n\n18:27.720 --> 18:28.880\n at all these different levels.\n\n18:28.880 --> 18:33.640\n And my way of thinking about this\n\n18:33.640 --> 18:37.560\n is an analogy to pace layers.\n\n18:37.560 --> 18:40.080\n So pace layers is a concept that Stewart Brand\n\n18:40.080 --> 18:43.000\n suggested about how to think about cities.\n\n18:43.000 --> 18:46.520\n So you have fashion, which changes rapidly in cities.\n\n18:46.520 --> 18:51.520\n You have governance, which changes more slowly.\n\n18:52.040 --> 18:54.440\n You have the structure, the buildings of a city,\n\n18:54.440 --> 18:57.760\n which changes more slowly, all the way down to nature.\n\n18:57.760 --> 18:59.560\n You've got all these different layers of things\n\n18:59.560 --> 19:02.680\n that are changing at different paces, at different speeds.\n\n19:02.680 --> 19:05.680\n I've taken that idea and mapped it onto the brain,\n\n19:05.680 --> 19:08.480\n which is to say you have some biochemical cascades\n\n19:08.480 --> 19:10.120\n that are just changing really rapidly\n\n19:10.120 --> 19:11.840\n when something happens, all the way down to things\n\n19:11.840 --> 19:14.520\n that are more and more cemented in there.\n\n19:14.520 --> 19:19.320\n And this actually allows us to understand a lot\n\n19:19.320 --> 19:20.920\n about particular kinds of things that happen.\n\n19:20.920 --> 19:22.160\n For example, one of the oldest,\n\n19:22.160 --> 19:24.680\n probably the oldest rule in neurology\n\n19:24.680 --> 19:27.520\n is called Ribot's Law, which is that older memories\n\n19:27.520 --> 19:29.600\n are more stable than newer memories.\n\n19:29.600 --> 19:32.640\n So when you get old and demented,\n\n19:32.640 --> 19:36.160\n you'll be able to remember things from your young life.\n\n19:36.160 --> 19:37.400\n Maybe you'll remember this podcast,\n\n19:37.400 --> 19:39.320\n but you won't remember what you did\n\n19:39.320 --> 19:41.520\n a month ago or a year ago.\n\n19:41.520 --> 19:43.440\n And this is a very weird structure, right?\n\n19:43.440 --> 19:44.640\n No other system works this way,\n\n19:44.640 --> 19:48.320\n where older memories are more stable than newer memories.\n\n19:48.320 --> 19:52.000\n But it's because through time,\n\n19:52.000 --> 19:53.520\n things get more and more cemented\n\n19:53.520 --> 19:56.280\n into deeper layers of the system.\n\n19:56.280 --> 19:59.880\n And so this is, I think, the way we have to think\n\n19:59.880 --> 20:03.080\n about the brain, not as, okay, you've got neurons,\n\n20:03.080 --> 20:04.880\n you've got synaptic weights, and that's it.\n\n20:04.880 --> 20:08.640\n So, yeah, so the idea of LiveWare and LiveWired\n\n20:08.640 --> 20:13.640\n is that it's like a, it's a gradual, yeah,\n\n20:14.480 --> 20:18.240\n it's a gradual spectrum between software and hardware.\n\n20:18.240 --> 20:22.000\n And so the metaphors completely doesn't make sense.\n\n20:22.000 --> 20:24.480\n Cause like when you talk about software and hardware,\n\n20:24.480 --> 20:26.480\n it's really hard lines.\n\n20:26.480 --> 20:31.480\n I mean, of course, software is unlike hard,\n\n20:31.480 --> 20:36.320\n but even hardware, but like, so there's two groups,\n\n20:36.320 --> 20:37.640\n but in the software world,\n\n20:37.640 --> 20:39.040\n there's levels of abstractions, right?\n\n20:39.040 --> 20:42.120\n There's the operating system, there's machine code,\n\n20:42.120 --> 20:44.520\n and then it gets higher and higher levels.\n\n20:44.520 --> 20:46.920\n But somehow that's actually fundamentally different\n\n20:46.920 --> 20:50.040\n than the layers of abstractions in the hardware.\n\n20:50.040 --> 20:53.160\n But in the brain, it's all like the same.\n\n20:53.160 --> 20:55.400\n And I love the city, the city metaphor.\n\n20:55.400 --> 20:57.880\n I mean, yeah, it's kind of mind blowing\n\n20:57.880 --> 21:01.440\n cause it's hard to know what to think about that.\n\n21:01.440 --> 21:03.200\n Like if I were to ask the question,\n\n21:04.160 --> 21:07.520\n this is an important question for machine learning is,\n\n21:07.520 --> 21:09.720\n how does the brain learn?\n\n21:09.720 --> 21:13.880\n So essentially you're saying that,\n\n21:13.880 --> 21:17.160\n I mean, it just learns on all of these different levels\n\n21:17.160 --> 21:19.040\n at all different paces.\n\n21:19.040 --> 21:19.880\n Exactly right.\n\n21:19.880 --> 21:21.360\n And as a result, what happens is\n\n21:21.360 --> 21:24.480\n as you practice something, you get good at something,\n\n21:24.480 --> 21:26.600\n you're physically changing the circuitry,\n\n21:26.600 --> 21:30.000\n you're adapting your brain around the thing\n\n21:30.000 --> 21:31.280\n that is relevant to you.\n\n21:31.280 --> 21:34.920\n So let's say you take up, do you know how to surf?\n\n21:34.920 --> 21:35.760\n Nope.\n\n21:35.760 --> 21:36.600\n Okay, great.\n\n21:36.600 --> 21:39.200\n So let's say you take up surfing now at this age.\n\n21:39.200 --> 21:41.080\n What happens is you'll be terrible at first,\n\n21:41.080 --> 21:42.000\n you don't know how to operate your body,\n\n21:42.000 --> 21:43.960\n you don't know how to read the waves, things like that.\n\n21:43.960 --> 21:45.680\n And through time you get better and better.\n\n21:45.680 --> 21:46.960\n What you're doing is you're burning that\n\n21:46.960 --> 21:48.600\n into the actual circuitry of your brain.\n\n21:48.600 --> 21:50.800\n You're of course conscious when you're first doing it,\n\n21:50.800 --> 21:52.120\n you're thinking about, okay, where am I doing?\n\n21:52.120 --> 21:53.600\n What's my body weight?\n\n21:53.600 --> 21:55.320\n But eventually when you become a pro at it,\n\n21:55.320 --> 21:57.160\n you are not conscious of it at all.\n\n21:57.160 --> 22:00.200\n In fact, you can't even unpack what it is that you did.\n\n22:00.200 --> 22:01.920\n Think about riding a bicycle.\n\n22:01.920 --> 22:04.080\n You can't describe how you're doing it,\n\n22:04.080 --> 22:05.600\n you're just doing it, you're changing your balance\n\n22:05.600 --> 22:08.040\n when you come, you know, you do this to go to a stop.\n\n22:08.040 --> 22:10.800\n So this is what we're constantly doing\n\n22:10.800 --> 22:14.320\n is actually shaping our own circuitry\n\n22:14.320 --> 22:16.000\n based on what is relevant for us.\n\n22:16.000 --> 22:18.800\n Survival, of course, being the top thing that's relevant.\n\n22:18.800 --> 22:21.440\n But interestingly, especially with humans,\n\n22:21.440 --> 22:23.400\n we have these particular goals in our lives,\n\n22:23.400 --> 22:25.600\n computer science, neuroscience, whatever.\n\n22:25.600 --> 22:28.680\n And so we actually shape our circuitry around that.\n\n22:28.680 --> 22:31.400\n I mean, you mentioned this gets slower and slower with age,\n\n22:31.400 --> 22:36.080\n but is there, like I think I've read and spoken offline,\n\n22:36.080 --> 22:41.080\n even on this podcast with a developmental neurobiologist,\n\n22:41.320 --> 22:43.400\n I guess would be the right terminology,\n\n22:43.400 --> 22:45.520\n is like looking at the very early,\n\n22:45.520 --> 22:50.440\n like from embryonic stem cells to the creation of the brain.\n\n22:50.440 --> 22:55.320\n And like, that's mind blowing how much stuff happens there.\n\n22:55.320 --> 22:57.440\n So it's very malleable at that stage.\n\n22:59.280 --> 23:01.560\n And then, but after that,\n\n23:01.560 --> 23:04.600\n at which point does it stop being malleable?\n\n23:04.600 --> 23:06.040\n So that's the interesting thing\n\n23:06.040 --> 23:08.480\n is that it remains malleable your whole life.\n\n23:08.480 --> 23:10.200\n So even when you're an old person,\n\n23:10.200 --> 23:13.120\n you'll be able to remember new faces and names,\n\n23:13.120 --> 23:15.680\n you'll be able to learn new sorts of tasks.\n\n23:15.680 --> 23:16.520\n And thank goodness,\n\n23:16.520 --> 23:17.960\n cause the world is changing rapidly\n\n23:17.960 --> 23:19.720\n in terms of technology and so on.\n\n23:19.720 --> 23:21.400\n I just sent my mother an Alexa\n\n23:21.400 --> 23:23.400\n and she figured out how to go on the settings\n\n23:23.400 --> 23:24.240\n and do the thing.\n\n23:24.240 --> 23:26.960\n And I was really impressed that she was able to do it.\n\n23:26.960 --> 23:28.520\n So there are parts of the brain\n\n23:28.520 --> 23:30.360\n that remain malleable their whole life.\n\n23:30.360 --> 23:34.200\n The interesting part is that really your goal\n\n23:34.200 --> 23:36.080\n is to make an internal model of the world.\n\n23:36.080 --> 23:39.120\n Your goal is to say, okay,\n\n23:39.120 --> 23:42.280\n the brain is trapped in silence and darkness,\n\n23:42.280 --> 23:43.520\n and it's trying to understand\n\n23:43.520 --> 23:46.040\n how the world works out there, right?\n\n23:46.040 --> 23:47.080\n I love that image.\n\n23:47.080 --> 23:48.240\n Yeah, I guess it is.\n\n23:48.240 --> 23:49.080\n Yeah.\n\n23:49.080 --> 23:53.040\n You forget, it's like this lonely thing\n\n23:53.040 --> 23:54.640\n is sitting in its own container\n\n23:54.640 --> 23:57.080\n and trying to actually throw a few sensors,\n\n23:57.080 --> 23:58.760\n figure out what the hell's going on.\n\n23:58.760 --> 23:59.800\n You know what I sometimes think about\n\n23:59.800 --> 24:03.120\n is that movie, The Martian with Matt Damon,\n\n24:03.120 --> 24:05.560\n the, I mean, it was written in a book, of course,\n\n24:05.560 --> 24:08.400\n but the movie poster shows Matt Damon\n\n24:08.400 --> 24:09.800\n all alone on the red planet.\n\n24:09.800 --> 24:12.520\n And I think, God, that's actually what it's like\n\n24:12.520 --> 24:16.360\n to be inside your head and my head and anybody's head\n\n24:16.360 --> 24:20.200\n is that you're essentially on your own planet in there.\n\n24:20.200 --> 24:21.600\n And I'm essentially on my own planet.\n\n24:21.600 --> 24:24.080\n And everyone's got their own world\n\n24:24.080 --> 24:26.680\n where you've absorbed all of your experiences\n\n24:26.680 --> 24:28.000\n up to this moment in your life\n\n24:28.000 --> 24:29.560\n that have made you exactly who you are\n\n24:29.560 --> 24:31.120\n and same for me and everyone.\n\n24:31.120 --> 24:36.120\n And we've got this very thin bandwidth of communication.\n\n24:36.680 --> 24:38.720\n And I'll say something like,\n\n24:38.720 --> 24:40.720\n oh yeah, that tastes just like peaches.\n\n24:40.720 --> 24:42.840\n And you'll say, oh, I know what you mean.\n\n24:42.840 --> 24:44.280\n But the experience, of course,\n\n24:44.280 --> 24:46.560\n might be vastly different for us.\n\n24:47.680 --> 24:48.520\n But anyway, yes.\n\n24:48.520 --> 24:50.520\n So the brain is trapped in silence and darkness,\n\n24:50.520 --> 24:53.280\n each one of us, and what it's trying to do,\n\n24:53.280 --> 24:54.120\n this is the important part,\n\n24:54.120 --> 24:55.720\n it's trying to make an internal model\n\n24:55.720 --> 24:56.560\n of what's going on out there,\n\n24:56.560 --> 24:58.800\n as in how do I function in the world?\n\n24:58.800 --> 25:00.800\n How do I interact with other people?\n\n25:00.800 --> 25:02.680\n Do I say something nice and polite?\n\n25:02.680 --> 25:04.040\n Do I say something aggressive and mean?\n\n25:04.040 --> 25:05.560\n Do I, you know, all these things\n\n25:05.560 --> 25:08.440\n that it's putting together about the world.\n\n25:08.440 --> 25:12.320\n And I think what happens when people get older and older,\n\n25:12.320 --> 25:15.480\n it may not be that plasticity is diminishing.\n\n25:15.480 --> 25:18.160\n It may be that their internal model essentially\n\n25:18.160 --> 25:20.120\n has set itself up in a way where it says,\n\n25:20.120 --> 25:21.160\n okay, I've pretty much got\n\n25:21.160 --> 25:22.800\n a really good understanding of the world now,\n\n25:22.800 --> 25:25.400\n and I don't really need to change, right?\n\n25:25.400 --> 25:28.600\n So when much older people find themselves\n\n25:28.600 --> 25:30.800\n in a situation where they need to change,\n\n25:30.800 --> 25:33.280\n they can actually are able to do it.\n\n25:33.280 --> 25:34.760\n It's just that I think this notion\n\n25:34.760 --> 25:36.960\n that we all have that plasticity diminishes\n\n25:36.960 --> 25:38.880\n as we grow older is in part\n\n25:38.880 --> 25:41.480\n because the motivation isn't there.\n\n25:41.480 --> 25:44.120\n But if you were 80 and you get fired from your job\n\n25:44.120 --> 25:45.720\n and suddenly had to figure out\n\n25:45.720 --> 25:47.440\n how to program a WordPress site or something,\n\n25:47.440 --> 25:48.920\n you'd figure it out.\n\n25:48.920 --> 25:49.760\n Got it.\n\n25:49.760 --> 25:53.720\n So the capability, the possibility of change is there.\n\n25:53.720 --> 25:57.040\n But then that's the highest challenge,\n\n25:57.040 --> 26:00.880\n the interesting challenge to this plasticity,\n\n26:00.880 --> 26:03.440\n to this liveware system.\n\n26:03.440 --> 26:06.000\n If we could talk about brain computer interfaces\n\n26:06.000 --> 26:09.040\n and Neuralink, what are your thoughts\n\n26:09.040 --> 26:13.680\n about the efforts of Elon Musk, Neuralink, BCI in general\n\n26:13.680 --> 26:18.320\n in this regard, which is adding a machine,\n\n26:18.320 --> 26:21.720\n a computer, the capability of a computer\n\n26:21.720 --> 26:22.800\n to communicate with the brain\n\n26:22.800 --> 26:24.920\n and the brain to communicate with a computer\n\n26:24.920 --> 26:26.800\n at the very basic applications\n\n26:26.800 --> 26:28.880\n and then like the futuristic kind of thoughts.\n\n26:28.880 --> 26:30.920\n Yeah, first of all, it's terrific\n\n26:30.920 --> 26:32.360\n that people are jumping in and doing that\n\n26:32.360 --> 26:34.480\n because it's clearly the future.\n\n26:34.480 --> 26:37.280\n The interesting part is our brains have pretty good methods\n\n26:37.280 --> 26:38.760\n of interacting with technology.\n\n26:38.760 --> 26:41.520\n So maybe it's your fat thumbs on a cell phone or something,\n\n26:41.520 --> 26:44.600\n but, or maybe it's watching a YouTube video\n\n26:44.600 --> 26:45.840\n and getting into your eye that way.\n\n26:45.840 --> 26:48.360\n But we have pretty rapid ways of communicating\n\n26:48.360 --> 26:49.960\n with technology and getting data.\n\n26:49.960 --> 26:52.760\n So if you actually crack open the skull\n\n26:52.760 --> 26:55.600\n and go into the inner sanctum of the brain,\n\n26:56.520 --> 26:58.200\n you might be able to get a little bit faster,\n\n26:58.200 --> 27:03.200\n but I'll tell you, I'm not so sanguine\n\n27:03.400 --> 27:06.640\n on the future of that as a business.\n\n27:06.640 --> 27:07.480\n And I'll tell you why.\n\n27:07.480 --> 27:10.040\n It's because there are various ways\n\n27:10.040 --> 27:11.160\n of getting data in and out\n\n27:11.160 --> 27:14.480\n and an open head surgery is a big deal.\n\n27:14.480 --> 27:16.560\n Neurosurgeons don't wanna do it\n\n27:16.560 --> 27:18.000\n because there's always risk of death\n\n27:18.000 --> 27:19.640\n and infection on the table.\n\n27:19.640 --> 27:23.200\n And also it's not clear how many people would say,\n\n27:23.200 --> 27:26.000\n I'm gonna volunteer to get something in my head\n\n27:26.000 --> 27:29.800\n so that I can text faster, 20% faster.\n\n27:29.800 --> 27:33.720\n So I think it's, mother nature surrounds the brain\n\n27:33.720 --> 27:37.840\n with this armored bunker of the skull\n\n27:37.840 --> 27:39.680\n because it's a very delicate material.\n\n27:39.680 --> 27:41.680\n And there's an expression in neurosurgery\n\n27:44.200 --> 27:46.480\n about the brain is,\n\n27:46.480 --> 27:49.080\n the person is never the same after you open up their skull.\n\n27:49.080 --> 27:51.640\n Now, whether or not that's true or whatever, who cares?\n\n27:51.640 --> 27:54.080\n But it's a big deal to do an open head surgery.\n\n27:54.080 --> 27:57.520\n So what I'm interested in is how can we get information\n\n27:57.520 --> 27:58.360\n in and out of the brain\n\n27:58.360 --> 28:00.680\n without having to crack the skull open?\n\n28:00.680 --> 28:03.880\n Without messing with the biological part,\n\n28:03.880 --> 28:06.480\n directly connecting or messing\n\n28:06.480 --> 28:10.440\n with the intricate biological thing that we got going on\n\n28:10.440 --> 28:11.920\n and it seems to be working.\n\n28:11.920 --> 28:12.760\n Yeah, exactly.\n\n28:12.760 --> 28:15.400\n And by the way, where Neuralink is going,\n\n28:15.400 --> 28:18.240\n which is wonderful, is going to be in patient cases.\n\n28:18.240 --> 28:20.520\n It really matters for all kinds of surgeries\n\n28:20.520 --> 28:21.760\n that a person needs,\n\n28:21.760 --> 28:24.000\n whether for Parkinson's or epilepsy or whatever.\n\n28:24.000 --> 28:25.680\n It's a terrific new technology\n\n28:25.680 --> 28:27.760\n for essentially sewing electrodes in there\n\n28:27.760 --> 28:30.000\n and getting more higher density of electrodes.\n\n28:30.000 --> 28:30.960\n So that's great.\n\n28:30.960 --> 28:34.400\n I just don't think as far as the future of BCI goes,\n\n28:34.400 --> 28:38.400\n I don't suspect that people will go in and say,\n\n28:38.400 --> 28:40.640\n yeah, drill a hole in my head and do this.\n\n28:40.640 --> 28:41.680\n Well, it's interesting\n\n28:41.680 --> 28:44.280\n because I think there's a similar intuition\n\n28:44.280 --> 28:46.680\n but say in the world of autonomous vehicles\n\n28:46.680 --> 28:49.400\n that folks know how hard it is\n\n28:49.400 --> 28:51.560\n and it seems damn impossible.\n\n28:51.560 --> 28:52.960\n The similar intuition about,\n\n28:52.960 --> 28:54.680\n I'm sticking on the Elon Musk thing\n\n28:54.680 --> 28:57.040\n is just a good, easy example.\n\n28:57.040 --> 28:59.680\n Similar intuition about colonizing Mars,\n\n28:59.680 --> 29:01.440\n it like, if you really think about it,\n\n29:01.440 --> 29:04.760\n it seems extremely difficult.\n\n29:04.760 --> 29:08.960\n And almost, I mean, just technically difficult\n\n29:08.960 --> 29:12.000\n to a degree where you wanna ask,\n\n29:12.000 --> 29:14.840\n is it really worth doing, worth trying?\n\n29:14.840 --> 29:17.880\n And then the same is applied with BCI.\n\n29:17.880 --> 29:20.400\n But the thing about the future\n\n29:21.800 --> 29:23.720\n is it's hard to predict.\n\n29:23.720 --> 29:26.680\n So the exciting thing to me with,\n\n29:26.680 --> 29:29.640\n so once it does, once if successful,\n\n29:29.640 --> 29:31.640\n it's able to help patients,\n\n29:31.640 --> 29:36.640\n it may be able to discover something very surprising\n\n29:36.680 --> 29:39.560\n of our ability to directly communicate with the brain.\n\n29:39.560 --> 29:42.840\n So exactly what you're interested in is figuring out\n\n29:42.840 --> 29:46.640\n how to play with this malleable brain,\n\n29:46.640 --> 29:49.480\n but like help assist it somehow.\n\n29:49.480 --> 29:52.240\n I mean, it's such a compelling notion to me\n\n29:52.240 --> 29:53.640\n that we're now working on\n\n29:53.640 --> 29:55.960\n all these exciting machine learning systems\n\n29:55.960 --> 29:59.760\n that are able to learn from data.\n\n29:59.760 --> 30:04.040\n And then if we can have this other brain\n\n30:04.040 --> 30:05.600\n that's a learning system,\n\n30:05.600 --> 30:09.600\n that's live wired on the human side\n\n30:09.600 --> 30:11.520\n and them to be able to communicate,\n\n30:11.520 --> 30:14.120\n it's like a self play mechanism\n\n30:14.120 --> 30:17.800\n was able to beat the world champion at Go.\n\n30:17.800 --> 30:19.560\n So they can play with each other,\n\n30:19.560 --> 30:22.440\n the computer and the brain, like when you sleep.\n\n30:22.440 --> 30:24.520\n I mean, there's a lot of futuristic kind of things\n\n30:24.520 --> 30:27.640\n that it's just exciting possibilities,\n\n30:27.640 --> 30:30.240\n but I hear you, we understand so little\n\n30:30.240 --> 30:34.080\n about the actual intricacies of the communication\n\n30:34.080 --> 30:38.480\n of the brain that it's hard to find the common language.\n\n30:38.480 --> 30:43.480\n Well, interestingly, the technologies that have been built\n\n30:45.800 --> 30:48.320\n don't actually require the perfect common language.\n\n30:48.320 --> 30:51.080\n So for example, hundreds of thousands of people\n\n30:51.080 --> 30:52.440\n are walking around with artificial ears\n\n30:52.440 --> 30:53.440\n and artificial eyes,\n\n30:53.440 --> 30:56.920\n meaning cochlear implants or retinal implants.\n\n30:56.920 --> 31:00.320\n So this is, you take a essentially digital microphone,\n\n31:00.320 --> 31:03.240\n you slip an electrode strip into the inner ear\n\n31:03.240 --> 31:05.160\n and people can learn how to hear that way,\n\n31:05.160 --> 31:06.600\n or you take an electrode grid\n\n31:06.600 --> 31:09.240\n and you plug it into the retina at the back of the eye\n\n31:09.240 --> 31:11.160\n and people can learn how to see that way.\n\n31:11.160 --> 31:13.880\n The interesting part is those devices\n\n31:13.880 --> 31:17.120\n don't speak exactly the natural biological language,\n\n31:17.120 --> 31:19.400\n they speak the dialect of Silicon Valley.\n\n31:19.400 --> 31:24.360\n And it turns out that as recently as about 25 years ago,\n\n31:24.360 --> 31:26.520\n a lot of people thought this was never gonna work.\n\n31:26.520 --> 31:28.960\n They thought it wasn't gonna work for that reason,\n\n31:28.960 --> 31:30.360\n but the brain figures it out.\n\n31:30.360 --> 31:32.200\n It's really good at saying, okay, look,\n\n31:32.200 --> 31:34.200\n there's some correlation between what I can touch\n\n31:34.200 --> 31:35.840\n and feel and hear and so on,\n\n31:35.840 --> 31:37.040\n and the data that's coming in,\n\n31:37.040 --> 31:41.520\n or between I clap my hands and I have signals coming in there\n\n31:41.520 --> 31:44.240\n and it figures out how to speak any language.\n\n31:44.240 --> 31:45.080\n Oh, that's fascinating.\n\n31:45.080 --> 31:50.000\n So like no matter if it's Neuralink,\n\n31:50.000 --> 31:51.760\n so directly communicating with the brain,\n\n31:51.760 --> 31:54.720\n or it's a smartphone or Google Glass,\n\n31:54.720 --> 31:58.800\n or the brain figures out the efficient way of communication.\n\n31:58.800 --> 32:00.200\n Well, exactly, exactly.\n\n32:00.200 --> 32:03.680\n And what I propose is the potato head theory of evolution,\n\n32:03.680 --> 32:08.320\n which is that all our eyes and nose and mouth and ears\n\n32:08.320 --> 32:10.760\n and fingertips, all this stuff is just plug and play.\n\n32:10.760 --> 32:12.760\n And the brain can figure out\n\n32:12.760 --> 32:14.160\n what to do with the data that comes in.\n\n32:14.160 --> 32:17.600\n And part of the reason that I think this is right,\n\n32:17.600 --> 32:18.960\n and I care so deeply about this,\n\n32:18.960 --> 32:20.360\n is when you look across the animal kingdom,\n\n32:20.360 --> 32:23.520\n you find all kinds of weird peripheral devices plugged in,\n\n32:23.520 --> 32:25.760\n and the brain figures out what to do with the data.\n\n32:25.760 --> 32:27.360\n And I don't believe that Mother Nature\n\n32:27.360 --> 32:32.360\n has to reinvent the principles of brain operation each time\n\n32:32.360 --> 32:33.800\n to say, oh, now I'm gonna have heat pits\n\n32:33.800 --> 32:34.640\n to detect infrared.\n\n32:34.640 --> 32:36.280\n Now I'm gonna have something\n\n32:36.280 --> 32:39.200\n to detect electroreceptors on the body.\n\n32:39.200 --> 32:40.040\n Now I'm gonna detect something\n\n32:40.040 --> 32:42.520\n to pick up the magnetic field of the earth\n\n32:42.520 --> 32:43.960\n with cryptochromes in the eye.\n\n32:43.960 --> 32:45.800\n And so instead the brain says, oh, I got it.\n\n32:45.800 --> 32:47.240\n There's data coming in.\n\n32:47.240 --> 32:48.080\n Is that useful?\n\n32:48.080 --> 32:48.920\n Can I do something with it?\n\n32:48.920 --> 32:50.440\n Oh, great, I'm gonna mold myself\n\n32:50.440 --> 32:52.640\n around the data that's coming in.\n\n32:52.640 --> 32:55.440\n It's kind of fascinating to think that,\n\n32:55.440 --> 32:56.560\n we think of smartphones\n\n32:56.560 --> 32:58.760\n and all this new technology as novel.\n\n32:58.760 --> 33:02.680\n It's totally novel as outside of what evolution\n\n33:02.680 --> 33:05.600\n ever intended or like what nature ever intended.\n\n33:05.600 --> 33:08.400\n It's fascinating to think that like the entirety\n\n33:08.400 --> 33:10.960\n of the process of evolution is perfectly fine\n\n33:10.960 --> 33:14.200\n and ready for the smartphone and the internet.\n\n33:14.200 --> 33:15.240\n Like it's ready.\n\n33:15.240 --> 33:17.120\n It's ready to be valuable to that.\n\n33:17.120 --> 33:21.440\n And whatever comes to cyborgs, to virtual reality,\n\n33:21.440 --> 33:23.480\n we kind of think like, this is, you know,\n\n33:23.480 --> 33:27.000\n there's all these like books written about what's natural\n\n33:27.000 --> 33:29.600\n and we're like destroying our natural cells\n\n33:29.600 --> 33:32.560\n by like embracing all this technology.\n\n33:32.560 --> 33:34.520\n It's kind of, you know,\n\n33:34.520 --> 33:36.480\n probably not giving the brain enough credit.\n\n33:36.480 --> 33:40.240\n Like this thing is just fine with new tech.\n\n33:40.240 --> 33:41.840\n Oh, exactly, it wraps itself around.\n\n33:41.840 --> 33:43.120\n And by the way, wait till you have kids.\n\n33:43.120 --> 33:46.320\n You'll see the ease with which they pick up on stuff.\n\n33:46.320 --> 33:50.280\n And as Kevin Kelly said,\n\n33:50.280 --> 33:54.480\n technology is what gets invented after you're born.\n\n33:54.480 --> 33:56.280\n But the stuff that already exists when you're born,\n\n33:56.280 --> 33:58.120\n that's not even tech, that's just background furniture.\n\n33:58.120 --> 34:00.840\n Like the fact that the iPad exists for my son and daughter,\n\n34:00.840 --> 34:02.320\n like that's just background furniture.\n\n34:02.320 --> 34:06.240\n So, yeah, it's because we have\n\n34:06.240 --> 34:08.200\n this incredibly malleable system,\n\n34:08.200 --> 34:10.680\n that just absorbs whatever is going on in the world\n\n34:10.680 --> 34:11.840\n and learns what to do with it.\n\n34:11.840 --> 34:15.400\n So do you think, just to linger for a little bit more,\n\n34:15.400 --> 34:20.400\n do you think it's possible to co adjust?\n\n34:22.160 --> 34:25.400\n Like we're kind of, you know,\n\n34:25.400 --> 34:27.880\n for the machine to adjust to the brain,\n\n34:27.880 --> 34:29.240\n for the brain to adjust to the machine.\n\n34:29.240 --> 34:31.040\n I guess that's what's already happening.\n\n34:31.040 --> 34:32.360\n Sure, that is what's happening.\n\n34:32.360 --> 34:34.640\n So for example, when you put electrodes\n\n34:34.640 --> 34:37.200\n in the motor cortex to control a robotic arm\n\n34:37.200 --> 34:39.240\n for somebody who's paralyzed,\n\n34:39.240 --> 34:41.080\n the engineers do a lot of work to figure out,\n\n34:41.080 --> 34:42.840\n okay, what can we do with the algorithm here\n\n34:42.840 --> 34:45.640\n so that we can detect what's going on from these cells\n\n34:45.640 --> 34:49.760\n and figure out how to best program the robotic arm to move\n\n34:49.760 --> 34:51.920\n given the data that we're measuring from these cells.\n\n34:51.920 --> 34:54.560\n But also the brain is learning too.\n\n34:54.560 --> 34:57.040\n So, you know, the paralyzed woman says,\n\n34:57.040 --> 34:58.840\n wait, I'm trying to grab this thing.\n\n34:58.840 --> 35:00.880\n And by the way, it's all about relevance.\n\n35:00.880 --> 35:04.040\n So if there's a piece of food there and she's hungry,\n\n35:04.040 --> 35:08.240\n she'll figure out how to get this food into her mouth\n\n35:08.240 --> 35:11.320\n with the robotic arm because that is what matters.\n\n35:13.240 --> 35:15.520\n Well, that's, okay, first of all,\n\n35:15.520 --> 35:17.640\n that paints a really promising and beautiful,\n\n35:17.640 --> 35:20.160\n for some reason, really optimistic picture\n\n35:20.160 --> 35:25.160\n that, you know, our brain is able to adjust to so much.\n\n35:26.320 --> 35:29.640\n You know, so many things happened this year, 2020,\n\n35:29.640 --> 35:32.960\n that you think like, how are we ever going to deal with it?\n\n35:32.960 --> 35:35.680\n And it's somehow encouraging\n\n35:35.680 --> 35:40.680\n and inspiring that like we're going to be okay.\n\n35:41.120 --> 35:41.960\n Well, that's right.\n\n35:41.960 --> 35:45.080\n I actually think, so 2020 has been an awful year\n\n35:45.080 --> 35:46.960\n for almost everybody in many ways,\n\n35:46.960 --> 35:50.440\n but the one silver lining has to do with brain plasticity,\n\n35:50.440 --> 35:54.080\n which is to say we've all been on our, you know,\n\n35:54.080 --> 35:56.480\n on our gerbil wheels, we've all been in our routines.\n\n35:56.480 --> 35:58.600\n And, you know, as I mentioned,\n\n35:58.600 --> 36:00.760\n our internal models are all about\n\n36:00.760 --> 36:02.320\n how do you maximally succeed?\n\n36:02.320 --> 36:04.560\n How do you optimize your operation\n\n36:04.560 --> 36:07.240\n in this circumstance where you are, right?\n\n36:07.240 --> 36:09.080\n And then all of a sudden, bang, 2020 comes,\n\n36:09.080 --> 36:10.920\n we're completely off our wheels.\n\n36:10.920 --> 36:14.880\n We're having to create new things all the time\n\n36:14.880 --> 36:15.960\n and figure out how to do it.\n\n36:15.960 --> 36:18.720\n And that is terrific for brain plasticity because,\n\n36:18.720 --> 36:23.480\n and we know this because there are very large studies\n\n36:23.480 --> 36:26.480\n on older people who stay cognitively active\n\n36:26.480 --> 36:28.000\n their whole lives.\n\n36:28.000 --> 36:31.760\n Some fraction of them have Alzheimer's disease\n\n36:31.760 --> 36:34.640\n physically, but nobody knows that when they're alive.\n\n36:34.640 --> 36:36.000\n Even though their brain is getting chewed up\n\n36:36.000 --> 36:38.600\n with the ravages of Alzheimer's,\n\n36:38.600 --> 36:40.000\n cognitively they're doing just fine.\n\n36:40.000 --> 36:40.840\n Why?\n\n36:40.840 --> 36:44.080\n It's because they're challenged all the time.\n\n36:44.080 --> 36:45.520\n They've got all these new things going on,\n\n36:45.520 --> 36:47.200\n all this novelty, all these responsibilities,\n\n36:47.200 --> 36:49.640\n chores, social life, all these things happening.\n\n36:49.640 --> 36:52.760\n And as a result, they're constantly building new roadways,\n\n36:52.760 --> 36:54.680\n even as parts degrade.\n\n36:54.680 --> 36:57.720\n And that's the only good news is that\n\n36:57.720 --> 36:59.480\n we are in a situation where suddenly\n\n36:59.480 --> 37:02.000\n we can't just operate like automata anymore.\n\n37:02.000 --> 37:05.520\n We have to think of completely new ways to do things.\n\n37:05.520 --> 37:06.720\n And that's wonderful.\n\n37:07.880 --> 37:11.200\n I don't know why this question popped into my head.\n\n37:11.200 --> 37:16.080\n It's quite absurd, but are we gonna be okay?\n\n37:16.080 --> 37:17.200\n Yeah.\n\n37:17.200 --> 37:19.640\n You said this is the promising silver lining\n\n37:19.640 --> 37:20.480\n just from your own,\n\n37:20.480 --> 37:22.840\n cause you've written about this and thought about this\n\n37:22.840 --> 37:25.240\n outside of maybe even the plasticity of the brain,\n\n37:25.240 --> 37:29.920\n but just this whole pandemic kind of changed the way\n\n37:29.920 --> 37:34.920\n it knocked us out of this hamster wheel like that of habit.\n\n37:35.560 --> 37:39.400\n A lot of people had to reinvent themselves.\n\n37:39.400 --> 37:42.240\n Unfortunately, and I have a lot of friends\n\n37:42.240 --> 37:47.240\n who either already or are going to lose their business,\n\n37:48.160 --> 37:52.720\n is basically it's taking the dreams that people have had\n\n37:52.720 --> 37:57.720\n and said this dream, this particular dream you've had\n\n37:58.160 --> 38:00.080\n will no longer be possible.\n\n38:00.080 --> 38:02.040\n So you have to find something new.\n\n38:02.040 --> 38:06.000\n What are your, are we gonna be okay?\n\n38:06.000 --> 38:08.080\n Yeah, we'll be okay in the sense that,\n\n38:08.080 --> 38:09.560\n I mean, it's gonna be a rough time\n\n38:09.560 --> 38:11.800\n for many or most people,\n\n38:11.800 --> 38:16.120\n but in the sense that it is sometimes useful\n\n38:18.000 --> 38:20.760\n to find that what you thought was your dream\n\n38:20.760 --> 38:24.520\n was not the thing that you're going to do.\n\n38:24.520 --> 38:26.760\n This is obviously the plot in lots of Hollywood movies\n\n38:26.760 --> 38:27.920\n that someone says, I'm gonna do this,\n\n38:27.920 --> 38:29.280\n and then that gets foiled\n\n38:29.280 --> 38:31.080\n and they end up doing something better.\n\n38:31.080 --> 38:32.320\n But this is true in life.\n\n38:32.320 --> 38:37.320\n I mean, in general, even though we plan our lives\n\n38:38.440 --> 38:42.080\n as best we can, it's predicated on our notion of,\n\n38:42.080 --> 38:43.600\n okay, given everything that's around me,\n\n38:43.600 --> 38:45.800\n this is what's possible for me next.\n\n38:47.040 --> 38:49.400\n But it takes 2020 to knock you off that\n\n38:49.400 --> 38:50.840\n where you think, oh, well, actually,\n\n38:50.840 --> 38:52.680\n maybe there's something I can be doing\n\n38:52.680 --> 38:54.320\n that's bigger, that's better.\n\n38:54.320 --> 38:56.560\n Yeah, you know, for me, one exciting thing,\n\n38:56.560 --> 38:59.600\n and I just talked to Grant Sanderson.\n\n38:59.600 --> 39:00.680\n I don't know if you know who he is.\n\n39:00.680 --> 39:03.600\n He's a 3Blue1Brown, it's a YouTube channel.\n\n39:03.600 --> 39:08.200\n He does, he's a, if you see it, you would recognize it.\n\n39:08.200 --> 39:11.120\n He's like a really famous math guy,\n\n39:11.120 --> 39:12.400\n and he's a math educator,\n\n39:12.400 --> 39:15.040\n and he does these incredible, beautiful videos.\n\n39:15.040 --> 39:17.000\n And now I see sort of at MIT,\n\n39:17.000 --> 39:19.680\n folks are struggling to try to figure out,\n\n39:19.680 --> 39:21.800\n you know, if we do teach remotely,\n\n39:21.800 --> 39:23.560\n how do we do it effectively?\n\n39:23.560 --> 39:27.960\n So you have these world class researchers\n\n39:27.960 --> 39:30.240\n and professors trying to figure out\n\n39:30.240 --> 39:33.760\n how to put content online that teaches people.\n\n39:33.760 --> 39:37.720\n And to me, a possible future of that is,\n\n39:37.720 --> 39:42.720\n you know, Nobel Prize winning faculty become YouTubers.\n\n39:42.720 --> 39:47.720\n Like that to me is so exciting, like what Grant said,\n\n39:47.720 --> 39:52.480\n which is like the possibility of creating canonical videos\n\n39:52.480 --> 39:55.000\n on the thing you're a world expert in.\n\n39:55.000 --> 39:56.880\n You know, there's so many topics.\n\n39:56.880 --> 40:00.880\n It just, the world doesn't, you know, there's faculty.\n\n40:00.880 --> 40:02.120\n I mentioned Russ Tedrick.\n\n40:02.120 --> 40:04.240\n There's all these people in robotics\n\n40:04.240 --> 40:07.880\n that are experts in a particular beautiful field\n\n40:07.880 --> 40:09.840\n on which there's only just papers.\n\n40:09.840 --> 40:12.680\n There's no popular book.\n\n40:12.680 --> 40:16.400\n There's no clean canonical video\n\n40:16.400 --> 40:18.120\n showing the beauty of a subject.\n\n40:18.120 --> 40:22.360\n And one possibility is they try to create that\n\n40:22.360 --> 40:25.400\n and share it with the world.\n\n40:25.400 --> 40:26.400\n This is the beautiful thing.\n\n40:26.400 --> 40:28.880\n This of course has been happening for a while already.\n\n40:28.880 --> 40:31.720\n I mean, for example, when I go and I give book talks,\n\n40:31.720 --> 40:33.760\n often what'll happen is some 13 year old\n\n40:33.760 --> 40:35.360\n will come up to me afterwards and say something,\n\n40:35.360 --> 40:37.160\n and I'll say, my God, that was so smart.\n\n40:37.160 --> 40:38.840\n Like, how did you know that?\n\n40:38.840 --> 40:40.320\n And they'll say, oh, I saw it on a Ted talk.\n\n40:40.320 --> 40:42.880\n Well, what an amazing opportunity.\n\n40:42.880 --> 40:46.440\n Here you got the best person in the world on subject X\n\n40:46.440 --> 40:51.440\n giving a 15 minute talk as beautifully as he or she can.\n\n40:51.880 --> 40:53.440\n And the 13 year old just grows up with that.\n\n40:53.440 --> 40:55.160\n That's just the mother's milk, right?\n\n40:55.160 --> 40:57.720\n As opposed to when we grew up,\n\n40:57.720 --> 41:00.320\n you know, I had whatever homeroom teacher I had\n\n41:00.320 --> 41:03.200\n and, you know, whatever classmates I had.\n\n41:03.200 --> 41:06.440\n And hopefully that person knew what he or she was teaching\n\n41:06.440 --> 41:08.760\n and often didn't and, you know, just made things up.\n\n41:08.760 --> 41:12.960\n So the opportunity that has become extraordinary\n\n41:12.960 --> 41:14.480\n to get the best of the world.\n\n41:14.480 --> 41:15.720\n And the reason this matters, of course,\n\n41:15.720 --> 41:18.560\n is because obviously, back to plasticity,\n\n41:18.560 --> 41:22.000\n the way that we, the way our brain gets molded\n\n41:22.000 --> 41:24.320\n is by absorbing everything from the world,\n\n41:24.320 --> 41:28.520\n all of the knowledge and the data and so on that it can get,\n\n41:28.520 --> 41:33.040\n and then springboarding off of that.\n\n41:33.040 --> 41:34.340\n And we're in a very lucky time now\n\n41:34.340 --> 41:39.340\n because we grew up with a lot of just in case learning.\n\n41:40.340 --> 41:42.000\n So, you know, just in case you ever need to know\n\n41:42.000 --> 41:44.720\n these dates in Mongolian history, here they are.\n\n41:44.720 --> 41:47.280\n But what kids are grown up with now, like my kids,\n\n41:47.280 --> 41:48.800\n is tons of just in time learning.\n\n41:48.800 --> 41:50.120\n So as soon as they're curious about something,\n\n41:50.120 --> 41:51.800\n they ask Alexa, they ask Google Home,\n\n41:51.800 --> 41:53.080\n they get the answer right there\n\n41:53.080 --> 41:54.600\n in the context of their curiosity.\n\n41:54.600 --> 41:59.600\n The reason this matters is because for plasticity to happen,\n\n41:59.720 --> 42:02.480\n you need to care, you need to be curious about something.\n\n42:02.480 --> 42:03.760\n And this is something, by the way,\n\n42:03.760 --> 42:06.320\n that the ancient Romans had noted.\n\n42:06.320 --> 42:08.360\n They had outlined seven different levels of learning\n\n42:08.360 --> 42:10.600\n and the highest level is when you're curious about a topic.\n\n42:10.600 --> 42:13.200\n But anyway, so kids now are getting tons\n\n42:13.200 --> 42:15.800\n of just in time learning, and as a result,\n\n42:15.800 --> 42:18.440\n they're gonna be so much smarter than we are.\n\n42:18.440 --> 42:19.760\n They're just, and we can already see that.\n\n42:19.760 --> 42:22.200\n I mean, my boy is eight years old, my girl is five.\n\n42:22.200 --> 42:25.740\n But I mean, the things that he knows are amazing\n\n42:25.740 --> 42:27.800\n because it's not just him having to do\n\n42:27.800 --> 42:29.960\n the rote memorization stuff that we did.\n\n42:29.960 --> 42:32.280\n Yeah, it's just fascinating what the brain,\n\n42:32.280 --> 42:33.640\n what young brains look like now\n\n42:33.640 --> 42:36.880\n because of all those TED Talks just loaded in there.\n\n42:36.880 --> 42:39.920\n And there's also, I mean, a lot of people, right,\n\n42:39.920 --> 42:42.960\n kind of, there's a sense that our attention span\n\n42:42.960 --> 42:46.320\n is growing shorter, but it's complicated\n\n42:46.320 --> 42:50.760\n because for example, most people, majority of people,\n\n42:50.760 --> 42:53.000\n it's the 80 plus percent of people listen\n\n42:53.000 --> 42:54.600\n to the entirety of these things,\n\n42:54.600 --> 42:56.800\n two, three hours for the podcast,\n\n42:56.800 --> 43:00.920\n long form podcasts are becoming more and more popular.\n\n43:00.920 --> 43:04.240\n So like that's, it's all really giant complicated mess.\n\n43:04.240 --> 43:07.440\n And the point is that the brain is able to adjust to it\n\n43:07.440 --> 43:11.840\n and somehow like form a worldview\n\n43:11.840 --> 43:16.840\n within this new medium of like information that we have.\n\n43:17.040 --> 43:19.920\n You have like these short tweets\n\n43:19.920 --> 43:22.840\n and you have these three, four hour podcasts\n\n43:22.840 --> 43:24.940\n and you have Netflix movie.\n\n43:24.940 --> 43:27.200\n I mean, it's just, it's adjusting to the entirety\n\n43:27.200 --> 43:30.080\n and just absorbing it and taking it all in\n\n43:30.080 --> 43:34.600\n and then pops up COVID that forces us all to be home\n\n43:34.600 --> 43:39.200\n and it all just adjusts and figures it out.\n\n43:39.200 --> 43:40.200\n Yeah, yeah, exactly.\n\n43:40.200 --> 43:41.880\n It's fascinating.\n\n43:41.880 --> 43:43.880\n Been talking about the brain\n\n43:43.880 --> 43:48.400\n as if it's something separate from the human\n\n43:48.400 --> 43:50.280\n that carries it a little bit.\n\n43:50.280 --> 43:52.180\n Like whenever you talk about the brain,\n\n43:52.180 --> 43:55.340\n it's easy to forget that that's like, that's us.\n\n43:55.340 --> 43:58.700\n Like how much do you,\n\n43:59.620 --> 44:03.420\n how much is the whole thing like predetermined?\n\n44:04.860 --> 44:07.720\n Like how much is it already encoded in there?\n\n44:08.580 --> 44:12.380\n And how much is it the, what's the hit?\n\n44:17.020 --> 44:22.020\n The actions, the decisions, the judgments, the...\n\n44:22.220 --> 44:23.300\n You mean like who you are?\n\n44:23.300 --> 44:24.140\n Who you are.\n\n44:24.140 --> 44:25.760\n Oh, yeah, yeah, okay, great question.\n\n44:25.760 --> 44:27.400\n Right, so there used to be a big debate\n\n44:27.400 --> 44:28.900\n about nature versus nurture.\n\n44:28.900 --> 44:31.380\n And we now know that it's always both.\n\n44:31.380 --> 44:32.720\n You can't even separate them\n\n44:32.720 --> 44:35.500\n because you come to the table with a certain amount of nature\n\n44:35.500 --> 44:37.740\n for example, your whole genome and so on.\n\n44:37.740 --> 44:39.680\n The experiences you have in the womb,\n\n44:39.680 --> 44:41.820\n like whether your mother is smoking or drinking,\n\n44:41.820 --> 44:43.740\n things like that, whether she's stressed, so on.\n\n44:43.740 --> 44:47.260\n Those all influence how you're gonna pop out of the womb.\n\n44:47.260 --> 44:50.180\n From there, everything is an interaction\n\n44:50.180 --> 44:55.180\n between all of your experiences and the nature.\n\n44:55.500 --> 44:59.900\n What I mean is, I think of it like a space time cone\n\n44:59.900 --> 45:01.820\n where you have, you drop into the world\n\n45:01.820 --> 45:03.160\n and depending on the experience that you have,\n\n45:03.160 --> 45:04.220\n you might go off in this direction\n\n45:04.220 --> 45:05.980\n or that direction or in that direction\n\n45:05.980 --> 45:08.460\n because there's interaction on the way.\n\n45:08.460 --> 45:11.080\n Your experiences determine what happens\n\n45:11.080 --> 45:12.380\n with the expression of your genes.\n\n45:12.380 --> 45:15.980\n So some genes get repressed, some get expressed and so on.\n\n45:15.980 --> 45:17.620\n And you actually become a different person\n\n45:17.620 --> 45:18.940\n based on your experiences.\n\n45:18.940 --> 45:21.140\n There's a whole field called epigenomics,\n\n45:21.140 --> 45:24.020\n which is, or epigenetics I should say,\n\n45:24.020 --> 45:26.400\n which is about the epigenome.\n\n45:26.400 --> 45:30.380\n And that is the layer that sits on top of the DNA\n\n45:30.380 --> 45:32.560\n and causes the genes to express differently.\n\n45:32.560 --> 45:35.140\n That is directly related to the experiences that you have.\n\n45:35.140 --> 45:38.700\n So if, just as an example, they take rat pups\n\n45:38.700 --> 45:41.560\n and one group is placed away from their parents\n\n45:41.560 --> 45:43.580\n and the other group is groomed and licked\n\n45:43.580 --> 45:44.620\n and taken good care of,\n\n45:44.620 --> 45:46.100\n that changes their gene expression\n\n45:46.100 --> 45:46.940\n for the rest of their life.\n\n45:46.940 --> 45:48.140\n They go off in different directions\n\n45:48.140 --> 45:49.580\n in this space time cone.\n\n45:50.940 --> 45:55.820\n So yeah, this is of course why it matters\n\n45:55.820 --> 45:58.380\n that we take care of children and pour money\n\n45:58.380 --> 46:00.780\n into things like education and good childcare\n\n46:00.780 --> 46:03.480\n and so on for children broadly,\n\n46:04.460 --> 46:08.340\n because these formative years matter so much.\n\n46:08.340 --> 46:10.160\n So is there a free will?\n\n46:11.620 --> 46:13.940\n This is a great question.\n\n46:13.940 --> 46:16.500\n I apologize for the absurd high level\n\n46:16.500 --> 46:17.340\n philosophical questions.\n\n46:17.340 --> 46:19.060\n No, no, these are my favorite kind of questions.\n\n46:19.060 --> 46:20.900\n Here's the thing, here's the thing.\n\n46:20.900 --> 46:21.780\n We don't know.\n\n46:21.780 --> 46:23.300\n If you ask most neuroscientists,\n\n46:23.300 --> 46:26.780\n they'll say that we can't really think\n\n46:26.780 --> 46:28.660\n of how you would get free will in there\n\n46:28.660 --> 46:30.280\n because as far as we can tell, it's a machine.\n\n46:30.280 --> 46:32.200\n It's a very complicated machine.\n\n46:33.420 --> 46:36.140\n Enormously sophisticated, 86 billion neurons,\n\n46:36.140 --> 46:38.140\n about the same number of glial cells.\n\n46:38.140 --> 46:40.140\n Each of these things is as complicated\n\n46:40.140 --> 46:41.280\n as the city of San Francisco.\n\n46:41.280 --> 46:43.500\n Each neuron in your head has the entire human genome in it.\n\n46:43.500 --> 46:47.580\n It's expressing millions of gene products.\n\n46:47.580 --> 46:50.000\n These are incredibly complicated biochemical cascades.\n\n46:50.000 --> 46:51.860\n Each one is connected to 10,000 of its neighbors,\n\n46:51.860 --> 46:54.960\n which means you have like half a quadrillion connections\n\n46:54.960 --> 46:55.800\n in the brain.\n\n46:55.800 --> 46:58.180\n So it's incredibly complicated thing,\n\n46:58.180 --> 47:01.560\n but it is fundamentally appears to just be a machine.\n\n47:02.540 --> 47:04.980\n And therefore, if there's nothing in it\n\n47:04.980 --> 47:07.420\n that's not being driven by something else,\n\n47:07.420 --> 47:10.160\n then it seems it's hard to understand\n\n47:10.160 --> 47:12.600\n where free will would come from.\n\n47:12.600 --> 47:14.860\n So that's the camp that pretty much all of us fall into,\n\n47:14.860 --> 47:18.120\n but I will say, our science is still quite young.\n\n47:18.120 --> 47:20.860\n And I'm a fan of the history of science,\n\n47:20.860 --> 47:22.780\n and the thing that always strikes me as interesting\n\n47:22.780 --> 47:26.100\n is when you look back at any moment in science,\n\n47:26.100 --> 47:28.500\n everybody believes something is true,\n\n47:28.500 --> 47:31.340\n and they simply didn't know about\n\n47:31.340 --> 47:33.180\n what Einstein revealed or whatever.\n\n47:33.180 --> 47:35.140\n And so who knows?\n\n47:35.140 --> 47:37.080\n And they all feel like that we've,\n\n47:37.080 --> 47:38.620\n at any moment in history,\n\n47:38.620 --> 47:40.700\n they all feel like we've converged to the final answer.\n\n47:40.700 --> 47:41.800\n Exactly, exactly.\n\n47:41.800 --> 47:43.780\n Like all the pieces of the puzzle are there.\n\n47:43.780 --> 47:45.620\n And I think that's a funny illusion\n\n47:45.620 --> 47:47.180\n that's worth getting rid of.\n\n47:47.180 --> 47:49.540\n And in fact, this is what drives good science\n\n47:49.540 --> 47:52.660\n is recognizing that we don't have most of the puzzle pieces.\n\n47:52.660 --> 47:55.620\n So as far as the free will question goes, I don't know.\n\n47:55.620 --> 47:57.060\n At the moment, it seems, wow,\n\n47:57.060 --> 47:58.540\n it'd be really impossible to figure out\n\n47:58.540 --> 48:00.020\n how something else could fit in there,\n\n48:00.020 --> 48:02.720\n but 100 years from now,\n\n48:02.720 --> 48:05.620\n our textbooks might be very different than they are now.\n\n48:05.620 --> 48:07.620\n I mean, could I ask you to speculate\n\n48:07.620 --> 48:11.060\n where do you think free will could be squeezed into there?\n\n48:11.060 --> 48:12.900\n Like, what's that even,\n\n48:14.580 --> 48:16.300\n is it possible that our brain just creates\n\n48:16.300 --> 48:19.880\n kinds of illusions that are useful for us?\n\n48:19.880 --> 48:24.200\n Or like what, where could it possibly be squeezed in?\n\n48:24.200 --> 48:27.140\n Well, let me give a speculation answer\n\n48:27.140 --> 48:28.740\n to your very nice question,\n\n48:28.740 --> 48:32.180\n but don't, and the listeners of this podcast,\n\n48:32.180 --> 48:33.140\n don't quote me on this.\n\n48:33.140 --> 48:33.980\n Yeah, exactly.\n\n48:33.980 --> 48:35.620\n I'm not saying this is what I believe to be true,\n\n48:35.620 --> 48:36.740\n but let me just give an example.\n\n48:36.740 --> 48:38.940\n I give this at the end of my book, Incognito.\n\n48:38.940 --> 48:41.340\n So the whole book of Incognito is about,\n\n48:41.340 --> 48:42.900\n all the what's happening in the brain.\n\n48:42.900 --> 48:44.060\n And essentially I'm saying, look,\n\n48:44.060 --> 48:45.460\n here's all the reasons to think\n\n48:45.460 --> 48:47.020\n that free will probably does not exist.\n\n48:47.020 --> 48:50.580\n But at the very end, I say, look,\n\n48:50.580 --> 48:52.560\n imagine that you are,\n\n48:53.860 --> 48:56.140\n imagine that you're a Kalahari Bushman\n\n48:56.140 --> 48:58.900\n and you find a radio in the sand\n\n48:58.900 --> 49:01.100\n and you've never seen anything like this.\n\n49:01.100 --> 49:04.420\n And you look at this radio and you realize\n\n49:04.420 --> 49:07.180\n that when you turn this knob, you hear voices coming from,\n\n49:07.180 --> 49:08.700\n there are voices coming from it.\n\n49:08.700 --> 49:11.700\n So being a radio materialist,\n\n49:11.700 --> 49:14.020\n you try to figure out like, how does this thing operate?\n\n49:14.020 --> 49:15.420\n So you take off the back cover\n\n49:15.420 --> 49:16.780\n and you realize there's all these wires.\n\n49:16.780 --> 49:19.740\n And when you take out some wires,\n\n49:19.740 --> 49:22.140\n the voices get garbled or stop or whatever.\n\n49:22.140 --> 49:24.300\n And so what you end up developing is a whole theory\n\n49:24.300 --> 49:26.820\n about how this connection, this pattern of wires\n\n49:26.820 --> 49:29.020\n gives rise to voices.\n\n49:29.020 --> 49:31.780\n But it would never strike you that in distant cities,\n\n49:31.780 --> 49:34.460\n there's a radio tower and there's invisible stuff beaming.\n\n49:34.460 --> 49:36.780\n And that's actually the origin of the voices.\n\n49:36.780 --> 49:38.700\n And this is just necessary for it.\n\n49:38.700 --> 49:42.580\n So I mentioned this just as a speculation,\n\n49:42.580 --> 49:44.100\n say, look, how would we know,\n\n49:44.100 --> 49:46.060\n what we know about the brain for absolutely certain\n\n49:46.060 --> 49:48.580\n is that when you damage pieces and parts of it,\n\n49:48.580 --> 49:50.580\n things get jumbled up.\n\n49:50.580 --> 49:52.680\n But how would you know if there's something else going on\n\n49:52.680 --> 49:55.140\n that we can't see like electromagnetic radiation\n\n49:55.140 --> 49:58.180\n that is what's actually generating this?\n\n49:58.180 --> 50:01.420\n Yeah, you paint a beautiful example\n\n50:01.420 --> 50:06.260\n of how totally,\n\n50:06.260 --> 50:10.300\n because we don't know most of how our universe works,\n\n50:10.300 --> 50:14.460\n how totally off base we might be with our science until,\n\n50:14.460 --> 50:19.100\n I mean, yeah, I mean, that's inspiring, that's beautiful.\n\n50:19.100 --> 50:21.780\n It's kind of terrifying, it's humbling.\n\n50:21.780 --> 50:23.980\n It's all of the above.\n\n50:23.980 --> 50:26.820\n And the important part just to recognize\n\n50:26.820 --> 50:28.660\n is that of course we're in the position\n\n50:28.660 --> 50:31.780\n of having massive unknowns.\n\n50:31.780 --> 50:36.340\n And we have of course the known unknowns\n\n50:36.340 --> 50:38.420\n and that's all the things we're pursuing in our labs\n\n50:38.420 --> 50:39.260\n and trying to figure out that,\n\n50:39.260 --> 50:41.620\n but there's this whole space of unknown unknowns.\n\n50:41.620 --> 50:44.020\n Things we haven't even realized we haven't asked yet.\n\n50:44.020 --> 50:47.660\n Let me kind of ask a weird, maybe a difficult question,\n\n50:47.660 --> 50:50.580\n part that has to do with,\n\n50:50.580 --> 50:54.340\n I've been recently reading a lot about World War II.\n\n50:54.340 --> 50:56.620\n I'm currently reading a book I recommend for people,\n\n50:56.620 --> 51:00.940\n which as a Jew has been difficult to read,\n\n51:00.940 --> 51:04.020\n but the rise and fall of the Third Reich.\n\n51:04.940 --> 51:08.900\n So let me just ask about like the nature of genius,\n\n51:08.900 --> 51:10.460\n the nature of evil.\n\n51:10.460 --> 51:14.220\n If we look at somebody like Einstein,\n\n51:14.220 --> 51:19.220\n we look at Hitler, Stalin, modern day Jeffrey Epstein,\n\n51:19.500 --> 51:24.500\n just folks who through their life have done with Einstein\n\n51:24.500 --> 51:27.540\n and works of genius and with the others I mentioned\n\n51:27.540 --> 51:29.420\n have done evil on this world.\n\n51:30.580 --> 51:34.940\n What do we think about that in a livewired brain?\n\n51:34.940 --> 51:39.580\n Like how do we think about these extreme people?\n\n51:39.580 --> 51:41.700\n Here's what I'd say.\n\n51:41.700 --> 51:43.540\n This is a very big and difficult question,\n\n51:43.540 --> 51:45.380\n but what I would say briefly on it is,\n\n51:47.620 --> 51:51.500\n first of all, I saw a cover of Time Magazine some years ago\n\n51:51.500 --> 51:55.500\n and it was a big sagittal slice of the brain\n\n51:55.500 --> 51:59.020\n and it said something like, what makes us good and evil?\n\n51:59.020 --> 52:00.460\n And there was a little spot pointing to it\n\n52:00.460 --> 52:01.300\n and there was a picture of Gandhi\n\n52:01.300 --> 52:03.380\n and there was a little spot that was pointing to Hitler.\n\n52:03.380 --> 52:05.780\n And these Time Magazine covers always make me mad\n\n52:05.780 --> 52:08.660\n because it's so goofy to think that we're gonna find\n\n52:08.660 --> 52:10.940\n some spot in the brain or something.\n\n52:10.940 --> 52:15.940\n Instead, the interesting part is because we're livewired,\n\n52:16.860 --> 52:20.580\n we are all about the world and the culture around us.\n\n52:20.580 --> 52:25.580\n So somebody like Adolf Hitler got all this positive feedback\n\n52:25.740 --> 52:28.780\n about what was going on and the crazier and crazier\n\n52:28.780 --> 52:31.980\n the ideas he had and he's like, let's set up death camps\n\n52:31.980 --> 52:34.140\n and murder a bunch of people and so on.\n\n52:34.140 --> 52:37.340\n Somehow he was getting positive feedback from that\n\n52:37.340 --> 52:40.300\n and all these other people, they're all spun each other up.\n\n52:40.300 --> 52:45.300\n And you look at anything like, I mean, look at the cultural\n\n52:45.300 --> 52:50.300\n revolution in China or the Russian revolution\n\n52:51.180 --> 52:52.620\n or things like this where you look at these things,\n\n52:52.620 --> 52:55.300\n my God, how do people all behave like this?\n\n52:55.300 --> 52:58.860\n But it's easy to see groups of people spinning themselves up\n\n52:58.860 --> 53:00.300\n in particular ways where they all say,\n\n53:00.300 --> 53:03.820\n well, would I have thought this was right\n\n53:03.820 --> 53:04.740\n in a different circumstance?\n\n53:04.740 --> 53:05.940\n I don't know, but Fred thinks it's right\n\n53:05.940 --> 53:06.780\n and Steve thinks it's right,\n\n53:06.780 --> 53:08.180\n everyone around me seems to think it's right.\n\n53:08.180 --> 53:13.060\n And so part of the maybe downside of having a livewired brain\n\n53:13.060 --> 53:17.500\n is that you can get crowds of people doing things as a group.\n\n53:17.500 --> 53:20.420\n So it's interesting to, we would pinpoint Hitler\n\n53:20.420 --> 53:21.660\n as saying that's the evil guy.\n\n53:21.660 --> 53:24.740\n But in a sense, I think it was Tolstoy who said\n\n53:24.740 --> 53:29.740\n the king becomes slave to the people.\n\n53:30.860 --> 53:34.740\n In other words, Hitler was just a representation\n\n53:34.740 --> 53:37.420\n of whatever was going on with that huge crowd\n\n53:37.420 --> 53:39.420\n that he was surrounded with.\n\n53:39.420 --> 53:44.420\n So I only bring that up to say that it's very difficult\n\n53:45.260 --> 53:48.340\n to say what it is about this person's brain\n\n53:48.340 --> 53:49.180\n or that person's brain.\n\n53:49.180 --> 53:51.660\n He obviously got feedback for what he was doing.\n\n53:51.660 --> 53:52.820\n The other thing, by the way,\n\n53:52.820 --> 53:57.300\n about what we often think of as being evil in society\n\n53:57.300 --> 54:01.820\n is my lab recently published some work\n\n54:01.820 --> 54:04.620\n on in groups and out groups,\n\n54:04.620 --> 54:08.260\n which is a very important part of this puzzle.\n\n54:08.260 --> 54:13.260\n So it turns out that we are very engineered\n\n54:13.860 --> 54:16.060\n to care about in groups versus out groups.\n\n54:16.060 --> 54:18.700\n And this seems to be like a really fundamental thing.\n\n54:18.700 --> 54:20.140\n So we did this experiment in my lab\n\n54:20.140 --> 54:23.420\n where we brought people and we stick them in the scanner.\n\n54:23.420 --> 54:25.020\n And we, I don't know if you noticed,\n\n54:25.020 --> 54:30.020\n but we show them on the screen six hands\n\n54:30.700 --> 54:33.460\n and the computer goes around randomly picks a hand.\n\n54:33.460 --> 54:34.980\n And then you see that hand gets stabbed\n\n54:34.980 --> 54:36.060\n with a syringe needle.\n\n54:36.060 --> 54:38.260\n So you actually see a syringe needle enter the hand\n\n54:38.260 --> 54:39.100\n and come out.\n\n54:39.100 --> 54:41.940\n And it's really, what that does is that triggers\n\n54:42.940 --> 54:44.540\n parts of the pain matrix,\n\n54:44.540 --> 54:46.140\n this areas in your brain that are involved\n\n54:46.140 --> 54:47.260\n in feeling physical pain.\n\n54:47.260 --> 54:48.860\n Now, the interesting thing is it's not your hand\n\n54:48.860 --> 54:49.940\n that was stabbed.\n\n54:49.940 --> 54:51.620\n So what you're seeing is empathy.\n\n54:51.620 --> 54:54.140\n This is you seeing someone else's hand gets stabbed.\n\n54:54.140 --> 54:56.220\n You feel like, oh God, this is awful, right?\n\n54:56.220 --> 54:57.420\n Okay.\n\n54:57.420 --> 54:58.580\n We contrast that by the way,\n\n54:58.580 --> 55:00.820\n with somebody's hand getting poked as a Q tip,\n\n55:00.820 --> 55:02.540\n which is, you know, looks visually the same,\n\n55:02.540 --> 55:06.100\n but you don't have that same level of response.\n\n55:06.100 --> 55:10.100\n Now what we do is we label each hand with a one word label,\n\n55:10.980 --> 55:14.340\n Christian, Jewish, Muslim, atheist, Scientologist, Hindu.\n\n55:14.340 --> 55:16.940\n And now the computer goes around, picks a hand,\n\n55:16.940 --> 55:17.900\n stabs the hand.\n\n55:17.900 --> 55:21.420\n And the question is, how much does your brain care\n\n55:21.420 --> 55:23.220\n about all the people in your out group\n\n55:23.220 --> 55:25.700\n versus the one label that happens to match you?\n\n55:26.660 --> 55:29.140\n And it turns out for everybody across all religions,\n\n55:29.140 --> 55:31.020\n they care much more about their in group\n\n55:31.020 --> 55:31.860\n than their out group.\n\n55:31.860 --> 55:33.420\n And when I say they care, what I mean is\n\n55:33.420 --> 55:35.580\n you get a bigger response from their brain.\n\n55:35.580 --> 55:36.420\n Everything's the same.\n\n55:36.420 --> 55:38.820\n It's the same hands.\n\n55:38.820 --> 55:40.620\n It's just a one word label.\n\n55:40.620 --> 55:42.900\n You care much more about your in group than your out group.\n\n55:42.900 --> 55:45.700\n And I wish this weren't true, but this is how humans are.\n\n55:45.700 --> 55:47.820\n I wonder how fundamental that is,\n\n55:47.820 --> 55:52.820\n or if it's the emergent thing about culture.\n\n55:53.220 --> 55:55.540\n Like if we lived alone with like,\n\n55:55.540 --> 55:57.500\n if it's genetically built into the brain,\n\n55:57.500 --> 56:00.300\n like this longing for tribe.\n\n56:00.300 --> 56:02.300\n So I'll tell you, we addressed that.\n\n56:02.300 --> 56:03.260\n So here's what we did.\n\n56:03.260 --> 56:06.820\n There are two, actually there are two other things\n\n56:06.820 --> 56:07.860\n we did as part of this study\n\n56:07.860 --> 56:09.580\n that I think matter for this point.\n\n56:09.580 --> 56:11.740\n One is, so okay, so we show that you have\n\n56:11.740 --> 56:13.020\n a much bigger response.\n\n56:13.020 --> 56:14.460\n And by the way, this is not a cognitive thing.\n\n56:14.460 --> 56:17.460\n This is a very low level basic response\n\n56:17.460 --> 56:19.060\n to seeing pain in somebody, okay.\n\n56:19.060 --> 56:20.060\n Great study by the way.\n\n56:20.060 --> 56:21.940\n Thanks, thanks, thanks.\n\n56:21.940 --> 56:24.820\n What we did next is we next have it where we say,\n\n56:24.820 --> 56:28.700\n okay, the year is 2025 and these three religions\n\n56:28.700 --> 56:30.780\n are now in a war against these three religions.\n\n56:30.780 --> 56:31.820\n And it's all randomized, right?\n\n56:31.820 --> 56:34.980\n But what you see is your thing and you have two allies now\n\n56:34.980 --> 56:36.020\n against these others.\n\n56:37.100 --> 56:38.700\n And now it happens over the course of many trials,\n\n56:38.700 --> 56:41.620\n you see everybody gets stabbed at different times.\n\n56:41.620 --> 56:43.500\n And the question is, do you care more about your allies?\n\n56:43.500 --> 56:44.340\n And the answer is yes.\n\n56:44.340 --> 56:45.940\n Suddenly people who a moment ago,\n\n56:45.940 --> 56:47.300\n you didn't really care when they got stabbed.\n\n56:47.300 --> 56:49.740\n Now, simply with this one word thing\n\n56:49.740 --> 56:52.700\n that they're now your allies, you care more about them.\n\n56:52.700 --> 56:55.340\n But then what I wanted to do was look at\n\n56:55.340 --> 56:57.660\n how ingrained is this or how arbitrary is it?\n\n56:57.660 --> 57:01.460\n So we brought new participants in and we said,\n\n57:01.460 --> 57:02.700\n here's a coin, toss the coin.\n\n57:02.700 --> 57:04.140\n If it's heads, you're an Augustinian.\n\n57:04.140 --> 57:06.140\n If it's a tails, you're a Justinian.\n\n57:06.140 --> 57:08.020\n These are totally made up.\n\n57:08.020 --> 57:10.100\n Okay, so they toss it, they get whatever.\n\n57:10.100 --> 57:13.380\n We give them a band that says Augustinian on it,\n\n57:13.380 --> 57:16.740\n whatever tribe they're in now, and they get in the scanner\n\n57:16.740 --> 57:18.500\n and they see a thing on the screen that says\n\n57:18.500 --> 57:21.100\n the Augustinians and Justinians are two warring tribes.\n\n57:21.100 --> 57:22.180\n Then you see a bunch of hands,\n\n57:22.180 --> 57:24.620\n some are labeled Augustinians, some are Justinian.\n\n57:24.620 --> 57:27.820\n And now you care more about whichever team you're on\n\n57:27.820 --> 57:29.740\n than the other team, even though it's totally arbitrary\n\n57:29.740 --> 57:30.580\n and you know it's arbitrary\n\n57:30.580 --> 57:32.900\n because you're the one who tossed the coin.\n\n57:32.900 --> 57:36.980\n So it's a state that's very easy to find ourselves in.\n\n57:36.980 --> 57:39.500\n In other words, just before walking in the door,\n\n57:39.500 --> 57:41.700\n they'd never even heard of Augustinian versus Justinian\n\n57:41.700 --> 57:43.940\n and now their brain is representing it\n\n57:43.940 --> 57:46.380\n simply because they're told they're on this team.\n\n57:46.380 --> 57:49.620\n You know, now I did my own personal study of this.\n\n57:49.620 --> 57:54.620\n So once you're an Augustinian, that tends to be sticky\n\n57:55.500 --> 57:57.460\n because I've been a Packers fan,\n\n57:57.460 --> 57:59.100\n grew to be a Packers fan my whole life.\n\n57:59.100 --> 58:03.020\n Now when I'm in Boston with like the Patriots,\n\n58:03.020 --> 58:05.420\n it's been tough going for my livewired brain\n\n58:05.420 --> 58:07.980\n to switch to the Patriots.\n\n58:07.980 --> 58:10.020\n So once you become, it's as interesting,\n\n58:10.020 --> 58:12.140\n once the tribe is sticky.\n\n58:12.140 --> 58:14.180\n Yeah, I'll admit that's true.\n\n58:14.180 --> 58:15.020\n That's it, you know.\n\n58:15.020 --> 58:16.620\n You know, we never tried that about saying,\n\n58:16.620 --> 58:19.140\n okay, now you're a Justinian and you were an Augustinian.\n\n58:19.140 --> 58:21.820\n We never saw how sticky it is.\n\n58:21.820 --> 58:24.380\n But there are studies of this,\n\n58:24.380 --> 58:28.500\n of monkey troops on some island.\n\n58:30.060 --> 58:33.580\n And what happens is they look at the way monkeys behave\n\n58:33.580 --> 58:34.460\n when they're part of this tribe\n\n58:34.460 --> 58:37.580\n and how they treat members of the other tribe of monkeys.\n\n58:37.580 --> 58:39.500\n And then what they do, I've forgotten how they do that,\n\n58:39.500 --> 58:42.060\n exactly, but they end up switching a monkey\n\n58:42.060 --> 58:43.100\n so he ends up in the other troop.\n\n58:43.100 --> 58:45.220\n And very quickly they end up becoming a part\n\n58:45.220 --> 58:48.180\n of that other troop and hating and behaving badly\n\n58:48.180 --> 58:50.380\n towards the original troop.\n\n58:50.380 --> 58:52.500\n These are fascinating studies, by the way.\n\n58:52.500 --> 58:55.020\n This is beautiful.\n\n58:55.020 --> 59:00.020\n In your book, you have a good light bulb joke.\n\n59:01.220 --> 59:04.460\n How many psychiatrists does it take to change a light bulb?\n\n59:04.460 --> 59:07.900\n Only one, but the light bulb has to want to change.\n\n59:07.900 --> 59:08.740\n Sorry.\n\n59:09.700 --> 59:11.780\n I'm a sucker for a good light bulb joke.\n\n59:11.780 --> 59:15.100\n Okay, so given, you know, I've been interested\n\n59:15.100 --> 59:19.140\n in psychiatry my whole life, just maybe tangentially.\n\n59:19.140 --> 59:22.500\n I've kind of early on dreamed to be a psychiatrist\n\n59:22.500 --> 59:24.420\n until I understood what it entails.\n\n59:25.660 --> 59:30.660\n But, you know, is there hope for psychiatry\n\n59:31.940 --> 59:36.940\n for somebody else to help this live, wired brain to adjust?\n\n59:37.260 --> 59:40.180\n Oh yeah, I mean, in the sense that,\n\n59:40.180 --> 59:41.180\n and this has to do with this issue\n\n59:41.180 --> 59:43.220\n about us being trapped on our own planet.\n\n59:43.220 --> 59:45.900\n Forget psychiatrists, just think of like\n\n59:45.900 --> 59:47.020\n when you're talking with a friend\n\n59:47.020 --> 59:48.900\n and you say, oh, I'm so upset about this.\n\n59:48.900 --> 59:51.500\n And your friend says, hey, just look at it this way.\n\n59:53.300 --> 59:55.780\n You know, all we have access to under normal circumstances\n\n59:55.780 --> 59:57.420\n is just the way we're seeing something.\n\n59:57.420 --> 1:00:02.180\n And so it's super helpful to have friends and communities\n\n1:00:02.180 --> 1:00:05.740\n and psychiatrists and so on to help things change that way.\n\n1:00:05.740 --> 1:00:07.220\n So that's how psychiatrists sort of helped us.\n\n1:00:07.220 --> 1:00:10.500\n But more importantly, the role that psychiatrists have played\n\n1:00:10.500 --> 1:00:13.940\n is that there's this sort of naive assumption\n\n1:00:13.940 --> 1:00:15.140\n that we all come to the table with,\n\n1:00:15.140 --> 1:00:18.340\n which is that everyone is fundamentally just like us.\n\n1:00:18.340 --> 1:00:21.140\n And when you're a kid, you believe this entirely,\n\n1:00:21.140 --> 1:00:22.780\n but as you get older and you start realizing,\n\n1:00:22.780 --> 1:00:25.260\n okay, there's something called schizophrenia\n\n1:00:25.260 --> 1:00:26.300\n and that's a real thing.\n\n1:00:26.300 --> 1:00:29.100\n And to be inside that person's head is totally different\n\n1:00:29.100 --> 1:00:32.140\n than what it is to be inside my head or their psychopathy.\n\n1:00:32.140 --> 1:00:34.900\n And to be inside the psychopath's head,\n\n1:00:34.900 --> 1:00:36.300\n he doesn't care about other people.\n\n1:00:36.300 --> 1:00:37.460\n He doesn't care about hurting other people.\n\n1:00:37.460 --> 1:00:40.900\n He's just doing what he needs to do to get what he needs.\n\n1:00:40.900 --> 1:00:42.100\n That's a different head.\n\n1:00:42.100 --> 1:00:45.540\n There's a million different things going on\n\n1:00:45.540 --> 1:00:47.740\n and it is different to be inside those heads.\n\n1:00:48.860 --> 1:00:51.300\n This is where the field of psychiatry comes in.\n\n1:00:51.300 --> 1:00:53.380\n Now, I think it's an interesting question\n\n1:00:53.380 --> 1:00:57.020\n about the degree to which neuroscience is leaking into\n\n1:00:57.020 --> 1:00:58.540\n and taking over psychiatry\n\n1:00:58.540 --> 1:01:00.860\n and what the landscape will look like 50 years from now.\n\n1:01:00.860 --> 1:01:05.860\n It may be that psychiatry as a profession changes a lot\n\n1:01:05.860 --> 1:01:07.220\n or maybe goes away entirely,\n\n1:01:07.220 --> 1:01:09.220\n and neuroscience will essentially be able\n\n1:01:09.220 --> 1:01:10.420\n to take over some of these functions,\n\n1:01:10.420 --> 1:01:14.220\n but it has been extremely useful to understand\n\n1:01:14.220 --> 1:01:18.220\n the differences between how people behave and why\n\n1:01:18.220 --> 1:01:19.580\n and what you can tell about what's going on\n\n1:01:19.580 --> 1:01:22.380\n inside their brain just based on observation\n\n1:01:22.380 --> 1:01:23.420\n of their behavior.\n\n1:01:25.220 --> 1:01:28.340\n This might be years ago, but I'm not sure.\n\n1:01:28.340 --> 1:01:30.300\n There's an Atlantic article you've written\n\n1:01:32.300 --> 1:01:34.460\n about moving away from a distinction\n\n1:01:34.460 --> 1:01:36.900\n between neurological disorders,\n\n1:01:36.900 --> 1:01:39.100\n quote unquote, brain problems,\n\n1:01:39.100 --> 1:01:43.820\n and psychiatric disorders or quote unquote, mind problems.\n\n1:01:43.820 --> 1:01:47.220\n So on that topic, how do you think about this gray area?\n\n1:01:47.220 --> 1:01:50.580\n Yeah, this is exactly the evolution that things are going\n\n1:01:50.580 --> 1:01:54.140\n is there was psychiatry and then there were guys and gals\n\n1:01:54.140 --> 1:01:55.940\n in labs poking cells and so on.\n\n1:01:55.940 --> 1:01:57.020\n Those were the neuroscientists.\n\n1:01:57.020 --> 1:01:58.860\n But yeah, I think these are moving together\n\n1:01:58.860 --> 1:02:00.580\n for exactly the reason you just cited.\n\n1:02:00.580 --> 1:02:02.540\n And where this matters a lot,\n\n1:02:02.540 --> 1:02:04.660\n the Atlantic article that I wrote\n\n1:02:04.660 --> 1:02:06.780\n was called The Brain on Trial,\n\n1:02:06.780 --> 1:02:09.580\n where this matters a lot is the legal system\n\n1:02:09.580 --> 1:02:12.740\n because the way we run our legal system now,\n\n1:02:12.740 --> 1:02:13.900\n and this is true everywhere in the world,\n\n1:02:13.900 --> 1:02:17.420\n is someone shows up in front of the judge's bench,\n\n1:02:17.420 --> 1:02:18.540\n or let's say there's five people\n\n1:02:18.540 --> 1:02:20.100\n in front of the judge's bench,\n\n1:02:20.100 --> 1:02:21.380\n and they've all committed the same crime.\n\n1:02:21.380 --> 1:02:23.820\n What we do, because we feel like, hey, this is fair,\n\n1:02:23.820 --> 1:02:25.580\n is we say, all right, you're gonna get the same sentence.\n\n1:02:25.580 --> 1:02:27.780\n You'll all get three years in prison or whatever it is.\n\n1:02:27.780 --> 1:02:29.780\n But in fact, brains can be so different.\n\n1:02:29.780 --> 1:02:31.580\n This guy's got schizophrenia, this guy's a psychopath,\n\n1:02:31.580 --> 1:02:33.620\n this guy's tweaked down on drugs, and so on and so on,\n\n1:02:33.620 --> 1:02:37.620\n that it actually doesn't make sense to keep doing that.\n\n1:02:37.620 --> 1:02:41.220\n And what we do in this country more than anywhere\n\n1:02:41.220 --> 1:02:44.100\n in the world is we imagine that incarceration\n\n1:02:44.100 --> 1:02:45.500\n is a one size fits all solution.\n\n1:02:45.500 --> 1:02:47.300\n And you may know we have the,\n\n1:02:47.300 --> 1:02:49.140\n America has the highest incarceration rate\n\n1:02:49.140 --> 1:02:50.860\n in the whole world in terms of the percentage\n\n1:02:50.860 --> 1:02:52.860\n of our population we put behind bars.\n\n1:02:52.860 --> 1:02:56.580\n So there's a much more refined thing we can do\n\n1:02:56.580 --> 1:02:59.180\n as neuroscience comes in and changes,\n\n1:02:59.180 --> 1:03:01.900\n and has the opportunity to change the legal system.\n\n1:03:01.900 --> 1:03:03.980\n Which is to say, this doesn't let anybody off the hook.\n\n1:03:03.980 --> 1:03:06.100\n It doesn't say, oh, it's not your fault, and so on.\n\n1:03:06.100 --> 1:03:09.380\n But what it does is it changes the equation\n\n1:03:09.380 --> 1:03:12.940\n so it's not about, hey, how blameworthy are you?\n\n1:03:12.940 --> 1:03:15.220\n But instead is about, hey, what do we do from here?\n\n1:03:15.220 --> 1:03:16.260\n What's the best thing to do from here?\n\n1:03:16.260 --> 1:03:17.740\n So if you take somebody with schizophrenia\n\n1:03:17.740 --> 1:03:21.100\n and you have them break rocks in the hot summer sun\n\n1:03:21.100 --> 1:03:24.500\n in a chain gang, that doesn't help their schizophrenia.\n\n1:03:24.500 --> 1:03:25.900\n That doesn't fix the problem.\n\n1:03:25.900 --> 1:03:28.020\n If you take somebody with a drug addiction\n\n1:03:28.020 --> 1:03:30.660\n who's in jail for being caught with two ounces\n\n1:03:30.660 --> 1:03:34.500\n of some illegal substance, and you put them in prison,\n\n1:03:34.500 --> 1:03:36.020\n it doesn't actually fix the addiction.\n\n1:03:36.020 --> 1:03:37.260\n It doesn't help anything.\n\n1:03:38.580 --> 1:03:40.580\n Happily, what neuroscience and psychiatry\n\n1:03:40.580 --> 1:03:43.260\n bring to the table is lots of really useful things\n\n1:03:43.260 --> 1:03:45.620\n you can do with schizophrenia, with drug addiction,\n\n1:03:45.620 --> 1:03:46.940\n things like this.\n\n1:03:46.940 --> 1:03:49.140\n And that's why, so I don't know if you guys\n\n1:03:49.140 --> 1:03:50.540\n better run a national law and profit\n\n1:03:50.540 --> 1:03:52.140\n called the Center for Science and Law.\n\n1:03:52.140 --> 1:03:53.660\n And it's all about this intersection\n\n1:03:53.660 --> 1:03:55.140\n of neuroscience and psychiatry.\n\n1:03:55.140 --> 1:03:57.340\n It's the intersection of neuroscience and legal system.\n\n1:03:57.340 --> 1:03:59.060\n And we're trying to implement changes\n\n1:03:59.060 --> 1:04:01.660\n in every county, in every state.\n\n1:04:02.540 --> 1:04:04.700\n I'll just, without going down that rabbit hole,\n\n1:04:04.700 --> 1:04:07.540\n I'll just say one of the very simplest things to do\n\n1:04:07.540 --> 1:04:09.140\n is to set up specialized court systems\n\n1:04:09.140 --> 1:04:12.660\n where you have a mental health court\n\n1:04:12.660 --> 1:04:14.980\n that has judges and juries with expertise\n\n1:04:14.980 --> 1:04:15.820\n in mental illness.\n\n1:04:15.820 --> 1:04:17.780\n Because if you go, by the way, to a regular court\n\n1:04:17.780 --> 1:04:21.220\n and the person says, or the defense lawyer says,\n\n1:04:21.220 --> 1:04:24.300\n this person has schizophrenia, most of the jury will say,\n\n1:04:24.300 --> 1:04:25.780\n man, I call bullshit on that.\n\n1:04:25.780 --> 1:04:26.620\n Why?\n\n1:04:26.620 --> 1:04:28.660\n Because they don't know about schizophrenia.\n\n1:04:28.660 --> 1:04:30.780\n They don't know what it's about.\n\n1:04:30.780 --> 1:04:34.500\n And it turns out people who know about schizophrenia\n\n1:04:34.500 --> 1:04:35.900\n feel very differently as a juror\n\n1:04:35.900 --> 1:04:37.740\n than someone who happens not to know anybody with\n\n1:04:37.740 --> 1:04:39.540\n schizophrenia, they think it's an excuse.\n\n1:04:39.540 --> 1:04:42.380\n So you have judges and juries with expertise\n\n1:04:42.380 --> 1:04:44.180\n in mental illness and they know the rehabilitative\n\n1:04:44.180 --> 1:04:45.780\n strategies that are available.\n\n1:04:45.780 --> 1:04:46.620\n That's one thing.\n\n1:04:46.620 --> 1:04:48.500\n Having a drug court where you have judges and juries\n\n1:04:48.500 --> 1:04:50.540\n with expertise in rehabilitative strategies\n\n1:04:50.540 --> 1:04:51.860\n and what can be done and so on.\n\n1:04:51.860 --> 1:04:54.140\n A specialized prostitution court and so on.\n\n1:04:54.140 --> 1:04:55.700\n All these different things.\n\n1:04:55.700 --> 1:04:57.620\n By the way, this is very easy for counties\n\n1:04:57.620 --> 1:04:59.260\n to implement this sort of thing.\n\n1:04:59.260 --> 1:05:01.820\n And this is, I think, where this matters\n\n1:05:01.820 --> 1:05:05.020\n to get neuroscience into public policy.\n\n1:05:05.020 --> 1:05:08.620\n What's the process of injecting expertise into this?\n\n1:05:08.620 --> 1:05:10.540\n Yeah, I'll tell you exactly what it is.\n\n1:05:10.540 --> 1:05:12.420\n A county needs to run out of money first.\n\n1:05:12.420 --> 1:05:14.460\n I've seen this happen over and over.\n\n1:05:14.460 --> 1:05:17.220\n So what happens is a county has a completely full jail\n\n1:05:17.220 --> 1:05:18.540\n and they say, you know what?\n\n1:05:18.540 --> 1:05:19.780\n We need to build another jail.\n\n1:05:19.780 --> 1:05:21.220\n And then they realize, God, we don't have any money.\n\n1:05:21.220 --> 1:05:22.260\n We can't afford this.\n\n1:05:22.260 --> 1:05:23.260\n We've got too many people in jail.\n\n1:05:23.260 --> 1:05:25.500\n And that's when they turn to,\n\n1:05:25.500 --> 1:05:26.700\n God, we need something smarter.\n\n1:05:26.700 --> 1:05:28.700\n And that's when they set up specialized court systems.\n\n1:05:28.700 --> 1:05:29.540\n Yeah.\n\n1:05:30.940 --> 1:05:34.300\n We're all function best when our back is against the wall.\n\n1:05:34.300 --> 1:05:36.180\n And that's what COVID is good for.\n\n1:05:36.180 --> 1:05:38.380\n It's because we've all had our routines\n\n1:05:38.380 --> 1:05:40.820\n and we are optimized for the things we do.\n\n1:05:40.820 --> 1:05:43.020\n And suddenly our backs are against the wall, all of us.\n\n1:05:43.020 --> 1:05:44.620\n Yeah, it's really, I mean,\n\n1:05:44.620 --> 1:05:47.580\n one of the exciting things about COVID.\n\n1:05:47.580 --> 1:05:51.940\n I mean, I'm a big believer in the possibility\n\n1:05:51.940 --> 1:05:56.140\n of what government can do for the people.\n\n1:05:56.140 --> 1:05:59.180\n And when it becomes too big of a bureaucracy,\n\n1:05:59.180 --> 1:06:02.580\n it starts functioning poorly, it starts wasting money.\n\n1:06:02.580 --> 1:06:07.140\n It's nice to, I mean, COVID reveals that nicely.\n\n1:06:07.140 --> 1:06:11.700\n And lessons to be learned about who gets elected\n\n1:06:11.700 --> 1:06:14.180\n and who goes into government.\n\n1:06:14.180 --> 1:06:18.860\n Hopefully this, hopefully this inspires talented\n\n1:06:18.860 --> 1:06:20.780\n and young people to go into government\n\n1:06:20.780 --> 1:06:23.580\n to revolutionize different aspects of it.\n\n1:06:23.580 --> 1:06:28.580\n Yeah, so that's the positive silver lining of COVID.\n\n1:06:28.660 --> 1:06:30.740\n I mean, I thought it'd be fun to ask you,\n\n1:06:30.740 --> 1:06:31.900\n I don't know if you're paying attention\n\n1:06:31.900 --> 1:06:34.620\n to the machine learning world and GPT3.\n\n1:06:37.100 --> 1:06:39.260\n So the GPT3 is this language model,\n\n1:06:39.260 --> 1:06:41.180\n this neural network that's able to,\n\n1:06:41.180 --> 1:06:44.860\n it has 175 billion parameters.\n\n1:06:44.860 --> 1:06:47.820\n So it's very large and it's trained\n\n1:06:47.820 --> 1:06:51.540\n in an unsupervised way on the internet.\n\n1:06:51.540 --> 1:06:55.780\n It just reads a lot of unstructured texts\n\n1:06:55.780 --> 1:06:59.420\n and it's able to generate some pretty impressive things.\n\n1:06:59.420 --> 1:07:02.020\n The human brain compared to that has about,\n\n1:07:02.020 --> 1:07:05.980\n you know, a thousand times more synapses.\n\n1:07:05.980 --> 1:07:10.060\n People get so upset when machine learning people\n\n1:07:10.060 --> 1:07:14.380\n compare the brain and we know synapses are different.\n\n1:07:14.380 --> 1:07:16.860\n It was very different, very different.\n\n1:07:16.860 --> 1:07:20.580\n But like, do you, what do you think about GPT3?\n\n1:07:20.580 --> 1:07:22.660\n Here's what I think, here's what I think, a few things.\n\n1:07:22.660 --> 1:07:25.580\n What GPT3 is doing is extremely impressive,\n\n1:07:25.580 --> 1:07:27.620\n but it's very different from what the brain does.\n\n1:07:27.620 --> 1:07:32.620\n So it's a good impersonator, but just as one example,\n\n1:07:33.060 --> 1:07:37.500\n everybody takes a passage that GPT3 has written\n\n1:07:37.500 --> 1:07:40.420\n and they say, wow, look at this, and it's pretty good, right?\n\n1:07:40.420 --> 1:07:42.420\n But it's already gone through a filtering process\n\n1:07:42.420 --> 1:07:43.740\n of humans looking at it and saying,\n\n1:07:43.740 --> 1:07:45.340\n okay, well that's crap, that's crap, okay.\n\n1:07:45.340 --> 1:07:47.500\n Oh, here's a sentence that's pretty cool.\n\n1:07:47.500 --> 1:07:49.940\n Now here's the thing, human creativity\n\n1:07:49.940 --> 1:07:51.740\n is about absorbing everything around it\n\n1:07:51.740 --> 1:07:53.420\n and remixing that and coming up with stuff.\n\n1:07:53.420 --> 1:07:55.420\n So in that sense, we're sort of like GPT3,\n\n1:07:55.420 --> 1:07:58.820\n you know, we're remixing what we've gotten in before.\n\n1:07:59.700 --> 1:08:03.140\n But we also know, we also have very good models\n\n1:08:03.140 --> 1:08:04.780\n of what it is to be another human.\n\n1:08:04.780 --> 1:08:08.220\n And so, you know, I don't know if you speak French\n\n1:08:08.220 --> 1:08:09.820\n or something, but I'm not gonna start speaking in French\n\n1:08:09.820 --> 1:08:11.500\n because then you'll say, wait, what are you doing?\n\n1:08:11.500 --> 1:08:12.420\n I don't understand it.\n\n1:08:12.420 --> 1:08:14.700\n Instead, everything coming out of my mouth\n\n1:08:14.700 --> 1:08:16.260\n is meant for your ears.\n\n1:08:16.260 --> 1:08:18.140\n I know what you'll understand.\n\n1:08:18.140 --> 1:08:20.140\n I know the vocabulary that you know and don't know.\n\n1:08:20.140 --> 1:08:21.860\n I know what parts you care about.\n\n1:08:23.740 --> 1:08:25.140\n That's a huge part of it.\n\n1:08:25.140 --> 1:08:28.580\n And so of all the possible sentences I could say,\n\n1:08:29.420 --> 1:08:31.700\n I'm navigating this thin bandwidth\n\n1:08:31.700 --> 1:08:34.540\n so that it's something useful for our conversation.\n\n1:08:34.540 --> 1:08:36.740\n Yeah, in real time, but also throughout your life.\n\n1:08:36.740 --> 1:08:39.740\n I mean, we're co evolving together.\n\n1:08:39.740 --> 1:08:42.980\n We're learning how to communicate together.\n\n1:08:42.980 --> 1:08:46.220\n Exactly, but this is what GPT3 does not do.\n\n1:08:46.220 --> 1:08:47.300\n All it's doing is saying, okay,\n\n1:08:47.300 --> 1:08:49.500\n I'm gonna take all these senses and remix stuff\n\n1:08:49.500 --> 1:08:51.100\n and pop some stuff out.\n\n1:08:51.100 --> 1:08:52.540\n But it doesn't know how to make it\n\n1:08:52.540 --> 1:08:54.340\n so that you, Lex, will feel like,\n\n1:08:54.340 --> 1:08:56.820\n oh yeah, that's exactly what I needed to hear.\n\n1:08:56.820 --> 1:08:59.700\n That's the next sentence that I needed to know about\n\n1:08:59.700 --> 1:09:00.540\n for something.\n\n1:09:00.540 --> 1:09:02.860\n Well, of course, it could be,\n\n1:09:02.860 --> 1:09:04.220\n all the impressive results we see.\n\n1:09:04.220 --> 1:09:07.700\n The question is, if you raise the number of parameters,\n\n1:09:07.700 --> 1:09:09.980\n whether it's going to be after some...\n\n1:09:09.980 --> 1:09:11.020\n It will not be.\n\n1:09:11.020 --> 1:09:11.860\n It will not be.\n\n1:09:11.860 --> 1:09:14.060\n Raising more parameters won't...\n\n1:09:14.060 --> 1:09:15.180\n Here's the thing.\n\n1:09:15.180 --> 1:09:16.740\n It's not that I don't think neural networks\n\n1:09:16.740 --> 1:09:18.100\n can't be like the human brain,\n\n1:09:18.100 --> 1:09:20.420\n because I suspect they will be at some point, 50 years.\n\n1:09:20.420 --> 1:09:21.260\n Who knows?\n\n1:09:21.260 --> 1:09:26.020\n But what we are missing in artificial neural networks\n\n1:09:26.020 --> 1:09:29.300\n is we've got this basic structure where you've got units\n\n1:09:29.300 --> 1:09:32.420\n and you've got synapses that are connected.\n\n1:09:32.420 --> 1:09:33.380\n And that's great.\n\n1:09:33.380 --> 1:09:35.820\n And it's done incredibly mind blowing, impressive things,\n\n1:09:35.820 --> 1:09:40.260\n but it's not doing the same algorithms as the human brain.\n\n1:09:40.260 --> 1:09:43.620\n So when I look at my children, as little kids,\n\n1:09:43.620 --> 1:09:47.660\n as infants, they can do things that no GPT3 can do.\n\n1:09:47.660 --> 1:09:50.620\n They can navigate a complex room.\n\n1:09:50.620 --> 1:09:54.900\n They can navigate social conversation with an adult.\n\n1:09:54.900 --> 1:09:55.740\n They can lie.\n\n1:09:55.740 --> 1:09:58.180\n They can do a million things.\n\n1:09:58.180 --> 1:10:03.180\n They are active thinkers in our world and doing things.\n\n1:10:03.180 --> 1:10:04.580\n And this, of course, I mean, look,\n\n1:10:04.580 --> 1:10:07.820\n we totally agree on how incredibly awesome\n\n1:10:07.820 --> 1:10:09.060\n artificial neural networks are right now,\n\n1:10:09.060 --> 1:10:12.780\n but we also know the things that they can't do well,\n\n1:10:12.780 --> 1:10:14.900\n like be generally intelligent,\n\n1:10:14.900 --> 1:10:16.380\n do all these different things.\n\n1:10:16.380 --> 1:10:17.620\n The reason about the world,\n\n1:10:17.620 --> 1:10:19.900\n efficiently learn, efficiently adapt.\n\n1:10:19.900 --> 1:10:20.740\n Exactly.\n\n1:10:20.740 --> 1:10:23.540\n But it's still the rate of improvement.\n\n1:10:23.540 --> 1:10:28.100\n It's, to me, it's possible that we'll be surprised.\n\n1:10:28.100 --> 1:10:30.020\n I agree, possible we'll be surprised.\n\n1:10:30.020 --> 1:10:33.060\n But what I would assert,\n\n1:10:33.060 --> 1:10:36.180\n and I'm glad I'm getting to say this on your podcast,\n\n1:10:36.180 --> 1:10:38.340\n we can look back at this in two years and 10 years,\n\n1:10:38.340 --> 1:10:41.580\n is that we've got to be much more sophisticated\n\n1:10:41.580 --> 1:10:44.740\n than units and synapses between them.\n\n1:10:44.740 --> 1:10:45.660\n Let me give you an example,\n\n1:10:45.660 --> 1:10:47.220\n and this is something I talk about in LiveWired,\n\n1:10:47.220 --> 1:10:50.540\n is despite the amazing impressiveness,\n\n1:10:50.540 --> 1:10:52.340\n mind blowing impressiveness,\n\n1:10:52.340 --> 1:10:54.580\n computers don't have some basic things,\n\n1:10:54.580 --> 1:10:56.580\n artificial neural networks don't have some basic things\n\n1:10:56.580 --> 1:10:59.460\n that we like caring about relevance, for example.\n\n1:10:59.460 --> 1:11:02.380\n So as humans, we are confronted\n\n1:11:02.380 --> 1:11:03.900\n with tons of data all the time,\n\n1:11:03.900 --> 1:11:05.620\n and we only encode particular things\n\n1:11:05.620 --> 1:11:07.740\n that are relevant to us.\n\n1:11:07.740 --> 1:11:10.060\n We have this very deep sense of relevance\n\n1:11:10.060 --> 1:11:11.900\n that I mentioned earlier is based on survival\n\n1:11:11.900 --> 1:11:12.740\n at the most basic level,\n\n1:11:12.740 --> 1:11:16.420\n but then all the things about my life and your life,\n\n1:11:16.420 --> 1:11:18.740\n what's relevant to you, that we encode.\n\n1:11:19.660 --> 1:11:20.500\n This is very useful.\n\n1:11:20.500 --> 1:11:21.980\n Computers at the moment don't have that.\n\n1:11:21.980 --> 1:11:24.020\n They don't even have a yen to survive\n\n1:11:24.020 --> 1:11:24.860\n and things like that.\n\n1:11:24.860 --> 1:11:27.500\n So we filled out a bunch of the junk we don't need.\n\n1:11:27.500 --> 1:11:29.900\n We're really good at efficiently\n\n1:11:29.900 --> 1:11:31.460\n zooming in on things we need.\n\n1:11:32.580 --> 1:11:34.500\n Again, could be argued, you know,\n\n1:11:34.500 --> 1:11:35.940\n let me put on my Freud hat.\n\n1:11:35.940 --> 1:11:39.660\n Maybe it's, I mean, that's our conscious mind.\n\n1:11:42.540 --> 1:11:44.060\n There's no reason that neural networks\n\n1:11:44.060 --> 1:11:46.140\n aren't doing the same kind of filtration.\n\n1:11:46.140 --> 1:11:48.500\n I mean, in the sense with GPT3 is doing,\n\n1:11:48.500 --> 1:11:50.820\n so there's a priming step.\n\n1:11:50.820 --> 1:11:53.420\n It's doing an essential kind of filtration\n\n1:11:53.420 --> 1:11:58.100\n when you ask it to generate tweets from,\n\n1:11:58.100 --> 1:12:00.780\n I don't know, from an Elon Musk or something like that.\n\n1:12:00.780 --> 1:12:04.060\n It's doing a filtration of it's throwing away\n\n1:12:04.060 --> 1:12:06.900\n all the parameters it doesn't need for this task.\n\n1:12:06.900 --> 1:12:09.700\n And it's figuring out how to do that successfully.\n\n1:12:09.700 --> 1:12:12.100\n And then ultimately it's not doing a very good job\n\n1:12:12.100 --> 1:12:14.340\n right now, but it's doing a lot better job\n\n1:12:14.340 --> 1:12:15.460\n than we expected.\n\n1:12:15.460 --> 1:12:17.500\n But it won't ever do a really good job.\n\n1:12:17.500 --> 1:12:18.340\n And I'll tell you why.\n\n1:12:18.340 --> 1:12:20.100\n I mean, so let's say we say,\n\n1:12:20.100 --> 1:12:21.660\n hey, produce an Elon Musk tweet.\n\n1:12:21.660 --> 1:12:23.980\n And we see like, oh, wow, it produced these three.\n\n1:12:23.980 --> 1:12:24.820\n That's great.\n\n1:12:24.820 --> 1:12:27.500\n But again, we're not seeing the 3000 produced\n\n1:12:27.500 --> 1:12:28.900\n that didn't really make any sense.\n\n1:12:28.900 --> 1:12:32.700\n It's because it has no idea what it is like to be a human.\n\n1:12:32.700 --> 1:12:34.540\n And all the things that you might want to say\n\n1:12:34.540 --> 1:12:35.380\n and all the reasons you wouldn't,\n\n1:12:35.380 --> 1:12:37.100\n like when you go to write a tweet,\n\n1:12:37.100 --> 1:12:38.140\n you might write something you think,\n\n1:12:38.140 --> 1:12:39.860\n ah, it's not gonna come off quite right\n\n1:12:39.860 --> 1:12:41.580\n in this modern political climate or whatever.\n\n1:12:41.580 --> 1:12:43.340\n Like, you know, you can change things.\n\n1:12:43.340 --> 1:12:44.180\n So.\n\n1:12:44.180 --> 1:12:46.700\n And it somehow boils down to fear of mortality\n\n1:12:46.700 --> 1:12:49.940\n and all of these human things at the end of the day,\n\n1:12:49.940 --> 1:12:52.500\n all contained with that tweeting experience.\n\n1:12:52.500 --> 1:12:55.540\n Well, interestingly, the fear of mortality\n\n1:12:55.540 --> 1:12:56.860\n is at the bottom of this,\n\n1:12:56.860 --> 1:12:58.700\n but you've got all these more things like,\n\n1:12:58.700 --> 1:13:01.220\n you know, oh, I want to,\n\n1:13:01.220 --> 1:13:03.180\n just in case the chairman of my department reads this,\n\n1:13:03.180 --> 1:13:04.260\n I want it to come off well there.\n\n1:13:04.260 --> 1:13:05.740\n Just in case my mom looks at this tweet,\n\n1:13:05.740 --> 1:13:08.220\n I want to make sure she, you know, and so on.\n\n1:13:08.220 --> 1:13:10.260\n So those are all the things that humans are able\n\n1:13:10.260 --> 1:13:12.340\n to sort of throw into the calculation.\n\n1:13:13.260 --> 1:13:14.820\n I mean.\n\n1:13:14.820 --> 1:13:16.540\n What it required, what it requires though,\n\n1:13:16.540 --> 1:13:18.740\n is having a model of your chairman,\n\n1:13:18.740 --> 1:13:19.820\n having a model of your mother,\n\n1:13:19.820 --> 1:13:22.060\n having a model of, you know,\n\n1:13:22.060 --> 1:13:24.500\n the person you want to go on a date with\n\n1:13:24.500 --> 1:13:26.020\n who might look at your tweet and so on.\n\n1:13:26.020 --> 1:13:27.820\n All these things are,\n\n1:13:27.820 --> 1:13:30.980\n you're running models of what it is like to be them.\n\n1:13:30.980 --> 1:13:34.540\n So in terms of the structure of the brain,\n\n1:13:34.540 --> 1:13:37.140\n again, this may be going into speculation land.\n\n1:13:37.140 --> 1:13:39.060\n I hope you go along with me.\n\n1:13:39.060 --> 1:13:39.900\n Yeah, of course.\n\n1:13:39.900 --> 1:13:40.740\n Yep.\n\n1:13:40.740 --> 1:13:45.220\n Is, okay, so the brain seems to be intelligent\n\n1:13:45.220 --> 1:13:48.380\n and our AI systems aren't very currently.\n\n1:13:48.380 --> 1:13:52.860\n So where do you think intelligence arises in the brain?\n\n1:13:52.860 --> 1:13:55.660\n Like what is it about the brain?\n\n1:13:55.660 --> 1:13:58.780\n So if you mean where location wise,\n\n1:13:58.780 --> 1:13:59.900\n it's no single spot.\n\n1:13:59.900 --> 1:14:01.980\n It would be equivalent to asking,\n\n1:14:01.980 --> 1:14:03.500\n I'm looking at New York city,\n\n1:14:04.820 --> 1:14:06.500\n where is the economy?\n\n1:14:06.500 --> 1:14:08.180\n The answer is you can't point to anywhere.\n\n1:14:08.180 --> 1:14:09.980\n The economy is all about the interaction\n\n1:14:09.980 --> 1:14:12.180\n of all of the pieces and parts of the city.\n\n1:14:12.180 --> 1:14:14.140\n And that's what, you know, intelligence,\n\n1:14:14.140 --> 1:14:15.540\n whatever we mean by that in the brain\n\n1:14:15.540 --> 1:14:18.220\n is interacting from everything going on at once.\n\n1:14:18.220 --> 1:14:19.500\n In terms of a structure.\n\n1:14:19.500 --> 1:14:23.620\n So we look humans are much smarter than fish,\n\n1:14:23.620 --> 1:14:26.700\n maybe not dolphins, but dolphins are mammals, right?\n\n1:14:26.700 --> 1:14:28.580\n I assert that what we mean by smarter\n\n1:14:28.580 --> 1:14:30.020\n has to do with live wiring.\n\n1:14:30.020 --> 1:14:32.220\n So what we mean when we say, oh, we're smart\n\n1:14:32.220 --> 1:14:33.700\n is, oh, we can figure out a new thing\n\n1:14:33.700 --> 1:14:36.740\n and figure out a new pathway to get where we need to go.\n\n1:14:36.740 --> 1:14:39.700\n And that's because fish are essentially coming to the table\n\n1:14:39.700 --> 1:14:43.740\n with, you know, okay, here's the hardware, go swim, mate.\n\n1:14:43.740 --> 1:14:46.100\n But we have the capacity to say,\n\n1:14:46.100 --> 1:14:47.580\n okay, look, I'm gonna absorb, oh, oh,\n\n1:14:47.580 --> 1:14:49.260\n but you know, I saw someone else do this thing\n\n1:14:49.260 --> 1:14:51.980\n and I read once that you could do this other thing\n\n1:14:51.980 --> 1:14:52.820\n and so on.\n\n1:14:52.820 --> 1:14:54.620\n So do you think there's, is there something,\n\n1:14:54.620 --> 1:14:56.700\n I know these are mysteries,\n\n1:14:56.700 --> 1:15:00.140\n but like architecturally speaking,\n\n1:15:00.140 --> 1:15:05.140\n what feature of the brain of the live wire aspect of it\n\n1:15:06.100 --> 1:15:08.140\n that is really useful for intelligence?\n\n1:15:08.140 --> 1:15:13.140\n So like, is it the ability of neurons to reconnect?\n\n1:15:15.180 --> 1:15:16.220\n Like, is there something,\n\n1:15:16.220 --> 1:15:18.180\n is there any lessons about the human brain\n\n1:15:18.180 --> 1:15:21.020\n you think might be inspiring for us\n\n1:15:21.020 --> 1:15:26.020\n to take into the artificial, into the machine learning world?\n\n1:15:26.860 --> 1:15:29.620\n Yeah, I'm actually just trying to write some up on this now\n\n1:15:29.620 --> 1:15:31.300\n called, you know, if you wanna build a robot,\n\n1:15:31.300 --> 1:15:32.460\n start with the stomach.\n\n1:15:32.460 --> 1:15:35.380\n And what I mean by that, what I mean by that is\n\n1:15:35.380 --> 1:15:37.220\n a robot has to care, it has to have hunger,\n\n1:15:37.220 --> 1:15:40.340\n it has to care about surviving, that kind of thing.\n\n1:15:40.340 --> 1:15:41.260\n Here's an example.\n\n1:15:41.260 --> 1:15:44.180\n So the penultimate chapter of my book,\n\n1:15:44.180 --> 1:15:46.620\n I titled The Wolf and the Mars Rover.\n\n1:15:46.620 --> 1:15:48.860\n And I just look at this simple comparison\n\n1:15:48.860 --> 1:15:52.580\n of you look at a wolf, it gets its leg caught in a trap.\n\n1:15:52.580 --> 1:15:53.420\n What does it do?\n\n1:15:53.420 --> 1:15:55.460\n It gnaws its leg off,\n\n1:15:55.460 --> 1:15:58.220\n and then it figures out how to walk on three legs.\n\n1:15:58.220 --> 1:15:59.060\n No problem.\n\n1:15:59.060 --> 1:16:02.180\n Now, the Mars Rover Curiosity got its front wheel stuck\n\n1:16:02.180 --> 1:16:05.220\n in some Martian soil, and it died.\n\n1:16:05.220 --> 1:16:09.100\n This project that cost billions of dollars died\n\n1:16:09.100 --> 1:16:09.980\n because it got its wheels.\n\n1:16:09.980 --> 1:16:12.740\n Wouldn't it be terrific if we could build a robot\n\n1:16:12.740 --> 1:16:15.260\n that chewed off its front wheel and figured out\n\n1:16:15.260 --> 1:16:17.780\n how to operate with a slightly different body plan?\n\n1:16:17.780 --> 1:16:21.020\n That's the kind of thing that we wanna be able to build.\n\n1:16:21.020 --> 1:16:23.300\n And to get there, what we need,\n\n1:16:23.300 --> 1:16:25.140\n the whole reason the wolf is able to do that\n\n1:16:25.140 --> 1:16:27.940\n is because its motor and somatosensory systems\n\n1:16:27.940 --> 1:16:28.780\n are live wired.\n\n1:16:28.780 --> 1:16:29.980\n So it says, oh, you know what?\n\n1:16:29.980 --> 1:16:31.620\n Turns out we've got a body plan that's different\n\n1:16:31.620 --> 1:16:34.140\n than what I thought a few minutes ago,\n\n1:16:34.140 --> 1:16:38.820\n but I have a yen to survive and I care about relevance,\n\n1:16:38.820 --> 1:16:40.660\n which in this case is getting to food,\n\n1:16:40.660 --> 1:16:42.580\n getting back to my pack and so on.\n\n1:16:42.580 --> 1:16:44.660\n So I'm just gonna figure out how to operate with this.\n\n1:16:44.660 --> 1:16:46.020\n Oh, whoops, that didn't work.\n\n1:16:46.020 --> 1:16:48.500\n Oh, okay, I'm kind of getting it to work.\n\n1:16:48.500 --> 1:16:49.900\n But the Mars Rover doesn't do that.\n\n1:16:49.900 --> 1:16:51.860\n It just says, oh geez, I was pre programmed.\n\n1:16:51.860 --> 1:16:53.980\n Four wheels, now I have three, I'm screwed.\n\n1:16:53.980 --> 1:16:55.900\n Yeah, you know, I don't know if you're familiar\n\n1:16:55.900 --> 1:16:58.180\n with a philosopher named Ernest Becker.\n\n1:16:58.180 --> 1:17:00.780\n He wrote a book called Denial of Death.\n\n1:17:00.780 --> 1:17:03.500\n And there's a few psychologists, Sheldon Solomon,\n\n1:17:03.500 --> 1:17:06.220\n I think I just spoke with him on his podcast\n\n1:17:07.260 --> 1:17:09.900\n who developed terror management theory,\n\n1:17:09.900 --> 1:17:12.940\n which is like Ernest Becker is a philosopher\n\n1:17:12.940 --> 1:17:17.220\n that basically said that fear of mortality\n\n1:17:17.220 --> 1:17:18.220\n is at the core of it.\n\n1:17:18.220 --> 1:17:19.060\n Yeah.\n\n1:17:19.060 --> 1:17:23.140\n And so I don't know if it sounds compelling as an idea\n\n1:17:23.140 --> 1:17:26.980\n that all of the civilization we've constructed\n\n1:17:26.980 --> 1:17:29.100\n is based on this, but it's.\n\n1:17:29.100 --> 1:17:30.300\n I'm familiar with his work.\n\n1:17:30.300 --> 1:17:31.220\n Here's what I think.\n\n1:17:31.220 --> 1:17:35.180\n I think that yes, fundamentally this desire to survive\n\n1:17:35.180 --> 1:17:37.420\n is at the core of it, I would agree with that.\n\n1:17:37.420 --> 1:17:40.660\n But how that expresses itself in your life\n\n1:17:40.660 --> 1:17:41.700\n ends up being very different.\n\n1:17:41.700 --> 1:17:45.340\n The reason you do what you do is, I mean,\n\n1:17:45.340 --> 1:17:47.900\n you could list the 100 reasons why you chose\n\n1:17:47.900 --> 1:17:49.300\n to write your tweet this way and that way.\n\n1:17:49.300 --> 1:17:51.340\n And it really has nothing to do with the survival part.\n\n1:17:51.340 --> 1:17:53.540\n It has to do with, you know, trying to impress fellow humans\n\n1:17:53.540 --> 1:17:55.260\n and surprise them and say something.\n\n1:17:55.260 --> 1:17:56.940\n Yeah, so many things built on top of each other,\n\n1:17:56.940 --> 1:17:58.820\n but it's fascinating to think\n\n1:17:58.820 --> 1:18:00.900\n that in artificial intelligence systems,\n\n1:18:00.900 --> 1:18:05.420\n we wanna be able to somehow engineer this drive\n\n1:18:05.420 --> 1:18:08.300\n for survival, for immortality.\n\n1:18:08.300 --> 1:18:11.460\n I mean, because as humans, we're not just about survival,\n\n1:18:11.460 --> 1:18:14.740\n we're aware of the fact that we're going to die,\n\n1:18:14.740 --> 1:18:17.420\n which is a very kind of, we're aware of like space time.\n\n1:18:17.420 --> 1:18:18.500\n Most people aren't, by the way.\n\n1:18:18.500 --> 1:18:19.340\n Aren't?\n\n1:18:19.340 --> 1:18:20.340\n Aren't.\n\n1:18:20.340 --> 1:18:25.340\n Confucius said, he said, each person has two lives.\n\n1:18:25.980 --> 1:18:28.060\n The second one begins when you realize\n\n1:18:28.060 --> 1:18:29.500\n that you have just one.\n\n1:18:29.500 --> 1:18:30.340\n Yeah.\n\n1:18:30.340 --> 1:18:31.340\n But most people, it takes a long time\n\n1:18:31.340 --> 1:18:32.700\n for most people to get there.\n\n1:18:32.700 --> 1:18:34.660\n I mean, you could argue this kind of Freudian thing,\n\n1:18:34.660 --> 1:18:41.660\n which Erzbecker argues is they actually figured it out\n\n1:18:41.660 --> 1:18:44.860\n early on and the terror they felt\n\n1:18:44.860 --> 1:18:47.580\n was like the reason it's been suppressed.\n\n1:18:47.580 --> 1:18:49.300\n And the reason most people, when I ask them\n\n1:18:49.300 --> 1:18:50.700\n about whether they're afraid of death,\n\n1:18:50.700 --> 1:18:52.180\n they basically say no.\n\n1:18:53.180 --> 1:18:56.980\n They basically say like, I'm afraid I won't get,\n\n1:18:56.980 --> 1:18:59.820\n like submit the paper before I die.\n\n1:18:59.820 --> 1:19:01.900\n Like they kind of see, they see death\n\n1:19:01.900 --> 1:19:04.780\n as a kind of a inconvenient deadline\n\n1:19:04.780 --> 1:19:08.180\n for a particular set of, like a book you're writing.\n\n1:19:08.180 --> 1:19:10.700\n As opposed to like, what the hell?\n\n1:19:10.700 --> 1:19:14.780\n This thing ends at any moment.\n\n1:19:14.780 --> 1:19:17.260\n Like most people, as I've encountered,\n\n1:19:17.260 --> 1:19:20.700\n do not meditate on the idea that like right now\n\n1:19:20.700 --> 1:19:21.740\n you could die.\n\n1:19:21.740 --> 1:19:26.380\n Like right now, like in the next five minutes,\n\n1:19:26.380 --> 1:19:29.940\n it could be all over and, you know, meditate on that idea.\n\n1:19:29.940 --> 1:19:32.580\n I think that somehow brings you closer\n\n1:19:32.580 --> 1:19:36.500\n to like the core of the motivations\n\n1:19:36.500 --> 1:19:40.140\n and the core of the human cognition condition.\n\n1:19:40.140 --> 1:19:41.300\n I think it might be the core, but like I said,\n\n1:19:41.300 --> 1:19:43.820\n it is not what drives us day to day.\n\n1:19:43.820 --> 1:19:45.540\n Yeah, there's so many things on top of it,\n\n1:19:45.540 --> 1:19:46.380\n but it is interesting.\n\n1:19:46.380 --> 1:19:48.780\n I mean, as the ancient poet said,\n\n1:19:49.660 --> 1:19:53.340\n death whispers at my ear, live for I come.\n\n1:19:53.340 --> 1:19:56.100\n So it's, it is certainly motivating\n\n1:19:56.100 --> 1:19:58.060\n when we think about that.\n\n1:19:58.060 --> 1:19:59.220\n Okay, I've got some deadline.\n\n1:19:59.220 --> 1:20:00.340\n I don't know exactly when it is,\n\n1:20:00.340 --> 1:20:02.180\n but I better make stuff happen.\n\n1:20:02.180 --> 1:20:04.300\n It is motivating, but I don't think,\n\n1:20:04.300 --> 1:20:06.780\n I mean, I know for just speaking for me personally,\n\n1:20:06.780 --> 1:20:08.900\n that's not what motivates me day to day.\n\n1:20:08.900 --> 1:20:13.380\n It's instead, oh, I want to get this, you know,\n\n1:20:13.380 --> 1:20:14.780\n program up and running before this,\n\n1:20:14.780 --> 1:20:17.300\n or I want to make sure my coauthor isn't mad at me\n\n1:20:17.300 --> 1:20:18.220\n because I haven't gotten this in,\n\n1:20:18.220 --> 1:20:19.580\n or I don't want to miss this grant deadline,\n\n1:20:19.580 --> 1:20:21.180\n or, you know, whatever the thing is.\n\n1:20:21.180 --> 1:20:24.060\n Yeah, it's too distant in a sense.\n\n1:20:24.060 --> 1:20:26.540\n Nevertheless, it is good to reconnect.\n\n1:20:26.540 --> 1:20:30.220\n But for the AI systems, none of that is there.\n\n1:20:31.220 --> 1:20:33.860\n Like a neural network does not fear its mortality.\n\n1:20:34.940 --> 1:20:37.180\n And that seems to be somehow\n\n1:20:37.180 --> 1:20:39.660\n fundamentally missing the point.\n\n1:20:39.660 --> 1:20:40.700\n I think that's missing the point,\n\n1:20:40.700 --> 1:20:42.420\n but I wonder, it's an interesting speculation\n\n1:20:42.420 --> 1:20:43.700\n about whether you can build an AI system\n\n1:20:43.700 --> 1:20:45.780\n that is much closer to being a human\n\n1:20:45.780 --> 1:20:48.380\n without the mortality and survival piece,\n\n1:20:48.380 --> 1:20:51.140\n but just the thing of relevance,\n\n1:20:51.140 --> 1:20:52.740\n just I care about this versus that.\n\n1:20:52.740 --> 1:20:54.780\n Right now, if you have a robot roll into the room,\n\n1:20:54.780 --> 1:20:55.660\n it's going to be frozen\n\n1:20:55.660 --> 1:20:57.700\n because it doesn't have any reason to go there versus there.\n\n1:20:57.700 --> 1:21:02.580\n It doesn't have any particular set of things\n\n1:21:02.580 --> 1:21:05.620\n about this is how I should navigate my next move\n\n1:21:05.620 --> 1:21:07.700\n because I want something.\n\n1:21:07.700 --> 1:21:10.900\n Yeah, the thing about humans\n\n1:21:10.900 --> 1:21:13.740\n is they seem to generate goals.\n\n1:21:13.740 --> 1:21:15.740\n They're like, you said livewired.\n\n1:21:15.740 --> 1:21:19.980\n I mean, it's very flexible in terms of the goals\n\n1:21:19.980 --> 1:21:21.780\n and creative in terms of the goals we generate\n\n1:21:21.780 --> 1:21:23.700\n when we enter a room.\n\n1:21:23.700 --> 1:21:25.540\n You show up to a party without a goal,\n\n1:21:25.540 --> 1:21:27.900\n usually, and then you figure it out along the way.\n\n1:21:27.900 --> 1:21:29.980\n Yes, but this goes back to the question about free will,\n\n1:21:29.980 --> 1:21:31.940\n which is when I walk into the party,\n\n1:21:33.340 --> 1:21:35.620\n if you rewound it 10,000 times,\n\n1:21:35.620 --> 1:21:37.980\n would I go and talk to that couple over there\n\n1:21:37.980 --> 1:21:38.980\n versus that person?\n\n1:21:38.980 --> 1:21:41.700\n Like, I might do this exact same thing every time\n\n1:21:41.700 --> 1:21:44.380\n because I've got some goal stack and I think,\n\n1:21:44.380 --> 1:21:45.820\n okay, well, at this party,\n\n1:21:45.820 --> 1:21:47.700\n I really want to meet these kind of people\n\n1:21:47.700 --> 1:21:51.340\n or I feel awkward or whatever my goals are.\n\n1:21:51.340 --> 1:21:52.620\n By the way, so there was something\n\n1:21:52.620 --> 1:21:54.580\n that I meant to mention earlier.\n\n1:21:54.580 --> 1:21:56.140\n If you don't mind going back,\n\n1:21:56.140 --> 1:21:58.340\n which is this, when we were talking about BCI.\n\n1:21:59.380 --> 1:22:00.260\n So I don't know if you know this,\n\n1:22:00.260 --> 1:22:02.620\n but what I'm spending 90% of my time doing now\n\n1:22:02.620 --> 1:22:03.820\n is running a company.\n\n1:22:03.820 --> 1:22:04.660\n Do you know about this?\n\n1:22:04.660 --> 1:22:08.100\n Yes, I wasn't sure what the company is involved in.\n\n1:22:08.100 --> 1:22:09.420\n Right, so. Can you talk about it?\n\n1:22:09.420 --> 1:22:10.820\n Yeah, yeah.\n\n1:22:10.820 --> 1:22:13.020\n So when it comes to the future of BCI,\n\n1:22:15.020 --> 1:22:18.860\n you can put stuff into the brain invasively,\n\n1:22:18.860 --> 1:22:22.060\n but my interest has been how you can get data streams\n\n1:22:22.060 --> 1:22:24.180\n into the brain noninvasively.\n\n1:22:24.180 --> 1:22:26.340\n So I run a company called Neosensory\n\n1:22:26.340 --> 1:22:29.620\n and what we build is this little wristband.\n\n1:22:29.620 --> 1:22:30.580\n We've built this in many different form factors.\n\n1:22:30.580 --> 1:22:31.940\n Oh, wow, that's it?\n\n1:22:31.940 --> 1:22:32.780\n Yeah, this is it.\n\n1:22:32.780 --> 1:22:35.420\n And it's got these vibratory motors in it.\n\n1:22:35.420 --> 1:22:38.220\n So these things, as I'm speaking, for example,\n\n1:22:38.220 --> 1:22:41.060\n it's capturing my voice and running algorithms\n\n1:22:41.060 --> 1:22:44.460\n and then turning that into patterns of vibration here.\n\n1:22:44.460 --> 1:22:48.740\n So people who are deaf, for example,\n\n1:22:48.740 --> 1:22:50.780\n learn to hear through their skin.\n\n1:22:50.780 --> 1:22:54.260\n So the information is getting up to their brain this way\n\n1:22:54.260 --> 1:22:55.820\n and they learn how to hear.\n\n1:22:55.820 --> 1:22:58.020\n So it turns out on day one, people are pretty good,\n\n1:22:58.020 --> 1:23:00.580\n like better than you'd expect at being able to say,\n\n1:23:00.580 --> 1:23:02.540\n oh, that's weird, was that a dog barking?\n\n1:23:02.540 --> 1:23:03.380\n Was that a baby crying?\n\n1:23:03.380 --> 1:23:04.740\n Was that a door knock, a doorbell?\n\n1:23:04.740 --> 1:23:06.500\n Like people are pretty good at it,\n\n1:23:06.500 --> 1:23:09.260\n but with time they get better and better\n\n1:23:09.260 --> 1:23:12.380\n and what it becomes is a new qualia.\n\n1:23:12.380 --> 1:23:15.380\n In other words, a new subjective internal experience.\n\n1:23:15.380 --> 1:23:18.380\n So on day one, they say, whoa, what was that?\n\n1:23:18.380 --> 1:23:20.620\n Oh, oh, that was the dog barking.\n\n1:23:20.620 --> 1:23:23.420\n But by three months later, they say,\n\n1:23:23.420 --> 1:23:24.540\n oh, there's a dog barking somewhere.\n\n1:23:24.540 --> 1:23:25.540\n Oh, there's the dog.\n\n1:23:25.540 --> 1:23:26.380\n That's fascinating.\n\n1:23:26.380 --> 1:23:27.700\n And by the way, that's exactly how you learn\n\n1:23:27.700 --> 1:23:29.380\n how to use your ears.\n\n1:23:29.380 --> 1:23:30.540\n So of course you don't remember this,\n\n1:23:30.540 --> 1:23:33.100\n but when you were an infant, all you have are\n\n1:23:33.100 --> 1:23:36.540\n your eardrum vibrating causes spikes to go down,\n\n1:23:36.540 --> 1:23:39.940\n your auditory nerves and impinging your auditory cortex.\n\n1:23:40.940 --> 1:23:43.060\n Your brain doesn't know what those mean automatically,\n\n1:23:43.060 --> 1:23:44.820\n but what happens is you learn how to hear\n\n1:23:44.820 --> 1:23:46.420\n by looking for correlations.\n\n1:23:46.420 --> 1:23:48.900\n You clap your hands as a baby,\n\n1:23:48.900 --> 1:23:50.860\n you look at your mother's mouth moving\n\n1:23:50.860 --> 1:23:53.180\n and that correlates with what's going on there.\n\n1:23:53.180 --> 1:23:54.860\n And eventually your brain says, all right,\n\n1:23:54.860 --> 1:23:57.940\n I'm just gonna summarize this as an internal experience,\n\n1:23:57.940 --> 1:23:59.300\n as a conscious experience.\n\n1:23:59.300 --> 1:24:01.260\n And that's exactly what happens here.\n\n1:24:01.260 --> 1:24:04.140\n The weird part is that you can feed data into the brain,\n\n1:24:04.140 --> 1:24:06.260\n not through the ears, but through any channel\n\n1:24:06.260 --> 1:24:07.180\n that gets there.\n\n1:24:07.180 --> 1:24:08.500\n As long as the information gets there,\n\n1:24:08.500 --> 1:24:10.260\n your brain figures out what to do with it.\n\n1:24:10.260 --> 1:24:11.340\n That's fascinating.\n\n1:24:11.340 --> 1:24:14.740\n Like expanding the set of sensors,\n\n1:24:14.740 --> 1:24:19.060\n it could be arbitrarily, yeah,\n\n1:24:19.060 --> 1:24:21.220\n it could expand arbitrarily, which is fascinating.\n\n1:24:21.220 --> 1:24:22.060\n Well, exactly.\n\n1:24:22.060 --> 1:24:24.500\n And by the way, the reason I use this skin,\n\n1:24:24.500 --> 1:24:26.300\n there's all kinds of cool stuff going on\n\n1:24:26.300 --> 1:24:28.140\n in the AR world with glasses.\n\n1:24:28.140 --> 1:24:29.940\n But the fact is your eyes are overtaxed\n\n1:24:29.940 --> 1:24:30.900\n and your ears are overtaxed\n\n1:24:30.900 --> 1:24:33.420\n and you need to be able to see and hear other stuff.\n\n1:24:33.420 --> 1:24:34.660\n But you're covered with the skin,\n\n1:24:34.660 --> 1:24:38.140\n which is this incredible computational material\n\n1:24:38.140 --> 1:24:39.700\n with which you can feed information.\n\n1:24:39.700 --> 1:24:42.540\n And we don't use our skin for much of anything nowadays.\n\n1:24:42.540 --> 1:24:44.260\n My joke in the lab is that I say,\n\n1:24:44.260 --> 1:24:45.820\n we don't call this the waste for nothing.\n\n1:24:45.820 --> 1:24:47.380\n Because originally we built this as the vest\n\n1:24:47.380 --> 1:24:51.020\n and you're passing in all this information that way.\n\n1:24:51.020 --> 1:24:56.020\n And what I'm doing here with the deaf community\n\n1:24:56.380 --> 1:24:59.020\n is what's called sensory substitution,\n\n1:24:59.020 --> 1:25:02.420\n where I'm capturing sound and I'm just replacing the ears\n\n1:25:02.420 --> 1:25:04.340\n with the skin and that works.\n\n1:25:05.900 --> 1:25:07.140\n One of the things I talk about LiveWire\n\n1:25:07.140 --> 1:25:09.500\n is sensory expansion.\n\n1:25:09.500 --> 1:25:11.980\n So what if you took something like your visual system,\n\n1:25:11.980 --> 1:25:13.500\n which picks up on a very thin slice\n\n1:25:13.500 --> 1:25:15.300\n of the electromagnetic spectrum,\n\n1:25:15.300 --> 1:25:18.460\n and you could see infrared or ultraviolet.\n\n1:25:18.460 --> 1:25:21.100\n So we've hooked that up, infrared and ultraviolet detectors,\n\n1:25:21.100 --> 1:25:22.780\n and I can feel what's going on.\n\n1:25:22.780 --> 1:25:25.220\n So just as an example, the first night I built the infrared,\n\n1:25:25.220 --> 1:25:27.460\n one of my engineers built it, the infrared detector,\n\n1:25:27.460 --> 1:25:29.420\n I was walking in the dark between two houses\n\n1:25:29.420 --> 1:25:31.780\n and suddenly I felt all this infrared radiation.\n\n1:25:31.780 --> 1:25:32.860\n I was like, where's that come from?\n\n1:25:32.860 --> 1:25:35.900\n And I just followed my wrist and I found an infrared camera,\n\n1:25:35.900 --> 1:25:37.780\n a night vision camera that was,\n\n1:25:37.780 --> 1:25:40.420\n but I immediately, oh, there's that thing there.\n\n1:25:40.420 --> 1:25:42.060\n Of course, I would have never seen it,\n\n1:25:42.060 --> 1:25:45.260\n but now it's just part of my reality.\n\n1:25:45.260 --> 1:25:46.100\n That's fascinating.\n\n1:25:46.100 --> 1:25:46.940\n Yeah, and then of course,\n\n1:25:46.940 --> 1:25:49.860\n what I'm really interested in is sensory addition.\n\n1:25:49.860 --> 1:25:51.620\n What if you could pick up on stuff\n\n1:25:51.620 --> 1:25:55.060\n that isn't even part of what we normally pick up on,\n\n1:25:55.060 --> 1:25:57.620\n like the magnetic field of the earth\n\n1:25:57.620 --> 1:26:00.660\n or Twitter or stock market or things like that.\n\n1:26:00.660 --> 1:26:02.300\n Or the, I don't know, some weird stuff\n\n1:26:02.300 --> 1:26:04.260\n like the moods of other people or something like that.\n\n1:26:04.260 --> 1:26:06.540\n Sure, now what you need is a way to measure this.\n\n1:26:06.540 --> 1:26:08.180\n So as long as there's a machine that can measure it,\n\n1:26:08.180 --> 1:26:09.980\n it's easy, it's trivial to feed this in here\n\n1:26:09.980 --> 1:26:14.300\n and you come to be, it comes to be part of your reality.\n\n1:26:14.300 --> 1:26:16.220\n It's like you have another sensor.\n\n1:26:16.220 --> 1:26:19.140\n And that kind of thing is without doing like,\n\n1:26:19.140 --> 1:26:20.860\n if you look in Neuralink,\n\n1:26:20.860 --> 1:26:23.700\n I forgot how you put it, but it was eloquent,\n\n1:26:23.700 --> 1:26:26.140\n without getting, cutting into the brain, basically.\n\n1:26:26.140 --> 1:26:27.300\n Yeah, exactly, exactly.\n\n1:26:27.300 --> 1:26:30.660\n So this costs, at the moment, $399.\n\n1:26:30.660 --> 1:26:32.060\n That's not gonna kill you.\n\n1:26:32.060 --> 1:26:33.380\n Yeah, it's not gonna kill you.\n\n1:26:33.380 --> 1:26:36.540\n You just put it on and when you're done, you take it off.\n\n1:26:36.540 --> 1:26:39.180\n Yeah, and so, and the name of the company, by the way,\n\n1:26:39.180 --> 1:26:42.700\n is Neosensory for new senses, because the whole idea is.\n\n1:26:42.700 --> 1:26:43.540\n Beautiful, that's.\n\n1:26:43.540 --> 1:26:45.940\n You can, as I said, you come to the table\n\n1:26:45.940 --> 1:26:48.060\n with certain plug and play devices and then that's it.\n\n1:26:48.060 --> 1:26:49.140\n Like I can pick up on this little bit\n\n1:26:49.140 --> 1:26:50.180\n of the electromagnetic radiation,\n\n1:26:50.180 --> 1:26:53.420\n you can pick up on this little frequency band\n\n1:26:53.420 --> 1:26:56.220\n for hearing and so on, but I'm stuck there\n\n1:26:56.220 --> 1:26:57.820\n and there's no reason we have to be stuck there.\n\n1:26:57.820 --> 1:27:01.740\n We can expand our umwelt by adding new senses, yeah.\n\n1:27:01.740 --> 1:27:02.660\n What's umwelt?\n\n1:27:02.660 --> 1:27:05.740\n Oh, I'm sorry, the umwelt is the slice of reality\n\n1:27:05.740 --> 1:27:06.580\n that you pick up on.\n\n1:27:06.580 --> 1:27:09.420\n So each animal has its own umwelt.\n\n1:27:09.420 --> 1:27:10.780\n Yeah, exactly.\n\n1:27:10.780 --> 1:27:11.620\n Nice.\n\n1:27:11.620 --> 1:27:12.460\n I'm sorry, I forgot to define it before.\n\n1:27:12.460 --> 1:27:15.660\n It's such an important concept, which is to say,\n\n1:27:17.340 --> 1:27:19.780\n for example, if you are a tick,\n\n1:27:19.780 --> 1:27:22.820\n you pick up on butyric gas, you pick up on odor\n\n1:27:22.820 --> 1:27:24.100\n and you pick up on temperature, that's it.\n\n1:27:24.100 --> 1:27:25.740\n That's how you construct your reality\n\n1:27:25.740 --> 1:27:26.860\n is with those two sensors.\n\n1:27:26.860 --> 1:27:28.820\n If you are a blind echolocating bat,\n\n1:27:28.820 --> 1:27:31.500\n you're picking up on air compression waves coming back,\n\n1:27:31.500 --> 1:27:32.540\n you know, echolocation.\n\n1:27:32.540 --> 1:27:34.820\n If you are the black ghost knife fish,\n\n1:27:34.820 --> 1:27:37.980\n you're picking up on changes in the electrical field\n\n1:27:37.980 --> 1:27:40.420\n around you with electroreception.\n\n1:27:40.420 --> 1:27:41.380\n That's how they swim around\n\n1:27:41.380 --> 1:27:43.020\n and tell there's a rock there and so on.\n\n1:27:43.020 --> 1:27:45.060\n But that's all they pick up on.\n\n1:27:45.060 --> 1:27:47.020\n That's their umwelt.\n\n1:27:47.020 --> 1:27:49.820\n That's the signals they get from the world\n\n1:27:49.820 --> 1:27:51.300\n from which to construct their reality.\n\n1:27:51.300 --> 1:27:53.540\n And they can be totally different umwelts.\n\n1:27:53.540 --> 1:27:54.380\n That's fantastic.\n\n1:27:54.380 --> 1:27:57.460\n And so our human umwelt is, you know,\n\n1:27:57.460 --> 1:27:59.380\n we've got little bits that we can pick up on.\n\n1:27:59.380 --> 1:28:01.100\n One of the things I like to do with my students\n\n1:28:01.100 --> 1:28:05.780\n is talk about, imagine that you are a bloodhound dog, right?\n\n1:28:05.780 --> 1:28:07.500\n You are a bloodhound dog with a huge snout\n\n1:28:07.500 --> 1:28:09.380\n with 200 million scent receptors in it.\n\n1:28:09.380 --> 1:28:11.260\n And your whole world is about smelling.\n\n1:28:11.260 --> 1:28:13.740\n You know, you've got slits in your nostrils,\n\n1:28:13.740 --> 1:28:15.300\n like big nose fulls of air and so on.\n\n1:28:15.300 --> 1:28:16.460\n Do you have a dog?\n\n1:28:16.460 --> 1:28:17.300\n Nope, used to.\n\n1:28:17.300 --> 1:28:18.140\n Used to, okay, right.\n\n1:28:18.140 --> 1:28:19.340\n So you know, you walk your dog around\n\n1:28:19.340 --> 1:28:21.020\n and your dog is smelling everything.\n\n1:28:21.020 --> 1:28:22.260\n The whole world is full of signals\n\n1:28:22.260 --> 1:28:23.820\n that you do not pick up on.\n\n1:28:23.820 --> 1:28:25.380\n And so imagine if you were that dog\n\n1:28:25.380 --> 1:28:26.940\n and you looked at your human master and thought,\n\n1:28:26.940 --> 1:28:28.100\n my God, what is it like to have\n\n1:28:28.100 --> 1:28:30.420\n the pitiful little nose of a human?\n\n1:28:30.420 --> 1:28:32.740\n How could you not know that there's a cat 100 yards away\n\n1:28:32.740 --> 1:28:34.500\n or that your friend was here six hours ago?\n\n1:28:34.500 --> 1:28:37.980\n And so the idea is because we're stuck in our own belt,\n\n1:28:37.980 --> 1:28:39.180\n because we have this little pitiful noses,\n\n1:28:39.180 --> 1:28:41.500\n we think, okay, well, yeah, we're seeing reality,\n\n1:28:41.500 --> 1:28:44.540\n but you can have very different sorts of realities\n\n1:28:44.540 --> 1:28:46.940\n depending on the peripheral plug and play devices\n\n1:28:46.940 --> 1:28:47.780\n you're equipped with.\n\n1:28:47.780 --> 1:28:49.660\n It's fascinating to think that like,\n\n1:28:49.660 --> 1:28:52.100\n if we're being honest, probably our own belt\n\n1:28:52.100 --> 1:28:57.340\n is, you know, some infinitely tiny percent\n\n1:28:57.340 --> 1:29:01.420\n of the possibilities of how you can sense,\n\n1:29:01.420 --> 1:29:04.380\n quote unquote, reality, even if you could,\n\n1:29:04.380 --> 1:29:08.780\n I mean, there's a guy named Donald Hoffman, yeah,\n\n1:29:08.780 --> 1:29:13.780\n who basically says we're really far away from reality\n\n1:29:13.860 --> 1:29:15.980\n in terms of our ability to sense anything.\n\n1:29:15.980 --> 1:29:20.700\n Like we're very, we're almost like we're floating out there\n\n1:29:20.700 --> 1:29:22.420\n that's almost like completely attached\n\n1:29:22.420 --> 1:29:24.220\n to the actual physical reality.\n\n1:29:24.220 --> 1:29:27.060\n It's fascinating that we can have extra senses\n\n1:29:27.060 --> 1:29:29.660\n that could help us get a little bit closer.\n\n1:29:29.660 --> 1:29:33.340\n Exactly, and by the way, this has been the fruits\n\n1:29:33.340 --> 1:29:36.100\n of science is realizing, like, for example,\n\n1:29:36.100 --> 1:29:36.940\n you know, you open your eyes\n\n1:29:36.940 --> 1:29:38.220\n and there's the world around you, right?\n\n1:29:38.220 --> 1:29:40.100\n But of course, depending on how you calculate it,\n\n1:29:40.100 --> 1:29:42.900\n it's less than a 10 trillionth of the electromagnetic\n\n1:29:42.900 --> 1:29:45.780\n spectrum that we call visible light.\n\n1:29:45.780 --> 1:29:46.620\n The reason I say it depends,\n\n1:29:46.620 --> 1:29:47.820\n because, you know, it's actually infinite\n\n1:29:47.820 --> 1:29:49.220\n in all directions presumably.\n\n1:29:49.220 --> 1:29:51.260\n Yeah, and so that's exactly that.\n\n1:29:51.260 --> 1:29:53.620\n And then science allows you to actually look\n\n1:29:53.620 --> 1:29:54.980\n into the rest of it.\n\n1:29:54.980 --> 1:29:57.140\n Exactly, so understanding how big the world is out there.\n\n1:29:57.140 --> 1:29:59.060\n And the same with the world of really small\n\n1:29:59.060 --> 1:30:00.460\n and the world of really large.\n\n1:30:00.460 --> 1:30:01.300\n Exactly.\n\n1:30:01.300 --> 1:30:03.100\n That's beyond our ability to sense.\n\n1:30:03.100 --> 1:30:04.980\n Exactly, and so the reason I think this kind of thing\n\n1:30:04.980 --> 1:30:07.740\n matters is because we now have an opportunity\n\n1:30:07.740 --> 1:30:10.900\n for the first time in human history to say,\n\n1:30:10.900 --> 1:30:13.060\n okay, well, I'm just gonna include other things\n\n1:30:13.060 --> 1:30:13.900\n in my own belt.\n\n1:30:13.900 --> 1:30:15.700\n So I'm gonna include infrared radiation\n\n1:30:15.700 --> 1:30:19.020\n and have a direct perceptual experience of that.\n\n1:30:19.020 --> 1:30:21.340\n And so I'm very, you know, I mean,\n\n1:30:21.340 --> 1:30:22.660\n so, you know, I've given up my lab\n\n1:30:22.660 --> 1:30:25.340\n and I run this company 90% of my time now.\n\n1:30:25.340 --> 1:30:26.180\n That's what I'm doing.\n\n1:30:26.180 --> 1:30:27.740\n I still teach at Stanford and I'm, you know,\n\n1:30:27.740 --> 1:30:29.660\n teaching courses and stuff like that.\n\n1:30:29.660 --> 1:30:32.980\n But this is like, this is your passion.\n\n1:30:32.980 --> 1:30:35.020\n The fire is on this.\n\n1:30:35.020 --> 1:30:37.420\n Yeah, I feel like this is the most important thing\n\n1:30:37.420 --> 1:30:38.820\n that's happening right now.\n\n1:30:38.820 --> 1:30:40.100\n I mean, obviously I think that,\n\n1:30:40.100 --> 1:30:42.300\n because that's what I'm devoting my time in my life to.\n\n1:30:42.300 --> 1:30:45.100\n But I mean, it's a brilliant set of ideas.\n\n1:30:45.100 --> 1:30:50.100\n It certainly is like, it's a step in a very vibrant future,\n\n1:30:50.100 --> 1:30:50.940\n I would say.\n\n1:30:50.940 --> 1:30:54.180\n Like the possibilities there are endless.\n\n1:30:54.180 --> 1:30:55.020\n Exactly.\n\n1:30:55.020 --> 1:30:57.220\n So if you ask what I think about Neuralink,\n\n1:30:57.220 --> 1:30:59.260\n I think it's amazing what those guys are doing\n\n1:30:59.260 --> 1:31:00.100\n and working on,\n\n1:31:00.100 --> 1:31:02.820\n but I think it's not practical for almost everybody.\n\n1:31:02.820 --> 1:31:05.700\n For example, for people who are deaf, they buy this\n\n1:31:05.700 --> 1:31:08.420\n and, you know, every day we're getting tons of emails\n\n1:31:08.420 --> 1:31:09.980\n and tweets and whatever from people saying, wow,\n\n1:31:09.980 --> 1:31:12.500\n I picked up on this and then I had no idea that was a,\n\n1:31:12.500 --> 1:31:14.700\n I didn't even know that was happening out there.\n\n1:31:14.700 --> 1:31:16.820\n And they're coming to hear, by the way,\n\n1:31:16.820 --> 1:31:18.700\n this is, you know, less than a 10 year old,\n\n1:31:18.700 --> 1:31:20.860\n by the way, this is less than a 10th of the price\n\n1:31:20.860 --> 1:31:23.340\n of a hearing aid and like 250 times less\n\n1:31:23.340 --> 1:31:25.220\n than a cochlear implant.\n\n1:31:25.220 --> 1:31:26.060\n That's amazing.\n\n1:31:27.100 --> 1:31:30.660\n People love hearing about what, you know,\n\n1:31:30.660 --> 1:31:33.900\n brilliant folks like yourself could recommend\n\n1:31:33.900 --> 1:31:35.020\n in terms of books.\n\n1:31:35.020 --> 1:31:36.980\n Of course, you're an author of many books.\n\n1:31:36.980 --> 1:31:38.780\n So I'll, in the introduction,\n\n1:31:38.780 --> 1:31:40.300\n mention all the books you've written.\n\n1:31:40.300 --> 1:31:42.500\n People should definitely read LiveWired.\n\n1:31:42.500 --> 1:31:44.820\n I've gotten a chance to read some of it and it's amazing.\n\n1:31:44.820 --> 1:31:48.300\n But is there three books, technical, fiction,\n\n1:31:48.300 --> 1:31:52.100\n philosophical that had an impact on you\n\n1:31:52.100 --> 1:31:56.380\n when you were younger or today and books,\n\n1:31:56.380 --> 1:31:59.580\n perhaps some of which you would want to recommend\n\n1:31:59.580 --> 1:32:00.500\n that others read?\n\n1:32:01.380 --> 1:32:02.460\n You know, as an undergraduate,\n\n1:32:02.460 --> 1:32:04.140\n I majored in British and American literature.\n\n1:32:04.140 --> 1:32:06.780\n That was my major because I love literature.\n\n1:32:06.780 --> 1:32:08.660\n I grew up with literature.\n\n1:32:08.660 --> 1:32:10.500\n My father had these extensive bookshelves.\n\n1:32:10.500 --> 1:32:13.860\n And so I grew up in the mountains in New Mexico.\n\n1:32:13.860 --> 1:32:16.100\n And so that was mostly why I spent my time was reading books.\n\n1:32:16.100 --> 1:32:21.100\n But, you know, I love, you know, Faulkner, Hemingway.\n\n1:32:23.660 --> 1:32:26.100\n I love many South American authors,\n\n1:32:26.100 --> 1:32:28.220\n Gabriel Garcia Marquez and Italo Calvino.\n\n1:32:28.220 --> 1:32:29.860\n I would actually recommend Invisible Cities.\n\n1:32:29.860 --> 1:32:33.140\n I just, I loved that book by Italo Calvino.\n\n1:32:33.140 --> 1:32:34.660\n Sorry, it's a book of fiction.\n\n1:32:37.020 --> 1:32:39.100\n Anthony Dorr wrote a book called\n\n1:32:39.100 --> 1:32:41.020\n All the Light We Cannot See,\n\n1:32:41.020 --> 1:32:44.140\n which actually was inspired by incognito,\n\n1:32:44.140 --> 1:32:45.940\n by exactly what we were talking about earlier\n\n1:32:45.940 --> 1:32:48.740\n about how you can only see a little bit of the,\n\n1:32:48.740 --> 1:32:51.460\n what we call visible light in the electromagnetic radiation.\n\n1:32:51.460 --> 1:32:52.780\n I wrote about this in incognito,\n\n1:32:52.780 --> 1:32:54.780\n and then he reviewed incognito for the Washington Post.\n\n1:32:54.780 --> 1:32:56.020\n Oh no, that's awesome.\n\n1:32:56.020 --> 1:32:57.580\n And then he wrote this book called,\n\n1:32:57.580 --> 1:32:58.700\n the book has nothing to do with that,\n\n1:32:58.700 --> 1:33:00.860\n but that's where the title comes from.\n\n1:33:00.860 --> 1:33:01.700\n All the Light We Cannot See\n\n1:33:01.700 --> 1:33:02.940\n is about the rest of the spectrum.\n\n1:33:02.940 --> 1:33:07.940\n But the, that's an absolutely gorgeous book.\n\n1:33:08.340 --> 1:33:09.420\n That's a book of fiction.\n\n1:33:09.420 --> 1:33:10.500\n Yeah, it's a book of fiction.\n\n1:33:10.500 --> 1:33:12.620\n What's it about?\n\n1:33:12.620 --> 1:33:14.340\n It takes place during World War II\n\n1:33:14.340 --> 1:33:15.420\n about these two young people,\n\n1:33:15.420 --> 1:33:18.260\n one of whom is blind and yeah.\n\n1:33:18.260 --> 1:33:19.820\n Anything else?\n\n1:33:19.820 --> 1:33:21.940\n So what, any, so you mentioned Hemingway?\n\n1:33:21.940 --> 1:33:22.780\n I mean.\n\n1:33:22.780 --> 1:33:26.500\n Old Man and the Sea, what's your favorite?\n\n1:33:27.860 --> 1:33:29.380\n Snow's a Kilimanjaro.\n\n1:33:29.380 --> 1:33:30.220\n Oh wow, okay.\n\n1:33:30.220 --> 1:33:31.660\n It's a collection of short stories that I love.\n\n1:33:31.660 --> 1:33:33.300\n As far as nonfiction goes,\n\n1:33:33.300 --> 1:33:35.780\n I grew up with Cosmos,\n\n1:33:35.780 --> 1:33:38.180\n both watching the PBS series and then reading the book,\n\n1:33:38.180 --> 1:33:41.260\n and that influenced me a huge amount in terms of what I do.\n\n1:33:41.260 --> 1:33:42.980\n I, from the time I was a kid,\n\n1:33:42.980 --> 1:33:44.940\n I felt like I want to be Carl Sagan.\n\n1:33:44.940 --> 1:33:46.140\n Like, I just, that's what I loved.\n\n1:33:46.140 --> 1:33:47.940\n And in the end, I just, you know,\n\n1:33:47.940 --> 1:33:50.980\n I studied space physics for a while as an undergrad,\n\n1:33:50.980 --> 1:33:53.560\n but then I, in my last semester,\n\n1:33:53.560 --> 1:33:55.460\n discovered neuroscience last semester,\n\n1:33:55.460 --> 1:33:57.540\n and I just thought, wow, I'm hooked on that.\n\n1:33:57.540 --> 1:33:59.580\n So the Carl Sagan of the brain.\n\n1:34:01.420 --> 1:34:02.260\n That was my aspiration.\n\n1:34:02.260 --> 1:34:03.700\n Is the aspiration.\n\n1:34:03.700 --> 1:34:07.900\n I mean, you're doing an incredible job of it.\n\n1:34:07.900 --> 1:34:11.900\n So you open the book live wide with a quote by Heidegger.\n\n1:34:11.900 --> 1:34:15.540\n Every man is born as many men and dies as a single one.\n\n1:34:17.700 --> 1:34:20.020\n Well, what do you mean, or what?\n\n1:34:20.020 --> 1:34:21.620\n I'll tell you what I meant by it.\n\n1:34:21.620 --> 1:34:23.740\n So he had his own reason why he was writing that,\n\n1:34:23.740 --> 1:34:25.740\n but I meant this in terms of brain plasticity,\n\n1:34:25.740 --> 1:34:26.860\n in terms of the library,\n\n1:34:26.860 --> 1:34:28.500\n which is this issue that I mentioned before\n\n1:34:28.500 --> 1:34:29.900\n about this, you know, this cone,\n\n1:34:29.900 --> 1:34:31.780\n the space time cone that we are in,\n\n1:34:31.780 --> 1:34:35.740\n which is that when you dropped into the world,\n\n1:34:35.740 --> 1:34:37.900\n you, Lex, had all this different potential.\n\n1:34:37.900 --> 1:34:40.400\n You could have been a great surfer\n\n1:34:40.400 --> 1:34:42.260\n or a great chess player or a,\n\n1:34:42.260 --> 1:34:45.460\n you could have been thousands of different men\n\n1:34:45.460 --> 1:34:46.460\n when you grew up,\n\n1:34:46.460 --> 1:34:49.300\n but what you did is things that were not your choice\n\n1:34:49.300 --> 1:34:50.620\n and your choice along the way.\n\n1:34:50.620 --> 1:34:52.760\n You know, you ended up navigating a particular path\n\n1:34:52.760 --> 1:34:54.140\n and now you're exactly who you are.\n\n1:34:54.140 --> 1:34:55.300\n You used to have lots of potential,\n\n1:34:55.300 --> 1:34:59.100\n but the day you die, you will be exactly Lex.\n\n1:34:59.100 --> 1:35:01.580\n You will be that one person, yeah.\n\n1:35:01.580 --> 1:35:03.580\n So on that, in that context,\n\n1:35:03.580 --> 1:35:06.580\n I mean, first of all, it's just a beautiful,\n\n1:35:06.580 --> 1:35:09.940\n it's a humbling picture, but it's a beautiful one\n\n1:35:09.940 --> 1:35:12.700\n because it's all the possible trajectories\n\n1:35:12.700 --> 1:35:14.540\n and you pick one and you walk down that road\n\n1:35:14.540 --> 1:35:16.260\n and it's the Robert Frost poem.\n\n1:35:16.260 --> 1:35:18.860\n But on that topic, let me ask the biggest\n\n1:35:18.860 --> 1:35:20.500\n and the most ridiculous question.\n\n1:35:21.380 --> 1:35:23.300\n So in this live, wide brain,\n\n1:35:23.300 --> 1:35:25.100\n when we choose all these different trajectories\n\n1:35:25.100 --> 1:35:27.940\n and end up with one, what's the meaning of it all?\n\n1:35:27.940 --> 1:35:32.180\n What's, is there a why here?\n\n1:35:32.180 --> 1:35:34.100\n What's the meaning of life?\n\n1:35:34.100 --> 1:35:34.940\n Yeah.\n\n1:35:34.940 --> 1:35:36.380\n David Engelman.\n\n1:35:36.380 --> 1:35:37.220\n That's it.\n\n1:35:37.220 --> 1:35:42.220\n I mean, this is the question that everyone has attacked\n\n1:35:42.940 --> 1:35:45.300\n from their own life or point of view,\n\n1:35:45.300 --> 1:35:47.300\n by which I mean, culturally,\n\n1:35:47.300 --> 1:35:49.180\n if you grew up in a religious society,\n\n1:35:49.180 --> 1:35:51.100\n you have one way of attacking that question.\n\n1:35:51.100 --> 1:35:53.300\n So if you grew up in a secular or scientific society,\n\n1:35:53.300 --> 1:35:55.460\n you have a different way of attacking that question.\n\n1:35:55.460 --> 1:35:59.660\n Obviously, I don't know, I abstain on that question.\n\n1:35:59.660 --> 1:36:00.860\n Yeah.\n\n1:36:00.860 --> 1:36:03.340\n I mean, I think one of the fundamental things,\n\n1:36:03.340 --> 1:36:06.260\n I guess, in that, in all those possible trajectories\n\n1:36:06.260 --> 1:36:09.260\n is you're always asking.\n\n1:36:09.260 --> 1:36:11.540\n I mean, that's the act of asking\n\n1:36:11.540 --> 1:36:14.220\n what the heck is this thing for,\n\n1:36:14.220 --> 1:36:18.460\n is equivalent to, or at least runs in parallel\n\n1:36:18.460 --> 1:36:20.860\n to all the choices that you're making.\n\n1:36:20.860 --> 1:36:23.700\n Cause it's kind of, that's the underlying question.\n\n1:36:23.700 --> 1:36:24.540\n Well, that's right.\n\n1:36:24.540 --> 1:36:25.500\n And by the way, you know,\n\n1:36:25.500 --> 1:36:27.820\n this is the interesting thing about human psychology.\n\n1:36:27.820 --> 1:36:29.460\n You know, we've got all these layers of things\n\n1:36:29.460 --> 1:36:30.900\n at which we can ask questions.\n\n1:36:30.900 --> 1:36:33.740\n And so if you keep asking yourself the question about,\n\n1:36:33.740 --> 1:36:36.500\n what is the optimal way for me to be spending my time?\n\n1:36:36.500 --> 1:36:37.340\n What should I be doing?\n\n1:36:37.340 --> 1:36:39.060\n What charity should I get involved with and so on?\n\n1:36:39.060 --> 1:36:41.340\n If you're asking those big questions\n\n1:36:42.500 --> 1:36:44.740\n that steers you appropriately,\n\n1:36:44.740 --> 1:36:46.540\n if you're the type of person who never asks,\n\n1:36:46.540 --> 1:36:48.900\n hey, is there something better I can be doing with my time,\n\n1:36:48.900 --> 1:36:51.060\n then presumably you won't optimize\n\n1:36:51.060 --> 1:36:53.740\n whatever it is that is important to you.\n\n1:36:53.740 --> 1:36:58.060\n So you've, I think just in your eyes, in your work,\n\n1:36:58.060 --> 1:37:03.060\n there's a passion that just is obvious and it's inspiring.\n\n1:37:03.060 --> 1:37:04.380\n It's contagious.\n\n1:37:04.380 --> 1:37:09.180\n What, if you were to give advice to us,\n\n1:37:09.180 --> 1:37:10.700\n a young person today,\n\n1:37:10.700 --> 1:37:14.660\n in the crazy chaos that we live today about life,\n\n1:37:14.660 --> 1:37:19.660\n about how to discover their passion,\n\n1:37:20.820 --> 1:37:23.220\n is there some words that you could give?\n\n1:37:24.620 --> 1:37:26.220\n First of all, I would say the main thing\n\n1:37:26.220 --> 1:37:29.500\n for a young person is stay adaptable.\n\n1:37:29.500 --> 1:37:31.980\n And this is back to this issue of why COVID\n\n1:37:31.980 --> 1:37:35.420\n is useful for us because it forces us off our tracks.\n\n1:37:35.420 --> 1:37:39.020\n The fact is the jobs that will exist 20 years from now,\n\n1:37:39.020 --> 1:37:40.100\n we don't even have names for it.\n\n1:37:40.100 --> 1:37:42.540\n We can't even imagine the jobs that are gonna exist.\n\n1:37:42.540 --> 1:37:44.980\n And so when young people that I know go into college\n\n1:37:44.980 --> 1:37:47.460\n and they say, hey, what should I major in and so on,\n\n1:37:47.460 --> 1:37:50.660\n college is and should be less and less vocational,\n\n1:37:50.660 --> 1:37:52.300\n as in, oh, I'm gonna learn how to do this\n\n1:37:52.300 --> 1:37:54.100\n and then I'm gonna do that the rest of my career.\n\n1:37:54.100 --> 1:37:55.620\n The world just isn't that way anymore\n\n1:37:55.620 --> 1:37:57.820\n with the exponential speed of things.\n\n1:37:57.820 --> 1:38:00.460\n So the important thing is learning how to learn,\n\n1:38:00.460 --> 1:38:03.540\n learning how to be livewired and adaptable.\n\n1:38:03.540 --> 1:38:04.580\n That's really key.\n\n1:38:04.580 --> 1:38:07.740\n And what I advise young people when I talk to them is,\n\n1:38:09.540 --> 1:38:13.660\n what you digest, that's what gives you the raw storehouse\n\n1:38:13.660 --> 1:38:17.380\n of things that you can remix and be creative with.\n\n1:38:17.380 --> 1:38:21.220\n And so eat broadly and widely.\n\n1:38:21.220 --> 1:38:23.020\n And obviously this is the wonderful thing\n\n1:38:23.020 --> 1:38:24.620\n about the internet world we live in now\n\n1:38:24.620 --> 1:38:25.580\n is you kind of can't help it.\n\n1:38:25.580 --> 1:38:27.140\n You're constantly, whoa.\n\n1:38:27.140 --> 1:38:28.900\n You go down some mole hole of Wikipedia\n\n1:38:28.900 --> 1:38:31.140\n and you think, oh, I didn't even realize that was a thing.\n\n1:38:31.140 --> 1:38:32.540\n I didn't know that existed.\n\n1:38:32.540 --> 1:38:33.740\n And so.\n\n1:38:33.740 --> 1:38:34.580\n Embrace that.\n\n1:38:34.580 --> 1:38:36.220\n Embrace that, yeah, exactly.\n\n1:38:36.220 --> 1:38:39.900\n And what I tell people is just always do a gut check\n\n1:38:39.900 --> 1:38:41.500\n about, okay, I'm reading this paper\n\n1:38:41.500 --> 1:38:44.260\n and yeah, I think that, but this paper, wow,\n\n1:38:44.260 --> 1:38:47.700\n that really, I really cared about that in some way.\n\n1:38:47.700 --> 1:38:50.500\n I tell them just to keep a real sniff out for that.\n\n1:38:50.500 --> 1:38:54.020\n And when you find those things, keep going down those paths.\n\n1:38:54.020 --> 1:38:55.020\n Yeah, don't be afraid.\n\n1:38:55.020 --> 1:38:58.260\n I mean, that's one of the challenges and the downsides\n\n1:38:58.260 --> 1:39:00.060\n of having so many beautiful options\n\n1:39:00.060 --> 1:39:02.860\n is that sometimes people are a little bit afraid\n\n1:39:02.860 --> 1:39:05.620\n to really commit, but that's very true.\n\n1:39:05.620 --> 1:39:09.140\n If there's something that just sparks your interest\n\n1:39:09.140 --> 1:39:10.860\n and passion, just run with it.\n\n1:39:10.860 --> 1:39:13.420\n I mean, that's, it goes back to the Haider quote.\n\n1:39:14.500 --> 1:39:16.220\n I mean, we only get this one life\n\n1:39:16.220 --> 1:39:20.140\n and that trajectory, it doesn't last forever.\n\n1:39:20.140 --> 1:39:23.540\n So just if something sparks your imagination,\n\n1:39:23.540 --> 1:39:24.940\n your passion is run with it.\n\n1:39:24.940 --> 1:39:26.380\n Yeah, exactly.\n\n1:39:26.380 --> 1:39:29.940\n I don't think there's a more beautiful way to end it.\n\n1:39:29.940 --> 1:39:32.620\n David, it's a huge honor to finally meet you.\n\n1:39:32.620 --> 1:39:34.860\n Your work is inspiring so many people.\n\n1:39:34.860 --> 1:39:36.340\n I've talked to so many people who are passionate\n\n1:39:36.340 --> 1:39:39.220\n about neuroscience, about the brain, even outside\n\n1:39:39.220 --> 1:39:40.900\n that read your book.\n\n1:39:40.900 --> 1:39:43.700\n So I hope you keep doing so.\n\n1:39:43.700 --> 1:39:46.100\n I think you're already there with Carl Sagan.\n\n1:39:46.100 --> 1:39:47.460\n I hope you continue growing.\n\n1:39:48.340 --> 1:39:50.060\n Yeah, it was an honor talking with you today.\n\n1:39:50.060 --> 1:39:50.900\n Thanks so much.\n\n1:39:50.900 --> 1:39:52.220\n Great, you too, Lex, wonderful.\n\n1:39:53.380 --> 1:39:54.900\n Thanks for listening to this conversation\n\n1:39:54.900 --> 1:39:58.100\n with David Eagleman, and thank you to our sponsors,\n\n1:39:58.100 --> 1:40:01.500\n Athletic Greens, BetterHelp, and Cash App.\n\n1:40:01.500 --> 1:40:03.860\n Click the sponsor links in the description\n\n1:40:03.860 --> 1:40:07.340\n to get a discount and to support this podcast.\n\n1:40:07.340 --> 1:40:09.620\n If you enjoy this thing, subscribe on YouTube,\n\n1:40:09.620 --> 1:40:11.860\n review it with Five Stars on Apple Podcast,\n\n1:40:11.860 --> 1:40:14.660\n follow on Spotify, support on Patreon,\n\n1:40:14.660 --> 1:40:18.380\n or connect with me on Twitter at Lex Friedman.\n\n1:40:18.380 --> 1:40:20.100\n And now let me leave you with some words\n\n1:40:20.100 --> 1:40:21.620\n from David Eagleman in his book,\n\n1:40:21.620 --> 1:40:25.020\n Some Forty Tales from the Afterlives.\n\n1:40:25.020 --> 1:40:28.020\n Imagine for a moment there were nothing but\n\n1:40:28.020 --> 1:40:30.380\n the product of billions of years of molecules\n\n1:40:30.380 --> 1:40:35.020\n coming together and ratcheting up through natural selection.\n\n1:40:35.020 --> 1:40:37.380\n There were composed only of highways of fluids\n\n1:40:37.380 --> 1:40:39.940\n and chemicals sliding along roadways\n\n1:40:39.940 --> 1:40:42.540\n within billions of dancing cells.\n\n1:40:42.540 --> 1:40:46.140\n The trillions of synaptic connections hum in parallel\n\n1:40:46.140 --> 1:40:50.220\n that this vast egg like fabric of micro thin circuitry\n\n1:40:50.220 --> 1:40:54.300\n runs algorithms undreamt of in modern science,\n\n1:40:54.300 --> 1:40:56.660\n and that these neural programs give rise to\n\n1:40:56.660 --> 1:41:01.660\n our decision making, loves, desires, fears, and aspirations.\n\n1:41:02.900 --> 1:41:07.540\n To me, understanding this would be a numinous experience,\n\n1:41:07.540 --> 1:41:11.940\n better than anything ever proposed in any holy text.\n\n1:41:11.940 --> 1:41:23.940\n Thank you for listening and hope to see you next time.\n\n"
}
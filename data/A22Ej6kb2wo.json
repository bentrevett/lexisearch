{
  "title": "Russ Tedrake: Underactuated Robotics, Control, Dynamics and Touch | Lex Fridman Podcast #114",
  "id": "A22Ej6kb2wo",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:03.000\n The following is a conversation with Russ Tedrick,\n\n00:03.000 --> 00:05.560\n a roboticist and professor at MIT\n\n00:05.560 --> 00:07.880\n and vice president of robotics research\n\n00:07.880 --> 00:11.240\n at Toyota Research Institute or TRI.\n\n00:11.240 --> 00:15.160\n He works on control of robots in interesting,\n\n00:15.160 --> 00:18.000\n complicated, underactuated, stochastic,\n\n00:18.000 --> 00:19.960\n difficult to model situations.\n\n00:19.960 --> 00:22.640\n He's a great teacher and a great person,\n\n00:22.640 --> 00:25.040\n one of my favorites at MIT.\n\n00:25.040 --> 00:28.280\n We'll get into a lot of topics in this conversation\n\n00:28.280 --> 00:32.760\n from his time leading MIT's Delta Robotics Challenge team\n\n00:32.760 --> 00:35.400\n to the awesome fact that he often runs\n\n00:35.400 --> 00:40.400\n close to a marathon a day to and from work barefoot.\n\n00:40.480 --> 00:43.400\n For a world class roboticist interested in elegant,\n\n00:43.400 --> 00:46.920\n efficient control of underactuated dynamical systems\n\n00:46.920 --> 00:50.840\n like the human body, this fact makes Russ\n\n00:50.840 --> 00:53.180\n one of the most fascinating people I know.\n\n00:54.480 --> 00:55.780\n Quick summary of the ads.\n\n00:55.780 --> 00:59.220\n Three sponsors, Magic Spoon Cereal, BetterHelp,\n\n00:59.220 --> 01:00.760\n and ExpressVPN.\n\n01:00.760 --> 01:02.620\n Please consider supporting this podcast\n\n01:02.620 --> 01:05.680\n by going to magicspoon.com slash lex\n\n01:05.680 --> 01:07.960\n and using code lex at checkout,\n\n01:07.960 --> 01:10.480\n going to betterhelp.com slash lex\n\n01:10.480 --> 01:14.640\n and signing up at expressvpn.com slash lexpod.\n\n01:14.640 --> 01:16.480\n Click the links in the description,\n\n01:16.480 --> 01:18.800\n buy the stuff, get the discount.\n\n01:18.800 --> 01:21.800\n It really is the best way to support this podcast.\n\n01:21.800 --> 01:24.000\n If you enjoy this thing, subscribe on YouTube,\n\n01:24.000 --> 01:26.240\n review it with five stars on Apple Podcast,\n\n01:26.240 --> 01:28.280\n support it on Patreon, or connect with me\n\n01:28.280 --> 01:31.280\n on Twitter at lexfreedman.\n\n01:31.280 --> 01:33.640\n As usual, I'll do a few minutes of ads now\n\n01:33.640 --> 01:34.880\n and never any ads in the middle\n\n01:34.880 --> 01:37.880\n that can break the flow of the conversation.\n\n01:37.880 --> 01:40.880\n This episode is supported by Magic Spoon,\n\n01:40.880 --> 01:43.460\n low carb keto friendly cereal.\n\n01:43.460 --> 01:45.800\n I've been on a mix of keto or carnivore diet\n\n01:45.800 --> 01:47.320\n for a very long time now.\n\n01:47.320 --> 01:50.520\n That means eating very little carbs.\n\n01:50.520 --> 01:52.200\n I used to love cereal.\n\n01:52.200 --> 01:54.960\n Obviously, most have crazy amounts of sugar,\n\n01:54.960 --> 01:58.000\n which is terrible for you, so I quit years ago,\n\n01:58.000 --> 02:00.420\n but Magic Spoon is a totally new thing.\n\n02:00.420 --> 02:03.000\n Zero sugar, 11 grams of protein,\n\n02:03.000 --> 02:05.720\n and only three net grams of carbs.\n\n02:05.720 --> 02:07.240\n It tastes delicious.\n\n02:07.240 --> 02:09.660\n It has a bunch of flavors, they're all good,\n\n02:09.660 --> 02:11.200\n but if you know what's good for you,\n\n02:11.200 --> 02:13.940\n you'll go with cocoa, my favorite flavor\n\n02:13.940 --> 02:15.820\n and the flavor of champions.\n\n02:15.820 --> 02:19.460\n Click the magicspoon.com slash lex link in the description,\n\n02:19.460 --> 02:22.160\n use code lex at checkout to get the discount\n\n02:22.160 --> 02:24.400\n and to let them know I sent you.\n\n02:24.400 --> 02:26.680\n So buy all of their cereal.\n\n02:26.680 --> 02:28.640\n It's delicious and good for you.\n\n02:28.640 --> 02:29.640\n You won't regret it.\n\n02:30.560 --> 02:33.160\n This show is also sponsored by BetterHelp,\n\n02:33.160 --> 02:36.040\n spelled H E L P Help.\n\n02:36.040 --> 02:39.440\n Check it out at betterhelp.com slash lex.\n\n02:39.440 --> 02:40.600\n They figure out what you need\n\n02:40.600 --> 02:43.240\n and match you with a licensed professional therapist\n\n02:43.240 --> 02:44.960\n in under 48 hours.\n\n02:44.960 --> 02:47.640\n It's not a crisis line, it's not self help,\n\n02:47.640 --> 02:51.040\n it is professional counseling done securely online.\n\n02:51.040 --> 02:53.720\n As you may know, I'm a bit from the David Goggins line\n\n02:53.720 --> 02:57.080\n of creatures and still have some demons to contend with,\n\n02:57.080 --> 03:01.580\n usually on long runs or all nighters full of self doubt.\n\n03:01.580 --> 03:04.360\n I think suffering is essential for creation,\n\n03:04.360 --> 03:06.040\n but you can suffer beautifully\n\n03:06.040 --> 03:08.200\n in a way that doesn't destroy you.\n\n03:08.200 --> 03:11.540\n For most people, I think a good therapist can help in this.\n\n03:11.540 --> 03:13.400\n So it's at least worth a try.\n\n03:13.400 --> 03:15.620\n Check out the reviews, they're all good.\n\n03:15.620 --> 03:19.220\n It's easy, private, affordable, available worldwide.\n\n03:19.220 --> 03:21.640\n You can communicate by text anytime\n\n03:21.640 --> 03:25.080\n and schedule weekly audio and video sessions.\n\n03:25.080 --> 03:28.500\n Check it out at betterhelp.com slash lex.\n\n03:28.500 --> 03:31.840\n This show is also sponsored by ExpressVPN.\n\n03:31.840 --> 03:34.860\n Get it at expressvpn.com slash lex pod\n\n03:34.860 --> 03:37.680\n to get a discount and to support this podcast.\n\n03:37.680 --> 03:39.680\n Have you ever watched The Office?\n\n03:39.680 --> 03:41.900\n If you have, you probably know it's based\n\n03:41.900 --> 03:45.120\n on a UK series also called The Office.\n\n03:45.120 --> 03:48.080\n Not to stir up trouble, but I personally think\n\n03:48.080 --> 03:50.320\n the British version is actually more brilliant\n\n03:50.320 --> 03:53.120\n than the American one, but both are amazing.\n\n03:53.120 --> 03:56.120\n Anyway, there are actually nine other countries\n\n03:56.120 --> 03:58.400\n with their own version of The Office.\n\n03:58.400 --> 04:01.180\n You can get access to them with no geo restriction\n\n04:01.180 --> 04:03.600\n when you use ExpressVPN.\n\n04:03.600 --> 04:05.560\n It lets you control where you want sites\n\n04:05.560 --> 04:07.340\n to think you're located.\n\n04:07.340 --> 04:10.360\n You can choose from nearly 100 different countries,\n\n04:10.360 --> 04:12.120\n giving you access to content\n\n04:12.120 --> 04:14.020\n that isn't available in your region.\n\n04:14.020 --> 04:19.020\n So again, get it on any device at expressvpn.com slash lex pod\n\n04:19.800 --> 04:22.080\n to get an extra three months free\n\n04:22.080 --> 04:25.000\n and to support this podcast.\n\n04:25.000 --> 04:28.640\n And now here's my conversation with Russ Tedrick.\n\n04:29.560 --> 04:31.480\n What is the most beautiful motion\n\n04:31.480 --> 04:34.420\n of an animal or robot that you've ever seen?\n\n04:36.160 --> 04:38.280\n I think the most beautiful motion of a robot\n\n04:38.280 --> 04:41.120\n has to be the passive dynamic walkers.\n\n04:41.120 --> 04:43.320\n I think there's just something fundamentally beautiful.\n\n04:43.320 --> 04:45.360\n The ones in particular that Steve Collins built\n\n04:45.360 --> 04:50.360\n with Andy Ruina at Cornell, a 3D walking machine.\n\n04:50.520 --> 04:53.720\n So it was not confined to a boom or a plane\n\n04:54.680 --> 04:57.460\n that you put it on top of a small ramp,\n\n04:57.460 --> 05:00.500\n give it a little push, it's powered only by gravity.\n\n05:00.500 --> 05:04.320\n No controllers, no batteries whatsoever.\n\n05:04.320 --> 05:06.160\n It just falls down the ramp.\n\n05:06.160 --> 05:09.520\n And at the time it looked more natural, more graceful,\n\n05:09.520 --> 05:13.460\n more human like than any robot we'd seen to date\n\n05:13.460 --> 05:15.240\n powered only by gravity.\n\n05:15.240 --> 05:16.160\n How does it work?\n\n05:17.160 --> 05:19.480\n Well, okay, the simplest model, it's kind of like a slinky.\n\n05:19.480 --> 05:21.560\n It's like an elaborate slinky.\n\n05:21.560 --> 05:23.840\n One of the simplest models we used to think about it\n\n05:23.840 --> 05:25.360\n is actually a rimless wheel.\n\n05:25.360 --> 05:30.100\n So imagine taking a bicycle wheel, but take the rim off.\n\n05:30.100 --> 05:32.640\n So it's now just got a bunch of spokes.\n\n05:32.640 --> 05:33.720\n If you give that a push,\n\n05:33.720 --> 05:35.840\n it still wants to roll down the ramp,\n\n05:35.840 --> 05:38.180\n but every time its foot, its spoke comes around\n\n05:38.180 --> 05:40.680\n and hits the ground, it loses a little energy.\n\n05:41.880 --> 05:43.280\n Every time it takes a step forward,\n\n05:43.280 --> 05:44.580\n it gains a little energy.\n\n05:45.800 --> 05:48.200\n Those things can come into perfect balance.\n\n05:48.200 --> 05:51.240\n And actually they want to, it's a stable phenomenon.\n\n05:51.240 --> 05:53.720\n If it's going too slow, it'll speed up.\n\n05:53.720 --> 05:55.880\n If it's going too fast, it'll slow down\n\n05:55.880 --> 05:58.180\n and it comes into a stable periodic motion.\n\n05:59.480 --> 06:02.120\n Now you can take that rimless wheel,\n\n06:02.120 --> 06:05.040\n which doesn't look very much like a human walking,\n\n06:05.040 --> 06:08.080\n take all the extra spokes away, put a hinge in the middle.\n\n06:08.080 --> 06:09.720\n Now it's two legs.\n\n06:09.720 --> 06:11.880\n That's called our compass gait walker.\n\n06:11.880 --> 06:13.800\n That can still, you give it a little push,\n\n06:13.800 --> 06:15.520\n it starts falling down a ramp.\n\n06:15.520 --> 06:17.240\n It looks a little bit more like walking.\n\n06:17.240 --> 06:18.360\n At least it's a biped.\n\n06:19.700 --> 06:21.400\n But what Steve and Andy,\n\n06:21.400 --> 06:23.480\n and Tad McGeer started the whole exercise,\n\n06:23.480 --> 06:25.200\n but what Steve and Andy did was they took it\n\n06:25.200 --> 06:27.460\n to this beautiful conclusion\n\n06:28.700 --> 06:32.440\n where they built something that had knees, arms, a torso.\n\n06:32.440 --> 06:36.320\n The arms swung naturally, give it a little push.\n\n06:36.320 --> 06:38.720\n And that looked like a stroll through the park.\n\n06:38.720 --> 06:40.240\n How do you design something like that?\n\n06:40.240 --> 06:42.360\n I mean, is that art or science?\n\n06:42.360 --> 06:43.800\n It's on the boundary.\n\n06:43.800 --> 06:47.640\n I think there's a science to getting close to the solution.\n\n06:47.640 --> 06:49.040\n I think there's certainly art in the way\n\n06:49.040 --> 06:52.000\n that they made a beautiful robot.\n\n06:52.000 --> 06:57.000\n But then the finesse, because they were working\n\n06:57.080 --> 06:58.980\n with a system that wasn't perfectly modeled,\n\n06:58.980 --> 07:01.060\n wasn't perfectly controlled,\n\n07:01.060 --> 07:02.800\n there's all these little tricks\n\n07:02.800 --> 07:05.480\n that you have to tune the suction cups at the knees,\n\n07:05.480 --> 07:07.960\n for instance, so that they stick,\n\n07:07.960 --> 07:09.640\n but then they release at just the right time.\n\n07:09.640 --> 07:12.360\n Or there's all these little tricks of the trade,\n\n07:12.360 --> 07:14.440\n which really are art, but it was a point.\n\n07:14.440 --> 07:16.200\n I mean, it made the point.\n\n07:16.200 --> 07:18.800\n We were, at that time, the walking robot,\n\n07:18.800 --> 07:21.840\n the best walking robot in the world was Honda's Asmo.\n\n07:21.840 --> 07:24.120\n Absolutely marvel of modern engineering.\n\n07:24.120 --> 07:25.240\n Is this 90s?\n\n07:25.240 --> 07:27.440\n This was in 97 when they first released.\n\n07:27.440 --> 07:29.920\n It sort of announced P2, and then it went through.\n\n07:29.920 --> 07:32.360\n It was Asmo by then in 2004.\n\n07:32.360 --> 07:37.360\n And it looks like this very cautious walking,\n\n07:37.840 --> 07:41.320\n like you're walking on hot coals or something like that.\n\n07:41.320 --> 07:43.760\n I think it gets a bad rap.\n\n07:43.760 --> 07:45.340\n Asmo is a beautiful machine.\n\n07:45.340 --> 07:47.000\n It does walk with its knees bent.\n\n07:47.000 --> 07:49.740\n Our Atlas walking had its knees bent.\n\n07:49.740 --> 07:52.340\n But actually, Asmo was pretty fantastic.\n\n07:52.340 --> 07:54.320\n But it wasn't energy efficient.\n\n07:54.320 --> 07:56.660\n Neither was Atlas when we worked on Atlas.\n\n07:58.220 --> 08:00.520\n None of our robots that have been that complicated\n\n08:00.520 --> 08:02.480\n have been very energy efficient.\n\n08:04.040 --> 08:09.040\n But there's a thing that happens when you do control,\n\n08:09.680 --> 08:12.480\n when you try to control a system of that complexity.\n\n08:12.480 --> 08:16.480\n You try to use your motors to basically counteract gravity.\n\n08:17.360 --> 08:20.680\n Take whatever the world's doing to you and push back,\n\n08:20.680 --> 08:23.520\n erase the dynamics of the world,\n\n08:23.520 --> 08:25.040\n and impose the dynamics you want\n\n08:25.040 --> 08:28.220\n because you can make them simple and analyzable,\n\n08:28.220 --> 08:30.760\n mathematically simple.\n\n08:30.760 --> 08:34.400\n And this was a very sort of beautiful example\n\n08:34.400 --> 08:36.380\n that you don't have to do that.\n\n08:36.380 --> 08:37.480\n You can just let go.\n\n08:37.480 --> 08:40.280\n Let physics do most of the work, right?\n\n08:40.280 --> 08:42.200\n And you just have to give it a little bit of energy.\n\n08:42.200 --> 08:43.560\n This one only walked down a ramp.\n\n08:43.560 --> 08:45.340\n It would never walk on the flat.\n\n08:45.340 --> 08:46.180\n To walk on the flat,\n\n08:46.180 --> 08:48.480\n you have to give a little energy at some point.\n\n08:48.480 --> 08:51.960\n But maybe instead of trying to take the forces imparted\n\n08:51.960 --> 08:55.200\n to you by the world and replacing them,\n\n08:55.200 --> 08:58.200\n what we should be doing is letting the world push us around\n\n08:58.200 --> 08:59.360\n and we go with the flow.\n\n08:59.360 --> 09:01.280\n Very zen, very zen robot.\n\n09:01.280 --> 09:03.440\n Yeah, but okay, so that sounds very zen,\n\n09:03.440 --> 09:08.440\n but I can also imagine how many like failed versions\n\n09:10.220 --> 09:11.640\n they had to go through.\n\n09:11.640 --> 09:14.040\n Like how many, like, I would say it's probably,\n\n09:14.040 --> 09:15.320\n would you say it's in the thousands\n\n09:15.320 --> 09:17.920\n that they've had to have the system fall down\n\n09:17.920 --> 09:19.840\n before they figured out how to get it?\n\n09:19.840 --> 09:22.560\n I don't know if it's thousands, but it's a lot.\n\n09:22.560 --> 09:23.560\n It takes some patience.\n\n09:23.560 --> 09:25.040\n There's no question.\n\n09:25.040 --> 09:28.320\n So in that sense, control might help a little bit.\n\n09:28.320 --> 09:32.100\n Oh, I think everybody, even at the time,\n\n09:32.100 --> 09:35.020\n said that the answer is to do with that with control.\n\n09:35.020 --> 09:36.340\n But it was just pointing out\n\n09:36.340 --> 09:39.120\n that maybe the way we're doing control right now\n\n09:39.120 --> 09:41.040\n isn't the way we should.\n\n09:41.040 --> 09:41.880\n Got it.\n\n09:41.880 --> 09:43.800\n So what about on the animal side,\n\n09:43.800 --> 09:46.200\n the ones that figured out how to move efficiently?\n\n09:46.200 --> 09:49.440\n Is there anything you find inspiring or beautiful\n\n09:49.440 --> 09:51.160\n in the movement of any particular animal?\n\n09:51.160 --> 09:51.980\n I do have a favorite example.\n\n09:51.980 --> 09:52.820\n Okay.\n\n09:52.820 --> 09:57.160\n So it sort of goes with the passive walking idea.\n\n09:57.160 --> 10:01.400\n So is there, you know, how energy efficient are animals?\n\n10:01.400 --> 10:03.840\n Okay, there's a great series of experiments\n\n10:03.840 --> 10:07.520\n by George Lauder at Harvard and Mike Tranofilo at MIT.\n\n10:07.520 --> 10:10.640\n They were studying fish swimming in a water tunnel.\n\n10:10.640 --> 10:11.820\n Okay.\n\n10:11.820 --> 10:15.240\n And one of these, the type of fish they were studying\n\n10:15.240 --> 10:17.240\n were these rainbow trout,\n\n10:17.240 --> 10:20.360\n because there was a phenomenon well understood\n\n10:20.360 --> 10:22.180\n that rainbow trout, when they're swimming upstream\n\n10:22.180 --> 10:25.120\n in mating season, they kind of hang out behind the rocks.\n\n10:25.120 --> 10:26.080\n And it looks like, I mean,\n\n10:26.080 --> 10:28.080\n that's tiring work swimming upstream.\n\n10:28.080 --> 10:29.180\n They're hanging out behind the rocks.\n\n10:29.180 --> 10:31.980\n Maybe there's something energetically interesting there.\n\n10:31.980 --> 10:33.400\n So they tried to recreate that.\n\n10:33.400 --> 10:36.440\n They put in this water tunnel, a rock basically,\n\n10:36.440 --> 10:40.560\n a cylinder that had the same sort of vortex street,\n\n10:40.560 --> 10:42.480\n the eddies coming off the back of the rock\n\n10:42.480 --> 10:44.240\n that you would see in a stream.\n\n10:44.240 --> 10:46.080\n And they put a real fish behind this\n\n10:46.080 --> 10:48.000\n and watched how it swims.\n\n10:48.000 --> 10:51.960\n And the amazing thing is that if you watch from above\n\n10:51.960 --> 10:53.800\n what the fish swims when it's not behind a rock,\n\n10:53.800 --> 10:56.120\n it has a particular gate.\n\n10:56.120 --> 10:58.240\n You can identify the fish the same way you look\n\n10:58.240 --> 10:59.840\n at a human walking down the street.\n\n10:59.840 --> 11:02.420\n You sort of have a sense of how a human walks.\n\n11:02.420 --> 11:04.120\n The fish has a characteristic gate.\n\n11:05.360 --> 11:07.920\n You put that fish behind the rock, its gate changes.\n\n11:09.160 --> 11:12.720\n And what they saw was that it was actually resonating\n\n11:12.720 --> 11:15.160\n and kind of surfing between the vortices.\n\n11:16.560 --> 11:20.140\n Now, here was the experiment that really was the clincher.\n\n11:20.140 --> 11:22.160\n Because there was still, it wasn't clear how much of that\n\n11:22.160 --> 11:24.000\n was mechanics of the fish,\n\n11:24.000 --> 11:26.940\n how much of that is control, the brain.\n\n11:26.940 --> 11:28.480\n So the clincher experiment,\n\n11:28.480 --> 11:29.800\n and maybe one of my favorites to date,\n\n11:29.800 --> 11:32.020\n although there are many good experiments.\n\n11:33.700 --> 11:37.060\n They took, this was now a dead fish.\n\n11:38.380 --> 11:40.200\n They took a dead fish.\n\n11:40.200 --> 11:41.640\n They put a string that went,\n\n11:41.640 --> 11:44.160\n that tied the mouth of the fish to the rock\n\n11:44.160 --> 11:47.160\n so it couldn't go back and get caught in the grates.\n\n11:47.160 --> 11:49.180\n And then they asked what would that dead fish do\n\n11:49.180 --> 11:51.160\n when it was hanging out behind the rock?\n\n11:51.160 --> 11:52.920\n And so what you'd expect, it sort of flopped around\n\n11:52.920 --> 11:56.120\n like a dead fish in the vortex wake\n\n11:56.120 --> 11:57.800\n until something sort of amazing happens.\n\n11:57.800 --> 12:02.800\n And this video is worth putting in, right?\n\n12:02.880 --> 12:04.040\n What happens?\n\n12:04.040 --> 12:07.520\n The dead fish basically starts swimming upstream, right?\n\n12:07.520 --> 12:12.160\n It's completely dead, no brain, no motors, no control.\n\n12:12.160 --> 12:14.600\n But it's somehow the mechanics of the fish\n\n12:14.600 --> 12:16.360\n resonate with the vortex street\n\n12:16.360 --> 12:18.280\n and it starts swimming upstream.\n\n12:18.280 --> 12:20.520\n It's one of the best examples ever.\n\n12:20.520 --> 12:23.740\n Who do you give credit for that to?\n\n12:23.740 --> 12:27.980\n Is that just evolution constantly just figuring out\n\n12:27.980 --> 12:30.920\n by killing a lot of generations of animals,\n\n12:30.920 --> 12:33.360\n like the most efficient motion?\n\n12:33.360 --> 12:38.360\n Is that, or maybe the physics of our world completely like,\n\n12:38.660 --> 12:40.920\n is like if evolution applied not only to animals,\n\n12:40.920 --> 12:45.220\n but just the entirety of it somehow drives to efficiency,\n\n12:45.220 --> 12:47.020\n like nature likes efficiency?\n\n12:47.020 --> 12:49.980\n I don't know if that question even makes any sense.\n\n12:49.980 --> 12:51.020\n I understand the question.\n\n12:51.020 --> 12:51.860\n That's reasonable.\n\n12:51.860 --> 12:54.460\n I mean, do they co evolve?\n\n12:54.460 --> 12:55.620\n Yeah, somehow co, yeah.\n\n12:55.620 --> 12:59.020\n Like I don't know if an environment can evolve, but.\n\n13:00.020 --> 13:02.340\n I mean, there are experiments that people do,\n\n13:02.340 --> 13:05.940\n careful experiments that show that animals can adapt\n\n13:05.940 --> 13:08.660\n to unusual situations and recover efficiency.\n\n13:08.660 --> 13:11.100\n So there seems like at least in one direction,\n\n13:11.100 --> 13:12.740\n I think there is reason to believe\n\n13:12.740 --> 13:17.100\n that the animal's motor system and probably its mechanics\n\n13:18.100 --> 13:20.060\n adapt in order to be more efficient.\n\n13:20.060 --> 13:23.140\n But efficiency isn't the only goal, of course.\n\n13:23.140 --> 13:26.220\n Sometimes it's too easy to think about only efficiency,\n\n13:26.220 --> 13:30.540\n but we have to do a lot of other things first, not get eaten.\n\n13:30.540 --> 13:34.140\n And then all other things being equal, try to save energy.\n\n13:34.140 --> 13:36.100\n By the way, let's draw a distinction\n\n13:36.100 --> 13:38.160\n between control and mechanics.\n\n13:38.160 --> 13:40.820\n Like how would you define each?\n\n13:40.820 --> 13:41.720\n Yeah.\n\n13:41.720 --> 13:43.940\n I mean, I think part of the point is that\n\n13:43.940 --> 13:47.860\n we shouldn't draw a line as clearly as we tend to.\n\n13:47.860 --> 13:51.460\n But on a robot, we have motors\n\n13:51.460 --> 13:54.840\n and we have the links of the robot, let's say.\n\n13:54.840 --> 13:56.260\n If the motors are turned off,\n\n13:56.260 --> 13:59.780\n the robot has some passive dynamics, okay?\n\n13:59.780 --> 14:01.380\n Gravity does the work.\n\n14:01.380 --> 14:03.700\n You can put springs, I would call that mechanics, right?\n\n14:03.700 --> 14:04.940\n If we have springs and dampers,\n\n14:04.940 --> 14:08.540\n which our muscles are springs and dampers and tendons.\n\n14:08.540 --> 14:10.440\n But then you have something that's doing active work,\n\n14:10.440 --> 14:13.240\n putting energy in, which are your motors on the robot.\n\n14:13.240 --> 14:16.580\n The controller's job is to send commands to the motor\n\n14:16.580 --> 14:19.960\n that add new energy into the system, right?\n\n14:19.960 --> 14:22.820\n So the mechanics and control interplay somewhere,\n\n14:22.820 --> 14:24.820\n the divide is around, you know,\n\n14:24.820 --> 14:27.560\n did you decide to send some commands to your motor\n\n14:27.560 --> 14:28.980\n or did you just leave the motors off,\n\n14:28.980 --> 14:30.580\n let them do their work?\n\n14:30.580 --> 14:33.900\n Would you say is most of nature\n\n14:35.140 --> 14:39.820\n on the dynamic side or the control side?\n\n14:39.820 --> 14:42.260\n So like, if you look at biological systems,\n\n14:43.580 --> 14:45.100\n we're living in a pandemic now,\n\n14:45.100 --> 14:46.700\n like, do you think a virus is a,\n\n14:47.840 --> 14:50.100\n do you think it's a dynamic system\n\n14:50.100 --> 14:54.100\n or is there a lot of control, intelligence?\n\n14:54.100 --> 14:57.040\n I think it's both, but I think we maybe have underestimated\n\n14:57.040 --> 14:59.700\n how important the dynamics are, right?\n\n15:02.020 --> 15:04.300\n I mean, even our bodies, the mechanics of our bodies,\n\n15:04.300 --> 15:06.140\n certainly with exercise, they evolve.\n\n15:06.140 --> 15:11.060\n But so I actually, I lost a finger in early 2000s\n\n15:11.060 --> 15:14.460\n and it's my fifth metacarpal.\n\n15:14.460 --> 15:16.620\n And it turns out you use that a lot\n\n15:16.620 --> 15:19.340\n in ways you don't expect when you're opening jars,\n\n15:19.340 --> 15:20.620\n even when I'm just walking around,\n\n15:20.620 --> 15:23.220\n if I bump it on something, there's a bone there\n\n15:23.220 --> 15:26.780\n that was used to taking contact.\n\n15:26.780 --> 15:28.820\n My fourth metacarpal wasn't used to taking contact,\n\n15:28.820 --> 15:31.100\n it used to hurt, it still does a little bit.\n\n15:31.100 --> 15:34.180\n But actually my bone has remodeled, right?\n\n15:34.180 --> 15:39.180\n Over a couple of years, the geometry,\n\n15:39.580 --> 15:42.100\n the mechanics of that bone changed\n\n15:42.100 --> 15:44.340\n to address the new circumstances.\n\n15:44.340 --> 15:46.820\n So the idea that somehow it's only our brain\n\n15:46.820 --> 15:48.980\n that's adapting or evolving is not right.\n\n15:50.140 --> 15:52.560\n Maybe sticking on evolution for a bit,\n\n15:52.560 --> 15:56.720\n because it's tended to create some interesting things.\n\n15:56.720 --> 16:01.720\n Bipedal walking, why the heck did evolution give us,\n\n16:01.720 --> 16:05.040\n I think we're, are we the only mammals that walk on two feet?\n\n16:05.040 --> 16:09.040\n No, I mean, there's a bunch of animals that do it a bit.\n\n16:09.040 --> 16:09.880\n A bit.\n\n16:09.880 --> 16:12.280\n I think we are the most successful bipeds.\n\n16:12.280 --> 16:17.280\n I think I read somewhere that the reason\n\n16:17.760 --> 16:22.760\n the evolution made us walk on two feet\n\n16:22.760 --> 16:24.720\n is because there's an advantage\n\n16:24.720 --> 16:27.200\n to being able to carry food back to the tribe\n\n16:27.200 --> 16:28.040\n or something like that.\n\n16:28.040 --> 16:31.960\n So like you can carry, it's kind of this communal,\n\n16:31.960 --> 16:35.080\n cooperative thing, so like to carry stuff back\n\n16:35.080 --> 16:40.080\n to a place of shelter and so on to share with others.\n\n16:40.080 --> 16:44.520\n Do you understand at all the value of walking on two feet\n\n16:44.520 --> 16:48.000\n from both a robotics and a human perspective?\n\n16:48.000 --> 16:50.280\n Yeah, there are some great books written\n\n16:50.280 --> 16:54.560\n about evolution of, walking evolution of the human body.\n\n16:54.560 --> 16:59.560\n I think it's easy though to make bad evolutionary arguments.\n\n17:00.600 --> 17:03.740\n Sure, most of them are probably bad,\n\n17:03.740 --> 17:05.320\n but what else can we do?\n\n17:06.200 --> 17:11.120\n I mean, I think a lot of what dominated our evolution\n\n17:11.120 --> 17:15.080\n probably was not the things that worked well\n\n17:15.080 --> 17:18.560\n sort of in the steady state, you know,\n\n17:18.560 --> 17:22.800\n when things are good, but for instance,\n\n17:22.800 --> 17:25.040\n people talk about what we should eat now\n\n17:25.040 --> 17:28.320\n because our ancestors were meat eaters or whatever.\n\n17:28.320 --> 17:30.240\n Oh yeah, I love that, yeah.\n\n17:30.240 --> 17:32.520\n But probably, you know, the reason\n\n17:32.520 --> 17:37.520\n that one pre Homo sapiens species versus another survived\n\n17:39.640 --> 17:43.440\n was not because of whether they ate well\n\n17:43.440 --> 17:45.300\n when there was lots of food.\n\n17:45.300 --> 17:47.920\n But when the ice age came, you know,\n\n17:47.920 --> 17:50.940\n probably one of them happened to be in the wrong place.\n\n17:50.940 --> 17:54.200\n One of them happened to forage a food that was okay\n\n17:54.200 --> 17:58.240\n even when the glaciers came or something like that, I mean.\n\n17:58.240 --> 18:00.560\n There's a million variables that contributed\n\n18:00.560 --> 18:04.080\n and we can't, and our, actually the amount of information\n\n18:04.080 --> 18:06.680\n we're working with and telling these stories,\n\n18:06.680 --> 18:10.220\n these evolutionary stories is very little.\n\n18:10.220 --> 18:13.080\n So yeah, just like you said, it seems like,\n\n18:13.080 --> 18:15.680\n if you study history, it seems like history turns\n\n18:15.680 --> 18:20.280\n on like these little events that otherwise\n\n18:20.280 --> 18:23.320\n would seem meaningless, but in a grant,\n\n18:23.320 --> 18:27.560\n like when you, in retrospect, were turning points.\n\n18:27.560 --> 18:28.400\n Absolutely.\n\n18:28.400 --> 18:31.280\n And that's probably how like somebody got hit in the head\n\n18:31.280 --> 18:35.160\n with a rock because somebody slept with the wrong person\n\n18:35.160 --> 18:38.500\n back in the cave days and somebody get angry\n\n18:38.500 --> 18:41.920\n and that turned, you know, warring tribes\n\n18:41.920 --> 18:45.360\n combined with the environment, all those millions of things\n\n18:45.360 --> 18:47.680\n and the meat eating, which I get a lot of criticism\n\n18:47.680 --> 18:51.480\n because I don't know what your dietary processes are like,\n\n18:51.480 --> 18:55.040\n but these days I've been eating only meat,\n\n18:55.040 --> 18:59.080\n which is, there's a large community of people who say,\n\n18:59.080 --> 19:01.080\n yeah, probably make evolutionary arguments\n\n19:01.080 --> 19:02.720\n and say you're doing a great job.\n\n19:02.720 --> 19:05.760\n There's probably an even larger community of people,\n\n19:05.760 --> 19:08.520\n including my mom, who says it's deeply unhealthy,\n\n19:08.520 --> 19:10.760\n it's wrong, but I just feel good doing it.\n\n19:10.760 --> 19:12.980\n But you're right, these evolutionary arguments\n\n19:12.980 --> 19:15.420\n can be flawed, but is there anything interesting\n\n19:15.420 --> 19:17.320\n to pull out for?\n\n19:17.320 --> 19:19.360\n There's a great book, by the way,\n\n19:19.360 --> 19:21.280\n well, a series of books by Nicholas Taleb\n\n19:21.280 --> 19:23.840\n about Fooled by Randomness and Black Swan.\n\n19:24.800 --> 19:26.840\n Highly recommend them, but yeah,\n\n19:26.840 --> 19:29.160\n they make the point nicely that probably\n\n19:29.160 --> 19:34.160\n it was a few random events that, yes,\n\n19:34.360 --> 19:37.280\n maybe it was someone getting hit by a rock, as you say.\n\n19:39.520 --> 19:42.700\n That said, do you think, I don't know how to ask this\n\n19:42.700 --> 19:44.080\n question or how to talk about this,\n\n19:44.080 --> 19:45.680\n but there's something elegant and beautiful\n\n19:45.680 --> 19:48.800\n about moving on two feet, obviously biased\n\n19:48.800 --> 19:53.280\n because I'm human, but from a robotics perspective, too,\n\n19:53.280 --> 19:55.440\n you work with robots on two feet,\n\n19:56.440 --> 20:00.120\n is it all useful to build robots that are on two feet\n\n20:00.120 --> 20:01.120\n as opposed to four?\n\n20:01.120 --> 20:02.320\n Is there something useful about it?\n\n20:02.320 --> 20:05.540\n I think the most, I mean, the reason I spent a long time\n\n20:05.540 --> 20:09.000\n working on bipedal walking was because it was hard\n\n20:09.000 --> 20:12.480\n and it challenged control theory in ways\n\n20:12.480 --> 20:13.920\n that I thought were important.\n\n20:13.920 --> 20:18.520\n I wouldn't have ever tried to convince you\n\n20:18.520 --> 20:22.440\n that you should start a company around bipeds\n\n20:22.440 --> 20:24.240\n or something like this.\n\n20:24.240 --> 20:26.120\n There are people that make pretty compelling arguments.\n\n20:26.120 --> 20:28.920\n I think the most compelling one is that the world\n\n20:28.920 --> 20:32.320\n is built for the human form, and if you want a robot\n\n20:32.320 --> 20:34.800\n to work in the world we have today,\n\n20:34.800 --> 20:38.020\n then having a human form is a pretty good way to go.\n\n20:39.680 --> 20:42.560\n There are places that a biped can go that would be hard\n\n20:42.560 --> 20:47.560\n for other form factors to go, even natural places,\n\n20:47.640 --> 20:51.360\n but at some point in the long run,\n\n20:51.360 --> 20:54.220\n we'll be building our environments for our robots, probably,\n\n20:54.220 --> 20:56.480\n and so maybe that argument falls aside.\n\n20:56.480 --> 20:58.760\n So you famously run barefoot.\n\n21:00.640 --> 21:02.120\n Do you still run barefoot?\n\n21:02.120 --> 21:03.080\n I still run barefoot.\n\n21:03.080 --> 21:04.760\n That's so awesome.\n\n21:04.760 --> 21:06.320\n Much to my wife's chagrin.\n\n21:07.800 --> 21:09.320\n Do you want to make an evolutionary argument\n\n21:09.320 --> 21:12.680\n for why running barefoot is advantageous?\n\n21:12.680 --> 21:17.560\n What have you learned about human and robot movement\n\n21:17.560 --> 21:19.840\n in general from running barefoot?\n\n21:21.160 --> 21:23.640\n Human or robot and or?\n\n21:23.640 --> 21:25.640\n Well, you know, it happened the other way, right?\n\n21:25.640 --> 21:27.680\n So I was studying walking robots,\n\n21:27.680 --> 21:31.760\n and there's a great conference called\n\n21:31.760 --> 21:35.320\n the Dynamic Walking Conference where it brings together\n\n21:35.320 --> 21:36.980\n both the biomechanics community\n\n21:36.980 --> 21:39.880\n and the walking robots community.\n\n21:39.880 --> 21:41.660\n And so I had been going to this for years\n\n21:41.660 --> 21:45.080\n and hearing talks by people who study barefoot running\n\n21:45.080 --> 21:46.920\n and other, the mechanics of running.\n\n21:48.080 --> 21:50.280\n So I did eventually read Born to Run.\n\n21:50.280 --> 21:52.820\n Most people read Born to Run in the first, right?\n\n21:54.080 --> 21:55.720\n The other thing I had going for me is actually\n\n21:55.720 --> 21:58.800\n that I wasn't a runner before,\n\n21:58.800 --> 22:01.560\n and I learned to run after I had learned\n\n22:01.560 --> 22:03.640\n about barefoot running, or I mean,\n\n22:03.640 --> 22:05.440\n started running longer distances.\n\n22:05.440 --> 22:07.360\n So I didn't have to unlearn.\n\n22:07.360 --> 22:11.080\n And I'm definitely, I'm a big fan of it for me,\n\n22:11.080 --> 22:12.360\n but I'm not going to,\n\n22:12.360 --> 22:14.600\n I tend to not try to convince other people.\n\n22:14.600 --> 22:17.240\n There's people who run beautifully with shoes on,\n\n22:17.240 --> 22:18.300\n and that's good.\n\n22:20.040 --> 22:21.880\n But here's why it makes sense for me.\n\n22:24.040 --> 22:26.360\n It's all about the longterm game, right?\n\n22:26.360 --> 22:29.440\n So I think it's just too easy to run 10 miles,\n\n22:29.440 --> 22:31.560\n feel pretty good, and then you get home at night\n\n22:31.560 --> 22:33.840\n and you realize my knees hurt.\n\n22:33.840 --> 22:35.480\n I did something wrong, right?\n\n22:37.880 --> 22:39.780\n If you take your shoes off,\n\n22:39.780 --> 22:43.040\n then if you hit hard with your foot at all,\n\n22:44.080 --> 22:45.720\n then it hurts.\n\n22:45.720 --> 22:47.560\n You don't like run 10 miles\n\n22:47.560 --> 22:50.800\n and then realize you've done some damage.\n\n22:50.800 --> 22:52.940\n You have immediate feedback telling you\n\n22:52.940 --> 22:55.420\n that you've done something that's maybe suboptimal,\n\n22:55.420 --> 22:56.520\n and you change your gait.\n\n22:56.520 --> 22:57.720\n I mean, it's even subconscious.\n\n22:57.720 --> 23:00.640\n If I, right now, having run many miles barefoot,\n\n23:00.640 --> 23:03.160\n if I put a shoe on, my gait changes\n\n23:03.160 --> 23:04.960\n in a way that I think is not as good.\n\n23:05.840 --> 23:09.520\n So it makes me land softer.\n\n23:09.520 --> 23:13.160\n And I think my goals for running\n\n23:13.160 --> 23:16.860\n are to do it for as long as I can into old age,\n\n23:16.860 --> 23:19.000\n not to win any races.\n\n23:19.000 --> 23:23.420\n And so for me, this is a way to protect myself.\n\n23:23.420 --> 23:25.680\n Yeah, I think, first of all,\n\n23:25.680 --> 23:29.540\n I've tried running barefoot many years ago,\n\n23:29.540 --> 23:30.480\n probably the other way,\n\n23:30.480 --> 23:33.920\n just reading Born to Run.\n\n23:33.920 --> 23:36.440\n But just to understand,\n\n23:36.440 --> 23:39.520\n because I felt like I couldn't put in the miles\n\n23:39.520 --> 23:40.840\n that I wanted to.\n\n23:40.840 --> 23:44.260\n And it feels like running for me,\n\n23:44.260 --> 23:46.280\n and I think for a lot of people,\n\n23:46.280 --> 23:48.880\n was one of those activities that we do often\n\n23:48.880 --> 23:52.140\n and we never really try to learn to do correctly.\n\n23:53.340 --> 23:55.920\n Like, it's funny, there's so many activities\n\n23:55.920 --> 24:00.280\n we do every day, like brushing our teeth, right?\n\n24:00.280 --> 24:02.360\n I think a lot of us, at least me,\n\n24:02.360 --> 24:04.320\n probably have never deeply studied\n\n24:04.320 --> 24:07.040\n how to properly brush my teeth, right?\n\n24:07.040 --> 24:08.960\n Or wash, as now with the pandemic,\n\n24:08.960 --> 24:10.640\n or how to properly wash our hands.\n\n24:10.640 --> 24:13.800\n We do it every day, but we haven't really studied,\n\n24:13.800 --> 24:15.200\n like, am I doing this correctly?\n\n24:15.200 --> 24:17.120\n But running felt like one of those things,\n\n24:17.120 --> 24:20.220\n it was absurd not to study how to do correctly,\n\n24:20.220 --> 24:23.320\n because it's the source of so much pain and suffering.\n\n24:23.320 --> 24:25.680\n Like, I hate running, but I do it.\n\n24:25.680 --> 24:28.940\n I do it because I hate it, but I feel good afterwards.\n\n24:28.940 --> 24:30.280\n But I think it feels like you need\n\n24:30.280 --> 24:31.440\n to learn how to do it properly.\n\n24:31.440 --> 24:33.540\n So that's where barefoot running came in,\n\n24:33.540 --> 24:35.760\n and then I quickly realized that my gait\n\n24:35.760 --> 24:38.040\n was completely wrong.\n\n24:38.040 --> 24:41.440\n I was taking huge steps,\n\n24:41.440 --> 24:45.840\n and landing hard on the heel, all those elements.\n\n24:45.840 --> 24:47.600\n And so, yeah, from that I actually learned\n\n24:47.600 --> 24:49.540\n to take really small steps, look.\n\n24:50.520 --> 24:52.280\n I already forgot the number,\n\n24:52.280 --> 24:55.600\n but I feel like it was 180 a minute or something like that.\n\n24:55.600 --> 25:00.080\n And I remember I actually just took songs\n\n25:00.080 --> 25:03.360\n that are 180 beats per minute,\n\n25:03.360 --> 25:05.500\n and then like tried to run at that beat,\n\n25:06.520 --> 25:07.660\n and just to teach myself.\n\n25:07.660 --> 25:11.120\n It took a long time, and I feel like after a while,\n\n25:11.120 --> 25:14.320\n you learn to run, you adjust properly,\n\n25:14.320 --> 25:15.960\n without going all the way to barefoot.\n\n25:15.960 --> 25:19.440\n But I feel like barefoot is the legit way to do it.\n\n25:19.440 --> 25:21.640\n I mean, I think a lot of people\n\n25:21.640 --> 25:23.360\n would be really curious about it.\n\n25:23.360 --> 25:25.560\n Can you, if they're interested in trying,\n\n25:25.560 --> 25:27.840\n what would you, how would you recommend\n\n25:27.840 --> 25:30.740\n they start, or try, or explore?\n\n25:30.740 --> 25:31.580\n Slowly.\n\n25:31.580 --> 25:33.720\n That's the biggest thing people do,\n\n25:33.720 --> 25:35.920\n is they are excellent runners,\n\n25:35.920 --> 25:37.620\n and they're used to running long distances,\n\n25:37.620 --> 25:39.240\n or running fast, and they take their shoes off,\n\n25:39.240 --> 25:42.520\n and they hurt themselves instantly trying to do\n\n25:42.520 --> 25:44.280\n something that they were used to doing.\n\n25:44.280 --> 25:46.000\n I think I lucked out in the sense\n\n25:46.000 --> 25:50.200\n that I couldn't run very far when I first started trying.\n\n25:50.200 --> 25:51.840\n And I run with minimal shoes too.\n\n25:51.840 --> 25:54.360\n I mean, I will bring along a pair of,\n\n25:54.360 --> 25:56.320\n actually, like aqua socks or something like this,\n\n25:56.320 --> 25:58.320\n I can just slip on, or running sandals,\n\n25:58.320 --> 26:00.360\n I've tried all of them.\n\n26:00.360 --> 26:02.600\n What's the difference between a minimal shoe\n\n26:02.600 --> 26:03.760\n and nothing at all?\n\n26:03.760 --> 26:07.020\n What's, like, feeling wise, what does it feel like?\n\n26:07.020 --> 26:10.000\n There is a, I mean, I notice my gait changing, right?\n\n26:10.000 --> 26:15.000\n So, I mean, your foot has as many muscles\n\n26:15.080 --> 26:17.600\n and sensors as your hand does, right?\n\n26:17.600 --> 26:19.960\n Sensors, ooh, okay.\n\n26:19.960 --> 26:23.200\n And we do amazing things with our hands.\n\n26:23.200 --> 26:26.000\n And we stick our foot in a big, solid shoe, right?\n\n26:26.000 --> 26:29.640\n So there's, I think, you know, when you're barefoot,\n\n26:29.640 --> 26:33.240\n you're just giving yourself more proprioception.\n\n26:33.240 --> 26:35.720\n And that's why you're more aware of some of the gait flaws\n\n26:35.720 --> 26:37.080\n and stuff like this.\n\n26:37.080 --> 26:39.840\n Now, you have less protection too, so.\n\n26:40.720 --> 26:42.400\n Rocks and stuff.\n\n26:42.400 --> 26:45.160\n I mean, yeah, so I think people who are afraid\n\n26:45.160 --> 26:47.160\n of barefoot running are worried about getting cuts\n\n26:47.160 --> 26:48.460\n or stepping on rocks.\n\n26:49.800 --> 26:51.560\n First of all, even if that was a concern,\n\n26:51.560 --> 26:54.240\n I think those are all, like, very short term.\n\n26:54.240 --> 26:55.420\n You know, if I get a scratch or something,\n\n26:55.420 --> 26:56.520\n it'll heal in a week.\n\n26:56.520 --> 26:58.240\n If I blow out my knees, I'm done running forever.\n\n26:58.240 --> 27:01.720\n So I will trade the short term for the long term anytime.\n\n27:01.720 --> 27:04.760\n But even then, you know, and this, again,\n\n27:04.760 --> 27:07.760\n to my wife's chagrin, your feet get tough, right?\n\n27:07.760 --> 27:11.480\n And, yeah, I can run over almost anything now.\n\n27:13.760 --> 27:17.240\n I mean, what, can you talk about,\n\n27:17.240 --> 27:21.940\n is there, like, is there tips or tricks\n\n27:21.940 --> 27:24.820\n that you have, suggestions about,\n\n27:24.820 --> 27:26.620\n like, if I wanted to try it?\n\n27:26.620 --> 27:29.580\n You know, there is a good book, actually.\n\n27:29.580 --> 27:32.700\n There's probably more good books since I read them.\n\n27:32.700 --> 27:35.680\n But Ken Bob, Barefoot Ken Bob Saxton.\n\n27:37.340 --> 27:38.820\n He's an interesting guy.\n\n27:38.820 --> 27:42.620\n But I think his book captures the right way\n\n27:42.620 --> 27:44.180\n to describe running, barefoot running,\n\n27:44.180 --> 27:48.580\n to somebody better than any other I've seen.\n\n27:48.580 --> 27:52.540\n So you run pretty good distances, and you bike,\n\n27:52.540 --> 27:57.540\n and is there, you know, if we talk about bucket list items,\n\n27:57.820 --> 28:00.220\n is there something crazy on your bucket list,\n\n28:00.220 --> 28:02.780\n athletically, that you hope to do one day?\n\n28:04.620 --> 28:07.180\n I mean, my commute is already a little crazy.\n\n28:07.180 --> 28:09.020\n What are we talking about here?\n\n28:09.020 --> 28:11.420\n What distance are we talking about?\n\n28:11.420 --> 28:14.680\n Well, I live about 12 miles from MIT,\n\n28:14.680 --> 28:16.620\n but you can find lots of different ways to get there.\n\n28:16.620 --> 28:20.540\n So, I mean, I've run there for many years, I've biked there.\n\n28:20.540 --> 28:21.460\n Old ways?\n\n28:21.460 --> 28:23.900\n Yeah, but normally I would try to run in\n\n28:23.900 --> 28:25.980\n and then bike home, bike in, run home.\n\n28:25.980 --> 28:28.140\n But you have run there and back before?\n\n28:28.140 --> 28:28.980\n Sure.\n\n28:28.980 --> 28:29.820\n Barefoot?\n\n28:29.820 --> 28:32.260\n Yeah, or with minimal shoes or whatever that.\n\n28:32.260 --> 28:34.340\n 12, 12 times two?\n\n28:34.340 --> 28:35.180\n Yeah.\n\n28:35.180 --> 28:36.020\n Okay.\n\n28:36.020 --> 28:38.500\n It became kind of a game of how can I get to work?\n\n28:38.500 --> 28:41.020\n I've rollerbladed, I've done all kinds of weird stuff,\n\n28:41.020 --> 28:42.700\n but my favorite one these days,\n\n28:42.700 --> 28:45.060\n I've been taking the Charles River to work.\n\n28:45.060 --> 28:50.060\n So, I can put in the rowboat not so far from my house,\n\n28:50.740 --> 28:53.300\n but the Charles River takes a long way to get to MIT,\n\n28:53.300 --> 28:56.380\n so I can spend a long time getting there.\n\n28:56.380 --> 28:59.640\n And it's not about, I don't know, it's just about,\n\n29:01.620 --> 29:02.560\n I've had people ask me,\n\n29:02.560 --> 29:04.460\n how can you justify taking that time?\n\n29:05.820 --> 29:10.140\n But for me, it's just a magical time to think,\n\n29:10.140 --> 29:12.320\n to compress, decompress.\n\n29:13.740 --> 29:16.220\n Especially, I'll wake up, do a lot of work in the morning,\n\n29:16.220 --> 29:19.180\n and then I kind of have to just let that settle\n\n29:19.180 --> 29:20.700\n before I'm ready for all my meetings.\n\n29:20.700 --> 29:23.160\n And then on the way home, it's a great time to sort of\n\n29:23.160 --> 29:24.580\n let that settle.\n\n29:24.580 --> 29:29.220\n You lead a large group of people.\n\n29:31.860 --> 29:33.980\n Is there days where you're like,\n\n29:33.980 --> 29:36.620\n oh shit, I gotta get to work in an hour?\n\n29:36.620 --> 29:41.620\n Like, I mean, is there a tension there?\n\n29:45.420 --> 29:47.940\n And like, if we look at the grand scheme of things,\n\n29:47.940 --> 29:49.500\n just like you said, long term,\n\n29:49.500 --> 29:51.700\n that meeting probably doesn't matter.\n\n29:51.700 --> 29:54.660\n Like, you can always say, I'll just, I'll run\n\n29:54.660 --> 29:57.100\n and let the meeting happen, how it happens.\n\n29:57.100 --> 30:02.100\n Like, what, how do you, that zen, how do you,\n\n30:02.200 --> 30:03.580\n what do you do with that tension\n\n30:03.580 --> 30:05.620\n between the real world saying urgently,\n\n30:05.620 --> 30:08.220\n you need to be there, this is important,\n\n30:08.220 --> 30:10.060\n everything is melting down,\n\n30:10.060 --> 30:11.820\n how are we gonna fix this robot?\n\n30:11.820 --> 30:14.660\n There's this critical meeting,\n\n30:14.660 --> 30:18.020\n and then there's this, the zen beauty of just running,\n\n30:18.020 --> 30:20.420\n the simplicity of it, you along with nature.\n\n30:21.380 --> 30:22.700\n What do you do with that?\n\n30:22.700 --> 30:25.540\n I would say I'm not a fast runner, particularly.\n\n30:25.540 --> 30:27.940\n Probably my fastest splits ever was when\n\n30:27.940 --> 30:29.220\n I had to get to daycare on time\n\n30:29.220 --> 30:30.700\n because they were gonna charge me, you know,\n\n30:30.700 --> 30:33.540\n some dollar per minute that I was late.\n\n30:33.540 --> 30:35.940\n I've run some fast splits to daycare.\n\n30:36.980 --> 30:39.800\n But those times are past now.\n\n30:41.700 --> 30:44.900\n I think work, you can find a work life balance in that way.\n\n30:44.900 --> 30:46.100\n I think you just have to.\n\n30:47.260 --> 30:48.620\n I think I am better at work\n\n30:48.620 --> 30:52.180\n because I take time to think on the way in.\n\n30:52.180 --> 30:54.380\n So I plan my day around it,\n\n30:55.300 --> 31:00.300\n and I rarely feel that those are really at odds.\n\n31:00.300 --> 31:03.380\n So what, the bucket list item.\n\n31:03.380 --> 31:08.380\n If we're talking 12 times two, or approaching a marathon,\n\n31:10.620 --> 31:15.060\n what, have you run an ultra marathon before?\n\n31:15.060 --> 31:16.740\n Do you do races?\n\n31:16.740 --> 31:17.580\n Is there, what's a...\n\n31:17.580 --> 31:18.740\n Not to win.\n\n31:21.620 --> 31:23.720\n I'm not gonna like take a dinghy across the Atlantic\n\n31:23.720 --> 31:24.780\n or something if that's what you want.\n\n31:24.780 --> 31:27.920\n But if someone does and wants to write a book,\n\n31:27.920 --> 31:28.760\n I would totally read it\n\n31:28.760 --> 31:31.140\n because I'm a sucker for that kind of thing.\n\n31:31.140 --> 31:33.420\n No, I do have some fun things that I will try.\n\n31:33.420 --> 31:35.300\n You know, I like to, when I travel,\n\n31:35.300 --> 31:37.020\n I almost always bike to Logan Airport\n\n31:37.020 --> 31:38.740\n and fold up a little folding bike\n\n31:38.740 --> 31:41.040\n and then take it with me and bike to wherever I'm going.\n\n31:41.040 --> 31:42.420\n And it's taken me,\n\n31:42.420 --> 31:44.580\n or I'll take a stand up paddle board these days\n\n31:44.580 --> 31:45.500\n on the airplane,\n\n31:45.500 --> 31:47.100\n and then I'll try to paddle around where I'm going\n\n31:47.100 --> 31:47.940\n or whatever.\n\n31:47.940 --> 31:50.720\n And I've done some crazy things, but...\n\n31:50.720 --> 31:55.140\n But not for the, you know, I now talk,\n\n31:55.140 --> 31:57.500\n I don't know if you know who David Goggins is by any chance.\n\n31:57.500 --> 31:58.460\n Not well, but yeah.\n\n31:58.460 --> 32:00.140\n But I talk to him now every day.\n\n32:00.140 --> 32:05.140\n So he's the person who made me do this stupid challenge.\n\n32:05.940 --> 32:10.160\n So he's insane and he does things for the purpose\n\n32:10.160 --> 32:11.380\n in the best kind of way.\n\n32:11.380 --> 32:16.380\n He does things like for the explicit purpose of suffering.\n\n32:16.980 --> 32:18.420\n Like he picks the thing that,\n\n32:18.420 --> 32:21.500\n like whatever he thinks he can do, he does more.\n\n32:22.940 --> 32:27.300\n So is that, do you have that thing in you or are you...\n\n32:27.300 --> 32:28.940\n I think it's become the opposite.\n\n32:29.820 --> 32:30.660\n It's a...\n\n32:30.660 --> 32:32.300\n So you're like that dynamical system\n\n32:32.300 --> 32:34.420\n that the walker, the efficient...\n\n32:34.420 --> 32:37.880\n Yeah, it's leave no pain, right?\n\n32:38.860 --> 32:40.900\n You should end feeling better than you started.\n\n32:40.900 --> 32:41.720\n Okay.\n\n32:41.720 --> 32:45.940\n But it's mostly, I think, and COVID has tested this\n\n32:45.940 --> 32:47.740\n because I've lost my commute.\n\n32:47.740 --> 32:51.980\n I think I'm perfectly happy walking around town\n\n32:51.980 --> 32:55.220\n with my wife and kids if they could get them to go.\n\n32:55.220 --> 32:57.780\n And it's more about just getting outside\n\n32:57.780 --> 32:59.980\n and getting away from the keyboard for some time\n\n32:59.980 --> 33:01.380\n just to let things compress.\n\n33:02.580 --> 33:04.100\n Let's go into robotics a little bit.\n\n33:04.100 --> 33:06.760\n What to use the most beautiful idea in robotics?\n\n33:07.800 --> 33:09.660\n Whether we're talking about control\n\n33:10.780 --> 33:12.740\n or whether we're talking about optimization\n\n33:12.740 --> 33:16.180\n and the math side of things or the engineering side of things\n\n33:16.180 --> 33:18.160\n or the philosophical side of things.\n\n33:20.380 --> 33:23.540\n I think I've been lucky to experience something\n\n33:23.540 --> 33:27.700\n that not so many roboticists have experienced,\n\n33:27.700 --> 33:30.220\n which is to hang out\n\n33:30.220 --> 33:33.540\n with some really amazing control theorists.\n\n33:34.420 --> 33:39.420\n And the clarity of thought\n\n33:40.700 --> 33:43.140\n that some of the more mathematical control theory\n\n33:43.140 --> 33:47.500\n can bring to even very complex, messy looking problems\n\n33:49.480 --> 33:53.140\n is really, it really had a big impact on me\n\n33:53.140 --> 33:57.900\n and I had a day even just a couple of weeks ago\n\n33:57.900 --> 34:01.020\n where I had spent the day on a Zoom robotics conference\n\n34:01.020 --> 34:04.020\n having great conversations with lots of people.\n\n34:04.020 --> 34:06.780\n Felt really good about the ideas\n\n34:06.780 --> 34:09.500\n that were flowing and the like.\n\n34:09.500 --> 34:12.940\n And then I had a late afternoon meeting\n\n34:12.940 --> 34:15.540\n with one of my favorite control theorists\n\n34:15.540 --> 34:20.540\n and we went from these abstract discussions\n\n34:20.540 --> 34:25.540\n about maybes and what ifs and what a great idea\n\n34:25.540 --> 34:29.140\n to these super precise statements\n\n34:30.100 --> 34:33.660\n about systems that aren't that much more simple\n\n34:33.660 --> 34:38.260\n or abstract than the ones I care about deeply.\n\n34:38.260 --> 34:40.200\n And the contrast of that is,\n\n34:42.540 --> 34:43.780\n I don't know, it really gets me.\n\n34:43.780 --> 34:47.580\n I think people underestimate\n\n34:47.580 --> 34:51.580\n maybe the power of clear thinking.\n\n34:51.580 --> 34:56.580\n And so for instance, deep learning is amazing.\n\n34:58.580 --> 35:00.380\n I use it heavily in our work.\n\n35:00.380 --> 35:02.740\n I think it's changed the world, unquestionable.\n\n35:04.700 --> 35:07.020\n It makes it easy to get things to work\n\n35:07.020 --> 35:08.580\n without thinking as critically about it.\n\n35:08.580 --> 35:11.300\n So I think one of the challenges as an educator\n\n35:11.300 --> 35:14.940\n is to think about how do we make sure people get a taste\n\n35:14.940 --> 35:17.860\n of the more rigorous thinking\n\n35:17.860 --> 35:22.620\n that I think goes along with some different approaches.\n\n35:22.620 --> 35:24.020\n Yeah, so that's really interesting.\n\n35:24.020 --> 35:26.900\n So understanding like the fundamentals,\n\n35:26.900 --> 35:31.900\n the first principles of the problem,\n\n35:31.900 --> 35:33.780\n where in this case it's mechanics,\n\n35:33.780 --> 35:38.780\n like how a thing moves, how a thing behaves,\n\n35:38.780 --> 35:40.420\n like all the forces involved,\n\n35:40.420 --> 35:42.740\n like really getting a deep understanding of that.\n\n35:42.740 --> 35:45.340\n I mean, from physics, the first principle thing\n\n35:45.340 --> 35:49.060\n come from physics, and here it's literally physics.\n\n35:50.100 --> 35:51.940\n Yeah, and this applies, in deep learning,\n\n35:51.940 --> 35:54.980\n this applies to not just, I mean,\n\n35:54.980 --> 35:57.300\n it applies so cleanly in robotics,\n\n35:57.300 --> 36:01.500\n but it also applies to just in any data set.\n\n36:01.500 --> 36:05.100\n I find this true, I mean, driving as well.\n\n36:05.100 --> 36:09.100\n There's a lot of folks in that work on autonomous vehicles\n\n36:09.100 --> 36:14.100\n that work on autonomous vehicles that don't study driving,\n\n36:17.900 --> 36:19.420\n like deeply.\n\n36:20.300 --> 36:23.100\n I might be coming a little bit from the psychology side,\n\n36:23.100 --> 36:28.100\n but I remember I spent a ridiculous number of hours\n\n36:28.380 --> 36:31.940\n at lunch, at this like lawn chair,\n\n36:31.940 --> 36:35.740\n and I would sit somewhere in MIT's campus,\n\n36:35.740 --> 36:37.260\n there's a few interesting intersections,\n\n36:37.260 --> 36:39.380\n and we'd just watch people cross.\n\n36:39.380 --> 36:43.220\n So we were studying pedestrian behavior,\n\n36:43.220 --> 36:46.220\n and I felt like, as we record a lot of video,\n\n36:46.220 --> 36:47.820\n to try, and then there's the computer vision\n\n36:47.820 --> 36:50.860\n extracts their movement, how they move their head, and so on,\n\n36:50.860 --> 36:55.340\n but like every time, I felt like I didn't understand enough.\n\n36:55.340 --> 36:58.620\n I just, I felt like I wasn't understanding\n\n36:58.620 --> 37:01.620\n what, how are people signaling to each other,\n\n37:01.620 --> 37:03.580\n what are they thinking,\n\n37:03.580 --> 37:07.820\n how cognizant are they of their fear of death?\n\n37:07.820 --> 37:11.900\n Like, what's the underlying game theory here?\n\n37:11.900 --> 37:14.140\n What are the incentives?\n\n37:14.140 --> 37:17.860\n And then I finally found a live stream of an intersection\n\n37:17.860 --> 37:20.300\n that's like high def that I just, I would watch\n\n37:20.300 --> 37:21.780\n so I wouldn't have to sit out there.\n\n37:21.780 --> 37:23.580\n But it's interesting, so like, I feel.\n\n37:23.580 --> 37:25.180\n But that's tough, that's a tough example,\n\n37:25.180 --> 37:27.100\n because I mean, the learning.\n\n37:27.100 --> 37:28.780\n Humans are involved.\n\n37:28.780 --> 37:33.460\n Not just because human, but I think the learning mantra\n\n37:33.460 --> 37:35.500\n is that basically the statistics of the data\n\n37:35.500 --> 37:37.940\n will tell me things I need to know, right?\n\n37:37.940 --> 37:41.860\n And, you know, for the example you gave\n\n37:41.860 --> 37:45.420\n of all the nuances of, you know, eye contact,\n\n37:45.420 --> 37:47.620\n or hand gestures, or whatever that are happening\n\n37:47.620 --> 37:48.900\n for these subtle interactions\n\n37:48.900 --> 37:51.140\n between pedestrians and traffic, right?\n\n37:51.140 --> 37:54.460\n Maybe the data will tell that story.\n\n37:54.460 --> 37:59.460\n I maybe even, one level more meta than what you're saying.\n\n38:01.300 --> 38:02.660\n For a particular problem,\n\n38:02.660 --> 38:03.820\n I think it might be the case\n\n38:03.820 --> 38:06.020\n that data should tell us the story.\n\n38:07.220 --> 38:09.420\n But I think there's a rigorous thinking\n\n38:09.420 --> 38:11.700\n that is just an essential skill\n\n38:11.700 --> 38:14.580\n for a mathematician or an engineer\n\n38:14.580 --> 38:18.380\n that I just don't wanna lose it.\n\n38:18.380 --> 38:22.460\n There are certainly super rigorous control,\n\n38:22.460 --> 38:24.940\n or sorry, machine learning people.\n\n38:24.940 --> 38:28.020\n I just think deep learning makes it so easy\n\n38:28.020 --> 38:31.580\n to do some things that our next generation,\n\n38:31.580 --> 38:35.860\n are not immediately rewarded\n\n38:35.860 --> 38:38.540\n for going through some of the more rigorous approaches.\n\n38:38.540 --> 38:40.740\n And then I wonder where that takes us.\n\n38:40.740 --> 38:42.260\n Well, I'm actually optimistic about it.\n\n38:42.260 --> 38:44.860\n I just want to do my part\n\n38:44.860 --> 38:48.020\n to try to steer that rigorous thinking.\n\n38:48.020 --> 38:50.940\n So there's like two questions I wanna ask.\n\n38:50.940 --> 38:55.940\n Do you have sort of a good example of rigorous thinking\n\n38:56.860 --> 39:00.860\n where it's easy to get lazy and not do the rigorous thinking?\n\n39:00.860 --> 39:02.500\n And the other question I have is like,\n\n39:02.500 --> 39:07.500\n do you have advice of how to practice rigorous thinking\n\n39:09.140 --> 39:14.140\n in all the computer science disciplines that we've mentioned?\n\n39:16.380 --> 39:21.380\n Yeah, I mean, there are times where problems\n\n39:21.500 --> 39:24.820\n that can be solved with well known mature methods\n\n39:25.860 --> 39:30.300\n could also be solved with a deep learning approach.\n\n39:30.300 --> 39:35.300\n And there's an argument that you must use learning\n\n39:36.740 --> 39:38.380\n even for the parts we already think we know,\n\n39:38.380 --> 39:39.780\n because if the human has touched it,\n\n39:39.780 --> 39:42.460\n then you've biased the system\n\n39:42.460 --> 39:44.340\n and you've suddenly put a bottleneck in there\n\n39:44.340 --> 39:46.300\n that is your own mental model.\n\n39:46.300 --> 39:49.100\n But something like converting a matrix,\n\n39:49.100 --> 39:50.780\n I think we know how to do that pretty well,\n\n39:50.780 --> 39:52.020\n even if it's a pretty big matrix,\n\n39:52.020 --> 39:53.140\n and we understand that pretty well.\n\n39:53.140 --> 39:55.060\n And you could train a deep network to do it,\n\n39:55.060 --> 39:57.340\n but you shouldn't probably.\n\n39:57.340 --> 40:02.220\n So in that sense, rigorous thinking is understanding\n\n40:02.220 --> 40:07.220\n the scope and the limitations of the methods that we have,\n\n40:07.340 --> 40:10.180\n like how to use the tools of mathematics properly.\n\n40:10.180 --> 40:15.100\n Yeah, I think taking a class on analysis\n\n40:15.100 --> 40:18.620\n is all I'm sort of arguing is to take a chance to stop\n\n40:18.620 --> 40:20.900\n and force yourself to think rigorously\n\n40:20.900 --> 40:25.140\n about even the rational numbers or something.\n\n40:25.140 --> 40:27.740\n It doesn't have to be the end all problem.\n\n40:27.740 --> 40:31.100\n But that exercise of clear thinking,\n\n40:31.100 --> 40:33.420\n I think goes a long way,\n\n40:33.420 --> 40:35.260\n and I just wanna make sure we keep preaching it.\n\n40:35.260 --> 40:36.380\n We don't lose it.\n\n40:36.380 --> 40:39.540\n But do you think when you're doing rigorous thinking\n\n40:39.540 --> 40:43.220\n or maybe trying to write down equations\n\n40:43.220 --> 40:47.980\n or sort of explicitly formally describe a system,\n\n40:47.980 --> 40:51.580\n do you think we naturally simplify things too much?\n\n40:51.580 --> 40:53.500\n Is that a danger you run into?\n\n40:53.500 --> 40:56.180\n Like in order to be able to understand something\n\n40:56.180 --> 40:58.180\n about the system mathematically,\n\n40:58.180 --> 41:01.700\n we make it too much of a toy example.\n\n41:01.700 --> 41:04.460\n But I think that's the good stuff, right?\n\n41:04.460 --> 41:07.060\n That's how you understand the fundamentals?\n\n41:07.060 --> 41:07.900\n I think so.\n\n41:07.900 --> 41:10.380\n I think maybe even that's a key to intelligence\n\n41:10.380 --> 41:12.460\n or something, but I mean, okay,\n\n41:12.460 --> 41:15.100\n what if Newton and Galileo had deep learning?\n\n41:15.100 --> 41:18.340\n And they had done a bunch of experiments\n\n41:18.340 --> 41:20.360\n and they told the world,\n\n41:20.360 --> 41:22.460\n here's your weights of your neural network.\n\n41:22.460 --> 41:24.260\n We've solved the problem.\n\n41:24.260 --> 41:25.380\n Where would we be today?\n\n41:25.380 --> 41:28.420\n I don't think we'd be as far as we are.\n\n41:28.420 --> 41:29.260\n There's something to be said\n\n41:29.260 --> 41:32.540\n about having the simplest explanation for a phenomenon.\n\n41:32.540 --> 41:37.180\n So I don't doubt that we can train neural networks\n\n41:37.180 --> 41:42.180\n to predict even physical F equals MA type equations.\n\n41:46.300 --> 41:51.300\n But I maybe, I want another Newton to come along\n\n41:51.300 --> 41:52.940\n because I think there's more to do\n\n41:52.940 --> 41:56.020\n in terms of coming up with the simple models\n\n41:56.020 --> 41:59.860\n for more complicated tasks.\n\n41:59.860 --> 42:04.240\n Yeah, let's not offend AI systems from 50 years\n\n42:04.240 --> 42:06.340\n from now that are listening to this\n\n42:06.340 --> 42:08.260\n that are probably better at,\n\n42:08.260 --> 42:10.180\n might be better coming up\n\n42:10.180 --> 42:13.080\n with F equals MA equations themselves.\n\n42:13.080 --> 42:16.940\n So sorry, I actually think learning is probably a route\n\n42:16.940 --> 42:21.180\n to achieving this, but the representation matters, right?\n\n42:21.180 --> 42:26.180\n And I think having a function that takes my inputs\n\n42:26.200 --> 42:29.060\n to outputs that is arbitrarily complex\n\n42:29.060 --> 42:30.780\n may not be the end goal.\n\n42:30.780 --> 42:34.140\n I think there's still the most simple\n\n42:34.140 --> 42:36.420\n or parsimonious explanation for the data.\n\n42:37.620 --> 42:39.000\n Simple doesn't mean low dimensional.\n\n42:39.000 --> 42:41.020\n That's one thing I think that we've,\n\n42:41.020 --> 42:41.960\n a lesson that we've learned.\n\n42:41.960 --> 42:46.080\n So a standard way to do model reduction\n\n42:46.080 --> 42:47.860\n or system identification and controls\n\n42:47.860 --> 42:50.460\n is the typical formulation is that you try to find\n\n42:50.460 --> 42:54.220\n the minimal state dimension realization of a system\n\n42:54.220 --> 42:57.760\n that hits some error bounds or something like that.\n\n42:57.760 --> 43:00.340\n And that's maybe not, I think we're learning\n\n43:00.340 --> 43:04.560\n that state dimension is not the right metric.\n\n43:05.980 --> 43:06.820\n Of complexity.\n\n43:06.820 --> 43:07.640\n Of complexity.\n\n43:07.640 --> 43:09.460\n But for me, I think a lot about contact,\n\n43:09.460 --> 43:10.820\n the mechanics of contact,\n\n43:10.820 --> 43:13.660\n if a robot hand is picking up an object or something.\n\n43:14.520 --> 43:17.220\n And when I write down the equations of motion for that,\n\n43:17.220 --> 43:19.100\n they look incredibly complex,\n\n43:19.100 --> 43:23.420\n not because, actually not so much\n\n43:23.420 --> 43:26.660\n because of the dynamics of the hand when it's moving,\n\n43:26.660 --> 43:28.500\n but it's just the interactions\n\n43:28.500 --> 43:30.860\n and when they turn on and off, right?\n\n43:30.860 --> 43:33.300\n So having a high dimensional,\n\n43:33.300 --> 43:36.420\n but simple description of what's happening out here is fine.\n\n43:36.420 --> 43:38.480\n But if when I actually start touching,\n\n43:38.480 --> 43:41.860\n if I write down a different dynamical system\n\n43:41.860 --> 43:45.420\n for every polygon on my robot hand\n\n43:45.420 --> 43:47.300\n and every polygon on the object,\n\n43:47.300 --> 43:49.000\n whether it's in contact or not,\n\n43:49.000 --> 43:51.700\n with all the combinatorics that explodes there,\n\n43:51.700 --> 43:54.460\n then that's too complex.\n\n43:54.460 --> 43:55.800\n So I need to somehow summarize that\n\n43:55.800 --> 44:00.800\n with a more intuitive physics way of thinking.\n\n44:01.460 --> 44:03.500\n And yeah, I'm very optimistic\n\n44:03.500 --> 44:05.700\n that machine learning will get us there.\n\n44:05.700 --> 44:08.220\n First of all, I mean, I'll probably do it\n\n44:08.220 --> 44:09.140\n in the introduction,\n\n44:09.140 --> 44:12.900\n but you're one of the great robotics people at MIT.\n\n44:12.900 --> 44:14.300\n You're a professor at MIT.\n\n44:14.300 --> 44:16.480\n You've teach him a lot of amazing courses.\n\n44:16.480 --> 44:19.180\n You run a large group\n\n44:19.180 --> 44:22.780\n and you have a important history for MIT, I think,\n\n44:22.780 --> 44:26.340\n as being a part of the DARPA Robotics Challenge.\n\n44:26.340 --> 44:28.340\n Can you maybe first say,\n\n44:28.340 --> 44:30.000\n what is the DARPA Robotics Challenge\n\n44:30.000 --> 44:35.000\n and then tell your story around it, your journey with it?\n\n44:36.380 --> 44:37.220\n Yeah, sure.\n\n44:39.260 --> 44:41.060\n So the DARPA Robotics Challenge,\n\n44:41.060 --> 44:44.720\n it came on the tails of the DARPA Grand Challenge\n\n44:44.720 --> 44:45.940\n and DARPA Urban Challenge,\n\n44:45.940 --> 44:48.420\n which were the challenges that brought us,\n\n44:49.660 --> 44:52.740\n put a spotlight on self driving cars.\n\n44:55.400 --> 45:00.400\n Gil Pratt was at DARPA and pitched a new challenge\n\n45:01.360 --> 45:03.520\n that involved disaster response.\n\n45:04.980 --> 45:07.140\n It didn't explicitly require humanoids,\n\n45:07.140 --> 45:09.140\n although humanoids came into the picture.\n\n45:10.220 --> 45:14.740\n This happened shortly after the Fukushima disaster in Japan\n\n45:14.740 --> 45:17.660\n and our challenge was motivated roughly by that\n\n45:17.660 --> 45:21.060\n because that was a case where if we had had robots\n\n45:21.060 --> 45:22.700\n that were ready to be sent in,\n\n45:22.700 --> 45:26.580\n there's a chance that we could have averted disaster.\n\n45:26.580 --> 45:30.620\n And certainly after the, in the disaster response,\n\n45:30.620 --> 45:32.380\n there were times we would have loved\n\n45:32.380 --> 45:33.540\n to have sent robots in.\n\n45:34.740 --> 45:39.220\n So in practice, what we ended up with was a grand challenge,\n\n45:39.220 --> 45:41.180\n a DARPA Robotics Challenge,\n\n45:41.180 --> 45:46.180\n where Boston Dynamics was to make humanoid robots.\n\n45:48.660 --> 45:52.520\n People like me and the amazing team at MIT\n\n45:53.660 --> 45:56.780\n were competing first in a simulation challenge\n\n45:56.780 --> 45:59.460\n to try to be one of the ones that wins the right\n\n45:59.460 --> 46:03.340\n to work on one of the Boston Dynamics humanoids\n\n46:03.340 --> 46:06.620\n in order to compete in the final challenge,\n\n46:06.620 --> 46:08.580\n which was a physical challenge.\n\n46:08.580 --> 46:11.260\n And at that point, it was already, so it was decided\n\n46:11.260 --> 46:13.420\n as humanoid robots early on.\n\n46:13.420 --> 46:15.140\n There were two tracks.\n\n46:15.140 --> 46:16.900\n You could enter as a hardware team\n\n46:16.900 --> 46:18.480\n where you brought your own robot,\n\n46:18.480 --> 46:21.380\n or you could enter through the virtual robotics challenge\n\n46:21.380 --> 46:24.300\n as a software team that would try to win the right\n\n46:24.300 --> 46:25.940\n to use one of the Boston Dynamics robots.\n\n46:25.940 --> 46:27.420\n Sure, called Atlas.\n\n46:27.420 --> 46:28.260\n Atlas.\n\n46:28.260 --> 46:29.080\n Humanoid robots.\n\n46:29.080 --> 46:31.500\n Yeah, it was a 400 pound Marvel,\n\n46:31.500 --> 46:34.460\n but a pretty big, scary looking robot.\n\n46:35.620 --> 46:36.700\n Expensive too.\n\n46:36.700 --> 46:38.260\n Expensive, yeah.\n\n46:38.260 --> 46:42.300\n Okay, so I mean, how did you feel\n\n46:42.300 --> 46:44.780\n at the prospect of this kind of challenge?\n\n46:44.780 --> 46:48.820\n I mean, it seems autonomous vehicles,\n\n46:48.820 --> 46:51.060\n yeah, I guess that sounds hard,\n\n46:51.060 --> 46:53.980\n but not really from a robotics perspective.\n\n46:53.980 --> 46:56.020\n It's like, didn't they do it in the 80s\n\n46:56.020 --> 46:57.820\n is the kind of feeling I would have,\n\n46:58.760 --> 47:00.820\n like when you first look at the problem,\n\n47:00.820 --> 47:04.900\n it's on wheels, but like humanoid robots,\n\n47:04.900 --> 47:07.060\n that sounds really hard.\n\n47:07.060 --> 47:12.060\n So what are your, psychologically speaking,\n\n47:12.860 --> 47:15.780\n what were you feeling, excited, scared?\n\n47:15.780 --> 47:18.020\n Why the heck did you get yourself involved\n\n47:18.020 --> 47:19.660\n in this kind of messy challenge?\n\n47:19.660 --> 47:23.260\n We didn't really know for sure what we were signing up for\n\n47:24.540 --> 47:26.820\n in the sense that you could have something that,\n\n47:26.820 --> 47:30.780\n as it was described in the call for participation,\n\n47:30.780 --> 47:33.900\n that could have put a huge emphasis on the dynamics\n\n47:33.900 --> 47:35.700\n of walking and not falling down\n\n47:35.700 --> 47:37.380\n and walking over rough terrain,\n\n47:37.380 --> 47:38.580\n or the same description,\n\n47:38.580 --> 47:40.780\n because the robot had to go into this disaster area\n\n47:40.780 --> 47:44.580\n and turn valves and pick up a drill,\n\n47:44.580 --> 47:45.780\n it cut the hole through a wall,\n\n47:45.780 --> 47:48.420\n it had to do some interesting things.\n\n47:48.420 --> 47:51.860\n The challenge could have really highlighted perception\n\n47:51.860 --> 47:54.820\n and autonomous planning,\n\n47:54.820 --> 47:59.820\n or it ended up that locomoting over complex terrain\n\n48:01.060 --> 48:03.600\n played a pretty big role in the competition.\n\n48:03.600 --> 48:05.520\n So...\n\n48:05.520 --> 48:08.360\n And the degree of autonomy wasn't clear.\n\n48:08.360 --> 48:09.560\n The degree of autonomy\n\n48:09.560 --> 48:11.920\n was always a central part of the discussion.\n\n48:11.920 --> 48:15.560\n So what wasn't clear was how we would be able,\n\n48:15.560 --> 48:17.520\n how far we'd be able to get with it.\n\n48:17.520 --> 48:21.640\n So the idea was always that you want semi autonomy,\n\n48:21.640 --> 48:24.280\n that you want the robot to have enough compute\n\n48:24.280 --> 48:27.640\n that you can have a degraded network link to a human.\n\n48:27.640 --> 48:30.640\n And so the same way we had degraded networks\n\n48:30.640 --> 48:33.160\n at many natural disasters,\n\n48:33.160 --> 48:34.960\n you'd send your robot in,\n\n48:34.960 --> 48:37.540\n you'd be able to get a few bits back and forth,\n\n48:37.540 --> 48:38.920\n but you don't get to have enough\n\n48:38.920 --> 48:42.080\n potentially to fully operate the robot\n\n48:42.080 --> 48:43.480\n in every joint of the robot.\n\n48:44.600 --> 48:46.160\n So, and then the question was,\n\n48:46.160 --> 48:48.880\n and the gamesmanship of the organizers\n\n48:48.880 --> 48:50.680\n was to figure out what we're capable of,\n\n48:50.680 --> 48:52.600\n push us as far as we could,\n\n48:52.600 --> 48:55.300\n so that it would differentiate the teams\n\n48:55.300 --> 48:57.540\n that put more autonomy on the robot\n\n48:57.540 --> 48:59.400\n and had a few clicks and just said,\n\n48:59.400 --> 49:00.920\n go there, do this, go there, do this,\n\n49:00.920 --> 49:03.400\n versus someone who's picking every footstep\n\n49:03.400 --> 49:05.280\n or something like that.\n\n49:05.280 --> 49:08.920\n So what were some memories,\n\n49:10.760 --> 49:13.620\n painful, triumphant from the experience?\n\n49:13.620 --> 49:15.040\n Like what was that journey?\n\n49:15.040 --> 49:17.680\n Maybe if you can dig in a little deeper,\n\n49:17.680 --> 49:21.120\n maybe even on the technical side, on the team side,\n\n49:21.120 --> 49:23.020\n that whole process of,\n\n49:24.120 --> 49:28.200\n from the early idea stages to actually competing.\n\n49:28.200 --> 49:31.680\n I mean, this was a defining experience for me.\n\n49:31.680 --> 49:33.940\n It came at the right time for me in my career.\n\n49:33.940 --> 49:37.480\n I had gotten tenure before I was due a sabbatical,\n\n49:37.480 --> 49:39.840\n and most people do something relaxing\n\n49:39.840 --> 49:41.920\n and restorative for a sabbatical.\n\n49:41.920 --> 49:44.520\n So you got tenure before this?\n\n49:44.520 --> 49:46.200\n Yeah, yeah, yeah.\n\n49:46.200 --> 49:48.120\n It was a good time for me.\n\n49:48.120 --> 49:50.960\n We had a bunch of algorithms that we were very happy with.\n\n49:50.960 --> 49:52.560\n We wanted to see how far we could push them,\n\n49:52.560 --> 49:54.920\n and this was a chance to really test our mettle\n\n49:54.920 --> 49:56.880\n to do more proper software engineering.\n\n49:56.880 --> 50:01.420\n So the team, we all just worked our butts off.\n\n50:01.420 --> 50:04.880\n We were in that lab almost all the time.\n\n50:07.680 --> 50:09.600\n Okay, so there were some, of course,\n\n50:09.600 --> 50:12.080\n high highs and low lows throughout that.\n\n50:12.080 --> 50:13.720\n Anytime you're not sleeping\n\n50:13.720 --> 50:16.400\n and devoting your life to a 400 pound humanoid.\n\n50:18.320 --> 50:20.720\n I remember actually one funny moment\n\n50:20.720 --> 50:21.940\n where we're all super tired,\n\n50:21.940 --> 50:24.760\n and so Atlas had to walk across cinder blocks.\n\n50:24.760 --> 50:26.520\n That was one of the obstacles.\n\n50:26.520 --> 50:28.240\n And I remember Atlas was powered down\n\n50:28.240 --> 50:31.280\n and hanging limp on its harness,\n\n50:31.280 --> 50:34.000\n and the humans were there picking up\n\n50:34.000 --> 50:35.200\n and laying the brick down\n\n50:35.200 --> 50:36.440\n so that the robot could walk over it.\n\n50:36.440 --> 50:38.240\n And I thought, what is wrong with this?\n\n50:38.240 --> 50:41.560\n We've got a robot just watching us\n\n50:41.560 --> 50:42.500\n do all the manual labor\n\n50:42.500 --> 50:47.040\n so that it can take its little stroll across the train.\n\n50:47.040 --> 50:52.040\n But I mean, even the virtual robotics challenge\n\n50:52.120 --> 50:54.640\n was super nerve wracking and dramatic.\n\n50:54.640 --> 50:59.640\n I remember, so we were using Gazebo as a simulator\n\n51:01.520 --> 51:02.360\n on the cloud,\n\n51:02.360 --> 51:03.920\n and there was all these interesting challenges.\n\n51:03.920 --> 51:08.560\n I think the investment that OSR FC,\n\n51:08.560 --> 51:10.020\n whatever they were called at that time,\n\n51:10.020 --> 51:12.220\n Brian Gerkey's team at Open Source Robotics,\n\n51:14.160 --> 51:16.000\n they were pushing on the capabilities of Gazebo\n\n51:16.000 --> 51:20.380\n in order to scale it to the complexity of these challenges.\n\n51:20.380 --> 51:23.900\n So, you know, up to the virtual competition.\n\n51:23.900 --> 51:26.220\n So the virtual competition was,\n\n51:26.220 --> 51:28.480\n you will sign on at a certain time\n\n51:28.480 --> 51:29.840\n and we'll have a network connection\n\n51:29.840 --> 51:32.080\n to another machine on the cloud\n\n51:32.080 --> 51:34.880\n that is running the simulator of your robot.\n\n51:34.880 --> 51:38.160\n And your controller will run on this computer\n\n51:38.160 --> 51:40.920\n and the physics will run on the other\n\n51:40.920 --> 51:43.060\n and you have to connect.\n\n51:43.060 --> 51:48.060\n Now, the physics, they wanted it to run at real time rates\n\n51:48.140 --> 51:50.740\n because there was an element of human interaction.\n\n51:50.740 --> 51:53.280\n And humans, if you do want to teleop,\n\n51:53.280 --> 51:56.120\n it works way better if it's at frame rate.\n\n51:56.120 --> 51:57.120\n Oh, cool.\n\n51:57.120 --> 51:58.720\n But it was very hard to simulate\n\n51:58.720 --> 52:03.240\n these complex scenes at real time rate.\n\n52:03.240 --> 52:06.520\n So right up to like days before the competition,\n\n52:06.520 --> 52:11.040\n the simulator wasn't quite at real time rate.\n\n52:11.040 --> 52:13.280\n And that was great for me because my controller\n\n52:13.280 --> 52:16.280\n was solving a pretty big optimization problem\n\n52:16.280 --> 52:17.760\n and it wasn't quite at real time rate.\n\n52:17.760 --> 52:18.880\n So I was fine.\n\n52:18.880 --> 52:20.480\n I was keeping up with the simulator.\n\n52:20.480 --> 52:22.880\n We were both running at about 0.7.\n\n52:22.880 --> 52:24.960\n And I remember getting this email.\n\n52:24.960 --> 52:28.440\n And by the way, the perception folks on our team hated\n\n52:28.440 --> 52:31.440\n that they knew that if my controller was too slow,\n\n52:31.440 --> 52:32.520\n the robot was gonna fall down.\n\n52:32.520 --> 52:34.920\n And no matter how good their perception system was,\n\n52:34.920 --> 52:36.940\n if I can't make my controller fast.\n\n52:36.940 --> 52:37.920\n Anyways, we get this email\n\n52:37.920 --> 52:40.480\n like three days before the virtual competition.\n\n52:40.480 --> 52:41.480\n It's for all the marbles.\n\n52:41.480 --> 52:44.920\n We're gonna either get a humanoid robot or we're not.\n\n52:44.920 --> 52:45.740\n And we get an email saying,\n\n52:45.740 --> 52:48.680\n good news, we made the robot, the simulator faster.\n\n52:48.680 --> 52:50.560\n It's now at one point.\n\n52:50.560 --> 52:54.800\n And I was just like, oh man, what are we gonna do here?\n\n52:54.800 --> 52:58.420\n So that came in late at night for me.\n\n52:59.520 --> 53:00.560\n A few days ahead.\n\n53:00.560 --> 53:01.440\n A few days ahead.\n\n53:01.440 --> 53:04.000\n I went over, it happened at Frank Permenter,\n\n53:04.000 --> 53:06.800\n who's a very, very sharp.\n\n53:06.800 --> 53:10.240\n He was a student at the time working on optimization.\n\n53:11.160 --> 53:12.180\n He was still in lab.\n\n53:13.640 --> 53:16.680\n Frank, we need to make the quadratic programming solver\n\n53:16.680 --> 53:18.360\n faster, not like a little faster.\n\n53:18.360 --> 53:22.600\n It's actually, you know, and we wrote a new solver\n\n53:22.600 --> 53:26.600\n for that QP together that night.\n\n53:28.160 --> 53:29.400\n It was terrifying.\n\n53:29.400 --> 53:31.920\n So there's a really hard optimization problem\n\n53:31.920 --> 53:33.520\n that you're constantly solving.\n\n53:34.480 --> 53:36.820\n You didn't make the optimization problem simpler?\n\n53:36.820 --> 53:38.480\n You wrote a new solver?\n\n53:38.480 --> 53:42.840\n So, I mean, your observation is almost spot on.\n\n53:42.840 --> 53:44.520\n What we did was what everybody,\n\n53:44.520 --> 53:45.800\n I mean, people know how to do this,\n\n53:45.800 --> 53:49.240\n but we had not yet done this idea of warm starting.\n\n53:49.240 --> 53:51.320\n So we are solving a big optimization problem\n\n53:51.320 --> 53:52.680\n at every time step.\n\n53:52.680 --> 53:54.280\n But if you're running fast enough,\n\n53:54.280 --> 53:55.680\n the optimization problem you're solving\n\n53:55.680 --> 53:57.920\n on the last time step is pretty similar\n\n53:57.920 --> 54:00.040\n to the optimization you're gonna solve with the next.\n\n54:00.040 --> 54:02.240\n We had course had told our commercial solver\n\n54:02.240 --> 54:05.520\n to use warm starting, but even the interface\n\n54:05.520 --> 54:09.840\n to that commercial solver was causing us these delays.\n\n54:09.840 --> 54:12.740\n So what we did was we basically wrote,\n\n54:12.740 --> 54:15.360\n we called it fast QP at the time.\n\n54:15.360 --> 54:18.480\n We wrote a very lightweight, very fast layer,\n\n54:18.480 --> 54:22.120\n which would basically check if nearby solutions\n\n54:22.120 --> 54:24.240\n to the quadratic program were,\n\n54:24.240 --> 54:26.560\n which were very easily checked,\n\n54:26.560 --> 54:28.000\n could stabilize the robot.\n\n54:28.000 --> 54:30.720\n And if they couldn't, we would fall back to the solver.\n\n54:30.720 --> 54:33.120\n You couldn't really test this well, right?\n\n54:33.120 --> 54:33.960\n Or like?\n\n54:33.960 --> 54:37.360\n I mean, so we always knew that if we fell back to,\n\n54:37.360 --> 54:40.440\n if we, it got to the point where if for some reason\n\n54:40.440 --> 54:42.840\n things slowed down and we fell back to the original solver,\n\n54:42.840 --> 54:46.040\n the robot would actually literally fall down.\n\n54:46.040 --> 54:49.360\n So it was a harrowing sort of edge we were,\n\n54:49.360 --> 54:51.200\n ledge we were sort of on.\n\n54:51.200 --> 54:53.200\n But I mean, it actually,\n\n54:53.200 --> 54:55.840\n like the 400 pound human could come crashing to the ground\n\n54:55.840 --> 54:58.020\n if your solver's not fast enough.\n\n54:58.880 --> 55:01.900\n But you know, we had lots of good experiences.\n\n55:01.900 --> 55:05.600\n So can I ask you a weird question I get\n\n55:06.640 --> 55:09.440\n about idea of hard work?\n\n55:09.440 --> 55:14.320\n So actually people, like students of yours\n\n55:14.320 --> 55:17.040\n that I've interacted with and just,\n\n55:17.040 --> 55:19.400\n and robotics people in general,\n\n55:19.400 --> 55:23.400\n but they have moments,\n\n55:23.400 --> 55:28.360\n at moments have worked harder than most people I know\n\n55:28.360 --> 55:30.600\n in terms of, if you look at different disciplines\n\n55:30.600 --> 55:32.360\n of how hard people work.\n\n55:32.360 --> 55:34.560\n But they're also like the happiest.\n\n55:34.560 --> 55:37.000\n Like, just like, I don't know.\n\n55:37.000 --> 55:39.200\n It's the same thing with like running.\n\n55:39.200 --> 55:41.380\n People that push themselves to like the limit,\n\n55:41.380 --> 55:44.760\n they also seem to be like the most like full of life\n\n55:44.760 --> 55:45.600\n somehow.\n\n55:46.720 --> 55:48.680\n And I get often criticized like,\n\n55:48.680 --> 55:50.420\n you're not getting enough sleep.\n\n55:50.420 --> 55:52.000\n What are you doing to your body?\n\n55:52.000 --> 55:54.680\n Blah, blah, blah, like this kind of stuff.\n\n55:54.680 --> 55:58.040\n And I usually just kind of respond like,\n\n55:58.040 --> 55:59.720\n I'm doing what I love.\n\n55:59.720 --> 56:00.920\n I'm passionate about it.\n\n56:00.920 --> 56:01.760\n I love it.\n\n56:01.760 --> 56:04.800\n I feel like it's, it's invigorating.\n\n56:04.800 --> 56:07.640\n I actually think, I don't think the lack of sleep\n\n56:07.640 --> 56:08.860\n is what hurts you.\n\n56:08.860 --> 56:12.040\n I think what hurts you is stress and lack of doing things\n\n56:12.040 --> 56:13.280\n that you're passionate about.\n\n56:13.280 --> 56:14.920\n But in this world, yeah, I mean,\n\n56:14.920 --> 56:19.920\n can you comment about why the heck robotics people\n\n56:20.720 --> 56:25.720\n are willing to push themselves to that degree?\n\n56:26.200 --> 56:27.680\n Is there value in that?\n\n56:27.680 --> 56:29.400\n And why are they so happy?\n\n56:30.360 --> 56:31.920\n I think, I think you got it right.\n\n56:31.920 --> 56:36.440\n I mean, I think the causality is not that we work hard.\n\n56:36.440 --> 56:38.500\n And I think other disciplines work very hard too,\n\n56:38.500 --> 56:40.300\n but it's, I don't think it's that we work hard\n\n56:40.300 --> 56:43.160\n and therefore we are happy.\n\n56:43.160 --> 56:44.700\n I think we found something\n\n56:44.700 --> 56:46.600\n that we're truly passionate about.\n\n56:48.080 --> 56:49.960\n It makes us very happy.\n\n56:49.960 --> 56:52.280\n And then we get a little involved with it\n\n56:52.280 --> 56:54.600\n and spend a lot of time on it.\n\n56:54.600 --> 56:55.980\n What a luxury to have something\n\n56:55.980 --> 56:58.240\n that you wanna spend all your time on, right?\n\n56:59.140 --> 57:00.800\n We could talk about this for many hours,\n\n57:00.800 --> 57:03.880\n but maybe if we could pick,\n\n57:03.880 --> 57:05.480\n is there something on the technical side\n\n57:05.480 --> 57:08.260\n on the approach that you took that's interesting\n\n57:08.260 --> 57:10.240\n that turned out to be a terrible failure\n\n57:10.240 --> 57:13.800\n or a success that you carry into your work today\n\n57:13.800 --> 57:17.260\n about all the different ideas that were involved\n\n57:17.260 --> 57:22.260\n in making, whether in the simulation or in the real world,\n\n57:23.400 --> 57:25.520\n making this semi autonomous system work?\n\n57:25.520 --> 57:30.520\n I mean, it really did teach me something fundamental\n\n57:30.880 --> 57:33.560\n about what it's gonna take to get robustness\n\n57:33.560 --> 57:35.320\n out of a system of this complexity.\n\n57:35.320 --> 57:37.720\n I would say the DARPA challenge\n\n57:37.720 --> 57:41.040\n really was foundational in my thinking.\n\n57:41.040 --> 57:43.720\n I think the autonomous driving community thinks about this.\n\n57:43.720 --> 57:45.580\n I think lots of people thinking\n\n57:45.580 --> 57:47.080\n about safety critical systems\n\n57:47.080 --> 57:48.920\n that might have machine learning in the loop\n\n57:48.920 --> 57:50.360\n are thinking about these questions.\n\n57:50.360 --> 57:53.340\n For me, the DARPA challenge was the moment\n\n57:53.340 --> 57:57.480\n where I realized we've spent every waking minute\n\n57:57.480 --> 57:58.920\n running this robot.\n\n57:58.920 --> 58:01.440\n And again, for the physical competition,\n\n58:01.440 --> 58:02.540\n days before the competition,\n\n58:02.540 --> 58:04.440\n we saw the robot fall down in a way\n\n58:04.440 --> 58:05.980\n it had never fallen down before.\n\n58:05.980 --> 58:09.260\n I thought, how could we have found that?\n\n58:10.520 --> 58:13.600\n We only have one robot, it's running almost all the time.\n\n58:13.600 --> 58:15.560\n We just didn't have enough hours in the day\n\n58:15.560 --> 58:17.120\n to test that robot.\n\n58:17.120 --> 58:19.380\n Something has to change, right?\n\n58:19.380 --> 58:21.080\n And then I think that, I mean,\n\n58:21.080 --> 58:24.880\n I would say that the team that won was,\n\n58:24.880 --> 58:28.020\n from KAIST, was the team that had two robots\n\n58:28.020 --> 58:30.560\n and was able to do not only incredible engineering,\n\n58:30.560 --> 58:33.240\n just absolutely top rate engineering,\n\n58:33.240 --> 58:36.080\n but also they were able to test at a rate\n\n58:36.080 --> 58:39.600\n and discipline that we didn't keep up with.\n\n58:39.600 --> 58:41.120\n What does testing look like?\n\n58:41.120 --> 58:42.280\n What are we talking about here?\n\n58:42.280 --> 58:45.000\n Like, what's a loop of tests?\n\n58:45.000 --> 58:48.800\n Like from start to finish, what is a loop of testing?\n\n58:48.800 --> 58:51.880\n Yeah, I mean, I think there's a whole philosophy to testing.\n\n58:51.880 --> 58:54.440\n There's the unit tests, and you can do that on a hardware,\n\n58:54.440 --> 58:56.360\n you can do that in a small piece of code.\n\n58:56.360 --> 58:58.280\n You write one function, you should write a test\n\n58:58.280 --> 59:00.620\n that checks that function's input and outputs.\n\n59:00.620 --> 59:02.440\n You should also write an integration test\n\n59:02.440 --> 59:05.320\n at the other extreme of running the whole system together,\n\n59:05.320 --> 59:09.120\n where they try to turn on all of the different functions\n\n59:09.120 --> 59:11.560\n that you think are correct.\n\n59:11.560 --> 59:13.400\n It's much harder to write the specifications\n\n59:13.400 --> 59:14.520\n for a system level test,\n\n59:14.520 --> 59:17.360\n especially if that system is as complicated\n\n59:17.360 --> 59:18.460\n as a humanoid robot.\n\n59:18.460 --> 59:21.040\n But the philosophy is sort of the same.\n\n59:21.040 --> 59:24.160\n On the real robot, it's no different,\n\n59:24.160 --> 59:26.040\n but on a real robot,\n\n59:26.040 --> 59:28.640\n it's impossible to run the same experiment twice.\n\n59:28.640 --> 59:32.480\n So if you see a failure,\n\n59:32.480 --> 59:34.380\n you hope you caught something in the logs\n\n59:34.380 --> 59:35.620\n that tell you what happened,\n\n59:35.620 --> 59:36.920\n but you'd probably never be able to run\n\n59:36.920 --> 59:38.480\n exactly that experiment again.\n\n59:39.400 --> 59:44.400\n And right now, I think our philosophy is just,\n\n59:45.720 --> 59:47.880\n basically Monte Carlo estimation,\n\n59:47.880 --> 59:50.880\n is just run as many experiments as we can,\n\n59:50.880 --> 59:53.080\n maybe try to set up the environment\n\n59:53.080 --> 59:58.080\n to make the things we are worried about happen\n\n59:58.120 --> 59:59.880\n as often as possible.\n\n59:59.880 --> 1:00:02.280\n But really we're relying on somewhat random search\n\n1:00:02.280 --> 1:00:03.180\n in order to test.\n\n1:00:04.220 --> 1:00:05.480\n Maybe that's all we'll ever be able to,\n\n1:00:05.480 --> 1:00:07.320\n but I think, you know,\n\n1:00:07.320 --> 1:00:10.520\n cause there's an argument that the things that'll get you\n\n1:00:10.520 --> 1:00:14.040\n are the things that are really nuanced in the world.\n\n1:00:14.040 --> 1:00:15.700\n And there'd be very hard to, for instance,\n\n1:00:15.700 --> 1:00:16.880\n put back in a simulation.\n\n1:00:16.880 --> 1:00:19.880\n Yeah, I guess the edge cases.\n\n1:00:19.880 --> 1:00:21.840\n What was the hardest thing?\n\n1:00:21.840 --> 1:00:24.680\n Like, so you said walking over rough terrain,\n\n1:00:24.680 --> 1:00:27.120\n like just taking footsteps.\n\n1:00:27.120 --> 1:00:31.360\n I mean, people, it's so dramatic and painful\n\n1:00:31.360 --> 1:00:33.520\n in a certain kind of way to watch these videos\n\n1:00:33.520 --> 1:00:37.600\n from the DRC of robots falling.\n\n1:00:37.600 --> 1:00:38.440\n Yep.\n\n1:00:38.440 --> 1:00:39.440\n It's just so heartbreaking.\n\n1:00:39.440 --> 1:00:40.280\n I don't know.\n\n1:00:40.280 --> 1:00:42.400\n Maybe it's because for me at least,\n\n1:00:42.400 --> 1:00:45.120\n we anthropomorphize the robot.\n\n1:00:45.120 --> 1:00:48.400\n Of course, it's also funny for some reason,\n\n1:00:48.400 --> 1:00:51.920\n like humans falling is funny for, I don't,\n\n1:00:51.920 --> 1:00:53.400\n it's some dark reason.\n\n1:00:53.400 --> 1:00:55.300\n I'm not sure why it is so,\n\n1:00:55.300 --> 1:00:57.880\n but it's also like tragic and painful.\n\n1:00:57.880 --> 1:01:00.380\n And so speaking of which, I mean,\n\n1:01:00.380 --> 1:01:05.000\n what made the robots fall and fail in your view?\n\n1:01:05.000 --> 1:01:06.960\n So I can tell you exactly what happened on our,\n\n1:01:06.960 --> 1:01:08.360\n we, I contributed one of those.\n\n1:01:08.360 --> 1:01:10.960\n Our team contributed one of those spectacular falls.\n\n1:01:10.960 --> 1:01:15.560\n Every one of those falls has a complicated story.\n\n1:01:15.560 --> 1:01:16.920\n I mean, at one time,\n\n1:01:16.920 --> 1:01:19.160\n the power effectively went out on the robot\n\n1:01:20.200 --> 1:01:21.720\n because it had been sitting at the door\n\n1:01:21.720 --> 1:01:24.400\n waiting for a green light to be able to proceed\n\n1:01:24.400 --> 1:01:26.280\n and its batteries, you know,\n\n1:01:26.280 --> 1:01:28.080\n and therefore it just fell backwards\n\n1:01:28.080 --> 1:01:29.280\n and smashed its head against the ground.\n\n1:01:29.280 --> 1:01:30.120\n And it was hilarious,\n\n1:01:30.120 --> 1:01:32.760\n but it wasn't because of bad software, right?\n\n1:01:34.100 --> 1:01:37.120\n But for ours, so the hardest part of the challenge,\n\n1:01:37.120 --> 1:01:40.400\n the hardest task in my view was getting out of the Polaris.\n\n1:01:40.400 --> 1:01:43.760\n It was actually relatively easy to drive the Polaris.\n\n1:01:43.760 --> 1:01:44.600\n Can you tell the story?\n\n1:01:44.600 --> 1:01:45.440\n Sorry to interrupt.\n\n1:01:45.440 --> 1:01:46.920\n The story of the car.\n\n1:01:50.040 --> 1:01:51.240\n People should watch this video.\n\n1:01:51.240 --> 1:01:53.900\n I mean, the thing you've come up with is just brilliant,\n\n1:01:53.900 --> 1:01:55.920\n but anyway, sorry, what's...\n\n1:01:55.920 --> 1:01:56.920\n Yeah, we kind of joke.\n\n1:01:56.920 --> 1:01:59.040\n We call it the big robot, little car problem\n\n1:01:59.040 --> 1:02:03.440\n because somehow the race organizers decided\n\n1:02:03.440 --> 1:02:05.360\n to give us a 400 pound humanoid.\n\n1:02:05.360 --> 1:02:07.480\n And then they also provided the vehicle,\n\n1:02:07.480 --> 1:02:08.640\n which was a little Polaris.\n\n1:02:08.640 --> 1:02:11.760\n And the robot didn't really fit in the car.\n\n1:02:11.760 --> 1:02:14.520\n So you couldn't drive the car with your feet\n\n1:02:14.520 --> 1:02:15.720\n under the steering column.\n\n1:02:15.720 --> 1:02:20.240\n We actually had to straddle the main column of the,\n\n1:02:21.280 --> 1:02:23.580\n and have basically one foot in the passenger seat,\n\n1:02:23.580 --> 1:02:25.280\n one foot in the driver's seat,\n\n1:02:25.280 --> 1:02:27.620\n and then drive with our left hand.\n\n1:02:28.880 --> 1:02:31.300\n But the hard part was we had to then park the car,\n\n1:02:31.300 --> 1:02:33.080\n get out of the car.\n\n1:02:33.080 --> 1:02:34.320\n It didn't have a door, that was okay.\n\n1:02:34.320 --> 1:02:38.720\n But it's just getting up from crouched, from sitting,\n\n1:02:38.720 --> 1:02:41.880\n when you're in this very constrained environment.\n\n1:02:41.880 --> 1:02:44.320\n First of all, I remember after watching those videos,\n\n1:02:44.320 --> 1:02:47.840\n I was much more cognizant of how hard it is for me\n\n1:02:47.840 --> 1:02:49.600\n to get in and out of the car,\n\n1:02:49.600 --> 1:02:51.760\n and out of the car, especially.\n\n1:02:51.760 --> 1:02:54.240\n It's actually a really difficult control problem.\n\n1:02:54.240 --> 1:02:55.480\n Yeah.\n\n1:02:55.480 --> 1:02:58.360\n I'm very cognizant of it when I'm like injured\n\n1:02:58.360 --> 1:02:59.200\n for whatever reason.\n\n1:02:59.200 --> 1:03:00.120\n Oh, that's really hard.\n\n1:03:00.120 --> 1:03:01.440\n Yeah.\n\n1:03:01.440 --> 1:03:03.560\n So how did you approach this problem?\n\n1:03:03.560 --> 1:03:08.160\n So we had, you think of NASA's operations,\n\n1:03:08.160 --> 1:03:09.800\n and they have these checklists,\n\n1:03:09.800 --> 1:03:11.080\n prelaunched checklists and the like.\n\n1:03:11.080 --> 1:03:12.380\n We weren't far off from that.\n\n1:03:12.380 --> 1:03:13.500\n We had this big checklist.\n\n1:03:13.500 --> 1:03:16.320\n And on the first day of the competition,\n\n1:03:16.320 --> 1:03:17.520\n we were running down our checklist.\n\n1:03:17.520 --> 1:03:19.120\n And one of the things we had to do,\n\n1:03:19.120 --> 1:03:21.320\n we had to turn off the controller,\n\n1:03:21.320 --> 1:03:23.320\n the piece of software that was running\n\n1:03:23.320 --> 1:03:25.560\n that would drive the left foot of the robot\n\n1:03:25.560 --> 1:03:28.120\n in order to accelerate on the gas.\n\n1:03:28.120 --> 1:03:30.840\n And then we turned on our balancing controller.\n\n1:03:30.840 --> 1:03:34.280\n And the nerves, jitters of the first day of the competition,\n\n1:03:34.280 --> 1:03:35.660\n someone forgot to check that box\n\n1:03:35.660 --> 1:03:37.560\n and turn that controller off.\n\n1:03:37.560 --> 1:03:40.880\n So we used a lot of motion planning\n\n1:03:40.880 --> 1:03:45.320\n to figure out a sort of configuration of the robot\n\n1:03:45.320 --> 1:03:47.200\n that we could get up and over.\n\n1:03:47.200 --> 1:03:49.440\n We relied heavily on our balancing controller.\n\n1:03:50.320 --> 1:03:53.760\n And basically, when the robot was in one\n\n1:03:53.760 --> 1:03:57.560\n of its most precarious sort of configurations,\n\n1:03:57.560 --> 1:04:00.920\n trying to sneak its big leg out of the side,\n\n1:04:01.800 --> 1:04:05.000\n the other controller that thought it was still driving\n\n1:04:05.000 --> 1:04:06.760\n told its left foot to go like this.\n\n1:04:06.760 --> 1:04:09.620\n And that wasn't good.\n\n1:04:11.000 --> 1:04:13.320\n But it turned disastrous for us\n\n1:04:13.320 --> 1:04:16.980\n because what happened was a little bit of push here.\n\n1:04:16.980 --> 1:04:21.080\n Actually, we have videos of us running into the robot\n\n1:04:21.080 --> 1:04:24.680\n with a 10 foot pole and it kind of will recover.\n\n1:04:24.680 --> 1:04:27.800\n But this is a case where there's no space to recover.\n\n1:04:27.800 --> 1:04:30.180\n So a lot of our secondary balancing mechanisms\n\n1:04:30.180 --> 1:04:32.160\n about like take a step to recover,\n\n1:04:32.160 --> 1:04:33.760\n they were all disabled because we were in the car\n\n1:04:33.760 --> 1:04:35.320\n and there was no place to step.\n\n1:04:35.320 --> 1:04:38.380\n So we were relying on our just lowest level reflexes.\n\n1:04:38.380 --> 1:04:42.200\n And even then, I think just hitting the foot on the seat,\n\n1:04:42.200 --> 1:04:44.960\n on the floor, we probably could have recovered from it.\n\n1:04:44.960 --> 1:04:46.400\n But the thing that was bad that happened\n\n1:04:46.400 --> 1:04:49.440\n is when we did that and we jostled a little bit,\n\n1:04:49.440 --> 1:04:53.720\n the tailbone of our robot was only a little off the seat,\n\n1:04:53.720 --> 1:04:54.600\n it hit the seat.\n\n1:04:55.480 --> 1:04:58.260\n And the other foot came off the ground just a little bit.\n\n1:04:58.260 --> 1:05:02.280\n And nothing in our plans had ever told us what to do\n\n1:05:02.280 --> 1:05:05.120\n if your butt's on the seat and your feet are in the air.\n\n1:05:05.120 --> 1:05:06.040\n Feet in the air.\n\n1:05:06.040 --> 1:05:10.080\n And then the thing is once you get off the script,\n\n1:05:10.080 --> 1:05:11.040\n things can go very wrong\n\n1:05:11.040 --> 1:05:12.760\n because even our state estimation,\n\n1:05:12.760 --> 1:05:15.200\n our system that was trying to collect all the data\n\n1:05:15.200 --> 1:05:16.760\n from the sensors and understand\n\n1:05:16.760 --> 1:05:18.480\n what's happening with the robot,\n\n1:05:18.480 --> 1:05:20.080\n it didn't know about this situation.\n\n1:05:20.080 --> 1:05:22.800\n So it was predicting things that were just wrong.\n\n1:05:22.800 --> 1:05:26.560\n And then we did a violent shake and fell off\n\n1:05:26.560 --> 1:05:29.180\n in our face first out of the robot.\n\n1:05:29.180 --> 1:05:32.520\n But like into the destination.\n\n1:05:32.520 --> 1:05:35.360\n That's true, we fell in, we got our point for egress.\n\n1:05:36.320 --> 1:05:39.280\n But so is there any hope for, that's interesting,\n\n1:05:39.280 --> 1:05:43.280\n is there any hope for Atlas to be able to do something\n\n1:05:43.280 --> 1:05:46.320\n when it's just on its butt and feet in the air?\n\n1:05:46.320 --> 1:05:47.200\n Absolutely.\n\n1:05:47.200 --> 1:05:48.520\n So you can, what do you?\n\n1:05:48.520 --> 1:05:50.920\n No, so that is one of the big challenges.\n\n1:05:50.920 --> 1:05:53.840\n And I think it's still true, you know,\n\n1:05:53.840 --> 1:05:58.840\n Boston Dynamics and Antimal and there's this incredible work\n\n1:05:59.120 --> 1:06:02.000\n on legged robots happening around the world.\n\n1:06:04.540 --> 1:06:07.620\n Most of them still are very good at the case\n\n1:06:07.620 --> 1:06:10.080\n where you're making contact with the world at your feet.\n\n1:06:10.080 --> 1:06:12.200\n And they have typically point feet relatively,\n\n1:06:12.200 --> 1:06:14.480\n they have balls on their feet, for instance.\n\n1:06:14.480 --> 1:06:16.600\n If those robots get in a situation\n\n1:06:16.600 --> 1:06:19.880\n where the elbow hits the wall or something like this,\n\n1:06:19.880 --> 1:06:21.240\n that's a pretty different situation.\n\n1:06:21.240 --> 1:06:24.080\n Now they have layers of mechanisms that will make,\n\n1:06:24.080 --> 1:06:27.680\n I think the more mature solutions have ways\n\n1:06:27.680 --> 1:06:31.240\n in which the controller won't do stupid things.\n\n1:06:31.240 --> 1:06:34.720\n But a human, for instance, is able to leverage\n\n1:06:34.720 --> 1:06:36.760\n incidental contact in order to accomplish a goal.\n\n1:06:36.760 --> 1:06:37.800\n In fact, I might, if you push me,\n\n1:06:37.800 --> 1:06:39.720\n I might actually put my hand out\n\n1:06:39.720 --> 1:06:42.220\n and make a new brand new contact.\n\n1:06:42.220 --> 1:06:44.940\n The feet of the robot are doing this on quadrupeds,\n\n1:06:44.940 --> 1:06:49.120\n but we mostly in robotics are afraid of contact\n\n1:06:49.120 --> 1:06:52.040\n on the rest of our body, which is crazy.\n\n1:06:53.180 --> 1:06:56.040\n There's this whole field of motion planning,\n\n1:06:56.040 --> 1:06:58.040\n collision free motion planning.\n\n1:06:58.040 --> 1:06:59.800\n And we write very complex algorithms\n\n1:06:59.800 --> 1:07:01.640\n so that the robot can dance around\n\n1:07:01.640 --> 1:07:04.100\n and make sure it doesn't touch the world.\n\n1:07:05.840 --> 1:07:07.720\n So people are just afraid of contact\n\n1:07:07.720 --> 1:07:09.880\n because contact the scene is a difficult.\n\n1:07:09.880 --> 1:07:13.380\n It's still a difficult control problem and sensing problem.\n\n1:07:13.380 --> 1:07:18.380\n Now you're a serious person, I'm a little bit of an idiot\n\n1:07:21.180 --> 1:07:24.140\n and I'm going to ask you some dumb questions.\n\n1:07:24.140 --> 1:07:27.140\n So I do martial arts.\n\n1:07:27.140 --> 1:07:30.380\n So like jiu jitsu, I wrestled my whole life.\n\n1:07:30.380 --> 1:07:35.380\n So let me ask the question, like whenever people learn\n\n1:07:35.380 --> 1:07:38.500\n that I do any kind of AI or like I mentioned robots\n\n1:07:38.500 --> 1:07:40.040\n and things like that, they say,\n\n1:07:40.040 --> 1:07:45.020\n when are we going to have robots that can win\n\n1:07:45.020 --> 1:07:49.020\n in a wrestling match or in a fight against a human?\n\n1:07:49.880 --> 1:07:52.160\n So we just mentioned sitting on your butt,\n\n1:07:52.160 --> 1:07:53.940\n if you're in the air, that's a common position.\n\n1:07:53.940 --> 1:07:55.420\n Jiu jitsu, when you're on the ground,\n\n1:07:55.420 --> 1:07:57.600\n you're a down opponent.\n\n1:07:59.100 --> 1:08:03.800\n Like how difficult do you think is the problem?\n\n1:08:03.800 --> 1:08:06.880\n And when will we have a robot that can defeat a human\n\n1:08:06.880 --> 1:08:08.580\n in a wrestling match?\n\n1:08:08.580 --> 1:08:11.100\n And we're talking about a lot, like, I don't know\n\n1:08:11.100 --> 1:08:13.940\n if you're familiar with wrestling, but essentially.\n\n1:08:15.340 --> 1:08:16.180\n Not very.\n\n1:08:16.180 --> 1:08:19.580\n It's basically the art of contact.\n\n1:08:19.580 --> 1:08:24.580\n It's like, it's because you're picking contact points\n\n1:08:24.580 --> 1:08:29.300\n and then using like leverage like to off balance\n\n1:08:29.300 --> 1:08:33.940\n to trick people, like you make them feel\n\n1:08:33.940 --> 1:08:35.620\n like you're doing one thing\n\n1:08:35.620 --> 1:08:38.840\n and then they change their balance\n\n1:08:38.840 --> 1:08:41.620\n and then you switch what you're doing\n\n1:08:41.620 --> 1:08:44.100\n and then results in a throw or whatever.\n\n1:08:44.100 --> 1:08:48.540\n So like, it's basically the art of multiple contacts.\n\n1:08:48.540 --> 1:08:49.380\n So.\n\n1:08:49.380 --> 1:08:50.820\n Awesome, that's a nice description of it.\n\n1:08:50.820 --> 1:08:53.040\n So there's also an opponent in there, right?\n\n1:08:53.040 --> 1:08:54.180\n So if.\n\n1:08:54.180 --> 1:08:55.060\n Very dynamic.\n\n1:08:55.060 --> 1:08:58.520\n Right, if you are wrestling a human\n\n1:08:58.520 --> 1:09:02.900\n and are in a game theoretic situation with a human,\n\n1:09:02.900 --> 1:09:07.900\n that's still hard, but just to speak to the, you know,\n\n1:09:08.220 --> 1:09:11.340\n quickly reasoning about contact part of it, for instance.\n\n1:09:11.340 --> 1:09:13.380\n Yeah, maybe even throwing the game theory out of it,\n\n1:09:13.380 --> 1:09:17.700\n almost like, yeah, almost like a non dynamic opponent.\n\n1:09:17.700 --> 1:09:20.060\n Right, there's reasons to be optimistic,\n\n1:09:20.060 --> 1:09:22.660\n but I think our best understanding of those problems\n\n1:09:22.660 --> 1:09:23.920\n are still pretty hard.\n\n1:09:24.820 --> 1:09:29.860\n I have been increasingly focused on manipulation,\n\n1:09:29.860 --> 1:09:31.720\n partly where that's a case where the contact\n\n1:09:31.720 --> 1:09:33.180\n has to be much more rich.\n\n1:09:35.800 --> 1:09:38.260\n And there are some really impressive examples\n\n1:09:38.260 --> 1:09:41.820\n of deep learning policies, controllers\n\n1:09:41.820 --> 1:09:46.820\n that can appear to do good things through contact.\n\n1:09:47.860 --> 1:09:51.380\n We've even got new examples of, you know,\n\n1:09:51.380 --> 1:09:53.940\n deep learning models of predicting what's gonna happen\n\n1:09:53.940 --> 1:09:56.220\n to objects as they go through contact.\n\n1:09:56.220 --> 1:09:59.780\n But I think the challenge you just offered there\n\n1:09:59.780 --> 1:10:01.500\n still eludes us, right?\n\n1:10:01.500 --> 1:10:03.620\n The ability to make a decision\n\n1:10:03.620 --> 1:10:05.320\n based on those models quickly.\n\n1:10:07.560 --> 1:10:10.140\n You know, I have to think though, it's hard for humans too,\n\n1:10:10.140 --> 1:10:11.380\n when you get that complicated.\n\n1:10:11.380 --> 1:10:16.100\n I think probably you had maybe a slow motion version\n\n1:10:16.100 --> 1:10:17.980\n of where you learned the basic skills\n\n1:10:17.980 --> 1:10:20.700\n and you've probably gotten better at it\n\n1:10:20.700 --> 1:10:24.660\n and there's much more subtle to you.\n\n1:10:24.660 --> 1:10:27.940\n But it might still be hard to actually, you know,\n\n1:10:27.940 --> 1:10:32.140\n really on the fly take a, you know, model of your humanoid\n\n1:10:32.140 --> 1:10:35.260\n and figure out how to plan the optimal sequence.\n\n1:10:35.260 --> 1:10:36.660\n That might be a problem we never solve.\n\n1:10:36.660 --> 1:10:40.360\n Well, the, I mean, one of the most amazing things to me\n\n1:10:40.360 --> 1:10:43.740\n about the, we can talk about martial arts.\n\n1:10:43.740 --> 1:10:45.340\n We could also talk about dancing.\n\n1:10:45.340 --> 1:10:46.740\n Doesn't really matter.\n\n1:10:46.740 --> 1:10:50.540\n Too human, I think it's the most interesting study\n\n1:10:50.540 --> 1:10:51.380\n of contact.\n\n1:10:51.380 --> 1:10:53.040\n It's not even the dynamic element of it.\n\n1:10:53.040 --> 1:10:58.040\n It's the, like when you get good at it, it's so effortless.\n\n1:10:58.740 --> 1:11:00.900\n Like I can just, I'm very cognizant\n\n1:11:00.900 --> 1:11:03.380\n of the entirety of the learning process\n\n1:11:03.380 --> 1:11:07.660\n being essentially like learning how to move my body\n\n1:11:07.660 --> 1:11:12.220\n in a way that I could throw very large weights\n\n1:11:12.220 --> 1:11:17.220\n around effortlessly, like, and I can feel the learning.\n\n1:11:18.500 --> 1:11:21.540\n Like I'm a huge believer in drilling of techniques\n\n1:11:21.540 --> 1:11:23.580\n and you can just like feel your, I don't,\n\n1:11:23.580 --> 1:11:26.780\n you're not feeling, you're feeling, sorry,\n\n1:11:26.780 --> 1:11:29.800\n you're learning it intellectually a little bit,\n\n1:11:29.800 --> 1:11:32.820\n but a lot of it is the body learning it somehow,\n\n1:11:32.820 --> 1:11:36.100\n like instinctually and whatever that learning is,\n\n1:11:36.100 --> 1:11:40.780\n that's really, I'm not even sure if that's equivalent\n\n1:11:40.780 --> 1:11:44.760\n to like a deep learning, learning a controller.\n\n1:11:44.760 --> 1:11:46.820\n I think it's something more,\n\n1:11:46.820 --> 1:11:49.720\n it feels like there's a lot of distributed learning\n\n1:11:49.720 --> 1:11:50.560\n going on.\n\n1:11:50.560 --> 1:11:54.520\n Yeah, I think there's hierarchy and composition\n\n1:11:56.440 --> 1:11:59.920\n probably in the systems that we don't capture very well yet.\n\n1:12:00.840 --> 1:12:02.440\n You have layers of control systems.\n\n1:12:02.440 --> 1:12:03.960\n You have reflexes at the bottom layer\n\n1:12:03.960 --> 1:12:07.440\n and you have a system that's capable\n\n1:12:07.440 --> 1:12:11.320\n of planning a vacation to some distant country,\n\n1:12:11.320 --> 1:12:14.240\n which is probably, you probably don't have a controller,\n\n1:12:14.240 --> 1:12:18.260\n a policy for every possible destination you'll ever pick.\n\n1:12:18.260 --> 1:12:19.100\n Right?\n\n1:12:20.380 --> 1:12:23.460\n But there's something magical in the in between\n\n1:12:23.460 --> 1:12:26.340\n and how do you go from these low level feedback loops\n\n1:12:26.340 --> 1:12:30.020\n to something that feels like a pretty complex\n\n1:12:30.020 --> 1:12:31.060\n set of outcomes.\n\n1:12:32.740 --> 1:12:34.760\n You know, my guess is, I think there's evidence\n\n1:12:34.760 --> 1:12:37.620\n that you can plan at some of these levels, right?\n\n1:12:37.620 --> 1:12:41.740\n So Josh Tenenbaum just showed it in his talk the other day.\n\n1:12:41.740 --> 1:12:43.320\n He's got a game he likes to talk about.\n\n1:12:43.320 --> 1:12:46.700\n I think he calls it the pick three game or something,\n\n1:12:46.700 --> 1:12:50.740\n where he puts a bunch of clutter down in front of a person\n\n1:12:50.740 --> 1:12:52.380\n and he says, okay, pick three objects.\n\n1:12:52.380 --> 1:12:55.700\n And it might be a telephone or a shoe\n\n1:12:55.700 --> 1:12:58.940\n or a Kleenex box or whatever.\n\n1:12:59.880 --> 1:13:01.820\n And apparently you pick three items and then you pick,\n\n1:13:01.820 --> 1:13:04.100\n he says, okay, pick the first one up with your right hand,\n\n1:13:04.100 --> 1:13:06.360\n the second one up with your left hand.\n\n1:13:06.360 --> 1:13:08.860\n Now using those objects, now as tools,\n\n1:13:08.860 --> 1:13:10.100\n pick up the third object.\n\n1:13:11.060 --> 1:13:15.700\n Right, so that's down at the level of physics\n\n1:13:15.700 --> 1:13:17.140\n and mechanics and contact mechanics\n\n1:13:17.140 --> 1:13:21.880\n that I think we do learning or we do have policies for,\n\n1:13:21.880 --> 1:13:24.740\n we do control for, almost feedback,\n\n1:13:24.740 --> 1:13:26.300\n but somehow we're able to still,\n\n1:13:26.300 --> 1:13:28.420\n I mean, I've never picked up a telephone\n\n1:13:28.420 --> 1:13:30.220\n with a shoe and a water bottle before.\n\n1:13:30.220 --> 1:13:33.140\n And somehow, and it takes me a little longer to do that\n\n1:13:33.140 --> 1:13:35.180\n the first time, but most of the time\n\n1:13:35.180 --> 1:13:37.260\n we can sort of figure that out.\n\n1:13:37.260 --> 1:13:41.940\n So yeah, I think the amazing thing is this ability\n\n1:13:41.940 --> 1:13:44.100\n to be flexible with our models,\n\n1:13:44.100 --> 1:13:48.700\n plan when we need to use our well oiled controllers\n\n1:13:48.700 --> 1:13:51.820\n when we don't, when we're in familiar territory.\n\n1:13:53.280 --> 1:13:55.560\n Having models, I think the other thing you just said\n\n1:13:55.560 --> 1:13:58.140\n was something about, I think your awareness\n\n1:13:58.140 --> 1:13:59.860\n of what's happening is even changing\n\n1:13:59.860 --> 1:14:02.380\n as you improve your expertise, right?\n\n1:14:02.380 --> 1:14:04.980\n So maybe you have a very approximate model\n\n1:14:04.980 --> 1:14:06.240\n of the mechanics to begin with.\n\n1:14:06.240 --> 1:14:09.300\n And as you gain expertise,\n\n1:14:09.300 --> 1:14:11.920\n you get a more refined version of that model.\n\n1:14:11.920 --> 1:14:16.920\n You're aware of muscles or balance components\n\n1:14:17.100 --> 1:14:19.700\n that you just weren't even aware of before.\n\n1:14:19.700 --> 1:14:21.740\n So how do you scaffold that?\n\n1:14:21.740 --> 1:14:24.180\n Yeah, plus the fear of injury,\n\n1:14:24.180 --> 1:14:28.780\n the ambition of goals, of excelling,\n\n1:14:28.780 --> 1:14:32.020\n and fear of mortality.\n\n1:14:32.020 --> 1:14:33.340\n Let's see, what else is in there?\n\n1:14:33.340 --> 1:14:38.040\n As the motivations, overinflated ego in the beginning,\n\n1:14:38.040 --> 1:14:42.900\n and then a crash of confidence in the middle.\n\n1:14:42.900 --> 1:14:46.700\n All of those seem to be essential for the learning process.\n\n1:14:46.700 --> 1:14:48.140\n And if all that's good,\n\n1:14:48.140 --> 1:14:50.500\n then you're probably optimizing energy efficiency.\n\n1:14:50.500 --> 1:14:53.080\n Yeah, right, so we have to get that right.\n\n1:14:53.080 --> 1:14:58.080\n So there was this idea that you would have robots\n\n1:14:58.580 --> 1:15:03.580\n play soccer better than human players by 2050.\n\n1:15:03.780 --> 1:15:05.300\n That was the goal.\n\n1:15:05.300 --> 1:15:10.140\n Basically, it was the goal to beat world champion team,\n\n1:15:10.140 --> 1:15:13.340\n to become a world cup, beat like a world cup level team.\n\n1:15:13.340 --> 1:15:15.900\n So are we gonna see that first?\n\n1:15:15.900 --> 1:15:19.580\n Or a robot, if you're familiar,\n\n1:15:19.580 --> 1:15:23.440\n there's an organization called UFC for mixed martial arts.\n\n1:15:23.440 --> 1:15:27.100\n Are we gonna see a world cup championship soccer team\n\n1:15:27.100 --> 1:15:32.100\n that have robots, or a UFC champion mixed martial artist\n\n1:15:32.660 --> 1:15:33.860\n as a robot?\n\n1:15:33.860 --> 1:15:37.140\n I mean, it's very hard to say one thing is harder,\n\n1:15:37.140 --> 1:15:38.580\n some problem is harder than the other.\n\n1:15:38.580 --> 1:15:43.580\n What probably matters is who started the organization that,\n\n1:15:44.980 --> 1:15:47.140\n I mean, I think RoboCup has a pretty serious following,\n\n1:15:47.140 --> 1:15:50.860\n and there is a history now of people playing that game,\n\n1:15:50.860 --> 1:15:53.620\n learning about that game, building robots to play that game,\n\n1:15:53.620 --> 1:15:55.820\n building increasingly more human robots.\n\n1:15:55.820 --> 1:15:57.020\n It's got momentum.\n\n1:15:57.020 --> 1:16:00.900\n So if you want to have mixed martial arts compete,\n\n1:16:00.900 --> 1:16:04.000\n you better start your organization now, right?\n\n1:16:05.460 --> 1:16:07.740\n I think almost independent of which problem\n\n1:16:07.740 --> 1:16:08.660\n is technically harder,\n\n1:16:08.660 --> 1:16:11.400\n because they're both hard and they're both different.\n\n1:16:11.400 --> 1:16:12.240\n That's a good point.\n\n1:16:12.240 --> 1:16:14.700\n I mean, those videos are just hilarious,\n\n1:16:14.700 --> 1:16:17.140\n like especially the humanoid robots\n\n1:16:17.140 --> 1:16:21.260\n trying to play soccer.\n\n1:16:21.260 --> 1:16:23.420\n I mean, they're kind of terrible right now.\n\n1:16:23.420 --> 1:16:26.020\n I mean, I guess there is robo sumo wrestling.\n\n1:16:26.020 --> 1:16:28.740\n There's like the robo one competitions,\n\n1:16:28.740 --> 1:16:31.140\n where they do have these robots that go on the table\n\n1:16:31.140 --> 1:16:32.100\n and basically fight.\n\n1:16:32.100 --> 1:16:33.720\n So maybe I'm wrong, maybe.\n\n1:16:33.720 --> 1:16:37.140\n First of all, do you have a year in mind for RoboCup,\n\n1:16:37.140 --> 1:16:39.100\n just from a robotics perspective?\n\n1:16:39.100 --> 1:16:42.060\n Seems like a super exciting possibility\n\n1:16:42.060 --> 1:16:46.340\n that like in the physical space,\n\n1:16:46.340 --> 1:16:47.620\n this is what's interesting.\n\n1:16:47.620 --> 1:16:50.560\n I think the world is captivated.\n\n1:16:50.560 --> 1:16:52.620\n I think it's really exciting.\n\n1:16:52.620 --> 1:16:56.400\n It inspires just a huge number of people\n\n1:16:56.400 --> 1:17:01.400\n when a machine beats a human at a game\n\n1:17:01.460 --> 1:17:03.460\n that humans are really damn good at.\n\n1:17:03.460 --> 1:17:05.740\n So you're talking about chess and go,\n\n1:17:05.740 --> 1:17:09.820\n but that's in the world of digital.\n\n1:17:09.820 --> 1:17:13.320\n I don't think machines have beat humans\n\n1:17:13.320 --> 1:17:16.020\n at a game in the physical space yet,\n\n1:17:16.020 --> 1:17:17.700\n but that would be just.\n\n1:17:17.700 --> 1:17:20.340\n You have to make the rules very carefully, right?\n\n1:17:20.340 --> 1:17:22.980\n I mean, if Atlas kicked me in the shins, I'm down\n\n1:17:22.980 --> 1:17:25.440\n and game over.\n\n1:17:25.440 --> 1:17:30.440\n So it's very subtle on what's fair.\n\n1:17:31.220 --> 1:17:33.020\n I think the fighting one is a weird one.\n\n1:17:33.020 --> 1:17:35.180\n Yeah, because you're talking about a machine\n\n1:17:35.180 --> 1:17:36.500\n that's much stronger than you.\n\n1:17:36.500 --> 1:17:39.740\n But yeah, in terms of soccer, basketball, all those kinds.\n\n1:17:39.740 --> 1:17:40.580\n Even soccer, right?\n\n1:17:40.580 --> 1:17:43.500\n I mean, as soon as there's contact or whatever,\n\n1:17:43.500 --> 1:17:46.540\n and there are some things that the robot will do better.\n\n1:17:46.540 --> 1:17:51.540\n I think if you really set yourself up to try to see\n\n1:17:51.540 --> 1:17:53.140\n could robots win the game of soccer\n\n1:17:53.140 --> 1:17:56.300\n as the rules were written, the right thing\n\n1:17:56.300 --> 1:17:58.060\n for the robot to do is to play very differently\n\n1:17:58.060 --> 1:17:59.680\n than a human would play.\n\n1:17:59.680 --> 1:18:04.060\n You're not gonna get the perfect soccer player robot.\n\n1:18:04.060 --> 1:18:07.900\n You're gonna get something that exploits the rules,\n\n1:18:07.900 --> 1:18:12.220\n exploits its super actuators, its super low bandwidth\n\n1:18:13.420 --> 1:18:15.340\n feedback loops or whatever, and it's gonna play the game\n\n1:18:15.340 --> 1:18:17.540\n differently than you want it to play.\n\n1:18:17.540 --> 1:18:21.380\n And I bet there's ways, I bet there's loopholes, right?\n\n1:18:21.380 --> 1:18:26.380\n We saw that in the DARPA challenge that it's very hard\n\n1:18:27.060 --> 1:18:29.420\n to write a set of rules that someone can't find\n\n1:18:30.660 --> 1:18:32.860\n a way to exploit.\n\n1:18:32.860 --> 1:18:35.020\n Let me ask another ridiculous question.\n\n1:18:35.020 --> 1:18:37.980\n I think this might be the last ridiculous question,\n\n1:18:37.980 --> 1:18:39.220\n but I doubt it.\n\n1:18:39.220 --> 1:18:44.220\n I aspire to ask as many ridiculous questions\n\n1:18:44.540 --> 1:18:48.060\n of a brilliant MIT professor.\n\n1:18:48.060 --> 1:18:52.440\n Okay, I don't know if you've seen the black mirror.\n\n1:18:53.660 --> 1:18:56.740\n It's funny, I never watched the episode.\n\n1:18:56.740 --> 1:19:00.620\n I know when it happened though, because I gave a talk\n\n1:19:00.620 --> 1:19:05.380\n to some MIT faculty one day on a unassuming Monday\n\n1:19:05.380 --> 1:19:08.500\n or whatever I was telling him about the state of robotics.\n\n1:19:08.500 --> 1:19:10.740\n And I showed some video from Boston Dynamics\n\n1:19:10.740 --> 1:19:13.940\n of the quadruped spot at the time.\n\n1:19:13.940 --> 1:19:15.900\n It was the early version of spot.\n\n1:19:15.900 --> 1:19:19.300\n And there was a look of horror that went across the room.\n\n1:19:19.300 --> 1:19:23.220\n And I said, I've shown videos like this a lot of times,\n\n1:19:23.220 --> 1:19:24.060\n what happened?\n\n1:19:24.060 --> 1:19:26.780\n And it turns out that this video had gone,\n\n1:19:26.780 --> 1:19:28.380\n this black mirror episode had changed\n\n1:19:28.380 --> 1:19:33.180\n the way people watched the videos I was putting out.\n\n1:19:33.180 --> 1:19:34.740\n The way they see these kinds of robots.\n\n1:19:34.740 --> 1:19:37.780\n So I talked to so many people who are just terrified\n\n1:19:37.780 --> 1:19:41.020\n because of that episode probably of these kinds of robots.\n\n1:19:41.020 --> 1:19:44.540\n I almost wanna say that they almost enjoy being terrified.\n\n1:19:44.540 --> 1:19:47.100\n I don't even know what it is about human psychology\n\n1:19:47.100 --> 1:19:49.220\n that kind of imagine doomsday,\n\n1:19:49.220 --> 1:19:52.780\n the destruction of the universe or our society\n\n1:19:52.780 --> 1:19:57.340\n and kind of like enjoy being afraid.\n\n1:19:57.340 --> 1:19:59.300\n I don't wanna simplify it, but it feels like\n\n1:19:59.300 --> 1:20:01.020\n they talk about it so often.\n\n1:20:01.020 --> 1:20:06.020\n It almost, there does seem to be an addictive quality to it.\n\n1:20:06.380 --> 1:20:09.500\n I talked to a guy, a guy named Joe Rogan,\n\n1:20:09.500 --> 1:20:11.580\n who's kind of the flag bearer\n\n1:20:11.580 --> 1:20:14.660\n for being terrified at these robots.\n\n1:20:14.660 --> 1:20:17.340\n Do you have two questions?\n\n1:20:17.340 --> 1:20:18.620\n One, do you have an understanding\n\n1:20:18.620 --> 1:20:21.700\n of why people are afraid of robots?\n\n1:20:21.700 --> 1:20:24.940\n And the second question is in black mirror,\n\n1:20:24.940 --> 1:20:26.380\n just to tell you the episode,\n\n1:20:26.380 --> 1:20:28.180\n I don't even remember it that much anymore,\n\n1:20:28.180 --> 1:20:31.100\n but these robots, I think they can shoot\n\n1:20:31.100 --> 1:20:32.820\n like a pellet or something.\n\n1:20:32.820 --> 1:20:36.540\n They basically have, it's basically a spot with a gun.\n\n1:20:36.540 --> 1:20:41.540\n And how far are we away from having robots\n\n1:20:41.940 --> 1:20:44.100\n that go rogue like that?\n\n1:20:44.100 --> 1:20:48.460\n Basically spot that goes rogue for some reason\n\n1:20:48.460 --> 1:20:49.980\n and somehow finds a gun.\n\n1:20:51.300 --> 1:20:56.300\n Right, so, I mean, I'm not a psychologist.\n\n1:20:56.420 --> 1:20:58.580\n I think, I don't know exactly why\n\n1:20:59.860 --> 1:21:01.700\n people react the way they do.\n\n1:21:01.700 --> 1:21:06.700\n I think we have to be careful about the way robots influence\n\n1:21:06.700 --> 1:21:07.980\n our society and the like.\n\n1:21:07.980 --> 1:21:09.860\n I think that's something, that's a responsibility\n\n1:21:09.860 --> 1:21:12.260\n that roboticists need to embrace.\n\n1:21:13.260 --> 1:21:15.460\n I don't think robots are gonna come after me\n\n1:21:15.460 --> 1:21:18.460\n with a kitchen knife or a pellet gun right away.\n\n1:21:18.460 --> 1:21:21.420\n And I mean, if they were programmed in such a way,\n\n1:21:21.420 --> 1:21:25.940\n but I used to joke with Atlas that all I had to do\n\n1:21:25.940 --> 1:21:28.340\n was run for five minutes and its battery would run out.\n\n1:21:28.340 --> 1:21:30.620\n But actually they've got to be careful\n\n1:21:30.620 --> 1:21:32.460\n and actually they've got a very big battery\n\n1:21:32.460 --> 1:21:33.300\n in there by the end.\n\n1:21:33.300 --> 1:21:34.500\n So it was over an hour.\n\n1:21:37.220 --> 1:21:39.420\n I think the fear is a bit cultural though.\n\n1:21:39.420 --> 1:21:44.420\n Cause I mean, you notice that, like, I think in my age,\n\n1:21:45.140 --> 1:21:48.260\n in the US, we grew up watching Terminator, right?\n\n1:21:48.260 --> 1:21:50.500\n If I had grown up at the same time in Japan,\n\n1:21:50.500 --> 1:21:52.740\n I probably would have been watching Astro Boy.\n\n1:21:52.740 --> 1:21:55.860\n And there's a very different reaction to robots\n\n1:21:55.860 --> 1:21:57.460\n in different countries, right?\n\n1:21:57.460 --> 1:22:02.460\n So I don't know if it's a human innate fear of metal marvels\n\n1:22:02.620 --> 1:22:06.420\n or if it's something that we've done to ourselves\n\n1:22:06.420 --> 1:22:07.460\n with our sci fi.\n\n1:22:09.860 --> 1:22:12.580\n Yeah, the stories we tell ourselves through movies,\n\n1:22:12.580 --> 1:22:16.780\n through just through popular media.\n\n1:22:16.780 --> 1:22:21.100\n But if I were to tell, you know, if you were my therapist\n\n1:22:21.100 --> 1:22:24.900\n and I said, I'm really terrified that we're going\n\n1:22:24.900 --> 1:22:29.300\n to have these robots very soon that will hurt us.\n\n1:22:30.900 --> 1:22:35.600\n Like, how do you approach making me feel better?\n\n1:22:36.620 --> 1:22:39.580\n Like, why shouldn't people be afraid?\n\n1:22:39.580 --> 1:22:41.380\n There's a, I think there's a video\n\n1:22:41.380 --> 1:22:44.500\n that went viral recently.\n\n1:22:44.500 --> 1:22:46.900\n Everything, everything was spot in Boston,\n\n1:22:46.900 --> 1:22:48.380\n which goes viral in general.\n\n1:22:48.380 --> 1:22:50.060\n But usually it's like really cool stuff.\n\n1:22:50.060 --> 1:22:51.420\n Like they're doing flips and stuff\n\n1:22:51.420 --> 1:22:56.140\n or like sad stuff, the Atlas being hit with a broomstick\n\n1:22:56.140 --> 1:22:57.300\n or something like that.\n\n1:22:57.300 --> 1:23:02.300\n But there's a video where I think one of the new productions\n\n1:23:02.420 --> 1:23:04.620\n bought robots, which are awesome.\n\n1:23:04.620 --> 1:23:08.540\n It was like patrolling somewhere in like in some country.\n\n1:23:08.540 --> 1:23:11.920\n And like people immediately were like saying like,\n\n1:23:11.920 --> 1:23:14.580\n this is like the dystopian future,\n\n1:23:14.580 --> 1:23:16.380\n like the surveillance state.\n\n1:23:16.380 --> 1:23:18.940\n For some reason, like you can just have a camera,\n\n1:23:18.940 --> 1:23:23.420\n like something about spot being able to walk on four feet\n\n1:23:23.420 --> 1:23:25.940\n with like really terrified people.\n\n1:23:25.940 --> 1:23:30.940\n So like, what do you say to those people?\n\n1:23:31.060 --> 1:23:33.820\n I think there is a legitimate fear there\n\n1:23:33.820 --> 1:23:36.160\n because so much of our future is uncertain.\n\n1:23:37.840 --> 1:23:40.140\n But at the same time, technically speaking,\n\n1:23:40.140 --> 1:23:41.920\n it seems like we're not there yet.\n\n1:23:41.920 --> 1:23:42.820\n So what do you say?\n\n1:23:42.820 --> 1:23:47.820\n I mean, I think technology is complicated.\n\n1:23:48.580 --> 1:23:49.940\n It can be used in many ways.\n\n1:23:49.940 --> 1:23:53.340\n I think there are purely software attacks\n\n1:23:56.360 --> 1:23:59.000\n that somebody could use to do great damage.\n\n1:23:59.000 --> 1:24:01.480\n Maybe they have already, you know,\n\n1:24:01.480 --> 1:24:06.480\n I think wheeled robots could be used in bad ways too.\n\n1:24:08.340 --> 1:24:09.180\n Drones.\n\n1:24:09.180 --> 1:24:14.180\n Drones, right, I don't think that, let's see.\n\n1:24:16.340 --> 1:24:19.920\n I don't want to be building technology\n\n1:24:19.920 --> 1:24:21.860\n just because I'm compelled to build technology\n\n1:24:21.860 --> 1:24:23.580\n and I don't think about it.\n\n1:24:23.580 --> 1:24:27.740\n But I would consider myself a technological optimist,\n\n1:24:27.740 --> 1:24:32.220\n I guess, in the sense that I think we should continue\n\n1:24:32.220 --> 1:24:37.220\n to create and evolve and our world will change.\n\n1:24:37.220 --> 1:24:40.780\n And if we will introduce new challenges,\n\n1:24:40.780 --> 1:24:42.900\n we'll screw something up maybe,\n\n1:24:42.900 --> 1:24:46.220\n but I think also we'll invent ourselves\n\n1:24:46.220 --> 1:24:49.380\n out of those challenges and life will go on.\n\n1:24:49.380 --> 1:24:51.580\n So it's interesting because you didn't mention\n\n1:24:51.580 --> 1:24:54.540\n like this is technically too hard.\n\n1:24:54.540 --> 1:24:57.380\n I don't think robots are, I think people attribute\n\n1:24:57.380 --> 1:24:59.140\n a robot that looks like an animal\n\n1:24:59.140 --> 1:25:02.140\n as maybe having a level of self awareness\n\n1:25:02.140 --> 1:25:05.460\n or consciousness or something that they don't have yet.\n\n1:25:05.460 --> 1:25:09.380\n Right, so it's not, I think our ability\n\n1:25:09.380 --> 1:25:12.780\n to anthropomorphize those robots is probably,\n\n1:25:13.700 --> 1:25:16.540\n we're assuming that they have a level of intelligence\n\n1:25:16.540 --> 1:25:17.940\n that they don't yet have.\n\n1:25:17.940 --> 1:25:20.060\n And that might be part of the fear.\n\n1:25:20.060 --> 1:25:22.260\n So in that sense, it's too hard.\n\n1:25:22.260 --> 1:25:25.540\n But, you know, there are many scary things in the world.\n\n1:25:25.540 --> 1:25:29.860\n Right, so I think we're right to ask those questions.\n\n1:25:29.860 --> 1:25:33.600\n We're right to think about the implications of our work.\n\n1:25:33.600 --> 1:25:38.600\n Right, in the short term as we're working on it for sure,\n\n1:25:39.720 --> 1:25:43.840\n is there something long term that scares you\n\n1:25:43.840 --> 1:25:47.680\n about our future with AI and robots?\n\n1:25:47.680 --> 1:25:52.400\n A lot of folks from Elon Musk to Sam Harris\n\n1:25:52.400 --> 1:25:56.860\n to a lot of folks talk about the existential threats\n\n1:25:56.860 --> 1:25:58.880\n about artificial intelligence.\n\n1:25:58.880 --> 1:26:03.680\n Oftentimes, robots kind of inspire that the most\n\n1:26:03.680 --> 1:26:05.840\n because of the anthropomorphism.\n\n1:26:05.840 --> 1:26:07.400\n Do you have any fears?\n\n1:26:07.400 --> 1:26:09.000\n It's an important question.\n\n1:26:12.120 --> 1:26:14.920\n I actually, I think I like Rod Brooks answer\n\n1:26:14.920 --> 1:26:17.080\n maybe the best on this, I think.\n\n1:26:17.080 --> 1:26:19.320\n And it's not the only answer he's given over the years,\n\n1:26:19.320 --> 1:26:24.320\n but maybe one of my favorites is he says,\n\n1:26:24.360 --> 1:26:25.920\n it's not gonna be, he's got a book,\n\n1:26:25.920 --> 1:26:29.960\n Flesh and Machines, I believe, it's not gonna be\n\n1:26:29.960 --> 1:26:31.880\n the robots versus the people,\n\n1:26:31.880 --> 1:26:34.240\n we're all gonna be robot people.\n\n1:26:34.240 --> 1:26:38.000\n Because, you know, we already have smartphones,\n\n1:26:38.000 --> 1:26:41.120\n some of us have serious technology implanted\n\n1:26:41.120 --> 1:26:43.780\n in our bodies already, whether we have a hearing aid\n\n1:26:43.780 --> 1:26:46.360\n or a pacemaker or anything like this,\n\n1:26:47.800 --> 1:26:50.880\n people with amputations might have prosthetics.\n\n1:26:50.880 --> 1:26:55.880\n And that's a trend I think that is likely to continue.\n\n1:26:57.340 --> 1:27:01.420\n I mean, this is now wild speculation.\n\n1:27:01.420 --> 1:27:05.500\n But I mean, when do we get to cognitive implants\n\n1:27:05.500 --> 1:27:06.620\n and the like, and.\n\n1:27:06.620 --> 1:27:09.500\n Yeah, with neural link, brain computer interfaces,\n\n1:27:09.500 --> 1:27:10.340\n that's interesting.\n\n1:27:10.340 --> 1:27:12.620\n So there's a dance between humans and robots\n\n1:27:12.620 --> 1:27:17.220\n that's going to be, it's going to be impossible\n\n1:27:17.220 --> 1:27:22.220\n to be scared of the other out there, the robot,\n\n1:27:23.380 --> 1:27:26.060\n because the robot will be part of us, essentially.\n\n1:27:26.060 --> 1:27:30.180\n It'd be so intricately sort of part of our society that.\n\n1:27:30.180 --> 1:27:33.060\n Yeah, and it might not even be implanted part of us,\n\n1:27:33.060 --> 1:27:37.220\n but just, it's so much a part of our, yeah, our society.\n\n1:27:37.220 --> 1:27:39.380\n So in that sense, the smartphone is already the robot\n\n1:27:39.380 --> 1:27:41.660\n we should be afraid of, yeah.\n\n1:27:41.660 --> 1:27:45.460\n I mean, yeah, and all the usual fears arise\n\n1:27:45.460 --> 1:27:50.460\n of the misinformation, the manipulation,\n\n1:27:51.860 --> 1:27:53.500\n all those kinds of things that,\n\n1:27:56.180 --> 1:27:57.860\n the problems are all the same.\n\n1:27:57.860 --> 1:28:00.700\n They're human problems, essentially, it feels like.\n\n1:28:00.700 --> 1:28:03.420\n Yeah, I mean, I think the way we interact\n\n1:28:03.420 --> 1:28:07.420\n with each other online is changing the value we put on,\n\n1:28:07.420 --> 1:28:08.940\n you know, personal interaction.\n\n1:28:08.940 --> 1:28:11.260\n And that's a crazy big change that's going to happen\n\n1:28:11.260 --> 1:28:13.080\n and rip through our, has already been ripping\n\n1:28:13.080 --> 1:28:14.200\n through our society, right?\n\n1:28:14.200 --> 1:28:18.060\n And that has implications that are massive.\n\n1:28:18.060 --> 1:28:19.300\n I don't know if they should be scared of it\n\n1:28:19.300 --> 1:28:24.300\n or go with the flow, but I don't see, you know,\n\n1:28:24.700 --> 1:28:26.500\n some battle lines between humans and robots\n\n1:28:26.500 --> 1:28:29.580\n being the first thing to worry about.\n\n1:28:29.580 --> 1:28:33.340\n I mean, I do want to just, as a kind of comment,\n\n1:28:33.340 --> 1:28:35.460\n maybe you can comment about your just feelings\n\n1:28:35.460 --> 1:28:38.660\n about Boston Dynamics in general, but you know,\n\n1:28:38.660 --> 1:28:40.300\n I love science, I love engineering,\n\n1:28:40.300 --> 1:28:42.540\n I think there's so many beautiful ideas in it.\n\n1:28:42.540 --> 1:28:45.300\n And when I look at Boston Dynamics\n\n1:28:45.300 --> 1:28:47.620\n or legged robots in general,\n\n1:28:47.620 --> 1:28:52.620\n I think they inspire people, curiosity and feelings\n\n1:28:54.620 --> 1:28:57.460\n in general, excitement about engineering\n\n1:28:57.460 --> 1:29:00.620\n more than almost anything else in popular culture.\n\n1:29:00.620 --> 1:29:03.660\n And I think that's such an exciting,\n\n1:29:03.660 --> 1:29:06.820\n like responsibility and possibility for robotics.\n\n1:29:06.820 --> 1:29:10.460\n And Boston Dynamics is riding that wave pretty damn well.\n\n1:29:10.460 --> 1:29:13.980\n Like they found it, they've discovered that hunger\n\n1:29:13.980 --> 1:29:17.540\n and curiosity in the people and they're doing magic with it.\n\n1:29:17.540 --> 1:29:19.820\n I don't care if the, I mean, I guess is that their company,\n\n1:29:19.820 --> 1:29:21.340\n they have to make money, right?\n\n1:29:21.340 --> 1:29:24.300\n But they're already doing incredible work\n\n1:29:24.300 --> 1:29:26.940\n and inspiring the world about technology.\n\n1:29:26.940 --> 1:29:30.700\n I mean, do you have thoughts about Boston Dynamics\n\n1:29:30.700 --> 1:29:34.620\n and maybe others, your own work in robotics\n\n1:29:34.620 --> 1:29:36.600\n and inspiring the world in that way?\n\n1:29:36.600 --> 1:29:40.240\n I completely agree, I think Boston Dynamics\n\n1:29:40.240 --> 1:29:42.640\n is absolutely awesome.\n\n1:29:42.640 --> 1:29:46.160\n I think I show my kids those videos, you know,\n\n1:29:46.160 --> 1:29:48.640\n and the best thing that happens is sometimes\n\n1:29:48.640 --> 1:29:50.740\n they've already seen them, you know, right?\n\n1:29:50.740 --> 1:29:55.360\n I think, I just think it's a pinnacle of success\n\n1:29:55.360 --> 1:29:58.760\n in robotics that is just one of the best things\n\n1:29:58.760 --> 1:30:01.660\n that's happened, absolutely completely agree.\n\n1:30:01.660 --> 1:30:06.220\n One of the heartbreaking things to me is how many\n\n1:30:06.220 --> 1:30:11.220\n robotics companies fail, how hard it is to make money\n\n1:30:11.300 --> 1:30:13.100\n with a robotics company.\n\n1:30:13.100 --> 1:30:17.220\n Like iRobot like went through hell just to arrive\n\n1:30:17.220 --> 1:30:19.740\n at a Roomba to figure out one product.\n\n1:30:19.740 --> 1:30:23.900\n And then there's so many home robotics companies\n\n1:30:23.900 --> 1:30:31.900\n like Jibo and Anki, Anki, the cutest toy that's a great robot\n\n1:30:32.720 --> 1:30:36.320\n I thought went down, I'm forgetting a bunch of them,\n\n1:30:36.320 --> 1:30:37.980\n but a bunch of robotics companies fail,\n\n1:30:37.980 --> 1:30:40.620\n Rod's company, Rethink Robotics.\n\n1:30:42.340 --> 1:30:47.260\n Like, do you have anything hopeful to say\n\n1:30:47.260 --> 1:30:50.340\n about the possibility of making money with robots?\n\n1:30:50.340 --> 1:30:54.220\n Oh, I think you can't just look at the failures.\n\n1:30:54.220 --> 1:30:55.940\n I mean, Boston Dynamics is a success.\n\n1:30:55.940 --> 1:30:58.500\n There's lots of companies that are still doing amazingly\n\n1:30:58.500 --> 1:31:01.140\n good work in robotics.\n\n1:31:01.140 --> 1:31:05.360\n I mean, this is the capitalist ecology or something, right?\n\n1:31:05.360 --> 1:31:07.700\n I think you have many companies, you have many startups\n\n1:31:07.700 --> 1:31:11.380\n and they push each other forward and many of them fail\n\n1:31:11.380 --> 1:31:13.820\n and some of them get through and that's sort of\n\n1:31:13.820 --> 1:31:17.040\n the natural way of those things.\n\n1:31:17.040 --> 1:31:20.460\n I don't know that is robotics really that much worse.\n\n1:31:20.460 --> 1:31:22.300\n I feel the pain that you feel too.\n\n1:31:22.300 --> 1:31:26.480\n Every time I read one of these, sometimes it's friends\n\n1:31:26.480 --> 1:31:31.480\n and I definitely wish it went better or went differently.\n\n1:31:33.580 --> 1:31:38.340\n But I think it's healthy and good to have bursts of ideas,\n\n1:31:38.340 --> 1:31:41.880\n bursts of activities, ideas, if they are really aggressive,\n\n1:31:41.880 --> 1:31:43.280\n they should fail sometimes.\n\n1:31:45.180 --> 1:31:46.940\n Certainly that's the research mantra, right?\n\n1:31:46.940 --> 1:31:50.780\n If you're succeeding at every problem you attempt,\n\n1:31:50.780 --> 1:31:53.380\n then you're not choosing aggressively enough.\n\n1:31:53.380 --> 1:31:55.980\n Is it exciting to you, the new spot?\n\n1:31:55.980 --> 1:31:57.620\n Oh, it's so good.\n\n1:31:57.620 --> 1:32:00.140\n When are you getting them as a pet or it?\n\n1:32:00.140 --> 1:32:03.220\n Yeah, I mean, I have to dig up 75K right now.\n\n1:32:03.220 --> 1:32:05.740\n I mean, it's so cool that there's a price tag,\n\n1:32:05.740 --> 1:32:08.620\n you can go and then actually buy it.\n\n1:32:08.620 --> 1:32:11.500\n I have a Skydio R1, love it.\n\n1:32:11.500 --> 1:32:16.500\n So no, I would absolutely be a customer.\n\n1:32:18.580 --> 1:32:20.060\n I wonder what your kids would think about it.\n\n1:32:20.060 --> 1:32:25.060\n I actually, Zach from Boston Dynamics would let my kid drive\n\n1:32:25.660 --> 1:32:27.140\n in one of their demos one time.\n\n1:32:27.140 --> 1:32:31.100\n And that was just so good, so good.\n\n1:32:31.100 --> 1:32:34.220\n And again, I'll forever be grateful for that.\n\n1:32:34.220 --> 1:32:37.260\n And there's something magical about the anthropomorphization\n\n1:32:37.260 --> 1:32:42.260\n of that arm, it adds another level of human connection.\n\n1:32:42.580 --> 1:32:47.480\n I'm not sure we understand from a control aspect,\n\n1:32:47.480 --> 1:32:49.500\n the value of anthropomorphization.\n\n1:32:51.540 --> 1:32:53.980\n I think that's an understudied\n\n1:32:53.980 --> 1:32:57.060\n and under understood engineering problem.\n\n1:32:57.060 --> 1:33:00.160\n There's been a, like psychologists have been studying it.\n\n1:33:00.160 --> 1:33:02.860\n I think it's part like manipulating our mind\n\n1:33:02.860 --> 1:33:06.740\n to believe things is a valuable engineering.\n\n1:33:06.740 --> 1:33:08.820\n Like this is another degree of freedom\n\n1:33:08.820 --> 1:33:09.820\n that can be controlled.\n\n1:33:09.820 --> 1:33:11.380\n I like that, yeah, I think that's right.\n\n1:33:11.380 --> 1:33:16.020\n I think there's something that humans seem to do\n\n1:33:16.020 --> 1:33:19.000\n or maybe my dangerous introspection is,\n\n1:33:20.340 --> 1:33:23.820\n I think we are able to make very simple models\n\n1:33:23.820 --> 1:33:27.780\n that assume a lot about the world very quickly.\n\n1:33:27.780 --> 1:33:31.220\n And then it takes us a lot more time, like you're wrestling.\n\n1:33:31.220 --> 1:33:33.080\n You probably thought you knew what you were doing\n\n1:33:33.080 --> 1:33:35.340\n with wrestling and you were fairly functional\n\n1:33:35.340 --> 1:33:36.900\n as a complete wrestler.\n\n1:33:36.900 --> 1:33:39.340\n And then you slowly got more expertise.\n\n1:33:39.340 --> 1:33:44.340\n So maybe it's natural that our first level of defense\n\n1:33:45.740 --> 1:33:48.040\n against seeing a new robot is to think of it\n\n1:33:48.040 --> 1:33:52.420\n in our existing models of how humans and animals behave.\n\n1:33:52.420 --> 1:33:55.060\n And it's just, as you spend more time with it,\n\n1:33:55.060 --> 1:33:56.980\n then you'll develop more sophisticated models\n\n1:33:56.980 --> 1:33:59.420\n that will appreciate the differences.\n\n1:34:00.340 --> 1:34:01.620\n Exactly.\n\n1:34:01.620 --> 1:34:05.700\n Can you say what does it take to control a robot?\n\n1:34:05.700 --> 1:34:08.580\n Like what is the control problem of a robot?\n\n1:34:08.580 --> 1:34:10.980\n And in general, what is a robot in your view?\n\n1:34:10.980 --> 1:34:13.900\n Like how do you think of this system?\n\n1:34:15.020 --> 1:34:16.020\n What is a robot?\n\n1:34:16.020 --> 1:34:17.580\n What is a robot?\n\n1:34:17.580 --> 1:34:18.400\n I think robotics.\n\n1:34:18.400 --> 1:34:20.020\n I told you ridiculous questions.\n\n1:34:20.020 --> 1:34:21.500\n No, no, it's good.\n\n1:34:21.500 --> 1:34:22.980\n I mean, there's standard definitions\n\n1:34:22.980 --> 1:34:27.460\n of combining computation with some ability\n\n1:34:27.460 --> 1:34:29.060\n to do mechanical work.\n\n1:34:29.060 --> 1:34:30.980\n I think that gets us pretty close.\n\n1:34:30.980 --> 1:34:34.180\n But I think robotics has this problem\n\n1:34:34.180 --> 1:34:37.200\n that once things really work,\n\n1:34:37.200 --> 1:34:38.920\n we don't call them robots anymore.\n\n1:34:38.920 --> 1:34:42.920\n Like my dishwasher at home is pretty sophisticated,\n\n1:34:44.100 --> 1:34:45.600\n beautiful mechanisms.\n\n1:34:45.600 --> 1:34:46.940\n There's actually a pretty good computer,\n\n1:34:46.940 --> 1:34:49.580\n probably a couple of chips in there doing amazing things.\n\n1:34:49.580 --> 1:34:51.620\n We don't think of that as a robot anymore,\n\n1:34:51.620 --> 1:34:52.460\n which isn't fair.\n\n1:34:52.460 --> 1:34:53.940\n Because then what roughly it means\n\n1:34:53.940 --> 1:34:58.340\n that robotics always has to solve the next problem\n\n1:34:58.340 --> 1:35:00.580\n and doesn't get to celebrate its past successes.\n\n1:35:00.580 --> 1:35:04.740\n I mean, even factory room floor robots\n\n1:35:05.660 --> 1:35:06.860\n are super successful.\n\n1:35:06.860 --> 1:35:08.260\n They're amazing.\n\n1:35:08.260 --> 1:35:09.500\n But that's not the ones,\n\n1:35:09.500 --> 1:35:10.880\n I mean, people think of them as robots,\n\n1:35:10.880 --> 1:35:11.720\n but they don't,\n\n1:35:11.720 --> 1:35:14.500\n if you ask what are the successes of robotics,\n\n1:35:14.500 --> 1:35:17.860\n somehow it doesn't come to your mind immediately.\n\n1:35:17.860 --> 1:35:20.560\n So the definition of robot is a system\n\n1:35:20.560 --> 1:35:23.500\n with some level of automation that fails frequently.\n\n1:35:23.500 --> 1:35:28.420\n Something like, it's the computation plus mechanical work\n\n1:35:28.420 --> 1:35:30.540\n and an unsolved problem.\n\n1:35:30.540 --> 1:35:32.300\n It's an unsolved problem, yeah.\n\n1:35:32.300 --> 1:35:37.020\n So from a perspective of control and mechanics,\n\n1:35:37.020 --> 1:35:39.840\n dynamics, what is a robot?\n\n1:35:40.700 --> 1:35:42.380\n So there are many different types of robots.\n\n1:35:42.380 --> 1:35:47.380\n The control that you need for a Jibo robot,\n\n1:35:47.620 --> 1:35:50.620\n you know, some robot that's sitting on your countertop\n\n1:35:50.620 --> 1:35:53.580\n and interacting with you, but not touching you,\n\n1:35:53.580 --> 1:35:55.820\n for instance, is very different than what you need\n\n1:35:55.820 --> 1:35:59.460\n for an autonomous car or an autonomous drone.\n\n1:35:59.460 --> 1:36:01.020\n It's very different than what you need for a robot\n\n1:36:01.020 --> 1:36:04.740\n that's gonna walk or pick things up with its hands, right?\n\n1:36:04.740 --> 1:36:09.140\n My passion has always been for the places\n\n1:36:09.140 --> 1:36:10.540\n where you're interacting more,\n\n1:36:10.540 --> 1:36:13.700\n you're doing more dynamic interactions with the world.\n\n1:36:13.700 --> 1:36:17.760\n So walking, now manipulation.\n\n1:36:18.740 --> 1:36:21.700\n And the control problems there are beautiful.\n\n1:36:21.700 --> 1:36:25.940\n I think contact is one thing that differentiates them\n\n1:36:25.940 --> 1:36:29.240\n from many of the control problems we've solved classically,\n\n1:36:29.240 --> 1:36:32.780\n right, like modern control grew up stabilizing fighter jets\n\n1:36:32.780 --> 1:36:34.060\n that were passively unstable,\n\n1:36:34.060 --> 1:36:37.020\n and there's like amazing success stories from control\n\n1:36:37.020 --> 1:36:38.080\n all over the place.\n\n1:36:39.140 --> 1:36:41.340\n Power grid, I mean, there's all kinds of,\n\n1:36:41.340 --> 1:36:44.640\n it's everywhere that we don't even realize,\n\n1:36:44.640 --> 1:36:47.540\n just like AI is now.\n\n1:36:47.540 --> 1:36:51.500\n So you mentioned contact, like what's contact?\n\n1:36:51.500 --> 1:36:54.980\n So an airplane is an extremely complex system\n\n1:36:54.980 --> 1:36:57.380\n or a spacecraft landing or whatever,\n\n1:36:57.380 --> 1:36:59.340\n but at least it has the luxury\n\n1:36:59.340 --> 1:37:03.640\n of things change relatively continuously.\n\n1:37:03.640 --> 1:37:04.940\n That's an oversimplification.\n\n1:37:04.940 --> 1:37:07.060\n But if I make a small change\n\n1:37:07.060 --> 1:37:10.140\n in the command I send to my actuator,\n\n1:37:10.140 --> 1:37:12.680\n then the path that the robot will take\n\n1:37:12.680 --> 1:37:15.860\n tends to change only by a small amount.\n\n1:37:16.820 --> 1:37:18.860\n And there's a feedback mechanism here.\n\n1:37:18.860 --> 1:37:19.700\n That's what we're talking about.\n\n1:37:19.700 --> 1:37:20.980\n And there's a feedback mechanism.\n\n1:37:20.980 --> 1:37:23.780\n And thinking about this as locally,\n\n1:37:23.780 --> 1:37:25.820\n like a linear system, for instance,\n\n1:37:25.820 --> 1:37:29.220\n I can use more linear algebra tools\n\n1:37:29.220 --> 1:37:31.340\n to study systems like that,\n\n1:37:31.340 --> 1:37:35.540\n generalizations of linear algebra to these smooth systems.\n\n1:37:36.400 --> 1:37:37.380\n What is contact?\n\n1:37:37.380 --> 1:37:41.540\n The robot has something very discontinuous\n\n1:37:41.540 --> 1:37:43.620\n that happens when it makes or breaks,\n\n1:37:43.620 --> 1:37:45.420\n when it starts touching the world.\n\n1:37:45.420 --> 1:37:48.080\n And even the way it touches or the order of contacts\n\n1:37:48.080 --> 1:37:53.080\n can change the outcome in potentially unpredictable ways.\n\n1:37:53.080 --> 1:37:55.880\n Not unpredictable, but complex ways.\n\n1:37:56.880 --> 1:37:58.680\n I do think there's a little bit of,\n\n1:38:01.440 --> 1:38:04.580\n a lot of people will say that contact is hard in robotics,\n\n1:38:04.580 --> 1:38:05.640\n even to simulate.\n\n1:38:06.360 --> 1:38:08.720\n And I think there's a little bit of a,\n\n1:38:08.720 --> 1:38:09.640\n there's truth to that,\n\n1:38:09.640 --> 1:38:12.020\n but maybe a misunderstanding around that.\n\n1:38:13.560 --> 1:38:18.560\n So what is limiting is that when we think about our robots\n\n1:38:19.600 --> 1:38:21.400\n and we write our simulators,\n\n1:38:21.400 --> 1:38:24.480\n we often make an assumption that objects are rigid.\n\n1:38:26.000 --> 1:38:30.720\n And when it comes down, that their mass moves all,\n\n1:38:30.720 --> 1:38:33.800\n stays in a constant position relative to each other itself.\n\n1:38:37.080 --> 1:38:39.360\n And that leads to some paradoxes\n\n1:38:39.360 --> 1:38:40.560\n when you go to try to talk about\n\n1:38:40.560 --> 1:38:43.200\n rigid body mechanics and contact.\n\n1:38:43.200 --> 1:38:48.200\n And so for instance, if I have a three legged stool\n\n1:38:48.200 --> 1:38:51.840\n with just imagine it comes to a point at the leg.\n\n1:38:51.840 --> 1:38:54.400\n So it's only touching the world at a point.\n\n1:38:54.400 --> 1:38:56.920\n If I draw my physics,\n\n1:38:56.920 --> 1:39:00.280\n my high school physics diagram of the system,\n\n1:39:00.280 --> 1:39:01.600\n then there's a couple of things\n\n1:39:01.600 --> 1:39:03.800\n that I'm given by elementary physics.\n\n1:39:03.800 --> 1:39:06.320\n I know if the system, if the table is at rest,\n\n1:39:06.320 --> 1:39:08.480\n if it's not moving, zero velocities,\n\n1:39:09.520 --> 1:39:11.120\n that means that the normal force,\n\n1:39:11.120 --> 1:39:13.280\n all the forces are in balance.\n\n1:39:13.280 --> 1:39:16.400\n So the force of gravity is being countered\n\n1:39:16.400 --> 1:39:20.080\n by the forces that the ground is pushing on my table legs.\n\n1:39:21.240 --> 1:39:23.880\n I also know since it's not rotating\n\n1:39:23.880 --> 1:39:25.800\n that the moments have to balance.\n\n1:39:25.800 --> 1:39:29.560\n And since it's a three dimensional table,\n\n1:39:29.560 --> 1:39:31.120\n it could fall in any direction.\n\n1:39:31.120 --> 1:39:33.040\n It actually tells me uniquely\n\n1:39:33.040 --> 1:39:35.360\n what those three normal forces have to be.\n\n1:39:37.080 --> 1:39:39.600\n If I have four legs on my table,\n\n1:39:39.600 --> 1:39:43.280\n four legged table and they were perfectly machined\n\n1:39:43.280 --> 1:39:45.360\n to be exactly the right same height\n\n1:39:45.360 --> 1:39:48.040\n and they're set down and the table's not moving,\n\n1:39:48.040 --> 1:39:51.960\n then the basic conservation laws don't tell me,\n\n1:39:51.960 --> 1:39:54.040\n there are many solutions for the forces\n\n1:39:54.040 --> 1:39:56.600\n that the ground could be putting on my legs\n\n1:39:56.600 --> 1:39:59.040\n that would still result in the table not moving.\n\n1:40:00.200 --> 1:40:03.920\n Now, the reason that seems fine, I could just pick one.\n\n1:40:03.920 --> 1:40:06.720\n But it gets funny now because if you think about friction,\n\n1:40:07.840 --> 1:40:11.000\n what we think about with friction is our standard model\n\n1:40:11.000 --> 1:40:15.880\n says the amount of force that the table will push back\n\n1:40:15.880 --> 1:40:18.000\n if I were to now try to push my table sideways,\n\n1:40:18.000 --> 1:40:19.400\n I guess I have a table here,\n\n1:40:20.880 --> 1:40:23.000\n is proportional to the normal force.\n\n1:40:24.040 --> 1:40:27.200\n So if I'm barely touching and I push, I'll slide,\n\n1:40:27.200 --> 1:40:30.440\n but if I'm pushing more and I push, I'll slide less.\n\n1:40:30.440 --> 1:40:33.720\n It's called coulomb friction is our standard model.\n\n1:40:33.720 --> 1:40:35.520\n Now, if you don't know what the normal force is\n\n1:40:35.520 --> 1:40:38.840\n on the four legs and you push the table,\n\n1:40:38.840 --> 1:40:42.400\n then you don't know what the friction forces are gonna be.\n\n1:40:43.440 --> 1:40:45.560\n And so you can't actually tell,\n\n1:40:45.560 --> 1:40:47.960\n the laws just aren't explicit yet\n\n1:40:47.960 --> 1:40:49.680\n about which way the table's gonna go.\n\n1:40:49.680 --> 1:40:51.360\n It could veer off to the left,\n\n1:40:51.360 --> 1:40:54.720\n it could veer off to the right, it could go straight.\n\n1:40:54.720 --> 1:40:58.440\n So the rigid body assumption of contact\n\n1:40:58.440 --> 1:40:59.840\n leaves us with some paradoxes,\n\n1:40:59.840 --> 1:41:02.840\n which are annoying for writing simulators\n\n1:41:02.840 --> 1:41:04.240\n and for writing controllers.\n\n1:41:04.240 --> 1:41:07.720\n We still do that sometimes because soft contact\n\n1:41:07.720 --> 1:41:11.400\n is potentially harder numerically or whatever,\n\n1:41:11.400 --> 1:41:12.920\n and the best simulators do both\n\n1:41:12.920 --> 1:41:15.240\n or do some combination of the two.\n\n1:41:15.240 --> 1:41:17.360\n But anyways, because of these kinds of paradoxes,\n\n1:41:17.360 --> 1:41:20.720\n there's all kinds of paradoxes in contact,\n\n1:41:20.720 --> 1:41:23.560\n mostly due to these rigid body assumptions.\n\n1:41:23.560 --> 1:41:27.880\n It becomes very hard to write the same kind of control laws\n\n1:41:27.880 --> 1:41:29.600\n that we've been able to be successful with\n\n1:41:29.600 --> 1:41:32.000\n for fighter jets.\n\n1:41:32.000 --> 1:41:34.560\n Like fighter jets, we haven't been as successful\n\n1:41:34.560 --> 1:41:37.440\n writing those controllers for manipulation.\n\n1:41:37.440 --> 1:41:39.160\n And so you don't know what's going to happen\n\n1:41:39.160 --> 1:41:41.480\n at the point of contact, at the moment of contact.\n\n1:41:41.480 --> 1:41:42.880\n There are situations absolutely\n\n1:41:42.880 --> 1:41:45.760\n where our laws don't tell us.\n\n1:41:45.760 --> 1:41:47.440\n So the standard approach, that's okay.\n\n1:41:47.440 --> 1:41:51.160\n I mean, instead of having a differential equation,\n\n1:41:51.160 --> 1:41:53.640\n you end up with a differential inclusion, it's called.\n\n1:41:53.640 --> 1:41:56.080\n It's a set valued equation.\n\n1:41:56.080 --> 1:41:58.320\n It says that I'm in this configuration,\n\n1:41:58.320 --> 1:42:00.000\n I have these forces applied on me.\n\n1:42:00.000 --> 1:42:03.480\n And there's a set of things that could happen, right?\n\n1:42:03.480 --> 1:42:04.320\n And you can...\n\n1:42:04.320 --> 1:42:07.480\n And those aren't continuous, I mean, what...\n\n1:42:07.480 --> 1:42:10.360\n So when you're saying like non smooth,\n\n1:42:10.360 --> 1:42:14.520\n they're not only not smooth, but this is discontinuous?\n\n1:42:14.520 --> 1:42:15.800\n The non smooth comes in\n\n1:42:15.800 --> 1:42:18.760\n when I make or break a new contact first,\n\n1:42:18.760 --> 1:42:21.200\n or when I transition from stick to slip.\n\n1:42:21.200 --> 1:42:23.520\n So you typically have static friction,\n\n1:42:23.520 --> 1:42:24.840\n and then you'll start sliding,\n\n1:42:24.840 --> 1:42:28.920\n and that'll be a discontinuous change in philosophy.\n\n1:42:28.920 --> 1:42:31.360\n In philosophy, for instance,\n\n1:42:31.360 --> 1:42:33.360\n especially if you come to rest or...\n\n1:42:33.360 --> 1:42:34.480\n That's so fascinating.\n\n1:42:34.480 --> 1:42:37.720\n Okay, so what do you do?\n\n1:42:37.720 --> 1:42:38.920\n Sorry, I interrupted you.\n\n1:42:38.920 --> 1:42:39.760\n It's fine.\n\n1:42:41.600 --> 1:42:44.160\n What's the hope under so much uncertainty\n\n1:42:44.160 --> 1:42:45.440\n about what's going to happen?\n\n1:42:45.440 --> 1:42:46.360\n What are you supposed to do?\n\n1:42:46.360 --> 1:42:48.520\n I mean, control has an answer for this.\n\n1:42:48.520 --> 1:42:50.240\n Robust control is one approach,\n\n1:42:50.240 --> 1:42:52.640\n but roughly you can write controllers\n\n1:42:52.640 --> 1:42:55.920\n which try to still perform the right task\n\n1:42:55.920 --> 1:42:58.120\n despite all the things that could possibly happen.\n\n1:42:58.120 --> 1:43:00.000\n The world might want the table to go this way and this way,\n\n1:43:00.000 --> 1:43:03.640\n but if I write a controller that pushes a little bit more\n\n1:43:03.640 --> 1:43:04.480\n and pushes a little bit,\n\n1:43:04.480 --> 1:43:08.000\n I can certainly make the table go in the direction I want.\n\n1:43:08.000 --> 1:43:10.000\n It just puts a little bit more of a burden\n\n1:43:10.000 --> 1:43:12.120\n on the control system, right?\n\n1:43:12.120 --> 1:43:15.440\n And this discontinuities do change the control system\n\n1:43:15.440 --> 1:43:19.840\n because the way we write it down right now,\n\n1:43:21.200 --> 1:43:24.320\n every different control configuration,\n\n1:43:24.320 --> 1:43:26.200\n including sticking or sliding\n\n1:43:26.200 --> 1:43:29.160\n or parts of my body that are in contact or not,\n\n1:43:29.160 --> 1:43:30.840\n looks like a different system.\n\n1:43:30.840 --> 1:43:31.880\n And I think of them,\n\n1:43:31.880 --> 1:43:34.680\n I reason about them separately or differently\n\n1:43:34.680 --> 1:43:38.000\n and the combinatorics of that blow up, right?\n\n1:43:38.000 --> 1:43:41.440\n So I just don't have enough time to compute\n\n1:43:41.440 --> 1:43:45.000\n all the possible contact configurations of my humanoid.\n\n1:43:45.000 --> 1:43:49.000\n Interestingly, I mean, I'm a humanoid.\n\n1:43:49.000 --> 1:43:52.400\n I have lots of degrees of freedom, lots of joints.\n\n1:43:52.400 --> 1:43:54.960\n I've only been around for a handful of years.\n\n1:43:54.960 --> 1:43:55.800\n It's getting up there,\n\n1:43:55.800 --> 1:43:59.200\n but I haven't had time in my life\n\n1:43:59.200 --> 1:44:02.080\n to visit all of the states in my system,\n\n1:44:03.080 --> 1:44:05.240\n certainly all the contact configurations.\n\n1:44:05.240 --> 1:44:08.320\n So if step one is to consider\n\n1:44:08.320 --> 1:44:12.160\n every possible contact configuration that I'll ever be in,\n\n1:44:12.160 --> 1:44:16.080\n that's probably not a problem I need to solve, right?\n\n1:44:17.040 --> 1:44:20.560\n Just as a small tangent, what's a contact configuration?\n\n1:44:20.560 --> 1:44:24.920\n What like, just so we can enumerate\n\n1:44:24.920 --> 1:44:26.280\n what are we talking about?\n\n1:44:26.280 --> 1:44:27.600\n How many are there?\n\n1:44:27.600 --> 1:44:30.000\n The simplest example maybe would be,\n\n1:44:30.000 --> 1:44:32.720\n imagine a robot with a flat foot.\n\n1:44:32.720 --> 1:44:35.440\n And we think about the phases of gait\n\n1:44:35.440 --> 1:44:40.000\n where the heel strikes and then the front toe strikes,\n\n1:44:40.000 --> 1:44:42.480\n and then you can heel up, toe off.\n\n1:44:43.720 --> 1:44:46.720\n Those are each different contact configurations.\n\n1:44:46.720 --> 1:44:48.320\n I only had two different contacts,\n\n1:44:48.320 --> 1:44:51.440\n but I ended up with four different contact configurations.\n\n1:44:51.440 --> 1:44:56.440\n Now, of course, my robot might actually have bumps on it\n\n1:44:57.400 --> 1:44:58.240\n or other things,\n\n1:44:58.240 --> 1:45:00.640\n so it could be much more subtle than that, right?\n\n1:45:00.640 --> 1:45:03.160\n But it's just even with one sort of box\n\n1:45:03.160 --> 1:45:06.240\n interacting with the ground already in the plane\n\n1:45:06.240 --> 1:45:07.120\n has that many, right?\n\n1:45:07.120 --> 1:45:09.440\n And if I was just even a 3D foot,\n\n1:45:09.440 --> 1:45:11.240\n then it probably my left toe might touch\n\n1:45:11.240 --> 1:45:14.360\n just before my right toe and things get subtle.\n\n1:45:14.360 --> 1:45:16.480\n Now, if I'm a dexterous hand\n\n1:45:16.480 --> 1:45:21.480\n and I go to talk about just grabbing a water bottle,\n\n1:45:22.280 --> 1:45:26.720\n if I have to enumerate every possible order\n\n1:45:26.720 --> 1:45:31.000\n that my hand came into contact with the bottle,\n\n1:45:31.000 --> 1:45:32.960\n then I'm dead in the water.\n\n1:45:32.960 --> 1:45:35.400\n Any approach that we were able to get away with that\n\n1:45:35.400 --> 1:45:38.480\n in walking because we mostly touched the ground\n\n1:45:38.480 --> 1:45:40.840\n within a small number of points, for instance,\n\n1:45:40.840 --> 1:45:43.800\n and we haven't been able to get dexterous hands that way.\n\n1:45:43.800 --> 1:45:48.800\n So you've mentioned that people think\n\n1:45:50.200 --> 1:45:52.520\n that contact is really hard\n\n1:45:52.520 --> 1:45:57.520\n and that that's the reason that robotic manipulation\n\n1:45:58.160 --> 1:46:00.560\n is problem is really hard.\n\n1:46:00.560 --> 1:46:05.560\n Is there any flaws in that thinking?\n\n1:46:06.560 --> 1:46:10.560\n So I think simulating contact is one aspect.\n\n1:46:10.560 --> 1:46:12.880\n I know people often say that we don't,\n\n1:46:12.880 --> 1:46:16.320\n that one of the reasons that we have a limit in robotics\n\n1:46:16.320 --> 1:46:19.040\n is because we do not simulate contact accurately\n\n1:46:19.040 --> 1:46:20.840\n in our simulators.\n\n1:46:20.840 --> 1:46:25.600\n And I think that is the extent to which that's true\n\n1:46:25.600 --> 1:46:27.880\n is partly because our simulators,\n\n1:46:27.880 --> 1:46:29.920\n we haven't got mature enough simulators.\n\n1:46:31.240 --> 1:46:34.120\n There are some things that are still hard, difficult,\n\n1:46:34.120 --> 1:46:35.320\n that we should change,\n\n1:46:38.200 --> 1:46:41.520\n but we actually, we know what the governing equations are.\n\n1:46:41.520 --> 1:46:44.720\n They have some foibles like this indeterminacy,\n\n1:46:44.720 --> 1:46:47.240\n but we should be able to simulate them accurately.\n\n1:46:48.600 --> 1:46:51.440\n We have incredible open source community in robotics,\n\n1:46:51.440 --> 1:46:54.360\n but it actually just takes a professional engineering team\n\n1:46:54.360 --> 1:46:57.740\n a lot of work to write a very good simulator like that.\n\n1:46:59.080 --> 1:47:02.160\n Now, where does, I believe you've written, Drake.\n\n1:47:03.280 --> 1:47:04.520\n There's a team of people.\n\n1:47:04.520 --> 1:47:07.320\n I certainly spent a lot of hours on it myself.\n\n1:47:07.320 --> 1:47:12.060\n But what is Drake and what does it take to create\n\n1:47:12.060 --> 1:47:17.060\n a simulation environment for the kind of difficult control\n\n1:47:18.200 --> 1:47:19.640\n problems we're talking about?\n\n1:47:20.740 --> 1:47:24.640\n Right, so Drake is the simulator that I've been working on.\n\n1:47:24.640 --> 1:47:26.780\n There are other good simulators out there.\n\n1:47:26.780 --> 1:47:29.680\n I don't like to think of Drake as just a simulator\n\n1:47:29.680 --> 1:47:31.780\n because we write our controllers in Drake,\n\n1:47:31.780 --> 1:47:34.360\n we write our perception systems a little bit in Drake,\n\n1:47:34.360 --> 1:47:37.040\n but we write all of our low level control\n\n1:47:37.040 --> 1:47:40.840\n and even planning and optimization.\n\n1:47:40.840 --> 1:47:42.480\n So it has optimization capabilities as well?\n\n1:47:42.480 --> 1:47:43.640\n Absolutely, yeah.\n\n1:47:43.640 --> 1:47:46.000\n I mean, Drake is three things roughly.\n\n1:47:46.000 --> 1:47:49.800\n It's an optimization library, which is sits on,\n\n1:47:49.800 --> 1:47:54.240\n it provides a layer of abstraction in C++ and Python\n\n1:47:54.240 --> 1:47:55.920\n for commercial solvers.\n\n1:47:55.920 --> 1:48:00.760\n You can write linear programs, quadratic programs,\n\n1:48:00.760 --> 1:48:03.340\n semi definite programs, sums of squares programs,\n\n1:48:03.340 --> 1:48:05.660\n the ones we've used, mixed integer programs,\n\n1:48:05.660 --> 1:48:07.960\n and it will do the work to curate those\n\n1:48:07.960 --> 1:48:10.360\n and send them to whatever the right solver is for instance,\n\n1:48:10.360 --> 1:48:12.500\n and it provides a level of abstraction.\n\n1:48:13.720 --> 1:48:18.360\n The second thing is a system modeling language,\n\n1:48:18.360 --> 1:48:20.880\n a bit like LabVIEW or Simulink,\n\n1:48:20.880 --> 1:48:24.840\n where you can make block diagrams out of complex systems,\n\n1:48:24.840 --> 1:48:26.640\n or it's like ROS in that sense,\n\n1:48:26.640 --> 1:48:29.040\n where you might have lots of ROS nodes\n\n1:48:29.040 --> 1:48:31.960\n that are each doing some part of your system,\n\n1:48:31.960 --> 1:48:36.560\n but to contrast it with ROS, we try to write,\n\n1:48:36.560 --> 1:48:38.960\n if you write a Drake system, then you have to,\n\n1:48:40.120 --> 1:48:43.000\n it asks you to describe a little bit more about the system.\n\n1:48:43.000 --> 1:48:46.240\n If you have any state, for instance, in the system,\n\n1:48:46.240 --> 1:48:47.680\n any variables that are gonna persist,\n\n1:48:47.680 --> 1:48:49.120\n you have to declare them.\n\n1:48:49.120 --> 1:48:51.620\n Parameters can be declared and the like,\n\n1:48:51.620 --> 1:48:54.160\n but the advantage of doing that is that you can,\n\n1:48:54.160 --> 1:48:57.460\n if you like, run things all on one process,\n\n1:48:57.460 --> 1:49:00.200\n but you can also do control design against it.\n\n1:49:00.200 --> 1:49:03.120\n You can do, I mean, simple things like rewinding\n\n1:49:03.120 --> 1:49:07.960\n and playing back your simulations, for instance,\n\n1:49:07.960 --> 1:49:09.600\n these things, you get some rewards\n\n1:49:09.600 --> 1:49:11.380\n for spending a little bit more upfront cost\n\n1:49:11.380 --> 1:49:13.320\n in describing each system.\n\n1:49:13.320 --> 1:49:16.920\n And I was inspired to do that\n\n1:49:16.920 --> 1:49:20.340\n because I think the complexity of Atlas, for instance,\n\n1:49:21.260 --> 1:49:22.600\n is just so great.\n\n1:49:22.600 --> 1:49:24.140\n And I think, although, I mean,\n\n1:49:24.140 --> 1:49:27.520\n ROS has been an incredible, absolutely huge fan\n\n1:49:27.520 --> 1:49:30.720\n of what it's done for the robotics community,\n\n1:49:30.720 --> 1:49:35.480\n but the ability to rapidly put different pieces together\n\n1:49:35.480 --> 1:49:37.960\n and have a functioning thing is very good.\n\n1:49:38.960 --> 1:49:42.880\n But I do think that it's hard to think clearly\n\n1:49:42.880 --> 1:49:45.000\n about a bag of disparate parts,\n\n1:49:45.000 --> 1:49:48.160\n Mr. Potato Head kind of software stack.\n\n1:49:48.160 --> 1:49:53.060\n And if you can ask a little bit more\n\n1:49:53.060 --> 1:49:54.200\n out of each of those parts,\n\n1:49:54.200 --> 1:49:56.120\n then you can understand the way they work better.\n\n1:49:56.120 --> 1:49:59.280\n You can try to verify them and the like,\n\n1:50:00.160 --> 1:50:02.680\n or you can do learning against them.\n\n1:50:02.680 --> 1:50:04.760\n And then one of those systems, the last thing,\n\n1:50:04.760 --> 1:50:06.480\n I said the first two things that Drake is,\n\n1:50:06.480 --> 1:50:09.680\n but the last thing is that there is a set\n\n1:50:09.680 --> 1:50:12.560\n of multi body equations, rigid body equations,\n\n1:50:12.560 --> 1:50:16.760\n that is trying to provide a system that simulates physics.\n\n1:50:16.760 --> 1:50:20.060\n And we also have renderers and other things,\n\n1:50:20.060 --> 1:50:23.300\n but I think the physics component of Drake is special\n\n1:50:23.300 --> 1:50:27.740\n in the sense that we have done excessive amount\n\n1:50:27.740 --> 1:50:29.840\n of engineering to make sure\n\n1:50:29.840 --> 1:50:31.580\n that we've written the equations correctly.\n\n1:50:31.580 --> 1:50:34.160\n Every possible tumbling satellite or spinning top\n\n1:50:34.160 --> 1:50:37.160\n or anything that we could possibly write as a test is tested.\n\n1:50:38.300 --> 1:50:42.000\n We are making some, I think, fundamental improvements\n\n1:50:42.000 --> 1:50:44.240\n on the way you simulate contact.\n\n1:50:44.240 --> 1:50:47.600\n Just what does it take to simulate contact?\n\n1:50:47.600 --> 1:50:49.120\n I mean, it just seems,\n\n1:50:50.920 --> 1:50:52.400\n I mean, there's something just beautiful\n\n1:50:52.400 --> 1:50:55.240\n to the way you were like explaining contact\n\n1:50:55.240 --> 1:50:56.720\n and you were like tapping your fingers\n\n1:50:56.720 --> 1:51:00.720\n on the table while you're doing it, just.\n\n1:51:00.720 --> 1:51:01.560\n Easily, right?\n\n1:51:01.560 --> 1:51:04.800\n Easily, just like, just not even like,\n\n1:51:04.800 --> 1:51:06.800\n it was like helping you think, I guess.\n\n1:51:10.640 --> 1:51:12.280\n So you have this like awesome demo\n\n1:51:12.280 --> 1:51:15.680\n of loading or unloading a dishwasher,\n\n1:51:16.720 --> 1:51:18.840\n just picking up a plate,\n\n1:51:18.840 --> 1:51:23.840\n or grasping it like for the first time.\n\n1:51:26.120 --> 1:51:28.180\n That's just seems like so difficult.\n\n1:51:29.440 --> 1:51:32.400\n What, how do you simulate any of that?\n\n1:51:33.600 --> 1:51:35.840\n So it was really interesting that what happened was\n\n1:51:35.840 --> 1:51:39.200\n that we started getting more professional\n\n1:51:39.200 --> 1:51:40.520\n about our software development\n\n1:51:40.520 --> 1:51:42.280\n during the DARPA Robotics Challenge.\n\n1:51:43.360 --> 1:51:46.040\n I learned the value of software engineering\n\n1:51:46.040 --> 1:51:48.640\n and how these, how to bridle complexity.\n\n1:51:48.640 --> 1:51:52.800\n I guess that's what I want to somehow fight against\n\n1:51:52.800 --> 1:51:54.760\n and bring some of the clear thinking of controls\n\n1:51:54.760 --> 1:51:58.220\n into these complex systems we're building for robots.\n\n1:52:00.460 --> 1:52:02.940\n Shortly after the DARPA Robotics Challenge,\n\n1:52:02.940 --> 1:52:04.600\n Toyota opened a research institute,\n\n1:52:04.600 --> 1:52:07.260\n TRI, Toyota Research Institute.\n\n1:52:08.200 --> 1:52:10.880\n They put one of their, there's three locations.\n\n1:52:10.880 --> 1:52:13.040\n One of them is just down the street from MIT.\n\n1:52:13.040 --> 1:52:17.520\n And I helped ramp that up right up\n\n1:52:17.520 --> 1:52:20.860\n as a part of my, the end of my sabbatical, I guess.\n\n1:52:23.480 --> 1:52:28.480\n So TRI has given me, the TRI robotics effort\n\n1:52:29.480 --> 1:52:32.640\n has made this investment in simulation in Drake.\n\n1:52:32.640 --> 1:52:34.480\n And Michael Sherman leads a team there\n\n1:52:34.480 --> 1:52:37.800\n of just absolutely top notch dynamics experts\n\n1:52:37.800 --> 1:52:40.120\n that are trying to write those simulators\n\n1:52:40.120 --> 1:52:41.960\n that can pick up the dishes.\n\n1:52:41.960 --> 1:52:44.780\n And there's also a team working on manipulation there\n\n1:52:44.780 --> 1:52:48.980\n that is taking problems like loading the dishwasher.\n\n1:52:48.980 --> 1:52:53.180\n And we're using that to study these really hard corner cases\n\n1:52:53.180 --> 1:52:55.280\n kind of problems in manipulation.\n\n1:52:55.280 --> 1:52:59.760\n So for me, this, you know, simulating the dishes,\n\n1:52:59.760 --> 1:53:01.580\n we could actually write a controller.\n\n1:53:01.580 --> 1:53:05.040\n If we just cared about picking up dishes in the sink once,\n\n1:53:05.040 --> 1:53:05.880\n we could write a controller\n\n1:53:05.880 --> 1:53:07.760\n without any simulation whatsoever,\n\n1:53:07.760 --> 1:53:10.040\n and we could call it done.\n\n1:53:10.040 --> 1:53:12.140\n But we want to understand like,\n\n1:53:12.140 --> 1:53:17.040\n what is the path you take to actually get to a robot\n\n1:53:17.040 --> 1:53:22.040\n that could perform that for any dish in anybody's kitchen\n\n1:53:22.120 --> 1:53:23.280\n with enough confidence\n\n1:53:23.280 --> 1:53:26.520\n that it could be a commercial product, right?\n\n1:53:26.520 --> 1:53:29.360\n And it has deep learning perception in the loop.\n\n1:53:29.360 --> 1:53:31.040\n It has complex dynamics in the loop.\n\n1:53:31.040 --> 1:53:33.240\n It has controller, it has a planner.\n\n1:53:33.240 --> 1:53:36.320\n And how do you take all of that complexity\n\n1:53:36.320 --> 1:53:39.020\n and put it through this engineering discipline\n\n1:53:39.020 --> 1:53:42.440\n and verification and validation process\n\n1:53:42.440 --> 1:53:46.440\n to actually get enough confidence to deploy?\n\n1:53:46.440 --> 1:53:49.840\n I mean, the DARPA challenge made me realize\n\n1:53:49.840 --> 1:53:52.000\n that that's not something you throw over the fence\n\n1:53:52.000 --> 1:53:54.080\n and hope that somebody will harden it for you,\n\n1:53:54.080 --> 1:53:57.380\n that there are really fundamental challenges\n\n1:53:57.380 --> 1:53:59.840\n in closing that last gap.\n\n1:53:59.840 --> 1:54:02.340\n They're doing the validation and the testing.\n\n1:54:03.520 --> 1:54:06.780\n I think it might even change the way we have to think about\n\n1:54:06.780 --> 1:54:09.580\n the way we write systems.\n\n1:54:09.580 --> 1:54:14.200\n What happens if you have the robot running lots of tests\n\n1:54:15.560 --> 1:54:19.040\n and it screws up, it breaks a dish, right?\n\n1:54:19.040 --> 1:54:19.960\n How do you capture that?\n\n1:54:19.960 --> 1:54:23.580\n I said, you can't run the same simulation\n\n1:54:23.580 --> 1:54:27.020\n or the same experiment twice on a real robot.\n\n1:54:27.920 --> 1:54:31.520\n Do we have to be able to bring that one off failure\n\n1:54:31.520 --> 1:54:32.640\n back into simulation\n\n1:54:32.640 --> 1:54:35.120\n in order to change our controllers, study it,\n\n1:54:35.120 --> 1:54:37.240\n make sure it won't happen again?\n\n1:54:37.240 --> 1:54:40.600\n Do we, is it enough to just try to add that\n\n1:54:40.600 --> 1:54:43.800\n to our distribution and understand that on average,\n\n1:54:43.800 --> 1:54:45.920\n we're gonna cover that situation again?\n\n1:54:45.920 --> 1:54:49.960\n There's like really subtle questions at the corner cases\n\n1:54:49.960 --> 1:54:53.240\n that I think we don't yet have satisfying answers for.\n\n1:54:53.240 --> 1:54:55.120\n Like how do you find the corner cases?\n\n1:54:55.120 --> 1:54:57.160\n That's one kind of, is there,\n\n1:54:57.160 --> 1:55:01.260\n do you think that's possible to create a systematized way\n\n1:55:01.260 --> 1:55:04.720\n of discovering corner cases efficiently?\n\n1:55:04.720 --> 1:55:05.560\n Yes.\n\n1:55:05.560 --> 1:55:07.600\n In whatever the problem is?\n\n1:55:07.600 --> 1:55:10.760\n Yes, I mean, I think we have to get better at that.\n\n1:55:10.760 --> 1:55:14.920\n I mean, control theory has for decades\n\n1:55:14.920 --> 1:55:16.920\n talked about active experiment design.\n\n1:55:17.840 --> 1:55:18.680\n What's that?\n\n1:55:19.560 --> 1:55:22.080\n So people call it curiosity these days.\n\n1:55:22.080 --> 1:55:24.800\n It's roughly this idea of trying to exploration\n\n1:55:24.800 --> 1:55:27.600\n or exploitation, but in the active experiment design\n\n1:55:27.600 --> 1:55:29.640\n is even, is more specific.\n\n1:55:29.640 --> 1:55:34.120\n You could try to understand the uncertainty in your system,\n\n1:55:34.120 --> 1:55:36.480\n design the experiment that will provide\n\n1:55:36.480 --> 1:55:40.120\n the maximum information to reduce that uncertainty.\n\n1:55:40.120 --> 1:55:42.360\n If there's a parameter you wanna learn about,\n\n1:55:42.360 --> 1:55:45.440\n what is the optimal trajectory I could execute\n\n1:55:45.440 --> 1:55:47.640\n to learn about that parameter, for instance.\n\n1:55:49.520 --> 1:55:51.720\n Scaling that up to something that has a deep network\n\n1:55:51.720 --> 1:55:55.660\n in the loop and a planning in the loop is tough.\n\n1:55:55.660 --> 1:55:58.200\n We've done some work on, you know,\n\n1:55:58.200 --> 1:56:00.280\n with Matt Okely and Aman Sinha,\n\n1:56:00.280 --> 1:56:03.600\n we've worked on some falsification algorithms\n\n1:56:03.600 --> 1:56:05.600\n that are trying to do rare event simulation\n\n1:56:05.600 --> 1:56:08.120\n that try to just hammer on your simulator.\n\n1:56:08.120 --> 1:56:10.000\n And if your simulator is good enough,\n\n1:56:10.000 --> 1:56:13.840\n you can spend a lot of time,\n\n1:56:13.840 --> 1:56:15.840\n or you can write good algorithms\n\n1:56:15.840 --> 1:56:19.920\n that try to spend most of their time in the corner cases.\n\n1:56:19.920 --> 1:56:24.920\n So you basically imagine you're building an autonomous car\n\n1:56:25.880 --> 1:56:27.360\n and you wanna put it in, I don't know,\n\n1:56:27.360 --> 1:56:29.400\n downtown New Delhi all the time, right?\n\n1:56:29.400 --> 1:56:30.760\n And accelerated testing.\n\n1:56:31.640 --> 1:56:33.340\n If you can write sampling strategies,\n\n1:56:33.340 --> 1:56:35.400\n which figure out where your controller's\n\n1:56:35.400 --> 1:56:37.440\n performing badly in simulation\n\n1:56:37.440 --> 1:56:40.600\n and start generating lots of examples around that.\n\n1:56:40.600 --> 1:56:44.060\n You know, it's just the space of possible places\n\n1:56:44.060 --> 1:56:48.040\n where that can be, where things can go wrong is very big.\n\n1:56:48.040 --> 1:56:49.800\n So it's hard to write those algorithms.\n\n1:56:49.800 --> 1:56:51.720\n Yeah, rare event simulation\n\n1:56:51.720 --> 1:56:55.760\n is just a really compelling notion, if it's possible.\n\n1:56:55.760 --> 1:56:58.600\n We joked and we call it the black swan generator.\n\n1:56:58.600 --> 1:57:00.080\n It's a black swan.\n\n1:57:00.080 --> 1:57:01.680\n Because you don't just want the rare events,\n\n1:57:01.680 --> 1:57:04.020\n you want the ones that are highly impactful.\n\n1:57:04.020 --> 1:57:05.680\n I mean, that's the most,\n\n1:57:06.560 --> 1:57:08.780\n those are the most sort of profound questions\n\n1:57:08.780 --> 1:57:10.120\n we ask of our world.\n\n1:57:10.120 --> 1:57:15.120\n Like, what's the worst that can happen?\n\n1:57:16.720 --> 1:57:18.080\n But what we're really asking\n\n1:57:18.080 --> 1:57:20.800\n isn't some kind of like computer science,\n\n1:57:20.800 --> 1:57:22.560\n worst case analysis.\n\n1:57:22.560 --> 1:57:25.600\n We're asking like, what are the millions of ways\n\n1:57:25.600 --> 1:57:27.360\n this can go wrong?\n\n1:57:27.360 --> 1:57:29.500\n And that's like our curiosity.\n\n1:57:29.500 --> 1:57:34.500\n And we humans, I think are pretty bad at,\n\n1:57:34.900 --> 1:57:36.980\n we just like run into it.\n\n1:57:36.980 --> 1:57:38.580\n And I think there's a distributed sense\n\n1:57:38.580 --> 1:57:41.620\n because there's now like 7.5 billion of us.\n\n1:57:41.620 --> 1:57:42.860\n And so there's a lot of them.\n\n1:57:42.860 --> 1:57:45.060\n And then a lot of them write blog posts\n\n1:57:45.060 --> 1:57:46.540\n about the stupid thing they've done.\n\n1:57:46.540 --> 1:57:48.900\n So we learn in a distributed way.\n\n1:57:49.980 --> 1:57:50.820\n There's some.\n\n1:57:50.820 --> 1:57:53.380\n I think that's gonna be important for robots too.\n\n1:57:53.380 --> 1:57:55.940\n I mean, that's another massive theme\n\n1:57:55.940 --> 1:57:58.800\n at Toyota Research for Robotics\n\n1:57:58.800 --> 1:58:00.540\n is this fleet learning concept\n\n1:58:00.540 --> 1:58:04.780\n is the idea that I, as a human,\n\n1:58:04.780 --> 1:58:07.880\n I don't have enough time to visit all of my states, right?\n\n1:58:07.880 --> 1:58:10.140\n There's just a, it's very hard for one robot\n\n1:58:10.140 --> 1:58:11.580\n to experience all the things.\n\n1:58:12.640 --> 1:58:15.540\n But that's not actually the problem we have to solve, right?\n\n1:58:16.540 --> 1:58:17.700\n We're gonna have fleets of robots\n\n1:58:17.700 --> 1:58:20.660\n that can have very similar appendages.\n\n1:58:20.660 --> 1:58:24.160\n And at some point, maybe collectively,\n\n1:58:24.160 --> 1:58:26.220\n they have enough data\n\n1:58:26.220 --> 1:58:29.340\n that their computational processes\n\n1:58:29.340 --> 1:58:31.860\n should be set up differently than ours, right?\n\n1:58:31.860 --> 1:58:34.180\n It's this vision of just,\n\n1:58:34.180 --> 1:58:38.880\n I mean, all these dishwasher unloading robots.\n\n1:58:38.880 --> 1:58:42.580\n I mean, that robot dropping a plate\n\n1:58:42.580 --> 1:58:46.860\n and a human looking at the robot probably pissed off.\n\n1:58:46.860 --> 1:58:47.820\n Yeah.\n\n1:58:47.820 --> 1:58:51.220\n But that's a special moment to record.\n\n1:58:51.220 --> 1:58:54.500\n I think one thing in terms of fleet learning,\n\n1:58:54.500 --> 1:58:57.740\n and I've seen that because I've talked to a lot of folks,\n\n1:58:57.740 --> 1:59:01.220\n just like Tesla users or Tesla drivers,\n\n1:59:01.220 --> 1:59:02.980\n they're another company\n\n1:59:02.980 --> 1:59:05.300\n that's using this kind of fleet learning idea.\n\n1:59:05.300 --> 1:59:08.220\n One hopeful thing I have about humans\n\n1:59:08.220 --> 1:59:13.220\n is they really enjoy when a system improves, learns.\n\n1:59:13.260 --> 1:59:14.680\n So they enjoy fleet learning.\n\n1:59:14.680 --> 1:59:17.260\n And the reason it's hopeful for me\n\n1:59:17.260 --> 1:59:20.300\n is they're willing to put up with something\n\n1:59:20.300 --> 1:59:22.660\n that's kind of dumb right now.\n\n1:59:22.660 --> 1:59:25.540\n And they're like, if it's improving,\n\n1:59:25.540 --> 1:59:29.460\n they almost like enjoy being part of the, like teaching it.\n\n1:59:29.460 --> 1:59:30.960\n Almost like if you have kids,\n\n1:59:30.960 --> 1:59:33.540\n like you're teaching them something, right?\n\n1:59:33.540 --> 1:59:35.140\n I think that's a beautiful thing\n\n1:59:35.140 --> 1:59:36.300\n because that gives me hope\n\n1:59:36.300 --> 1:59:38.720\n that we can put dumb robots out there.\n\n1:59:40.100 --> 1:59:43.340\n I mean, the problem on the Tesla side with cars,\n\n1:59:43.340 --> 1:59:45.320\n cars can kill you.\n\n1:59:45.320 --> 1:59:47.740\n That makes the problem so much harder.\n\n1:59:47.740 --> 1:59:50.580\n Dishwasher unloading is a little safe.\n\n1:59:50.580 --> 1:59:54.220\n That's why home robotics is really exciting.\n\n1:59:54.220 --> 1:59:57.580\n And just to clarify, I mean, for people who might not know,\n\n1:59:57.580 --> 2:00:00.100\n I mean, TRI, Toyota Research Institute.\n\n2:00:00.100 --> 2:00:03.980\n So they're, I mean, they're pretty well known\n\n2:00:03.980 --> 2:00:06.140\n for like autonomous vehicle research,\n\n2:00:06.140 --> 2:00:10.260\n but they're also interested in home robotics.\n\n2:00:10.260 --> 2:00:12.780\n Yep, there's a big group working on,\n\n2:00:12.780 --> 2:00:14.340\n multiple groups working on home robotics.\n\n2:00:14.340 --> 2:00:17.480\n It's a major part of the portfolio.\n\n2:00:17.480 --> 2:00:19.100\n There's also a couple other projects\n\n2:00:19.100 --> 2:00:21.300\n in advanced materials discovery,\n\n2:00:21.300 --> 2:00:24.420\n using AI and machine learning to discover new materials\n\n2:00:24.420 --> 2:00:28.540\n for car batteries and the like, for instance, yeah.\n\n2:00:28.540 --> 2:00:31.500\n And that's been actually an incredibly successful team.\n\n2:00:31.500 --> 2:00:33.540\n There's new projects starting up too, so.\n\n2:00:33.540 --> 2:00:38.540\n Do you see a future of where like robots are in our home\n\n2:00:38.940 --> 2:00:43.940\n and like robots that have like actuators\n\n2:00:44.040 --> 2:00:46.620\n that look like arms in our home\n\n2:00:46.620 --> 2:00:49.340\n or like, you know, more like humanoid type robots?\n\n2:00:49.340 --> 2:00:51.820\n Or is this, are we gonna do the same thing\n\n2:00:51.820 --> 2:00:53.860\n that you just mentioned that, you know,\n\n2:00:53.860 --> 2:00:55.980\n the dishwasher is no longer a robot.\n\n2:00:55.980 --> 2:00:58.700\n We're going to just not even see them as robots.\n\n2:00:58.700 --> 2:01:02.500\n But I mean, what's your vision of the home of the future\n\n2:01:02.500 --> 2:01:06.220\n 10, 20 years from now, 50 years, if you get crazy?\n\n2:01:06.220 --> 2:01:10.720\n Yeah, I think we already have Roombas cruising around.\n\n2:01:10.720 --> 2:01:13.700\n We have, you know, Alexis or Google Homes\n\n2:01:13.700 --> 2:01:16.240\n on our kitchen counter.\n\n2:01:16.240 --> 2:01:18.060\n It's only a matter of time until they spring arms\n\n2:01:18.060 --> 2:01:20.780\n and start doing something useful like that.\n\n2:01:21.860 --> 2:01:23.860\n So I do think it's coming.\n\n2:01:23.860 --> 2:01:27.660\n I think lots of people have lots of motivations\n\n2:01:27.660 --> 2:01:29.380\n for doing it.\n\n2:01:29.380 --> 2:01:31.520\n It's been super interesting actually learning\n\n2:01:31.520 --> 2:01:33.900\n about Toyota's vision for it,\n\n2:01:33.900 --> 2:01:36.380\n which is about helping people age in place.\n\n2:01:38.700 --> 2:01:41.620\n Cause I think that's not necessarily the first entry,\n\n2:01:41.620 --> 2:01:44.340\n the most lucrative entry point,\n\n2:01:44.340 --> 2:01:48.680\n but it's the problem maybe that we really need to solve\n\n2:01:48.680 --> 2:01:50.020\n no matter what.\n\n2:01:50.020 --> 2:01:53.900\n And so I think there's a real opportunity.\n\n2:01:53.900 --> 2:01:55.740\n It's a delicate problem.\n\n2:01:55.740 --> 2:01:59.340\n How do you work with people, help people,\n\n2:01:59.340 --> 2:02:02.320\n keep them active, engaged, you know,\n\n2:02:03.300 --> 2:02:05.060\n but improve their quality of life\n\n2:02:05.060 --> 2:02:08.340\n and help them age in place, for instance.\n\n2:02:08.340 --> 2:02:12.440\n It's interesting because older folks are also,\n\n2:02:12.440 --> 2:02:13.700\n I mean, there's a contrast there\n\n2:02:13.700 --> 2:02:18.080\n because they're not always the folks\n\n2:02:18.080 --> 2:02:20.900\n who are the most comfortable with technology, for example.\n\n2:02:20.900 --> 2:02:24.860\n So there's a division that's interesting.\n\n2:02:24.860 --> 2:02:29.860\n You can do so much good with a robot for older folks,\n\n2:02:32.020 --> 2:02:36.380\n but there's a gap to fill of understanding.\n\n2:02:36.380 --> 2:02:38.380\n I mean, it's actually kind of beautiful.\n\n2:02:39.360 --> 2:02:41.140\n Robot is learning about the human\n\n2:02:41.140 --> 2:02:44.820\n and the human is kind of learning about this new robot thing.\n\n2:02:44.820 --> 2:02:49.660\n And it's also with, at least with,\n\n2:02:49.660 --> 2:02:51.460\n like when I talked to my parents about robots,\n\n2:02:51.460 --> 2:02:54.540\n there's a little bit of a blank slate there too.\n\n2:02:54.540 --> 2:02:58.020\n Like you can, I mean, they don't know anything\n\n2:02:58.020 --> 2:03:02.640\n about robotics, so it's completely like wide open.\n\n2:03:02.640 --> 2:03:03.880\n They don't have, they haven't,\n\n2:03:03.880 --> 2:03:05.780\n my parents haven't seen Black Mirror.\n\n2:03:06.780 --> 2:03:09.460\n So like they, it's a blank slate.\n\n2:03:09.460 --> 2:03:11.980\n Here's a cool thing, like what can it do for me?\n\n2:03:11.980 --> 2:03:14.380\n Yeah, so it's an exciting space.\n\n2:03:14.380 --> 2:03:16.340\n I think it's a really important space.\n\n2:03:16.340 --> 2:03:20.020\n I do feel like a few years ago,\n\n2:03:20.020 --> 2:03:22.740\n drones were successful enough in academia.\n\n2:03:22.740 --> 2:03:25.980\n They kind of broke out and started an industry\n\n2:03:25.980 --> 2:03:29.100\n and autonomous cars have been happening.\n\n2:03:29.100 --> 2:03:32.900\n It does feel like manipulation in logistics, of course,\n\n2:03:32.900 --> 2:03:35.700\n first, but in the home shortly after,\n\n2:03:35.700 --> 2:03:37.180\n seems like one of the next big things\n\n2:03:37.180 --> 2:03:40.060\n that's gonna really pop.\n\n2:03:40.060 --> 2:03:42.100\n So I don't think we talked about it,\n\n2:03:42.100 --> 2:03:44.540\n but what's soft robotics?\n\n2:03:44.540 --> 2:03:49.300\n So we talked about like rigid bodies.\n\n2:03:49.300 --> 2:03:52.020\n Like if we can just linger on this whole touch thing.\n\n2:03:52.940 --> 2:03:54.620\n Yeah, so what's soft robotics?\n\n2:03:54.620 --> 2:03:59.620\n So I told you that I really dislike the fact\n\n2:04:00.780 --> 2:04:03.140\n that robots are afraid of touching the world\n\n2:04:03.140 --> 2:04:04.860\n all over their body.\n\n2:04:04.860 --> 2:04:06.900\n So there's a couple reasons for that.\n\n2:04:06.900 --> 2:04:08.740\n If you look carefully at all the places\n\n2:04:08.740 --> 2:04:11.220\n that robots actually do touch the world,\n\n2:04:11.220 --> 2:04:12.540\n they're almost always soft.\n\n2:04:12.540 --> 2:04:14.700\n They have some sort of pad on their fingers\n\n2:04:14.700 --> 2:04:16.900\n or a rubber sole on their foot.\n\n2:04:17.900 --> 2:04:19.300\n But if you look up and down the arm,\n\n2:04:19.300 --> 2:04:21.700\n we're just pure aluminum or something.\n\n2:04:25.340 --> 2:04:26.660\n So that makes it hard actually.\n\n2:04:26.660 --> 2:04:30.460\n In fact, hitting the table with your rigid arm\n\n2:04:30.460 --> 2:04:34.580\n or nearly rigid arm has some of the problems\n\n2:04:34.580 --> 2:04:37.260\n that we talked about in terms of simulation.\n\n2:04:37.260 --> 2:04:39.940\n I think it fundamentally changes the mechanics of contact\n\n2:04:39.940 --> 2:04:41.260\n when you're soft, right?\n\n2:04:41.260 --> 2:04:45.020\n You turn point contacts into patch contacts,\n\n2:04:45.020 --> 2:04:47.020\n which can have torsional friction.\n\n2:04:47.020 --> 2:04:49.260\n You can have distributed load.\n\n2:04:49.260 --> 2:04:52.460\n If I wanna pick up an egg, right?\n\n2:04:52.460 --> 2:04:54.300\n If I pick it up with two points,\n\n2:04:54.300 --> 2:04:56.220\n then in order to put enough force\n\n2:04:56.220 --> 2:04:57.340\n to sustain the weight of the egg,\n\n2:04:57.340 --> 2:04:59.980\n I might have to put a lot of force to break the egg.\n\n2:04:59.980 --> 2:05:04.460\n If I envelop it with contact all around,\n\n2:05:04.460 --> 2:05:07.540\n then I can distribute my force across the shell of the egg\n\n2:05:07.540 --> 2:05:10.620\n and have a better chance of not breaking it.\n\n2:05:10.620 --> 2:05:12.860\n So soft robotics is for me a lot about changing\n\n2:05:12.860 --> 2:05:15.500\n the mechanics of contact.\n\n2:05:15.500 --> 2:05:17.380\n Does it make the problem a lot harder?\n\n2:05:19.380 --> 2:05:22.260\n Quite the opposite.\n\n2:05:24.020 --> 2:05:26.740\n It changes the computational problem.\n\n2:05:26.740 --> 2:05:30.460\n I think because of the, I think our world\n\n2:05:30.460 --> 2:05:34.180\n and our mathematics has biased us towards rigid.\n\n2:05:34.180 --> 2:05:35.020\n I see.\n\n2:05:35.020 --> 2:05:37.620\n But it really should make things better in some ways, right?\n\n2:05:40.740 --> 2:05:43.060\n I think the future is unwritten there.\n\n2:05:44.620 --> 2:05:45.460\n But the other thing it can do.\n\n2:05:45.460 --> 2:05:46.820\n I think ultimately, sorry to interrupt,\n\n2:05:46.820 --> 2:05:49.540\n but I think ultimately it will make things simpler\n\n2:05:49.540 --> 2:05:51.580\n if we embrace the softness of the world.\n\n2:05:51.580 --> 2:05:55.740\n It makes things smoother, right?\n\n2:05:55.740 --> 2:06:00.740\n So the result of small actions is less discontinuous,\n\n2:06:00.740 --> 2:06:05.740\n but it also means potentially less instantaneously bad.\n\n2:06:05.980 --> 2:06:09.060\n For instance, I won't necessarily contact something\n\n2:06:09.060 --> 2:06:10.420\n and send it flying off.\n\n2:06:12.300 --> 2:06:13.140\n The other aspect of it\n\n2:06:13.140 --> 2:06:14.860\n that just happens to dovetail really well\n\n2:06:14.860 --> 2:06:17.260\n is that soft robotics tends to be a place\n\n2:06:17.260 --> 2:06:19.100\n where we can embed a lot of sensors too.\n\n2:06:19.100 --> 2:06:23.540\n So if you change your hardware and make it more soft,\n\n2:06:23.540 --> 2:06:25.620\n then you can potentially have a tactile sensor,\n\n2:06:25.620 --> 2:06:27.820\n which is measuring the deformation.\n\n2:06:27.820 --> 2:06:32.180\n So there's a team at TRI that's working on soft hands\n\n2:06:32.180 --> 2:06:35.500\n and you get so much more information.\n\n2:06:35.500 --> 2:06:38.820\n You can put a camera behind the skin roughly\n\n2:06:38.820 --> 2:06:42.860\n and get fantastic tactile information,\n\n2:06:42.860 --> 2:06:46.180\n which is, it's super important.\n\n2:06:46.180 --> 2:06:47.020\n Like in manipulation,\n\n2:06:47.020 --> 2:06:49.820\n one of the things that really is frustrating\n\n2:06:49.820 --> 2:06:52.140\n is if you work super hard on your head mounted,\n\n2:06:52.140 --> 2:06:54.540\n on your perception system for your head mounted cameras,\n\n2:06:54.540 --> 2:06:56.060\n and then you get a lot of information\n\n2:06:56.060 --> 2:06:57.700\n for your head mounted cameras,\n\n2:06:57.700 --> 2:06:59.460\n and then you've identified an object,\n\n2:06:59.460 --> 2:07:00.380\n you reach down to touch it,\n\n2:07:00.380 --> 2:07:01.900\n and the last thing that happens,\n\n2:07:01.900 --> 2:07:03.980\n right before the most important time,\n\n2:07:03.980 --> 2:07:04.820\n you stick your hand\n\n2:07:04.820 --> 2:07:07.380\n and you're occluding your head mounted sensors.\n\n2:07:07.380 --> 2:07:10.220\n So in all the part that really matters,\n\n2:07:10.220 --> 2:07:13.580\n all of your off board sensors are occluded.\n\n2:07:13.580 --> 2:07:15.900\n And really, if you don't have tactile information,\n\n2:07:15.900 --> 2:07:19.300\n then you're blind in an important way.\n\n2:07:19.300 --> 2:07:23.140\n So it happens that soft robotics and tactile sensing\n\n2:07:23.140 --> 2:07:25.100\n tend to go hand in hand.\n\n2:07:25.100 --> 2:07:26.820\n I think we've kind of talked about it,\n\n2:07:26.820 --> 2:07:31.060\n but you taught a course on underactuated robotics.\n\n2:07:31.060 --> 2:07:32.780\n I believe that was the name of it, actually.\n\n2:07:32.780 --> 2:07:33.620\n That's right.\n\n2:07:34.980 --> 2:07:37.340\n Can you talk about it in that context?\n\n2:07:37.340 --> 2:07:40.380\n What is underactuated robotics?\n\n2:07:40.380 --> 2:07:43.740\n Right, so underactuated robotics is my graduate course.\n\n2:07:43.740 --> 2:07:46.620\n It's online mostly now,\n\n2:07:46.620 --> 2:07:47.460\n in the sense that the lectures.\n\n2:07:47.460 --> 2:07:49.060\n Several versions of it, I think.\n\n2:07:49.060 --> 2:07:49.900\n Right, the YouTube.\n\n2:07:49.900 --> 2:07:52.060\n It's really great, I recommend it highly.\n\n2:07:52.060 --> 2:07:55.060\n Look on YouTube for the 2020 versions.\n\n2:07:55.060 --> 2:07:57.460\n Until March, and then you have to go back to 2019,\n\n2:07:57.460 --> 2:07:58.900\n thanks to COVID.\n\n2:08:00.740 --> 2:08:03.540\n No, I've poured my heart into that class.\n\n2:08:04.820 --> 2:08:06.620\n And lecture one is basically explaining\n\n2:08:06.620 --> 2:08:07.940\n what the word underactuated means.\n\n2:08:07.940 --> 2:08:09.860\n So people are very kind to show up\n\n2:08:09.860 --> 2:08:12.220\n and then maybe have to learn\n\n2:08:12.220 --> 2:08:13.460\n what the title of the course means\n\n2:08:13.460 --> 2:08:15.420\n over the course of the first lecture.\n\n2:08:15.420 --> 2:08:17.500\n That first lecture is really good.\n\n2:08:17.500 --> 2:08:18.780\n You should watch it.\n\n2:08:18.780 --> 2:08:19.860\n Thanks.\n\n2:08:19.860 --> 2:08:21.500\n It's a strange name,\n\n2:08:21.500 --> 2:08:25.860\n but I thought it captured the essence\n\n2:08:25.860 --> 2:08:27.940\n of what control was good at doing\n\n2:08:27.940 --> 2:08:29.980\n and what control was bad at doing.\n\n2:08:29.980 --> 2:08:31.940\n So what do I mean by underactuated?\n\n2:08:31.940 --> 2:08:34.700\n So a mechanical system\n\n2:08:36.340 --> 2:08:39.500\n has many degrees of freedom, for instance.\n\n2:08:39.500 --> 2:08:41.940\n I think of a joint as a degree of freedom.\n\n2:08:41.940 --> 2:08:46.180\n And it has some number of actuators, motors.\n\n2:08:46.180 --> 2:08:49.220\n So if you have a robot that's bolted to the table\n\n2:08:49.220 --> 2:08:54.100\n that has five degrees of freedom and five motors,\n\n2:08:54.100 --> 2:08:55.860\n then you have a fully actuated robot.\n\n2:08:57.140 --> 2:09:00.540\n If you take away one of those motors,\n\n2:09:00.540 --> 2:09:03.180\n then you have an underactuated robot.\n\n2:09:03.180 --> 2:09:04.940\n Now, why on earth?\n\n2:09:04.940 --> 2:09:07.460\n I have a good friend who likes to tease me.\n\n2:09:07.460 --> 2:09:09.500\n He said, Ross, if you had more research funding,\n\n2:09:09.500 --> 2:09:11.740\n would you work on fully actuated robots?\n\n2:09:11.740 --> 2:09:12.580\n Yeah.\n\n2:09:12.580 --> 2:09:15.180\n And the answer is no.\n\n2:09:15.180 --> 2:09:17.420\n The world gives us underactuated robots,\n\n2:09:17.420 --> 2:09:18.460\n whether we like it or not.\n\n2:09:18.460 --> 2:09:19.860\n I'm a human.\n\n2:09:19.860 --> 2:09:21.500\n I'm an underactuated robot,\n\n2:09:21.500 --> 2:09:23.540\n even though I have more muscles\n\n2:09:23.540 --> 2:09:25.220\n than my big degrees of freedom,\n\n2:09:25.220 --> 2:09:27.740\n because I have in some places\n\n2:09:27.740 --> 2:09:29.940\n multiple muscles attached to the same joint.\n\n2:09:30.820 --> 2:09:33.900\n But still, there's a really important degree of freedom\n\n2:09:33.900 --> 2:09:37.140\n that I have, which is the location of my center of mass\n\n2:09:37.140 --> 2:09:38.580\n in space, for instance.\n\n2:09:39.580 --> 2:09:42.500\n All right, I can jump into the air,\n\n2:09:42.500 --> 2:09:45.220\n and there's no motor that connects my center of mass\n\n2:09:45.220 --> 2:09:47.220\n to the ground in that case.\n\n2:09:47.220 --> 2:09:49.420\n So I have to think about the implications\n\n2:09:49.420 --> 2:09:51.700\n of not having control over everything.\n\n2:09:52.740 --> 2:09:56.540\n The passive dynamic walkers are the extreme view of that,\n\n2:09:56.540 --> 2:09:57.860\n where you've taken away all the motors,\n\n2:09:57.860 --> 2:09:59.980\n and you have to let physics do the work.\n\n2:09:59.980 --> 2:10:02.220\n But it shows up in all of the walking robots,\n\n2:10:02.220 --> 2:10:04.540\n where you have to use some of the actuators\n\n2:10:04.540 --> 2:10:06.980\n to push and pull even the degrees of freedom\n\n2:10:06.980 --> 2:10:08.940\n that you don't have an actuator on.\n\n2:10:09.980 --> 2:10:13.140\n That's referring to walking if you're falling forward.\n\n2:10:13.140 --> 2:10:16.260\n Is there a way to walk that's fully actuated?\n\n2:10:16.260 --> 2:10:18.340\n So it's a subtle point.\n\n2:10:18.340 --> 2:10:23.340\n When you're in contact and you have your feet on the ground,\n\n2:10:23.940 --> 2:10:26.540\n there are still limits to what you can do, right?\n\n2:10:26.540 --> 2:10:29.140\n Unless I have suction cups on my feet,\n\n2:10:29.140 --> 2:10:32.620\n I cannot accelerate my center of mass towards the ground\n\n2:10:32.620 --> 2:10:33.780\n faster than gravity,\n\n2:10:33.780 --> 2:10:37.420\n because I can't get a force pushing me down, right?\n\n2:10:37.420 --> 2:10:39.420\n But I can still do most of the things that I want to.\n\n2:10:39.420 --> 2:10:42.460\n So you can get away with basically thinking of the system\n\n2:10:42.460 --> 2:10:43.420\n as fully actuated,\n\n2:10:43.420 --> 2:10:46.460\n unless you suddenly needed to accelerate down super fast.\n\n2:10:47.460 --> 2:10:49.260\n But as soon as I take a step,\n\n2:10:49.260 --> 2:10:52.980\n I get into the more nuanced territory,\n\n2:10:52.980 --> 2:10:55.780\n and to get to really dynamic robots,\n\n2:10:55.780 --> 2:10:59.220\n or airplanes or other things,\n\n2:10:59.220 --> 2:11:02.620\n I think you have to embrace the underactuated dynamics.\n\n2:11:02.620 --> 2:11:06.940\n Manipulation, people think, is manipulation underactuated?\n\n2:11:06.940 --> 2:11:10.580\n Even if my arm is fully actuated, I have a motor,\n\n2:11:10.580 --> 2:11:14.260\n if my goal is to control the position and orientation\n\n2:11:14.260 --> 2:11:18.460\n of this cup, then I don't have an actuator\n\n2:11:18.460 --> 2:11:19.300\n for that directly.\n\n2:11:19.300 --> 2:11:21.100\n So I have to use my actuators over here\n\n2:11:21.100 --> 2:11:22.300\n to control this thing.\n\n2:11:23.380 --> 2:11:24.340\n Now it gets even worse,\n\n2:11:24.340 --> 2:11:27.740\n like what if I have to button my shirt, okay?\n\n2:11:29.300 --> 2:11:31.340\n What are the degrees of freedom of my shirt, right?\n\n2:11:31.340 --> 2:11:34.540\n I suddenly, that's a hard question to think about.\n\n2:11:34.540 --> 2:11:36.740\n It kind of makes me queasy\n\n2:11:36.740 --> 2:11:40.740\n thinking about my state space control ideas.\n\n2:11:40.740 --> 2:11:41.820\n But actually those are the problems\n\n2:11:41.820 --> 2:11:44.540\n that make me so excited about manipulation right now,\n\n2:11:44.540 --> 2:11:47.020\n is that it breaks some of the,\n\n2:11:48.020 --> 2:11:50.060\n it breaks a lot of the foundational control stuff\n\n2:11:50.060 --> 2:11:51.420\n that I've been thinking about.\n\n2:11:51.420 --> 2:11:54.580\n Is there, what are some interesting insights\n\n2:11:54.580 --> 2:11:58.060\n you could say about trying to solve an underactuated,\n\n2:11:58.060 --> 2:12:02.380\n a control in an underactuated system?\n\n2:12:02.380 --> 2:12:04.820\n So I think the philosophy there\n\n2:12:04.820 --> 2:12:07.220\n is let physics do more of the work.\n\n2:12:08.460 --> 2:12:12.180\n The technical approach has been optimization.\n\n2:12:12.180 --> 2:12:14.260\n So you typically formulate your decision making\n\n2:12:14.260 --> 2:12:17.140\n for control as an optimization problem.\n\n2:12:17.140 --> 2:12:19.420\n And you use the language of optimal control\n\n2:12:19.420 --> 2:12:22.780\n and sometimes often numerical optimal control\n\n2:12:22.780 --> 2:12:26.620\n in order to make those decisions and balance,\n\n2:12:26.620 --> 2:12:29.100\n these complicated equations of,\n\n2:12:29.100 --> 2:12:30.900\n and in order to control,\n\n2:12:30.900 --> 2:12:33.140\n you don't have to use optimal control\n\n2:12:33.140 --> 2:12:34.900\n to do underactuated systems,\n\n2:12:34.900 --> 2:12:36.340\n but that has been the technical approach\n\n2:12:36.340 --> 2:12:39.100\n that has borne the most fruit in our,\n\n2:12:39.100 --> 2:12:40.900\n at least in our line of work.\n\n2:12:40.900 --> 2:12:44.060\n And there's some, so in underactuated systems,\n\n2:12:44.060 --> 2:12:46.820\n when you say let physics do some of the work,\n\n2:12:46.820 --> 2:12:50.380\n so there's a kind of feedback loop\n\n2:12:50.380 --> 2:12:54.540\n that observes the state that the physics brought you to.\n\n2:12:54.540 --> 2:12:57.780\n So like you've, there's a perception there,\n\n2:12:57.780 --> 2:13:00.420\n there's a feedback somehow.\n\n2:13:00.420 --> 2:13:05.420\n Do you ever loop in like complicated perception systems\n\n2:13:05.420 --> 2:13:06.900\n into this whole picture?\n\n2:13:06.900 --> 2:13:09.620\n Right, right around the time of the DARPA challenge,\n\n2:13:09.620 --> 2:13:11.340\n we had a complicated perception system\n\n2:13:11.340 --> 2:13:12.700\n in the DARPA challenge.\n\n2:13:12.700 --> 2:13:15.580\n We also started to embrace perception\n\n2:13:15.580 --> 2:13:17.340\n for our flying vehicles at the time.\n\n2:13:17.340 --> 2:13:20.100\n We had a really good project\n\n2:13:20.100 --> 2:13:21.820\n on trying to make airplanes fly\n\n2:13:21.820 --> 2:13:23.340\n at high speeds through forests.\n\n2:13:24.780 --> 2:13:27.460\n Sirtash Karaman was on that project\n\n2:13:27.460 --> 2:13:30.700\n and we had, it was a really fun team to work on.\n\n2:13:30.700 --> 2:13:34.220\n He's carried it farther, much farther forward since then.\n\n2:13:34.220 --> 2:13:35.980\n And that's using cameras for perception?\n\n2:13:35.980 --> 2:13:37.580\n So that was using cameras.\n\n2:13:37.580 --> 2:13:40.300\n That was, at the time we felt like LIDAR\n\n2:13:40.300 --> 2:13:44.860\n was too heavy and too power heavy\n\n2:13:44.860 --> 2:13:47.740\n to be carried on a light UAV,\n\n2:13:47.740 --> 2:13:49.220\n and we were using cameras.\n\n2:13:49.220 --> 2:13:50.660\n And that was a big part of it was just\n\n2:13:50.660 --> 2:13:53.100\n how do you do even stereo matching\n\n2:13:53.100 --> 2:13:56.460\n at a fast enough rate with a small camera,\n\n2:13:56.460 --> 2:13:57.620\n small onboard compute.\n\n2:13:58.620 --> 2:14:00.700\n Since then we have now,\n\n2:14:00.700 --> 2:14:02.140\n so the deep learning revolution\n\n2:14:02.140 --> 2:14:05.540\n unquestionably changed what we can do\n\n2:14:05.540 --> 2:14:09.020\n with perception for robotics and control.\n\n2:14:09.020 --> 2:14:11.020\n So in manipulation, we can address,\n\n2:14:11.020 --> 2:14:14.660\n we can use perception in I think a much deeper way.\n\n2:14:14.660 --> 2:14:17.340\n And we get into not only,\n\n2:14:17.340 --> 2:14:19.820\n I think the first use of it naturally\n\n2:14:19.820 --> 2:14:22.940\n would be to ask your deep learning system\n\n2:14:22.940 --> 2:14:25.980\n to look at the cameras and produce the state,\n\n2:14:25.980 --> 2:14:28.900\n which is like the pose of my thing, for instance.\n\n2:14:28.900 --> 2:14:30.460\n But I think we've quickly found out\n\n2:14:30.460 --> 2:14:33.620\n that that's not always the right thing to do.\n\n2:14:34.460 --> 2:14:35.620\n Why is that?\n\n2:14:35.620 --> 2:14:38.420\n Because what's the state of my shirt?\n\n2:14:38.420 --> 2:14:39.740\n Imagine, I've always,\n\n2:14:39.740 --> 2:14:41.300\n Very noisy, you mean, or?\n\n2:14:41.300 --> 2:14:46.140\n It's, if the first step of me trying to button my shirt\n\n2:14:46.140 --> 2:14:48.580\n is estimate the full state of my shirt,\n\n2:14:48.580 --> 2:14:50.460\n including like what's happening in the back here,\n\n2:14:50.460 --> 2:14:51.820\n whatever, whatever.\n\n2:14:51.820 --> 2:14:55.780\n That's just not the right specification.\n\n2:14:55.780 --> 2:14:57.500\n There are aspects of the state\n\n2:14:57.500 --> 2:15:00.260\n that are very important to the task.\n\n2:15:00.260 --> 2:15:03.220\n There are many that are unobservable\n\n2:15:03.220 --> 2:15:05.860\n and not important to the task.\n\n2:15:05.860 --> 2:15:06.940\n So you really need,\n\n2:15:06.940 --> 2:15:11.100\n it begs new questions about state representation.\n\n2:15:11.100 --> 2:15:13.100\n Another example that we've been playing with in lab\n\n2:15:13.100 --> 2:15:17.660\n has been just the idea of chopping onions, okay?\n\n2:15:17.660 --> 2:15:19.540\n Or carrots, turns out to be better.\n\n2:15:20.540 --> 2:15:22.500\n So onions stink up the lab.\n\n2:15:22.500 --> 2:15:25.380\n And they're hard to see in a camera.\n\n2:15:26.220 --> 2:15:27.900\n But so,\n\n2:15:27.900 --> 2:15:28.740\n Details matter, yeah.\n\n2:15:28.740 --> 2:15:30.180\n Details matter, you know?\n\n2:15:30.180 --> 2:15:35.180\n So if I'm moving around a particular object, right?\n\n2:15:35.220 --> 2:15:36.060\n Then I think about,\n\n2:15:36.060 --> 2:15:38.020\n oh, it's got a position or an orientation in space.\n\n2:15:38.020 --> 2:15:39.780\n That's the description I want.\n\n2:15:39.780 --> 2:15:42.300\n Now, when I'm chopping an onion, okay?\n\n2:15:42.300 --> 2:15:44.260\n Like the first chop comes down.\n\n2:15:44.260 --> 2:15:46.820\n I have now a hundred pieces of onion.\n\n2:15:48.420 --> 2:15:50.300\n Does my control system really need to understand\n\n2:15:50.300 --> 2:15:52.660\n the position and orientation and even the shape\n\n2:15:52.660 --> 2:15:56.100\n of the hundred pieces of onion in order to make a decision?\n\n2:15:56.100 --> 2:15:56.940\n Probably not, you know?\n\n2:15:56.940 --> 2:15:58.900\n And if I keep going, I'm just getting,\n\n2:15:58.900 --> 2:16:01.860\n more and more is my state space getting bigger as I cut?\n\n2:16:04.740 --> 2:16:06.020\n It's not right.\n\n2:16:06.020 --> 2:16:08.100\n So somehow there's a,\n\n2:16:08.100 --> 2:16:13.100\n I think there's a richer idea of state.\n\n2:16:13.100 --> 2:16:15.740\n It's not the state that is given to us\n\n2:16:15.740 --> 2:16:17.180\n by Lagrangian mechanics.\n\n2:16:17.180 --> 2:16:21.340\n There is a proper Lagrangian state of the system,\n\n2:16:21.340 --> 2:16:26.340\n but the relevant state for this is some latent state\n\n2:16:26.460 --> 2:16:28.540\n is what we call it in machine learning.\n\n2:16:28.540 --> 2:16:32.180\n But, you know, there's some different state representation.\n\n2:16:32.180 --> 2:16:35.020\n Some compressed representation, some.\n\n2:16:35.020 --> 2:16:37.260\n And that's what I worry about saying compressed\n\n2:16:37.260 --> 2:16:38.260\n because it doesn't,\n\n2:16:38.260 --> 2:16:41.460\n I don't mind that it's low dimensional or not,\n\n2:16:43.020 --> 2:16:46.260\n but it has to be something that's easier to think about.\n\n2:16:46.260 --> 2:16:47.380\n By us humans.\n\n2:16:48.460 --> 2:16:49.300\n Or my algorithms.\n\n2:16:49.300 --> 2:16:53.860\n Or the algorithms being like control, optimal.\n\n2:16:53.860 --> 2:16:56.540\n So for instance, if the contact mechanics\n\n2:16:56.540 --> 2:16:59.660\n of all of those onion pieces and all the permutations\n\n2:16:59.660 --> 2:17:02.540\n of possible touches between those onion pieces,\n\n2:17:02.540 --> 2:17:03.620\n you know, you can give me\n\n2:17:03.620 --> 2:17:05.100\n a high dimensional state representation,\n\n2:17:05.100 --> 2:17:06.780\n I'm okay if it's linear.\n\n2:17:06.780 --> 2:17:08.660\n But if I have to think about all the possible\n\n2:17:08.660 --> 2:17:10.760\n shattering combinatorics of that,\n\n2:17:11.700 --> 2:17:13.860\n then my robot's gonna sit there thinking\n\n2:17:13.860 --> 2:17:17.380\n and the soup's gonna get cold or something.\n\n2:17:17.380 --> 2:17:20.100\n So since you taught the course,\n\n2:17:20.100 --> 2:17:22.740\n it kind of entered my mind,\n\n2:17:22.740 --> 2:17:25.980\n the idea of underactuated as really compelling\n\n2:17:25.980 --> 2:17:28.700\n to see the world in this kind of way.\n\n2:17:29.540 --> 2:17:32.420\n Do you ever, you know, if we talk about onions\n\n2:17:32.420 --> 2:17:35.480\n or you talk about the world with people in it in general,\n\n2:17:35.480 --> 2:17:39.980\n do you see the world as basically an underactuated system?\n\n2:17:39.980 --> 2:17:42.380\n Do you like often look at the world in this way?\n\n2:17:42.380 --> 2:17:44.780\n Or is this overreach?\n\n2:17:47.040 --> 2:17:49.160\n Underactuated is a way of life, man.\n\n2:17:49.160 --> 2:17:51.480\n Exactly, I guess that's what I'm asking.\n\n2:17:53.560 --> 2:17:54.960\n I do think it's everywhere.\n\n2:17:54.960 --> 2:17:57.320\n I think in some places,\n\n2:17:58.840 --> 2:18:01.380\n we already have natural tools to deal with it.\n\n2:18:01.380 --> 2:18:02.480\n You know, it rears its head.\n\n2:18:02.480 --> 2:18:04.280\n I mean, in linear systems, it's not a problem.\n\n2:18:04.280 --> 2:18:07.340\n We just, like an underactuated linear system\n\n2:18:07.340 --> 2:18:09.000\n is really not sufficiently distinct\n\n2:18:09.000 --> 2:18:10.760\n from a fully actuated linear system.\n\n2:18:10.760 --> 2:18:15.600\n It's a subtle point about when that becomes a bottleneck\n\n2:18:15.600 --> 2:18:17.220\n in what we know how to do with control.\n\n2:18:17.220 --> 2:18:18.840\n It happens to be a bottleneck,\n\n2:18:19.800 --> 2:18:22.500\n although we've gotten incredibly good solutions now,\n\n2:18:22.500 --> 2:18:24.200\n but for a long time that I felt\n\n2:18:24.200 --> 2:18:27.100\n that that was the key bottleneck in legged robots.\n\n2:18:27.100 --> 2:18:29.200\n And roughly now the underactuated course\n\n2:18:29.200 --> 2:18:33.840\n is me trying to tell people everything I can\n\n2:18:33.840 --> 2:18:37.280\n about how to make Atlas do a backflip, right?\n\n2:18:38.500 --> 2:18:39.920\n I have a second course now\n\n2:18:39.920 --> 2:18:41.280\n that I teach in the other semesters,\n\n2:18:41.280 --> 2:18:43.600\n which is on manipulation.\n\n2:18:43.600 --> 2:18:45.840\n And that's where we get into now more of the,\n\n2:18:45.840 --> 2:18:47.160\n that's a newer class.\n\n2:18:47.160 --> 2:18:51.600\n I'm hoping to put it online this fall completely.\n\n2:18:51.600 --> 2:18:53.700\n And that's gonna have much more aspects\n\n2:18:53.700 --> 2:18:55.460\n about these perception problems\n\n2:18:55.460 --> 2:18:57.200\n and the state representation questions,\n\n2:18:57.200 --> 2:18:59.260\n and then how do you do control.\n\n2:18:59.260 --> 2:19:04.040\n And the thing that's a little bit sad is that,\n\n2:19:04.040 --> 2:19:07.480\n for me at least, is there's a lot of manipulation tasks\n\n2:19:07.480 --> 2:19:09.280\n that people wanna do and should wanna do.\n\n2:19:09.280 --> 2:19:12.740\n They could start a company with it and be very successful\n\n2:19:12.740 --> 2:19:15.600\n that don't actually require you to think that much\n\n2:19:15.600 --> 2:19:18.040\n about underact, or dynamics at all even,\n\n2:19:18.040 --> 2:19:20.020\n but certainly underactuated dynamics.\n\n2:19:20.020 --> 2:19:23.100\n Once I have, if I reach out and grab something,\n\n2:19:23.100 --> 2:19:25.720\n if I can sort of assume it's rigidly attached to my hand,\n\n2:19:25.720 --> 2:19:26.920\n then I can do a lot of interesting,\n\n2:19:26.920 --> 2:19:28.800\n meaningful things with it\n\n2:19:28.800 --> 2:19:30.960\n without really ever thinking about the dynamics\n\n2:19:30.960 --> 2:19:32.860\n of that object.\n\n2:19:32.860 --> 2:19:37.860\n So we've built systems that kind of reduce the need for that.\n\n2:19:37.860 --> 2:19:39.660\n Enveloping grasps and the like.\n\n2:19:40.780 --> 2:19:43.060\n But I think the really good problems in manipulation.\n\n2:19:43.060 --> 2:19:48.060\n So manipulation, by the way, is more than just pick and place.\n\n2:19:48.540 --> 2:19:51.780\n That's like a lot of people think of that, just grasping.\n\n2:19:51.780 --> 2:19:52.620\n I don't mean that.\n\n2:19:52.620 --> 2:19:56.500\n I mean buttoning my shirt, I mean tying shoelaces.\n\n2:19:56.500 --> 2:19:59.060\n How do you program a robot to tie shoelaces?\n\n2:19:59.060 --> 2:20:02.860\n And not just one shoe, but every shoe, right?\n\n2:20:02.860 --> 2:20:05.580\n That's a really good problem.\n\n2:20:05.580 --> 2:20:08.420\n It's tempting to write down like the infinite dimensional\n\n2:20:08.420 --> 2:20:13.180\n state of the laces, that's probably not needed\n\n2:20:13.180 --> 2:20:15.100\n to write a good controller.\n\n2:20:15.100 --> 2:20:18.340\n I know we could hand design a controller that would do it,\n\n2:20:18.340 --> 2:20:19.180\n but I don't want that.\n\n2:20:19.180 --> 2:20:22.460\n I want to understand the principles that would allow me\n\n2:20:22.460 --> 2:20:25.380\n to solve another problem that's kind of like that.\n\n2:20:25.380 --> 2:20:29.820\n But I think if we can stay pure in our approach,\n\n2:20:29.820 --> 2:20:33.820\n then the challenge of tying anybody's shoes\n\n2:20:33.820 --> 2:20:36.300\n is a great challenge.\n\n2:20:36.300 --> 2:20:37.220\n That's a great challenge.\n\n2:20:37.220 --> 2:20:40.940\n I mean, and the soft touch comes into play there.\n\n2:20:40.940 --> 2:20:43.100\n That's really interesting.\n\n2:20:43.100 --> 2:20:46.260\n Let me ask another ridiculous question on this topic.\n\n2:20:47.500 --> 2:20:49.780\n How important is touch?\n\n2:20:49.780 --> 2:20:52.300\n We haven't talked much about humans,\n\n2:20:52.300 --> 2:20:54.780\n but I have this argument with my dad\n\n2:20:56.220 --> 2:20:59.620\n where like I think you can fall in love with a robot\n\n2:20:59.620 --> 2:21:02.580\n based on language alone.\n\n2:21:02.580 --> 2:21:05.380\n And he believes that touch is essential.\n\n2:21:06.460 --> 2:21:07.660\n Touch and smell, he says.\n\n2:21:07.660 --> 2:21:12.660\n But so in terms of robots, connecting with humans,\n\n2:21:17.380 --> 2:21:19.660\n we can go philosophical in terms of like a deep,\n\n2:21:19.660 --> 2:21:21.820\n meaningful connection, like love,\n\n2:21:21.820 --> 2:21:25.580\n but even just like collaborating in an interesting way,\n\n2:21:25.580 --> 2:21:30.580\n how important is touch like from an engineering perspective\n\n2:21:30.580 --> 2:21:32.780\n and a philosophical one?\n\n2:21:32.780 --> 2:21:34.460\n I think it's super important.\n\n2:21:35.700 --> 2:21:37.020\n Even just in a practical sense,\n\n2:21:37.020 --> 2:21:39.260\n if we forget about the emotional part of it.\n\n2:21:40.700 --> 2:21:43.300\n But for robots to interact safely\n\n2:21:43.300 --> 2:21:46.380\n while they're doing meaningful mechanical work\n\n2:21:47.220 --> 2:21:52.220\n in the close contact with or vicinity of people\n\n2:21:52.420 --> 2:21:55.220\n that need help, I think we have to have them,\n\n2:21:55.220 --> 2:21:57.500\n we have to build them differently.\n\n2:21:57.500 --> 2:21:59.860\n They have to be afraid, not afraid of touching the world.\n\n2:21:59.860 --> 2:22:02.820\n So I think Baymax is just awesome.\n\n2:22:02.820 --> 2:22:06.260\n That's just like the movie of Big Hero 6\n\n2:22:06.260 --> 2:22:08.700\n and the concept of Baymax, that's just awesome.\n\n2:22:08.700 --> 2:22:13.060\n I think we should, and we have some folks at Toyota\n\n2:22:13.060 --> 2:22:14.420\n that are trying to, Toyota Research\n\n2:22:14.420 --> 2:22:16.860\n that are trying to build Baymax roughly.\n\n2:22:16.860 --> 2:22:21.860\n And I think it's just a fantastically good project.\n\n2:22:21.900 --> 2:22:25.620\n I think it will change the way people physically interact.\n\n2:22:25.620 --> 2:22:27.980\n The same way, I mean, you gave a couple examples earlier,\n\n2:22:27.980 --> 2:22:31.940\n but if the robot that was walking around my home\n\n2:22:31.940 --> 2:22:33.980\n looked more like a teddy bear\n\n2:22:33.980 --> 2:22:35.980\n and a little less like the Terminator,\n\n2:22:35.980 --> 2:22:38.900\n that could change completely the way people perceive it\n\n2:22:38.900 --> 2:22:39.820\n and interact with it.\n\n2:22:39.820 --> 2:22:44.340\n And maybe they'll even wanna teach it, like you said, right?\n\n2:22:44.340 --> 2:22:47.660\n You could not quite gamify it,\n\n2:22:47.660 --> 2:22:50.060\n but somehow instead of people judging it\n\n2:22:50.060 --> 2:22:54.340\n and looking at it as if it's not doing as well as a human,\n\n2:22:54.340 --> 2:22:57.060\n they're gonna try to help out the cute teddy bear, right?\n\n2:22:57.060 --> 2:23:01.260\n Who knows, but I think we're building robots wrong\n\n2:23:01.260 --> 2:23:06.260\n and being more soft and more contact is important, right?\n\n2:23:07.780 --> 2:23:09.860\n Yeah, I mean, like all the magical moments\n\n2:23:09.860 --> 2:23:12.380\n I can remember with robots,\n\n2:23:12.380 --> 2:23:15.980\n well, first of all, just visiting your lab and seeing Atlas,\n\n2:23:16.900 --> 2:23:21.660\n but also Spotmini, when I first saw Spotmini in person\n\n2:23:21.660 --> 2:23:26.260\n and hung out with him, her, it,\n\n2:23:26.260 --> 2:23:28.380\n I don't have trouble engendering robots.\n\n2:23:28.380 --> 2:23:31.500\n I feel the robotics people really say, oh, is it it?\n\n2:23:31.500 --> 2:23:34.460\n I kinda like the idea that it's a her or a him.\n\n2:23:35.780 --> 2:23:38.780\n There's a magical moment, but there's no touching.\n\n2:23:38.780 --> 2:23:41.620\n I guess the question I have, have you ever been,\n\n2:23:41.620 --> 2:23:44.940\n like, have you had a human robot experience\n\n2:23:44.940 --> 2:23:47.940\n where a robot touched you?\n\n2:23:49.580 --> 2:23:51.660\n And like, it was like, wait,\n\n2:23:51.660 --> 2:23:53.980\n like, was there a moment that you've forgotten\n\n2:23:53.980 --> 2:23:57.740\n that a robot is a robot and like,\n\n2:23:57.740 --> 2:24:00.820\n the anthropomorphization stepped in\n\n2:24:00.820 --> 2:24:03.500\n and for a second you forgot that it's not human?\n\n2:24:04.900 --> 2:24:07.820\n I mean, I think when you're in on the details,\n\n2:24:07.820 --> 2:24:12.380\n then we, of course, anthropomorphized our work with Atlas,\n\n2:24:12.380 --> 2:24:17.100\n but in verbal communication and the like,\n\n2:24:17.100 --> 2:24:18.980\n I think we were pretty aware of it\n\n2:24:18.980 --> 2:24:21.740\n as a machine that needed to be respected.\n\n2:24:21.740 --> 2:24:26.260\n And I actually, I worry more about the smaller robots\n\n2:24:26.260 --> 2:24:29.540\n that could still move quickly if programmed wrong\n\n2:24:29.540 --> 2:24:31.660\n and we have to be careful actually\n\n2:24:31.660 --> 2:24:33.740\n about safety and the like right now.\n\n2:24:33.740 --> 2:24:36.380\n And that, if we build our robots correctly,\n\n2:24:36.380 --> 2:24:40.300\n I think then those, a lot of those concerns could go away.\n\n2:24:40.300 --> 2:24:41.260\n And we're seeing that trend.\n\n2:24:41.260 --> 2:24:44.100\n We're seeing the lower cost, lighter weight arms now\n\n2:24:44.100 --> 2:24:46.740\n that could be fundamentally safe.\n\n2:24:46.740 --> 2:24:49.060\n I mean, I do think touch is so fundamental.\n\n2:24:49.060 --> 2:24:51.100\n Ted Adelson is great.\n\n2:24:51.100 --> 2:24:54.580\n He's a perceptual scientist at MIT\n\n2:24:55.740 --> 2:24:58.180\n and he studied vision most of his life.\n\n2:24:58.180 --> 2:25:01.220\n And he said, when I had kids,\n\n2:25:01.220 --> 2:25:04.540\n I expected to be fascinated by their perceptual development.\n\n2:25:06.380 --> 2:25:09.260\n But what really, what he noticed was,\n\n2:25:09.260 --> 2:25:10.780\n felt more impressive, more dominant\n\n2:25:10.780 --> 2:25:13.060\n was the way that they would touch everything\n\n2:25:13.060 --> 2:25:13.900\n and lick everything.\n\n2:25:13.900 --> 2:25:16.900\n And pick things up, stick it on their tongue and whatever.\n\n2:25:16.900 --> 2:25:21.900\n And he said, watching his daughter convinced him\n\n2:25:22.180 --> 2:25:25.580\n that actually he needed to study tactile sensing more.\n\n2:25:25.580 --> 2:25:30.580\n So there's something very important.\n\n2:25:30.580 --> 2:25:32.780\n I think it's a little bit also of the passive\n\n2:25:32.780 --> 2:25:35.660\n versus active part of the world, right?\n\n2:25:35.660 --> 2:25:38.460\n You can passively perceive the world.\n\n2:25:38.460 --> 2:25:41.460\n But it's fundamentally different if you can do an experiment\n\n2:25:41.460 --> 2:25:43.340\n and if you can change the world\n\n2:25:43.340 --> 2:25:46.220\n and you can learn a lot more than a passive observer.\n\n2:25:47.460 --> 2:25:51.500\n So you can in dialogue, that was your initial example,\n\n2:25:51.500 --> 2:25:54.580\n you could have an active experiment exchange.\n\n2:25:54.580 --> 2:25:57.460\n But I think if you're just a camera watching YouTube,\n\n2:25:57.460 --> 2:26:00.380\n I think that's a very different problem\n\n2:26:00.380 --> 2:26:03.700\n than if you're a robot that can apply force.\n\n2:26:03.700 --> 2:26:05.900\n And I think that's a very different problem\n\n2:26:05.900 --> 2:26:10.740\n than if you're a robot that can apply force and touch.\n\n2:26:13.260 --> 2:26:15.540\n I think it's important.\n\n2:26:15.540 --> 2:26:18.020\n Yeah, I think it's just an exciting area of research.\n\n2:26:18.020 --> 2:26:19.260\n I think you're probably right\n\n2:26:19.260 --> 2:26:21.540\n that this hasn't been under researched.\n\n2:26:23.900 --> 2:26:25.780\n To me as a person who's captivated\n\n2:26:25.780 --> 2:26:27.820\n by the idea of human robot interaction,\n\n2:26:27.820 --> 2:26:32.820\n it feels like such a rich opportunity to explore touch.\n\n2:26:34.140 --> 2:26:35.860\n Not even from a safety perspective,\n\n2:26:35.860 --> 2:26:38.060\n but like you said, the emotional too.\n\n2:26:38.060 --> 2:26:39.660\n I mean, safety comes first,\n\n2:26:41.220 --> 2:26:46.220\n but the next step is like a real human connection.\n\n2:26:48.300 --> 2:26:51.380\n Even in the industrial setting,\n\n2:26:51.380 --> 2:26:55.540\n it just feels like it's nice for the robot.\n\n2:26:55.540 --> 2:26:58.060\n I don't know, you might disagree with this,\n\n2:26:58.060 --> 2:27:01.220\n but because I think it's important\n\n2:27:01.220 --> 2:27:04.340\n to see robots as tools often,\n\n2:27:04.340 --> 2:27:06.060\n but I don't know,\n\n2:27:06.060 --> 2:27:08.540\n I think they're just always going to be more effective\n\n2:27:08.540 --> 2:27:10.140\n once you humanize them.\n\n2:27:11.700 --> 2:27:14.340\n Like it's convenient now to think of them as tools\n\n2:27:14.340 --> 2:27:16.140\n because we want to focus on the safety,\n\n2:27:16.140 --> 2:27:21.140\n but I think ultimately to create like a good experience\n\n2:27:22.300 --> 2:27:24.860\n for the worker, for the person,\n\n2:27:24.860 --> 2:27:27.980\n there has to be a human element.\n\n2:27:27.980 --> 2:27:29.260\n I don't know, for me,\n\n2:27:30.140 --> 2:27:33.140\n it feels like an industrial robotic arm\n\n2:27:33.140 --> 2:27:34.860\n would be better if it has a human element.\n\n2:27:34.860 --> 2:27:37.060\n I think like Rethink Robotics had that idea\n\n2:27:37.060 --> 2:27:40.260\n with the Baxter and having eyes and so on,\n\n2:27:40.260 --> 2:27:43.100\n having, I don't know, I'm a big believer in that.\n\n2:27:45.220 --> 2:27:48.060\n It's not my area, but I am also a big believer.\n\n2:27:49.300 --> 2:27:51.900\n Do you have an emotional connection to Atlas?\n\n2:27:51.900 --> 2:27:54.940\n Like do you miss him?\n\n2:27:54.940 --> 2:27:59.940\n I mean, yes, I don't know if I more so\n\n2:27:59.940 --> 2:28:01.620\n than if I had a different science project\n\n2:28:01.620 --> 2:28:03.420\n that I'd worked on super hard, right?\n\n2:28:03.420 --> 2:28:08.420\n But yeah, I mean, the robot,\n\n2:28:09.900 --> 2:28:11.780\n we basically had to do heart surgery on the robot\n\n2:28:11.780 --> 2:28:14.380\n in the final competition because we melted the core.\n\n2:28:18.380 --> 2:28:20.140\n Yeah, there was something about watching that robot\n\n2:28:20.140 --> 2:28:20.980\n hanging there.\n\n2:28:20.980 --> 2:28:22.540\n We know we had to compete with it in an hour\n\n2:28:22.540 --> 2:28:25.260\n and it was getting its guts ripped out.\n\n2:28:25.260 --> 2:28:27.460\n Those are all historic moments.\n\n2:28:27.460 --> 2:28:30.140\n I think if you look back like a hundred years from now,\n\n2:28:32.140 --> 2:28:35.140\n yeah, I think those are important moments in robotics.\n\n2:28:35.140 --> 2:28:36.660\n I mean, these are the early days.\n\n2:28:36.660 --> 2:28:37.980\n You look at like the early days\n\n2:28:37.980 --> 2:28:39.500\n of a lot of scientific disciplines.\n\n2:28:39.500 --> 2:28:42.020\n They look ridiculous, they're full of failure,\n\n2:28:42.020 --> 2:28:45.060\n but it feels like robotics will be important\n\n2:28:45.060 --> 2:28:48.940\n in the coming a hundred years.\n\n2:28:48.940 --> 2:28:50.860\n And these are the early days.\n\n2:28:50.860 --> 2:28:54.420\n So I think a lot of people are,\n\n2:28:54.420 --> 2:28:57.900\n look at a brilliant person such as yourself\n\n2:28:57.900 --> 2:29:01.740\n and are curious about the intellectual journey they've took.\n\n2:29:01.740 --> 2:29:06.260\n Is there maybe three books, technical, fiction,\n\n2:29:06.260 --> 2:29:10.540\n philosophical that had a big impact on your life\n\n2:29:10.540 --> 2:29:13.340\n that you would recommend perhaps others reading?\n\n2:29:15.260 --> 2:29:18.460\n Yeah, so I actually didn't read that much as a kid,\n\n2:29:18.460 --> 2:29:21.260\n but I read fairly voraciously now.\n\n2:29:21.260 --> 2:29:24.940\n There are some recent books that if you're interested\n\n2:29:24.940 --> 2:29:29.940\n in this kind of topic, like AI Superpowers by Kai Fu Lee\n\n2:29:29.940 --> 2:29:31.660\n is just a fantastic read.\n\n2:29:31.660 --> 2:29:33.100\n You must read that.\n\n2:29:35.100 --> 2:29:40.100\n Yuval Harari is just, I think that can open your mind.\n\n2:29:40.500 --> 2:29:41.580\n Sapiens.\n\n2:29:41.580 --> 2:29:46.580\n Sapiens is the first one, Homo Deus is the second, yeah.\n\n2:29:46.980 --> 2:29:48.340\n We mentioned it in the book,\n\n2:29:48.340 --> 2:29:51.060\n Homo Deus is the second, yeah.\n\n2:29:51.060 --> 2:29:53.500\n We mentioned The Black Swan by Taleb.\n\n2:29:53.500 --> 2:29:56.100\n I think that's a good sort of mind opener.\n\n2:29:57.220 --> 2:30:02.220\n I actually, so there's maybe a more controversial\n\n2:30:04.420 --> 2:30:06.220\n recommendation I could give.\n\n2:30:06.220 --> 2:30:08.740\n Great, we love controversy.\n\n2:30:08.740 --> 2:30:11.580\n In some sense, it's so classical it might surprise you,\n\n2:30:11.580 --> 2:30:16.020\n but I actually recently read Mortimer Adler's\n\n2:30:16.020 --> 2:30:19.020\n How to Read a Book, not so long, it was a while ago,\n\n2:30:19.020 --> 2:30:22.300\n but some people hate that book.\n\n2:30:23.220 --> 2:30:24.820\n I loved it.\n\n2:30:24.820 --> 2:30:28.980\n I think we're in this time right now where,\n\n2:30:30.860 --> 2:30:33.780\n boy, we're just inundated with research papers\n\n2:30:33.780 --> 2:30:38.580\n that you could read on archive with limited peer review\n\n2:30:38.580 --> 2:30:40.980\n and just this wealth of information.\n\n2:30:40.980 --> 2:30:45.980\n I don't know, I think the passion of what you can get\n\n2:30:46.460 --> 2:30:49.460\n out of a book, a really good book or a really good paper\n\n2:30:49.460 --> 2:30:52.220\n if you find it, the attitude, the realization\n\n2:30:52.220 --> 2:30:54.220\n that you're only gonna find a few that really\n\n2:30:54.220 --> 2:30:58.300\n are worth all your time, but then once you find them,\n\n2:30:58.300 --> 2:31:02.660\n you should just dig in and understand it very deeply\n\n2:31:02.660 --> 2:31:07.660\n and it's worth marking it up and having the hard copy\n\n2:31:07.660 --> 2:31:11.340\n writing in the side notes, side margins.\n\n2:31:11.340 --> 2:31:16.340\n I think that was really, I read it at the right time\n\n2:31:16.340 --> 2:31:19.260\n where I was just feeling just overwhelmed\n\n2:31:19.260 --> 2:31:22.260\n with really low quality stuff, I guess.\n\n2:31:23.780 --> 2:31:28.780\n And similarly, I'm just giving more than three now,\n\n2:31:28.780 --> 2:31:31.460\n I'm sorry if I've exceeded my quota.\n\n2:31:31.460 --> 2:31:34.140\n But on that topic just real quick is,\n\n2:31:34.140 --> 2:31:38.140\n so basically finding a few companions to keep\n\n2:31:38.140 --> 2:31:41.340\n for the rest of your life in terms of papers and books\n\n2:31:41.340 --> 2:31:44.140\n and so on and those are the ones,\n\n2:31:44.140 --> 2:31:48.900\n like not doing, what is it, FOMO, fear of missing out,\n\n2:31:48.900 --> 2:31:50.820\n constantly trying to update yourself,\n\n2:31:50.820 --> 2:31:53.700\n but really deeply making a life journey\n\n2:31:53.700 --> 2:31:57.500\n of studying a particular paper, essentially, set of papers.\n\n2:31:57.500 --> 2:32:02.500\n Yeah, I think when you really start to understand\n\n2:32:02.500 --> 2:32:06.100\n when you really find something,\n\n2:32:06.100 --> 2:32:07.780\n which a book that resonates with you\n\n2:32:07.780 --> 2:32:10.420\n might not be the same book that resonates with me,\n\n2:32:10.420 --> 2:32:13.180\n but when you really find one that resonates with you,\n\n2:32:13.180 --> 2:32:16.260\n I think the dialogue that happens and that's what,\n\n2:32:16.260 --> 2:32:20.140\n I loved that Adler was saying, I think Socrates and Plato\n\n2:32:20.140 --> 2:32:25.140\n say the written word is never gonna capture\n\n2:32:25.740 --> 2:32:28.020\n the beauty of dialogue, right?\n\n2:32:28.020 --> 2:32:33.020\n But Adler says, no, no, a really good book\n\n2:32:33.100 --> 2:32:35.380\n is a dialogue between you and the author\n\n2:32:35.380 --> 2:32:39.180\n and it crosses time and space and I don't know,\n\n2:32:39.180 --> 2:32:40.740\n I think it's a very romantic,\n\n2:32:40.740 --> 2:32:42.740\n there's a bunch of like specific advice,\n\n2:32:42.740 --> 2:32:44.380\n which you can just gloss over,\n\n2:32:44.380 --> 2:32:47.260\n but the romantic view of how to read\n\n2:32:47.260 --> 2:32:51.060\n and really appreciate it is so good.\n\n2:32:52.140 --> 2:32:53.900\n And similarly, teaching,\n\n2:32:53.900 --> 2:32:58.820\n yeah, I thought a lot about teaching\n\n2:32:58.820 --> 2:33:03.300\n and so Isaac Asimov, great science fiction writer,\n\n2:33:03.300 --> 2:33:05.340\n has also actually spent a lot of his career\n\n2:33:05.340 --> 2:33:07.260\n writing nonfiction, right?\n\n2:33:07.260 --> 2:33:08.740\n His memoir is fantastic.\n\n2:33:09.940 --> 2:33:12.740\n He was passionate about explaining things, right?\n\n2:33:12.740 --> 2:33:13.700\n He wrote all kinds of books\n\n2:33:13.700 --> 2:33:16.100\n on all kinds of topics in science.\n\n2:33:16.100 --> 2:33:17.740\n He was known as the great explainer\n\n2:33:17.740 --> 2:33:22.340\n and I do really resonate with his style\n\n2:33:22.340 --> 2:33:27.180\n and just his way of talking about,\n\n2:33:28.420 --> 2:33:30.540\n by communicating and explaining to something\n\n2:33:30.540 --> 2:33:32.540\n is really the way that you learn something.\n\n2:33:32.540 --> 2:33:36.260\n I think about problems very differently\n\n2:33:36.260 --> 2:33:39.220\n because of the way I've been given the opportunity\n\n2:33:39.220 --> 2:33:40.460\n to teach them at MIT.\n\n2:33:42.140 --> 2:33:45.500\n We have questions asked, the fear of the lecture,\n\n2:33:45.500 --> 2:33:47.700\n the experience of the lecture\n\n2:33:47.700 --> 2:33:50.220\n and the questions I get and the interactions\n\n2:33:50.220 --> 2:33:53.140\n just forces me to be rock solid on these ideas\n\n2:33:53.140 --> 2:33:55.060\n in a way that if I didn't have that,\n\n2:33:55.060 --> 2:33:58.260\n I don't know, I would be in a different intellectual space.\n\n2:33:58.260 --> 2:34:00.420\n Also, video, does that scare you\n\n2:34:00.420 --> 2:34:02.140\n that your lectures are online\n\n2:34:02.140 --> 2:34:05.460\n and people like me in sweatpants can sit sipping coffee\n\n2:34:05.460 --> 2:34:08.260\n and watch you give lectures?\n\n2:34:08.260 --> 2:34:09.980\n I think it's great.\n\n2:34:09.980 --> 2:34:12.820\n I do think that something's changed right now,\n\n2:34:12.820 --> 2:34:16.900\n which is, right now we're giving lectures over Zoom.\n\n2:34:16.900 --> 2:34:21.260\n I mean, giving seminars over Zoom and everything.\n\n2:34:21.260 --> 2:34:24.380\n I'm trying to figure out, I think it's a new medium.\n\n2:34:24.380 --> 2:34:28.020\n I'm trying to figure out how to exploit it.\n\n2:34:28.020 --> 2:34:33.020\n Yeah, I've been quite cynical\n\n2:34:34.500 --> 2:34:39.500\n about human to human connection over that medium,\n\n2:34:39.820 --> 2:34:43.420\n but I think that's because it hasn't been explored fully\n\n2:34:43.420 --> 2:34:45.780\n and teaching is a different thing.\n\n2:34:45.780 --> 2:34:49.100\n Every lecture is a, I'm sorry, every seminar even,\n\n2:34:49.100 --> 2:34:53.460\n I think every talk I give is an opportunity\n\n2:34:53.460 --> 2:34:54.980\n to give that differently.\n\n2:34:54.980 --> 2:34:57.940\n I can deliver content directly into your browser.\n\n2:34:57.940 --> 2:35:00.020\n You have a WebGL engine right there.\n\n2:35:00.020 --> 2:35:04.900\n I can throw 3D content into your browser\n\n2:35:04.900 --> 2:35:06.900\n while you're listening to me, right?\n\n2:35:06.900 --> 2:35:10.020\n And I can assume that you have at least\n\n2:35:10.020 --> 2:35:13.020\n a powerful enough laptop or something to watch Zoom\n\n2:35:13.020 --> 2:35:15.460\n while I'm doing that, while I'm giving a lecture.\n\n2:35:15.460 --> 2:35:18.060\n That's a new communication tool\n\n2:35:18.060 --> 2:35:19.980\n that I didn't have last year, right?\n\n2:35:19.980 --> 2:35:24.180\n And I think robotics can potentially benefit a lot\n\n2:35:24.180 --> 2:35:25.340\n from teaching that way.\n\n2:35:26.420 --> 2:35:28.180\n We'll see, it's gonna be an experiment this fall.\n\n2:35:28.180 --> 2:35:29.020\n It's interesting.\n\n2:35:29.020 --> 2:35:30.340\n I'm thinking a lot about it.\n\n2:35:30.340 --> 2:35:35.340\n Yeah, and also like the length of lectures\n\n2:35:35.580 --> 2:35:38.820\n or the length of like, there's something,\n\n2:35:38.820 --> 2:35:42.900\n so like I guarantee you, it's like 80% of people\n\n2:35:42.900 --> 2:35:44.900\n who started listening to our conversation\n\n2:35:44.900 --> 2:35:48.180\n are still listening to now, which is crazy to me.\n\n2:35:48.180 --> 2:35:51.140\n But so there's a patience and interest\n\n2:35:51.140 --> 2:35:53.540\n in long form content, but at the same time,\n\n2:35:53.540 --> 2:35:57.940\n there's a magic to forcing yourself to condense\n\n2:35:57.940 --> 2:36:01.220\n an idea to as short as possible.\n\n2:36:02.740 --> 2:36:04.660\n As short as possible, like clip,\n\n2:36:04.660 --> 2:36:06.180\n it can be a part of a longer thing,\n\n2:36:06.180 --> 2:36:09.620\n but like just like really beautifully condense an idea.\n\n2:36:09.620 --> 2:36:11.900\n There's a lot of opportunity there\n\n2:36:11.900 --> 2:36:16.900\n that's easier to do in remote with, I don't know,\n\n2:36:17.500 --> 2:36:19.020\n with editing too.\n\n2:36:19.020 --> 2:36:20.980\n Editing is an interesting thing.\n\n2:36:20.980 --> 2:36:25.020\n Like what, you know, most professors don't get,\n\n2:36:25.020 --> 2:36:25.860\n when they give a lecture,\n\n2:36:25.860 --> 2:36:28.220\n they don't get to go back and edit out parts,\n\n2:36:28.220 --> 2:36:31.580\n like crisp it up a little bit.\n\n2:36:31.580 --> 2:36:34.180\n That's also, it can do magic.\n\n2:36:34.180 --> 2:36:37.620\n Like if you remove like five to 10 minutes\n\n2:36:37.620 --> 2:36:41.140\n from an hour lecture, it can actually,\n\n2:36:41.140 --> 2:36:43.220\n it can make something special of a lecture.\n\n2:36:43.220 --> 2:36:47.860\n I've seen that in myself and in others too,\n\n2:36:47.860 --> 2:36:50.580\n because I edit other people's lectures to extract clips.\n\n2:36:50.580 --> 2:36:52.740\n It's like, there's certain tangents that are like,\n\n2:36:52.740 --> 2:36:54.420\n that lose, they're not interesting.\n\n2:36:54.420 --> 2:36:57.180\n They're mumbling, they're just not,\n\n2:36:57.180 --> 2:36:59.780\n they're not clarifying, they're not helpful at all.\n\n2:36:59.780 --> 2:37:02.820\n And once you remove them, it's just, I don't know.\n\n2:37:02.820 --> 2:37:04.580\n Editing can be magic.\n\n2:37:04.580 --> 2:37:05.900\n It takes a lot of time.\n\n2:37:05.900 --> 2:37:08.940\n Yeah, it takes, it depends like what is teaching,\n\n2:37:08.940 --> 2:37:09.780\n you have to ask.\n\n2:37:09.780 --> 2:37:13.100\n Yeah, yeah.\n\n2:37:13.100 --> 2:37:18.020\n Cause I find the editing process is also beneficial\n\n2:37:18.020 --> 2:37:21.620\n as for teaching, but also for your own learning.\n\n2:37:21.620 --> 2:37:23.740\n I don't know if, have you watched yourself?\n\n2:37:23.740 --> 2:37:24.780\n Yeah, sure.\n\n2:37:24.780 --> 2:37:26.180\n Have you watched those videos?\n\n2:37:26.180 --> 2:37:27.900\n I mean, not all of them.\n\n2:37:27.900 --> 2:37:32.900\n It could be painful to see like how to improve.\n\n2:37:33.340 --> 2:37:37.180\n So do you find that, I know you segment your podcast.\n\n2:37:37.180 --> 2:37:40.740\n Do you think that helps people with the,\n\n2:37:40.740 --> 2:37:42.220\n the attention span aspect of it?\n\n2:37:42.220 --> 2:37:44.220\n Or is it the segment like sections like,\n\n2:37:44.220 --> 2:37:46.380\n yeah, we're talking about this topic, whatever.\n\n2:37:46.380 --> 2:37:48.260\n Nope, nope, that just helps me.\n\n2:37:48.260 --> 2:37:49.420\n It's actually bad.\n\n2:37:49.420 --> 2:37:52.900\n So, and you've been incredible.\n\n2:37:53.820 --> 2:37:56.420\n So I'm learning, like I'm afraid of conversation.\n\n2:37:56.420 --> 2:37:59.180\n This is even today, I'm terrified of talking to you.\n\n2:37:59.180 --> 2:38:04.180\n I mean, it's something I'm trying to remove for myself.\n\n2:38:04.180 --> 2:38:07.420\n There's a guy, I mean, I've learned from a lot of people,\n\n2:38:07.420 --> 2:38:10.740\n but really there's been a few people\n\n2:38:10.740 --> 2:38:14.100\n who's been inspirational to me in terms of conversation.\n\n2:38:14.100 --> 2:38:15.700\n Whatever people think of him,\n\n2:38:15.700 --> 2:38:17.500\n Joe Rogan has been inspirational to me\n\n2:38:17.500 --> 2:38:20.500\n because comedians have been too.\n\n2:38:20.500 --> 2:38:23.300\n Being able to just have fun and enjoy themselves\n\n2:38:23.300 --> 2:38:25.580\n and lose themselves in conversation\n\n2:38:25.580 --> 2:38:28.820\n that requires you to be a great storyteller,\n\n2:38:28.820 --> 2:38:31.500\n to be able to pull a lot of different pieces\n\n2:38:31.500 --> 2:38:32.820\n of information together.\n\n2:38:32.820 --> 2:38:36.500\n But mostly just to enjoy yourself in conversations.\n\n2:38:36.500 --> 2:38:38.060\n And I'm trying to learn that.\n\n2:38:38.060 --> 2:38:41.660\n These notes are, you see me looking down.\n\n2:38:41.660 --> 2:38:43.020\n That's like a safety blanket\n\n2:38:43.020 --> 2:38:45.260\n that I'm trying to let go of more and more.\n\n2:38:45.260 --> 2:38:46.260\n Cool.\n\n2:38:46.260 --> 2:38:49.420\n So that's, people love just regular conversation.\n\n2:38:49.420 --> 2:38:52.660\n That's what they, the structure is like, whatever.\n\n2:38:52.660 --> 2:38:57.620\n I would say, I would say maybe like 10 to like,\n\n2:38:57.620 --> 2:38:59.820\n so there's a bunch of, you know,\n\n2:38:59.820 --> 2:39:03.820\n there's probably a couple of thousand PhD students\n\n2:39:03.820 --> 2:39:06.980\n listening to this right now, right?\n\n2:39:06.980 --> 2:39:09.540\n And they might know what we're talking about.\n\n2:39:09.540 --> 2:39:12.140\n But there is somebody, I guarantee you right now,\n\n2:39:13.460 --> 2:39:16.580\n in Russia, some kid who's just like,\n\n2:39:16.580 --> 2:39:19.380\n who's just smoked some weed, is sitting back\n\n2:39:19.380 --> 2:39:22.580\n and just enjoying the hell out of this conversation.\n\n2:39:22.580 --> 2:39:23.860\n Not really understanding.\n\n2:39:23.860 --> 2:39:25.980\n He kind of watched some Boston Dynamics videos.\n\n2:39:25.980 --> 2:39:27.300\n He's just enjoying it.\n\n2:39:27.300 --> 2:39:29.300\n And I salute you, sir.\n\n2:39:29.300 --> 2:39:32.780\n No, but just like, there's so much variety of people\n\n2:39:32.780 --> 2:39:35.260\n that just have curiosity about engineering,\n\n2:39:35.260 --> 2:39:37.980\n about sciences, about mathematics.\n\n2:39:37.980 --> 2:39:42.980\n And also like, I should, I mean,\n\n2:39:43.940 --> 2:39:44.980\n enjoying it is one thing,\n\n2:39:44.980 --> 2:39:49.180\n but also often notice it inspires people to,\n\n2:39:49.180 --> 2:39:50.860\n there's a lot of people who are like\n\n2:39:50.860 --> 2:39:53.660\n in their undergraduate studies trying to figure out what,\n\n2:39:54.700 --> 2:39:56.140\n trying to figure out what to pursue.\n\n2:39:56.140 --> 2:39:59.220\n And these conversations can really spark\n\n2:39:59.220 --> 2:40:01.820\n the direction of their life.\n\n2:40:01.820 --> 2:40:03.580\n And in terms of robotics, I hope it does,\n\n2:40:03.580 --> 2:40:06.540\n because I'm excited about the possibilities\n\n2:40:06.540 --> 2:40:07.580\n of what robotics brings.\n\n2:40:07.580 --> 2:40:12.580\n On that topic, do you have advice?\n\n2:40:12.580 --> 2:40:14.060\n Like what advice would you give\n\n2:40:14.060 --> 2:40:16.860\n to a young person about life?\n\n2:40:18.260 --> 2:40:19.380\n A young person about life\n\n2:40:19.380 --> 2:40:22.060\n or a young person about life in robotics?\n\n2:40:23.060 --> 2:40:24.380\n It could be in robotics.\n\n2:40:24.380 --> 2:40:26.660\n Robotics, it could be in life in general.\n\n2:40:26.660 --> 2:40:28.460\n It could be career.\n\n2:40:28.460 --> 2:40:31.300\n It could be a relationship advice.\n\n2:40:31.300 --> 2:40:32.900\n It could be running advice.\n\n2:40:32.900 --> 2:40:36.620\n Just like they're, that's one of the things I see,\n\n2:40:36.620 --> 2:40:38.620\n like we talked to like 20 year olds.\n\n2:40:38.620 --> 2:40:42.500\n They're like, how do I do this thing?\n\n2:40:42.500 --> 2:40:43.900\n What do I do?\n\n2:40:45.620 --> 2:40:48.020\n If they come up to you, what would you tell them?\n\n2:40:48.020 --> 2:40:53.980\n I think it's an interesting time to be a kid these days.\n\n2:40:53.980 --> 2:40:57.860\n Everything points to this being sort of a winner,\n\n2:40:57.860 --> 2:40:59.300\n take all economy and the like.\n\n2:40:59.300 --> 2:41:04.300\n I think the people that will really excel in my opinion\n\n2:41:04.500 --> 2:41:06.820\n are going to be the ones that can think deeply\n\n2:41:06.820 --> 2:41:08.380\n about problems.\n\n2:41:11.180 --> 2:41:13.940\n You have to be able to ask questions agilely\n\n2:41:13.940 --> 2:41:15.820\n and use the internet for everything it's good for\n\n2:41:15.820 --> 2:41:16.660\n and stuff like this.\n\n2:41:16.660 --> 2:41:19.460\n And I think a lot of people will develop those skills.\n\n2:41:19.460 --> 2:41:24.460\n I think the leaders, thought leaders,\n\n2:41:24.820 --> 2:41:26.860\n robotics leaders, whatever,\n\n2:41:26.860 --> 2:41:29.100\n are gonna be the ones that can do more\n\n2:41:29.100 --> 2:41:31.340\n and they can think very deeply and critically.\n\n2:41:32.420 --> 2:41:35.020\n And that's a harder thing to learn.\n\n2:41:35.020 --> 2:41:38.140\n I think one path to learning that is through mathematics,\n\n2:41:38.140 --> 2:41:39.140\n through engineering.\n\n2:41:41.660 --> 2:41:44.180\n I would encourage people to start math early.\n\n2:41:44.180 --> 2:41:46.900\n I mean, I didn't really start.\n\n2:41:46.900 --> 2:41:50.460\n I mean, I was always in the better math classes\n\n2:41:50.460 --> 2:41:51.300\n that I could take,\n\n2:41:51.300 --> 2:41:54.700\n but I wasn't pursuing super advanced mathematics\n\n2:41:54.700 --> 2:41:56.700\n or anything like that until I got to MIT.\n\n2:41:56.700 --> 2:41:59.020\n I think MIT lit me up\n\n2:41:59.020 --> 2:42:04.020\n and really started the life that I'm living now.\n\n2:42:05.580 --> 2:42:10.580\n But yeah, I really want kids to dig deep,\n\n2:42:10.740 --> 2:42:12.460\n really understand things, building things too.\n\n2:42:12.460 --> 2:42:15.180\n I mean, pull things apart, put them back together.\n\n2:42:15.180 --> 2:42:17.180\n Like that's just such a good way\n\n2:42:17.180 --> 2:42:19.980\n to really understand things\n\n2:42:19.980 --> 2:42:23.660\n and expect it to be a long journey, right?\n\n2:42:23.660 --> 2:42:27.260\n It's, you don't have to know everything.\n\n2:42:27.260 --> 2:42:29.500\n You're never gonna know everything.\n\n2:42:29.500 --> 2:42:31.460\n So think deeply and stick with it.\n\n2:42:32.860 --> 2:42:35.300\n Enjoy the ride, but just make sure you're not,\n\n2:42:37.580 --> 2:42:40.580\n yeah, just make sure you're stopping\n\n2:42:40.580 --> 2:42:43.180\n to think about why things work.\n\n2:42:43.180 --> 2:42:45.420\n And it's true, it's easy to lose yourself\n\n2:42:45.420 --> 2:42:49.140\n in the distractions of the world.\n\n2:42:51.180 --> 2:42:52.740\n We're overwhelmed with content right now,\n\n2:42:52.740 --> 2:42:56.260\n but you have to stop and pick some of it\n\n2:42:56.260 --> 2:42:58.780\n and really understand it.\n\n2:42:58.780 --> 2:43:00.380\n Yeah, on the book point,\n\n2:43:00.380 --> 2:43:04.940\n I've read Animal Farm by George Orwell\n\n2:43:04.940 --> 2:43:06.100\n a ridiculous number of times.\n\n2:43:06.100 --> 2:43:07.860\n So for me, like that book,\n\n2:43:07.860 --> 2:43:09.780\n I don't know if it's a good book in general,\n\n2:43:09.780 --> 2:43:12.140\n but for me it connects deeply somehow.\n\n2:43:13.340 --> 2:43:18.260\n It somehow connects, so I was born in the Soviet Union.\n\n2:43:18.260 --> 2:43:20.460\n So it connects to me into the entirety of the history\n\n2:43:20.460 --> 2:43:23.180\n of the Soviet Union and to World War II\n\n2:43:23.180 --> 2:43:26.500\n and to the love and hatred and suffering\n\n2:43:26.500 --> 2:43:31.500\n that went on there and the corrupting nature of power\n\n2:43:33.140 --> 2:43:36.340\n and greed and just somehow I just,\n\n2:43:36.340 --> 2:43:38.100\n that book has taught me more about life\n\n2:43:38.100 --> 2:43:39.380\n than like anything else.\n\n2:43:39.380 --> 2:43:42.860\n Even though it's just like a silly childlike book\n\n2:43:42.860 --> 2:43:46.980\n about pigs, I don't know why,\n\n2:43:46.980 --> 2:43:49.300\n it just connects and inspires.\n\n2:43:49.300 --> 2:43:53.780\n The same, there's a few technical books too\n\n2:43:53.780 --> 2:43:58.020\n and algorithms that just, yeah, you return to often.\n\n2:43:58.020 --> 2:43:59.700\n I'm with you.\n\n2:44:01.900 --> 2:44:04.100\n Yeah, there's, and I've been losing that\n\n2:44:04.100 --> 2:44:05.380\n because of the internet.\n\n2:44:05.380 --> 2:44:09.700\n I've been like going on, I've been going on archive\n\n2:44:09.700 --> 2:44:12.420\n and blog posts and GitHub and the new thing\n\n2:44:12.420 --> 2:44:17.420\n and you lose your ability to really master an idea.\n\n2:44:18.100 --> 2:44:18.940\n Right.\n\n2:44:18.940 --> 2:44:19.780\n Wow.\n\n2:44:19.780 --> 2:44:21.100\n Exactly right.\n\n2:44:21.100 --> 2:44:23.540\n What's a fond memory from childhood?\n\n2:44:24.940 --> 2:44:27.460\n When baby Russ Tedrick.\n\n2:44:29.540 --> 2:44:33.940\n Well, I guess I just said that at least my current life\n\n2:44:33.940 --> 2:44:36.780\n began when I got to MIT.\n\n2:44:36.780 --> 2:44:38.900\n If I have to go farther than that.\n\n2:44:38.900 --> 2:44:41.300\n Yeah, what was, was there a life before MIT?\n\n2:44:42.260 --> 2:44:47.260\n Oh, absolutely, but let me actually tell you\n\n2:44:47.380 --> 2:44:48.900\n what happened when I first got to MIT\n\n2:44:48.900 --> 2:44:52.220\n because that I think might be relevant here,\n\n2:44:52.220 --> 2:44:57.220\n but I had taken a computer engineering degree at Michigan.\n\n2:44:57.540 --> 2:45:00.420\n I enjoyed it immensely, learned a bunch of stuff.\n\n2:45:00.420 --> 2:45:04.580\n I liked computers, I liked programming,\n\n2:45:04.580 --> 2:45:07.340\n but when I did get to MIT and started working\n\n2:45:07.340 --> 2:45:10.300\n with Sebastian Sung, theoretical physicist,\n\n2:45:10.300 --> 2:45:15.180\n computational neuroscientist, the culture here\n\n2:45:15.180 --> 2:45:17.220\n was just different.\n\n2:45:17.220 --> 2:45:20.260\n It demanded more of me, certainly mathematically\n\n2:45:20.260 --> 2:45:22.660\n and in the critical thinking.\n\n2:45:22.660 --> 2:45:27.660\n And I remember the day that I borrowed one of the books\n\n2:45:27.700 --> 2:45:29.780\n from my advisor's office and walked down\n\n2:45:29.780 --> 2:45:32.140\n to the Charles River and was like,\n\n2:45:32.140 --> 2:45:33.540\n I'm getting my butt kicked.\n\n2:45:36.620 --> 2:45:38.180\n And I think that's gonna happen to everybody\n\n2:45:38.180 --> 2:45:40.220\n who's doing this kind of stuff.\n\n2:45:40.220 --> 2:45:45.220\n I think I expected you to ask me the meaning of life.\n\n2:45:46.020 --> 2:45:51.020\n I think that somehow I think that's gotta be part of it.\n\n2:45:52.780 --> 2:45:53.940\n Doing hard things?\n\n2:45:55.140 --> 2:45:56.460\n Yeah.\n\n2:45:56.460 --> 2:45:58.220\n Did you consider quitting at any point?\n\n2:45:58.220 --> 2:45:59.780\n Did you consider this isn't for me?\n\n2:45:59.780 --> 2:46:01.740\n No, never that.\n\n2:46:01.740 --> 2:46:06.740\n I was working hard, but I was loving it.\n\n2:46:07.180 --> 2:46:08.860\n I think there's this magical thing\n\n2:46:08.860 --> 2:46:11.900\n where I'm lucky to surround myself with people\n\n2:46:11.900 --> 2:46:16.900\n that basically almost every day I'll see something,\n\n2:46:17.900 --> 2:46:20.340\n I'll be told something or something that I realize,\n\n2:46:20.340 --> 2:46:22.020\n wow, I don't understand that.\n\n2:46:22.020 --> 2:46:24.180\n And if I could just understand that,\n\n2:46:24.180 --> 2:46:26.020\n there's something else to learn.\n\n2:46:26.020 --> 2:46:28.140\n That if I could just learn that thing,\n\n2:46:28.140 --> 2:46:30.220\n I would connect another piece of the puzzle.\n\n2:46:30.220 --> 2:46:35.220\n And I think that is just such an important aspect\n\n2:46:36.220 --> 2:46:40.260\n and being willing to understand what you can and can't do\n\n2:46:40.260 --> 2:46:43.580\n and loving the journey of going\n\n2:46:43.580 --> 2:46:44.820\n and learning those other things.\n\n2:46:44.820 --> 2:46:46.260\n I think that's the best part.\n\n2:46:47.340 --> 2:46:51.500\n I don't think there's a better way to end it, Russ.\n\n2:46:51.500 --> 2:46:55.580\n You've been an inspiration to me since I showed up at MIT.\n\n2:46:55.580 --> 2:46:57.700\n Your work has been an inspiration to the world.\n\n2:46:57.700 --> 2:46:59.740\n This conversation was amazing.\n\n2:46:59.740 --> 2:47:01.700\n I can't wait to see what you do next\n\n2:47:01.700 --> 2:47:03.220\n with robotics, home robots.\n\n2:47:03.220 --> 2:47:05.780\n I hope to see you work in my home one day.\n\n2:47:05.780 --> 2:47:08.100\n So thanks so much for talking today, it's been awesome.\n\n2:47:08.100 --> 2:47:09.480\n Cheers.\n\n2:47:09.480 --> 2:47:11.060\n Thanks for listening to this conversation\n\n2:47:11.060 --> 2:47:14.180\n with Russ Tedrick and thank you to our sponsors,\n\n2:47:14.180 --> 2:47:18.220\n Magic Spoon Cereal, BetterHelp and ExpressVPN.\n\n2:47:18.220 --> 2:47:20.180\n Please consider supporting this podcast\n\n2:47:20.180 --> 2:47:23.420\n by going to magicspoon.com slash Lex\n\n2:47:23.420 --> 2:47:25.500\n and using code Lex at checkout.\n\n2:47:25.500 --> 2:47:27.780\n Go into betterhelp.com slash Lex\n\n2:47:27.780 --> 2:47:32.780\n and signing up at expressvpn.com slash Lex pod.\n\n2:47:32.820 --> 2:47:36.180\n Click the links, buy the stuff, get the discount.\n\n2:47:36.180 --> 2:47:39.380\n It really is the best way to support this podcast.\n\n2:47:39.380 --> 2:47:41.520\n If you enjoy this thing, subscribe on YouTube,\n\n2:47:41.520 --> 2:47:43.700\n review it with five stars and up a podcast,\n\n2:47:43.700 --> 2:47:46.540\n support on Patreon or connect with me on Twitter\n\n2:47:46.540 --> 2:47:50.620\n at Lex Friedman spelled somehow without the E\n\n2:47:50.620 --> 2:47:53.460\n just F R I D M A N.\n\n2:47:53.460 --> 2:47:55.100\n And now let me leave you with some words\n\n2:47:55.100 --> 2:47:58.540\n from Neil deGrasse Tyson talking about robots in space\n\n2:47:58.540 --> 2:48:00.680\n and the emphasis we humans put\n\n2:48:00.680 --> 2:48:03.640\n on human based space exploration.\n\n2:48:03.640 --> 2:48:05.680\n Robots are important.\n\n2:48:05.680 --> 2:48:07.980\n If I don my pure scientist hat,\n\n2:48:07.980 --> 2:48:10.020\n I would say just send robots.\n\n2:48:10.020 --> 2:48:12.340\n I'll stay down here and get the data.\n\n2:48:12.340 --> 2:48:15.080\n But nobody's ever given a parade for a robot.\n\n2:48:15.080 --> 2:48:17.940\n Nobody's ever named a high school after a robot.\n\n2:48:17.940 --> 2:48:20.180\n So when I don my public educator hat,\n\n2:48:20.180 --> 2:48:22.780\n I have to recognize the elements of exploration\n\n2:48:22.780 --> 2:48:24.180\n that excite people.\n\n2:48:24.180 --> 2:48:26.980\n It's not only the discoveries and the beautiful photos\n\n2:48:26.980 --> 2:48:29.020\n that come down from the heavens.\n\n2:48:29.020 --> 2:48:33.020\n It's the vicarious participation in discovery itself.\n\n2:48:33.020 --> 2:48:54.020\n Thank you for listening and hope to see you next time.\n\n"
}
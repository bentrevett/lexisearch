{
  "title": "Andrew Ng: Deep Learning, Education, and Real-World AI | Lex Fridman Podcast #73",
  "id": "0jspaMLxBig",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:03.640\n The following is a conversation with Andrew Ng,\n\n00:03.640 --> 00:08.120\n one of the most impactful educators, researchers, innovators, and leaders\n\n00:08.120 --> 00:11.960\n in artificial intelligence and technology space in general.\n\n00:11.960 --> 00:15.320\n He cofounded Coursera and Google Brain,\n\n00:15.320 --> 00:19.640\n launched Deep Learning AI, Landing AI, and the AI Fund,\n\n00:19.640 --> 00:23.120\n and was the chief scientist at Baidu.\n\n00:23.120 --> 00:27.320\n As a Stanford professor and with Coursera and Deep Learning AI,\n\n00:27.320 --> 00:33.640\n he has helped educate and inspire millions of students, including me.\n\n00:33.640 --> 00:36.320\n This is the Artificial Intelligence Podcast.\n\n00:36.320 --> 00:40.520\n If you enjoy it, subscribe on YouTube, give it five stars on Apple Podcast,\n\n00:40.520 --> 00:43.800\n support it on Patreon, or simply connect with me on Twitter\n\n00:43.800 --> 00:48.360\n at Lex Friedman, spelled F R I D M A N.\n\n00:48.360 --> 00:51.280\n As usual, I'll do one or two minutes of ads now\n\n00:51.280 --> 00:54.960\n and never any ads in the middle that can break the flow of the conversation.\n\n00:54.960 --> 00:59.040\n I hope that works for you and doesn't hurt the listening experience.\n\n00:59.040 --> 01:03.640\n This show is presented by Cash App, the number one finance app in the App Store.\n\n01:03.640 --> 01:07.080\n When you get it, use code LEXPODCAST.\n\n01:07.080 --> 01:10.440\n Cash App lets you send money to friends, buy Bitcoin,\n\n01:10.440 --> 01:13.760\n and invest in the stock market with as little as $1.\n\n01:13.760 --> 01:16.760\n Broker services are provided by Cash App Investing,\n\n01:16.760 --> 01:20.800\n a subsidiary of Square, a member SIPC.\n\n01:20.800 --> 01:23.120\n Since Cash App allows you to buy Bitcoin,\n\n01:23.120 --> 01:28.840\n let me mention that cryptocurrency in the context of the history of money is fascinating.\n\n01:28.840 --> 01:33.800\n I recommend Ascent of Money as a great book on this history.\n\n01:33.800 --> 01:38.520\n Debits and credits on ledgers started over 30,000 years ago.\n\n01:38.520 --> 01:42.240\n The US dollar was created over 200 years ago,\n\n01:42.240 --> 01:48.200\n and Bitcoin, the first decentralized cryptocurrency, released just over 10 years ago.\n\n01:48.200 --> 01:53.640\n So given that history, cryptocurrency is still very much in its early days of development,\n\n01:53.640 --> 01:59.800\n but it's still aiming to and just might redefine the nature of money.\n\n01:59.800 --> 02:03.480\n So again, if you get Cash App from the App Store or Google Play\n\n02:03.480 --> 02:07.320\n and use the code LEXPODCAST, you'll get $10,\n\n02:07.320 --> 02:10.160\n and Cash App will also donate $10 to FIRST,\n\n02:10.160 --> 02:15.480\n one of my favorite organizations that is helping to advance robotics and STEM education\n\n02:15.480 --> 02:18.600\n for young people around the world.\n\n02:18.600 --> 02:23.200\n And now, here's my conversation with Andrew Ng.\n\n02:23.200 --> 02:25.920\n The courses you taught on machine learning at Stanford\n\n02:25.920 --> 02:31.880\n and later on Coursera that you cofounded have educated and inspired millions of people.\n\n02:31.880 --> 02:35.080\n So let me ask you, what people or ideas inspired you\n\n02:35.080 --> 02:39.200\n to get into computer science and machine learning when you were young?\n\n02:39.200 --> 02:43.840\n When did you first fall in love with the field, is another way to put it.\n\n02:43.840 --> 02:50.120\n Growing up in Hong Kong and Singapore, I started learning to code when I was five or six years old.\n\n02:50.120 --> 02:53.680\n At that time, I was learning the basic programming language,\n\n02:53.680 --> 02:56.160\n and they would take these books and they'll tell you,\n\n02:56.160 --> 03:00.080\n type this program into your computer, so type that program to my computer.\n\n03:00.080 --> 03:05.840\n And as a result of all that typing, I would get to play these very simple shoot them up games\n\n03:05.840 --> 03:09.880\n that I had implemented on my little computer.\n\n03:09.880 --> 03:14.920\n So I thought it was fascinating as a young kid that I could write this code.\n\n03:14.920 --> 03:18.280\n I was really just copying code from a book into my computer\n\n03:18.280 --> 03:21.000\n to then play these cool little video games.\n\n03:21.000 --> 03:27.080\n Another moment for me was when I was a teenager and my father,\n\n03:27.080 --> 03:31.400\n who's a doctor, was reading about expert systems and about neural networks.\n\n03:31.400 --> 03:34.800\n So he got me to read some of these books, and I thought it was really cool.\n\n03:34.800 --> 03:39.320\n You could write a computer that started to exhibit intelligence.\n\n03:39.320 --> 03:44.440\n Then I remember doing an internship while I was in high school, this was in Singapore,\n\n03:44.440 --> 03:50.360\n where I remember doing a lot of photocopying and as an office assistant.\n\n03:50.360 --> 03:53.800\n And the highlight of my job was when I got to use the shredder.\n\n03:53.800 --> 03:57.800\n So the teenager me, remote thinking, boy, this is a lot of photocopying.\n\n03:57.800 --> 04:01.080\n If only we could write software, build a robot, something to automate this,\n\n04:01.080 --> 04:03.000\n maybe I could do something else.\n\n04:03.000 --> 04:07.640\n So I think a lot of my work since then has centered on the theme of automation.\n\n04:07.640 --> 04:09.960\n Even the way I think about machine learning today,\n\n04:09.960 --> 04:14.920\n we're very good at writing learning algorithms that can automate things that people can do.\n\n04:14.920 --> 04:20.040\n Or even launching the first MOOCs, Mass Open Online Courses, that later led to Coursera.\n\n04:20.040 --> 04:25.320\n I was trying to automate what could be automatable in how I was teaching on campus.\n\n04:25.320 --> 04:30.280\n Process of education, trying to automate parts of that to make it more,\n\n04:30.280 --> 04:34.680\n sort of to have more impact from a single teacher, a single educator.\n\n04:34.680 --> 04:37.800\n Yeah, I felt, you know, teaching at Stanford,\n\n04:37.800 --> 04:41.240\n teaching machine learning to about 400 students a year at the time.\n\n04:41.240 --> 04:46.040\n And I found myself filming the exact same video every year,\n\n04:46.040 --> 04:48.680\n telling the same jokes in the same room.\n\n04:48.680 --> 04:50.200\n And I thought, why am I doing this?\n\n04:50.200 --> 04:51.720\n Why don't we just take last year's video?\n\n04:51.720 --> 04:55.240\n And then I can spend my time building a deeper relationship with students.\n\n04:55.240 --> 04:57.880\n So that process of thinking through how to do that,\n\n04:57.880 --> 05:00.520\n that led to the first MOOCs that we launched.\n\n05:00.520 --> 05:03.320\n And then you have more time to write new jokes.\n\n05:03.320 --> 05:06.200\n Are there favorite memories from your early days at Stanford,\n\n05:06.200 --> 05:11.240\n teaching thousands of people in person and then millions of people online?\n\n05:12.520 --> 05:19.720\n You know, teaching online, what not many people know was that a lot of those videos\n\n05:19.720 --> 05:24.520\n were shot between the hours of 10 p.m. and 3 a.m.\n\n05:24.520 --> 05:31.400\n A lot of times, we were launching the first MOOCs at Stanford.\n\n05:31.400 --> 05:33.960\n We had already announced the course, about 100,000 people signed up.\n\n05:33.960 --> 05:39.240\n We just started to write the code and we had not yet actually filmed the videos.\n\n05:39.240 --> 05:42.680\n So a lot of pressure, 100,000 people waiting for us to produce the content.\n\n05:43.320 --> 05:48.360\n So many Fridays, Saturdays, I would go out, have dinner with my friends,\n\n05:49.160 --> 05:51.480\n and then I would think, OK, do you want to go home now?\n\n05:51.480 --> 05:54.680\n Or do you want to go to the office to film videos?\n\n05:54.680 --> 05:59.400\n And the thought of being able to help 100,000 people potentially learn machine learning,\n\n05:59.400 --> 06:03.080\n fortunately, that made me think, OK, I want to go to my office,\n\n06:03.080 --> 06:05.320\n go to my tiny little recording studio.\n\n06:05.320 --> 06:10.520\n I would adjust my Logitech webcam, adjust my Wacom tablet,\n\n06:10.520 --> 06:12.440\n make sure my lapel mic was on,\n\n06:12.440 --> 06:15.880\n and then I would start recording often until 2 a.m. or 3 a.m.\n\n06:15.880 --> 06:20.360\n I think unfortunately, that doesn't show that it was recorded that late at night,\n\n06:20.360 --> 06:25.480\n but it was really inspiring the thought that we could create content\n\n06:25.480 --> 06:27.800\n to help so many people learn about machine learning.\n\n06:27.800 --> 06:28.600\n How did that feel?\n\n06:29.320 --> 06:31.400\n The fact that you're probably somewhat alone,\n\n06:31.400 --> 06:35.560\n maybe a couple of friends recording with a Logitech webcam\n\n06:36.120 --> 06:40.920\n and kind of going home alone at 1 or 2 a.m. at night\n\n06:40.920 --> 06:45.160\n and knowing that that's going to reach sort of thousands of people,\n\n06:45.160 --> 06:48.840\n eventually millions of people, what's that feeling like?\n\n06:48.840 --> 06:53.320\n I mean, is there a feeling of just satisfaction of pushing through?\n\n06:54.040 --> 06:55.160\n I think it's humbling.\n\n06:55.160 --> 06:57.960\n And I wasn't thinking about what I was feeling.\n\n06:57.960 --> 07:02.440\n I think one thing that I'm proud to say we got right from the early days\n\n07:02.440 --> 07:06.360\n was I told my whole team back then that the number one priority\n\n07:06.360 --> 07:09.160\n is to do what's best for learners, do what's best for students.\n\n07:09.160 --> 07:11.480\n And so when I went to the recording studio,\n\n07:11.480 --> 07:13.880\n the only thing on my mind was what can I say?\n\n07:13.880 --> 07:15.080\n How can I design my slides?\n\n07:15.080 --> 07:19.880\n What I need to draw right to make these concepts as clear as possible for learners?\n\n07:20.520 --> 07:24.120\n I think I've seen sometimes instructors is tempting to,\n\n07:24.120 --> 07:25.480\n hey, let's talk about my work.\n\n07:25.480 --> 07:27.400\n Maybe if I teach you about my research,\n\n07:27.400 --> 07:29.960\n someone will cite my papers a couple more times.\n\n07:29.960 --> 07:31.800\n And I think one of the things we got right,\n\n07:31.800 --> 07:34.200\n launching the first few MOOCs and later building Coursera,\n\n07:34.200 --> 07:37.080\n was putting in place that bedrock principle of\n\n07:37.080 --> 07:40.200\n let's just do what's best for learners and forget about everything else.\n\n07:40.200 --> 07:43.160\n And I think that that is a guiding principle\n\n07:43.160 --> 07:46.840\n turned out to be really important to the rise of the MOOC movement.\n\n07:46.840 --> 07:49.320\n And the kind of learner you imagined in your mind\n\n07:49.320 --> 07:53.880\n is as broad as possible, as global as possible.\n\n07:53.880 --> 07:56.280\n So really try to reach as many people\n\n07:56.280 --> 07:59.640\n interested in machine learning and AI as possible.\n\n07:59.640 --> 08:02.600\n I really want to help anyone that had an interest in machine learning\n\n08:03.160 --> 08:04.280\n to break into the field.\n\n08:05.560 --> 08:08.280\n And I think sometimes I've actually had people ask me,\n\n08:08.280 --> 08:11.560\n hey, why are you spending so much time explaining gradient descent?\n\n08:11.560 --> 08:15.560\n And my answer was, if I look at what I think the learner needs\n\n08:15.560 --> 08:18.280\n and what benefit from, I felt that having that\n\n08:18.920 --> 08:22.040\n a good understanding of the foundations coming back to the basics\n\n08:22.040 --> 08:25.880\n would put them in a better stead to then build on a long term career.\n\n08:26.840 --> 08:30.520\n So try to consistently make decisions on that principle.\n\n08:30.520 --> 08:35.160\n So one of the things you actually revealed to the narrow AI community\n\n08:35.800 --> 08:39.560\n at the time and to the world is that the amount of people\n\n08:39.560 --> 08:42.600\n who are actually interested in AI is much larger than we imagined.\n\n08:43.480 --> 08:46.200\n By you teaching the class and how popular it became,\n\n08:47.000 --> 08:50.920\n it showed that, wow, this isn't just a small community\n\n08:50.920 --> 08:56.680\n of sort of people who go to NeurIPS and it's much bigger.\n\n08:56.680 --> 08:59.800\n It's developers, it's people from all over the world.\n\n08:59.800 --> 09:03.320\n I mean, I'm Russian, so everybody in Russia is really interested.\n\n09:03.320 --> 09:06.600\n There's a huge number of programmers who are interested in machine learning,\n\n09:06.600 --> 09:10.680\n India, China, South America, everywhere.\n\n09:10.680 --> 09:13.480\n There's just millions of people who are interested in machine learning.\n\n09:13.480 --> 09:16.760\n So how big do you get a sense that the number of people\n\n09:16.760 --> 09:20.360\n is that are interested from your perspective?\n\n09:20.360 --> 09:22.360\n I think the number has grown over time.\n\n09:22.920 --> 09:26.360\n I think it's one of those things that maybe it feels like it came out of nowhere,\n\n09:26.360 --> 09:28.600\n but it's an insight that building it, it took years.\n\n09:28.600 --> 09:32.600\n It's one of those overnight successes that took years to get there.\n\n09:33.160 --> 09:35.960\n My first foray into this type of online education\n\n09:35.960 --> 09:37.880\n was when we were filming my Stanford class\n\n09:37.880 --> 09:40.360\n and sticking the videos on YouTube and some other things.\n\n09:40.360 --> 09:42.040\n We had uploaded the horrors and so on,\n\n09:42.040 --> 09:46.360\n but it's basically the one hour, 15 minute video that we put on YouTube.\n\n09:47.160 --> 09:51.240\n And then we had four or five other versions of websites that I had built,\n\n09:52.040 --> 09:53.800\n most of which you would never have heard of\n\n09:53.800 --> 09:55.720\n because they reached small audiences,\n\n09:55.720 --> 09:57.480\n but that allowed me to iterate,\n\n09:57.480 --> 09:59.000\n allowed my team and me to iterate,\n\n09:59.000 --> 10:01.480\n to learn what are the ideas that work and what doesn't.\n\n10:02.280 --> 10:04.920\n For example, one of the features I was really excited about\n\n10:04.920 --> 10:07.240\n and really proud of was build this website\n\n10:07.240 --> 10:10.600\n where multiple people could be logged into the website at the same time.\n\n10:11.240 --> 10:12.760\n So today, if you go to a website,\n\n10:13.480 --> 10:15.800\n if you are logged in and then I want to log in,\n\n10:15.800 --> 10:18.200\n you need to log out because it's the same browser, the same computer.\n\n10:18.760 --> 10:21.240\n But I thought, well, what if two people say you and me\n\n10:21.240 --> 10:24.200\n were watching a video together in front of a computer?\n\n10:24.200 --> 10:27.480\n What if a website could have you type your name and password,\n\n10:27.480 --> 10:28.920\n have me type my name and password,\n\n10:28.920 --> 10:31.720\n and then now the computer knows both of us are watching together\n\n10:31.720 --> 10:35.320\n and it gives both of us credit for anything we do as a group.\n\n10:35.320 --> 10:39.640\n Influencers feature rolled it out in a high school in San Francisco.\n\n10:39.640 --> 10:41.560\n We had about 20 something users.\n\n10:42.920 --> 10:43.880\n Where's the teacher there?\n\n10:43.880 --> 10:46.200\n Sacred Heart Cathedral Prep, the teacher is great.\n\n10:46.200 --> 10:47.400\n I mean, guess what?\n\n10:47.400 --> 10:49.080\n Zero people use this feature.\n\n10:49.720 --> 10:51.800\n It turns out people studying online,\n\n10:51.800 --> 10:53.960\n they want to watch the videos by themselves.\n\n10:53.960 --> 10:57.720\n So you can play back, pause at your own speed rather than in groups.\n\n10:57.720 --> 11:01.560\n So that was one example of a tiny lesson learned out of many\n\n11:01.560 --> 11:04.840\n that allowed us to hone into the set of features.\n\n11:04.840 --> 11:06.360\n It sounds like a brilliant feature.\n\n11:06.360 --> 11:09.000\n So I guess the lesson to take from that is\n\n11:11.080 --> 11:15.160\n there's something that looks amazing on paper and then nobody uses it.\n\n11:15.160 --> 11:18.200\n It doesn't actually have the impact that you think it might have.\n\n11:18.200 --> 11:21.640\n And so, yeah, I saw that you really went through a lot of different features\n\n11:21.640 --> 11:25.000\n and a lot of ideas to arrive at Coursera,\n\n11:25.000 --> 11:28.920\n the final kind of powerful thing that showed the world\n\n11:28.920 --> 11:32.040\n that MOOCs can educate millions.\n\n11:32.040 --> 11:35.480\n And I think with the whole machine learning movement as well,\n\n11:35.480 --> 11:38.280\n I think it didn't come out of nowhere.\n\n11:38.280 --> 11:42.200\n Instead, what happened was as more people learn about machine learning,\n\n11:42.200 --> 11:44.040\n they will tell their friends and their friends will see\n\n11:44.040 --> 11:45.880\n how it's applicable to their work.\n\n11:45.880 --> 11:48.680\n And then the community kept on growing.\n\n11:48.680 --> 11:49.720\n And I think we're still growing.\n\n11:50.920 --> 11:54.680\n I don't know in the future what percentage of all developers\n\n11:54.680 --> 11:56.040\n will be AI developers.\n\n11:56.040 --> 11:58.840\n I could easily see it being north of 50%, right?\n\n11:58.840 --> 12:03.880\n Because so many AI developers broadly construed,\n\n12:03.880 --> 12:05.800\n not just people doing the machine learning modeling,\n\n12:05.800 --> 12:08.840\n but the people building infrastructure, data pipelines,\n\n12:08.840 --> 12:12.440\n all the software surrounding the core machine learning model\n\n12:13.000 --> 12:14.600\n maybe is even bigger.\n\n12:14.600 --> 12:17.560\n I feel like today almost every software engineer\n\n12:17.560 --> 12:19.720\n has some understanding of the cloud.\n\n12:19.720 --> 12:23.160\n Not all, but maybe this is my microcontroller developer\n\n12:23.160 --> 12:24.760\n that doesn't need to deal with the cloud.\n\n12:24.760 --> 12:28.360\n But I feel like the vast majority of software engineers today\n\n12:28.360 --> 12:30.680\n are sort of having an appreciation of the cloud.\n\n12:31.320 --> 12:35.320\n I think in the future, maybe we'll approach nearly 100% of all developers\n\n12:35.320 --> 12:38.440\n being in some way an AI developer\n\n12:38.440 --> 12:41.240\n or at least having an appreciation of machine learning.\n\n12:41.240 --> 12:44.440\n And my hope is that there's this kind of effect\n\n12:44.440 --> 12:48.360\n that there's people who are not really interested in being a programmer\n\n12:48.360 --> 12:51.960\n or being into software engineering, like biologists, chemists,\n\n12:51.960 --> 12:55.480\n and physicists, even mechanical engineers,\n\n12:55.480 --> 13:00.760\n all these disciplines that are now more and more sitting on large data sets.\n\n13:01.560 --> 13:04.360\n And here they didn't think they're interested in programming\n\n13:04.360 --> 13:06.040\n until they have this data set and they realize\n\n13:06.040 --> 13:07.640\n there's this set of machine learning tools\n\n13:07.640 --> 13:09.320\n that allow you to use the data set.\n\n13:09.320 --> 13:12.040\n So they actually become, they learn to program\n\n13:12.040 --> 13:13.480\n and they become new programmers.\n\n13:13.480 --> 13:16.040\n So like the, not just because you've mentioned\n\n13:16.040 --> 13:19.240\n a larger percentage of developers become machine learning people.\n\n13:19.240 --> 13:24.200\n So it seems like more and more the kinds of people\n\n13:24.200 --> 13:27.560\n who are becoming developers is also growing significantly.\n\n13:27.560 --> 13:30.040\n Yeah, I think once upon a time,\n\n13:30.040 --> 13:34.040\n only a small part of humanity was literate, could read and write.\n\n13:34.040 --> 13:37.800\n And maybe you thought, maybe not everyone needs to learn to read and write.\n\n13:37.800 --> 13:44.360\n You just go listen to a few monks read to you and maybe that was enough.\n\n13:44.360 --> 13:47.960\n Or maybe you just need a few handful of authors to write the bestsellers\n\n13:47.960 --> 13:49.640\n and no one else needs to write.\n\n13:50.200 --> 13:52.920\n But what we found was that by giving as many people,\n\n13:53.480 --> 13:56.680\n in some countries, almost everyone, basic literacy,\n\n13:56.680 --> 13:59.320\n it dramatically enhanced human to human communications.\n\n13:59.320 --> 14:01.240\n And we can now write for an audience of one,\n\n14:01.240 --> 14:03.400\n such as if I send you an email or you send me an email.\n\n14:04.760 --> 14:07.640\n I think in computing, we're still in that phase\n\n14:07.640 --> 14:09.720\n where so few people know how to code\n\n14:09.720 --> 14:14.280\n that the coders mostly have to code for relatively large audiences.\n\n14:14.280 --> 14:20.360\n But if everyone, or most people became developers at some level,\n\n14:20.360 --> 14:24.280\n similar to how most people in developed economies are somewhat literate,\n\n14:24.280 --> 14:27.720\n I would love to see the owners of a mom and pop store\n\n14:27.720 --> 14:30.840\n be able to write a little bit of code to customize the TV display\n\n14:30.840 --> 14:32.280\n for their special this week.\n\n14:32.280 --> 14:35.560\n And I think it will enhance human to computer communications,\n\n14:36.280 --> 14:38.600\n which is becoming more and more important today as well.\n\n14:38.600 --> 14:41.640\n So you think it's possible that machine learning\n\n14:41.640 --> 14:45.000\n becomes kind of similar to literacy,\n\n14:45.000 --> 14:49.800\n where like you said, the owners of a mom and pop shop,\n\n14:49.800 --> 14:52.040\n is basically everybody in all walks of life\n\n14:52.040 --> 14:54.760\n would have some degree of programming capability?\n\n14:55.480 --> 14:57.560\n I could see society getting there.\n\n14:58.360 --> 14:59.480\n There's one other interesting thing.\n\n15:00.600 --> 15:02.680\n If I go talk to the mom and pop store,\n\n15:02.680 --> 15:05.240\n if I talk to a lot of people in their daily professions,\n\n15:05.240 --> 15:09.400\n I previously didn't have a good story for why they should learn to code.\n\n15:09.400 --> 15:11.080\n We could give them some reasons.\n\n15:11.080 --> 15:14.440\n But what I found with the rise of machine learning and data science is that\n\n15:14.440 --> 15:18.280\n I think the number of people with a concrete use for data science\n\n15:18.280 --> 15:20.360\n in their daily lives, in their jobs,\n\n15:20.360 --> 15:22.600\n may be even larger than the number of people\n\n15:22.600 --> 15:25.240\n who have concrete use for software engineering.\n\n15:25.240 --> 15:28.040\n For example, if you run a small mom and pop store,\n\n15:28.040 --> 15:31.880\n I think if you can analyze the data about your sales, your customers,\n\n15:31.880 --> 15:33.480\n I think there's actually real value there,\n\n15:34.120 --> 15:36.600\n maybe even more than traditional software engineering.\n\n15:37.160 --> 15:40.280\n So I find that for a lot of my friends in various professions,\n\n15:40.280 --> 15:45.080\n be it recruiters or accountants or people that work in the factories,\n\n15:45.080 --> 15:46.840\n which I deal with more and more these days,\n\n15:48.120 --> 15:51.160\n I feel if they were data scientists at some level,\n\n15:51.160 --> 15:53.400\n they could immediately use that in their work.\n\n15:54.440 --> 15:56.760\n So I think that data science and machine learning\n\n15:56.760 --> 16:00.280\n may be an even easier entree into the developer world\n\n16:00.280 --> 16:03.240\n for a lot of people than the software engineering.\n\n16:03.240 --> 16:04.280\n That's interesting.\n\n16:04.280 --> 16:06.360\n And I agree with that, but that's beautifully put.\n\n16:06.360 --> 16:11.320\n But we live in a world where most courses and talks have slides,\n\n16:11.320 --> 16:12.920\n PowerPoint, keynote,\n\n16:12.920 --> 16:16.600\n and yet you famously often still use a marker and a whiteboard.\n\n16:17.400 --> 16:19.480\n The simplicity of that is compelling,\n\n16:19.480 --> 16:21.320\n and for me at least, fun to watch.\n\n16:22.200 --> 16:25.960\n So let me ask, why do you like using a marker and whiteboard,\n\n16:25.960 --> 16:27.480\n even on the biggest of stages?\n\n16:28.920 --> 16:31.480\n I think it depends on the concepts you want to explain.\n\n16:32.520 --> 16:34.120\n For mathematical concepts,\n\n16:34.120 --> 16:36.440\n it's nice to build up the equation one piece at a time,\n\n16:37.000 --> 16:41.320\n and the whiteboard marker or the pen and stylus\n\n16:41.320 --> 16:43.880\n is a very easy way to build up the equation,\n\n16:43.880 --> 16:46.680\n to build up a complex concept one piece at a time\n\n16:47.320 --> 16:48.440\n while you're talking about it,\n\n16:48.440 --> 16:51.400\n and sometimes that enhances understandability.\n\n16:52.680 --> 16:54.760\n The downside of writing is that it's slow,\n\n16:54.760 --> 16:57.240\n and so if you want a long sentence, it's very hard to write that.\n\n16:57.240 --> 16:58.360\n So I think there are pros and cons,\n\n16:58.360 --> 17:00.360\n and sometimes I use slides,\n\n17:00.360 --> 17:03.160\n and sometimes I use a whiteboard or a stylus.\n\n17:03.160 --> 17:05.640\n The slowness of a whiteboard is also its upside,\n\n17:06.200 --> 17:10.600\n because it forces you to reduce everything to the basics.\n\n17:12.600 --> 17:14.760\n Some of your talks involve the whiteboard.\n\n17:14.760 --> 17:17.720\n I mean, you go very slowly,\n\n17:17.720 --> 17:20.040\n and you really focus on the most simple principles,\n\n17:20.040 --> 17:21.160\n and that's a beautiful,\n\n17:22.760 --> 17:26.440\n that enforces a kind of a minimalism of ideas\n\n17:26.440 --> 17:31.560\n that I think is surprising at least for me is great for education.\n\n17:31.560 --> 17:36.360\n Like a great talk, I think, is not one that has a lot of content.\n\n17:36.920 --> 17:41.800\n A great talk is one that just clearly says a few simple ideas,\n\n17:41.800 --> 17:45.480\n and I think the whiteboard somehow enforces that.\n\n17:46.280 --> 17:49.400\n Peter Abbeel, who's now one of the top roboticists\n\n17:49.400 --> 17:51.400\n and reinforcement learning experts in the world,\n\n17:51.400 --> 17:52.920\n was your first PhD student.\n\n17:54.280 --> 17:56.760\n So I bring him up just because I kind of imagine\n\n17:58.360 --> 18:01.400\n this must have been an interesting time in your life,\n\n18:01.400 --> 18:04.840\n and do you have any favorite memories of working with Peter,\n\n18:04.840 --> 18:08.280\n since you were your first student in those uncertain times,\n\n18:08.280 --> 18:14.840\n especially before deep learning really sort of blew up?\n\n18:15.400 --> 18:17.000\n Any favorite memories from those times?\n\n18:17.720 --> 18:20.680\n Yeah, I was really fortunate to have had Peter Abbeel\n\n18:20.680 --> 18:22.040\n as my first PhD student,\n\n18:22.600 --> 18:25.480\n and I think even my long term professional success\n\n18:25.480 --> 18:27.640\n builds on early foundations or early work\n\n18:27.640 --> 18:29.880\n that Peter was so critical to.\n\n18:29.880 --> 18:32.920\n So I was really grateful to him for working with me.\n\n18:34.840 --> 18:39.720\n What not a lot of people know is just how hard research was,\n\n18:39.720 --> 18:40.760\n and still is.\n\n18:42.200 --> 18:44.840\n Peter's PhD thesis was using reinforcement learning\n\n18:44.840 --> 18:46.040\n to fly helicopters.\n\n18:47.080 --> 18:51.640\n And so, even today, the website heli.stanford.edu,\n\n18:51.640 --> 18:53.320\n heli.stanford.edu is still up.\n\n18:53.320 --> 18:56.200\n You can watch videos of us using reinforcement learning\n\n18:56.200 --> 18:57.960\n to make a helicopter fly upside down,\n\n18:57.960 --> 18:59.880\n fly loose roses, so it's cool.\n\n18:59.880 --> 19:02.360\n It's one of the most incredible robotics videos ever,\n\n19:02.360 --> 19:03.560\n so people should watch it.\n\n19:03.560 --> 19:04.280\n Oh yeah, thank you.\n\n19:04.280 --> 19:05.000\n It's inspiring.\n\n19:05.000 --> 19:10.360\n That's from like 2008 or seven or six, like that range.\n\n19:10.360 --> 19:11.400\n Yeah, something like that.\n\n19:11.400 --> 19:12.920\n Yeah, so it was over 10 years old.\n\n19:12.920 --> 19:14.760\n That was really inspiring to a lot of people, yeah.\n\n19:15.320 --> 19:18.040\n What not many people see is how hard it was.\n\n19:18.920 --> 19:22.680\n So Peter and Adam Coase and Morgan Quigley and I\n\n19:22.680 --> 19:25.400\n were working on various versions of the helicopter,\n\n19:25.400 --> 19:27.320\n and a lot of things did not work.\n\n19:27.320 --> 19:29.800\n For example, it turns out one of the hardest problems we had\n\n19:29.800 --> 19:32.200\n was when the helicopter's flying around upside down,\n\n19:32.200 --> 19:34.760\n doing stunts, how do you figure out the position?\n\n19:34.760 --> 19:36.760\n How do you localize the helicopter?\n\n19:36.760 --> 19:38.280\n So we wanted to try all sorts of things.\n\n19:38.840 --> 19:41.080\n Having one GPS unit doesn't work\n\n19:41.080 --> 19:42.120\n because you're flying upside down,\n\n19:42.120 --> 19:44.760\n the GPS unit's facing down, so you can't see the satellites.\n\n19:44.760 --> 19:48.520\n So we experimented trying to have two GPS units,\n\n19:48.520 --> 19:49.880\n one facing up, one facing down.\n\n19:49.880 --> 19:51.720\n So if you flip over, that didn't work\n\n19:51.720 --> 19:54.200\n because the downward facing one couldn't synchronize\n\n19:54.200 --> 19:55.880\n if you're flipping quickly.\n\n19:55.880 --> 19:58.520\n Morgan Quigley was exploring this crazy,\n\n19:58.520 --> 20:01.560\n complicated configuration of specialized hardware\n\n20:01.560 --> 20:03.800\n to interpret GPS signals.\n\n20:03.800 --> 20:06.040\n Looking at the FPG is completely insane.\n\n20:06.040 --> 20:09.480\n Spent about a year working on that, didn't work.\n\n20:09.480 --> 20:13.400\n So I remember Peter, great guy, him and me,\n\n20:13.400 --> 20:17.160\n sitting down in my office looking at some of the latest things\n\n20:17.160 --> 20:19.560\n we had tried that didn't work and saying,\n\n20:20.920 --> 20:22.440\n done it, what now?\n\n20:22.440 --> 20:25.720\n Because we tried so many things and it just didn't work.\n\n20:25.720 --> 20:31.240\n In the end, what we did, and Adam Coles was crucial to this,\n\n20:31.240 --> 20:34.280\n was put cameras on the ground and use cameras on the ground\n\n20:34.280 --> 20:35.880\n to localize the helicopter.\n\n20:35.880 --> 20:38.600\n And that solved the localization problem\n\n20:38.600 --> 20:41.080\n so that we could then focus on the reinforcement learning\n\n20:41.080 --> 20:43.160\n and inverse reinforcement learning techniques\n\n20:43.160 --> 20:44.920\n so it didn't actually make the helicopter fly.\n\n20:46.600 --> 20:50.600\n And I'm reminded, when I was doing this work at Stanford,\n\n20:50.600 --> 20:54.040\n around that time, there was a lot of reinforcement learning\n\n20:54.040 --> 20:57.800\n theoretical papers, but not a lot of practical applications.\n\n20:58.360 --> 21:02.120\n So the autonomous helicopter work for flying helicopters\n\n21:02.120 --> 21:05.400\n was one of the few practical applications\n\n21:05.400 --> 21:06.840\n of reinforcement learning at the time,\n\n21:06.840 --> 21:09.960\n which caused it to become pretty well known.\n\n21:10.440 --> 21:13.560\n I feel like we might have almost come full circle with today.\n\n21:13.560 --> 21:16.280\n There's so much buzz, so much hype, so much excitement\n\n21:16.280 --> 21:17.720\n about reinforcement learning.\n\n21:17.720 --> 21:20.600\n But again, we're hunting for more applications\n\n21:20.600 --> 21:23.800\n of all of these great ideas that David Kuhnke has come up with.\n\n21:23.800 --> 21:28.120\n What was the drive sort of in the face of the fact\n\n21:28.120 --> 21:30.040\n that most people are doing theoretical work?\n\n21:30.040 --> 21:32.920\n What motivates you in the uncertainty and the challenges\n\n21:32.920 --> 21:36.360\n to get the helicopter sort of to do the applied work,\n\n21:36.360 --> 21:38.200\n to get the actual system to work?\n\n21:39.320 --> 21:43.240\n Yeah, in the face of fear, uncertainty, sort of the setbacks\n\n21:43.240 --> 21:44.920\n that you mentioned for localization.\n\n21:45.880 --> 21:47.080\n I like stuff that works.\n\n21:47.960 --> 21:48.840\n In the physical world.\n\n21:48.840 --> 21:50.920\n So like, it's back to the shredder.\n\n21:50.920 --> 21:55.400\n You know, I like theory, but when I work on theory myself,\n\n21:55.400 --> 21:56.440\n and this is personal taste,\n\n21:56.440 --> 21:58.600\n I'm not saying anyone else should do what I do.\n\n21:58.600 --> 22:01.880\n But when I work on theory, I personally enjoy it more\n\n22:01.880 --> 22:06.360\n if I feel that the work I do will influence people,\n\n22:06.360 --> 22:08.360\n have positive impact, or help someone.\n\n22:10.040 --> 22:12.680\n I remember when many years ago,\n\n22:12.680 --> 22:14.680\n I was speaking with a mathematics professor,\n\n22:15.480 --> 22:18.280\n and it kind of just said, hey, why do you do what you do?\n\n22:18.280 --> 22:20.360\n It kind of just said, hey, why do you do what you do?\n\n22:21.160 --> 22:25.640\n And then he said, he had stars in his eyes when he answered.\n\n22:25.640 --> 22:28.760\n And this mathematician, not from Stanford,\n\n22:28.760 --> 22:31.320\n different university, he said, I do what I do\n\n22:31.320 --> 22:35.320\n because it helps me to discover truth and beauty\n\n22:35.320 --> 22:36.600\n in the universe.\n\n22:36.600 --> 22:38.360\n He had stars in his eyes when he said that.\n\n22:38.360 --> 22:39.320\n And I thought, that's great.\n\n22:41.240 --> 22:42.440\n I don't want to do that.\n\n22:42.440 --> 22:44.040\n I think it's great that someone does that,\n\n22:44.040 --> 22:45.320\n fully support the people that do it,\n\n22:45.320 --> 22:46.920\n a lot of respect for people that do that.\n\n22:46.920 --> 22:50.680\n But I am more motivated when I can see a line\n\n22:50.680 --> 22:55.160\n to how the work that my teams and I are doing helps people.\n\n22:56.920 --> 22:58.440\n The world needs all sorts of people.\n\n22:58.440 --> 22:59.320\n I'm just one type.\n\n22:59.320 --> 23:01.160\n I don't think everyone should do things\n\n23:01.160 --> 23:02.360\n the same way as I do.\n\n23:02.360 --> 23:05.960\n But when I delve into either theory or practice,\n\n23:05.960 --> 23:09.320\n if I personally have conviction that here's a pathway\n\n23:09.320 --> 23:13.560\n to help people, I find that more satisfying\n\n23:14.200 --> 23:15.160\n to have that conviction.\n\n23:15.160 --> 23:17.560\n That's your path.\n\n23:17.560 --> 23:19.960\n You were a proponent of deep learning\n\n23:19.960 --> 23:22.200\n before it gained widespread acceptance.\n\n23:23.320 --> 23:26.120\n What did you see in this field that gave you confidence?\n\n23:26.120 --> 23:28.680\n What was your thinking process like in that first decade\n\n23:28.680 --> 23:32.840\n of the, I don't know what that's called, 2000s, the aughts?\n\n23:33.720 --> 23:35.480\n Yeah, I can tell you the thing we got wrong\n\n23:35.480 --> 23:36.760\n and the thing we got right.\n\n23:36.760 --> 23:39.320\n The thing we really got wrong was the importance of,\n\n23:40.520 --> 23:42.840\n the early importance of unsupervised learning.\n\n23:42.840 --> 23:46.040\n So early days of Google Brain,\n\n23:46.040 --> 23:48.040\n we put a lot of effort into unsupervised learning\n\n23:48.040 --> 23:49.560\n rather than supervised learning.\n\n23:49.560 --> 23:50.840\n And there was this argument,\n\n23:50.840 --> 23:55.400\n I think it was around 2005 after NeurIPS,\n\n23:55.400 --> 23:58.280\n at that time called NIPS, but now NeurIPS had ended.\n\n23:58.280 --> 24:01.320\n And Jeff Hinton and I were sitting in the cafeteria\n\n24:01.320 --> 24:02.680\n outside the conference.\n\n24:02.680 --> 24:04.200\n We had lunch, we were just chatting.\n\n24:04.200 --> 24:05.480\n And Jeff pulled up this napkin.\n\n24:05.480 --> 24:07.960\n He started sketching this argument on a napkin.\n\n24:07.960 --> 24:10.120\n It was very compelling, as I'll repeat it.\n\n24:10.120 --> 24:12.520\n Human brain has about a hundred trillion.\n\n24:12.520 --> 24:15.240\n So there's 10 to the 14 synaptic connections.\n\n24:16.200 --> 24:19.480\n You will live for about 10 to the nine seconds.\n\n24:19.480 --> 24:20.360\n That's 30 years.\n\n24:20.360 --> 24:22.760\n You actually live for two by 10 to the nine,\n\n24:22.760 --> 24:24.200\n maybe three by 10 to the nine seconds.\n\n24:24.200 --> 24:25.480\n So just let's say 10 to the nine.\n\n24:26.440 --> 24:29.000\n So if each synaptic connection,\n\n24:29.000 --> 24:31.000\n each weight in your brain's neural network\n\n24:31.000 --> 24:33.240\n has just a one bit parameter,\n\n24:33.240 --> 24:35.720\n that's 10 to the 14 bits you need to learn\n\n24:36.440 --> 24:38.920\n in up to 10 to the nine seconds.\n\n24:38.920 --> 24:41.000\n 10 to the nine seconds of your life.\n\n24:41.800 --> 24:43.560\n So via this simple argument,\n\n24:43.560 --> 24:45.960\n which is a lot of problems, it's very simplified.\n\n24:45.960 --> 24:47.480\n That's 10 to the five bits per second\n\n24:47.480 --> 24:49.080\n you need to learn in your life.\n\n24:49.720 --> 24:51.480\n And I have a one year old daughter.\n\n24:52.440 --> 24:56.440\n I am not pointing out 10 to five bits per second\n\n24:56.440 --> 24:57.960\n of labels to her.\n\n24:59.640 --> 25:01.960\n And I think I'm a very loving parent,\n\n25:01.960 --> 25:03.080\n but I'm just not gonna do that.\n\n25:04.840 --> 25:08.680\n So from this very crude, definitely problematic argument,\n\n25:08.680 --> 25:11.240\n there's just no way that most of what we know\n\n25:11.240 --> 25:12.760\n is through supervised learning.\n\n25:13.320 --> 25:15.160\n But where you get so many bits of information\n\n25:15.160 --> 25:16.840\n is from sucking in images, audio,\n\n25:16.840 --> 25:18.280\n those experiences in the world.\n\n25:19.480 --> 25:21.320\n And so that argument,\n\n25:21.320 --> 25:23.080\n and there are a lot of known forces argument\n\n25:23.080 --> 25:24.680\n you should go into,\n\n25:24.680 --> 25:26.840\n really convinced me that there's a lot of power\n\n25:26.840 --> 25:27.880\n to unsupervised learning.\n\n25:29.400 --> 25:32.360\n So that was the part that we actually maybe got wrong.\n\n25:32.360 --> 25:34.680\n I still think unsupervised learning is really important,\n\n25:34.680 --> 25:38.760\n but in the early days, 10, 15 years ago,\n\n25:38.760 --> 25:41.080\n a lot of us thought that was the path forward.\n\n25:41.080 --> 25:43.400\n Oh, so you're saying that that perhaps\n\n25:43.400 --> 25:45.560\n was the wrong intuition for the time.\n\n25:45.560 --> 25:47.560\n For the time, that was the part we got wrong.\n\n25:48.440 --> 25:51.560\n The part we got right was the importance of scale.\n\n25:51.560 --> 25:55.400\n So Adam Coates, another wonderful person,\n\n25:55.960 --> 25:57.080\n fortunate to have worked with him,\n\n25:57.960 --> 25:59.880\n he was in my group at Stanford at the time\n\n25:59.880 --> 26:02.280\n and Adam had run these experiments at Stanford\n\n26:02.280 --> 26:05.960\n showing that the bigger we train a learning algorithm,\n\n26:05.960 --> 26:07.240\n the better its performance.\n\n26:07.800 --> 26:09.960\n And it was based on that.\n\n26:09.960 --> 26:11.720\n There was a graph that Adam generated\n\n26:12.760 --> 26:15.640\n where the X axis, Y axis lines going up into the right.\n\n26:15.640 --> 26:17.320\n So the bigger you make this thing,\n\n26:17.320 --> 26:20.200\n the better its performance accuracy is the vertical axis.\n\n26:20.200 --> 26:22.600\n So it's really based on that chart that Adam generated\n\n26:22.600 --> 26:23.800\n that he gave me the conviction\n\n26:23.800 --> 26:26.120\n that you could scale these models way bigger\n\n26:26.120 --> 26:27.720\n than what we could on a few CPUs,\n\n26:27.720 --> 26:29.240\n which is where we had at Stanford\n\n26:29.240 --> 26:31.400\n that we could get even better results.\n\n26:31.400 --> 26:33.240\n And it was really based on that one figure\n\n26:33.240 --> 26:34.920\n that Adam generated\n\n26:34.920 --> 26:38.600\n that gave me the conviction to go with Sebastian Thrun\n\n26:38.600 --> 26:42.600\n to pitch starting a project at Google,\n\n26:42.600 --> 26:43.960\n which became the Google Brain project.\n\n26:43.960 --> 26:45.640\n The Brain, you go find a Google Brain.\n\n26:45.640 --> 26:48.920\n And there the intuition was scale\n\n26:48.920 --> 26:52.120\n will bring performance for the system.\n\n26:52.120 --> 26:54.760\n So we should chase a larger and larger scale.\n\n26:55.320 --> 27:00.040\n And I think people don't realize how groundbreaking of it.\n\n27:00.040 --> 27:02.200\n It's simple, but it's a groundbreaking idea\n\n27:02.200 --> 27:05.960\n that bigger data sets will result in better performance.\n\n27:05.960 --> 27:08.600\n It was controversial at the time.\n\n27:08.600 --> 27:10.120\n Some of my well meaning friends,\n\n27:10.120 --> 27:11.480\n senior people in the machine learning community,\n\n27:11.480 --> 27:15.000\n I won't name, but some of whom we know,\n\n27:16.040 --> 27:17.800\n my well meaning friends came\n\n27:17.800 --> 27:19.160\n and were trying to give me friendly,\n\n27:19.160 --> 27:20.840\n I was like, hey, Andrew, why are you doing this?\n\n27:20.840 --> 27:21.720\n This is crazy.\n\n27:21.720 --> 27:23.160\n It's in the near natural architecture.\n\n27:23.160 --> 27:24.760\n Look at these architectures of building.\n\n27:24.760 --> 27:25.960\n You just want to go for scale?\n\n27:25.960 --> 27:27.320\n Like this is a bad career move.\n\n27:27.320 --> 27:29.000\n So my well meaning friends,\n\n27:29.000 --> 27:32.120\n some of them were trying to talk me out of it.\n\n27:33.960 --> 27:35.880\n But I find that if you want to make a breakthrough,\n\n27:36.760 --> 27:38.920\n you sometimes have to have conviction\n\n27:38.920 --> 27:40.920\n and do something before it's popular,\n\n27:40.920 --> 27:42.440\n since that lets you have a bigger impact.\n\n27:43.000 --> 27:45.400\n Let me ask you just a small tangent on that topic.\n\n27:45.960 --> 27:51.320\n I find myself arguing with people saying that greater scale,\n\n27:51.320 --> 27:53.400\n especially in the context of active learning,\n\n27:53.400 --> 27:56.840\n so very carefully selecting the data set,\n\n27:56.840 --> 27:59.160\n but growing the scale of the data set\n\n27:59.160 --> 28:01.560\n is going to lead to even further breakthroughs\n\n28:01.560 --> 28:02.680\n in deep learning.\n\n28:02.680 --> 28:05.800\n And there's currently pushback at that idea\n\n28:05.800 --> 28:07.800\n that larger data sets are no longer,\n\n28:09.000 --> 28:11.800\n so you want to increase the efficiency of learning.\n\n28:11.800 --> 28:13.960\n You want to make better learning mechanisms.\n\n28:13.960 --> 28:17.640\n And I personally believe that bigger data sets will still,\n\n28:17.640 --> 28:19.880\n with the same learning methods we have now,\n\n28:19.880 --> 28:21.720\n will result in better performance.\n\n28:21.720 --> 28:23.400\n What's your intuition at this time\n\n28:23.400 --> 28:27.480\n on this dual side?\n\n28:27.480 --> 28:31.240\n Do we need to come up with better architectures for learning\n\n28:31.240 --> 28:35.080\n or can we just get bigger, better data sets\n\n28:35.080 --> 28:36.360\n that will improve performance?\n\n28:37.160 --> 28:40.360\n I think both are important and it's also problem dependent.\n\n28:40.360 --> 28:41.800\n So for a few data sets,\n\n28:41.800 --> 28:45.960\n we may be approaching a Bayes error rate\n\n28:45.960 --> 28:48.600\n or approaching or surpassing human level performance\n\n28:48.600 --> 28:50.680\n and then there's that theoretical ceiling\n\n28:50.680 --> 28:51.880\n that we will never surpass,\n\n28:51.880 --> 28:53.480\n so Bayes error rate.\n\n28:54.520 --> 28:56.120\n But then I think there are plenty of problems\n\n28:56.120 --> 28:57.960\n where we're still quite far\n\n28:57.960 --> 28:59.640\n from either human level performance\n\n28:59.640 --> 29:00.840\n or from Bayes error rate\n\n29:00.840 --> 29:04.200\n and bigger data sets with neural networks\n\n29:05.240 --> 29:07.000\n without further algorithmic innovation\n\n29:07.000 --> 29:09.160\n will be sufficient to take us further.\n\n29:10.280 --> 29:11.240\n But on the flip side,\n\n29:11.240 --> 29:12.760\n if we look at the recent breakthroughs\n\n29:12.760 --> 29:15.480\n using transforming networks or language models,\n\n29:15.480 --> 29:18.200\n it was a combination of novel architecture\n\n29:18.200 --> 29:20.440\n but also scale had a lot to do with it.\n\n29:20.440 --> 29:22.920\n If we look at what happened with GP2 and BERTZ,\n\n29:22.920 --> 29:25.560\n I think scale was a large part of the story.\n\n29:26.200 --> 29:28.200\n Yeah, that's not often talked about\n\n29:28.200 --> 29:30.920\n is the scale of the data set it was trained on\n\n29:30.920 --> 29:32.360\n and the quality of the data set\n\n29:32.360 --> 29:33.880\n because there's some,\n\n29:35.000 --> 29:37.560\n so it was like reddit threads that had,\n\n29:38.280 --> 29:39.880\n they were operated highly.\n\n29:39.880 --> 29:42.920\n So there's already some weak supervision\n\n29:42.920 --> 29:44.680\n on a very large data set\n\n29:44.680 --> 29:46.360\n that people don't often talk about, right?\n\n29:47.160 --> 29:50.360\n I find that today we have maturing processes\n\n29:50.360 --> 29:51.640\n to managing code,\n\n29:52.360 --> 29:53.400\n things like Git, right?\n\n29:53.400 --> 29:54.520\n Version control.\n\n29:54.520 --> 29:57.320\n It took us a long time to evolve the good processes.\n\n29:58.360 --> 29:59.560\n I remember when my friends and I\n\n29:59.560 --> 30:02.200\n were emailing each other C++ files in email,\n\n30:02.200 --> 30:03.080\n but then we had,\n\n30:03.080 --> 30:05.080\n was it CVS or version Git?\n\n30:05.080 --> 30:06.280\n Maybe something else in the future.\n\n30:07.400 --> 30:10.600\n We're very mature in terms of tools for managing data\n\n30:10.600 --> 30:11.960\n and think about the clean data\n\n30:11.960 --> 30:14.600\n and how to solve down very hot, messy data problems.\n\n30:15.320 --> 30:17.160\n I think there's a lot of innovation there\n\n30:17.160 --> 30:17.960\n to be had still.\n\n30:17.960 --> 30:21.160\n I love the idea that you were versioning through email.\n\n30:21.960 --> 30:23.080\n I'll give you one example.\n\n30:23.880 --> 30:27.880\n When we work with manufacturing companies,\n\n30:29.160 --> 30:31.160\n it's not at all uncommon\n\n30:31.160 --> 30:34.200\n for there to be multiple labels\n\n30:34.200 --> 30:36.280\n that disagree with each other, right?\n\n30:36.280 --> 30:39.720\n And so we would do the work in visual inspection.\n\n30:40.440 --> 30:42.920\n We will take, say, a plastic part\n\n30:42.920 --> 30:44.680\n and show it to one inspector\n\n30:44.680 --> 30:47.160\n and the inspector, sometimes very opinionated,\n\n30:47.160 --> 30:48.520\n they'll go, clearly, that's a defect.\n\n30:48.520 --> 30:49.640\n This scratch, unacceptable.\n\n30:49.640 --> 30:51.160\n Gotta reject this part.\n\n30:51.160 --> 30:53.320\n Take the same part to different inspector,\n\n30:53.320 --> 30:54.920\n different, very opinionated.\n\n30:54.920 --> 30:56.200\n Clearly, the scratch is small.\n\n30:56.200 --> 30:56.760\n It's fine.\n\n30:56.760 --> 30:57.480\n Don't throw it away.\n\n30:57.480 --> 30:58.680\n You're gonna make us, you know.\n\n30:59.240 --> 31:01.800\n And then sometimes you take the same plastic part,\n\n31:01.800 --> 31:03.400\n show it to the same inspector\n\n31:03.400 --> 31:05.400\n in the afternoon, I suppose, in the morning,\n\n31:05.400 --> 31:07.480\n and very opinionated go, in the morning,\n\n31:07.480 --> 31:08.680\n they say, clearly, it's okay.\n\n31:08.680 --> 31:10.600\n In the afternoon, equally confident.\n\n31:10.600 --> 31:12.280\n Clearly, this is a defect.\n\n31:12.280 --> 31:14.760\n And so what is an AI team supposed to do\n\n31:14.760 --> 31:17.400\n if sometimes even one person doesn't agree\n\n31:17.400 --> 31:19.720\n with himself or herself in the span of a day?\n\n31:20.280 --> 31:23.640\n So I think these are the types of very practical,\n\n31:23.640 --> 31:28.520\n very messy data problems that my teams wrestle with.\n\n31:30.200 --> 31:32.840\n In the case of large consumer internet companies\n\n31:32.840 --> 31:34.200\n where you have a billion users,\n\n31:34.200 --> 31:35.480\n you have a lot of data.\n\n31:35.480 --> 31:36.360\n You don't worry about it.\n\n31:36.360 --> 31:37.160\n Just take the average.\n\n31:37.160 --> 31:38.280\n It kind of works.\n\n31:38.280 --> 31:40.760\n But in a case of other industry settings,\n\n31:40.760 --> 31:42.360\n we don't have big data.\n\n31:42.360 --> 31:44.520\n If just a small data, very small data sets,\n\n31:44.520 --> 31:46.520\n maybe around 100 defective parts\n\n31:47.720 --> 31:49.720\n or 100 examples of a defect.\n\n31:49.720 --> 31:51.320\n If you have only 100 examples,\n\n31:51.320 --> 31:53.240\n these little labeling errors,\n\n31:53.240 --> 31:55.800\n if 10 of your 100 labels are wrong,\n\n31:55.800 --> 31:58.520\n that actually is 10% of your data set has a big impact.\n\n31:58.520 --> 31:59.640\n So how do you clean this up?\n\n31:59.640 --> 32:00.520\n What are you supposed to do?\n\n32:01.160 --> 32:03.400\n This is an example of the types of things\n\n32:03.400 --> 32:06.680\n that my teams, this is a landing AI example,\n\n32:06.680 --> 32:09.000\n are wrestling with to deal with small data,\n\n32:09.000 --> 32:10.040\n which comes up all the time\n\n32:10.040 --> 32:12.120\n once you're outside consumer internet.\n\n32:12.120 --> 32:13.000\n Yeah, that's fascinating.\n\n32:13.000 --> 32:15.240\n So then you invest more effort and time\n\n32:15.240 --> 32:18.040\n in thinking about the actual labeling process.\n\n32:18.040 --> 32:19.560\n What are the labels?\n\n32:19.560 --> 32:22.440\n What are the how are disagreements resolved\n\n32:22.440 --> 32:25.640\n and all those kinds of like pragmatic real world problems.\n\n32:25.640 --> 32:27.240\n That's a fascinating space.\n\n32:27.240 --> 32:29.560\n Yeah, I find that actually when I'm teaching at Stanford,\n\n32:29.560 --> 32:32.680\n I increasingly encourage students at Stanford\n\n32:32.680 --> 32:35.960\n to try to find their own project\n\n32:37.080 --> 32:38.280\n for the end of term project,\n\n32:38.280 --> 32:40.360\n rather than just downloading someone else's\n\n32:40.360 --> 32:41.880\n nicely clean data set.\n\n32:41.880 --> 32:43.320\n It's actually much harder if you need to go\n\n32:43.320 --> 32:45.480\n and define your own problem and find your own data set,\n\n32:45.480 --> 32:48.680\n rather than you go to one of the several good websites,\n\n32:48.680 --> 32:52.760\n very good websites with clean scoped data sets\n\n32:52.760 --> 32:53.800\n that you could just work on.\n\n32:55.240 --> 32:56.920\n You're now running three efforts,\n\n32:56.920 --> 33:01.320\n the AI Fund, Landing AI, and deeplearning.ai.\n\n33:02.280 --> 33:04.520\n As you've said, the AI Fund is involved\n\n33:04.520 --> 33:06.600\n in creating new companies from scratch.\n\n33:06.600 --> 33:08.520\n Landing AI is involved in helping\n\n33:08.520 --> 33:10.440\n already established companies do AI\n\n33:10.440 --> 33:14.600\n and deeplearning.ai is for education of everyone else\n\n33:14.600 --> 33:18.040\n or of individuals interested in getting into the field\n\n33:18.040 --> 33:19.320\n and excelling in it.\n\n33:19.320 --> 33:22.280\n So let's perhaps talk about each of these areas.\n\n33:22.280 --> 33:24.200\n First, deeplearning.ai.\n\n33:25.560 --> 33:27.640\n How, the basic question,\n\n33:27.640 --> 33:30.040\n how does a person interested in deep learning\n\n33:30.040 --> 33:31.240\n get started in the field?\n\n33:32.280 --> 33:35.640\n Deep learning.ai is working to create courses\n\n33:35.640 --> 33:37.480\n to help people break into AI.\n\n33:37.480 --> 33:42.120\n So my machine learning course that I taught through Stanford\n\n33:42.120 --> 33:45.400\n is one of the most popular courses on Coursera.\n\n33:45.400 --> 33:47.640\n To this day, it's probably one of the courses,\n\n33:48.440 --> 33:49.720\n sort of, if I asked somebody,\n\n33:49.720 --> 33:52.200\n how did you get into machine learning\n\n33:52.200 --> 33:54.040\n or how did you fall in love with machine learning\n\n33:54.040 --> 33:55.160\n or would get you interested,\n\n33:55.800 --> 33:58.920\n it always goes back to Andrew Ng at some point.\n\n33:58.920 --> 34:00.040\n I see, yeah, I'm sure.\n\n34:00.040 --> 34:01.880\n You've influenced, the amount of people\n\n34:01.880 --> 34:03.160\n you've influenced is ridiculous.\n\n34:03.160 --> 34:05.720\n So for that, I'm sure I speak for a lot of people\n\n34:05.720 --> 34:07.080\n say big thank you.\n\n34:07.080 --> 34:07.800\n No, yeah, thank you.\n\n34:09.080 --> 34:11.720\n I was once reading a news article,\n\n34:13.320 --> 34:15.080\n I think it was tech review\n\n34:15.080 --> 34:17.480\n and I'm gonna mess up the statistic,\n\n34:17.480 --> 34:19.240\n but I remember reading an article that said\n\n34:20.120 --> 34:23.640\n something like one third of all programmers are self taught.\n\n34:23.640 --> 34:24.760\n I may have the number one third,\n\n34:24.760 --> 34:25.640\n around me was two thirds,\n\n34:25.640 --> 34:26.600\n but when I read that article,\n\n34:26.600 --> 34:28.120\n I thought this doesn't make sense.\n\n34:28.120 --> 34:29.400\n Everyone is self taught.\n\n34:29.400 --> 34:31.160\n So, cause you teach yourself.\n\n34:31.160 --> 34:32.200\n I don't teach people.\n\n34:32.920 --> 34:33.480\n That's well put.\n\n34:33.480 --> 34:37.960\n Yeah, so how does one get started in deep learning\n\n34:37.960 --> 34:40.520\n and where does deeplearning.ai fit into that?\n\n34:40.520 --> 34:43.640\n So the deep learning specialization offered by deeplearning.ai\n\n34:43.640 --> 34:49.880\n is I think it was Coursera's top specialization.\n\n34:49.880 --> 34:50.680\n It might still be.\n\n34:50.680 --> 34:52.840\n So it's a very popular way for people\n\n34:52.840 --> 34:54.360\n to take that specialization\n\n34:54.360 --> 34:57.720\n to learn about everything from neural networks\n\n34:57.720 --> 34:59.960\n to how to tune in your network\n\n34:59.960 --> 35:02.920\n to what is a ConvNet to what is a RNN\n\n35:02.920 --> 35:05.800\n or a sequence model or what is an attention model.\n\n35:05.800 --> 35:07.880\n And so the deep learning specialization\n\n35:09.080 --> 35:10.840\n steps everyone through those algorithms\n\n35:10.840 --> 35:12.200\n so you deeply understand it\n\n35:12.200 --> 35:15.160\n and can implement it and use it for whatever application.\n\n35:15.160 --> 35:16.440\n From the very beginning.\n\n35:16.440 --> 35:19.480\n So what would you say are the prerequisites\n\n35:19.480 --> 35:22.040\n for somebody to take the deep learning specialization\n\n35:22.040 --> 35:25.560\n in terms of maybe math or programming background?\n\n35:25.560 --> 35:27.960\n Yeah, need to understand basic programming\n\n35:27.960 --> 35:30.120\n since there are programming exercises in Python\n\n35:30.120 --> 35:34.360\n and the math prereq is quite basic.\n\n35:34.360 --> 35:35.880\n So no calculus is needed.\n\n35:35.880 --> 35:38.600\n If you know calculus is great, you get better intuitions\n\n35:38.600 --> 35:41.160\n but deliberately try to teach that specialization\n\n35:41.160 --> 35:42.680\n without requiring calculus.\n\n35:42.680 --> 35:47.160\n So I think high school math would be sufficient.\n\n35:47.160 --> 35:49.000\n If you know how to multiply two matrices,\n\n35:49.000 --> 35:51.480\n I think that's great.\n\n35:52.120 --> 35:54.680\n So a little basic linear algebra is great.\n\n35:54.680 --> 35:55.960\n Basic linear algebra,\n\n35:55.960 --> 36:00.040\n even very, very basic linear algebra in some programming.\n\n36:00.040 --> 36:02.120\n I think that people that have done the machine learning course\n\n36:02.120 --> 36:05.000\n will find a deep learning specialization a bit easier\n\n36:05.000 --> 36:06.360\n but it's also possible to jump\n\n36:06.360 --> 36:08.280\n into the deep learning specialization directly\n\n36:08.280 --> 36:09.960\n but it will be a little bit harder\n\n36:09.960 --> 36:14.440\n since we tend to go over faster concepts\n\n36:14.440 --> 36:16.120\n like how does gradient descent work\n\n36:16.120 --> 36:17.640\n and what is the objective function\n\n36:17.640 --> 36:20.120\n which is covered more slowly in the machine learning course.\n\n36:20.120 --> 36:22.840\n Could you briefly mention some of the key concepts\n\n36:22.840 --> 36:25.000\n in deep learning that students should learn\n\n36:25.000 --> 36:27.640\n that you envision them learning in the first few months\n\n36:27.640 --> 36:28.680\n in the first year or so?\n\n36:29.320 --> 36:31.880\n So if you take the deep learning specialization,\n\n36:31.880 --> 36:34.840\n you learn the foundations of what is a neural network.\n\n36:34.840 --> 36:36.840\n How do you build up a neural network\n\n36:36.840 --> 36:40.600\n from a single logistic unit to a stack of layers\n\n36:40.600 --> 36:43.000\n to different activation functions.\n\n36:43.000 --> 36:44.920\n You learn how to train the neural networks.\n\n36:44.920 --> 36:47.720\n One thing I'm very proud of in that specialization\n\n36:47.720 --> 36:50.200\n is we go through a lot of practical knowhow\n\n36:50.200 --> 36:52.200\n of how to actually make these things work.\n\n36:52.200 --> 36:55.640\n So what are the differences between different optimization algorithms?\n\n36:55.640 --> 36:57.240\n What do you do if the algorithm overfits\n\n36:57.240 --> 36:59.000\n or how do you tell if the algorithm is overfitting?\n\n36:59.000 --> 37:00.120\n When do you collect more data?\n\n37:00.120 --> 37:03.160\n When should you not bother to collect more data?\n\n37:03.160 --> 37:06.200\n I find that even today, unfortunately,\n\n37:06.200 --> 37:09.960\n there are engineers that will spend six months\n\n37:09.960 --> 37:11.720\n trying to pursue a particular direction\n\n37:12.520 --> 37:13.880\n such as collect more data\n\n37:13.880 --> 37:15.800\n because we heard more data is valuable\n\n37:15.800 --> 37:18.280\n but sometimes you could run some tests\n\n37:18.280 --> 37:20.360\n and could have figured out six months earlier\n\n37:20.360 --> 37:23.880\n that for this particular problem, collecting more data isn't going to cut it.\n\n37:23.880 --> 37:26.280\n So just don't spend six months collecting more data.\n\n37:26.280 --> 37:30.280\n Spend your time modifying the architecture or trying something else.\n\n37:30.280 --> 37:32.600\n So go through a lot of the practical knowhow\n\n37:32.600 --> 37:37.240\n so that when someone, when you take the deep learning specialization,\n\n37:37.240 --> 37:39.720\n you have those skills to be very efficient\n\n37:39.720 --> 37:41.960\n in how you build these networks.\n\n37:41.960 --> 37:45.160\n So dive right in to play with the network, to train it,\n\n37:45.160 --> 37:47.160\n to do the inference on a particular data set,\n\n37:47.160 --> 37:52.120\n to build intuition about it without building it up too big\n\n37:52.120 --> 37:53.960\n to where you spend, like you said, six months\n\n37:54.760 --> 37:57.320\n learning, building up your big project\n\n37:57.320 --> 38:02.200\n without building any intuition of a small aspect of the data\n\n38:02.200 --> 38:05.000\n that could already tell you everything you need to know about that data.\n\n38:05.640 --> 38:09.240\n Yes, and also the systematic frameworks of thinking\n\n38:09.240 --> 38:12.280\n for how to go about building practical machine learning.\n\n38:12.280 --> 38:15.320\n Maybe to make an analogy, when we learn to code,\n\n38:15.320 --> 38:17.960\n we have to learn the syntax of some programming language, right?\n\n38:17.960 --> 38:20.600\n Be it Python or C++ or Octave or whatever.\n\n38:21.480 --> 38:24.920\n But the equally important or maybe even more important part of coding\n\n38:24.920 --> 38:27.640\n is to understand how to string together these lines of code\n\n38:27.640 --> 38:28.760\n into coherent things.\n\n38:28.760 --> 38:31.880\n So when should you put something in a function column?\n\n38:31.880 --> 38:32.840\n When should you not?\n\n38:32.840 --> 38:34.040\n How do you think about abstraction?\n\n38:34.600 --> 38:39.000\n So those frameworks are what makes a programmer efficient\n\n38:39.000 --> 38:40.920\n even more than understanding the syntax.\n\n38:41.560 --> 38:44.120\n I remember when I was an undergrad at Carnegie Mellon,\n\n38:44.120 --> 38:47.480\n one of my friends would debug their code\n\n38:47.480 --> 38:50.840\n by first trying to compile it, and then it was C++ code.\n\n38:50.840 --> 38:53.240\n And then every line in the syntax error,\n\n38:53.240 --> 38:55.640\n they want to get rid of the syntax errors as quickly as possible.\n\n38:55.640 --> 38:56.520\n So how do you do that?\n\n38:56.520 --> 38:59.640\n Well, they would delete every single line of code with a syntax error.\n\n38:59.640 --> 39:01.640\n So really efficient for getting rid of syntax errors\n\n39:01.640 --> 39:02.920\n for horrible debugging errors.\n\n39:02.920 --> 39:04.680\n So I think we learn how to debug.\n\n39:05.320 --> 39:06.920\n And I think in machine learning,\n\n39:06.920 --> 39:09.320\n the way you debug a machine learning program\n\n39:09.320 --> 39:13.000\n is very different than the way you do binary search or whatever,\n\n39:13.000 --> 39:15.080\n or use a debugger, trace through the code\n\n39:15.080 --> 39:17.000\n in traditional software engineering.\n\n39:17.000 --> 39:18.920\n So it's an evolving discipline,\n\n39:18.920 --> 39:20.760\n but I find that the people that are really good\n\n39:20.760 --> 39:22.840\n at debugging machine learning algorithms\n\n39:22.840 --> 39:27.080\n are easily 10x, maybe 100x faster at getting something to work.\n\n39:28.120 --> 39:29.800\n And the basic process of debugging is,\n\n39:30.760 --> 39:32.600\n so the bug in this case,\n\n39:32.600 --> 39:36.360\n why isn't this thing learning, improving,\n\n39:36.360 --> 39:39.240\n sort of going into the questions of overfitting\n\n39:39.240 --> 39:40.760\n and all those kinds of things?\n\n39:40.760 --> 39:45.240\n That's the logical space that the debugging is happening in\n\n39:45.240 --> 39:46.440\n with neural networks.\n\n39:46.440 --> 39:49.480\n Yeah, often the question is, why doesn't it work yet?\n\n39:50.280 --> 39:52.120\n Or can I expect it to eventually work?\n\n39:52.920 --> 39:54.760\n And what are the things I could try?\n\n39:54.760 --> 39:57.400\n Change the architecture, more data, more regularization,\n\n39:57.400 --> 39:58.760\n different optimization algorithm,\n\n40:00.600 --> 40:01.880\n different types of data.\n\n40:01.880 --> 40:04.200\n So to answer those questions systematically,\n\n40:04.200 --> 40:08.040\n so that you don't spend six months hitting down the blind alley\n\n40:08.040 --> 40:09.720\n before someone comes and says,\n\n40:09.720 --> 40:11.160\n why did you spend six months doing this?\n\n40:12.120 --> 40:13.960\n What concepts in deep learning\n\n40:13.960 --> 40:16.440\n do you think students struggle the most with?\n\n40:16.440 --> 40:19.000\n Or sort of is the biggest challenge for them\n\n40:19.000 --> 40:21.080\n was to get over that hill.\n\n40:23.160 --> 40:26.360\n It hooks them and it inspires them and they really get it.\n\n40:28.040 --> 40:30.200\n Similar to learning mathematics,\n\n40:30.200 --> 40:32.440\n I think one of the challenges of deep learning\n\n40:32.440 --> 40:33.960\n is that there are a lot of concepts\n\n40:33.960 --> 40:35.320\n that build on top of each other.\n\n40:36.760 --> 40:38.760\n If you ask me what's hard about mathematics,\n\n40:38.760 --> 40:40.920\n I have a hard time pinpointing one thing.\n\n40:40.920 --> 40:42.280\n Is it addition, subtraction?\n\n40:42.280 --> 40:43.080\n Is it a carry?\n\n40:43.080 --> 40:44.360\n Is it multiplication?\n\n40:44.360 --> 40:45.720\n There's just a lot of stuff.\n\n40:45.720 --> 40:48.040\n I think one of the challenges of learning math\n\n40:48.040 --> 40:49.800\n and of learning certain technical fields\n\n40:49.800 --> 40:51.480\n is that there are a lot of concepts\n\n40:51.480 --> 40:53.080\n and if you miss a concept,\n\n40:53.080 --> 40:55.400\n then you're kind of missing the prerequisite\n\n40:55.400 --> 40:56.760\n for something that comes later.\n\n40:58.040 --> 41:00.840\n So in the deep learning specialization,\n\n41:01.880 --> 41:03.480\n try to break down the concepts\n\n41:03.480 --> 41:06.920\n to maximize the odds of each component being understandable.\n\n41:06.920 --> 41:09.240\n So when you move on to the more advanced thing,\n\n41:09.240 --> 41:10.760\n we learn confidence,\n\n41:10.760 --> 41:12.280\n hopefully you have enough intuitions\n\n41:12.280 --> 41:13.880\n from the earlier sections\n\n41:13.880 --> 41:16.760\n to then understand why we structure confidence\n\n41:16.760 --> 41:18.520\n in a certain way\n\n41:18.520 --> 41:23.000\n and then eventually why we built RNNs and LSTMs\n\n41:23.000 --> 41:24.760\n or attention models in a certain way\n\n41:24.760 --> 41:26.600\n building on top of the earlier concepts.\n\n41:27.560 --> 41:28.600\n Actually, I'm curious,\n\n41:28.600 --> 41:30.920\n you do a lot of teaching as well.\n\n41:30.920 --> 41:33.080\n Do you have a favorite,\n\n41:33.080 --> 41:39.480\n this is the hard concept moment in your teaching?\n\n41:39.480 --> 41:41.960\n Well, I don't think anyone's ever turned the interview on me.\n\n41:43.320 --> 41:44.120\n I'm glad you get first.\n\n41:46.600 --> 41:47.880\n I think that's a really good question.\n\n41:48.920 --> 41:51.160\n Yeah, it's really hard to capture the moment\n\n41:51.160 --> 41:51.800\n when they struggle.\n\n41:51.800 --> 41:53.320\n I think you put it really eloquently.\n\n41:53.320 --> 41:55.080\n I do think there's moments\n\n41:55.080 --> 41:57.240\n that are like aha moments\n\n41:57.240 --> 41:59.400\n that really inspire people.\n\n41:59.400 --> 42:01.400\n I think for some reason,\n\n42:01.400 --> 42:03.240\n reinforcement learning,\n\n42:03.240 --> 42:04.920\n especially deep reinforcement learning\n\n42:05.560 --> 42:07.400\n is a really great way\n\n42:07.400 --> 42:09.560\n to really inspire people\n\n42:09.560 --> 42:12.920\n and get what the use of neural networks can do.\n\n42:13.480 --> 42:15.160\n Even though neural networks\n\n42:15.160 --> 42:18.440\n really are just a part of the deep RL framework,\n\n42:18.440 --> 42:19.640\n but it's a really nice way\n\n42:19.640 --> 42:22.360\n to paint the entirety of the picture\n\n42:22.360 --> 42:23.960\n of a neural network\n\n42:23.960 --> 42:25.880\n being able to learn from scratch,\n\n42:25.880 --> 42:27.720\n knowing nothing and explore the world\n\n42:27.720 --> 42:29.080\n and pick up lessons.\n\n42:29.080 --> 42:31.240\n I find that a lot of the aha moments\n\n42:31.240 --> 42:33.640\n happen when you use deep RL\n\n42:33.640 --> 42:36.200\n to teach people about neural networks,\n\n42:36.200 --> 42:37.720\n which is counterintuitive.\n\n42:37.720 --> 42:40.680\n I find like a lot of the inspired sort of fire\n\n42:40.680 --> 42:41.560\n in people's passion,\n\n42:41.560 --> 42:42.200\n people's eyes,\n\n42:42.200 --> 42:44.040\n it comes from the RL world.\n\n42:44.680 --> 42:46.280\n Do you find reinforcement learning\n\n42:46.920 --> 42:48.520\n to be a useful part\n\n42:48.520 --> 42:50.440\n of the teaching process or no?\n\n42:51.800 --> 42:53.400\n I still teach reinforcement learning\n\n42:53.400 --> 42:54.920\n in one of my Stanford classes\n\n42:55.480 --> 42:57.320\n and my PhD thesis was on reinforcement learning.\n\n42:57.320 --> 42:58.440\n So I clearly loved a few.\n\n42:59.240 --> 43:00.840\n I find that if I'm trying to teach\n\n43:00.840 --> 43:03.000\n students the most useful techniques\n\n43:03.000 --> 43:04.520\n for them to use today,\n\n43:04.520 --> 43:07.000\n I end up shrinking the amount of time\n\n43:07.000 --> 43:08.840\n I talk about reinforcement learning.\n\n43:08.840 --> 43:10.760\n It's not what's working today.\n\n43:10.760 --> 43:12.280\n Now, our world changes so fast.\n\n43:12.280 --> 43:13.480\n Maybe this will be totally different\n\n43:13.480 --> 43:14.360\n in a couple of years.\n\n43:15.800 --> 43:17.640\n But I think we need a couple more things\n\n43:17.640 --> 43:19.240\n for reinforcement learning to get there.\n\n43:20.600 --> 43:21.720\n One of my teams is looking\n\n43:21.720 --> 43:22.600\n to reinforcement learning\n\n43:22.600 --> 43:23.800\n for some robotic control tasks.\n\n43:23.800 --> 43:25.160\n So I see the applications,\n\n43:25.160 --> 43:27.560\n but if you look at it as a percentage\n\n43:27.560 --> 43:28.520\n of all of the impact\n\n43:28.520 --> 43:30.040\n of the types of things we do,\n\n43:30.040 --> 43:32.680\n it's at least today outside of\n\n43:33.720 --> 43:35.320\n playing video games, right?\n\n43:35.320 --> 43:37.800\n In a few of the games, the scope.\n\n43:38.440 --> 43:39.560\n Actually, at NeurIPS,\n\n43:39.560 --> 43:40.840\n a bunch of us were standing around\n\n43:40.840 --> 43:42.760\n saying, hey, what's your best example\n\n43:42.760 --> 43:44.200\n of an actual deploy reinforcement\n\n43:44.200 --> 43:45.240\n learning application?\n\n43:45.240 --> 43:47.160\n And among like\n\n43:47.160 --> 43:49.000\n senior machine learning researchers, right?\n\n43:49.000 --> 43:51.400\n And again, there are some emerging ones,\n\n43:51.400 --> 43:54.520\n but there are not that many great examples.\n\n43:55.240 --> 43:57.480\n I think you're absolutely right.\n\n43:58.040 --> 43:59.880\n The sad thing is there hasn't been\n\n43:59.880 --> 44:03.480\n a big impactful real world application\n\n44:03.480 --> 44:04.840\n of reinforcement learning.\n\n44:04.840 --> 44:07.560\n I think its biggest impact to me\n\n44:07.560 --> 44:09.320\n has been in the toy domain,\n\n44:09.320 --> 44:10.200\n in the game domain,\n\n44:10.200 --> 44:11.240\n in the small example.\n\n44:11.240 --> 44:13.560\n That's what I mean for educational purpose.\n\n44:13.560 --> 44:15.640\n It seems to be a fun thing to explore\n\n44:15.640 --> 44:16.760\n in your networks with.\n\n44:16.760 --> 44:19.000\n But I think from your perspective,\n\n44:19.000 --> 44:20.440\n and I think that might be\n\n44:20.440 --> 44:22.280\n the best perspective is\n\n44:22.280 --> 44:23.560\n if you're trying to educate\n\n44:23.560 --> 44:24.680\n with a simple example\n\n44:24.680 --> 44:25.800\n in order to illustrate\n\n44:25.800 --> 44:27.640\n how this can actually be grown\n\n44:27.640 --> 44:31.000\n to scale and have a real world impact,\n\n44:31.560 --> 44:33.640\n then perhaps focusing on the fundamentals\n\n44:33.640 --> 44:34.840\n of supervised learning\n\n44:35.400 --> 44:38.920\n in the context of a simple data set,\n\n44:38.920 --> 44:40.440\n even like an MNIST data set\n\n44:40.440 --> 44:41.160\n is the right way,\n\n44:42.040 --> 44:43.480\n is the right path to take.\n\n44:45.080 --> 44:46.520\n The amount of fun I've seen people\n\n44:46.520 --> 44:47.880\n have with reinforcement learning\n\n44:47.880 --> 44:48.440\n has been great,\n\n44:48.440 --> 44:51.320\n but not in the applied impact\n\n44:51.320 --> 44:52.760\n in the real world setting.\n\n44:52.760 --> 44:54.040\n So it's a trade off,\n\n44:54.040 --> 44:55.320\n how much impact you want to have\n\n44:55.320 --> 44:56.680\n versus how much fun you want to have.\n\n44:56.680 --> 44:58.200\n Yeah, that's really cool.\n\n44:58.200 --> 44:59.960\n And I feel like the world\n\n44:59.960 --> 45:01.240\n actually needs all sorts.\n\n45:01.240 --> 45:02.520\n Even within machine learning,\n\n45:02.520 --> 45:04.360\n I feel like deep learning\n\n45:04.360 --> 45:05.800\n is so exciting,\n\n45:05.800 --> 45:07.080\n but the AI team\n\n45:07.080 --> 45:08.360\n shouldn't just use deep learning.\n\n45:08.360 --> 45:09.320\n I find that my teams\n\n45:09.320 --> 45:10.760\n use a portfolio of tools.\n\n45:11.640 --> 45:13.080\n And maybe that's not the exciting thing\n\n45:13.080 --> 45:14.680\n to say, but some days\n\n45:14.680 --> 45:15.720\n we use a neural net,\n\n45:15.720 --> 45:19.240\n some days we use a PCA.\n\n45:19.960 --> 45:20.600\n Actually, the other day,\n\n45:20.600 --> 45:21.480\n I was sitting down with my team\n\n45:21.480 --> 45:22.760\n looking at PCA residuals,\n\n45:22.760 --> 45:23.800\n trying to figure out what's going on\n\n45:23.800 --> 45:24.600\n with PCA applied\n\n45:24.600 --> 45:25.640\n to manufacturing problem.\n\n45:25.640 --> 45:26.920\n And some days we use\n\n45:26.920 --> 45:28.200\n a probabilistic graphical model,\n\n45:28.200 --> 45:29.720\n some days we use a knowledge draft,\n\n45:29.720 --> 45:30.520\n which is one of the things\n\n45:30.520 --> 45:33.000\n that has tremendous industry impact.\n\n45:33.000 --> 45:34.680\n But the amount of chatter\n\n45:34.680 --> 45:36.360\n about knowledge drafts in academia\n\n45:36.360 --> 45:37.640\n is really thin compared\n\n45:37.640 --> 45:39.640\n to the actual real world impact.\n\n45:39.640 --> 45:41.400\n So I think reinforcement learning\n\n45:41.400 --> 45:42.520\n should be in that portfolio.\n\n45:42.520 --> 45:43.640\n And then it's about balancing\n\n45:43.640 --> 45:45.240\n how much we teach all of these things.\n\n45:45.240 --> 45:47.000\n And the world should have\n\n45:47.000 --> 45:47.800\n diverse skills.\n\n45:47.800 --> 45:49.240\n It'd be sad if everyone\n\n45:49.240 --> 45:51.400\n just learned one narrow thing.\n\n45:51.400 --> 45:52.360\n Yeah, the diverse skill\n\n45:52.360 --> 45:53.720\n help you discover the right tool\n\n45:53.720 --> 45:54.280\n for the job.\n\n45:54.280 --> 45:56.680\n What is the most beautiful,\n\n45:56.680 --> 45:59.160\n surprising or inspiring idea\n\n45:59.160 --> 46:00.200\n in deep learning to you?\n\n46:00.760 --> 46:03.400\n Something that captivated\n\n46:03.400 --> 46:04.600\n your imagination.\n\n46:04.600 --> 46:06.520\n Is it the scale that could be,\n\n46:07.080 --> 46:07.960\n the performance that could be\n\n46:07.960 --> 46:08.920\n achieved with scale?\n\n46:08.920 --> 46:10.120\n Or is there other ideas?\n\n46:11.560 --> 46:14.360\n I think that if my only job\n\n46:14.360 --> 46:16.520\n was being an academic researcher,\n\n46:16.520 --> 46:18.120\n if an unlimited budget\n\n46:18.120 --> 46:19.960\n and didn't have to worry\n\n46:19.960 --> 46:21.800\n about short term impact\n\n46:21.800 --> 46:23.800\n and only focus on long term impact,\n\n46:23.800 --> 46:24.760\n I'd probably spend all my time\n\n46:24.760 --> 46:26.360\n doing research on unsupervised learning.\n\n46:27.400 --> 46:28.840\n I still think unsupervised learning\n\n46:28.840 --> 46:29.880\n is a beautiful idea.\n\n46:31.400 --> 46:34.600\n At both this past NeurIPS and ICML,\n\n46:34.600 --> 46:35.960\n I was attending workshops\n\n46:35.960 --> 46:37.480\n or listening to various talks\n\n46:37.480 --> 46:39.160\n about self supervised learning,\n\n46:39.160 --> 46:41.480\n which is one vertical segment\n\n46:41.480 --> 46:43.160\n maybe of unsupervised learning\n\n46:43.160 --> 46:44.120\n that I'm excited about.\n\n46:45.160 --> 46:46.360\n Maybe just to summarize the idea,\n\n46:46.360 --> 46:47.400\n I guess you know the idea\n\n46:47.400 --> 46:48.520\n about describing fleet.\n\n46:48.520 --> 46:49.080\n No, please.\n\n46:49.080 --> 46:49.960\n So here's the example\n\n46:49.960 --> 46:51.400\n of self supervised learning.\n\n46:52.040 --> 46:53.480\n Let's say we grab a lot\n\n46:53.480 --> 46:55.560\n of unlabeled images off the internet.\n\n46:55.560 --> 46:56.680\n So with infinite amounts\n\n46:56.680 --> 46:58.040\n of this type of data,\n\n46:58.040 --> 46:59.320\n I'm going to take each image\n\n46:59.320 --> 47:01.160\n and rotate it by a random\n\n47:01.160 --> 47:03.000\n multiple of 90 degrees.\n\n47:03.000 --> 47:04.760\n And then I'm going to train\n\n47:04.760 --> 47:06.200\n a supervised neural network\n\n47:06.200 --> 47:07.400\n to predict what was\n\n47:07.400 --> 47:08.920\n the original orientation.\n\n47:08.920 --> 47:10.760\n So it has to be rotated 90 degrees,\n\n47:10.760 --> 47:12.440\n 180 degrees, 270 degrees,\n\n47:12.440 --> 47:13.800\n or zero degrees.\n\n47:14.360 --> 47:15.640\n So you can generate\n\n47:15.640 --> 47:17.560\n an infinite amounts of labeled data\n\n47:17.560 --> 47:18.920\n because you rotated the image\n\n47:18.920 --> 47:19.880\n so you know what's the\n\n47:19.880 --> 47:20.760\n ground truth label.\n\n47:20.760 --> 47:23.320\n And so various researchers\n\n47:23.320 --> 47:24.680\n have found that by taking\n\n47:24.680 --> 47:26.600\n unlabeled data and making\n\n47:26.600 --> 47:27.880\n up labeled data sets\n\n47:27.880 --> 47:29.720\n and training a large neural network\n\n47:29.720 --> 47:30.920\n on these tasks,\n\n47:30.920 --> 47:32.040\n you can then take the hidden\n\n47:32.040 --> 47:34.120\n layer representation and transfer\n\n47:34.120 --> 47:35.400\n it to a different task\n\n47:35.400 --> 47:36.520\n very powerfully.\n\n47:37.640 --> 47:39.000\n Learning word embeddings\n\n47:39.000 --> 47:40.040\n where we take a sentence,\n\n47:40.040 --> 47:40.760\n delete a word,\n\n47:40.760 --> 47:42.120\n predict the missing word,\n\n47:42.120 --> 47:43.480\n which is how we learn.\n\n47:43.480 --> 47:44.440\n One of the ways we learn\n\n47:44.440 --> 47:45.480\n word embeddings\n\n47:45.480 --> 47:47.160\n is another example.\n\n47:47.160 --> 47:48.680\n And I think there's now\n\n47:48.680 --> 47:50.440\n this portfolio of techniques\n\n47:50.440 --> 47:52.760\n for generating these made up tasks.\n\n47:53.320 --> 47:54.760\n Another one called jigsaw\n\n47:54.760 --> 47:56.760\n would be if you take an image,\n\n47:56.760 --> 47:59.240\n cut it up into a three by three grid,\n\n47:59.240 --> 48:00.040\n so like a nine,\n\n48:00.040 --> 48:01.560\n three by three puzzle piece,\n\n48:01.560 --> 48:02.840\n jump up the nine pieces\n\n48:02.840 --> 48:04.520\n and have a neural network predict\n\n48:04.520 --> 48:06.360\n which of the nine factorial\n\n48:06.360 --> 48:07.880\n possible permutations\n\n48:07.880 --> 48:08.840\n it came from.\n\n48:09.320 --> 48:11.480\n So many groups,\n\n48:11.480 --> 48:13.080\n including OpenAI,\n\n48:13.080 --> 48:14.520\n Peter B has been doing\n\n48:14.520 --> 48:15.560\n some work on this too,\n\n48:16.280 --> 48:18.440\n Facebook, Google Brain,\n\n48:18.440 --> 48:19.560\n I think DeepMind,\n\n48:19.560 --> 48:21.240\n oh actually,\n\n48:21.240 --> 48:22.200\n Aaron van der Oort\n\n48:22.200 --> 48:24.360\n has great work on the CPC objective.\n\n48:24.360 --> 48:26.120\n So many teams are doing exciting work\n\n48:26.120 --> 48:27.640\n and I think this is a way\n\n48:27.640 --> 48:29.560\n to generate infinite label data\n\n48:30.440 --> 48:32.920\n and I find this a very exciting\n\n48:32.920 --> 48:34.040\n piece of unsupervised learning.\n\n48:34.040 --> 48:35.080\n So long term you think\n\n48:35.080 --> 48:37.160\n that's going to unlock\n\n48:37.160 --> 48:38.280\n a lot of power\n\n48:38.280 --> 48:39.960\n in machine learning systems\n\n48:39.960 --> 48:42.200\n is this kind of unsupervised learning.\n\n48:42.200 --> 48:43.080\n I don't think there's\n\n48:43.080 --> 48:43.880\n a whole enchilada,\n\n48:43.880 --> 48:45.080\n I think it's just a piece of it\n\n48:45.080 --> 48:46.440\n and I think this one piece\n\n48:46.440 --> 48:47.320\n unsupervised,\n\n48:47.320 --> 48:48.840\n self supervised learning\n\n48:48.840 --> 48:50.200\n is starting to get traction.\n\n48:50.200 --> 48:51.320\n We're very close\n\n48:51.320 --> 48:52.440\n to it being useful.\n\n48:53.160 --> 48:54.040\n Well, word embedding\n\n48:54.040 --> 48:55.480\n is really useful.\n\n48:55.480 --> 48:56.200\n I think we're getting\n\n48:56.200 --> 48:57.080\n closer and closer\n\n48:57.080 --> 48:59.240\n to just having a significant\n\n48:59.240 --> 49:00.440\n real world impact\n\n49:00.440 --> 49:02.040\n maybe in computer vision and video\n\n49:03.080 --> 49:04.360\n but I think this concept\n\n49:05.000 --> 49:05.880\n and I think there'll be\n\n49:05.880 --> 49:07.000\n other concepts around it.\n\n49:07.000 --> 49:08.760\n You know, other unsupervised\n\n49:08.760 --> 49:10.520\n learning things that I worked on\n\n49:10.520 --> 49:11.320\n I've been excited about.\n\n49:12.040 --> 49:12.840\n I was really excited\n\n49:12.840 --> 49:13.960\n about sparse coding\n\n49:14.600 --> 49:15.320\n and ICA,\n\n49:16.040 --> 49:17.480\n slow feature analysis.\n\n49:17.480 --> 49:18.760\n I think all of these are ideas\n\n49:18.760 --> 49:20.040\n that various of us\n\n49:20.040 --> 49:20.680\n were working on\n\n49:20.680 --> 49:21.720\n about a decade ago\n\n49:21.720 --> 49:23.160\n before we all got distracted\n\n49:23.160 --> 49:24.680\n by how well supervised\n\n49:24.680 --> 49:26.200\n learning was doing.\n\n49:26.200 --> 49:27.320\n So we would return\n\n49:27.880 --> 49:29.400\n we would return to the fundamentals\n\n49:29.400 --> 49:30.760\n of representation learning\n\n49:30.760 --> 49:32.200\n that really started\n\n49:32.200 --> 49:33.720\n this movement of deep learning.\n\n49:33.720 --> 49:34.840\n I think there's a lot more work\n\n49:34.840 --> 49:36.120\n that one could explore around\n\n49:36.120 --> 49:37.080\n this theme of ideas\n\n49:37.080 --> 49:38.200\n and other ideas\n\n49:38.200 --> 49:39.480\n to come up with better algorithms.\n\n49:40.200 --> 49:41.480\n So if we could return\n\n49:42.040 --> 49:43.880\n to maybe talk quickly\n\n49:43.880 --> 49:45.080\n about the specifics\n\n49:45.080 --> 49:46.600\n of deep learning.ai\n\n49:46.600 --> 49:48.120\n the deep learning specialization\n\n49:48.120 --> 49:50.360\n perhaps how long does it take\n\n49:50.360 --> 49:51.240\n to complete the course\n\n49:51.240 --> 49:51.800\n would you say?\n\n49:52.680 --> 49:53.800\n The official length\n\n49:53.800 --> 49:55.320\n of the deep learning specialization\n\n49:55.320 --> 49:57.080\n is I think 16 weeks\n\n49:57.080 --> 49:58.280\n so about four months\n\n49:58.920 --> 50:00.760\n but it's go at your own pace.\n\n50:00.760 --> 50:01.960\n So if you subscribe\n\n50:01.960 --> 50:03.560\n to the deep learning specialization\n\n50:03.560 --> 50:04.760\n there are people that finished it\n\n50:04.760 --> 50:05.720\n in less than a month\n\n50:05.720 --> 50:07.000\n by working more intensely\n\n50:07.000 --> 50:07.960\n and studying more intensely\n\n50:07.960 --> 50:09.240\n so it really depends on\n\n50:09.240 --> 50:10.040\n on the individual.\n\n50:10.920 --> 50:11.480\n When we created\n\n50:11.480 --> 50:12.760\n the deep learning specialization\n\n50:13.480 --> 50:15.400\n we wanted to make it\n\n50:15.400 --> 50:16.360\n very accessible\n\n50:16.360 --> 50:18.440\n and very affordable.\n\n50:18.440 --> 50:19.480\n And with you know\n\n50:19.480 --> 50:20.840\n Coursera and deep learning.ai\n\n50:20.840 --> 50:21.720\n education mission\n\n50:21.720 --> 50:22.120\n one of the things\n\n50:22.120 --> 50:23.480\n that's really important to me\n\n50:23.480 --> 50:25.560\n is that if there's someone\n\n50:25.560 --> 50:27.160\n for whom paying anything\n\n50:27.160 --> 50:28.760\n is a financial hardship\n\n50:29.320 --> 50:30.920\n then just apply for financial aid\n\n50:30.920 --> 50:32.520\n and get it for free.\n\n50:34.280 --> 50:35.880\n If you were to recommend\n\n50:35.880 --> 50:37.480\n a daily schedule for people\n\n50:38.040 --> 50:39.240\n in learning whether it's\n\n50:39.240 --> 50:40.600\n through the deep learning.ai\n\n50:40.600 --> 50:42.120\n specialization or just learning\n\n50:42.680 --> 50:43.960\n in the world of deep learning\n\n50:43.960 --> 50:45.480\n what would you recommend?\n\n50:45.480 --> 50:47.160\n How do they go about day to day\n\n50:47.160 --> 50:48.760\n sort of specific advice\n\n50:48.760 --> 50:49.800\n about learning\n\n50:49.800 --> 50:51.720\n about their journey in the world\n\n50:51.720 --> 50:52.760\n of deep learning machine learning?\n\n50:53.400 --> 50:56.040\n I think getting the habit of learning\n\n50:56.760 --> 50:59.400\n is key and that means regularity.\n\n51:00.920 --> 51:02.840\n So for example\n\n51:02.840 --> 51:05.080\n we send out a weekly newsletter\n\n51:05.080 --> 51:06.680\n the batch every Wednesday\n\n51:06.680 --> 51:08.200\n so people know it's coming Wednesday\n\n51:08.200 --> 51:09.160\n you can spend a little bit of time\n\n51:09.160 --> 51:10.200\n on Wednesday\n\n51:10.200 --> 51:11.560\n catching up on the latest news\n\n51:11.560 --> 51:13.640\n catching up on the latest news\n\n51:13.640 --> 51:16.600\n through the batch on Wednesday\n\n51:17.400 --> 51:18.600\n and for myself\n\n51:18.600 --> 51:21.160\n I've picked up a habit of spending\n\n51:21.160 --> 51:22.520\n some time every Saturday\n\n51:22.520 --> 51:24.600\n and every Sunday reading or studying\n\n51:24.600 --> 51:26.600\n and so I don't wake up on the Saturday\n\n51:26.600 --> 51:27.640\n and have to make a decision\n\n51:27.640 --> 51:28.840\n do I feel like reading\n\n51:28.840 --> 51:30.280\n or studying today or not\n\n51:30.280 --> 51:31.640\n it's just what I do\n\n51:31.640 --> 51:33.160\n and the fact is a habit\n\n51:33.160 --> 51:34.200\n makes it easier.\n\n51:34.200 --> 51:37.640\n So I think if someone can get into that habit\n\n51:37.640 --> 51:38.760\n it's like you know\n\n51:38.760 --> 51:41.080\n just like we brush our teeth every morning\n\n51:41.080 --> 51:42.040\n I don't think about it\n\n51:42.040 --> 51:42.760\n if I thought about it\n\n51:42.760 --> 51:43.480\n it's a little bit annoying\n\n51:43.480 --> 51:44.920\n to have to spend two minutes doing that\n\n51:45.960 --> 51:47.720\n but it's a habit that it takes\n\n51:47.720 --> 51:49.080\n no cognitive load\n\n51:49.080 --> 51:50.360\n but this would be so much harder\n\n51:50.360 --> 51:51.880\n if we have to make a decision every morning\n\n51:53.640 --> 51:54.680\n and actually that's the reason\n\n51:54.680 --> 51:56.040\n why I wear the same thing every day as well\n\n51:56.040 --> 51:57.160\n it's just one less decision\n\n51:57.160 --> 51:59.560\n I just get up and wear my blue shirt\n\n51:59.560 --> 52:01.160\n so but I think if you can get that habit\n\n52:01.160 --> 52:02.840\n that consistency of studying\n\n52:02.840 --> 52:04.600\n then it actually feels easier.\n\n52:05.720 --> 52:07.480\n So yeah it's kind of amazing\n\n52:08.600 --> 52:09.320\n in my own life\n\n52:09.320 --> 52:11.560\n like I play guitar every day for\n\n52:12.840 --> 52:14.920\n I force myself to at least for five minutes\n\n52:14.920 --> 52:15.560\n play guitar\n\n52:15.560 --> 52:18.040\n it's just it's a ridiculously short period of time\n\n52:18.040 --> 52:20.120\n but because I've gotten into that habit\n\n52:20.120 --> 52:21.720\n it's incredible what you can accomplish\n\n52:21.720 --> 52:24.440\n in a period of a year or two years\n\n52:24.440 --> 52:25.000\n you can become\n\n52:26.280 --> 52:28.280\n you know exceptionally good\n\n52:28.280 --> 52:29.720\n at certain aspects of a thing\n\n52:29.720 --> 52:30.920\n by just doing it every day\n\n52:30.920 --> 52:32.040\n for a very short period of time\n\n52:32.040 --> 52:33.000\n it's kind of a miracle\n\n52:33.000 --> 52:34.600\n that that's how it works\n\n52:34.600 --> 52:36.200\n it adds up over time.\n\n52:36.200 --> 52:38.360\n Yeah and I think this is often\n\n52:38.360 --> 52:40.760\n not about the bursts of sustained efforts\n\n52:40.760 --> 52:41.880\n and the all nighters\n\n52:41.880 --> 52:43.080\n because you could only do that\n\n52:43.080 --> 52:44.200\n a limited number of times\n\n52:44.200 --> 52:46.600\n it's the sustained effort over a long time\n\n52:47.240 --> 52:49.560\n I think you know reading two research papers\n\n52:50.360 --> 52:51.880\n is a nice thing to do\n\n52:51.880 --> 52:54.200\n but the power is not reading two research papers\n\n52:54.200 --> 52:56.760\n it's reading two research papers a week\n\n52:56.760 --> 52:57.480\n for a year\n\n52:57.480 --> 52:58.920\n then you read a hundred papers\n\n52:58.920 --> 53:00.200\n and you actually learn a lot\n\n53:00.200 --> 53:01.400\n when you read a hundred papers.\n\n53:02.040 --> 53:05.720\n So regularity and making learning a habit\n\n53:05.720 --> 53:09.720\n do you have general other study tips\n\n53:09.720 --> 53:11.880\n for particularly deep learning\n\n53:11.880 --> 53:12.680\n that people should\n\n53:13.400 --> 53:15.000\n in their process of learning\n\n53:15.000 --> 53:16.600\n is there some kind of recommendations\n\n53:16.600 --> 53:18.920\n or tips you have as they learn?\n\n53:19.720 --> 53:21.560\n One thing I still do\n\n53:21.560 --> 53:23.320\n when I'm trying to study something really deeply\n\n53:23.320 --> 53:25.000\n is take handwritten notes\n\n53:25.800 --> 53:26.360\n it varies\n\n53:26.360 --> 53:27.640\n I know there are a lot of people\n\n53:27.640 --> 53:29.320\n that take the deep learning courses\n\n53:29.320 --> 53:31.960\n during a commute or something\n\n53:31.960 --> 53:33.800\n where it may be more awkward to take notes\n\n53:33.800 --> 53:36.120\n so I know it may not work for everyone\n\n53:36.680 --> 53:39.640\n but when I'm taking courses on Coursera\n\n53:39.640 --> 53:41.640\n and I still take some every now and then\n\n53:41.640 --> 53:42.520\n the most recent one I took\n\n53:42.520 --> 53:44.360\n was a course on clinical trials\n\n53:44.360 --> 53:45.640\n because I was interested about that\n\n53:45.640 --> 53:47.880\n I got out my little Moleskine notebook\n\n53:47.880 --> 53:48.840\n and what I was seeing on my desk\n\n53:48.840 --> 53:50.280\n was just taking down notes\n\n53:50.280 --> 53:51.480\n so what the instructor was saying\n\n53:51.480 --> 53:53.000\n and that act we know that\n\n53:53.000 --> 53:54.760\n that act of taking notes\n\n53:54.760 --> 53:56.120\n preferably handwritten notes\n\n53:57.240 --> 53:58.520\n increases retention.\n\n53:59.560 --> 54:01.720\n So as you're sort of watching the video\n\n54:01.720 --> 54:03.800\n just kind of pausing maybe\n\n54:03.800 --> 54:07.240\n and then taking the basic insights down on paper.\n\n54:07.800 --> 54:09.960\n Yeah so there have been a few studies\n\n54:09.960 --> 54:11.080\n if you search online\n\n54:11.080 --> 54:12.680\n you find some of these studies\n\n54:12.680 --> 54:15.080\n that taking handwritten notes\n\n54:15.080 --> 54:16.920\n because handwriting is slower\n\n54:16.920 --> 54:17.800\n as we're saying just now\n\n54:18.920 --> 54:21.240\n it causes you to recode the knowledge\n\n54:21.240 --> 54:23.080\n in your own words more\n\n54:23.080 --> 54:24.840\n and that process of recoding\n\n54:24.840 --> 54:26.600\n promotes long term retention\n\n54:26.600 --> 54:28.200\n this is as opposed to typing\n\n54:28.200 --> 54:28.920\n which is fine\n\n54:28.920 --> 54:30.680\n again typing is better than nothing\n\n54:30.680 --> 54:31.800\n or in taking a class\n\n54:31.800 --> 54:32.760\n and not taking notes is better\n\n54:32.760 --> 54:34.360\n than not taking any class at all\n\n54:34.360 --> 54:36.440\n but comparing handwritten notes\n\n54:36.440 --> 54:37.000\n and typing\n\n54:37.960 --> 54:39.480\n you can usually type faster\n\n54:39.480 --> 54:40.280\n for a lot of people\n\n54:40.280 --> 54:41.480\n you can handwrite notes\n\n54:41.480 --> 54:42.920\n and so when people type\n\n54:42.920 --> 54:44.920\n they're more likely to just transcribe\n\n54:44.920 --> 54:46.280\n verbatim what they heard\n\n54:46.280 --> 54:49.080\n and that reduces the amount of recoding\n\n54:49.080 --> 54:50.360\n and that actually results\n\n54:50.360 --> 54:52.360\n in less long term retention.\n\n54:52.360 --> 54:53.960\n I don't know what the psychological effect\n\n54:53.960 --> 54:55.320\n there is but so true\n\n54:55.320 --> 54:56.840\n there's something fundamentally different\n\n54:56.840 --> 54:58.840\n about writing hand handwriting\n\n54:59.400 --> 55:00.200\n I wonder what that is\n\n55:00.200 --> 55:01.640\n I wonder if it is as simple\n\n55:01.640 --> 55:04.360\n as just the time it takes to write it slower\n\n55:04.360 --> 55:07.400\n yeah and because you can't write\n\n55:07.400 --> 55:08.120\n as many words\n\n55:08.120 --> 55:10.200\n you have to take whatever they said\n\n55:10.200 --> 55:11.960\n and summarize it into fewer words\n\n55:11.960 --> 55:13.400\n and that summarization process\n\n55:13.400 --> 55:15.240\n requires deeper processing of the meaning\n\n55:15.880 --> 55:17.880\n which then results in better retention\n\n55:17.880 --> 55:18.680\n that's fascinating\n\n55:20.040 --> 55:22.440\n oh and I think because of Coursera\n\n55:22.440 --> 55:24.120\n I spent so much time studying pedagogy\n\n55:24.120 --> 55:25.400\n this is actually one of my passions\n\n55:25.400 --> 55:27.000\n I really love learning\n\n55:27.000 --> 55:28.040\n how to more efficiently\n\n55:28.040 --> 55:28.920\n help others learn\n\n55:28.920 --> 55:30.600\n you know one of the things I do\n\n55:30.600 --> 55:32.280\n both when creating videos\n\n55:32.280 --> 55:33.800\n or when we write the batch is\n\n55:34.760 --> 55:37.800\n I try to think is one minute spent of us\n\n55:37.800 --> 55:40.600\n going to be a more efficient learning experience\n\n55:40.600 --> 55:42.520\n than one minute spent anywhere else\n\n55:42.520 --> 55:45.080\n and we really try to you know\n\n55:45.080 --> 55:46.920\n make it time efficient for the learners\n\n55:46.920 --> 55:47.960\n because you know everyone's busy\n\n55:48.680 --> 55:50.280\n so when when we're editing\n\n55:50.280 --> 55:51.960\n I often tell my teams\n\n55:51.960 --> 55:53.800\n every word needs to fight for its life\n\n55:53.800 --> 55:54.680\n and if you can delete a word\n\n55:54.680 --> 55:56.360\n let's just delete it and not wait\n\n55:56.360 --> 55:57.880\n let's not waste the learning time\n\n55:57.880 --> 55:59.400\n let's not waste the learning time\n\n55:59.960 --> 56:01.400\n oh that's so it's so amazing\n\n56:01.400 --> 56:02.200\n that you think that way\n\n56:02.200 --> 56:03.560\n because there is millions of people\n\n56:03.560 --> 56:04.840\n that are impacted by your teaching\n\n56:04.840 --> 56:06.680\n and sort of that one minute spent\n\n56:06.680 --> 56:08.360\n has a ripple effect right\n\n56:08.360 --> 56:09.560\n through years of time\n\n56:09.560 --> 56:11.480\n which is it's just fascinating to think about\n\n56:12.600 --> 56:14.280\n how does one make a career\n\n56:14.280 --> 56:15.960\n out of an interest in deep learning\n\n56:15.960 --> 56:18.680\n do you have advice for people\n\n56:18.680 --> 56:19.480\n we just talked about\n\n56:19.480 --> 56:21.400\n sort of the beginning early steps\n\n56:21.400 --> 56:22.600\n but if you want to make it\n\n56:22.600 --> 56:24.280\n an entire life's journey\n\n56:24.280 --> 56:26.360\n or at least a journey of a decade or two\n\n56:26.360 --> 56:27.480\n how do you how do you do it\n\n56:28.200 --> 56:30.120\n so most important thing is to get started\n\n56:30.120 --> 56:34.280\n right and and I think in the early parts\n\n56:34.280 --> 56:35.800\n of a career coursework\n\n56:35.800 --> 56:38.040\n um like the deep learning specialization\n\n56:38.040 --> 56:40.600\n or it's a very efficient way\n\n56:41.080 --> 56:42.520\n to master this material\n\n56:43.320 --> 56:46.600\n so because you know instructors\n\n56:46.600 --> 56:48.280\n uh be it me or someone else\n\n56:48.280 --> 56:49.640\n or you know Lawrence Maroney\n\n56:49.640 --> 56:51.240\n teaches our TensorFlow specialization\n\n56:51.240 --> 56:52.280\n or other things we're working on\n\n56:52.280 --> 56:55.640\n spend effort to try to make it time efficient\n\n56:55.640 --> 56:57.640\n for you to learn a new concept\n\n56:57.640 --> 57:00.600\n so coursework is actually a very efficient way\n\n57:00.600 --> 57:02.280\n for people to learn concepts\n\n57:02.280 --> 57:04.120\n and the beginning parts of breaking\n\n57:04.120 --> 57:04.760\n into a new field\n\n57:05.960 --> 57:07.960\n in fact one thing I see at Stanford\n\n57:08.520 --> 57:10.280\n some of my PhD students want to jump\n\n57:10.280 --> 57:11.400\n in the research right away\n\n57:11.400 --> 57:13.160\n and I actually tend to say look\n\n57:13.160 --> 57:14.440\n in your first couple years of PhD\n\n57:14.440 --> 57:16.680\n and spend time taking courses\n\n57:16.680 --> 57:17.960\n because it lays a foundation\n\n57:17.960 --> 57:19.640\n it's fine if you're less productive\n\n57:19.640 --> 57:20.680\n in your first couple years\n\n57:20.680 --> 57:22.200\n you'll be better off in the long term\n\n57:23.400 --> 57:24.520\n beyond a certain point\n\n57:24.520 --> 57:27.640\n there's materials that doesn't exist in courses\n\n57:27.640 --> 57:28.840\n because it's too cutting edge\n\n57:28.840 --> 57:30.040\n the course hasn't been created yet\n\n57:30.040 --> 57:31.320\n there's some practical experience\n\n57:31.320 --> 57:32.760\n that we're not yet that good\n\n57:32.760 --> 57:34.440\n as teaching in a course\n\n57:34.440 --> 57:36.040\n and I think after exhausting\n\n57:36.040 --> 57:37.720\n the efficient coursework\n\n57:37.720 --> 57:40.360\n then most people need to go on\n\n57:40.360 --> 57:44.520\n to either ideally work on projects\n\n57:44.520 --> 57:47.080\n and then maybe also continue their learning\n\n57:47.080 --> 57:49.560\n by reading blog posts and research papers\n\n57:49.560 --> 57:50.280\n and things like that\n\n57:50.920 --> 57:52.280\n doing projects is really important\n\n57:52.280 --> 57:55.080\n and again I think it's important\n\n57:55.080 --> 57:57.560\n to start small and just do something\n\n57:57.560 --> 57:58.920\n today you read about deep learning\n\n57:58.920 --> 57:59.800\n feels like oh all these people\n\n57:59.800 --> 58:01.080\n doing such exciting things\n\n58:01.080 --> 58:02.920\n what if I'm not building a neural network\n\n58:02.920 --> 58:03.720\n that changes the world\n\n58:03.720 --> 58:04.440\n then what's the point?\n\n58:04.440 --> 58:06.360\n Well the point is sometimes building\n\n58:06.360 --> 58:07.720\n that tiny neural network\n\n58:07.720 --> 58:10.120\n you know be it MNIST or upgrade\n\n58:10.120 --> 58:12.280\n to a fashion MNIST to whatever\n\n58:12.280 --> 58:14.680\n so doing your own fun hobby project\n\n58:14.680 --> 58:15.960\n that's how you gain the skills\n\n58:15.960 --> 58:18.200\n to let you do bigger and bigger projects\n\n58:18.200 --> 58:20.520\n I find this to be true at the individual level\n\n58:20.520 --> 58:23.080\n and also at the organizational level\n\n58:23.080 --> 58:24.920\n for a company to become good at machine learning\n\n58:24.920 --> 58:26.200\n sometimes the right thing to do\n\n58:26.200 --> 58:29.240\n is not to tackle the giant project\n\n58:29.240 --> 58:31.240\n is instead to do the small project\n\n58:31.240 --> 58:33.320\n that lets the organization learn\n\n58:33.320 --> 58:34.600\n and then build out from there\n\n58:34.600 --> 58:35.960\n but this is true both for individuals\n\n58:35.960 --> 58:38.200\n and for companies\n\n58:38.200 --> 58:40.680\n taking the first step\n\n58:40.680 --> 58:44.040\n and then taking small steps is the key\n\n58:44.520 --> 58:46.280\n should students pursue a PhD\n\n58:46.280 --> 58:48.520\n do you think you can do so much\n\n58:48.520 --> 58:50.200\n that's one of the fascinating things\n\n58:50.200 --> 58:51.160\n in machine learning\n\n58:51.160 --> 58:52.280\n you can have so much impact\n\n58:52.280 --> 58:54.440\n without ever getting a PhD\n\n58:54.440 --> 58:56.040\n so what are your thoughts\n\n58:56.040 --> 58:57.400\n should people go to grad school\n\n58:57.400 --> 58:59.400\n should people get a PhD?\n\n58:59.400 --> 59:01.720\n I think that there are multiple good options\n\n59:01.720 --> 59:05.000\n of which doing a PhD could be one of them\n\n59:05.000 --> 59:06.920\n I think that if someone's admitted\n\n59:06.920 --> 59:08.520\n to a top PhD program\n\n59:08.520 --> 59:11.880\n you know at MIT, Stanford, top schools\n\n59:11.880 --> 59:15.320\n I think that's a very good experience\n\n59:15.320 --> 59:17.000\n or if someone gets a job\n\n59:17.000 --> 59:18.760\n at a top organization\n\n59:18.760 --> 59:20.440\n at the top AI team\n\n59:20.440 --> 59:23.880\n I think that's also a very good experience\n\n59:23.880 --> 59:25.880\n there are some things you still need a PhD to do\n\n59:25.880 --> 59:27.640\n if someone's aspiration is to be a professor\n\n59:27.640 --> 59:29.080\n you know at the top academic university\n\n59:29.080 --> 59:30.920\n you just need a PhD to do that\n\n59:30.920 --> 59:32.520\n but if it goes to you know\n\n59:32.520 --> 59:34.120\n start a company, build a company\n\n59:34.120 --> 59:35.320\n do great technical work\n\n59:35.320 --> 59:37.640\n I think a PhD is a good experience\n\n59:37.640 --> 59:40.200\n but I would look at the different options\n\n59:40.200 --> 59:41.160\n available to someone\n\n59:41.160 --> 59:42.120\n you know where are the places\n\n59:42.120 --> 59:42.920\n where you can get a job\n\n59:42.920 --> 59:44.920\n where are the places to get a PhD program\n\n59:44.920 --> 59:46.840\n and kind of weigh the pros and cons of those\n\n59:46.840 --> 59:50.040\n So just to linger on that for a little bit longer\n\n59:50.040 --> 59:51.720\n what final dreams and goals\n\n59:51.720 --> 59:53.000\n do you think people should have\n\n59:53.000 --> 59:57.320\n so what options should they explore\n\n59:57.320 --> 59:59.720\n so you can work in industry\n\n59:59.720 --> 1:00:00.920\n so for a large company\n\n1:00:01.960 --> 1:00:03.560\n like Google, Facebook, Baidu\n\n1:00:03.560 --> 1:00:06.040\n all these large sort of companies\n\n1:00:06.040 --> 1:00:07.720\n that already have huge teams\n\n1:00:07.720 --> 1:00:09.160\n of machine learning engineers\n\n1:00:09.160 --> 1:00:10.920\n you can also do with an industry\n\n1:00:10.920 --> 1:00:12.200\n sort of more research groups\n\n1:00:12.200 --> 1:00:14.440\n that kind of like Google Research, Google Brain\n\n1:00:14.440 --> 1:00:16.600\n then you can also do\n\n1:00:16.600 --> 1:00:19.800\n like we said a professor in academia\n\n1:00:20.360 --> 1:00:21.800\n and what else\n\n1:00:21.800 --> 1:00:23.320\n oh you can build your own company\n\n1:00:23.880 --> 1:00:25.080\n you can do a startup\n\n1:00:25.080 --> 1:00:27.240\n is there anything that stands out\n\n1:00:27.240 --> 1:00:28.440\n between those options\n\n1:00:28.440 --> 1:00:30.680\n or are they all beautiful different journeys\n\n1:00:30.680 --> 1:00:31.800\n that people should consider\n\n1:00:32.520 --> 1:00:34.760\n I think the thing that affects your experience more\n\n1:00:34.760 --> 1:00:36.920\n is less are you in this company\n\n1:00:36.920 --> 1:00:38.040\n versus that company\n\n1:00:38.040 --> 1:00:40.040\n or academia versus industry\n\n1:00:40.040 --> 1:00:41.480\n I think the thing that affects your experience most\n\n1:00:41.480 --> 1:00:43.640\n is who are the people you're interacting with\n\n1:00:43.640 --> 1:00:44.920\n in a daily basis\n\n1:00:45.480 --> 1:00:48.760\n so even if you look at some of the large companies\n\n1:00:49.400 --> 1:00:50.920\n the experience of individuals\n\n1:00:50.920 --> 1:00:52.920\n in different teams is very different\n\n1:00:52.920 --> 1:00:56.120\n and what matters most is not the logo above the door\n\n1:00:56.120 --> 1:00:58.280\n when you walk into the giant building every day\n\n1:00:58.280 --> 1:01:00.440\n what matters the most is who are the 10 people\n\n1:01:00.440 --> 1:01:03.080\n who are the 30 people you interact with every day\n\n1:01:03.080 --> 1:01:04.840\n so I actually tend to advise people\n\n1:01:04.840 --> 1:01:06.680\n if you get a job from a company\n\n1:01:07.480 --> 1:01:09.320\n ask who is your manager\n\n1:01:09.320 --> 1:01:10.120\n who are your peers\n\n1:01:10.120 --> 1:01:11.320\n who are you actually going to talk to\n\n1:01:11.320 --> 1:01:12.440\n we're all social creatures\n\n1:01:12.440 --> 1:01:15.400\n we tend to become more like the people around us\n\n1:01:15.400 --> 1:01:17.480\n and if you're working with great people\n\n1:01:17.480 --> 1:01:18.600\n you will learn faster\n\n1:01:19.240 --> 1:01:20.520\n or if you get admitted\n\n1:01:20.520 --> 1:01:23.000\n if you get a job at a great company\n\n1:01:23.000 --> 1:01:24.120\n or a great university\n\n1:01:24.120 --> 1:01:26.680\n maybe the logo you walk in is great\n\n1:01:26.680 --> 1:01:28.200\n but you're actually stuck on some team\n\n1:01:28.200 --> 1:01:30.600\n doing really work that doesn't excite you\n\n1:01:31.160 --> 1:01:33.000\n and then that's actually a really bad experience\n\n1:01:33.640 --> 1:01:36.280\n so this is true both for universities\n\n1:01:36.280 --> 1:01:37.960\n and for large companies\n\n1:01:37.960 --> 1:01:39.640\n for small companies you can kind of figure out\n\n1:01:39.640 --> 1:01:41.240\n who you'll be working with quite quickly\n\n1:01:41.240 --> 1:01:43.240\n and I tend to advise people\n\n1:01:43.240 --> 1:01:45.080\n if a company refuses to tell you\n\n1:01:45.080 --> 1:01:46.120\n who you will work with\n\n1:01:46.120 --> 1:01:47.160\n someone say oh join us\n\n1:01:47.160 --> 1:01:48.920\n the rotation system will figure it out\n\n1:01:48.920 --> 1:01:51.000\n I think that that's a worrying answer\n\n1:01:51.000 --> 1:01:54.680\n because it because it means you may not get sent\n\n1:01:54.680 --> 1:01:57.640\n to you may not actually get to a team\n\n1:01:57.640 --> 1:02:00.120\n with great peers and great people to work with\n\n1:02:00.120 --> 1:02:01.960\n it's actually a really profound advice\n\n1:02:01.960 --> 1:02:03.800\n that we kind of sometimes sweep\n\n1:02:04.440 --> 1:02:07.880\n we don't consider too rigorously or carefully\n\n1:02:07.880 --> 1:02:10.280\n the people around you are really often\n\n1:02:10.280 --> 1:02:13.000\n especially when you accomplish great things\n\n1:02:13.000 --> 1:02:14.600\n it seems the great things are accomplished\n\n1:02:14.600 --> 1:02:15.880\n because of the people around you\n\n1:02:16.680 --> 1:02:20.360\n so that's a it's not about the the\n\n1:02:20.360 --> 1:02:21.880\n where whether you learn this thing\n\n1:02:21.880 --> 1:02:23.320\n or that thing or like you said\n\n1:02:23.320 --> 1:02:25.000\n the logo that hangs up top\n\n1:02:25.000 --> 1:02:26.680\n it's the people that's a fascinating\n\n1:02:27.320 --> 1:02:29.160\n and it's such a hard search process\n\n1:02:30.520 --> 1:02:34.120\n of finding just like finding the right friends\n\n1:02:34.120 --> 1:02:36.360\n and somebody to get married with\n\n1:02:36.360 --> 1:02:37.400\n and that kind of thing\n\n1:02:37.400 --> 1:02:38.680\n it's a very hard search\n\n1:02:38.680 --> 1:02:40.280\n it's a people search problem\n\n1:02:40.840 --> 1:02:43.320\n yeah but I think when someone interviews\n\n1:02:43.320 --> 1:02:44.440\n you know at a university\n\n1:02:44.440 --> 1:02:46.280\n or the research lab or the large corporation\n\n1:02:47.320 --> 1:02:49.400\n it's good to insist on just asking\n\n1:02:49.400 --> 1:02:50.200\n who are the people\n\n1:02:50.200 --> 1:02:51.320\n who is my manager\n\n1:02:51.320 --> 1:02:52.520\n and if you refuse to tell me\n\n1:02:52.520 --> 1:02:54.440\n I'm gonna think well maybe that's\n\n1:02:54.440 --> 1:02:55.560\n because you don't have a good answer\n\n1:02:55.560 --> 1:02:57.240\n it may not be someone I like\n\n1:02:57.240 --> 1:02:59.320\n and if you don't particularly connect\n\n1:02:59.320 --> 1:03:01.240\n if something feels off with the people\n\n1:03:02.360 --> 1:03:05.880\n then don't stick to it\n\n1:03:05.880 --> 1:03:08.520\n you know that's a really important signal to consider\n\n1:03:08.520 --> 1:03:10.600\n yeah yeah and actually I actually\n\n1:03:11.160 --> 1:03:13.240\n in my standard class CS230\n\n1:03:13.240 --> 1:03:14.520\n as well as an ACM talk\n\n1:03:14.520 --> 1:03:16.920\n I think I gave like a hour long talk\n\n1:03:16.920 --> 1:03:18.200\n on career advice\n\n1:03:18.200 --> 1:03:20.200\n including on the job search process\n\n1:03:20.200 --> 1:03:20.920\n and then some of these\n\n1:03:20.920 --> 1:03:23.160\n so you can find those videos online\n\n1:03:23.160 --> 1:03:24.280\n awesome and I'll point them\n\n1:03:25.000 --> 1:03:26.440\n I'll point people to them\n\n1:03:26.440 --> 1:03:26.840\n beautiful\n\n1:03:28.360 --> 1:03:32.120\n so the AI fund helps AI startups\n\n1:03:32.120 --> 1:03:33.400\n get off the ground\n\n1:03:33.400 --> 1:03:34.680\n or perhaps you can elaborate\n\n1:03:34.680 --> 1:03:36.920\n on all the fun things it's involved with\n\n1:03:36.920 --> 1:03:37.800\n what's your advice\n\n1:03:37.800 --> 1:03:40.600\n and how does one build a successful AI startup\n\n1:03:41.880 --> 1:03:43.320\n you know in Silicon Valley\n\n1:03:43.320 --> 1:03:44.920\n a lot of startup failures\n\n1:03:44.920 --> 1:03:46.680\n come from building other products\n\n1:03:46.680 --> 1:03:48.520\n that no one wanted\n\n1:03:48.520 --> 1:03:51.800\n so when you know cool technology\n\n1:03:51.800 --> 1:03:53.400\n but who's going to use it\n\n1:03:53.400 --> 1:03:56.920\n so I think I tend to be very outcome driven\n\n1:03:57.640 --> 1:03:59.080\n and customer obsessed\n\n1:04:00.280 --> 1:04:02.360\n ultimately we don't get to vote\n\n1:04:02.360 --> 1:04:04.120\n if we succeed or fail\n\n1:04:04.120 --> 1:04:05.560\n it's only the customer\n\n1:04:05.560 --> 1:04:06.920\n that they're the only one\n\n1:04:06.920 --> 1:04:08.840\n that gets a thumbs up or thumbs down vote\n\n1:04:08.840 --> 1:04:09.560\n in the long term\n\n1:04:09.560 --> 1:04:10.600\n in the short term\n\n1:04:10.600 --> 1:04:12.040\n you know there are various people\n\n1:04:12.040 --> 1:04:13.000\n that get various votes\n\n1:04:13.000 --> 1:04:14.440\n but in the long term\n\n1:04:14.440 --> 1:04:15.640\n that's what really matters\n\n1:04:16.280 --> 1:04:17.400\n so as you build the startup\n\n1:04:17.400 --> 1:04:19.240\n you have to constantly ask the question\n\n1:04:20.760 --> 1:04:23.560\n will the customer give a thumbs up on this\n\n1:04:24.120 --> 1:04:24.760\n I think so\n\n1:04:24.760 --> 1:04:27.320\n I think startups that are very customer focused\n\n1:04:27.320 --> 1:04:28.200\n customer obsessed\n\n1:04:28.200 --> 1:04:30.360\n deeply understand the customer\n\n1:04:30.360 --> 1:04:34.200\n and are oriented to serve the customer\n\n1:04:34.200 --> 1:04:35.720\n are more likely to succeed\n\n1:04:36.360 --> 1:04:37.240\n with the provisional\n\n1:04:37.240 --> 1:04:38.920\n I think all of us should only do things\n\n1:04:38.920 --> 1:04:40.760\n that we think create social good\n\n1:04:40.760 --> 1:04:41.880\n and moves the world forward\n\n1:04:41.880 --> 1:04:44.360\n so I personally don't want to build\n\n1:04:44.360 --> 1:04:45.880\n addictive digital products\n\n1:04:45.880 --> 1:04:47.160\n just to sell a lot of ads\n\n1:04:47.160 --> 1:04:48.200\n or you know there are things\n\n1:04:48.200 --> 1:04:49.400\n that could be lucrative\n\n1:04:49.400 --> 1:04:50.120\n that I won't do\n\n1:04:51.720 --> 1:04:53.640\n but if we can find ways to serve people\n\n1:04:53.640 --> 1:04:54.520\n in meaningful ways\n\n1:04:55.160 --> 1:04:56.120\n I think those can be\n\n1:04:57.240 --> 1:04:58.920\n great things to do\n\n1:04:58.920 --> 1:05:00.360\n either in the academic setting\n\n1:05:00.360 --> 1:05:01.320\n or in a corporate setting\n\n1:05:01.320 --> 1:05:02.360\n or a startup setting\n\n1:05:02.920 --> 1:05:04.440\n so can you give me the idea\n\n1:05:04.440 --> 1:05:07.400\n of why you started the AI fund\n\n1:05:08.520 --> 1:05:10.120\n I remember when I was leading\n\n1:05:10.120 --> 1:05:12.280\n the AI group at Baidu\n\n1:05:13.160 --> 1:05:14.920\n I had two jobs\n\n1:05:14.920 --> 1:05:15.800\n two parts of my job\n\n1:05:15.800 --> 1:05:17.240\n one was to build an AI engine\n\n1:05:17.240 --> 1:05:19.000\n to support the existing businesses\n\n1:05:19.000 --> 1:05:20.520\n and that was running\n\n1:05:20.520 --> 1:05:21.320\n just ran\n\n1:05:21.320 --> 1:05:23.080\n just performed by itself\n\n1:05:23.080 --> 1:05:24.600\n there was a second part of my job at the time\n\n1:05:24.600 --> 1:05:27.240\n which was to try to systematically initiate\n\n1:05:27.240 --> 1:05:28.920\n new lines of businesses\n\n1:05:28.920 --> 1:05:31.080\n using the company's AI capabilities\n\n1:05:31.080 --> 1:05:33.240\n so you know the self driving car team\n\n1:05:33.240 --> 1:05:34.360\n came out of my group\n\n1:05:34.360 --> 1:05:36.120\n the smart speaker team\n\n1:05:37.080 --> 1:05:40.840\n similar to what is Amazon Echo Alexa in the US\n\n1:05:40.840 --> 1:05:41.720\n but we actually announced it\n\n1:05:41.720 --> 1:05:42.760\n before Amazon did\n\n1:05:42.760 --> 1:05:46.440\n so Baidu wasn't following Amazon\n\n1:05:47.320 --> 1:05:48.600\n that came out of my group\n\n1:05:48.600 --> 1:05:50.040\n and I found that to be\n\n1:05:50.680 --> 1:05:52.440\n actually the most fun part of my job\n\n1:05:53.400 --> 1:05:55.080\n so what I wanted to do was\n\n1:05:55.080 --> 1:05:58.200\n to build AI fund as a startup studio\n\n1:05:58.200 --> 1:06:01.000\n to systematically create new startups\n\n1:06:01.000 --> 1:06:01.640\n from scratch\n\n1:06:02.600 --> 1:06:04.840\n with all the things we can now do with AI\n\n1:06:04.840 --> 1:06:07.240\n I think the ability to build new teams\n\n1:06:07.240 --> 1:06:09.960\n to go after this rich space of opportunities\n\n1:06:09.960 --> 1:06:11.720\n is a very important way\n\n1:06:11.720 --> 1:06:13.480\n to very important mechanism\n\n1:06:13.480 --> 1:06:14.760\n to get these projects done\n\n1:06:14.760 --> 1:06:16.520\n that I think will move the world forward\n\n1:06:16.520 --> 1:06:19.160\n so I've been fortunate to build a few teams\n\n1:06:19.160 --> 1:06:21.560\n that had a meaningful positive impact\n\n1:06:21.560 --> 1:06:25.000\n and I felt that we might be able to do this\n\n1:06:25.000 --> 1:06:27.160\n in a more systematic repeatable way\n\n1:06:27.880 --> 1:06:31.400\n so a startup studio is a relatively new concept\n\n1:06:31.400 --> 1:06:34.120\n there are maybe dozens of startup studios\n\n1:06:34.120 --> 1:06:34.840\n you know right now\n\n1:06:35.640 --> 1:06:38.680\n but I feel like all of us\n\n1:06:38.680 --> 1:06:40.840\n many teams are still trying to figure out\n\n1:06:40.840 --> 1:06:43.640\n how do you systematically build companies\n\n1:06:43.640 --> 1:06:45.320\n with a high success rate\n\n1:06:45.320 --> 1:06:47.960\n so I think even a lot of my you know\n\n1:06:47.960 --> 1:06:49.560\n venture capital friends are\n\n1:06:49.560 --> 1:06:51.640\n seem to be more and more building companies\n\n1:06:51.640 --> 1:06:53.000\n rather than investing in companies\n\n1:06:53.000 --> 1:06:54.680\n but I find a fascinating thing to do\n\n1:06:55.240 --> 1:06:56.520\n to figure out the mechanisms\n\n1:06:56.520 --> 1:06:58.680\n by which we could systematically build\n\n1:06:58.680 --> 1:07:00.520\n successful teams, successful businesses\n\n1:07:01.400 --> 1:07:03.320\n in areas that we find meaningful\n\n1:07:03.320 --> 1:07:05.720\n so a startup studio is something\n\n1:07:05.720 --> 1:07:08.440\n is a place and a mechanism\n\n1:07:08.440 --> 1:07:11.000\n for startups to go from zero to success\n\n1:07:11.000 --> 1:07:13.080\n to try to develop a blueprint\n\n1:07:13.720 --> 1:07:14.680\n it's actually a place for us\n\n1:07:14.680 --> 1:07:16.520\n to build startups from scratch\n\n1:07:16.520 --> 1:07:19.320\n so we often bring in founders\n\n1:07:19.320 --> 1:07:21.160\n and work with them\n\n1:07:21.160 --> 1:07:23.720\n or maybe even have existing ideas\n\n1:07:23.720 --> 1:07:25.880\n that we match founders with\n\n1:07:26.440 --> 1:07:27.880\n and then this launches\n\n1:07:27.880 --> 1:07:30.920\n you know hopefully into successful companies\n\n1:07:30.920 --> 1:07:34.040\n so how close are you to figuring out\n\n1:07:34.040 --> 1:07:36.920\n a way to automate the process\n\n1:07:36.920 --> 1:07:38.280\n of starting from scratch\n\n1:07:38.280 --> 1:07:40.440\n and building a successful AI startup\n\n1:07:40.440 --> 1:07:43.720\n yeah I think we've been constantly\n\n1:07:43.720 --> 1:07:46.040\n improving and iterating on our processes\n\n1:07:46.680 --> 1:07:47.560\n how we do that\n\n1:07:47.560 --> 1:07:48.920\n so things like you know\n\n1:07:48.920 --> 1:07:50.600\n how many customer calls do we need to make\n\n1:07:50.600 --> 1:07:52.280\n in order to get customer validation\n\n1:07:52.840 --> 1:07:54.040\n how do we make sure this technology\n\n1:07:54.040 --> 1:07:54.520\n can be built\n\n1:07:54.520 --> 1:07:56.200\n quite a lot of our businesses\n\n1:07:56.200 --> 1:07:58.440\n need cutting edge machine learning algorithms\n\n1:07:58.440 --> 1:07:59.480\n so you know kind of algorithms\n\n1:07:59.480 --> 1:08:01.880\n have developed in the last one or two years\n\n1:08:01.880 --> 1:08:04.280\n and even if it works in a research paper\n\n1:08:04.280 --> 1:08:05.640\n it turns out taking the production\n\n1:08:05.640 --> 1:08:06.200\n is really hard\n\n1:08:06.200 --> 1:08:07.160\n there are a lot of issues\n\n1:08:07.160 --> 1:08:09.480\n for making these things work in the real life\n\n1:08:10.840 --> 1:08:13.400\n that are not widely addressed in academia\n\n1:08:13.400 --> 1:08:14.520\n so how do we validate\n\n1:08:14.520 --> 1:08:15.720\n that this is actually doable\n\n1:08:15.720 --> 1:08:17.080\n how do you build a team\n\n1:08:17.080 --> 1:08:18.600\n get the specialized domain knowledge\n\n1:08:18.600 --> 1:08:20.200\n be it in education or health care\n\n1:08:20.200 --> 1:08:21.800\n whatever sector we're focusing on\n\n1:08:21.800 --> 1:08:23.240\n so I think we've actually getting\n\n1:08:23.240 --> 1:08:24.680\n we've been getting much better\n\n1:08:24.680 --> 1:08:27.880\n at giving the entrepreneurs\n\n1:08:27.880 --> 1:08:29.400\n a high success rate\n\n1:08:29.400 --> 1:08:30.440\n but I think we're still\n\n1:08:31.080 --> 1:08:32.520\n I think the whole world is still\n\n1:08:32.520 --> 1:08:34.120\n in the early phases of figuring this out\n\n1:08:34.120 --> 1:08:36.840\n but do you think there is some aspects\n\n1:08:36.840 --> 1:08:38.760\n of that process that are transferable\n\n1:08:38.760 --> 1:08:40.280\n from one startup to another\n\n1:08:40.280 --> 1:08:41.640\n to another to another\n\n1:08:41.640 --> 1:08:43.000\n yeah very much so\n\n1:08:43.000 --> 1:08:45.080\n you know starting from scratch\n\n1:08:45.080 --> 1:08:46.520\n you know starting a company\n\n1:08:46.520 --> 1:08:47.640\n to most entrepreneurs\n\n1:08:47.640 --> 1:08:50.680\n is a really lonely thing\n\n1:08:50.680 --> 1:08:53.720\n and I've seen so many entrepreneurs\n\n1:08:53.720 --> 1:08:56.200\n not know how to make certain decisions\n\n1:08:56.200 --> 1:08:57.720\n like when do you need to\n\n1:08:58.440 --> 1:09:00.040\n how do you do B2B sales right\n\n1:09:00.040 --> 1:09:00.920\n if you don't know that\n\n1:09:00.920 --> 1:09:02.280\n it's really hard\n\n1:09:02.280 --> 1:09:05.400\n or how do you market this efficiently\n\n1:09:05.400 --> 1:09:06.920\n other than you know buying ads\n\n1:09:06.920 --> 1:09:08.360\n which is really expensive\n\n1:09:08.360 --> 1:09:10.040\n are there more efficient tactics for that\n\n1:09:10.040 --> 1:09:12.360\n or for a machine learning project\n\n1:09:12.360 --> 1:09:14.200\n you know basic decisions\n\n1:09:14.200 --> 1:09:15.320\n can change the course of\n\n1:09:15.320 --> 1:09:17.720\n whether machine learning product works or not\n\n1:09:18.360 --> 1:09:20.920\n and so there are so many hundreds of decisions\n\n1:09:20.920 --> 1:09:22.600\n that entrepreneurs need to make\n\n1:09:22.600 --> 1:09:24.440\n and making a mistake\n\n1:09:24.440 --> 1:09:25.640\n and a couple key decisions\n\n1:09:25.640 --> 1:09:26.840\n can have a huge impact\n\n1:09:28.520 --> 1:09:30.120\n on the fate of the company\n\n1:09:30.120 --> 1:09:31.400\n so I think a startup studio\n\n1:09:31.400 --> 1:09:32.920\n provides a support structure\n\n1:09:32.920 --> 1:09:34.280\n that makes starting a company\n\n1:09:34.280 --> 1:09:36.200\n much less of a lonely experience\n\n1:09:36.200 --> 1:09:39.960\n and also when facing with these key decisions\n\n1:09:39.960 --> 1:09:42.280\n like trying to hire your first\n\n1:09:42.280 --> 1:09:44.120\n uh the VP of engineering\n\n1:09:44.840 --> 1:09:46.280\n what's a good selection criteria\n\n1:09:46.280 --> 1:09:46.920\n how do you solve\n\n1:09:46.920 --> 1:09:48.600\n should I hire this person or not\n\n1:09:48.600 --> 1:09:51.400\n by helping by having a ecosystem\n\n1:09:51.400 --> 1:09:52.920\n around the entrepreneurs\n\n1:09:52.920 --> 1:09:54.520\n the founders to help\n\n1:09:54.520 --> 1:09:57.320\n I think we help them at the key moments\n\n1:09:57.320 --> 1:09:58.680\n and hopefully significantly\n\n1:09:59.720 --> 1:10:00.840\n make them more enjoyable\n\n1:10:00.840 --> 1:10:02.280\n and then higher success rate\n\n1:10:02.280 --> 1:10:04.520\n so there's somebody to brainstorm with\n\n1:10:04.520 --> 1:10:07.080\n in these very difficult decision points\n\n1:10:07.880 --> 1:10:10.920\n and also to help them recognize\n\n1:10:10.920 --> 1:10:12.840\n what they may not even realize\n\n1:10:12.840 --> 1:10:14.120\n is a key decision point\n\n1:10:14.760 --> 1:10:15.800\n that's that's the first\n\n1:10:15.800 --> 1:10:17.240\n and probably the most important part\n\n1:10:17.240 --> 1:10:19.720\n yeah actually I can say one other thing\n\n1:10:19.720 --> 1:10:21.400\n um you know I think\n\n1:10:22.200 --> 1:10:23.800\n building companies is one thing\n\n1:10:23.800 --> 1:10:26.360\n but I feel like it's really important\n\n1:10:26.360 --> 1:10:28.040\n that we build companies\n\n1:10:28.040 --> 1:10:29.960\n that move the world forward\n\n1:10:29.960 --> 1:10:32.360\n for example within the AI Fund team\n\n1:10:32.360 --> 1:10:33.640\n there was once an idea\n\n1:10:33.640 --> 1:10:35.480\n for a new company\n\n1:10:35.480 --> 1:10:37.240\n that if it had succeeded\n\n1:10:37.240 --> 1:10:38.680\n would have resulted in people\n\n1:10:38.680 --> 1:10:40.040\n watching a lot more videos\n\n1:10:40.040 --> 1:10:42.760\n in a certain narrow vertical type of video\n\n1:10:42.760 --> 1:10:43.880\n um I looked at it\n\n1:10:43.880 --> 1:10:45.480\n the business case was fine\n\n1:10:45.480 --> 1:10:46.600\n the revenue case was fine\n\n1:10:46.600 --> 1:10:47.560\n but I looked and just said\n\n1:10:48.200 --> 1:10:49.240\n I don't want to do this\n\n1:10:49.240 --> 1:10:50.600\n like you know I don't actually\n\n1:10:50.600 --> 1:10:52.360\n just want to have a lot more people\n\n1:10:52.360 --> 1:10:53.720\n watch this type of video\n\n1:10:53.720 --> 1:10:54.600\n wasn't educational\n\n1:10:54.600 --> 1:10:56.200\n it's an educational baby\n\n1:10:56.200 --> 1:10:59.000\n and so and so I I I I code the idea\n\n1:10:59.000 --> 1:11:00.520\n on the basis that I didn't think\n\n1:11:00.520 --> 1:11:01.880\n it would actually help people\n\n1:11:01.880 --> 1:11:04.040\n so um whether building companies\n\n1:11:04.040 --> 1:11:05.240\n or working enterprises\n\n1:11:05.240 --> 1:11:06.600\n or doing personal projects\n\n1:11:06.600 --> 1:11:10.200\n I think um it's up to each of us\n\n1:11:10.200 --> 1:11:11.480\n to figure out what's the difference\n\n1:11:11.480 --> 1:11:12.600\n we want to make in the world\n\n1:11:13.960 --> 1:11:15.240\n With landing AI\n\n1:11:15.240 --> 1:11:17.000\n you help already established companies\n\n1:11:17.000 --> 1:11:19.320\n grow their AI and machine learning efforts\n\n1:11:20.040 --> 1:11:21.720\n how does a large company\n\n1:11:21.720 --> 1:11:22.840\n integrate machine learning\n\n1:11:22.840 --> 1:11:23.640\n into their efforts?\n\n1:11:25.240 --> 1:11:27.560\n AI is a general purpose technology\n\n1:11:27.560 --> 1:11:29.560\n and I think it will transform every industry\n\n1:11:30.360 --> 1:11:32.920\n our community has already transformed\n\n1:11:32.920 --> 1:11:33.640\n to a large extent\n\n1:11:33.640 --> 1:11:35.320\n the software internet sector\n\n1:11:35.320 --> 1:11:36.840\n most software internet companies\n\n1:11:36.840 --> 1:11:38.040\n outside the top right\n\n1:11:38.040 --> 1:11:39.240\n five or six or three or four\n\n1:11:39.960 --> 1:11:41.880\n already have reasonable\n\n1:11:41.880 --> 1:11:43.160\n machine learning capabilities\n\n1:11:43.160 --> 1:11:44.040\n or or getting there\n\n1:11:44.040 --> 1:11:45.160\n it's still room for improvement\n\n1:11:46.200 --> 1:11:47.320\n but when I look outside\n\n1:11:47.320 --> 1:11:49.080\n the software internet sector\n\n1:11:49.080 --> 1:11:50.600\n everything from manufacturing\n\n1:11:50.600 --> 1:11:52.040\n agriculture, healthcare\n\n1:11:52.040 --> 1:11:53.720\n logistics transportation\n\n1:11:53.720 --> 1:11:55.480\n there's so many opportunities\n\n1:11:55.480 --> 1:11:57.800\n that very few people are working on\n\n1:11:57.800 --> 1:11:59.640\n so I think the next wave of AI\n\n1:11:59.640 --> 1:12:01.080\n is for us to also transform\n\n1:12:01.080 --> 1:12:02.680\n all of those other industries\n\n1:12:03.240 --> 1:12:04.440\n there was a McKinsey study\n\n1:12:04.440 --> 1:12:06.840\n estimating 13 trillion dollars\n\n1:12:06.840 --> 1:12:08.520\n of global economic growth\n\n1:12:09.560 --> 1:12:11.560\n US GDP is 19 trillion dollars\n\n1:12:11.560 --> 1:12:13.160\n so 13 trillion is a big number\n\n1:12:13.160 --> 1:12:16.040\n or PwC estimates 16 trillion dollars\n\n1:12:16.040 --> 1:12:18.200\n so whatever number is is large\n\n1:12:18.200 --> 1:12:19.400\n but the interesting thing to me\n\n1:12:19.400 --> 1:12:20.600\n was a lot of that impact\n\n1:12:20.600 --> 1:12:21.640\n will be outside\n\n1:12:21.640 --> 1:12:23.080\n the software internet sector\n\n1:12:23.640 --> 1:12:25.160\n so we need more teams\n\n1:12:25.880 --> 1:12:27.880\n to work with these companies\n\n1:12:27.880 --> 1:12:29.640\n to help them adopt AI\n\n1:12:29.640 --> 1:12:30.680\n and I think this is one thing\n\n1:12:30.680 --> 1:12:31.800\n so make you know\n\n1:12:31.800 --> 1:12:33.560\n help drive global economic growth\n\n1:12:33.560 --> 1:12:35.800\n and make humanity more powerful\n\n1:12:35.800 --> 1:12:37.720\n and like you said the impact is there\n\n1:12:37.720 --> 1:12:39.400\n so what are the best industries\n\n1:12:39.400 --> 1:12:40.360\n the biggest industries\n\n1:12:40.360 --> 1:12:41.560\n where AI can help\n\n1:12:41.560 --> 1:12:43.720\n perhaps outside the software tech sector\n\n1:12:44.360 --> 1:12:45.880\n frankly I think it's all of them\n\n1:12:47.880 --> 1:12:49.800\n some of the ones I'm spending a lot of time on\n\n1:12:49.800 --> 1:12:52.360\n are manufacturing agriculture\n\n1:12:52.360 --> 1:12:53.400\n look into healthcare\n\n1:12:54.440 --> 1:12:56.360\n for example in manufacturing\n\n1:12:56.360 --> 1:12:58.600\n we do a lot of work in visual inspection\n\n1:12:58.600 --> 1:13:01.320\n where today there are people standing around\n\n1:13:01.320 --> 1:13:02.840\n using the eye human eye\n\n1:13:02.840 --> 1:13:03.880\n to check if you know\n\n1:13:03.880 --> 1:13:05.720\n this plastic part or the smartphone\n\n1:13:05.720 --> 1:13:07.320\n or this thing has a scratch\n\n1:13:07.320 --> 1:13:08.440\n or a dent or something in it\n\n1:13:09.320 --> 1:13:12.440\n we can use a camera to take a picture\n\n1:13:12.440 --> 1:13:14.040\n use a algorithm\n\n1:13:14.040 --> 1:13:15.400\n deep learning and other things\n\n1:13:15.400 --> 1:13:17.800\n to check if it's defective or not\n\n1:13:17.800 --> 1:13:20.440\n and thus help factories improve yield\n\n1:13:20.440 --> 1:13:21.560\n and improve quality\n\n1:13:21.560 --> 1:13:22.680\n and improve throughput\n\n1:13:23.480 --> 1:13:25.000\n it turns out the practical problems\n\n1:13:25.000 --> 1:13:26.520\n we run into are very different\n\n1:13:26.520 --> 1:13:28.040\n than the ones you might read about\n\n1:13:28.040 --> 1:13:29.400\n in in most research papers\n\n1:13:29.400 --> 1:13:30.680\n the data sets are really small\n\n1:13:30.680 --> 1:13:33.160\n so we face small data problems\n\n1:13:33.160 --> 1:13:34.200\n you know the factories\n\n1:13:34.200 --> 1:13:35.800\n keep on changing the environment\n\n1:13:35.800 --> 1:13:38.200\n so it works well on your test set\n\n1:13:38.200 --> 1:13:39.000\n but guess what\n\n1:13:40.680 --> 1:13:41.960\n something changes in the factory\n\n1:13:41.960 --> 1:13:43.480\n the lights go on or off\n\n1:13:43.480 --> 1:13:45.080\n recently there was a factory\n\n1:13:45.080 --> 1:13:47.800\n in which a bird threw through the factory\n\n1:13:47.800 --> 1:13:48.840\n and pooped on something\n\n1:13:48.840 --> 1:13:50.760\n and so that changed stuff\n\n1:13:50.760 --> 1:13:53.080\n and so increasing our algorithm\n\n1:13:53.080 --> 1:13:54.200\n makes robustness\n\n1:13:54.200 --> 1:13:56.280\n so all the changes happen in the factory\n\n1:13:56.920 --> 1:13:59.160\n I find that we run a lot of practical problems\n\n1:13:59.160 --> 1:14:01.480\n that are not as widely discussed\n\n1:14:01.480 --> 1:14:02.600\n in academia\n\n1:14:02.600 --> 1:14:03.960\n and it's really fun\n\n1:14:03.960 --> 1:14:05.080\n kind of being on the cutting edge\n\n1:14:05.080 --> 1:14:06.600\n solving these problems before\n\n1:14:07.560 --> 1:14:09.240\n maybe before many people are even aware\n\n1:14:09.240 --> 1:14:10.360\n that there is a problem there\n\n1:14:10.360 --> 1:14:12.280\n and that's such a fascinating space\n\n1:14:12.280 --> 1:14:13.160\n you're absolutely right\n\n1:14:13.160 --> 1:14:15.400\n but what is the first step\n\n1:14:15.400 --> 1:14:16.520\n that a company should take\n\n1:14:16.520 --> 1:14:18.200\n it's just scary leap\n\n1:14:18.200 --> 1:14:19.480\n into this new world of\n\n1:14:20.120 --> 1:14:21.720\n going from the human eye\n\n1:14:21.720 --> 1:14:24.680\n inspecting to digitizing that process\n\n1:14:24.680 --> 1:14:25.640\n having a camera\n\n1:14:25.640 --> 1:14:26.680\n having an algorithm\n\n1:14:27.240 --> 1:14:28.200\n what's the first step\n\n1:14:28.200 --> 1:14:30.040\n like what's the early journey\n\n1:14:30.040 --> 1:14:31.080\n that you recommend\n\n1:14:31.080 --> 1:14:32.840\n that you see these companies taking\n\n1:14:33.400 --> 1:14:34.520\n I published a document\n\n1:14:34.520 --> 1:14:37.000\n called the AI Transformation Playbook\n\n1:14:37.000 --> 1:14:37.720\n that's online\n\n1:14:37.720 --> 1:14:39.800\n and taught briefly in the AI for Everyone\n\n1:14:39.800 --> 1:14:41.000\n course on Coursera\n\n1:14:41.000 --> 1:14:42.760\n about the long term journey\n\n1:14:42.760 --> 1:14:44.120\n that companies should take\n\n1:14:44.120 --> 1:14:45.000\n but the first step\n\n1:14:45.000 --> 1:14:46.920\n is actually to start small\n\n1:14:46.920 --> 1:14:48.840\n I've seen a lot more companies fail\n\n1:14:48.840 --> 1:14:50.280\n by starting too big\n\n1:14:50.280 --> 1:14:51.800\n than by starting too small\n\n1:14:52.680 --> 1:14:54.120\n take even Google\n\n1:14:54.120 --> 1:14:55.640\n you know most people don't realize\n\n1:14:55.640 --> 1:14:56.920\n how hard it was\n\n1:14:56.920 --> 1:14:58.440\n and how controversial it was\n\n1:14:58.440 --> 1:14:59.960\n in the early days\n\n1:14:59.960 --> 1:15:01.320\n so when I started Google Brain\n\n1:15:02.360 --> 1:15:03.560\n it was controversial\n\n1:15:03.560 --> 1:15:04.680\n you know people thought\n\n1:15:04.680 --> 1:15:06.280\n deep learning near nest\n\n1:15:06.280 --> 1:15:07.320\n tried it didn't work\n\n1:15:07.320 --> 1:15:09.240\n why would you want to do deep learning\n\n1:15:09.240 --> 1:15:11.560\n so my first internal customer\n\n1:15:11.560 --> 1:15:12.360\n within Google\n\n1:15:12.360 --> 1:15:13.960\n was the Google speech team\n\n1:15:13.960 --> 1:15:15.560\n which is not the most lucrative\n\n1:15:15.560 --> 1:15:16.360\n project in Google\n\n1:15:17.160 --> 1:15:18.280\n not the most important\n\n1:15:18.280 --> 1:15:20.040\n it's not web search or advertising\n\n1:15:20.600 --> 1:15:21.880\n but by starting small\n\n1:15:22.840 --> 1:15:25.800\n my team helped the speech team\n\n1:15:25.800 --> 1:15:28.280\n build a more accurate speech recognition system\n\n1:15:28.280 --> 1:15:30.120\n and this caused their peers\n\n1:15:30.120 --> 1:15:31.080\n other teams to start\n\n1:15:31.080 --> 1:15:32.920\n to have more faith in deep learning\n\n1:15:32.920 --> 1:15:34.360\n my second internal customer\n\n1:15:34.360 --> 1:15:36.360\n was the Google Maps team\n\n1:15:36.360 --> 1:15:37.880\n where we used computer vision\n\n1:15:37.880 --> 1:15:38.920\n to read house numbers\n\n1:15:39.560 --> 1:15:41.000\n from basic street view images\n\n1:15:41.000 --> 1:15:42.600\n to more accurately locate houses\n\n1:15:42.600 --> 1:15:43.560\n within Google Maps\n\n1:15:43.560 --> 1:15:45.240\n so improve the quality of geodata\n\n1:15:45.800 --> 1:15:48.200\n and it was only after those two successes\n\n1:15:48.200 --> 1:15:49.240\n that I then started\n\n1:15:49.240 --> 1:15:50.440\n a more serious conversation\n\n1:15:50.440 --> 1:15:51.720\n with the Google Ads team\n\n1:15:52.600 --> 1:15:54.120\n and so there's a ripple effect\n\n1:15:54.120 --> 1:15:55.480\n that you showed that it works\n\n1:15:55.480 --> 1:15:56.680\n in these cases\n\n1:15:56.680 --> 1:15:58.120\n and then it just propagates\n\n1:15:58.120 --> 1:15:59.080\n through the entire company\n\n1:15:59.080 --> 1:16:01.400\n that this thing has a lot of value\n\n1:16:01.400 --> 1:16:02.120\n and use for us\n\n1:16:02.760 --> 1:16:05.160\n I think the early small scale projects\n\n1:16:05.160 --> 1:16:07.160\n it helps the teams gain faith\n\n1:16:07.160 --> 1:16:09.160\n but also helps the teams learn\n\n1:16:09.160 --> 1:16:10.840\n what these technologies do\n\n1:16:11.480 --> 1:16:14.360\n I still remember when our first GPU server\n\n1:16:14.360 --> 1:16:16.840\n it was a server under some guy's desk\n\n1:16:16.840 --> 1:16:19.240\n and you know and then that taught us\n\n1:16:19.240 --> 1:16:21.080\n early important lessons about\n\n1:16:21.080 --> 1:16:23.480\n how do you have multiple users\n\n1:16:23.480 --> 1:16:25.000\n share a set of GPUs\n\n1:16:25.000 --> 1:16:26.920\n which is really not obvious at the time\n\n1:16:26.920 --> 1:16:29.240\n but those early lessons were important\n\n1:16:29.240 --> 1:16:31.880\n we learned a lot from that first GPU server\n\n1:16:31.880 --> 1:16:33.880\n that later helped the teams think through\n\n1:16:33.880 --> 1:16:34.840\n how to scale it up\n\n1:16:34.840 --> 1:16:36.520\n to much larger deployments\n\n1:16:37.320 --> 1:16:38.840\n Are there concrete challenges\n\n1:16:38.840 --> 1:16:40.120\n that companies face\n\n1:16:40.120 --> 1:16:42.760\n that you see is important for them to solve?\n\n1:16:43.800 --> 1:16:45.080\n I think building and deploying\n\n1:16:45.080 --> 1:16:47.080\n machine learning systems is hard\n\n1:16:47.080 --> 1:16:48.760\n there's a huge gulf between\n\n1:16:48.760 --> 1:16:49.560\n something that works\n\n1:16:49.560 --> 1:16:51.560\n in a jupyter notebook on your laptop\n\n1:16:51.560 --> 1:16:52.840\n versus something that runs\n\n1:16:52.840 --> 1:16:54.440\n their production deployment setting\n\n1:16:54.440 --> 1:16:57.480\n in a factory or agriculture plant or whatever\n\n1:16:58.200 --> 1:16:59.720\n so I see a lot of people\n\n1:16:59.720 --> 1:17:01.000\n get something to work on your laptop\n\n1:17:01.000 --> 1:17:02.120\n and say wow look what I've done\n\n1:17:02.120 --> 1:17:03.800\n and that's great that's hard\n\n1:17:03.800 --> 1:17:05.640\n that's a very important first step\n\n1:17:05.640 --> 1:17:07.160\n but a lot of teams underestimate\n\n1:17:07.160 --> 1:17:08.600\n the rest of the steps needed\n\n1:17:09.480 --> 1:17:10.280\n so for example\n\n1:17:10.280 --> 1:17:12.360\n I've heard this exact same conversation\n\n1:17:12.360 --> 1:17:13.880\n between a lot of machine learning people\n\n1:17:13.880 --> 1:17:15.000\n and business people\n\n1:17:15.000 --> 1:17:16.360\n the machine learning person says\n\n1:17:16.920 --> 1:17:20.760\n look my algorithm does well on the test set\n\n1:17:20.760 --> 1:17:22.440\n and it's a clean test set at the end of peak\n\n1:17:22.440 --> 1:17:24.360\n and the machine and the business person says\n\n1:17:24.360 --> 1:17:25.560\n thank you very much\n\n1:17:25.560 --> 1:17:27.880\n but your algorithm sucks it doesn't work\n\n1:17:28.440 --> 1:17:29.960\n and the machine learning person says\n\n1:17:29.960 --> 1:17:32.680\n no wait I did well on the test set\n\n1:17:33.720 --> 1:17:36.680\n and I think there is a gulf between\n\n1:17:36.680 --> 1:17:38.760\n what it takes to do well on the test set\n\n1:17:38.760 --> 1:17:39.720\n on your hard drive\n\n1:17:39.720 --> 1:17:41.560\n versus what it takes to work well\n\n1:17:41.560 --> 1:17:43.240\n in a deployment setting\n\n1:17:43.240 --> 1:17:44.520\n some common problems\n\n1:17:45.560 --> 1:17:47.240\n robustness and generalization\n\n1:17:47.240 --> 1:17:49.640\n you deploy something in the factory\n\n1:17:49.640 --> 1:17:51.640\n maybe they chop down a tree outside the factory\n\n1:17:51.640 --> 1:17:54.280\n so the tree no longer covers the window\n\n1:17:54.280 --> 1:17:55.320\n and the lighting is different\n\n1:17:55.320 --> 1:17:56.760\n so the test set changes\n\n1:17:56.760 --> 1:17:58.360\n and in machine learning\n\n1:17:58.360 --> 1:17:59.640\n and especially in academia\n\n1:18:00.360 --> 1:18:02.840\n we don't know how to deal with test set distributions\n\n1:18:02.840 --> 1:18:04.360\n that are dramatically different\n\n1:18:04.360 --> 1:18:06.280\n than the training set distribution\n\n1:18:06.280 --> 1:18:07.560\n you know that this research\n\n1:18:07.560 --> 1:18:09.400\n the stuff like domain annotation\n\n1:18:10.200 --> 1:18:11.000\n transfer learning\n\n1:18:11.000 --> 1:18:12.680\n you know there are people working on it\n\n1:18:12.680 --> 1:18:14.440\n but we're really not good at this\n\n1:18:14.440 --> 1:18:17.000\n so how do you actually get this to work\n\n1:18:17.000 --> 1:18:18.360\n because your test set distribution\n\n1:18:18.360 --> 1:18:19.320\n is going to change\n\n1:18:19.320 --> 1:18:23.240\n and I think also if you look at the number of lines of code\n\n1:18:23.240 --> 1:18:24.760\n in the software system\n\n1:18:24.760 --> 1:18:27.960\n the machine learning model is maybe five percent\n\n1:18:27.960 --> 1:18:28.760\n or even fewer\n\n1:18:29.800 --> 1:18:31.960\n relative to the entire software system\n\n1:18:31.960 --> 1:18:33.000\n you need to build\n\n1:18:33.000 --> 1:18:34.760\n so how do you get all that work done\n\n1:18:34.760 --> 1:18:36.520\n and make it reliable and systematic\n\n1:18:36.520 --> 1:18:38.360\n so good software engineering work\n\n1:18:38.360 --> 1:18:39.400\n is fundamental here\n\n1:18:40.200 --> 1:18:43.560\n to building a successful small machine learning system\n\n1:18:44.120 --> 1:18:46.040\n yes and the software system\n\n1:18:46.040 --> 1:18:48.360\n needs to interface with the machine learning system\n\n1:18:48.360 --> 1:18:50.600\n needs to interface with people's workloads\n\n1:18:50.600 --> 1:18:53.960\n so machine learning is automation on steroids\n\n1:18:53.960 --> 1:18:56.280\n if we take one task out of many tasks\n\n1:18:56.280 --> 1:18:57.080\n that are done in the factory\n\n1:18:57.080 --> 1:18:58.760\n so the factory does lots of things\n\n1:18:58.760 --> 1:19:00.680\n one task is vision inspection\n\n1:19:00.680 --> 1:19:02.360\n if we automate that one task\n\n1:19:02.360 --> 1:19:03.800\n it can be really valuable\n\n1:19:03.800 --> 1:19:06.040\n but you may need to redesign a lot of other tasks\n\n1:19:06.040 --> 1:19:07.240\n around that one task\n\n1:19:07.240 --> 1:19:09.720\n for example say the machine learning algorithm\n\n1:19:09.720 --> 1:19:10.920\n says this is defective\n\n1:19:10.920 --> 1:19:11.720\n what are you supposed to do\n\n1:19:11.720 --> 1:19:12.520\n do you throw it away\n\n1:19:12.520 --> 1:19:14.040\n do you get a human to double check\n\n1:19:14.040 --> 1:19:16.120\n do you want to rework it or fix it\n\n1:19:16.120 --> 1:19:17.960\n so you need to redesign a lot of tasks\n\n1:19:17.960 --> 1:19:20.040\n around that thing you've now automated\n\n1:19:20.040 --> 1:19:22.600\n so planning for the change management\n\n1:19:22.600 --> 1:19:24.840\n and making sure that the software you write\n\n1:19:24.840 --> 1:19:26.680\n is consistent with the new workflow\n\n1:19:26.680 --> 1:19:28.200\n and you take the time to explain to people\n\n1:19:28.200 --> 1:19:29.000\n what needs to happen\n\n1:19:29.000 --> 1:19:33.480\n so I think what landing AI has become good at\n\n1:19:34.360 --> 1:19:36.520\n and then I think we learned by making the steps\n\n1:19:36.520 --> 1:19:38.280\n and you know painful experiences\n\n1:19:38.280 --> 1:19:41.080\n well my what would become good at is\n\n1:19:41.720 --> 1:19:43.800\n working with our partners to think through\n\n1:19:43.800 --> 1:19:46.440\n all the things beyond just the machine learning model\n\n1:19:46.440 --> 1:19:47.560\n or running the jupyter notebook\n\n1:19:47.560 --> 1:19:50.200\n but to build the entire system\n\n1:19:50.200 --> 1:19:51.720\n manage the change process\n\n1:19:51.720 --> 1:19:53.160\n and figure out how to deploy this in a way\n\n1:19:53.160 --> 1:19:54.680\n that has an actual impact\n\n1:19:55.480 --> 1:19:58.120\n the processes that the large software tech companies\n\n1:19:58.120 --> 1:19:59.880\n use for deploying don't work\n\n1:19:59.880 --> 1:20:01.480\n for a lot of other scenarios\n\n1:20:01.480 --> 1:20:04.920\n for example when I was leading large speech teams\n\n1:20:05.720 --> 1:20:07.800\n if the speech recognition system goes down\n\n1:20:07.800 --> 1:20:09.560\n what happens well alarms goes off\n\n1:20:09.560 --> 1:20:11.400\n and then someone like me would say hey\n\n1:20:11.400 --> 1:20:12.840\n you 20 engine environment\n\n1:20:12.840 --> 1:20:14.840\n you 20 engineers please fix this\n\n1:20:16.600 --> 1:20:19.240\n but if you have a system girl in the factory\n\n1:20:19.240 --> 1:20:21.320\n there are not 20 machine learning engineers\n\n1:20:21.320 --> 1:20:22.920\n sitting around you can page your duty\n\n1:20:22.920 --> 1:20:23.800\n and have them fix it\n\n1:20:23.800 --> 1:20:26.200\n so how do you deal with the maintenance\n\n1:20:26.200 --> 1:20:28.280\n or the or the dev ops or the mo ops\n\n1:20:28.280 --> 1:20:29.720\n or the other aspects of this\n\n1:20:30.280 --> 1:20:33.960\n so these are concepts that I think landing AI\n\n1:20:33.960 --> 1:20:36.360\n and a few other teams on the cutting edge\n\n1:20:36.360 --> 1:20:39.480\n but we don't even have systematic terminology yet\n\n1:20:39.480 --> 1:20:40.920\n to describe some of the stuff we do\n\n1:20:40.920 --> 1:20:43.000\n because I think we're inventing it on the fly.\n\n1:20:44.680 --> 1:20:46.600\n So you mentioned some people are interested\n\n1:20:46.600 --> 1:20:48.360\n in discovering mathematical beauty\n\n1:20:48.360 --> 1:20:49.560\n and truth in the universe\n\n1:20:49.560 --> 1:20:50.920\n and you're interested in having\n\n1:20:51.640 --> 1:20:54.200\n a big positive impact in the world\n\n1:20:54.920 --> 1:20:57.240\n so let me ask the two are not inconsistent\n\n1:20:57.240 --> 1:20:58.200\n no they're all together\n\n1:20:58.760 --> 1:21:00.840\n I'm only half joking\n\n1:21:00.840 --> 1:21:02.920\n because you're probably interested a little bit in both\n\n1:21:03.480 --> 1:21:06.040\n but let me ask a romanticized question\n\n1:21:06.040 --> 1:21:07.320\n so much of the work\n\n1:21:08.040 --> 1:21:09.480\n your work and our discussion today\n\n1:21:09.480 --> 1:21:11.000\n has been on applied AI\n\n1:21:11.960 --> 1:21:13.880\n maybe you can even call narrow AI\n\n1:21:14.440 --> 1:21:15.720\n where the goal is to create systems\n\n1:21:15.720 --> 1:21:17.400\n that automate some specific process\n\n1:21:17.400 --> 1:21:18.920\n that adds a lot of value to the world\n\n1:21:19.640 --> 1:21:21.240\n but there's another branch of AI\n\n1:21:21.240 --> 1:21:22.760\n starting with Alan Turing\n\n1:21:22.760 --> 1:21:25.560\n that kind of dreams of creating human level\n\n1:21:25.560 --> 1:21:27.160\n or superhuman level intelligence\n\n1:21:28.360 --> 1:21:30.360\n is this something you dream of as well\n\n1:21:30.360 --> 1:21:32.120\n do you think we human beings\n\n1:21:32.120 --> 1:21:34.440\n will ever build a human level intelligence\n\n1:21:34.440 --> 1:21:36.440\n or superhuman level intelligence system?\n\n1:21:37.160 --> 1:21:38.680\n I would love to get to AGI\n\n1:21:38.680 --> 1:21:40.280\n and I think humanity will\n\n1:21:40.840 --> 1:21:42.600\n but whether it takes 100 years\n\n1:21:42.600 --> 1:21:45.000\n or 500 or 5000\n\n1:21:45.000 --> 1:21:46.680\n I find hard to estimate\n\n1:21:47.960 --> 1:21:48.440\n do you have\n\n1:21:49.880 --> 1:21:51.640\n some folks have worries\n\n1:21:51.640 --> 1:21:53.160\n about the different trajectories\n\n1:21:53.160 --> 1:21:54.360\n that path would take\n\n1:21:54.360 --> 1:21:57.400\n even existential threats of an AGI system\n\n1:21:57.400 --> 1:21:58.760\n do you have such concerns\n\n1:21:59.560 --> 1:22:01.320\n whether in the short term or the long term?\n\n1:22:02.200 --> 1:22:05.880\n I do worry about the long term fate of humanity\n\n1:22:05.880 --> 1:22:08.280\n I do wonder as well\n\n1:22:08.280 --> 1:22:11.320\n I do worry about overpopulation on the planet Mars\n\n1:22:12.280 --> 1:22:13.400\n just not today\n\n1:22:13.400 --> 1:22:14.600\n I think there will be a day\n\n1:22:15.160 --> 1:22:17.080\n when maybe someday in the future\n\n1:22:17.640 --> 1:22:19.160\n Mars will be polluted\n\n1:22:19.160 --> 1:22:20.680\n there are all these children dying\n\n1:22:20.680 --> 1:22:22.040\n and someone will look back at this video\n\n1:22:22.040 --> 1:22:24.040\n and say Andrew how is Andrew so heartless?\n\n1:22:24.040 --> 1:22:25.640\n He didn't care about all these children\n\n1:22:25.640 --> 1:22:27.080\n dying on the planet Mars\n\n1:22:27.080 --> 1:22:29.400\n and I apologize to the future viewer\n\n1:22:29.400 --> 1:22:31.000\n I do care about the children\n\n1:22:31.000 --> 1:22:32.200\n but I just don't know how to\n\n1:22:32.200 --> 1:22:33.720\n productively work on that today\n\n1:22:33.720 --> 1:22:35.960\n your picture will be in the dictionary\n\n1:22:35.960 --> 1:22:37.240\n for the people who are ignorant\n\n1:22:37.240 --> 1:22:39.080\n about the overpopulation on Mars\n\n1:22:39.800 --> 1:22:42.440\n yes so it's a long term problem\n\n1:22:42.440 --> 1:22:43.960\n is there something in the short term\n\n1:22:43.960 --> 1:22:45.160\n we should be thinking about\n\n1:22:45.720 --> 1:22:48.520\n in terms of aligning the values of our AI systems\n\n1:22:48.520 --> 1:22:51.560\n with the values of us humans\n\n1:22:52.440 --> 1:22:54.520\n sort of something that Stuart Russell\n\n1:22:54.520 --> 1:22:56.200\n and other folks are thinking about\n\n1:22:56.200 --> 1:22:58.600\n as this system develops more and more\n\n1:22:58.600 --> 1:23:01.400\n we want to make sure that it represents\n\n1:23:01.400 --> 1:23:03.720\n the better angels of our nature\n\n1:23:03.720 --> 1:23:06.760\n the ethics the values of our society\n\n1:23:07.800 --> 1:23:10.040\n you know if you take self driving cars\n\n1:23:11.080 --> 1:23:12.600\n the biggest problem with self driving cars\n\n1:23:12.600 --> 1:23:16.040\n is not that there's some trolley dilemma\n\n1:23:16.040 --> 1:23:17.640\n and you teach this so you know\n\n1:23:17.640 --> 1:23:20.040\n how many times when you are driving your car\n\n1:23:20.040 --> 1:23:21.800\n did you face this moral dilemma\n\n1:23:21.800 --> 1:23:24.120\n who do I crash into?\n\n1:23:24.120 --> 1:23:25.320\n so I think self driving cars\n\n1:23:25.320 --> 1:23:27.640\n will run into that problem roughly as often\n\n1:23:27.640 --> 1:23:29.240\n as we do when we drive our cars\n\n1:23:29.240 --> 1:23:30.920\n the biggest problem with self driving cars\n\n1:23:30.920 --> 1:23:33.160\n is when there's a big white truck across the road\n\n1:23:33.160 --> 1:23:34.360\n and what you should do is break\n\n1:23:34.360 --> 1:23:35.560\n and not crash into it\n\n1:23:35.560 --> 1:23:37.560\n and the self driving car fails\n\n1:23:37.560 --> 1:23:38.520\n and it crashes into it\n\n1:23:38.520 --> 1:23:40.600\n so I think we need to solve that problem first\n\n1:23:40.600 --> 1:23:42.920\n I think the problem with some of these discussions\n\n1:23:42.920 --> 1:23:47.080\n about AGI you know alignments\n\n1:23:47.080 --> 1:23:48.440\n the paperclip problem\n\n1:23:49.480 --> 1:23:51.720\n is that is a huge distraction\n\n1:23:51.720 --> 1:23:53.560\n from the much harder problems\n\n1:23:53.560 --> 1:23:56.120\n that we actually need to address today\n\n1:23:56.120 --> 1:23:57.640\n it's not the hardest problems\n\n1:23:57.640 --> 1:23:59.320\n we need to address today\n\n1:23:59.320 --> 1:24:00.040\n it's not the hard problems\n\n1:24:00.040 --> 1:24:01.000\n we need to address today\n\n1:24:01.000 --> 1:24:04.120\n I think bias is a huge issue\n\n1:24:04.120 --> 1:24:06.120\n I worry about wealth and equality\n\n1:24:06.120 --> 1:24:09.000\n the AI and internet are causing\n\n1:24:09.000 --> 1:24:11.240\n an acceleration of concentration of power\n\n1:24:11.240 --> 1:24:13.640\n because we can now centralize data\n\n1:24:13.640 --> 1:24:14.760\n use AI to process it\n\n1:24:14.760 --> 1:24:16.280\n and so industry after industry\n\n1:24:16.280 --> 1:24:18.040\n we've affected every industry\n\n1:24:18.040 --> 1:24:20.040\n so the internet industry has a lot of\n\n1:24:20.040 --> 1:24:20.760\n win and take most\n\n1:24:20.760 --> 1:24:22.520\n or win and take all dynamics\n\n1:24:22.520 --> 1:24:24.760\n but we've infected all these other industries\n\n1:24:24.760 --> 1:24:26.600\n so we're also giving these other industries\n\n1:24:26.600 --> 1:24:28.600\n most of them to take all flavors\n\n1:24:28.600 --> 1:24:30.920\n so look at what Uber and Lyft\n\n1:24:30.920 --> 1:24:32.440\n did to the taxi industry\n\n1:24:32.440 --> 1:24:33.560\n so we're doing this type of thing\n\n1:24:33.560 --> 1:24:34.920\n it's a lot and so this\n\n1:24:34.920 --> 1:24:36.360\n so we're creating tremendous wealth\n\n1:24:36.360 --> 1:24:37.720\n but how do we make sure that the wealth\n\n1:24:37.720 --> 1:24:38.600\n is fairly shared\n\n1:24:39.800 --> 1:24:43.080\n I think that and then how do we help\n\n1:24:43.080 --> 1:24:44.760\n people whose jobs are displaced\n\n1:24:44.760 --> 1:24:46.920\n you know I think education is part of it\n\n1:24:46.920 --> 1:24:48.360\n there may be even more\n\n1:24:48.360 --> 1:24:50.200\n that we need to do than education\n\n1:24:52.040 --> 1:24:54.200\n I think bias is a serious issue\n\n1:24:54.200 --> 1:24:56.520\n there are adverse uses of AI\n\n1:24:56.520 --> 1:24:57.960\n like deepfakes being used\n\n1:24:57.960 --> 1:24:59.400\n for various and various purposes\n\n1:24:59.880 --> 1:25:03.960\n so I worry about some teams\n\n1:25:04.440 --> 1:25:05.480\n maybe accidentally\n\n1:25:05.480 --> 1:25:07.240\n and I hope not deliberately\n\n1:25:07.240 --> 1:25:09.960\n making a lot of noise about things\n\n1:25:09.960 --> 1:25:11.960\n that problems in the distant future\n\n1:25:12.520 --> 1:25:13.880\n rather than focusing on\n\n1:25:13.880 --> 1:25:15.160\n some of the much harder problems\n\n1:25:15.160 --> 1:25:17.000\n yeah the overshadow of the problems\n\n1:25:17.000 --> 1:25:18.120\n that we have already today\n\n1:25:18.120 --> 1:25:19.560\n they're exceptionally challenging\n\n1:25:19.560 --> 1:25:20.520\n like those you said\n\n1:25:20.520 --> 1:25:21.960\n and even the silly ones\n\n1:25:21.960 --> 1:25:23.560\n but the ones that have a huge impact\n\n1:25:23.560 --> 1:25:24.520\n huge impact\n\n1:25:24.520 --> 1:25:25.960\n which is the lighting variation\n\n1:25:25.960 --> 1:25:27.400\n outside of your factory window\n\n1:25:27.960 --> 1:25:30.120\n that that ultimately is\n\n1:25:30.120 --> 1:25:31.320\n what makes the difference\n\n1:25:31.320 --> 1:25:32.120\n between like you said\n\n1:25:32.120 --> 1:25:33.160\n the Jupiter notebook\n\n1:25:33.160 --> 1:25:35.400\n and something that actually transforms\n\n1:25:35.400 --> 1:25:36.840\n an entire industry potentially\n\n1:25:37.400 --> 1:25:38.200\n yeah and I think\n\n1:25:38.200 --> 1:25:40.600\n and then just to some companies\n\n1:25:40.600 --> 1:25:42.600\n or a regulator comes to you\n\n1:25:42.600 --> 1:25:44.200\n and says look your product\n\n1:25:44.200 --> 1:25:45.240\n is messing things up\n\n1:25:45.880 --> 1:25:47.720\n fixing it may have a revenue impact\n\n1:25:47.720 --> 1:25:49.400\n well it's much more fun to talk to them\n\n1:25:49.400 --> 1:25:50.440\n about how you promise\n\n1:25:50.440 --> 1:25:51.960\n not to wipe out humanity\n\n1:25:51.960 --> 1:25:54.440\n and to face the actually really hard problems we face\n\n1:25:55.720 --> 1:25:57.480\n so your life has been a great journey\n\n1:25:57.480 --> 1:25:58.840\n from teaching to research\n\n1:25:58.840 --> 1:25:59.960\n to entrepreneurship\n\n1:26:00.680 --> 1:26:01.880\n two questions\n\n1:26:01.880 --> 1:26:04.040\n one are there regrets\n\n1:26:04.040 --> 1:26:05.560\n moments that if you went back\n\n1:26:05.560 --> 1:26:07.000\n you would do differently\n\n1:26:07.000 --> 1:26:08.920\n and two are there moments\n\n1:26:08.920 --> 1:26:10.120\n you're especially proud of\n\n1:26:10.680 --> 1:26:12.360\n moments that made you truly happy\n\n1:26:13.160 --> 1:26:15.320\n you know I've made so many mistakes\n\n1:26:17.080 --> 1:26:18.440\n it feels like every time\n\n1:26:18.440 --> 1:26:19.720\n I discover something\n\n1:26:19.720 --> 1:26:22.200\n I go why didn't I think of this\n\n1:26:23.080 --> 1:26:24.520\n you know five years earlier\n\n1:26:24.520 --> 1:26:25.640\n or even 10 years earlier\n\n1:26:27.240 --> 1:26:29.480\n and as recently\n\n1:26:29.480 --> 1:26:30.920\n and then sometimes I read a book\n\n1:26:30.920 --> 1:26:33.800\n and I go I wish I read this book 10 years ago\n\n1:26:33.800 --> 1:26:35.480\n my life would have been so different\n\n1:26:35.480 --> 1:26:36.600\n although that happened recently\n\n1:26:36.600 --> 1:26:37.800\n and then I was thinking\n\n1:26:37.800 --> 1:26:39.240\n if only I read this book\n\n1:26:39.240 --> 1:26:40.520\n when we're starting up Coursera\n\n1:26:40.520 --> 1:26:41.880\n I could have been so much better\n\n1:26:42.760 --> 1:26:43.640\n but I discovered the book\n\n1:26:43.640 --> 1:26:44.600\n had not yet been written\n\n1:26:44.600 --> 1:26:45.560\n we're starting Coursera\n\n1:26:45.560 --> 1:26:46.600\n so that made me feel better\n\n1:26:46.600 --> 1:26:48.280\n so that made me feel better\n\n1:26:49.400 --> 1:26:53.080\n but I find that the process of discovery\n\n1:26:53.080 --> 1:26:54.440\n we keep on finding out things\n\n1:26:54.440 --> 1:26:56.440\n that seem so obvious in hindsight\n\n1:26:57.480 --> 1:26:59.320\n but it always takes us so much longer\n\n1:26:59.320 --> 1:27:01.880\n than than I wish to to figure it out\n\n1:27:03.400 --> 1:27:04.600\n so on the second question\n\n1:27:06.280 --> 1:27:08.040\n are there moments in your life\n\n1:27:08.040 --> 1:27:09.960\n that if you look back\n\n1:27:09.960 --> 1:27:12.440\n that you're especially proud of\n\n1:27:12.440 --> 1:27:13.800\n or you're especially happy\n\n1:27:13.800 --> 1:27:17.480\n what would be the that filled you with happiness\n\n1:27:17.480 --> 1:27:18.440\n and fulfillment\n\n1:27:18.440 --> 1:27:20.280\n well two answers\n\n1:27:20.280 --> 1:27:21.800\n one does my daughter know of her\n\n1:27:21.800 --> 1:27:22.680\n yes of course\n\n1:27:22.680 --> 1:27:24.280\n because I know how much time I spent with her\n\n1:27:24.280 --> 1:27:25.720\n I just can't spend enough time with her\n\n1:27:25.720 --> 1:27:26.840\n congratulations by the way\n\n1:27:26.840 --> 1:27:27.800\n thank you\n\n1:27:27.800 --> 1:27:29.880\n and then second is helping other people\n\n1:27:29.880 --> 1:27:30.920\n I think to me\n\n1:27:30.920 --> 1:27:32.520\n I think the meaning of life\n\n1:27:32.520 --> 1:27:35.160\n is helping others achieve\n\n1:27:35.160 --> 1:27:36.360\n whatever are their dreams\n\n1:27:37.160 --> 1:27:40.440\n and then also to try to move the world forward\n\n1:27:40.440 --> 1:27:43.880\n making humanity more powerful as a whole\n\n1:27:43.880 --> 1:27:46.040\n so the times that I felt most happy\n\n1:27:46.040 --> 1:27:47.640\n most proud was when I felt\n\n1:27:49.000 --> 1:27:52.600\n someone else allowed me the good fortune\n\n1:27:52.600 --> 1:27:54.440\n of helping them a little bit\n\n1:27:54.440 --> 1:27:55.880\n on the path to their dreams\n\n1:27:57.160 --> 1:27:58.840\n I think there's no better way to end it\n\n1:27:58.840 --> 1:28:00.120\n than talking about happiness\n\n1:28:00.120 --> 1:28:01.080\n and the meaning of life\n\n1:28:01.080 --> 1:28:03.240\n so Andrew it's a huge honor\n\n1:28:03.240 --> 1:28:04.360\n me and millions of people\n\n1:28:04.360 --> 1:28:05.960\n thank you for all the work you've done\n\n1:28:05.960 --> 1:28:07.160\n thank you for talking today\n\n1:28:07.160 --> 1:28:07.960\n thank you so much thanks\n\n1:28:07.960 --> 1:28:10.760\n thanks for listening to this conversation with Andrew Ng\n\n1:28:10.760 --> 1:28:13.720\n and thank you to our presenting sponsor Cash App\n\n1:28:13.720 --> 1:28:16.440\n download it use code LEX podcast\n\n1:28:16.440 --> 1:28:17.720\n you'll get ten dollars\n\n1:28:17.720 --> 1:28:19.320\n and ten dollars will go to FIRST\n\n1:28:19.320 --> 1:28:22.360\n an organization that inspires and educates young minds\n\n1:28:22.360 --> 1:28:25.160\n to become science and technology innovators of tomorrow\n\n1:28:25.720 --> 1:28:27.160\n if you enjoy this podcast\n\n1:28:27.160 --> 1:28:28.600\n subscribe on YouTube\n\n1:28:28.600 --> 1:28:30.680\n give it five stars on Apple podcast\n\n1:28:30.680 --> 1:28:32.040\n support it on Patreon\n\n1:28:32.040 --> 1:28:34.040\n or simply connect with me on Twitter\n\n1:28:34.040 --> 1:28:35.240\n at LEX Freedman\n\n1:28:35.240 --> 1:28:38.440\n and now let me leave you with some words of wisdom from Andrew Ng\n\n1:28:39.320 --> 1:28:40.280\n ask yourself\n\n1:28:40.840 --> 1:28:44.360\n if what you're working on succeeds beyond your wildest dreams\n\n1:28:44.360 --> 1:28:46.840\n would you have significantly helped other people?\n\n1:28:47.880 --> 1:28:51.160\n if not then keep searching for something else to work on\n\n1:28:51.160 --> 1:28:54.440\n otherwise you're not living up to your full potential\n\n1:28:54.440 --> 1:29:04.840\n thank you for listening and hope to see you next time\n\n"
}
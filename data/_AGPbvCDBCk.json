{
  "title": "Eugenia Kuyda: Friendship with an AI Companion | Lex Fridman Podcast #121",
  "id": "_AGPbvCDBCk",
  "transcript": "WEBVTT\n\n00:00.000 --> 00:06.480\n The following is a conversation with Eugenia Kuida, cofounder of Replika, which is an app\n\n00:06.480 --> 00:11.720\n that allows you to make friends with an artificial intelligence system, a chatbot, that learns\n\n00:11.720 --> 00:18.720\n to connect with you on an emotional, you could even say a human level, by being a friend.\n\n00:18.720 --> 00:24.080\n For those of you who know my interest in AI and views on life in general, know that Replika\n\n00:24.080 --> 00:28.200\n and Eugenia's line of work is near and dear to my heart.\n\n00:28.200 --> 00:33.480\n The origin story of Replika is grounded in a personal tragedy of Eugenia losing her close\n\n00:33.480 --> 00:39.840\n friend Roman Muzarenki, who was killed crossing the street by a hit and run driver in late\n\n00:39.840 --> 00:40.840\n 2015.\n\n00:40.840 --> 00:43.160\n He was 34.\n\n00:43.160 --> 00:47.680\n The app started as a way to grieve the loss of a friend, by trading a chatbot and your\n\n00:47.680 --> 00:51.600\n old net on text messages between Eugenia and Roman.\n\n00:51.600 --> 00:55.920\n The rest is a beautiful human story, as we talk about with Eugenia.\n\n00:55.920 --> 01:00.920\n When a friend mentioned Eugenia's work to me, I knew I had to meet her and talk to her.\n\n01:00.920 --> 01:06.840\n I felt before, during, and after that this meeting would be an important one in my life.\n\n01:06.840 --> 01:07.840\n And it was.\n\n01:07.840 --> 01:12.920\n I think in ways that only time will truly show, to me and others.\n\n01:12.920 --> 01:15.720\n She is a kind and brilliant person.\n\n01:15.720 --> 01:19.160\n It was an honor and a pleasure to talk to her.\n\n01:19.160 --> 01:24.400\n Quick summary of the sponsors, DoorDash, Dollar Shave Club, and Cash App.\n\n01:24.400 --> 01:29.720\n Click the sponsor links in the description to get a discount and to support this podcast.\n\n01:29.720 --> 01:34.920\n As a side note, let me say that deep, meaningful connection between human beings and artificial\n\n01:34.920 --> 01:38.480\n intelligence systems is a lifelong passion for me.\n\n01:38.480 --> 01:43.080\n I'm not yet sure where that passion will take me, but I decided some time ago that\n\n01:43.080 --> 01:48.280\n I will follow it boldly and without fear, to as far as I can take it.\n\n01:48.280 --> 01:53.720\n With a bit of hard work and a bit of luck, I hope I'll succeed in helping build AI systems\n\n01:53.720 --> 01:59.200\n that have some positive impact on the world and on the lives of a few people out there.\n\n01:59.200 --> 02:06.600\n But also, it is entirely possible that I am in fact one of the chatbots that Eugenia and\n\n02:06.600 --> 02:08.720\n the Replica team have built.\n\n02:08.720 --> 02:13.320\n And this podcast is simply a training process for the neural net that's trying to learn\n\n02:13.320 --> 02:18.160\n to connect to human beings, one episode at a time.\n\n02:18.160 --> 02:24.320\n In any case, I wouldn't know if I was or wasn't, and if I did, I wouldn't tell you.\n\n02:24.320 --> 02:28.720\n If you enjoy this thing, subscribe on YouTube, review it with 5 Stars and Apple Podcast,\n\n02:28.720 --> 02:34.680\n follow on Spotify, support on Patreon, or connect with me on Twitter at Lex Friedman.\n\n02:34.680 --> 02:37.760\n As usual, I'll do a few minutes of ads now and no ads in the middle.\n\n02:37.760 --> 02:42.520\n I'll try to make these interesting, but give you timestamps so you can skip, but please\n\n02:42.520 --> 02:47.760\n do still check out the sponsors by clicking the links in the description to get a discount,\n\n02:47.760 --> 02:53.440\n buy whatever they're selling, it really is the best way to support this podcast.\n\n02:53.440 --> 02:56.240\n This show is sponsored by Dollar Shave Club.\n\n02:56.240 --> 03:01.600\n Try them out with a one time offer for only 5 bucks and free shipping at dollarshave.com\n\n03:01.600 --> 03:03.060\n slash lex.\n\n03:03.060 --> 03:08.180\n The starter kit comes with a 6 blade razor, refills, and all kinds of other stuff that\n\n03:08.180 --> 03:10.840\n makes shaving feel great.\n\n03:10.840 --> 03:15.680\n I've been a member of Dollar Shave Club for over 5 years, and actually signed up when\n\n03:15.680 --> 03:19.520\n I first heard about them on the Joe Rogan Experience podcast.\n\n03:19.520 --> 03:22.960\n And now, friends, we have come full circle.\n\n03:22.960 --> 03:26.920\n It feels like I made it, now that I can do a read for them just like Joe did all those\n\n03:26.920 --> 03:35.320\n years ago, back when he also did ads for some less reputable companies, let's say, that\n\n03:35.320 --> 03:39.920\n you know about if you're a true fan of the old school podcasting world.\n\n03:39.920 --> 03:44.580\n Anyway, I just used the razor and the refills, but they told me I should really try out the\n\n03:44.580 --> 03:45.580\n shave butter.\n\n03:45.580 --> 03:46.580\n I did.\n\n03:46.580 --> 03:47.580\n I love it.\n\n03:47.580 --> 03:51.720\n It's translucent somehow, which is a cool new experience.\n\n03:51.720 --> 03:56.760\n Again, try the Ultimate Shave Starter set today for just 5 bucks plus free shipping\n\n03:56.760 --> 04:00.800\n at dollarshaveclub.com slash lex.\n\n04:00.800 --> 04:03.560\n This show is also sponsored by DoorDash.\n\n04:03.560 --> 04:08.860\n Get $5 off and zero delivery fees on your first order of 15 bucks or more when you download\n\n04:08.860 --> 04:13.920\n the DoorDash app and enter code, you guessed it, LEX.\n\n04:13.920 --> 04:18.760\n I have so many memories of working late nights for a deadline with a team of engineers, whether\n\n04:18.760 --> 04:24.440\n that's for my PhD at Google or MIT, and eventually taking a break to argue about which\n\n04:24.440 --> 04:26.900\n DoorDash restaurant to order from.\n\n04:26.900 --> 04:32.340\n And when the food came, those moments of bonding, of exchanging ideas, of pausing to shift attention\n\n04:32.340 --> 04:36.320\n from the programs to humans were special.\n\n04:36.320 --> 04:41.520\n For a bit of time, I'm on my own now, so I miss that camaraderie, but actually, I still\n\n04:41.520 --> 04:43.360\n use DoorDash a lot.\n\n04:43.360 --> 04:46.680\n There's a million options that fit into my crazy keto diet ways.\n\n04:46.680 --> 04:51.240\n Also, it's a great way to support restaurants in these challenging times.\n\n04:51.240 --> 04:56.120\n Once again, download the DoorDash app and enter code LEX to get 5 bucks off and zero\n\n04:56.120 --> 04:59.640\n delivery fees on your first order of 15 dollars or more.\n\n04:59.640 --> 05:04.600\n Finally, this show is presented by Cash App, the number one finance app in the App Store.\n\n05:04.600 --> 05:09.800\n I can truly say that they're an amazing company, one of the first sponsors, if not the first\n\n05:09.800 --> 05:16.000\n sponsor to truly believe in me, and I think quite possibly the reason I'm still doing\n\n05:16.000 --> 05:17.000\n this podcast.\n\n05:17.000 --> 05:20.320\n So I am forever grateful to Cash App.\n\n05:20.320 --> 05:21.320\n So thank you.\n\n05:21.320 --> 05:27.560\n And as I said many times before, use code LEXBODCAST when you download the app from\n\n05:27.560 --> 05:29.840\n Google Play or the App Store.\n\n05:29.840 --> 05:34.160\n Cash App lets you send money to friends, buy Bitcoin, and invest in the stock market with\n\n05:34.160 --> 05:36.600\n as little as one dollar.\n\n05:36.600 --> 05:40.560\n I usually say other stuff here in the read, but I wasted all that time up front saying\n\n05:40.560 --> 05:42.440\n how grateful I am to Cash App.\n\n05:42.440 --> 05:47.280\n I'm going to try to go off the top of my head a little bit more for these reads because\n\n05:47.280 --> 05:52.120\n I'm actually very lucky to be able to choose the sponsors that we take on, and that means\n\n05:52.120 --> 05:56.360\n I can really only take on the sponsors that I truly love, and then I can just talk about\n\n05:56.360 --> 05:57.580\n why I love them.\n\n05:57.580 --> 05:59.120\n So it's pretty simple.\n\n05:59.120 --> 06:04.080\n Again, get Cash App from the App Store or Google Play, use code LEXBODCAST, get 10\n\n06:04.080 --> 06:08.560\n bucks, and Cash App will also donate 10 bucks to FIRST, an organization that is helping\n\n06:08.560 --> 06:13.680\n to advance robotics and STEM education for young people around the world.\n\n06:13.680 --> 06:17.640\n And now, here's my conversation with Eugenia Kuida.\n\n06:17.640 --> 06:23.600\n Okay, before we talk about AI and the amazing work you're doing, let me ask you ridiculously,\n\n06:23.600 --> 06:28.760\n we're both Russian, so let me ask a ridiculously romanticized Russian question.\n\n06:28.760 --> 06:37.360\n Do you think human beings are alone, like fundamentally, on a philosophical level?\n\n06:37.360 --> 06:46.960\n Like in our existence, when we like go through life, do you think just the nature of our\n\n06:46.960 --> 06:49.480\n life is loneliness?\n\n06:49.480 --> 06:55.000\n Yeah, so we have to read Dostoevsky at school, as you probably know, so...\n\n06:55.000 --> 06:56.000\n In Russian?\n\n06:56.000 --> 06:59.960\n I mean, it's part of your school program.\n\n06:59.960 --> 07:03.520\n So I guess if you read that, then you sort of have to believe that.\n\n07:03.520 --> 07:08.000\n You're made to believe that you're fundamentally alone, and that's how you live your life.\n\n07:08.000 --> 07:09.000\n How do you think about it?\n\n07:09.000 --> 07:15.100\n You have a lot of friends, but at the end of the day, do you have like a longing for\n\n07:15.100 --> 07:17.360\n connection with other people?\n\n07:17.360 --> 07:20.240\n That's maybe another way of asking it.\n\n07:20.240 --> 07:23.620\n Do you think that's ever fully satisfied?\n\n07:23.620 --> 07:25.200\n I think we are fundamentally alone.\n\n07:25.200 --> 07:32.120\n We're born alone, we die alone, but I view my whole life as trying to get away from that,\n\n07:32.120 --> 07:38.720\n trying to not feel lonely, and again, we're talking about a subjective way of feeling\n\n07:38.720 --> 07:39.720\n alone.\n\n07:39.720 --> 07:45.000\n It doesn't necessarily mean that you don't have any connections or you are actually isolated.\n\n07:45.000 --> 07:52.280\n You think it's a subjective thing, but like again, another absurd measurement wise thing,\n\n07:52.280 --> 07:55.160\n how much loneliness do you think there is in the world?\n\n07:55.160 --> 08:05.080\n Like if you see loneliness as a condition, how much of it is there, do you think?\n\n08:05.080 --> 08:11.000\n Like how, I guess how many, you know, there's all kinds of studies and measures of how many\n\n08:11.000 --> 08:12.840\n people in the world feel alone.\n\n08:12.840 --> 08:18.240\n There's all these like measures of how many people are, you know, self report or just\n\n08:18.240 --> 08:24.600\n all these kinds of different measures, but in your own perspective, how big of a problem\n\n08:24.600 --> 08:27.640\n do you think it is size wise?\n\n08:27.640 --> 08:30.040\n I'm actually fascinated by the topic of loneliness.\n\n08:30.040 --> 08:34.640\n I try to read about it as much as I can.\n\n08:34.640 --> 08:39.900\n What really, and I think there's a paradox because loneliness is not a clinical disorder.\n\n08:39.900 --> 08:44.200\n It's not something that you can get your insurance to pay for if you're struggling with that.\n\n08:44.200 --> 08:50.200\n Yet it's actually proven and pretty, you know, tons of papers, tons of research around that.\n\n08:50.200 --> 08:58.080\n It is proven that it's correlated with earlier life expectancy, shorter lifespan.\n\n08:58.080 --> 09:02.200\n And it is, you know, in a way like right now, what scientists would say that it, you know,\n\n09:02.200 --> 09:07.560\n it's a little bit worse than being obese or not actually doing any physical activity in\n\n09:07.560 --> 09:08.560\n your life.\n\n09:08.560 --> 09:09.560\n In terms of the impact on your health?\n\n09:09.560 --> 09:10.720\n In terms of impact on your physiological health.\n\n09:10.720 --> 09:11.720\n Yeah.\n\n09:11.720 --> 09:16.840\n So it's basically puts you, if you're constantly feeling lonely, your body responds like it's\n\n09:16.840 --> 09:19.280\n basically all the time under stress.\n\n09:19.280 --> 09:24.720\n It's always in this alert state and so it's really bad for you because it actually like\n\n09:24.720 --> 09:29.960\n drops your immune system and get it, your response to inflammation is quite different.\n\n09:29.960 --> 09:34.940\n So all the cardiovascular diseases actually responds to viruses.\n\n09:34.940 --> 09:37.200\n So it's much easier to catch a virus.\n\n09:37.200 --> 09:42.880\n That's sad now that we're living in a pandemic and it's probably making us a lot more alone\n\n09:42.880 --> 09:47.720\n and it's probably weakening the immune system, making us more susceptible to the virus.\n\n09:47.720 --> 09:49.680\n It's kind of sad.\n\n09:49.680 --> 09:50.680\n Yeah.\n\n09:50.680 --> 09:54.760\n The statistics are pretty horrible around that.\n\n09:54.760 --> 09:59.400\n So around 30% of all millennials report that they're feeling lonely constantly.\n\n09:59.400 --> 10:00.400\n 30?\n\n10:00.400 --> 10:01.400\n 30%.\n\n10:01.400 --> 10:02.560\n And then it's much worse for Gen Z.\n\n10:02.560 --> 10:07.000\n And then 20% of millennials say that they feel lonely and they also don't have any close\n\n10:07.000 --> 10:08.000\n friends.\n\n10:08.000 --> 10:12.080\n And then I think 25 or so, and then 20% would say they don't even have acquaintances.\n\n10:12.080 --> 10:14.080\n And that's in the United States?\n\n10:14.080 --> 10:15.080\n That's in the United States.\n\n10:15.080 --> 10:17.800\n And I'm pretty sure that that's much worse everywhere else.\n\n10:17.800 --> 10:24.280\n Like in the UK, I mean, it was widely tweeted and posted when they were talking about a\n\n10:24.280 --> 10:28.400\n minister of loneliness that they wanted to appoint because four out of 10 people in the\n\n10:28.400 --> 10:29.400\n UK feel lonely.\n\n10:29.400 --> 10:30.400\n Minister of loneliness.\n\n10:30.400 --> 10:35.960\n I think that thing actually exists.\n\n10:35.960 --> 10:41.160\n So yeah, you will die sooner if you are lonely.\n\n10:41.160 --> 10:46.160\n And again, this is only when we're only talking about your perception of loneliness or feeling\n\n10:46.160 --> 10:47.160\n lonely.\n\n10:47.160 --> 10:50.840\n That is not objectively being fully socially isolated.\n\n10:50.840 --> 10:56.480\n However, the combination of being fully socially isolated and not having many connections and\n\n10:56.480 --> 11:00.800\n also feeling lonely, that's pretty much a deadly combination.\n\n11:00.800 --> 11:08.400\n So it strikes me bizarre or strange that this is a wide known fact and then there's really\n\n11:08.400 --> 11:12.120\n no one working really on that because it's like subclinical.\n\n11:12.120 --> 11:13.120\n It's not clinical.\n\n11:13.120 --> 11:17.440\n It's not something that you can, we'll tell your doctor and get a treatment or something.\n\n11:17.440 --> 11:18.800\n Yet it's killing us.\n\n11:18.800 --> 11:19.800\n Yeah.\n\n11:19.800 --> 11:24.440\n So there's a bunch of people trying to evaluate, like try to measure the problem by looking\n\n11:24.440 --> 11:28.200\n at like how social media is affecting loneliness and all that kind of stuff.\n\n11:28.200 --> 11:29.200\n So it's like measurement.\n\n11:29.200 --> 11:33.720\n Like if you look at the field of psychology, they're trying to measure the problem and\n\n11:33.720 --> 11:36.960\n not that many people actually, but some.\n\n11:36.960 --> 11:43.280\n But you're basically saying how many people are trying to solve the problem.\n\n11:43.280 --> 11:48.840\n Like how would you try to solve the problem of loneliness?\n\n11:48.840 --> 11:55.280\n Like if you just stick to humans, uh, I mean, or basically not just the humans, but the\n\n11:55.280 --> 11:57.720\n technology that connects us humans.\n\n11:57.720 --> 12:03.160\n Do you think there's a hope for that technology to do the connection?\n\n12:03.160 --> 12:05.720\n Like I, are you on social media much?\n\n12:05.720 --> 12:12.680\n Unfortunately, do you find yourself like, uh, again, if you sort of introspect about\n\n12:12.680 --> 12:16.960\n how connected you feel to other human beings, how not alone you feel, do you think social\n\n12:16.960 --> 12:23.960\n media makes it better or worse maybe for you personally, or in general, I think it's, it's\n\n12:23.960 --> 12:29.720\n easier to look at some stats and, um, I mean, Gen Z seems to be generation Z seems to be\n\n12:29.720 --> 12:33.440\n much lonelier than millennials in terms of how they report loneliness.\n\n12:33.440 --> 12:36.960\n They're definitely the most connected generation in the world.\n\n12:36.960 --> 12:42.600\n I mean, I still remember life without an iPhone, without Facebook, they don't know that that\n\n12:42.600 --> 12:47.560\n ever existed, uh, or at least don't know how it was.\n\n12:47.560 --> 12:53.900\n So that tells me a little bit about the fact that that might be, um, you know, this hyper\n\n12:53.900 --> 12:58.520\n connected world might actually make people feel lonely, lonelier.\n\n12:58.520 --> 13:02.520\n I don't know exactly what the, what the measurements are around that, but I would say, you know,\n\n13:02.520 --> 13:07.600\n my personal experience, I think it does make you feel a lot lonelier, mostly, yeah, we're\n\n13:07.600 --> 13:08.600\n all super connected.\n\n13:08.600 --> 13:13.720\n Uh, but I think loneliness, the feeling of loneliness doesn't come from not having any\n\n13:13.720 --> 13:15.040\n social connections whatsoever.\n\n13:15.040 --> 13:20.800\n Again, tons of people that are, are in longterm relationships experience bouts of loneliness\n\n13:20.800 --> 13:22.440\n and continued loneliness.\n\n13:22.440 --> 13:28.720\n Um, and it's more the question about the true connection about actually being deeply seen,\n\n13:28.720 --> 13:29.720\n deeply understood.\n\n13:29.720 --> 13:36.480\n Um, and in a way it's also about your relationship with yourself, like in order to not feel lonely,\n\n13:36.480 --> 13:42.160\n you actually need to have a better relationship and feel more connected to yourself than this\n\n13:42.160 --> 13:44.640\n feeling actually starts to go away a little bit.\n\n13:44.640 --> 13:51.120\n And then you, um, open up yourself to actually meeting other people in a very special way.\n\n13:51.120 --> 13:55.400\n Uh, not in just, you know, at a friend on Facebook kind of way.\n\n13:55.400 --> 14:00.040\n So just to briefly touch on it, I mean, do you think it's possible to form that kind\n\n14:00.040 --> 14:08.320\n of connection with AI systems more down the line of some of your work?\n\n14:08.320 --> 14:16.540\n Do you think that's, um, engineering wise, a possibility to alleviate loneliness is not\n\n14:16.540 --> 14:19.280\n with another human, but with an AI system?\n\n14:19.280 --> 14:23.240\n Well, I know that's, that's a fact, that's what we're doing.\n\n14:23.240 --> 14:29.360\n And we see it and we measure that and we see how people start to feel less lonely, um,\n\n14:29.360 --> 14:33.000\n talking to their virtual AI friend.\n\n14:33.000 --> 14:37.640\n So basically a chat bot at the basic level, but it could be more like, do you have, I'm\n\n14:37.640 --> 14:44.920\n not even speaking sort of, uh, about specifics, but do you have a hope, like if you look 50\n\n14:44.920 --> 14:51.640\n years from now, do you have a hope that there's just like AIs that are like optimized for,\n\n14:51.640 --> 14:56.160\n um, let me, let me first start like right now, the way people perceive AI, which is\n\n14:56.160 --> 15:04.360\n recommender systems for Facebook and Twitter, social media, they see AI is basically destroying\n\n15:04.360 --> 15:06.200\n first of all, the fabric of our civilization.\n\n15:06.200 --> 15:08.720\n But second of all, making us more lonely.\n\n15:08.720 --> 15:13.600\n Do you see like a world where it's possible to just have AI systems floating about that\n\n15:13.600 --> 15:18.080\n like make our life less lonely?\n\n15:18.080 --> 15:19.440\n Yeah.\n\n15:19.440 --> 15:20.440\n Make us happy.\n\n15:20.440 --> 15:26.000\n Like are putting good things into the world in terms of our individual lives.\n\n15:26.000 --> 15:27.000\n Yeah.\n\n15:27.000 --> 15:28.200\n Totally believe in that.\n\n15:28.200 --> 15:31.000\n That's why we're, I'm also working on that.\n\n15:31.000 --> 15:36.200\n Um, I think we need to also make sure that, um, what we're trying to optimize for, we're\n\n15:36.200 --> 15:40.240\n actually measuring and it is a North star metric that we're going after.\n\n15:40.240 --> 15:44.640\n And all of our product and all of our business models are optimized for that because you\n\n15:44.640 --> 15:48.560\n can talk, you know, a lot of products that talk about, um, you know, making you feel\n\n15:48.560 --> 15:50.760\n less lonely or making you feel more connected.\n\n15:50.760 --> 15:52.520\n They're not really measuring that.\n\n15:52.520 --> 15:56.600\n So they don't really know whether their users are actually feeling less lonely in the long\n\n15:56.600 --> 15:58.880\n run or feeling more connected in the long run.\n\n15:58.880 --> 16:02.480\n Um, so I think it's really important to put your measure it.\n\n16:02.480 --> 16:03.480\n Yeah.\n\n16:03.480 --> 16:04.480\n To measure it.\n\n16:04.480 --> 16:07.080\n What's a, what's a good measurement of loneliness?\n\n16:07.080 --> 16:10.900\n Well, so that's something that I'm really interested in.\n\n16:10.900 --> 16:14.920\n How do you measure that people are feeling better or that they're feeling less lonely\n\n16:14.920 --> 16:15.920\n with loneliness?\n\n16:15.920 --> 16:16.920\n There's a scale.\n\n16:16.920 --> 16:21.040\n There's UCLA 20 and UCLA three recently scale, which is basically a questionnaire that you\n\n16:21.040 --> 16:26.660\n fill out and you can see whether in the long run it's improving or not.\n\n16:26.660 --> 16:32.120\n And that, uh, does it capture the momentary feeling of loneliness?\n\n16:32.120 --> 16:35.600\n Does it look in like the past month?\n\n16:35.600 --> 16:38.240\n Like, uh, does it basically self report?\n\n16:38.240 --> 16:43.720\n Does it try to sneak up on you tricky to answer honestly or something like that?\n\n16:43.720 --> 16:46.360\n Well, what's yeah, I'm not familiar with the question.\n\n16:46.360 --> 16:47.840\n It is just asking you a few questions.\n\n16:47.840 --> 16:52.120\n Like how often did you feel, uh, like lonely or how often do you feel connected to other\n\n16:52.120 --> 16:55.360\n people in this last few couple of weeks?\n\n16:55.360 --> 17:01.200\n Um, it's similar to the self report questionnaires for depression, anxiety, like PHQ nine and\n\n17:01.200 --> 17:02.620\n get seven.\n\n17:02.620 --> 17:09.480\n Of course, as any, as any self report questionnaires, that's not necessarily very precise or very\n\n17:09.480 --> 17:14.420\n well measured, but still, if you take a big enough population and you get them through\n\n17:14.420 --> 17:19.440\n these, uh, questionnaires, you can see, you can see a positive dynamic.\n\n17:19.440 --> 17:24.560\n And so you basically, uh, you put people through questionnaires to see like, is this thing\n\n17:24.560 --> 17:28.120\n is our, is what we're creating, making people happier?\n\n17:28.120 --> 17:31.760\n Yeah, we measure, so we measure two outcomes.\n\n17:31.760 --> 17:36.940\n One short term, right after the conversation, we ask people whether this conversation made\n\n17:36.940 --> 17:43.260\n them feel better, worse or same, um, this, this metric right now is at 80%.\n\n17:43.260 --> 17:47.520\n So 80% of all our conversations make people feel better, but I should have done the questionnaire\n\n17:47.520 --> 17:48.520\n with you.\n\n17:48.520 --> 17:53.000\n You feel a lot worse after we've done this conversation.\n\n17:53.000 --> 17:54.000\n That's actually fascinating.\n\n17:54.000 --> 17:57.980\n I should probably do that, but that's, that's how we do that.\n\n17:57.980 --> 18:05.320\n You should totally and aim for 80% aim to outperform your current state of the art AI\n\n18:05.320 --> 18:09.480\n system in these human conversations.\n\n18:09.480 --> 18:16.080\n So we'll get to your work with replica, but let me continue on the line of absurd questions.\n\n18:16.080 --> 18:22.320\n So you talked about, um, you know, deep connection with the humans, deep connection with AI,\n\n18:22.320 --> 18:23.320\n meaningful connection.\n\n18:23.320 --> 18:25.120\n Let me ask about love.\n\n18:25.120 --> 18:28.360\n People make fun of me cause I talk about love all the time.\n\n18:28.360 --> 18:36.000\n But uh, what, what do you think love is like maybe in the context of, um, a meaningful\n\n18:36.000 --> 18:37.680\n connection with somebody else?\n\n18:37.680 --> 18:47.320\n Do you draw a distinction between love, like friendship and Facebook friends or is it a\n\n18:47.320 --> 18:48.320\n graduate?\n\n18:48.320 --> 18:51.320\n No, it's all the same.\n\n18:51.320 --> 18:52.320\n No.\n\n18:52.320 --> 18:56.240\n Like, is it, is it just a gradual thing or is there something fundamental about us humans\n\n18:56.240 --> 19:05.320\n that seek like a really deep connection, uh, with another human being and what is that?\n\n19:05.320 --> 19:15.680\n What is love Eugenia, I'm going to just enjoy asking you these questions seeing you struggle.\n\n19:15.680 --> 19:16.680\n Thanks.\n\n19:16.680 --> 19:22.160\n Um, well the way I see it, um, and specifically, um, the way it relates to our work and the\n\n19:22.160 --> 19:30.400\n way it was, the way it inspired our work on replica, um, I think one of the biggest and\n\n19:30.400 --> 19:37.200\n the most precious gifts we can give to each other now in 2020 as humans is this gift of\n\n19:37.200 --> 19:42.400\n deep empathetic understanding, the feeling of being deeply seen.\n\n19:42.400 --> 19:43.400\n Like what does that mean?\n\n19:43.400 --> 19:49.200\n Like that you exist, like somebody acknowledging that somebody seeing you for who you actually\n\n19:49.200 --> 19:50.200\n are.\n\n19:50.200 --> 19:51.760\n And that's extremely, extremely rare.\n\n19:51.760 --> 19:59.680\n Um, I think that is that combined with unconditional positive regard, um, belief and trust that\n\n19:59.680 --> 20:05.080\n um, you internally are always inclined for positive growth and believing you in this\n\n20:05.080 --> 20:09.960\n way, letting you be a separate person at the same time.\n\n20:09.960 --> 20:15.880\n And this deep empathetic understanding for me, that's the, that's the combination that\n\n20:15.880 --> 20:21.440\n really creates something special, something that people, when they feel it once, they\n\n20:21.440 --> 20:23.440\n will always long for it again.\n\n20:23.440 --> 20:28.240\n And something that starts huge fundamental changes in people.\n\n20:28.240 --> 20:34.480\n Um, when we see that someone's accepts us so deeply, we start to accept ourselves.\n\n20:34.480 --> 20:41.120\n And um, the paradox is that's when big changes start happening, big fundamental changes in\n\n20:41.120 --> 20:42.120\n people start happening.\n\n20:42.120 --> 20:47.040\n So I think that is the ultimate therapeutic relationship that is, and that might be in\n\n20:47.040 --> 20:50.160\n some way a definition of love.\n\n20:50.160 --> 20:56.520\n So acknowledging that there's a separate person and accepting you for who you are.\n\n20:56.520 --> 21:03.640\n Um, now on a slightly that, and you mentioned therapeutic, that sounds a very, like a very\n\n21:03.640 --> 21:12.920\n healthy view of love, but, uh, is there also like a, like, you know, if we look at heartbreak\n\n21:12.920 --> 21:17.760\n and uh, you know, most love songs are probably about heartbreak, right?\n\n21:17.760 --> 21:25.520\n Is that like the mystery, the tension, the danger, the fear of loss, you know, all of\n\n21:25.520 --> 21:32.040\n that, what people might see in a negative light as like games or whatever, but just,\n\n21:32.040 --> 21:34.440\n just the, the dance of human interaction.\n\n21:34.440 --> 21:35.440\n Yeah.\n\n21:35.440 --> 21:41.460\n Fear of loss and fear of like, you said, you said like once you feel it once, you long\n\n21:41.460 --> 21:46.880\n for it again, but you also, once you feel it once, you might, for many people, they've\n\n21:46.880 --> 21:48.560\n lost it.\n\n21:48.560 --> 21:49.920\n So they fear losing it.\n\n21:49.920 --> 21:50.920\n They feel loss.\n\n21:50.920 --> 21:55.480\n So is that part of it, like you're, you're speaking like beautifully about like the\n\n21:55.480 --> 22:02.520\n positive things, but is it important to be able to, uh, be afraid of losing it from an\n\n22:02.520 --> 22:04.520\n engineering perspective?\n\n22:04.520 --> 22:12.160\n I mean, it's a huge part of it and unfortunately we all, you know, um, face it at some points\n\n22:12.160 --> 22:13.160\n in our lives.\n\n22:13.160 --> 22:14.160\n I mean, I did.\n\n22:14.160 --> 22:15.160\n You want to go into details?\n\n22:15.160 --> 22:18.160\n How'd you get your heartbroken?\n\n22:18.160 --> 22:19.280\n Sure.\n\n22:19.280 --> 22:26.720\n So mine is pretty straight, my story is pretty straightforward, um, there I did have a friend\n\n22:26.720 --> 22:31.800\n that was, you know, that at some point, um, in my twenties became really, really close\n\n22:31.800 --> 22:34.320\n to me and we, we became really close friends.\n\n22:34.320 --> 22:36.520\n Um, well, I grew up pretty lonely.\n\n22:36.520 --> 22:40.120\n So in many ways when I'm building, you know, these, these AI friends, I'm thinking about\n\n22:40.120 --> 22:44.520\n myself when I was 17 writing horrible poetry and you know, in my dial up modem at home\n\n22:44.520 --> 22:49.440\n and, um, you know, and that was the feeling that I grew up with.\n\n22:49.440 --> 22:54.400\n I left, I lived, um, alone for a long time when I was a teenager, where did you go up\n\n22:54.400 --> 22:57.040\n in Moscow and the outskirts of Moscow.\n\n22:57.040 --> 23:01.840\n Um, so I'd just skateboard during the day and come back home and you know, connect to\n\n23:01.840 --> 23:08.640\n the internet and then write horrible poetry and love poems, all sorts of poems, obviously\n\n23:08.640 --> 23:09.640\n love poems.\n\n23:09.640 --> 23:13.360\n I mean, what, what other poetry can you write when you're 17, um, it could be political\n\n23:13.360 --> 23:15.240\n or something, but yeah.\n\n23:15.240 --> 23:19.920\n But that was, you know, that was kind of my fiat, like deeply, um, influenced by Joseph\n\n23:19.920 --> 23:26.880\n Brodsky and like all sorts of sports that, um, every 17 year old will, will be looking,\n\n23:26.880 --> 23:32.000\n you know, looking at and reading, but yeah, that was my, uh, these were my teenage years\n\n23:32.000 --> 23:37.560\n and I just never had a person that I thought would, you know, take me as it is, would accept\n\n23:37.560 --> 23:43.640\n me the way I am, um, and I just thought, you know, working and just doing my thing and\n\n23:43.640 --> 23:47.600\n being angry at the world and being a reporter, I was an investigative reporter working undercover\n\n23:47.600 --> 23:53.680\n and writing about people was my way to connect with, you know, with, with others.\n\n23:53.680 --> 23:57.040\n I was deeply curious about every, everyone else.\n\n23:57.040 --> 24:01.000\n And I thought that, you know, if I, if I go out there, if I write their stories, that\n\n24:01.000 --> 24:03.000\n means I'm more connected.\n\n24:03.000 --> 24:07.520\n This is what this podcast as well, by the way, I'm desperate, well, I'm seeking connection\n\n24:07.520 --> 24:08.520\n now.\n\n24:08.520 --> 24:09.520\n I'm just kidding.\n\n24:09.520 --> 24:10.520\n Or am I?\n\n24:10.520 --> 24:11.520\n I don't know.\n\n24:11.520 --> 24:17.840\n So what, wait, reporter, uh, what, how did that make you feel more connected?\n\n24:17.840 --> 24:21.520\n I mean, you're still fundamentally pretty alone,\n\n24:21.520 --> 24:26.160\n But you're always with other people, you know, you're always thinking about what other place\n\n24:26.160 --> 24:27.280\n can I infiltrate?\n\n24:27.280 --> 24:29.880\n What other community can I write about?\n\n24:29.880 --> 24:32.840\n What other phenomenon can I explore?\n\n24:32.840 --> 24:37.560\n And you sort of like a trickster, you know, and like, and, and a mythological character,\n\n24:37.560 --> 24:41.720\n like creature, that's just jumping, uh, between all sorts of different worlds and feel and\n\n24:41.720 --> 24:44.400\n feel sort of okay with in all of them.\n\n24:44.400 --> 24:48.700\n So, um, that was my dream job, by the way, that was like totally what I would have been\n\n24:48.700 --> 24:49.700\n doing.\n\n24:49.700 --> 24:54.380\n Um, if Russia was a different place and a little bit undercover.\n\n24:54.380 --> 24:59.040\n So like you weren't, you were trying to, like you said, mythological creature trying to\n\n24:59.040 --> 25:00.040\n infiltrate.\n\n25:00.040 --> 25:01.840\n So try to be a part of the world.\n\n25:01.840 --> 25:02.840\n What are we talking about?\n\n25:02.840 --> 25:05.400\n What kind of things did you enjoy writing about?\n\n25:05.400 --> 25:08.440\n I'd go work at a strip club or go.\n\n25:08.440 --> 25:09.440\n Awesome.\n\n25:09.440 --> 25:10.440\n Okay.\n\n25:10.440 --> 25:19.800\n Well, I'd go work at a restaurant or just go write about, you know, um, certain phenomenons\n\n25:19.800 --> 25:22.800\n or phenomenons or people in the city.\n\n25:22.800 --> 25:29.400\n And what, uh, sorry to keep interrupting and I'm the worst, I'm a conversationalist.\n\n25:29.400 --> 25:32.160\n What stage of Russia is this?\n\n25:32.160 --> 25:36.880\n What, uh, is this pre Putin, post Putin?\n\n25:36.880 --> 25:38.960\n What was Russia like?\n\n25:38.960 --> 25:43.000\n Pre Putin is really long ago.\n\n25:43.000 --> 25:44.000\n This is Putin era.\n\n25:44.000 --> 25:49.400\n That's a beginning of two thousands and 2010, 2007, eight, nine, 10.\n\n25:49.400 --> 25:57.200\n What were strip clubs like in Russia and restaurants and culture and people's minds like in that\n\n25:57.200 --> 25:59.160\n early Russia that you were covering?\n\n25:59.160 --> 26:02.400\n In those early two thousands, this was, there was still a lot of hope.\n\n26:02.400 --> 26:11.240\n There were still tons of hope that, um, you know, we're sort of becoming this, uh, Western,\n\n26:11.240 --> 26:12.240\n Westernized society.\n\n26:12.240 --> 26:17.920\n Uh, the restaurants were opening, we were really looking at, you know, um, we're trying,\n\n26:17.920 --> 26:22.880\n we're trying to copy a lot of things from, uh, from the US, from Europe, um, bringing\n\n26:22.880 --> 26:25.600\n all these things and very enthusiastic about that.\n\n26:25.600 --> 26:27.720\n So there was a lot of, you know, stuff going on.\n\n26:27.720 --> 26:33.400\n There was a lot of hope and dream for this, you know, new Moscow that would be similar\n\n26:33.400 --> 26:34.800\n to, I guess, New York.\n\n26:34.800 --> 26:41.620\n I mean, just to give you an idea in, um, year 2000 was the year when we had two, uh, movie\n\n26:41.620 --> 26:47.260\n theaters in Moscow and there was one first coffee house that opened and it was like really\n\n26:47.260 --> 26:48.260\n big deal.\n\n26:48.260 --> 26:51.580\n Uh, by 2010 there were all sorts of things everywhere.\n\n26:51.580 --> 26:55.920\n Almost like a chain, like a Starbucks type of coffee house or like, you mean, oh yeah,\n\n26:55.920 --> 26:56.920\n like a Starbucks.\n\n26:56.920 --> 27:01.120\n I mean, I remember we were reporting on, like, we were writing about the opening of Starbucks.\n\n27:01.120 --> 27:05.240\n I think in 2007 that was one of the biggest things that happened in, you know, in Moscow\n\n27:05.240 --> 27:10.080\n back, back in the time, like, you know, that was worthy of a magazine cover.\n\n27:10.080 --> 27:13.440\n And, uh, that was definitely the, you know, the biggest talk of the time.\n\n27:13.440 --> 27:14.440\n Yeah.\n\n27:14.440 --> 27:15.440\n When was McDonald's?\n\n27:15.440 --> 27:17.560\n Cause I was still in Russia when McDonald's opened.\n\n27:17.560 --> 27:18.560\n That was in the nineties.\n\n27:18.560 --> 27:19.560\n I mean, yeah.\n\n27:19.560 --> 27:20.560\n Oh yeah.\n\n27:20.560 --> 27:21.560\n I remember that very well.\n\n27:21.560 --> 27:22.560\n Yeah.\n\n27:22.560 --> 27:23.560\n Those were long, long lines.\n\n27:23.560 --> 27:27.640\n I think it was 1993 or four, I don't remember.\n\n27:27.640 --> 27:33.600\n Um, actually earlier at that time, did you do, I mean, that was a luxurious outing.\n\n27:33.600 --> 27:35.800\n That was definitely not something you do every day.\n\n27:35.800 --> 27:37.560\n And also the line was at least three hours.\n\n27:37.560 --> 27:40.040\n So if you're going to McDonald's, that is not fast food.\n\n27:40.040 --> 27:44.560\n That is like at least three hours in line and then no one is trying to eat fast after\n\n27:44.560 --> 27:45.560\n that.\n\n27:45.560 --> 27:47.040\n Everyone is like trying to enjoy as much as possible.\n\n27:47.040 --> 27:50.200\n What's your memory of that?\n\n27:50.200 --> 27:52.200\n Oh, it was insane.\n\n27:52.200 --> 27:53.200\n How did it go?\n\n27:53.200 --> 27:54.640\n It was extremely positive.\n\n27:54.640 --> 27:59.080\n It's a small strawberry milkshake and the hamburger and small fries and my mom's there.\n\n27:59.080 --> 28:03.320\n And sometimes I'll just, cause I was really little, they'll just let me run, you know,\n\n28:03.320 --> 28:09.200\n up the kitchen and like cut the line, which is like, you cannot really do that in Russia\n\n28:09.200 --> 28:10.200\n or.\n\n28:10.200 --> 28:17.800\n So like for a lot of people, like a lot of those experiences might seem not very fulfilling,\n\n28:17.800 --> 28:22.360\n you know, like it's on the verge of poverty, I suppose.\n\n28:22.360 --> 28:29.920\n But do you remember all that time fondly, like, cause I do like the first time I drank,\n\n28:29.920 --> 28:36.640\n you know, Coke, you know, all that stuff, right.\n\n28:36.640 --> 28:37.800\n And just, yeah.\n\n28:37.800 --> 28:44.000\n The connection with other human beings in Russia, I remember, I remember it really positively.\n\n28:44.000 --> 28:48.760\n Like how do you remember what the nineties and then the Russia you were covering, just\n\n28:48.760 --> 28:53.400\n the human connections you had with people and the experiences?\n\n28:53.400 --> 28:57.200\n Well, my, my parents were both, both physicists.\n\n28:57.200 --> 29:05.800\n My grandparents were both, well, my grandpa, grandfather was in nuclear physicist, a professor\n\n29:05.800 --> 29:06.840\n at the university.\n\n29:06.840 --> 29:13.700\n My dad worked at Chernobyl when I was born in Chernobyl, analyzing kind of the everything\n\n29:13.700 --> 29:15.260\n after the explosion.\n\n29:15.260 --> 29:19.880\n And then I remember that and they were, so they were making sort of enough money in the\n\n29:19.880 --> 29:20.880\n Soviet union.\n\n29:20.880 --> 29:23.520\n So they were not, you know, extremely poor or anything.\n\n29:23.520 --> 29:28.320\n It was pretty prestigious to be a professor, the Dean and the university.\n\n29:28.320 --> 29:33.800\n And then I remember my grandfather started making a hundred dollars a month after, you\n\n29:33.800 --> 29:35.040\n know, in the nineties.\n\n29:35.040 --> 29:40.020\n So then I remember we started our main line of work would be to go to our little tiny\n\n29:40.020 --> 29:48.560\n country house, get a lot of apples there from apple trees, bring them back to the city and\n\n29:48.560 --> 29:50.880\n sell them in the street.\n\n29:50.880 --> 29:56.000\n So me and my nuclear physicist grandfather were just standing there and he selling those\n\n29:56.000 --> 30:00.680\n apples the whole day, cause that would make you more money than, you know, working at\n\n30:00.680 --> 30:01.740\n the university.\n\n30:01.740 --> 30:07.960\n And then he'll just tell me, try to teach me, you know, something about planets and\n\n30:07.960 --> 30:10.240\n whatever the particles and stuff.\n\n30:10.240 --> 30:14.340\n And, you know, I'm not smart at all, so I could never understand anything, but I was\n\n30:14.340 --> 30:18.000\n interested as a journalist kind of type interested.\n\n30:18.000 --> 30:19.000\n But that was my memory.\n\n30:19.000 --> 30:25.200\n And, you know, I'm happy that I wasn't, I somehow got spared that I was probably too\n\n30:25.200 --> 30:27.400\n young to remember any of the traumatic stuff.\n\n30:27.400 --> 30:31.860\n So the only thing I really remember had this bootleg that was very traumatic, had this\n\n30:31.860 --> 30:35.760\n bootleg Nintendo, which was called Dandy in Russia.\n\n30:35.760 --> 30:39.280\n So in 1993, there was nothing to eat, like, even if you had any money, you would go to\n\n30:39.280 --> 30:40.800\n the store and there was no food.\n\n30:40.800 --> 30:42.880\n I don't know if you remember that.\n\n30:42.880 --> 30:49.960\n And our friend had a restaurant, like a government, half government owned something restaurant.\n\n30:49.960 --> 30:51.960\n So they always had supplies.\n\n30:51.960 --> 31:00.080\n So he exchanged a big bag of wheat for this Nintendo, the bootleg Nintendo, that I remember\n\n31:00.080 --> 31:05.560\n very fondly, cause I think I was nine or something like that and we're seven.\n\n31:05.560 --> 31:11.480\n Like we just got it and I was playing it and there was this, you know, Dandy TV show.\n\n31:11.480 --> 31:12.480\n Yeah.\n\n31:12.480 --> 31:17.080\n So traumatic in a positive sense, you mean like, like a definitive, well, they took it\n\n31:17.080 --> 31:19.440\n away and gave me a bag of wheat instead.\n\n31:19.440 --> 31:23.720\n And I cried like my eyes out for days and days and days.\n\n31:23.720 --> 31:24.720\n Oh no.\n\n31:24.720 --> 31:28.680\n And then, you know, as a, and my dad said, we're going to like exchange it back in a\n\n31:28.680 --> 31:29.680\n little bit.\n\n31:29.680 --> 31:32.880\n So you keep the little gun, you know, the one that you shoot the ducks with.\n\n31:32.880 --> 31:34.240\n So I'm like, okay, I'm keeping the gun.\n\n31:34.240 --> 31:38.880\n So sometime it's going to come back, but then they exchanged the gun as well for some sugar\n\n31:38.880 --> 31:39.880\n or something.\n\n31:39.880 --> 31:41.520\n I was so pissed.\n\n31:41.520 --> 31:43.840\n I was like, I didn't want to eat for days after that.\n\n31:43.840 --> 31:44.840\n I'm like, I don't want your food.\n\n31:44.840 --> 31:47.640\n Give me my Nintendo back.\n\n31:47.640 --> 31:50.120\n That was extremely traumatic.\n\n31:50.120 --> 31:53.640\n But you know, I was happy that that was my only traumatic experience.\n\n31:53.640 --> 31:57.640\n You know, my dad had to actually go to Chernobyl with a bunch of 20 year olds.\n\n31:57.640 --> 32:01.760\n He was 20 when he went to Chernobyl and that was right after the explosion.\n\n32:01.760 --> 32:03.440\n No one knew anything.\n\n32:03.440 --> 32:05.800\n The whole crew he went with, all of them are dead now.\n\n32:05.800 --> 32:11.760\n I think there was this one guy still, that was still alive for this last few years.\n\n32:11.760 --> 32:13.920\n I think he died a few years ago now.\n\n32:13.920 --> 32:19.360\n My dad somehow luckily got back earlier than everyone else, but just the fact that that\n\n32:19.360 --> 32:21.960\n was the, and I was always like, well, how did they send you?\n\n32:21.960 --> 32:26.280\n I was only, I was just born, you know, you had a newborn talk about paternity leave.\n\n32:26.280 --> 32:29.800\n They were like, but that's who they took because they didn't know whether you would be able\n\n32:29.800 --> 32:31.120\n to have kids when you come back.\n\n32:31.120 --> 32:33.880\n So they took the ones with kids.\n\n32:33.880 --> 32:40.360\n So him with some guys went to, and I'm just thinking of me when I was 20, I was so sheltered\n\n32:40.360 --> 32:42.200\n from any problems whatsoever in life.\n\n32:42.200 --> 32:51.200\n And then my dad, his 21st birthday at the reactor, you like work three hours a day,\n\n32:51.200 --> 32:57.040\n you sleep the rest and, and I, yeah, so I played with a lot of toys from Chernobyl.\n\n32:57.040 --> 33:02.640\n What are your memories of Chernobyl in general, like the bigger context, you know, because\n\n33:02.640 --> 33:09.240\n of that HBO show it's the world's attention turned to it once again, like, what are your\n\n33:09.240 --> 33:10.840\n thoughts about Chernobyl?\n\n33:10.840 --> 33:13.000\n Did Russia screw that one up?\n\n33:13.000 --> 33:18.760\n Like, you know, there's probably a lot of lessons about our modern times with data about\n\n33:18.760 --> 33:20.520\n coronavirus and all that kind of stuff.\n\n33:20.520 --> 33:22.960\n It seems like there's a lot of misinformation.\n\n33:22.960 --> 33:29.720\n There's a lot of people kind of trying to hide whether they screwed something up or\n\n33:29.720 --> 33:35.580\n not, as it's very understandable, it's very human, very wrong, probably, but obviously\n\n33:35.580 --> 33:40.320\n Russia was probably trying to hide that they screwed things up.\n\n33:40.320 --> 33:45.520\n Like, what are your thoughts about that time, personal and general?\n\n33:45.520 --> 33:50.200\n I mean, I was born when the explosion happened.\n\n33:50.200 --> 33:55.120\n So actually a few months after, so of course I don't remember anything apart from the fact\n\n33:55.120 --> 34:02.040\n that my dad would bring me tiny toys, like plastic things that would just go crazy haywire\n\n34:02.040 --> 34:06.360\n when you, you know, put the Geiger thing to it.\n\n34:06.360 --> 34:09.240\n My mom was like, just nuclear about that.\n\n34:09.240 --> 34:13.440\n She was like, what are you bringing, you should not do that.\n\n34:13.440 --> 34:14.440\n She was nuclear.\n\n34:14.440 --> 34:15.440\n Very nice.\n\n34:15.440 --> 34:16.440\n Well done.\n\n34:16.440 --> 34:17.440\n I'm sorry.\n\n34:17.440 --> 34:21.200\n It was, but yeah, but the TV show was just phenomenal.\n\n34:21.200 --> 34:22.760\n The HBO one?\n\n34:22.760 --> 34:28.960\n Yeah, it was definitely, first of all, it's incredible how that was made not by the Russians,\n\n34:28.960 --> 34:37.360\n but someone else, but capturing so well everything about our country.\n\n34:37.360 --> 34:41.160\n It felt a lot more genuine than most of the movies and TV shows that are made now in Russia,\n\n34:41.160 --> 34:43.320\n just so much more genuine.\n\n34:43.320 --> 34:47.800\n And most of my friends in Russia were just in complete awe about the show, but I think\n\n34:47.800 --> 34:48.800\n that...\n\n34:48.800 --> 34:49.800\n How good of a job they did.\n\n34:49.800 --> 34:50.800\n Oh my God, phenomenal.\n\n34:50.800 --> 34:51.800\n But also...\n\n34:51.800 --> 34:52.800\n The apartments, there's something, yeah.\n\n34:52.800 --> 34:53.800\n The set design.\n\n34:53.800 --> 34:58.240\n I mean, Russians can't do that, you know, but you see everything and it's like, wow,\n\n34:58.240 --> 35:00.240\n that's exactly how it was.\n\n35:00.240 --> 35:06.840\n So I don't know, that show, I don't know what to think about that because it's British accents,\n\n35:06.840 --> 35:12.560\n British actors of a person, I forgot who created the show.\n\n35:12.560 --> 35:17.480\n But I remember reading about him and he's not, he doesn't even feel like, like there's\n\n35:17.480 --> 35:19.040\n no Russia in this history.\n\n35:19.040 --> 35:21.400\n No, he did like super bad or something like that.\n\n35:21.400 --> 35:22.400\n Or like, I don't know.\n\n35:22.400 --> 35:23.400\n Yeah, like exactly.\n\n35:23.400 --> 35:28.580\n Whatever that thing about the bachelor party in Vegas, number four and five or something\n\n35:28.580 --> 35:30.080\n were the ones that he worked with.\n\n35:30.080 --> 35:31.080\n Yeah.\n\n35:31.080 --> 35:38.600\n But so he made me feel really sad for some reason that if a person, obviously a genius,\n\n35:38.600 --> 35:46.000\n could go in and just study and just be extreme attention to detail, they can do a good job.\n\n35:46.000 --> 35:52.520\n It made me think like, why don't other people do a good job with this?\n\n35:52.520 --> 35:56.320\n Like about Russia, like there's so little about Russia.\n\n35:56.320 --> 36:02.600\n There's so few good films about the Russian side of World War II.\n\n36:02.600 --> 36:10.560\n I mean, there's so much interesting evil and not, and beautiful moments in the history\n\n36:10.560 --> 36:16.640\n of the 20th century in Russia that it feels like there's not many good films on from the\n\n36:16.640 --> 36:17.640\n Russians.\n\n36:17.640 --> 36:18.640\n You would expect something from the Russians.\n\n36:18.640 --> 36:21.640\n Well, they keep making these propaganda movies now.\n\n36:21.640 --> 36:22.640\n Oh no.\n\n36:22.640 --> 36:23.640\n Unfortunately.\n\n36:23.640 --> 36:26.560\n But yeah, no, Chernobyl was such a perfect TV show.\n\n36:26.560 --> 36:30.720\n I think capturing really well, it's not about like even the set design, which was phenomenal,\n\n36:30.720 --> 36:37.120\n but just capturing all the problems that exist now with the country and like focusing on\n\n36:37.120 --> 36:38.120\n the right things.\n\n36:38.120 --> 36:41.960\n Like if you build the whole country on a lie, that's what's going to happen.\n\n36:41.960 --> 36:47.120\n And that's just this very simple kind of thing.\n\n36:47.120 --> 36:48.960\n Yeah.\n\n36:48.960 --> 36:55.760\n And did you have your dad talked about it to you, like his thoughts on the experience?\n\n36:55.760 --> 36:56.760\n He never talks.\n\n36:56.760 --> 37:02.240\n He's this kind of Russian man that just, my husband who's American and he asked him a\n\n37:02.240 --> 37:06.560\n few times like, you know, Igor, how did you, but why did you say yes?\n\n37:06.560 --> 37:08.420\n Or like, why did you decide to go?\n\n37:08.420 --> 37:10.200\n You could have said no, not go to Chernobyl.\n\n37:10.200 --> 37:14.880\n Why would like a person like, that's what you do.\n\n37:14.880 --> 37:15.880\n You cannot say no.\n\n37:15.880 --> 37:16.880\n Yeah.\n\n37:16.880 --> 37:17.880\n Yeah.\n\n37:17.880 --> 37:21.560\n It's just, it's like a Russian way.\n\n37:21.560 --> 37:22.560\n It's the Russian way.\n\n37:22.560 --> 37:23.560\n Men don't talk that much.\n\n37:23.560 --> 37:24.560\n Nope.\n\n37:24.560 --> 37:27.080\n There's no one upsides for that.\n\n37:27.080 --> 37:29.400\n Yeah, that's the truth.\n\n37:29.400 --> 37:30.400\n Okay.\n\n37:30.400 --> 37:37.320\n So back to post Putin Russia, or maybe we skipped a few steps along the way, but you\n\n37:37.320 --> 37:43.560\n were trying to do, to be a journalist in that time.\n\n37:43.560 --> 37:46.640\n What was, what was Russia like at that time?\n\n37:46.640 --> 37:51.860\n Post you said 2007 Starbucks type of thing.\n\n37:51.860 --> 37:55.560\n What else, what else was Russia like then?\n\n37:55.560 --> 37:56.720\n I think there was just hope.\n\n37:56.720 --> 38:01.840\n There was this big hope that we're going to be, you know, friends with the United States\n\n38:01.840 --> 38:06.600\n and we're going to be friends with Europe and we're just going to be also a country\n\n38:06.600 --> 38:12.720\n like those with, you know, bike lanes and parks and everything's going to be urbanized.\n\n38:12.720 --> 38:16.920\n And again, we're talking about nineties where like people would be shot in the street.\n\n38:16.920 --> 38:21.800\n And it was, I still have a fond memory of going into a movie theater and, you know,\n\n38:21.800 --> 38:22.980\n coming out of it after the movie.\n\n38:22.980 --> 38:28.100\n And the guy that I saw on the stairs was like neither shot, which was, again, it was like\n\n38:28.100 --> 38:30.280\n a thing in the nineties that would be happening.\n\n38:30.280 --> 38:35.400\n People were, you know, people were getting shot here and there, tons of violence, tons\n\n38:35.400 --> 38:40.040\n of you know, just basically mafia mobs on in the streets.\n\n38:40.040 --> 38:44.560\n And then the two thousands were like, you know, things just got cleaned up, oil went\n\n38:44.560 --> 38:50.700\n up and the country started getting a little bit richer, you know, the nineties were so\n\n38:50.700 --> 38:54.960\n grim mostly because the economy was in shambles and oil prices were not high.\n\n38:54.960 --> 38:56.740\n So the country didn't have anything.\n\n38:56.740 --> 39:01.680\n We defaulted in 1998 and the money kept jumping back and forth.\n\n39:01.680 --> 39:05.640\n Like first there were millions of rubbles, then it got like default, you know, then it\n\n39:05.640 --> 39:06.640\n got to like thousands.\n\n39:06.640 --> 39:11.800\n Then it was one rubble was something then again to millions, there's like crazy town.\n\n39:11.800 --> 39:12.960\n That was crazy.\n\n39:12.960 --> 39:19.480\n And then the two thousands were just these years of stability in a way and the country\n\n39:19.480 --> 39:22.680\n getting a little bit richer because of, you know, again, oil and gas.\n\n39:22.680 --> 39:27.040\n And we were starting to, we started to look at specifically in Moscow and St. Petersburg\n\n39:27.040 --> 39:34.600\n to look at other cities in Europe and New York and US and trying to do the same in our\n\n39:34.600 --> 39:38.000\n like small kind of cities, towns there.\n\n39:38.000 --> 39:40.320\n What was, what were your thoughts of Putin at the time?\n\n39:40.320 --> 39:43.480\n Well, in the beginning he was really positive.\n\n39:43.480 --> 39:46.000\n Everyone was very, you know, positive about Putin.\n\n39:46.000 --> 39:47.000\n He was young.\n\n39:47.000 --> 39:49.560\n Um, it's very energetic.\n\n39:49.560 --> 39:55.960\n He also immediate the shirtless somewhat compared to, well, that was not like way before the\n\n39:55.960 --> 39:56.960\n shirtless era.\n\n39:56.960 --> 39:57.960\n Um, the shirtless era.\n\n39:57.960 --> 39:58.960\n Okay.\n\n39:58.960 --> 39:59.960\n So he didn't start out shirtless.\n\n39:59.960 --> 40:05.720\n When did the shirtless era, it's like the propaganda of riding horse, fishing, 2010,\n\n40:05.720 --> 40:06.720\n 11, 12.\n\n40:06.720 --> 40:07.720\n Yeah.\n\n40:07.720 --> 40:08.720\n That's my favorite.\n\n40:08.720 --> 40:14.760\n You know, like people talk about the favorite Beatles, like the, that's my favorite Putin\n\n40:14.760 --> 40:15.760\n is the shirtless Putin.\n\n40:15.760 --> 40:20.960\n Now I remember very, very clearly 1996 where, you know, Americans really helped Russia with\n\n40:20.960 --> 40:27.560\n elections and Yeltsin got reelected, um, thankfully so, uh, because there's a huge threat that\n\n40:27.560 --> 40:29.680\n actually the communists will get back to power.\n\n40:29.680 --> 40:32.680\n Uh, they were a lot more popular.\n\n40:32.680 --> 40:39.660\n And then a lot of American experts, political experts, uh, and campaign experts descended\n\n40:39.660 --> 40:44.360\n on Moscow and helped Yeltsin actually get, get the presidency, the second term for the\n\n40:44.360 --> 40:46.340\n pro, um, the, of the presidency.\n\n40:46.340 --> 40:52.240\n But Yeltsin was not feeling great, you know, in the, by the end of his second term, uh,\n\n40:52.240 --> 40:53.920\n he was, you know, alcoholic.\n\n40:53.920 --> 40:54.920\n He was really old.\n\n40:54.920 --> 40:59.960\n He was falling off, uh, you know, the stages when he, where he was talking.\n\n40:59.960 --> 41:04.560\n Uh, so people were looking for fresh, I think for a fresh face, for someone who's going\n\n41:04.560 --> 41:09.680\n to continue Yeltsin's, uh, work, but who's going to be a lot more energetic and a lot\n\n41:09.680 --> 41:15.480\n more active, young, um, efficient, maybe.\n\n41:15.480 --> 41:17.880\n So that w that's what we all saw in Putin back in the day.\n\n41:17.880 --> 41:22.360\n I, I'd say that everyone, absolutely everyone in Russia in early two thousands who was not\n\n41:22.360 --> 41:25.360\n a communist would be, yeah, Putin's great.\n\n41:25.360 --> 41:26.960\n We have a lot of hopes for him.\n\n41:26.960 --> 41:27.960\n What are your thoughts?\n\n41:27.960 --> 41:34.240\n And I promise we'll get back to, uh, first of all, your love story.\n\n41:34.240 --> 41:40.200\n Second of all, AI, well, what are your thoughts about, um, communism?\n\n41:40.200 --> 41:42.680\n The 20th century, I apologize.\n\n41:42.680 --> 41:46.240\n I'm reading the rise and fall of the third Reich.\n\n41:46.240 --> 41:48.580\n Oh my God.\n\n41:48.580 --> 41:56.660\n So I'm like really steeped into like world war II and Stalin and Hitler and just these\n\n41:56.660 --> 42:00.840\n dramatic personalities that brought so much evil to the world.\n\n42:00.840 --> 42:06.580\n But it's also interesting to politically think about these different systems and what they've\n\n42:06.580 --> 42:08.320\n led to.\n\n42:08.320 --> 42:16.280\n And Russia is one of the sort of beacons of communism in the 20th century.\n\n42:16.280 --> 42:17.840\n What are your thoughts about communism?\n\n42:17.840 --> 42:20.480\n Having experienced it as a political system?\n\n42:20.480 --> 42:24.360\n I mean, I have only experienced it a little bit, but mostly through stories and through,\n\n42:24.360 --> 42:29.320\n you know, seeing my parents and my grandparents who lived through that, I mean, it was horrible.\n\n42:29.320 --> 42:31.120\n It was just plain horrible.\n\n42:31.120 --> 42:33.360\n It was just awful.\n\n42:33.360 --> 42:40.960\n You think it's, there's something, I mean, it sounds nice on paper.\n\n42:40.960 --> 42:47.840\n There's a, so like the drawbacks of capitalism is that, uh, you know, eventually there is,\n\n42:47.840 --> 42:51.160\n it's a, it's the point of like a slippery slope.\n\n42:51.160 --> 42:59.040\n Eventually it creates, uh, you know, the rich get richer, it creates a disparity, like inequality\n\n42:59.040 --> 43:02.520\n of, um, wealth inequality.\n\n43:02.520 --> 43:09.080\n If like, you know, I guess it's hypothetical at this point, but eventually capitalism leads\n\n43:09.080 --> 43:13.720\n to humongous inequality and that that's, you know, some people argue that that's a source\n\n43:13.720 --> 43:17.720\n of unhappiness is it's not like absolute wealth of people.\n\n43:17.720 --> 43:21.240\n It's the fact that there's a lot of people much richer than you.\n\n43:21.240 --> 43:25.300\n There's a feeling of like, that's where unhappiness can come from.\n\n43:25.300 --> 43:32.960\n So the idea of, of communism or these sort of Marxism is, uh, is, is not allowing that\n\n43:32.960 --> 43:37.800\n kind of slippery slope, but then you see the actual implementations of it and stuff seems\n\n43:37.800 --> 43:42.400\n to be, seems to go wrong very badly.\n\n43:42.400 --> 43:43.880\n What do you think that is?\n\n43:43.880 --> 43:46.680\n Why does it go wrong?\n\n43:46.680 --> 43:47.680\n What is it about human nature?\n\n43:47.680 --> 43:54.740\n If we look at Chernobyl, you know, those kinds of bureaucracies that were constructed.\n\n43:54.740 --> 44:00.280\n Is there something like, do you think about this much of like why it goes wrong?\n\n44:00.280 --> 44:05.320\n Well, there's no one was really like, it's not that everyone was equal.\n\n44:05.320 --> 44:12.160\n Obviously the, you know, the, the government and everyone close to that were the bosses.\n\n44:12.160 --> 44:17.740\n So it's not like fully, I guess, uh, this dream of equal life.\n\n44:17.740 --> 44:24.720\n So then I guess the, the situation that we had in, you know, the Russia had in the Soviet\n\n44:24.720 --> 44:30.720\n union, it was more, it's a bunch of really poor people without any way to make any, you\n\n44:30.720 --> 44:37.640\n know, significant fortune or build anything living constant, um, under constant surveillance,\n\n44:37.640 --> 44:38.920\n surveillance from other people.\n\n44:38.920 --> 44:45.800\n Like you can't even, you know, uh, do anything that's not fully approved by the dictatorship\n\n44:45.800 --> 44:46.800\n basically.\n\n44:46.800 --> 44:53.080\n Otherwise your neighbor will write a letter and you'll go to jail, absolute absence of\n\n44:53.080 --> 44:54.080\n actual law.\n\n44:54.080 --> 44:55.080\n Yeah.\n\n44:55.080 --> 44:57.880\n It's a constant state of fear.\n\n44:57.880 --> 45:00.000\n You didn't own any, own anything.\n\n45:00.000 --> 45:05.760\n It didn't, you know, the, you couldn't go travel, you couldn't read anything, uh, Western\n\n45:05.760 --> 45:11.840\n or you couldn't make a career really, unless you're working in the, uh, military complex.\n\n45:11.840 --> 45:15.560\n Um, which is why most of the scientists were so well regarded.\n\n45:15.560 --> 45:20.580\n I come from, you know, both my dad and my mom come from families of scientists and they,\n\n45:20.580 --> 45:23.280\n they were really well regarded as you, as you know, obviously.\n\n45:23.280 --> 45:29.960\n Because the state wanted, I mean, cause there's a lot of value to them being well regarded.\n\n45:29.960 --> 45:34.800\n Because they were developing things that could be used in, in the military.\n\n45:34.800 --> 45:35.800\n So that was very important.\n\n45:35.800 --> 45:36.800\n That was the main investment.\n\n45:36.800 --> 45:40.320\n Um, but it was miserable, it was all miserable.\n\n45:40.320 --> 45:43.640\n That's why, you know, a lot of Russians now live in the state of constant PTSD.\n\n45:43.640 --> 45:48.360\n That's why we, you know, want to buy, buy, buy, buy, buy and definitely if as soon as\n\n45:48.360 --> 45:53.000\n we have the opportunity, you know, we just got to it finally that we can, you know, own\n\n45:53.000 --> 45:54.000\n things.\n\n45:54.000 --> 45:57.560\n You know, I remember the time that we got our first yogurts and that was the biggest\n\n45:57.560 --> 45:58.560\n deal in the world.\n\n45:58.560 --> 46:03.920\n It was already in the nineties, by the way, I mean, what was your like, favorite food\n\n46:03.920 --> 46:12.600\n where it was like, well, like this is possible, Oh, fruit, because we only had apples, bananas\n\n46:12.600 --> 46:13.600\n and whatever.\n\n46:13.600 --> 46:17.960\n And you know, whatever watermelons, whatever, you know, people would grow in the Soviet\n\n46:17.960 --> 46:18.960\n Union.\n\n46:18.960 --> 46:24.240\n There were no pineapples or papaya or mango, like you've never seen those fruit things.\n\n46:24.240 --> 46:27.480\n Like those were so ridiculously good.\n\n46:27.480 --> 46:32.760\n And obviously you could not get any like strawberries in winter or anything that's not, you know,\n\n46:32.760 --> 46:33.760\n seasonal.\n\n46:33.760 --> 46:34.760\n Um, so that was a really big deal.\n\n46:34.760 --> 46:36.240\n I've seen all these fruit things.\n\n46:36.240 --> 46:37.240\n Yeah.\n\n46:37.240 --> 46:38.240\n Me too.\n\n46:38.240 --> 46:39.240\n Actually.\n\n46:39.240 --> 46:40.240\n I don't know.\n\n46:40.240 --> 46:44.160\n I think I have a, like, I don't think I have any too many demons, uh, or like addictions\n\n46:44.160 --> 46:47.960\n or so on, but I think I've developed an unhealthy relationship with fruit.\n\n46:47.960 --> 46:51.880\n I still struggle with, Oh, you can get any type of fruit, right?\n\n46:51.880 --> 46:57.880\n If you get like also these weird fruit, fruits like dragon fruit or something or all kinds\n\n46:57.880 --> 47:02.080\n of like different types of peaches, like cherries were killer for me.\n\n47:02.080 --> 47:06.720\n I know, I know you say like we had bananas and so on, but I don't remember having the\n\n47:06.720 --> 47:07.720\n kind of banana.\n\n47:07.720 --> 47:12.920\n Like when I first came to this country, the amount of banana, I like literally got fat\n\n47:12.920 --> 47:17.520\n on bananas, like the amount, Oh yeah, for sure.\n\n47:17.520 --> 47:18.520\n They were delicious.\n\n47:18.520 --> 47:24.160\n And like cherries, the kind, like just the quality of the food, I was like, this is capitalism.\n\n47:24.160 --> 47:25.160\n This is delicious.\n\n47:25.160 --> 47:26.160\n Yeah.\n\n47:26.160 --> 47:27.160\n I am.\n\n47:27.160 --> 47:28.160\n Yeah.\n\n47:28.160 --> 47:29.160\n It's funny.\n\n47:29.160 --> 47:30.160\n It's funny.\n\n47:30.160 --> 47:31.160\n Yeah.\n\n47:31.160 --> 47:36.800\n Like it's, it's funny to read.\n\n47:36.800 --> 47:44.280\n I don't know what to think of it, of, um, it's funny to think how an idea that's just\n\n47:44.280 --> 47:49.720\n written on paper, when carried out amongst millions of people, how that gets actually\n\n47:49.720 --> 47:58.640\n when it becomes reality, what it actually looks like, uh, sorry, but the, uh, been studying\n\n47:58.640 --> 48:04.040\n Hitler a lot recently and, uh, going through Mein Kampf.\n\n48:04.040 --> 48:07.960\n He pretty much wrote out of Mein Kampf everything he was going to do.\n\n48:07.960 --> 48:13.480\n Unfortunately, most leaders, including Stalin didn't read the, read it, but it's, it's kind\n\n48:13.480 --> 48:16.140\n of terrifying and I don't know.\n\n48:16.140 --> 48:21.120\n And amazing in some sense that you can have some words on paper and they can be brought\n\n48:21.120 --> 48:26.560\n to life and they can either inspire the world or they can destroy the world.\n\n48:26.560 --> 48:32.480\n And uh, yeah, there's a lot of lessons to study in history that I think people don't\n\n48:32.480 --> 48:35.520\n study enough now.\n\n48:35.520 --> 48:40.000\n One of the things I'm hoping with, I've been practicing Russian a little bit.\n\n48:40.000 --> 48:49.640\n I'm hoping to sort of find, rediscover the, uh, the beauty and the terror of Russian history\n\n48:49.640 --> 48:55.360\n through this stupid podcast by talking to a few people.\n\n48:55.360 --> 48:58.400\n So anyway, I just feel like so much was forgotten.\n\n48:58.400 --> 48:59.400\n So much was forgotten.\n\n48:59.400 --> 49:04.960\n I'll probably, I'm going to try to convince myself to, um, you're a super busy and super\n\n49:04.960 --> 49:11.000\n important person when I'm going to, I'm going to try to befriend you to, uh, to try to become\n\n49:11.000 --> 49:12.000\n a better Russian.\n\n49:12.000 --> 49:14.160\n Cause I feel like I'm a shitty Russian.\n\n49:14.160 --> 49:15.160\n Not that busy.\n\n49:15.160 --> 49:19.040\n So I can totally be your Russian Sherpa.\n\n49:19.040 --> 49:20.920\n Yeah.\n\n49:20.920 --> 49:28.160\n But love, you were, you were talking about your early days of, uh, being a little bit\n\n49:28.160 --> 49:33.240\n alone and finding a connection with the world through being a journalist.\n\n49:33.240 --> 49:36.200\n Where did love come into that?\n\n49:36.200 --> 49:42.680\n I guess finding for the first time, um, some friends, it's very, you know, simple story.\n\n49:42.680 --> 49:48.920\n Some friends that all of a sudden we, I guess we were the same, you know, the same, at the\n\n49:48.920 --> 49:55.400\n same place with our lives, um, we're 25, 26, I guess.\n\n49:55.400 --> 50:00.400\n And, um, somehow remember, and we just got really close and somehow remember this one\n\n50:00.400 --> 50:06.640\n day where, um, it's one day and, you know, in summer that we just stayed out, um, outdoor\n\n50:06.640 --> 50:11.240\n the whole night and just talked and for some unknown reason, it just felt for the first\n\n50:11.240 --> 50:17.000\n time that someone could, you know, see me for who I am and it just felt extremely like\n\n50:17.000 --> 50:18.000\n extremely good.\n\n50:18.000 --> 50:22.520\n And I, you know, we fell asleep outside and just talking and it was raining.\n\n50:22.520 --> 50:28.440\n It was beautiful, you know, sunrise and it's really cheesy, but, um, at the same time,\n\n50:28.440 --> 50:33.840\n we just became friends in a way that I've never been friends with anyone else before.\n\n50:33.840 --> 50:38.360\n And I do remember that before and after that you sort of have this unconditional family\n\n50:38.360 --> 50:43.440\n sort of, um, and it gives you tons of power.\n\n50:43.440 --> 50:50.680\n It just basically gives you this tremendous power to do things in your life and to, um,\n\n50:50.680 --> 50:53.920\n change positively on many different levels.\n\n50:53.920 --> 50:56.720\n Power because you could be yourself.\n\n50:56.720 --> 51:01.760\n At least you know that some somewhere you can be just yourself, like you don't need\n\n51:01.760 --> 51:07.920\n to pretend, you don't need to be, you know, um, great at work or tell some story or sell\n\n51:07.920 --> 51:10.280\n yourself in somewhere or another.\n\n51:10.280 --> 51:17.200\n And so it became this really close friends and, um, in a way, um, I started a company\n\n51:17.200 --> 51:20.120\n cause he had a startup and I felt like I kind of want to start up too.\n\n51:20.120 --> 51:21.120\n It felt really cool.\n\n51:21.120 --> 51:25.720\n I don't know what I'm going to, what I would really do, but I felt like I kind of need\n\n51:25.720 --> 51:26.720\n a startup.\n\n51:26.720 --> 51:27.720\n Okay.\n\n51:27.720 --> 51:32.040\n So that's, so that pulled you in to the startup world.\n\n51:32.040 --> 51:33.320\n Yeah.\n\n51:33.320 --> 51:35.680\n And then, yeah.\n\n51:35.680 --> 51:38.400\n And then this, uh, closest friend of mine died.\n\n51:38.400 --> 51:42.720\n We actually moved here to San Francisco together and then we went back for a visa to Moscow\n\n51:42.720 --> 51:48.520\n and, uh, we lived together, we're roommates and we came back and, um, he got hit by a\n\n51:48.520 --> 51:54.520\n car right in front of Kremlin on a, you know, next to the river, um, and died the same day\n\n51:54.520 --> 51:58.440\n I met this is the Roman hospital.\n\n51:58.440 --> 52:05.720\n So, and you've moved to America at that point, at that point I was, what about him?\n\n52:05.720 --> 52:06.720\n What about Roman?\n\n52:06.720 --> 52:07.720\n Him too.\n\n52:07.720 --> 52:08.720\n He actually moved first.\n\n52:08.720 --> 52:11.960\n So I was always sort of trying to do what he was doing, so I didn't like that he was\n\n52:11.960 --> 52:15.580\n already here and I was still, you know, in Moscow and we weren't hanging out together\n\n52:15.580 --> 52:16.580\n all the time.\n\n52:16.580 --> 52:18.080\n So was he in San Francisco?\n\n52:18.080 --> 52:20.540\n Yeah, we were roommates.\n\n52:20.540 --> 52:23.400\n So he just visited Moscow for a little bit.\n\n52:23.400 --> 52:28.920\n We went back for, for our visas, we had to get a stamp in our passport for our work visas\n\n52:28.920 --> 52:34.720\n and the embassy was taking a little longer, so we stayed there for a couple of weeks.\n\n52:34.720 --> 52:35.720\n What happened?\n\n52:35.720 --> 52:40.200\n How did he, so how, how did he, uh, how did he die?\n\n52:40.200 --> 52:45.280\n Um, he was crossing the street and the car was going really fast and way over the speed\n\n52:45.280 --> 52:51.520\n limit and just didn't stop on the, on the pedestrian cross on the zebra and just ran\n\n52:51.520 --> 52:52.520\n over him.\n\n52:52.520 --> 52:53.520\n When was this?\n\n52:53.520 --> 52:59.320\n It was in 2015 on 28th of November, so it was a long ago now.\n\n52:59.320 --> 53:06.120\n Um, but at the time, you know, I was 29, so for me it was, um, the first kind of meaningful\n\n53:06.120 --> 53:07.760\n death in my life.\n\n53:07.760 --> 53:12.840\n Um, you know, both sets of, I had both sets of grandparents at the time.\n\n53:12.840 --> 53:18.880\n I didn't see anyone so close die and death sort of existed, but as a concept, but definitely\n\n53:18.880 --> 53:24.720\n not as something that would be, you know, happening to us anytime soon and specifically\n\n53:24.720 --> 53:25.720\n our friends.\n\n53:25.720 --> 53:29.880\n Cause we were, you know, we're still in our twenties or early thirties and it still, it\n\n53:29.880 --> 53:36.120\n still felt like the whole life is, you know, you could still dream about ridiculous things\n\n53:36.120 --> 53:37.120\n different.\n\n53:37.120 --> 53:43.840\n Um, so that was, it was just really, really abrupt I'd say.\n\n53:43.840 --> 53:49.680\n What did it feel like to, uh, to lose him, like that feeling of loss?\n\n53:49.680 --> 53:53.120\n You talked about the feeling of love, having power.\n\n53:53.120 --> 53:57.520\n What is the feeling of loss, if you like?\n\n53:57.520 --> 54:04.720\n Well in Buddhism, there's this concept of Samaya where something really like huge happens\n\n54:04.720 --> 54:07.160\n and then you can see very clearly.\n\n54:07.160 --> 54:13.320\n Um, I think that, that was it like basically something changed so, changed me so much in\n\n54:13.320 --> 54:19.240\n such a short period of time that I could just see really, really clearly what mattered or\n\n54:19.240 --> 54:20.240\n what not.\n\n54:20.240 --> 54:25.800\n Well, I definitely saw that whatever I was doing at work didn't matter at all and some\n\n54:25.800 --> 54:26.800\n of the things.\n\n54:26.800 --> 54:31.400\n And, um, it was just this big realization when it's this very, very clear vision of\n\n54:31.400 --> 54:35.280\n what life's about.\n\n54:35.280 --> 54:37.280\n You still miss him today?\n\n54:37.280 --> 54:40.360\n Yeah, for sure.\n\n54:40.360 --> 54:41.840\n For sure.\n\n54:41.840 --> 54:47.360\n He was just this constant, I think it was, he was really important for, for me and for\n\n54:47.360 --> 54:53.120\n our friends for many different reasons and, um, I think one of them being that we didn't\n\n54:53.120 --> 54:58.160\n just say goodbye to him, but we sort of said goodbye to our youth in a way.\n\n54:58.160 --> 55:02.400\n It was like the end of an era and it's on so many different levels.\n\n55:02.400 --> 55:08.720\n The end of Moscow as we knew it, the end of, you know, us living through our twenties and\n\n55:08.720 --> 55:11.600\n kind of dreaming about the future.\n\n55:11.600 --> 55:17.920\n Do you remember like last several conversations, is there moments with him that stick out that\n\n55:17.920 --> 55:22.720\n kind of haunt you and you're just when you think about him?\n\n55:22.720 --> 55:28.920\n Yeah, well his last year here in San Francisco, he was pretty depressed for as his startup\n\n55:28.920 --> 55:32.600\n was not going really anywhere and he wanted to do something else.\n\n55:32.600 --> 55:39.880\n He wanted to do build, he played with toy, like played with a bunch of ideas, but the\n\n55:39.880 --> 55:44.680\n last one he had was around, um, building a startup around death.\n\n55:44.680 --> 55:52.280\n So having, um, he applied to Y Combinator with a video that, you know, I had on my computer\n\n55:52.280 --> 55:57.760\n and it was all about, you know, disrupting death, thinking about new cemeteries, uh,\n\n55:57.760 --> 56:03.400\n more biologically, like things that could be better biologically for, for humans.\n\n56:03.400 --> 56:12.800\n And at the same time, having those, um, digital avatars, this kind of AI avatars that would\n\n56:12.800 --> 56:15.920\n store all the memory about a person that he could interact with.\n\n56:15.920 --> 56:16.920\n What year was this?\n\n56:16.920 --> 56:17.920\n 2015.\n\n56:17.920 --> 56:19.920\n Well, right before his death.\n\n56:19.920 --> 56:23.760\n So it was like a couple of months before that he recorded that video.\n\n56:23.760 --> 56:28.180\n And so I found out my computer when, um, it was in our living room.\n\n56:28.180 --> 56:33.080\n He never got in, but, um, he was thinking about a lot somehow.\n\n56:33.080 --> 56:35.240\n Does it have the digital avatar idea?\n\n56:35.240 --> 56:36.240\n Yeah.\n\n56:36.240 --> 56:37.240\n That's so interesting.\n\n56:37.240 --> 56:42.160\n Well, he just says, well, that's in his hit is the pitch has this idea and he'll, he talks\n\n56:42.160 --> 56:45.960\n about like, I want to rethink how people grieve and how people talk about death.\n\n56:45.960 --> 56:48.960\n Why was he interested in this?\n\n56:48.960 --> 56:56.000\n Is it, maybe someone who's depressed is like naturally inclined thinking about that.\n\n56:56.000 --> 57:00.800\n But I just felt, you know, this year in San Francisco, we just had so much, um, I was\n\n57:00.800 --> 57:01.800\n going through a hard time.\n\n57:01.800 --> 57:07.940\n And we were definitely, I was trying to make him just happy somehow to make him feel better.\n\n57:07.940 --> 57:13.840\n And it felt like, you know, this, um, I dunno, I just felt like I was taking care of him\n\n57:13.840 --> 57:17.000\n a lot and he almost started to feel better.\n\n57:17.000 --> 57:23.920\n And then that happened and I dunno, I just felt, I just felt lonely again, I guess.\n\n57:23.920 --> 57:28.440\n And that was, you know, coming back to San Francisco in December or help, you know, helped\n\n57:28.440 --> 57:33.680\n organize the funeral, help help his parents and I came back here and it was a really lonely\n\n57:33.680 --> 57:38.520\n apartment, a bunch of his clothes everywhere and Christmas time.\n\n57:38.520 --> 57:42.280\n And I remember I had a board meeting with my investors and I just couldn't talk about\n\n57:42.280 --> 57:44.960\n like, I had to pretend everything's okay.\n\n57:44.960 --> 57:47.360\n And you know, I'm just working on this company.\n\n57:47.360 --> 57:55.360\n Um, yeah, it was definitely very, very tough, tough time.\n\n57:55.360 --> 58:00.160\n Do you think about your own mortality?\n\n58:00.160 --> 58:06.900\n You said, uh, you know, we're young, the, the, the, the possibility of doing all kinds\n\n58:06.900 --> 58:12.900\n of crazy things is still out there, is still before us, but, uh, it can end any moment.\n\n58:12.900 --> 58:17.640\n Do you think about your own ending at any moment?\n\n58:17.640 --> 58:23.320\n Unfortunately, I think about way too, about it way too much.\n\n58:23.320 --> 58:27.800\n Somehow after Roman, like every year after that, I started losing people that I really\n\n58:27.800 --> 58:28.800\n love.\n\n58:28.800 --> 58:34.640\n I lost my grandfather the next year, my, you know, the, the person who would explain to\n\n58:34.640 --> 58:41.360\n me, you know, what the universe is made of while selling apples and then I lost another\n\n58:41.360 --> 58:46.680\n close friend of mine and, um, and it just made me very scared.\n\n58:46.680 --> 58:48.520\n I have tons of fear about, about that.\n\n58:48.520 --> 58:54.760\n That's what makes me not fall asleep oftentimes and just go in loops and, um, and then as\n\n58:54.760 --> 59:02.520\n my therapist, you know, recommended to me, I open up, uh, some nice calming images with\n\n59:02.520 --> 59:06.680\n the voiceover and it calms me down for sleep.\n\n59:06.680 --> 59:07.680\n Yeah.\n\n59:07.680 --> 59:08.680\n I'm really scared of death.\n\n59:08.680 --> 59:15.000\n This is a big, I definitely have tons of, I guess, some pretty big trauma about it and,\n\n59:15.000 --> 59:17.300\n um, still working through.\n\n59:17.300 --> 59:22.920\n There's a philosopher, Ernest Becker, who wrote a book, um, Denial of Death.\n\n59:22.920 --> 59:25.600\n I'm not sure if you're familiar with any of those folks.\n\n59:25.600 --> 59:32.320\n Um, there's a, in psychology, a whole field called terror management theory.\n\n59:32.320 --> 59:36.240\n Sheldon, who's just done the podcast, he wrote the book.\n\n59:36.240 --> 59:44.720\n He was the, we talked for four hours about death, uh, fear of death, but his, his whole\n\n59:44.720 --> 59:52.160\n idea is that, um, Ernest Becker, I think I find this idea really compelling is, uh, that\n\n59:52.160 --> 1:00:00.640\n everything human beings have created, like our whole motivation in life is to, uh, create\n\n1:00:00.640 --> 1:00:11.640\n like escape death is to try to, um, construct an illusion of, um, that we're somehow immortal.\n\n1:00:11.640 --> 1:00:21.040\n So like everything around us, this room, your startup, your dreams, all everything you do\n\n1:00:21.040 --> 1:00:30.460\n is a kind of, um, creation of a brain unlike any other mammal or species is able to be\n\n1:00:30.460 --> 1:00:35.180\n cognizant of the fact that it ends for us.\n\n1:00:35.180 --> 1:00:40.540\n I think, so, you know, there's this, the question of like the meaning of life that, you know,\n\n1:00:40.540 --> 1:00:44.260\n you look at like what drives us, uh, humans.\n\n1:00:44.260 --> 1:00:50.060\n And when I read Ernest Becker that I highly recommend people read is the first time I,\n\n1:00:50.060 --> 1:00:54.160\n this scene, it felt like this is the right thing at the core.\n\n1:00:54.160 --> 1:00:57.980\n Uh, Sheldon's work is called warm at the core.\n\n1:00:57.980 --> 1:01:05.240\n So he's saying it's, I think it's, uh, William James he's quoting or whoever is like the,\n\n1:01:05.240 --> 1:01:07.760\n the thing, what is at the core of it all?\n\n1:01:07.760 --> 1:01:12.540\n Whether there's like love, you know, Jesus might talk about like love is at the core\n\n1:01:12.540 --> 1:01:13.540\n of everything.\n\n1:01:13.540 --> 1:01:15.640\n I don't, you know, that's the open question.\n\n1:01:15.640 --> 1:01:19.980\n What's at the, you know, it's turtles, turtles, but it can't be turtles all the way down.\n\n1:01:19.980 --> 1:01:22.300\n What's what's at the, at the bottom.\n\n1:01:22.300 --> 1:01:30.980\n And, uh, Ernest Becker says the fear of death and the way, in fact, uh, cause you said therapist\n\n1:01:30.980 --> 1:01:36.860\n and calming images, his whole idea is, um, you know, we, we want to bring that fear of\n\n1:01:36.860 --> 1:01:43.900\n death as close as possible to the surface because it's, um, and like meditate on that.\n\n1:01:43.900 --> 1:01:49.820\n Uh, and, and use the clarity of vision that provides to, uh, you know, to live a more\n\n1:01:49.820 --> 1:01:58.580\n fulfilling life, to, um, to live a more honest life, to, to discover, you know, there's something\n\n1:01:58.580 --> 1:02:05.500\n about, you know, being cognizant of the finiteness of it all that might result in, um, in the\n\n1:02:05.500 --> 1:02:07.580\n most fulfilling life.\n\n1:02:07.580 --> 1:02:10.500\n So that's the, that's the dual of what you're saying.\n\n1:02:10.500 --> 1:02:15.180\n Cause you kind of said, it's like, I unfortunately think about it too much.\n\n1:02:15.180 --> 1:02:20.020\n It's a question whether it's good to think about it because I, I've, um, again, I talk\n\n1:02:20.020 --> 1:02:23.260\n about way too much about love and probably death.\n\n1:02:23.260 --> 1:02:29.620\n And when I ask people, friends, which is why I probably don't have many friends, are you\n\n1:02:29.620 --> 1:02:30.820\n afraid of death?\n\n1:02:30.820 --> 1:02:35.020\n I think most people say they're not.\n\n1:02:35.020 --> 1:02:41.700\n Whether they say they're, um, they're afraid, you know, it's kind of almost like they see\n\n1:02:41.700 --> 1:02:45.980\n death as this kind of like, uh, a paper deadline or something.\n\n1:02:45.980 --> 1:02:50.020\n And they're afraid not to finish the paper before the paper, like, like I'm afraid not\n\n1:02:50.020 --> 1:02:57.540\n to finish, um, the goals I have, but it feels like they're not actually realizing that this\n\n1:02:57.540 --> 1:03:04.340\n thing ends, like really realizing, like really thinking as Nietzsche and all these philosophy,\n\n1:03:04.340 --> 1:03:13.740\n like thinking deeply about it, like, uh, the very thing that, you know, um, like when you\n\n1:03:13.740 --> 1:03:18.500\n think deeply about something, you can just, you can realize that you haven't actually\n\n1:03:18.500 --> 1:03:20.500\n thought about it.\n\n1:03:20.500 --> 1:03:22.660\n Uh, yeah.\n\n1:03:22.660 --> 1:03:28.500\n And I, and when I think about death, it's like, um, it can be, it's terrifying.\n\n1:03:28.500 --> 1:03:34.000\n If it feels like stepping outside into the cold or it's freezing and then I have to like\n\n1:03:34.000 --> 1:03:36.820\n hurry back inside or it's warm.\n\n1:03:36.820 --> 1:03:43.180\n Uh, but like, I think there's something valuable about stepping out there into the freezing\n\n1:03:43.180 --> 1:03:44.180\n cold.\n\n1:03:44.180 --> 1:03:45.180\n Definitely.\n\n1:03:45.180 --> 1:03:52.820\n When I talk to my mentor about it, he always, uh, tells me, well, what dies?\n\n1:03:52.820 --> 1:04:00.700\n There's nothing there that can die, but I guess that requires, um, well in, in Buddhism,\n\n1:04:00.700 --> 1:04:05.240\n one of the concepts that are really hard to grasp and that people spend all their lives\n\n1:04:05.240 --> 1:04:12.420\n meditating on would be Anatta, which is the concept of non, not self and kind of thinking\n\n1:04:12.420 --> 1:04:15.260\n that, you know, if you're not your thoughts, which you're obviously not your thoughts because\n\n1:04:15.260 --> 1:04:20.980\n you can observe them and not your emotions and not your body, then what is this?\n\n1:04:20.980 --> 1:04:27.580\n And if you go really far, then finally you see that there's not self, there's this concept\n\n1:04:27.580 --> 1:04:28.580\n of not self.\n\n1:04:28.580 --> 1:04:32.260\n So once you get there, how can that actually die?\n\n1:04:32.260 --> 1:04:33.260\n What is dying?\n\n1:04:33.260 --> 1:04:34.260\n Right.\n\n1:04:34.260 --> 1:04:38.900\n You're just a bunch of molecules, stardust.\n\n1:04:38.900 --> 1:04:44.300\n But that is very, um, you know, very advanced, um, spiritual work for me.\n\n1:04:44.300 --> 1:04:47.100\n I'm definitely just, definitely not.\n\n1:04:47.100 --> 1:04:48.100\n Oh my God.\n\n1:04:48.100 --> 1:04:50.740\n No, I have, uh, I think it's very, very useful.\n\n1:04:50.740 --> 1:04:56.500\n It's just the fact that maybe being so afraid is not useful and mine is more, I'm just terrified.\n\n1:04:56.500 --> 1:04:58.300\n Like it's really makes me, um,\n\n1:04:58.300 --> 1:04:59.300\n On a personal level.\n\n1:04:59.300 --> 1:05:00.300\n On a personal level.\n\n1:05:00.300 --> 1:05:01.300\n I'm terrified.\n\n1:05:01.300 --> 1:05:02.300\n How do you overcome that?\n\n1:05:02.300 --> 1:05:03.300\n I don't.\n\n1:05:03.300 --> 1:05:04.300\n I'm still trying to.\n\n1:05:04.300 --> 1:05:05.300\n Have pleasant images?\n\n1:05:05.300 --> 1:05:20.540\n Well, pleasant images get me to sleep and then during the day I can distract myself with\n\n1:05:20.540 --> 1:05:24.460\n other things, like talking to you.\n\n1:05:24.460 --> 1:05:26.740\n I'm glad we're both doing the same exact thing.\n\n1:05:26.740 --> 1:05:27.740\n Okay, good.\n\n1:05:27.740 --> 1:05:39.540\n Is there other, like, is there moments since you've, uh, lost Roman that you had like moments\n\n1:05:39.540 --> 1:05:47.980\n of like bliss and like that you've forgotten that you have achieved that Buddhist like\n\n1:05:47.980 --> 1:05:52.380\n level of like what can possibly die.\n\n1:05:52.380 --> 1:06:02.020\n I'm part like, uh, losing yourself in the moment, in the ticking time of like this universe\n\n1:06:02.020 --> 1:06:06.980\n and you're just part of it for a brief moment and just enjoying it.\n\n1:06:06.980 --> 1:06:08.260\n Well that goes hand in hand.\n\n1:06:08.260 --> 1:06:13.940\n I remember I think a day or two after he died, we went to finally get his password out of\n\n1:06:13.940 --> 1:06:19.340\n the embassy and we're driving around Moscow and it was, you know, December, which is usually\n\n1:06:19.340 --> 1:06:25.420\n there's never a sun in Moscow in December and somehow it was an extremely sunny day\n\n1:06:25.420 --> 1:06:30.700\n and we were driving with a close friend.\n\n1:06:30.700 --> 1:06:35.420\n And I remember feeling for the first time maybe this just moment of incredible clarity\n\n1:06:35.420 --> 1:06:45.860\n and somehow happiness, not like happy happiness, but happiness and just feeling that, you know,\n\n1:06:45.860 --> 1:06:49.820\n I know what the universe is sort of about, whether it's good or bad.\n\n1:06:49.820 --> 1:06:50.820\n And it wasn't a sad feeling.\n\n1:06:50.820 --> 1:06:56.120\n It was probably the most beautiful feeling that you can ever achieve.\n\n1:06:56.120 --> 1:07:03.260\n And you can only get it when something, oftentimes when something traumatic like that happens.\n\n1:07:03.260 --> 1:07:07.040\n But also if you just, you really spend a lot of time meditating and looking at the nature\n\n1:07:07.040 --> 1:07:09.900\n doing something that really gets you there.\n\n1:07:09.900 --> 1:07:14.460\n But once you're there, I think when you, uh, summit a mountain, a really hard mountain,\n\n1:07:14.460 --> 1:07:16.100\n you inevitably get there.\n\n1:07:16.100 --> 1:07:18.500\n That's just a way to get to the state.\n\n1:07:18.500 --> 1:07:24.140\n But once you're on this, in this state, um, you can do really big things.\n\n1:07:24.140 --> 1:07:25.140\n I think.\n\n1:07:25.140 --> 1:07:26.140\n Yeah.\n\n1:07:26.140 --> 1:07:28.100\n Sucks it doesn't last forever.\n\n1:07:28.100 --> 1:07:32.460\n So Bukowski talked about like, love is a fog.\n\n1:07:32.460 --> 1:07:38.500\n Like it's a, when you wake up in the morning, it's, it's there, but it eventually dissipates.\n\n1:07:38.500 --> 1:07:40.460\n It's really sad.\n\n1:07:40.460 --> 1:07:41.460\n Nothing lasts forever.\n\n1:07:41.460 --> 1:07:46.620\n But I definitely like doing this pushup and running thing.\n\n1:07:46.620 --> 1:07:51.100\n There's moments at a couple of moments, like I'm not a crier.\n\n1:07:51.100 --> 1:07:52.100\n I don't cry.\n\n1:07:52.100 --> 1:07:59.100\n But there's moments where I was like facedown on the carpet, like with tears in my eyes\n\n1:07:59.100 --> 1:08:00.100\n is interesting.\n\n1:08:00.100 --> 1:08:05.100\n And then that, that complete, like, uh, there's a lot of demons.\n\n1:08:05.100 --> 1:08:07.740\n I've got demons had to face them.\n\n1:08:07.740 --> 1:08:09.560\n Funny how running makes you face your demons.\n\n1:08:09.560 --> 1:08:16.580\n But at the same time, the flip side of that, there's a few moments where I was in bliss\n\n1:08:16.580 --> 1:08:19.420\n and all of it alone, which is funny.\n\n1:08:19.420 --> 1:08:20.420\n That's beautiful.\n\n1:08:20.420 --> 1:08:27.060\n I like that, but definitely pushing yourself physically one of it for sure.\n\n1:08:27.060 --> 1:08:28.060\n Yeah.\n\n1:08:28.060 --> 1:08:29.060\n Yeah.\n\n1:08:29.060 --> 1:08:34.020\n Like you said, I mean, you were speaking as a metaphor of Mount Everest, but it also works\n\n1:08:34.020 --> 1:08:39.580\n like literally, I think physical endeavor somehow.\n\n1:08:39.580 --> 1:08:40.580\n Yeah.\n\n1:08:40.580 --> 1:08:41.580\n There's something.\n\n1:08:41.580 --> 1:08:46.860\n I mean, we're monkeys, apes, whatever physical, there's a physical thing to it, but there's\n\n1:08:46.860 --> 1:08:53.020\n something to this pushing yourself physical, physically, but alone that happens when you're\n\n1:08:53.020 --> 1:08:58.060\n doing like things like you do or strenuous like workouts or, you know, rolling extra\n\n1:08:58.060 --> 1:09:01.580\n across the Atlantic or like marathons.\n\n1:09:01.580 --> 1:09:09.540\n I love watching marathons and you know, it's so boring, but you can see them getting there.\n\n1:09:09.540 --> 1:09:14.100\n So the other thing, I don't know if you know, there's a guy named David Goggins.\n\n1:09:14.100 --> 1:09:20.020\n He's a, he basically, uh, so he's been either email on the phone with me every day through\n\n1:09:20.020 --> 1:09:21.020\n this.\n\n1:09:21.020 --> 1:09:27.820\n I haven't been exactly alone, but he, he's kind of, he's the, he's the devil on the devil's\n\n1:09:27.820 --> 1:09:28.820\n shoulder.\n\n1:09:28.820 --> 1:09:36.140\n Uh, so he's like the worst possible human being in terms of giving you, uh, like he\n\n1:09:36.140 --> 1:09:40.840\n has, um, through everything I've been doing, he's been doubling everything I do.\n\n1:09:40.840 --> 1:09:42.620\n So he, he's insane.\n\n1:09:42.620 --> 1:09:45.740\n Uh, he's a, this Navy seal person.\n\n1:09:45.740 --> 1:09:47.620\n Uh, he's wrote this book.\n\n1:09:47.620 --> 1:09:48.620\n Can't hurt me.\n\n1:09:48.620 --> 1:09:50.620\n He's basically one of the toughest human beings on earth.\n\n1:09:50.620 --> 1:09:54.180\n He ran all these crazy ultra marathons in the desert.\n\n1:09:54.180 --> 1:09:56.980\n He set the world record number of pull ups.\n\n1:09:56.980 --> 1:10:03.620\n He just does everything where it's like, he, like, how can I suffer today?\n\n1:10:03.620 --> 1:10:05.500\n He figures that out and does it.\n\n1:10:05.500 --> 1:10:06.500\n Yeah.\n\n1:10:06.500 --> 1:10:11.660\n That, um, whatever that is, uh, that process of self discovery is really important.\n\n1:10:11.660 --> 1:10:16.100\n I actually had to turn myself off from the internet mostly because I started this like\n\n1:10:16.100 --> 1:10:24.140\n workout thing, like a happy go getter with my like headband and like, just like, uh,\n\n1:10:24.140 --> 1:10:27.500\n because a lot of people were like inspired and they're like, yeah, we're going to exercise\n\n1:10:27.500 --> 1:10:28.740\n with you.\n\n1:10:28.740 --> 1:10:30.220\n And I was like, yeah, great.\n\n1:10:30.220 --> 1:10:38.700\n You know, but then like, I realized that this, this journey can't be done together with others.\n\n1:10:38.700 --> 1:10:41.460\n This has to be done alone.\n\n1:10:41.460 --> 1:10:48.820\n So out of the moments of love, out of the moments of loss, can we, uh, talk about your\n\n1:10:48.820 --> 1:10:56.780\n journey of finding, I think, an incredible idea and incredible company and incredible\n\n1:10:56.780 --> 1:10:59.180\n system in Replica?\n\n1:10:59.180 --> 1:11:01.320\n How did that come to be?\n\n1:11:01.320 --> 1:11:05.940\n So yeah, so I was a journalist and then I went to business school for a couple of years\n\n1:11:05.940 --> 1:11:12.700\n to, um, just see if I can maybe switch gears and do something else with 23.\n\n1:11:12.700 --> 1:11:17.500\n And then I came back and started working for a businessman in Russia who built the first\n\n1:11:17.500 --> 1:11:25.580\n ROG network, um, in our country and was very visionary and asked me whether I want to do\n\n1:11:25.580 --> 1:11:26.580\n fun stuff together.\n\n1:11:26.580 --> 1:11:34.060\n Um, and we worked on a bank, um, the idea was to build a bank on top of, um, a telco.\n\n1:11:34.060 --> 1:11:42.560\n So that was 2011 or 12, um, and a lot of telecommunication company, um, mobile network operators didn't\n\n1:11:42.560 --> 1:11:47.660\n really know what to do next in terms of, you know, new products, new revenue.\n\n1:11:47.660 --> 1:11:53.620\n And this big idea was that, you know, um, you put a bank on top and then all work works\n\n1:11:53.620 --> 1:11:54.620\n out.\n\n1:11:54.620 --> 1:11:58.900\n Basically a prepaid account becomes your bank account and, um, you can use it as, as your\n\n1:11:58.900 --> 1:11:59.900\n bank.\n\n1:11:59.900 --> 1:12:05.060\n Uh, so, you know, a third of a country wakes up as, as your bank client.\n\n1:12:05.060 --> 1:12:10.100\n Um, but we couldn't quite figure out what, what would be the main interface to interact\n\n1:12:10.100 --> 1:12:11.180\n with the bank.\n\n1:12:11.180 --> 1:12:15.500\n The problem was that most people didn't have smart, smart phones back in the time in Russia,\n\n1:12:15.500 --> 1:12:20.300\n the penetration of smartphones was low, um, people didn't use mobile banking or online\n\n1:12:20.300 --> 1:12:22.720\n banking and their computers.\n\n1:12:22.720 --> 1:12:26.940\n So we figured out that SMS would be the best way, uh, cause that would work on feature\n\n1:12:26.940 --> 1:12:27.940\n phones.\n\n1:12:27.940 --> 1:12:33.900\n Um, but that required some chat bot technology, which I didn't know anything about, um, obviously.\n\n1:12:33.900 --> 1:12:37.540\n So I started looking into it and saw that there's nothing really, well, there wasn't\n\n1:12:37.540 --> 1:12:38.540\n just nothing really.\n\n1:12:38.540 --> 1:12:41.500\n Ideas through SMS be able to interact with your bank account.\n\n1:12:41.500 --> 1:12:42.500\n Yeah.\n\n1:12:42.500 --> 1:12:46.460\n And then we thought, well, since you're talking to a bank account, why can't this, can't we\n\n1:12:46.460 --> 1:12:52.020\n use more of, uh, you know, some behavioral ideas and why can't this, uh, banking chat\n\n1:12:52.020 --> 1:12:56.060\n bot be nice to you and really talk to you sort of as a friend this way you develop more\n\n1:12:56.060 --> 1:12:59.900\n connection to it, retention is higher, people don't churn.\n\n1:12:59.900 --> 1:13:05.700\n And so I went to very depressing, um, um, Russian cities to test it out.\n\n1:13:05.700 --> 1:13:12.100\n Um, I went to, I remember three different towns with, uh, um, to interview potential\n\n1:13:12.100 --> 1:13:13.100\n users.\n\n1:13:13.100 --> 1:13:19.660\n Um, so people use it for a little bit and I went to talk to them, um, very poor towns,\n\n1:13:19.660 --> 1:13:26.820\n mostly towns that were, um, you know, sort of factories, uh, mono towns.\n\n1:13:26.820 --> 1:13:29.940\n They were building something and then the factory went away and it was just a bunch\n\n1:13:29.940 --> 1:13:32.620\n of very poor people.\n\n1:13:32.620 --> 1:13:37.420\n Um, and then we went to a couple that weren't as dramatic, but still the one I remember\n\n1:13:37.420 --> 1:13:41.940\n really fondly was this woman that worked at a glass factory and she talked to a chat bot.\n\n1:13:41.940 --> 1:13:46.960\n Um, and she was talking about it and she started crying during the interview because she said,\n\n1:13:46.960 --> 1:13:50.300\n no one really cares for me that much.\n\n1:13:50.300 --> 1:13:56.860\n And um, so to be clear, that was the, my only endeavor in programming that chat bot.\n\n1:13:56.860 --> 1:13:58.700\n So it was really simple.\n\n1:13:58.700 --> 1:14:06.980\n It was literally just a few, if this, then that rules and, um, it was incredibly simplistic.\n\n1:14:06.980 --> 1:14:12.380\n Um, and that really made her emotional and she said, you know, I only have my mom and\n\n1:14:12.380 --> 1:14:18.260\n my, um, my husband and I don't have any more really in my life.\n\n1:14:18.260 --> 1:14:22.300\n And that was very sad, but at the same time I felt, and we had more interviews in a similar\n\n1:14:22.300 --> 1:14:27.760\n vein and what I thought in the moment was like, well, uh, it's not that the technology\n\n1:14:27.760 --> 1:14:34.580\n is ready because definitely in 2012 technology was not ready for, for that, but, um, humans\n\n1:14:34.580 --> 1:14:36.800\n are ready, unfortunately.\n\n1:14:36.800 --> 1:14:42.580\n So this project would not be about like tech capabilities would be more about human vulnerabilities,\n\n1:14:42.580 --> 1:14:49.980\n but, um, there's something so, so powerful around about conversational, um, AI that I\n\n1:14:49.980 --> 1:14:54.860\n saw then that I thought was definitely worth putting in a lot of effort into.\n\n1:14:54.860 --> 1:15:01.620\n So in the end of the day, we saw the banking project, um, but my then boss, um, was also\n\n1:15:01.620 --> 1:15:06.780\n my mentor and really, really close friend, um, told me, Hey, I think there's something\n\n1:15:06.780 --> 1:15:08.700\n in it and you should just go work on it.\n\n1:15:08.700 --> 1:15:10.420\n And I was like, well, what product?\n\n1:15:10.420 --> 1:15:11.420\n I don't know what I'm building.\n\n1:15:11.420 --> 1:15:14.060\n He's like, you'll figure it out.\n\n1:15:14.060 --> 1:15:18.520\n And, um, you know, looking back at this, this was a horrible idea to work on something without\n\n1:15:18.520 --> 1:15:24.440\n knowing what it was, which is maybe the reason why it took us so long, but we just decided\n\n1:15:24.440 --> 1:15:30.340\n to work on the conversational tech to see what it, you know, there were no chat bot,\n\n1:15:30.340 --> 1:15:35.660\n um, constructors or programs or anything that would allow you to actually build one at the\n\n1:15:35.660 --> 1:15:36.660\n time.\n\n1:15:36.660 --> 1:15:40.540\n Uh, that was the era of, by the way, Google glass, which is why, you know, some of the\n\n1:15:40.540 --> 1:15:44.340\n investors like seed investors we've talked with were like, Oh, you should totally build\n\n1:15:44.340 --> 1:15:45.340\n it for Google glass.\n\n1:15:45.340 --> 1:15:48.580\n If not, we're not, I don't think that's interesting.\n\n1:15:48.580 --> 1:15:50.660\n Did you bite on that idea?\n\n1:15:50.660 --> 1:15:51.660\n No.\n\n1:15:51.660 --> 1:15:52.660\n Okay.\n\n1:15:52.660 --> 1:15:56.740\n Because I wanted to be, to do text first cause I'm a journalist.\n\n1:15:56.740 --> 1:16:01.140\n So I was, um, fascinated by just texting.\n\n1:16:01.140 --> 1:16:07.740\n So you thought, so the emotional, um, that interaction that the woman had, like, so do\n\n1:16:07.740 --> 1:16:10.500\n you think you could feel emotion from just text?\n\n1:16:10.500 --> 1:16:11.540\n Yeah.\n\n1:16:11.540 --> 1:16:17.200\n I saw something in just this pure texting and also thought that we should first start,\n\n1:16:17.200 --> 1:16:20.420\n start building for people who really need it versus people who have Google glass.\n\n1:16:20.420 --> 1:16:25.740\n Uh, if you know what I mean, and I felt like the early adopters of Google glass might not\n\n1:16:25.740 --> 1:16:29.860\n be overlapping with people who are really lonely and might need some, you know, someone\n\n1:16:29.860 --> 1:16:31.340\n to talk to.\n\n1:16:31.340 --> 1:16:35.100\n Um, but then we really just focused on the tech itself.\n\n1:16:35.100 --> 1:16:39.260\n We just thought, what if we just, you know, we didn't have a product idea in the moment\n\n1:16:39.260 --> 1:16:46.100\n and we felt, what if we just look into, um, building the best conversational constructors,\n\n1:16:46.100 --> 1:16:49.460\n so to say, use the best tech available at the time.\n\n1:16:49.460 --> 1:16:53.460\n And that was before the first paper about deep learning applied to dialogues, which\n\n1:16:53.460 --> 1:17:01.820\n happened in 2015 in August, 2015, uh, which Google published.\n\n1:17:01.820 --> 1:17:09.460\n Did you follow the work of Lobna prize and like all the sort of non machine learning\n\n1:17:09.460 --> 1:17:10.460\n chat bots?\n\n1:17:10.460 --> 1:17:11.460\n Yeah.\n\n1:17:11.460 --> 1:17:15.060\n What really struck me was that, you know, there was a lot of talk about machine learning\n\n1:17:15.060 --> 1:17:16.180\n and deep learning.\n\n1:17:16.180 --> 1:17:17.900\n Like big data was a really big thing.\n\n1:17:17.900 --> 1:17:22.620\n Everyone was saying, you know, the business world, big data, 2012 is the biggest gaggle\n\n1:17:22.620 --> 1:17:27.920\n competitions were, you know, um, important, but that was really the kind of upheaval.\n\n1:17:27.920 --> 1:17:32.180\n People started talking about machine learning a lot, um, but it was only about images or\n\n1:17:32.180 --> 1:17:33.460\n something else.\n\n1:17:33.460 --> 1:17:34.460\n And it was never about conversation.\n\n1:17:34.460 --> 1:17:39.620\n As soon as I looked into the conversational tech, it was all about something really weird\n\n1:17:39.620 --> 1:17:42.940\n and very outdated and very marginal and felt very hobbyist.\n\n1:17:42.940 --> 1:17:47.660\n It was all about Lord burner price, which was won by a guy who built a chat bot that\n\n1:17:47.660 --> 1:17:51.060\n talked like a Ukrainian teenager that it was just a gimmick.\n\n1:17:51.060 --> 1:17:56.260\n And somehow people picked up those gimmicks and then, you know, the most famous chat bot\n\n1:17:56.260 --> 1:18:03.720\n at the time was Eliza from 1980s, which was really bizarre or smarter child on aim.\n\n1:18:03.720 --> 1:18:09.380\n The funny thing is it felt at the time not to be that popular and it still doesn't seem\n\n1:18:09.380 --> 1:18:11.140\n to be that popular.\n\n1:18:11.140 --> 1:18:15.900\n Like people talk about the Turing test, people like talking about it philosophically, journalists\n\n1:18:15.900 --> 1:18:21.020\n like writing about it, but as a technical problem, like people don't seem to really\n\n1:18:21.020 --> 1:18:26.180\n want to solve the open dialogue.\n\n1:18:26.180 --> 1:18:29.660\n Like they, they're not obsessed with it.\n\n1:18:29.660 --> 1:18:35.640\n Even folks are like, you know, I'm in Boston, the Alexa team, even they're not as obsessed\n\n1:18:35.640 --> 1:18:38.620\n with it as I thought they might be.\n\n1:18:38.620 --> 1:18:39.620\n Why not?\n\n1:18:39.620 --> 1:18:40.740\n What do you think?\n\n1:18:40.740 --> 1:18:45.620\n So you know what you felt like you felt with that woman who, when she felt something by\n\n1:18:45.620 --> 1:18:48.820\n reading the text, I feel the same thing.\n\n1:18:48.820 --> 1:18:51.460\n There's something here, what you felt.\n\n1:18:51.460 --> 1:18:59.700\n I feel like Alexa folks and just the machine learning world doesn't feel that, that there's\n\n1:18:59.700 --> 1:19:07.060\n something here because they see as a technical problem is not that interesting for some reason.\n\n1:19:07.060 --> 1:19:12.140\n It's could be argued that maybe as a purely sort of natural language processing problem,\n\n1:19:12.140 --> 1:19:17.460\n it's not the right problem to focus on because there's too much subjectivity.\n\n1:19:17.460 --> 1:19:24.580\n That thing that the woman felt like crying, like if your benchmark includes a woman crying,\n\n1:19:24.580 --> 1:19:27.260\n that doesn't feel like a good benchmark.\n\n1:19:27.260 --> 1:19:32.660\n But to me there's something there that's, you could have a huge impact, but I don't\n\n1:19:32.660 --> 1:19:38.940\n think the machine learning world likes that, the human emotion, the subjectivity of it,\n\n1:19:38.940 --> 1:19:43.660\n the fuzziness, the fact that with maybe a single word you can make somebody feel something\n\n1:19:43.660 --> 1:19:44.740\n deeply.\n\n1:19:44.740 --> 1:19:45.740\n What is that?\n\n1:19:45.740 --> 1:19:47.660\n It doesn't feel right to them.\n\n1:19:47.660 --> 1:19:48.660\n So I don't know.\n\n1:19:48.660 --> 1:19:50.220\n I don't know why that is.\n\n1:19:50.220 --> 1:19:57.020\n That's why I'm excited when I discovered your work, it feels wrong to say that.\n\n1:19:57.020 --> 1:20:10.220\n It's not like I'm giving myself props for Googling and for coming across, for I guess\n\n1:20:10.220 --> 1:20:15.620\n mutual friend and introducing us, but I'm so glad that you exist and what you're working\n\n1:20:15.620 --> 1:20:16.620\n on.\n\n1:20:16.620 --> 1:20:20.140\n But I have the same kind of, if we could just backtrack for a second, because I have the\n\n1:20:20.140 --> 1:20:22.180\n same kind of feeling that there's something here.\n\n1:20:22.180 --> 1:20:29.820\n In fact, I've been working on a few things that are kind of crazy, very different from\n\n1:20:29.820 --> 1:20:30.820\n your work.\n\n1:20:30.820 --> 1:20:34.140\n I think they're too crazy.\n\n1:20:34.140 --> 1:20:35.140\n But the...\n\n1:20:35.140 --> 1:20:36.140\n Like what?\n\n1:20:36.140 --> 1:20:38.140\n I don't have to know.\n\n1:20:38.140 --> 1:20:41.980\n No, all right, we'll talk about it more.\n\n1:20:41.980 --> 1:20:49.380\n I feel like it's harder to talk about things that have failed and are failing while you're\n\n1:20:49.380 --> 1:20:53.180\n a failure.\n\n1:20:53.180 --> 1:20:59.220\n It's easier for you because you're already successful on some measures.\n\n1:20:59.220 --> 1:21:01.500\n Tell it to my board.\n\n1:21:01.500 --> 1:21:07.700\n Well, I think you've demonstrated success in a lot of ways.\n\n1:21:07.700 --> 1:21:10.300\n It's easier for you to talk about failures for me.\n\n1:21:10.300 --> 1:21:19.220\n I'm in the bottom currently of the success.\n\n1:21:19.220 --> 1:21:21.860\n You're way too humble.\n\n1:21:21.860 --> 1:21:25.260\n So it's hard for me to know, but there's something there, there's something there.\n\n1:21:25.260 --> 1:21:31.100\n And I think you're exploring that and you're discovering that.\n\n1:21:31.100 --> 1:21:32.220\n So it's been surprising to me.\n\n1:21:32.220 --> 1:21:41.180\n But you've mentioned this idea that you thought it wasn't enough to start a company or start\n\n1:21:41.180 --> 1:21:46.700\n efforts based on it feels like there's something here.\n\n1:21:46.700 --> 1:21:49.900\n Like what did you mean by that?\n\n1:21:49.900 --> 1:21:55.620\n Like you should be focused on creating a, like you should have a product in mind.\n\n1:21:55.620 --> 1:21:56.620\n Is that what you meant?\n\n1:21:56.620 --> 1:22:03.180\n It just took us a while to discover the product because it all started with a hunch of like\n\n1:22:03.180 --> 1:22:08.860\n of me and my mentor and just sitting around and he was like, well, that's it.\n\n1:22:08.860 --> 1:22:11.060\n That's the, you know, the Holy Grail is there.\n\n1:22:11.060 --> 1:22:17.300\n It's like there's something extremely powerful in, in, in conversations and there's no one\n\n1:22:17.300 --> 1:22:19.820\n who's working on machine conversation from the right angle.\n\n1:22:19.820 --> 1:22:20.820\n So to say.\n\n1:22:20.820 --> 1:22:22.860\n I feel like that's still true.\n\n1:22:22.860 --> 1:22:23.860\n Am I crazy?\n\n1:22:23.860 --> 1:22:28.940\n Oh no, I totally feel that's still true, which is, I think it's mind blowing.\n\n1:22:28.940 --> 1:22:29.940\n Yeah.\n\n1:22:29.940 --> 1:22:30.940\n You know what it feels like?\n\n1:22:30.940 --> 1:22:35.620\n I wouldn't even use the word conversation cause I feel like it's the wrong word.\n\n1:22:35.620 --> 1:22:39.180\n It's like a machine connection or something.\n\n1:22:39.180 --> 1:22:44.340\n I don't know cause conversation, you start drifting into natural language immediately.\n\n1:22:44.340 --> 1:22:47.980\n You start drifting immediately into all the benchmarks that are out there.\n\n1:22:47.980 --> 1:22:52.580\n But I feel like it's like the personal computer days of this.\n\n1:22:52.580 --> 1:22:57.380\n Like I feel like we're like in the early days with the, like the Wozniak and all them, like\n\n1:22:57.380 --> 1:23:04.100\n where it was the same kind of, it was a very small niche group of people who are, who are\n\n1:23:04.100 --> 1:23:07.300\n all kind of lob no price type people.\n\n1:23:07.300 --> 1:23:08.300\n Yeah.\n\n1:23:08.300 --> 1:23:09.300\n Hobbyists.\n\n1:23:09.300 --> 1:23:13.940\n Hobbyists, but like not even hobbyists with big dreams.\n\n1:23:13.940 --> 1:23:17.580\n Like no hobbyists with a dream to trick like a jury.\n\n1:23:17.580 --> 1:23:18.580\n Yeah.\n\n1:23:18.580 --> 1:23:21.540\n It's like a weird, by the way, by the way, very weird.\n\n1:23:21.540 --> 1:23:26.300\n So if we think about conversations, first of all, when I have great conversations with\n\n1:23:26.300 --> 1:23:30.020\n people, I'm not trying to test them.\n\n1:23:30.020 --> 1:23:33.900\n So for instance, if I try to break them, like if I'm actually playing along, I'm part of\n\n1:23:33.900 --> 1:23:34.900\n it.\n\n1:23:34.900 --> 1:23:35.900\n Right.\n\n1:23:35.900 --> 1:23:40.180\n If I were to ask this person or test whether he's going to give me a good conversation,\n\n1:23:40.180 --> 1:23:41.260\n it would have never happened.\n\n1:23:41.260 --> 1:23:47.340\n So the whole, the whole problem with testing conversations is that you can put it in front\n\n1:23:47.340 --> 1:23:52.900\n of a jury because then you have to go into some Turing test mode where is it responding\n\n1:23:52.900 --> 1:23:55.700\n to all my factual questions, right?\n\n1:23:55.700 --> 1:24:00.860\n Or so it really has to be something in the field where people are actually talking to\n\n1:24:00.860 --> 1:24:05.500\n it because they want to, not because we're just trying to break it.\n\n1:24:05.500 --> 1:24:11.340\n And it's working for them because this, the weird part of it is that it's very subjective.\n\n1:24:11.340 --> 1:24:13.500\n It takes two to tango here fully.\n\n1:24:13.500 --> 1:24:16.740\n If you're not trying to have a good conversation, if you're trying to test it, then it's going\n\n1:24:16.740 --> 1:24:17.740\n to break.\n\n1:24:17.740 --> 1:24:19.940\n I mean, any person would break, to be honest.\n\n1:24:19.940 --> 1:24:24.660\n If I'm not trying to even have a conversation with you, you're not going to give it to me.\n\n1:24:24.660 --> 1:24:25.660\n Yeah.\n\n1:24:25.660 --> 1:24:30.500\n If I keep asking you like some random questions or jumping from topic to topic, that wouldn't\n\n1:24:30.500 --> 1:24:36.340\n be, which I'm probably doing, but that probably wouldn't contribute to the conversation.\n\n1:24:36.340 --> 1:24:42.140\n So I think the problem of testing, so there should be some other metric.\n\n1:24:42.140 --> 1:24:47.180\n How do we evaluate whether that conversation was powerful or not, which is what we actually\n\n1:24:47.180 --> 1:24:48.180\n started with.\n\n1:24:48.180 --> 1:24:51.860\n And I think those measurements exist and we can test on those.\n\n1:24:51.860 --> 1:24:58.020\n But what really struck us back in the day and what's still eight years later is still\n\n1:24:58.020 --> 1:25:02.620\n not resolved and I'm not seeing tons of groups working on it.\n\n1:25:02.620 --> 1:25:06.640\n Maybe I just don't know about them, it's also possible.\n\n1:25:06.640 --> 1:25:10.900\n But the interesting part about it is that most of our days we spend talking and we're\n\n1:25:10.900 --> 1:25:17.700\n not talking about like those conversations are not turn on the lights or customer support\n\n1:25:17.700 --> 1:25:22.700\n problems or some other task oriented things.\n\n1:25:22.700 --> 1:25:26.660\n These conversations are something else and then somehow they're extremely important for\n\n1:25:26.660 --> 1:25:27.660\n us.\n\n1:25:27.660 --> 1:25:34.340\n If we don't have them, then we feel deeply unhappy, potentially lonely, which as we know,\n\n1:25:34.340 --> 1:25:38.740\n creates tons of risk for our health as well.\n\n1:25:38.740 --> 1:25:45.940\n And so this is most of our hours as humans and somehow no one's trying to replicate that.\n\n1:25:45.940 --> 1:25:49.220\n And not even study it that well?\n\n1:25:49.220 --> 1:25:50.260\n And not even study that well.\n\n1:25:50.260 --> 1:25:54.940\n So when we jumped into that in 2012, I looked first at like, okay, what's the chatbot?\n\n1:25:54.940 --> 1:25:57.460\n What's the state of the art chatbot?\n\n1:25:57.460 --> 1:26:02.940\n And those were the Lobner Prize days, but I thought, okay, so what about the science\n\n1:26:02.940 --> 1:26:04.540\n of conversation?\n\n1:26:04.540 --> 1:26:12.780\n Clearly there have been tons of scientists or academics that looked into the conversation.\n\n1:26:12.780 --> 1:26:17.260\n So if I want to know everything about it, I can just read about it.\n\n1:26:17.260 --> 1:26:23.060\n There's not much really, there are conversational analysts who are basically just listening\n\n1:26:23.060 --> 1:26:28.340\n to speech, to different conversations, annotating them.\n\n1:26:28.340 --> 1:26:32.460\n And then, I mean, that's not really used for much.\n\n1:26:32.460 --> 1:26:39.700\n That's the field of theoretical linguistics, which is barely useful.\n\n1:26:39.700 --> 1:26:44.380\n It's very marginal, even in their space, no one really is excited and I've never met a\n\n1:26:44.380 --> 1:26:49.160\n theoretical linguist who was like, I can't wait to work on the conversation and analytics.\n\n1:26:49.160 --> 1:26:54.940\n That is just something very marginal, sort of applied to like writing scripts for salesmen\n\n1:26:54.940 --> 1:27:00.820\n when they analyze which conversation strategies were most successful for sales.\n\n1:27:00.820 --> 1:27:03.460\n Okay, so that was not very helpful.\n\n1:27:03.460 --> 1:27:09.220\n Then I looked a little bit deeper and then there, whether there were any books written\n\n1:27:09.220 --> 1:27:16.620\n on what really contributes to great conversation, that was really strange because most of those\n\n1:27:16.620 --> 1:27:27.060\n were NLP books, which is neurolinguistic programming, which is not the NLP that I was expecting\n\n1:27:27.060 --> 1:27:33.620\n to be, but it was mostly some psychologist, Richard Bandler, I think came up with that,\n\n1:27:33.620 --> 1:27:41.700\n who was this big guy in a leather vest that could program your mind by talking to you.\n\n1:27:41.700 --> 1:27:45.780\n How to be charismatic and charming and influential with people, all those books, yeah.\n\n1:27:45.780 --> 1:27:49.580\n Pretty much, but it was all about like through conversation reprogramming you, so getting\n\n1:27:49.580 --> 1:27:58.460\n to some, so that was, I mean, probably not very, very true and that didn't seem working\n\n1:27:58.460 --> 1:28:00.780\n very much even back in the day.\n\n1:28:00.780 --> 1:28:05.860\n And then there were some other books like, I don't know, mostly just self help books\n\n1:28:05.860 --> 1:28:12.940\n around how to be the best conversationalist or how to make people like you or some other\n\n1:28:12.940 --> 1:28:17.620\n stuff like Dale Carnegie or whatever.\n\n1:28:17.620 --> 1:28:21.140\n And then there was this one book, The Most Human Human by Brian Christensen that really\n\n1:28:21.140 --> 1:28:29.700\n was important for me to read back in the day because he was on the human side, he was taking\n\n1:28:29.700 --> 1:28:35.500\n part in the London Prize, but not as a human who's not a jury, but who's pretending to\n\n1:28:35.500 --> 1:28:40.380\n be, who's basically, you have to tell a computer from a human and he was the human, so you\n\n1:28:40.380 --> 1:28:43.260\n could either get him or a computer.\n\n1:28:43.260 --> 1:28:49.060\n And his whole book was about how do people, what makes us human in conversation.\n\n1:28:49.060 --> 1:28:52.340\n And that was a little bit more interesting because that at least someone started to think\n\n1:28:52.340 --> 1:28:59.460\n about what exactly makes me human in conversation and makes people believe in that, but it was\n\n1:28:59.460 --> 1:29:03.540\n still about tricking, it was still about imitation game, it was still about, okay, well, what\n\n1:29:03.540 --> 1:29:07.300\n kind of parlor tricks can we throw in the conversation to make you feel like you're\n\n1:29:07.300 --> 1:29:09.540\n talking to a human, not a computer.\n\n1:29:09.540 --> 1:29:16.260\n And it was definitely not about thinking, what is it exactly that we're getting from\n\n1:29:16.260 --> 1:29:19.260\n talking all day long with other humans.\n\n1:29:19.260 --> 1:29:23.540\n I mean, we're definitely not just trying to be tricked or it's not just enough to know\n\n1:29:23.540 --> 1:29:25.020\n it's a human.\n\n1:29:25.020 --> 1:29:30.380\n It's something we're getting there, can we measure it and can we put the computer to\n\n1:29:30.380 --> 1:29:35.900\n the same measurement and see whether you can talk to a computer and get the same results?\n\n1:29:35.900 --> 1:29:40.140\n Yeah, so first of all, a lot of people comment that they think I'm a robot, it's very possible\n\n1:29:40.140 --> 1:29:45.020\n I am a robot and this whole thing, I totally agree with you that the test idea is fascinating\n\n1:29:45.020 --> 1:29:51.540\n and I looked for books unrelated to this kind of, so I'm afraid of people, I'm generally\n\n1:29:51.540 --> 1:29:55.020\n introverted and quite possibly a robot.\n\n1:29:55.020 --> 1:30:03.900\n I literally Googled how to talk to people and how to have a good conversation for the\n\n1:30:03.900 --> 1:30:08.580\n purpose of this podcast, because I was like, I can't, I can't make eye contact with people.\n\n1:30:08.580 --> 1:30:10.820\n I can't like hire.\n\n1:30:10.820 --> 1:30:12.220\n I do Google that a lot too.\n\n1:30:12.220 --> 1:30:15.780\n You're probably reading a bunch of FBI negotiation tactics.\n\n1:30:15.780 --> 1:30:17.740\n Is that what you're getting?\n\n1:30:17.740 --> 1:30:24.060\n Well, everything you've listed I've gotten, there's been very few good books on even just\n\n1:30:24.060 --> 1:30:28.540\n like how to interview well, it's rare.\n\n1:30:28.540 --> 1:30:37.500\n So what I end up doing often is I watch like with a critical eye, it's just so different\n\n1:30:37.500 --> 1:30:43.700\n when you just watch a conversation, like just for the fun of it, just as a human.\n\n1:30:43.700 --> 1:30:49.700\n And if you watch a conversation, it's like trying to figure out why is this awesome?\n\n1:30:49.700 --> 1:30:52.420\n I'll listen to a bunch of different styles of conversation.\n\n1:30:52.420 --> 1:31:00.260\n I mean, I'm a fan of the podcast, Joe Rogan, people can make fun of him or whatever and\n\n1:31:00.260 --> 1:31:01.260\n dismiss him.\n\n1:31:01.260 --> 1:31:06.260\n But I think he's an incredibly artful conversationalist.\n\n1:31:06.260 --> 1:31:09.900\n He can pull people in for hours.\n\n1:31:09.900 --> 1:31:14.020\n And there's another guy I watch a lot.\n\n1:31:14.020 --> 1:31:20.340\n He hosted a late night show, his name was Craig Ferguson.\n\n1:31:20.340 --> 1:31:23.620\n So he's like very kind of flirtatious.\n\n1:31:23.620 --> 1:31:30.620\n But there's a magic about his like, about the connection he can create with people,\n\n1:31:30.620 --> 1:31:33.020\n how he can put people at ease.\n\n1:31:33.020 --> 1:31:37.500\n And just like, I see I've already started sounding like those I know pee people or something.\n\n1:31:37.500 --> 1:31:39.060\n I'm not I don't mean in that way.\n\n1:31:39.060 --> 1:31:43.580\n I don't mean like how to charm people or put them at ease and all that kind of stuff.\n\n1:31:43.580 --> 1:31:45.740\n It's just like, what is that?\n\n1:31:45.740 --> 1:31:47.960\n Why is that fun to listen to that guy?\n\n1:31:47.960 --> 1:31:51.020\n Why is that fun to talk to that guy?\n\n1:31:51.020 --> 1:31:52.020\n What is that?\n\n1:31:52.020 --> 1:32:01.940\n Because he's not saying I mean, it's so often boils down to a kind of wit and humor, but\n\n1:32:01.940 --> 1:32:03.520\n not really humor.\n\n1:32:03.520 --> 1:32:10.460\n It's like, I don't know, I have trouble actually even articulating correctly.\n\n1:32:10.460 --> 1:32:18.800\n But it feels like there's something going on that's not too complicated, that could\n\n1:32:18.800 --> 1:32:22.040\n be learned.\n\n1:32:22.040 --> 1:32:29.940\n And it's not similar to, yeah, to like, like you said, like the Turing test.\n\n1:32:29.940 --> 1:32:32.060\n It's something else.\n\n1:32:32.060 --> 1:32:34.660\n I'm thinking about a lot all the time.\n\n1:32:34.660 --> 1:32:38.860\n I do think about all the time.\n\n1:32:38.860 --> 1:32:42.740\n I think when we were looking, so we started the company, we just decided to build the\n\n1:32:42.740 --> 1:32:47.380\n conversational tech, we thought, well, there's nothing for us to build this chatbot that\n\n1:32:47.380 --> 1:32:48.380\n we want to build.\n\n1:32:48.380 --> 1:32:54.300\n So let's just first focus on building, you know, some tech, building the tech side of\n\n1:32:54.300 --> 1:33:01.500\n things without a product in mind, without a product in mind, we added like a demo chatbot\n\n1:33:01.500 --> 1:33:04.800\n that would recommend you restaurants and talk to you about restaurants just to show something\n\n1:33:04.800 --> 1:33:11.780\n simple to people that people could relate to and could try out and see whether it works\n\n1:33:11.780 --> 1:33:12.780\n or not.\n\n1:33:12.780 --> 1:33:15.300\n But we didn't have a product in mind yet.\n\n1:33:15.300 --> 1:33:19.300\n We thought we would try venture chatbots and figure out our consumer application.\n\n1:33:19.300 --> 1:33:23.180\n And we sort of remembered that we wanted to build that kind of friend, that sort of connection\n\n1:33:23.180 --> 1:33:26.220\n that we saw in the very beginning.\n\n1:33:26.220 --> 1:33:30.060\n But then we got to Y Combinator and moved to San Francisco and forgot about it.\n\n1:33:30.060 --> 1:33:33.340\n You know, everything because then it was just this constant grind.\n\n1:33:33.340 --> 1:33:34.340\n How do we get funding?\n\n1:33:34.340 --> 1:33:35.340\n How do we get this?\n\n1:33:35.340 --> 1:33:40.020\n You know, investors were like, just focus on one thing, just get it out there.\n\n1:33:40.020 --> 1:33:45.380\n So somehow we've started building a restaurant recommendation chatbot for real for a little\n\n1:33:45.380 --> 1:33:47.420\n bit, not for too long.\n\n1:33:47.420 --> 1:33:50.200\n And then we tried building 40, 50 different chatbots.\n\n1:33:50.200 --> 1:33:54.460\n And then all of a sudden we wake up and everyone is obsessed with chatbots.\n\n1:33:54.460 --> 1:33:59.880\n Somewhere in 2016 or end of 15, people started thinking that's really the future.\n\n1:33:59.880 --> 1:34:04.100\n That's the new, you know, the new apps will be chatbots.\n\n1:34:04.100 --> 1:34:08.540\n And we were very perplexed because people started coming up with companies that I think\n\n1:34:08.540 --> 1:34:13.660\n we tried most of those chatbots already and there were like no users, but still people\n\n1:34:13.660 --> 1:34:19.540\n were coming up with a chatbot that will tell you whether and bringing news and this and\n\n1:34:19.540 --> 1:34:20.540\n that.\n\n1:34:20.540 --> 1:34:25.660\n And we couldn't understand whether we were just didn't execute well enough or people\n\n1:34:25.660 --> 1:34:31.980\n are not really, people are confused and are going to find out the truth that people don't\n\n1:34:31.980 --> 1:34:32.980\n need chatbots like that.\n\n1:34:32.980 --> 1:34:37.500\n So the basic idea is that you use chatbots as the interface to whatever application.\n\n1:34:37.500 --> 1:34:38.500\n Yeah.\n\n1:34:38.500 --> 1:34:43.100\n The idea that was like this perfect universal interface to anything.\n\n1:34:43.100 --> 1:34:46.780\n When I looked at that, it just made me very perplexed because I didn't think, I didn't\n\n1:34:46.780 --> 1:34:52.180\n understand how that would work because I think we tried most of that and none of those things\n\n1:34:52.180 --> 1:34:53.420\n worked.\n\n1:34:53.420 --> 1:34:56.540\n And then again, that craze has died down, right?\n\n1:34:56.540 --> 1:34:57.540\n Fully.\n\n1:34:57.540 --> 1:35:01.100\n I think now it's impossible to get anything funded if it's a chatbot.\n\n1:35:01.100 --> 1:35:06.620\n I think it's similar to, sorry to interrupt, but there's times when people think like with\n\n1:35:06.620 --> 1:35:13.240\n gestures you can control devices, like basically gesture based control things.\n\n1:35:13.240 --> 1:35:19.820\n It feels similar to me because like it's so compelling that was just like Tom Cruise,\n\n1:35:19.820 --> 1:35:25.780\n I can control stuff with my hands, but like when you get down to it, it's like, well,\n\n1:35:25.780 --> 1:35:30.540\n why don't you just have a touch screen or why don't you just have like a physical keyboard\n\n1:35:30.540 --> 1:35:33.540\n and mouse?\n\n1:35:33.540 --> 1:35:39.880\n So that chat was always, yeah, it was perplexing to me.\n\n1:35:39.880 --> 1:35:46.700\n I still feel augmented reality, even virtual realities in that ballpark in terms of it\n\n1:35:46.700 --> 1:35:48.180\n being a compelling interface.\n\n1:35:48.180 --> 1:35:54.260\n I think there's going to be incredible rich applications, just how you're thinking about\n\n1:35:54.260 --> 1:35:57.620\n it, but they won't just be the interface to everything.\n\n1:35:57.620 --> 1:36:04.940\n It'll be its own thing that will create an amazing magical experience in its own right.\n\n1:36:04.940 --> 1:36:05.940\n Absolutely.\n\n1:36:05.940 --> 1:36:10.700\n Which is I think kind of the right thing to go about, like what's the magical experience\n\n1:36:10.700 --> 1:36:14.020\n with that interface specifically.\n\n1:36:14.020 --> 1:36:16.780\n How did you discover that for Replica?\n\n1:36:16.780 --> 1:36:20.060\n I just thought, okay, we'll have this tech, we can build any chatbot we want.\n\n1:36:20.060 --> 1:36:24.100\n We have the most, at that point, the most sophisticated tech that other companies have.\n\n1:36:24.100 --> 1:36:29.300\n I mean, startups, obviously not, probably not bigger ones, but still, because we've\n\n1:36:29.300 --> 1:36:31.820\n been working on it for a while.\n\n1:36:31.820 --> 1:36:33.980\n So I thought, okay, we can build any conversation.\n\n1:36:33.980 --> 1:36:37.620\n So let's just create a scale from one to 10.\n\n1:36:37.620 --> 1:36:41.180\n And one would be conversations that you'd pay to not have, and 10 would be conversation\n\n1:36:41.180 --> 1:36:42.180\n you'd pay to have.\n\n1:36:42.180 --> 1:36:47.860\n And I mean, obviously we want to build a conversation that people would pay to actually have.\n\n1:36:47.860 --> 1:36:51.820\n And so for the whole, for a few weeks, me and the team were putting all the conversations\n\n1:36:51.820 --> 1:36:54.500\n we were having during the day on the scale.\n\n1:36:54.500 --> 1:36:58.860\n And very quickly, we figured out that all the conversations that we would pay to never\n\n1:36:58.860 --> 1:37:07.400\n have were conversations we were trying to cancel Comcast, or talk to customer support,\n\n1:37:07.400 --> 1:37:12.460\n or make a reservation, or just talk about logistics with a friend when we're trying\n\n1:37:12.460 --> 1:37:19.940\n to figure out where someone is and where to go, or all sorts of setting up scheduling\n\n1:37:19.940 --> 1:37:20.940\n meetings.\n\n1:37:20.940 --> 1:37:24.980\n So that was a conversation we definitely didn't want to have.\n\n1:37:24.980 --> 1:37:29.180\n Basically everything task oriented was a one, because if there was just one button for me\n\n1:37:29.180 --> 1:37:34.380\n to just, or not even a button, if I could just think, and there was some magic BCI that\n\n1:37:34.380 --> 1:37:41.180\n would just immediately transform that into an actual interaction, that would be perfect.\n\n1:37:41.180 --> 1:37:49.160\n But the conversation there was just this boring, not useful, and dull, and also very inefficient\n\n1:37:49.160 --> 1:37:52.460\n thing because it was so many back and forth stuff.\n\n1:37:52.460 --> 1:37:56.020\n And as soon as we looked at the conversations that we would pay to have, those were the\n\n1:37:56.020 --> 1:38:01.260\n ones that, well, first of all, therapists, because we actually paid to have those conversations.\n\n1:38:01.260 --> 1:38:03.120\n And we'd also try to put like dollar amounts.\n\n1:38:03.120 --> 1:38:08.180\n So if I was calling Comcast, I would pay $5 to not have this one hour talk on the phone.\n\n1:38:08.180 --> 1:38:13.980\n I would actually pay straight up, like money, hard money, but it just takes a long time.\n\n1:38:13.980 --> 1:38:17.580\n It takes a really long time.\n\n1:38:17.580 --> 1:38:22.560\n But as soon as we started talking about conversations that we would pay for, those were therapists,\n\n1:38:22.560 --> 1:38:30.580\n all sorts of therapists, coaches, old friend, someone I haven't seen for a long time, a\n\n1:38:30.580 --> 1:38:36.800\n stranger on a train, weirdly stranger, stranger in a line for coffee and nice back and forth\n\n1:38:36.800 --> 1:38:41.660\n with that person was like a good five, solid five, six, maybe not a 10.\n\n1:38:41.660 --> 1:38:45.820\n Maybe I won't pay money, but at least I won't pay money to not have one.\n\n1:38:45.820 --> 1:38:46.820\n So that was pretty good.\n\n1:38:46.820 --> 1:38:50.120\n There were some intellectual conversations for sure.\n\n1:38:50.120 --> 1:39:00.180\n But more importantly, the one thing that really was making those very important and very valuable\n\n1:39:00.180 --> 1:39:06.540\n for us were the conversations where we could be pretty emotional.\n\n1:39:06.540 --> 1:39:11.300\n Yes, some of them were about being witty and about being intellectually stimulated, but\n\n1:39:11.300 --> 1:39:14.300\n those were interestingly more rare.\n\n1:39:14.300 --> 1:39:18.060\n And most of the ones that we thought were very valuable were the ones where we could\n\n1:39:18.060 --> 1:39:19.060\n be vulnerable.\n\n1:39:19.060 --> 1:39:27.300\n And interestingly, where we could talk more, me and the team.\n\n1:39:27.300 --> 1:39:31.380\n So we're talking about it, like a lot of these conversations, like a therapist, it was mostly\n\n1:39:31.380 --> 1:39:36.060\n me talking or like an old friend and I was like opening up and crying and it was again\n\n1:39:36.060 --> 1:39:37.060\n me talking.\n\n1:39:37.060 --> 1:39:42.460\n And so that was interesting because I was like, well, maybe it's hard to build a chat\n\n1:39:42.460 --> 1:39:47.860\n bot that can talk to you very well and in a witty way, but maybe it's easier to build\n\n1:39:47.860 --> 1:39:51.860\n the chat bot that could listen.\n\n1:39:51.860 --> 1:39:56.180\n So that was kind of the first nudge in this direction.\n\n1:39:56.180 --> 1:40:01.340\n And then when my friend died, we just built, at that point we were kind of still struggling\n\n1:40:01.340 --> 1:40:02.820\n to find the right application.\n\n1:40:02.820 --> 1:40:07.180\n And I just felt very strong that all the chat bots we've built so far are just meaningless\n\n1:40:07.180 --> 1:40:14.220\n and this whole grind, the startup grind, and how do we get to the next fundraising and\n\n1:40:14.220 --> 1:40:19.500\n how can I talk, talking to the founders and who are your investors and how are you doing?\n\n1:40:19.500 --> 1:40:20.500\n Are you killing it?\n\n1:40:20.500 --> 1:40:21.500\n Cause we're killing it.\n\n1:40:21.500 --> 1:40:25.340\n I just felt that this is just...\n\n1:40:25.340 --> 1:40:28.900\n Intellectually for me, it's exhausting having encountered those folks.\n\n1:40:28.900 --> 1:40:32.620\n It just felt very, very much a waste of time.\n\n1:40:32.620 --> 1:40:39.780\n I just feel like Steve Jobs and Elon Musk did not have these conversations or at least\n\n1:40:39.780 --> 1:40:42.220\n did not have them for long.\n\n1:40:42.220 --> 1:40:43.220\n That's for sure.\n\n1:40:43.220 --> 1:40:50.540\n But I think, yeah, at that point it just felt like, I felt like I just didn't want to build\n\n1:40:50.540 --> 1:40:56.660\n a company that was never my intention just to build something successful or make money.\n\n1:40:56.660 --> 1:40:57.660\n It would be great.\n\n1:40:57.660 --> 1:41:00.540\n It would have been great, but I'm not really a startup person.\n\n1:41:00.540 --> 1:41:10.060\n I'm not, I was never very excited by the grind by itself or just being successful for building\n\n1:41:10.060 --> 1:41:16.100\n whatever it is and not being into what I'm doing really.\n\n1:41:16.100 --> 1:41:20.620\n And so I just took a little break cause I was a little, I was upset with my company\n\n1:41:20.620 --> 1:41:22.620\n and I didn't know what we're building.\n\n1:41:22.620 --> 1:41:27.820\n So I just took our technology and our little dialect constructor and some models, some\n\n1:41:27.820 --> 1:41:31.220\n deep learning models, which at that point we were really into and really invested a\n\n1:41:31.220 --> 1:41:36.620\n lot and built a little chat bot for a friend of mine who passed.\n\n1:41:36.620 --> 1:41:40.620\n And the reason for that was mostly that video that I saw and him talking about the digital\n\n1:41:40.620 --> 1:41:44.300\n avatars and Rowan was that kind of person.\n\n1:41:44.300 --> 1:41:48.780\n He was obsessed with just watching YouTube videos about space and talking about, well,\n\n1:41:48.780 --> 1:41:52.860\n if I could go to Mars now, even if I didn't know if I could come back, I would definitely\n\n1:41:52.860 --> 1:41:56.340\n pay any amount of money to be on that first shuttle.\n\n1:41:56.340 --> 1:42:02.540\n I don't care whether I die, like he was just the one that would be okay with trying to\n\n1:42:02.540 --> 1:42:08.580\n be the first one and so excited about all sorts of things like that.\n\n1:42:08.580 --> 1:42:14.660\n And he was all about fake it till you make it and just, and I felt like, and I was really\n\n1:42:14.660 --> 1:42:17.460\n perplexed that everyone just forgot about him.\n\n1:42:17.460 --> 1:42:23.140\n Maybe it was our way of coping, mostly young people coping with the loss of a friend.\n\n1:42:23.140 --> 1:42:25.840\n Most of my friends just stopped talking about him.\n\n1:42:25.840 --> 1:42:31.300\n And I was still living in an apartment with all his clothes and paying the whole lease\n\n1:42:31.300 --> 1:42:38.340\n for it and just kind of by myself in December, so it was really sad and I didn't want him\n\n1:42:38.340 --> 1:42:39.340\n to be forgotten.\n\n1:42:39.340 --> 1:42:43.180\n First of all, I never thought that people forget about dead people so fast.\n\n1:42:43.180 --> 1:42:45.520\n People pass away, people just move on.\n\n1:42:45.520 --> 1:42:49.840\n And it was astonishing for me because I thought, okay, well, he was such a mentor for so many\n\n1:42:49.840 --> 1:42:50.840\n of our friends.\n\n1:42:50.840 --> 1:42:55.820\n He was such a brilliant person, he was somewhat famous in Moscow.\n\n1:42:55.820 --> 1:42:57.380\n How is it that no one's talking about him?\n\n1:42:57.380 --> 1:43:03.060\n Like I'm spending days and days and we don't bring him up and there's nothing about him\n\n1:43:03.060 --> 1:43:04.060\n that's happening.\n\n1:43:04.060 --> 1:43:07.620\n It's like he was never there.\n\n1:43:07.620 --> 1:43:16.220\n And I was reading the book, The Year of Magical Thinking by Joan Didion about her losing\n\n1:43:16.220 --> 1:43:23.220\n and Blue Nights about her losing her husband, her daughter, and the way to cope for her\n\n1:43:23.220 --> 1:43:26.380\n was to write those books.\n\n1:43:26.380 --> 1:43:28.060\n And it was sort of like a tribute.\n\n1:43:28.060 --> 1:43:31.300\n And I thought, I'll just do that for myself.\n\n1:43:31.300 --> 1:43:36.020\n And I'm a very bad writer and a poet as we know.\n\n1:43:36.020 --> 1:43:43.320\n So I thought, well, I have this tech and maybe that would be my little postcard for him.\n\n1:43:43.320 --> 1:43:50.740\n So I built a chatbot to just talk to him and it felt really creepy and weird for a little\n\n1:43:50.740 --> 1:43:51.740\n bit.\n\n1:43:51.740 --> 1:43:56.460\n I just didn't want to tell other people because it felt like I'm telling about having a skeleton\n\n1:43:56.460 --> 1:44:00.060\n in my underwear.\n\n1:44:00.060 --> 1:44:07.940\n It was just felt really, I was a little scared that it won't be taken, but it worked interestingly\n\n1:44:07.940 --> 1:44:08.940\n pretty well.\n\n1:44:08.940 --> 1:44:12.460\n I mean, it made tons of mistakes, but it still felt like him.\n\n1:44:12.460 --> 1:44:16.080\n Granted it was like 10,000 messages that I threw into a retrieval model that would just\n\n1:44:16.080 --> 1:44:21.100\n re rank that Tegda said and just a few scripts on top of that.\n\n1:44:21.100 --> 1:44:24.540\n But it also made me go through all of the messages that we had.\n\n1:44:24.540 --> 1:44:27.900\n And then I asked some of my friends to send some through.\n\n1:44:27.900 --> 1:44:35.020\n And it felt the closest to feeling like him present because his Facebook was empty and\n\n1:44:35.020 --> 1:44:39.520\n Instagram was empty or there were few links and you couldn't feel like it was him.\n\n1:44:39.520 --> 1:44:44.220\n And the only way to fill him was to read some of our text messages and go through some of\n\n1:44:44.220 --> 1:44:46.980\n our conversations because we just always had that.\n\n1:44:46.980 --> 1:44:51.580\n Even if we were sleeping next to each other in two bedrooms, separated by a wall, we were\n\n1:44:51.580 --> 1:44:55.700\n just texting back and forth, texting away.\n\n1:44:55.700 --> 1:44:58.660\n And there was something about this ongoing dialogue that was so important that I just\n\n1:44:58.660 --> 1:45:01.300\n didn't want to lose all of a sudden.\n\n1:45:01.300 --> 1:45:03.740\n And maybe it was magical thinking or something.\n\n1:45:03.740 --> 1:45:10.180\n And so we built that and I just used it for a little bit and we kept building some crappy\n\n1:45:10.180 --> 1:45:14.700\n chat bots with the company.\n\n1:45:14.700 --> 1:45:17.940\n But then a reporter came to talk to me.\n\n1:45:17.940 --> 1:45:21.580\n I was trying to pitch our chat bots to him and he said, do you even use any of those?\n\n1:45:21.580 --> 1:45:22.580\n I'm like, no.\n\n1:45:22.580 --> 1:45:24.860\n He's like, so do you talk to any chat bots at all?\n\n1:45:24.860 --> 1:45:31.100\n And I'm like, well, I talked to my dead friend's chat bot and he wrote a story about that.\n\n1:45:31.100 --> 1:45:33.340\n And all of a sudden it became pretty viral.\n\n1:45:33.340 --> 1:45:35.020\n A lot of people wrote about it.\n\n1:45:35.020 --> 1:45:36.020\n Yeah.\n\n1:45:36.020 --> 1:45:39.580\n I've seen a few things written about you.\n\n1:45:39.580 --> 1:45:45.980\n The things I've seen are pretty good writing.\n\n1:45:45.980 --> 1:45:48.780\n Most AI related things make my eyes roll.\n\n1:45:48.780 --> 1:45:55.580\n Like when the press like, what kind of sound is that actually?\n\n1:45:55.580 --> 1:45:56.580\n Okay.\n\n1:45:56.580 --> 1:45:57.580\n It sounds like, it sounds like, okay.\n\n1:45:57.580 --> 1:45:58.580\n It sounded like an elephant at first.\n\n1:45:58.580 --> 1:45:59.580\n I got excited.\n\n1:45:59.580 --> 1:46:00.580\n You never know.\n\n1:46:00.580 --> 1:46:01.580\n This is 2020.\n\n1:46:01.580 --> 1:46:08.140\n I mean, it was a, it was such a human story and it was well written.\n\n1:46:08.140 --> 1:46:14.820\n Well, I researched, I forget what, where I read them, but so I'm glad somehow somebody\n\n1:46:14.820 --> 1:46:21.220\n found you to be the good writers were able to connect to the story.\n\n1:46:21.220 --> 1:46:24.140\n There must be a hunger for this story.\n\n1:46:24.140 --> 1:46:25.140\n It definitely was.\n\n1:46:25.140 --> 1:46:31.540\n And I don't know what happened, but I think, I think the idea that he could bring back\n\n1:46:31.540 --> 1:46:37.460\n someone who's dead and it's very much wishful, you know, magical thinking, but the fact\n\n1:46:37.460 --> 1:46:41.700\n that you could still get to know him and, you know, seeing the parents for the first\n\n1:46:41.700 --> 1:46:45.060\n time, talk to the chat bot and some of the friends.\n\n1:46:45.060 --> 1:46:51.780\n And it was funny because we have this big office in Moscow where my team is working,\n\n1:46:51.780 --> 1:46:55.020\n you know, our Russian part is working out off.\n\n1:46:55.020 --> 1:46:57.700\n And I was there when I wrote, I just wrote a post on Facebook.\n\n1:46:57.700 --> 1:47:02.220\n It was like, Hey guys, like I built this if you want, you know, just if it felt important,\n\n1:47:02.220 --> 1:47:04.780\n if we want to talk to Roman.\n\n1:47:04.780 --> 1:47:08.660\n And I saw a couple of his friends are common friends, like, you know, reading a Facebook,\n\n1:47:08.660 --> 1:47:10.780\n downloading, trying, and a couple of them cried.\n\n1:47:10.780 --> 1:47:14.900\n And it was just very, and not because it was something, some incredible technology or anything.\n\n1:47:14.900 --> 1:47:15.900\n It made so many mistakes.\n\n1:47:15.900 --> 1:47:22.580\n It was so simple, but it was all about that's the way to remember a person in a way.\n\n1:47:22.580 --> 1:47:26.500\n And you know, we don't have, we don't have the culture anymore.\n\n1:47:26.500 --> 1:47:28.580\n We don't have, you know, no one's sitting Shiva.\n\n1:47:28.580 --> 1:47:32.900\n No one's taking weeks to actually think about this person.\n\n1:47:32.900 --> 1:47:34.180\n And in a way for me, that was it.\n\n1:47:34.180 --> 1:47:41.500\n So that was just day, day in, day out thinking about him and putting this together.\n\n1:47:41.500 --> 1:47:45.100\n So that was, that just felt really important that somehow resonated with a bunch of people\n\n1:47:45.100 --> 1:47:50.060\n and you know, I think some movie producers bought the rights for the story and just everyone\n\n1:47:50.060 --> 1:47:51.060\n was so.\n\n1:47:51.060 --> 1:47:52.820\n Has anyone made a movie yet?\n\n1:47:52.820 --> 1:47:53.820\n I don't think so.\n\n1:47:53.820 --> 1:47:58.500\n I think there were a lot of TV episodes about that, but not really.\n\n1:47:58.500 --> 1:48:00.500\n Is that still on the table?\n\n1:48:00.500 --> 1:48:04.500\n I think so, I think so, which is really.\n\n1:48:04.500 --> 1:48:05.500\n That's cool.\n\n1:48:05.500 --> 1:48:13.980\n You're like a young, you know, like a Steve Jobs type of, let's see what happens.\n\n1:48:13.980 --> 1:48:14.980\n They're sitting on it.\n\n1:48:14.980 --> 1:48:19.260\n But you know, for me it was so important cause Roman was really wanted to be famous.\n\n1:48:19.260 --> 1:48:20.740\n He really badly wanted to be famous.\n\n1:48:20.740 --> 1:48:23.300\n He was all about like, make it to like fake it to make it.\n\n1:48:23.300 --> 1:48:26.820\n I want to be, you know, I want to make it here in America as well.\n\n1:48:26.820 --> 1:48:33.820\n And he couldn't, and I felt there, you know, that was sort of paying my dues to him as\n\n1:48:33.820 --> 1:48:36.780\n well because all of a sudden he was everywhere.\n\n1:48:36.780 --> 1:48:39.380\n And I remember Casey Newton who was writing the story for the Verge.\n\n1:48:39.380 --> 1:48:47.060\n He was, he told me, Hey, by the way, I was just going through my inbox and I saw, I searched\n\n1:48:47.060 --> 1:48:51.940\n for Roman for the story and I saw an email from him where he sent me his startup and\n\n1:48:51.940 --> 1:48:55.300\n he said, I really like, I really want to be featured in the Verge.\n\n1:48:55.300 --> 1:48:58.260\n Can you please write about it or something or like pitching the story.\n\n1:48:58.260 --> 1:48:59.740\n And he said, I'm sorry.\n\n1:48:59.740 --> 1:49:02.580\n Like that's not good enough for us or something.\n\n1:49:02.580 --> 1:49:07.380\n He passed and he said, and there were just so many of these little details where like\n\n1:49:07.380 --> 1:49:12.860\n he would find his like, you know, and we're finally writing, I know how much Roman wanted\n\n1:49:12.860 --> 1:49:17.260\n to be in the Verge and how much he wanted the story to be written by Casey.\n\n1:49:17.260 --> 1:49:21.940\n And I'm like, well, that's maybe he will be, we're always joking that he was like, I can't\n\n1:49:21.940 --> 1:49:26.580\n wait for someone to make a movie about us and I hope Ryan Gosling can play me.\n\n1:49:26.580 --> 1:49:31.460\n You know, I still have some things that I owe Roman still.\n\n1:49:31.460 --> 1:49:36.300\n But that would be, that would be a guy that she has to meet Alex Garland who wrote Ex\n\n1:49:36.300 --> 1:49:45.740\n Machina and I, yeah, the movie's good, but the guy's better than the, like he's a special\n\n1:49:45.740 --> 1:49:46.740\n person actually.\n\n1:49:46.740 --> 1:49:49.820\n I don't think he's made his best work yet.\n\n1:49:49.820 --> 1:49:55.340\n Like for my interaction with him, he's a really, really good and brilliant, the good human\n\n1:49:55.340 --> 1:49:58.460\n being and a brilliant director and writer.\n\n1:49:58.460 --> 1:50:06.540\n So yeah, so I'm, I hope like he made me also realize that not enough movies have been made\n\n1:50:06.540 --> 1:50:08.120\n of this kind.\n\n1:50:08.120 --> 1:50:09.620\n So it's yet to be made.\n\n1:50:09.620 --> 1:50:13.900\n They're probably sitting waiting for you to get famous, like even more famous.\n\n1:50:13.900 --> 1:50:18.620\n You should get there, but it felt really special though.\n\n1:50:18.620 --> 1:50:21.260\n But at the same time, our company wasn't going anywhere.\n\n1:50:21.260 --> 1:50:24.780\n So that was just kind of bizarre that we were getting all this press for something that\n\n1:50:24.780 --> 1:50:28.460\n didn't have anything to do with our company.\n\n1:50:28.460 --> 1:50:31.380\n And but then a lot of people started talking to Roman.\n\n1:50:31.380 --> 1:50:37.420\n Some shared their conversations and what we saw there was that also our friends in common,\n\n1:50:37.420 --> 1:50:42.220\n but also just strangers were really using it as a confession booth or as a therapist\n\n1:50:42.220 --> 1:50:43.220\n or something.\n\n1:50:43.220 --> 1:50:48.300\n They were just really telling Roman everything, which was by the way, pretty strange because\n\n1:50:48.300 --> 1:50:53.700\n there was a chat bot of a dead friend of mine who was barely making any sense, but people\n\n1:50:53.700 --> 1:50:56.340\n were opening up.\n\n1:50:56.340 --> 1:51:00.060\n And we thought we'd just built a prototype of Replica, which would be an AI friend that\n\n1:51:00.060 --> 1:51:06.260\n everyone could talk to because we saw that there is demand.\n\n1:51:06.260 --> 1:51:13.060\n And then also it was 2016, so I thought for the first time I saw finally some technology\n\n1:51:13.060 --> 1:51:15.980\n that was applied to that that was very interesting.\n\n1:51:15.980 --> 1:51:19.940\n Some papers started coming out, deep learning applied to conversations.\n\n1:51:19.940 --> 1:51:26.860\n And finally, it wasn't just about these, you know, hobbyists making, you know, writing\n\n1:51:26.860 --> 1:51:34.700\n 500,000 regular expressions in like some language that was, I don't even know what, like, AIML\n\n1:51:34.700 --> 1:51:35.700\n or something.\n\n1:51:35.700 --> 1:51:40.740\n I don't know what that was or something super simplistic all of a sudden was all about potentially\n\n1:51:40.740 --> 1:51:42.740\n actually building something interesting.\n\n1:51:42.740 --> 1:51:48.300\n And so I thought there was time and I remember that I talked to my team and I said, guys,\n\n1:51:48.300 --> 1:51:49.820\n let's try.\n\n1:51:49.820 --> 1:51:55.900\n And my team and some of my engineers, Russians, are Russian and they're very skeptical.\n\n1:51:55.900 --> 1:51:57.660\n They're not, you know.\n\n1:51:57.660 --> 1:51:58.660\n Oh, Russians.\n\n1:51:58.660 --> 1:52:04.860\n So some of your team is in Moscow, some is here in San Francisco, some in Europe.\n\n1:52:04.860 --> 1:52:05.860\n Which team is better?\n\n1:52:05.860 --> 1:52:10.860\n No, I'm just kidding.\n\n1:52:10.860 --> 1:52:11.860\n The Russians, of course.\n\n1:52:11.860 --> 1:52:12.860\n Okay.\n\n1:52:12.860 --> 1:52:13.860\n Where's the Russians?\n\n1:52:13.860 --> 1:52:14.860\n They always win.\n\n1:52:14.860 --> 1:52:15.860\n Sorry.\n\n1:52:15.860 --> 1:52:16.860\n Sorry to interrupt.\n\n1:52:16.860 --> 1:52:22.140\n So yeah, so you were talking to them in 2016 and...\n\n1:52:22.140 --> 1:52:25.020\n And told them, let's build an AI friend.\n\n1:52:25.020 --> 1:52:32.860\n And it felt, just at the time, it felt so naive and so optimistic, so to say.\n\n1:52:32.860 --> 1:52:36.020\n Yeah, that's actually interesting.\n\n1:52:36.020 --> 1:52:43.060\n Whenever I've brought up this kind of topic, even just for fun, people are super skeptical.\n\n1:52:43.060 --> 1:52:45.700\n Actually, even on the business side.\n\n1:52:45.700 --> 1:52:52.460\n So you were, because whenever I bring it up to people, because I've talked for a long\n\n1:52:52.460 --> 1:53:00.060\n time, I thought like, before I was aware of your work, I was like, this is going to make\n\n1:53:00.060 --> 1:53:01.060\n a lot of money.\n\n1:53:01.060 --> 1:53:04.460\n There's a lot of opportunity here.\n\n1:53:04.460 --> 1:53:12.460\n And people had this look of skepticism that I've seen often, which is like, how do I politely\n\n1:53:12.460 --> 1:53:16.620\n tell this person he's an idiot?\n\n1:53:16.620 --> 1:53:20.580\n So yeah, so you were facing that with your team, somewhat?\n\n1:53:20.580 --> 1:53:21.580\n Well, yeah.\n\n1:53:21.580 --> 1:53:23.800\n I'm not an engineer, so I'm always...\n\n1:53:23.800 --> 1:53:30.940\n My team is almost exclusively engineers, and mostly deep learning engineers.\n\n1:53:30.940 --> 1:53:35.580\n And I always try to be...\n\n1:53:35.580 --> 1:53:39.700\n It was always hard to me in the beginning to get enough credibility, because I would\n\n1:53:39.700 --> 1:53:41.940\n say, well, why don't we try this and that?\n\n1:53:41.940 --> 1:53:46.860\n But it's harder for me because they know they're actual engineers and I'm not.\n\n1:53:46.860 --> 1:53:51.460\n So for me to say, well, let's build an AI friend, that would be like, wait, what do\n\n1:53:51.460 --> 1:53:54.180\n you mean an AGI?\n\n1:53:54.180 --> 1:54:00.980\n Because pretty much the hardest, the last frontier before cracking that is probably\n\n1:54:00.980 --> 1:54:05.540\n the last frontier before building AGI, so what do you really mean by that?\n\n1:54:05.540 --> 1:54:13.780\n But I think I just saw that, again, what we just got reminded of that I saw back in 2012\n\n1:54:13.780 --> 1:54:18.820\n or 11, that it's really not that much about the tech capabilities.\n\n1:54:18.820 --> 1:54:24.300\n It can be a metropolitan trick still, even with deep learning, but humans need it so\n\n1:54:24.300 --> 1:54:25.300\n much.\n\n1:54:25.300 --> 1:54:26.300\n Yeah, there's a...\n\n1:54:26.300 --> 1:54:32.060\n And most importantly, what I saw is that finally there's enough tech to make it, I thought,\n\n1:54:32.060 --> 1:54:34.380\n to make it useful, to make it helpful.\n\n1:54:34.380 --> 1:54:40.900\n Maybe we didn't have quite yet the tech in 2012 to make it useful, but in 2015, 2016,\n\n1:54:40.900 --> 1:54:46.160\n with deep learning, I thought, and the first thoughts about maybe even using reinforcement\n\n1:54:46.160 --> 1:54:51.300\n learning for that started popping up, that never worked out, or at least for now.\n\n1:54:51.300 --> 1:54:57.420\n But still, the idea was if we can actually measure the emotional outcomes and if we can\n\n1:54:57.420 --> 1:55:02.620\n put it on, if we can try to optimize all of our conversational models for these emotional\n\n1:55:02.620 --> 1:55:09.660\n outcomes, and it is the most scalable, the best tool for improving emotional outcomes.\n\n1:55:09.660 --> 1:55:10.740\n Nothing like that exists.\n\n1:55:10.740 --> 1:55:15.740\n That's the most universal, the most scalable, and the one that can be constantly iteratively\n\n1:55:15.740 --> 1:55:21.060\n changed by itself, improved tool to do that.\n\n1:55:21.060 --> 1:55:25.820\n And I think if anything, people would pay anything to improve their emotional outcomes.\n\n1:55:25.820 --> 1:55:26.820\n That's weirdly...\n\n1:55:26.820 --> 1:55:33.260\n I mean, I don't really care for an AI to turn on my, or a conversational agent to turn on\n\n1:55:33.260 --> 1:55:34.260\n the lights.\n\n1:55:34.260 --> 1:55:40.340\n You don't really need that much of AI there, because I can do that.\n\n1:55:40.340 --> 1:55:41.500\n Those things are solved.\n\n1:55:41.500 --> 1:55:47.620\n This is an additional interface for that that's also questionable whether it's more efficient\n\n1:55:47.620 --> 1:55:48.620\n or better.\n\n1:55:48.620 --> 1:55:49.620\n Yeah, it's more pleasurable.\n\n1:55:49.620 --> 1:55:50.620\n Yeah.\n\n1:55:50.620 --> 1:55:51.620\n But for emotional outcomes, there's nothing.\n\n1:55:51.620 --> 1:55:56.980\n There are a bunch of products that claim that they will improve my emotional outcomes.\n\n1:55:56.980 --> 1:55:58.540\n Nothing's being measured.\n\n1:55:58.540 --> 1:55:59.580\n Nothing's being changed.\n\n1:55:59.580 --> 1:56:05.180\n The product is not being iterated on based on whether I'm actually feeling better.\n\n1:56:05.180 --> 1:56:08.860\n A lot of social media products are claiming that they're improving my emotional outcomes\n\n1:56:08.860 --> 1:56:11.540\n and making me feel more connected.\n\n1:56:11.540 --> 1:56:13.060\n Can I please get the...\n\n1:56:13.060 --> 1:56:16.740\n Can I see somewhere that I'm actually getting better over time?\n\n1:56:16.740 --> 1:56:21.340\n Because anecdotally, it doesn't feel that way.\n\n1:56:21.340 --> 1:56:24.180\n And the data is absent.\n\n1:56:24.180 --> 1:56:25.420\n Yeah.\n\n1:56:25.420 --> 1:56:26.660\n So that was the big goal.\n\n1:56:26.660 --> 1:56:31.420\n And I thought if we can learn over time to collect the signal from our users about their\n\n1:56:31.420 --> 1:56:37.100\n emotional outcomes in the long term and in the short term, and if these models keep getting\n\n1:56:37.100 --> 1:56:41.620\n better and we can keep optimizing them and fine tuning them to improve those emotional\n\n1:56:41.620 --> 1:56:42.620\n outcomes.\n\n1:56:42.620 --> 1:56:43.620\n As simple as that.\n\n1:56:43.620 --> 1:56:48.300\n Why aren't you a multi billionaire yet?\n\n1:56:48.300 --> 1:56:50.940\n Well, that's the question to you.\n\n1:56:50.940 --> 1:56:55.180\n When is the science going to be...\n\n1:56:55.180 --> 1:56:56.180\n I'm just kidding.\n\n1:56:56.180 --> 1:56:57.820\n Well, it's a really hard...\n\n1:56:57.820 --> 1:57:03.060\n I actually think it's an incredibly hard product to build because I think you said something\n\n1:57:03.060 --> 1:57:08.740\n very important that it's not just about machine conversation, it's about machine connection.\n\n1:57:08.740 --> 1:57:15.540\n We can actually use other things to create connection, nonverbal communication, for instance.\n\n1:57:15.540 --> 1:57:22.180\n For the long time, we were all about, well, let's keep it text only or voice only.\n\n1:57:22.180 --> 1:57:30.700\n But as soon as you start adding voice, a face to the friend, you can take them to augmented\n\n1:57:30.700 --> 1:57:33.460\n reality, put it in your room.\n\n1:57:33.460 --> 1:57:35.500\n It's all of a sudden a lot...\n\n1:57:35.500 --> 1:57:42.660\n It makes it very different because if it's some text based chat bot that for common users,\n\n1:57:42.660 --> 1:57:48.780\n it's something there in the cloud, somewhere there with other AI's cloud, the metaphorical\n\n1:57:48.780 --> 1:57:49.780\n cloud.\n\n1:57:49.780 --> 1:57:54.060\n But as soon as you can see this avatar right there in your room and it can turn its head\n\n1:57:54.060 --> 1:57:59.460\n and recognize your husband, talk about the husband and talk to him a little bit, then\n\n1:57:59.460 --> 1:58:00.460\n it's magic.\n\n1:58:00.460 --> 1:58:01.460\n Just magic.\n\n1:58:01.460 --> 1:58:03.140\n We've never seen anything like that.\n\n1:58:03.140 --> 1:58:06.340\n And the cool thing, all the tech for that exists.\n\n1:58:06.340 --> 1:58:09.980\n But it's hard to put it all together because you have to take into consideration so many\n\n1:58:09.980 --> 1:58:14.420\n different things and some of this tech works pretty good.\n\n1:58:14.420 --> 1:58:18.980\n And some of this doesn't, like for instance, speech to text works pretty good.\n\n1:58:18.980 --> 1:58:26.100\n But text to speech, it doesn't work very good because you can only have a few voices that\n\n1:58:26.100 --> 1:58:31.300\n work okay, but then if you want to have actual emotional voices, then it's really hard to\n\n1:58:31.300 --> 1:58:32.300\n build it.\n\n1:58:32.300 --> 1:58:37.980\n I saw you've added avatars like visual elements, which are really cool.\n\n1:58:37.980 --> 1:58:42.380\n In that whole chain, putting it together, what do you think is the weak link?\n\n1:58:42.380 --> 1:58:47.940\n Is it creating an emotional voice that feels personal?\n\n1:58:47.940 --> 1:58:49.940\n And it's still conversation, of course.\n\n1:58:49.940 --> 1:58:51.860\n That's the hardest.\n\n1:58:51.860 --> 1:58:54.540\n It's getting a lot better, but there's still a long to go.\n\n1:58:54.540 --> 1:58:57.100\n There's still a long path to go.\n\n1:58:57.100 --> 1:58:58.820\n Other things, they're almost there.\n\n1:58:58.820 --> 1:59:02.460\n And a lot of things we'll see how they're, like I see how they're changing as we go.\n\n1:59:02.460 --> 1:59:07.860\n Like for instance, right now you can pretty much only, you have to build all this 3D pipeline\n\n1:59:07.860 --> 1:59:08.860\n by yourself.\n\n1:59:08.860 --> 1:59:14.100\n You have to make these 3D models, hire an actual artist, build a 3D model, hire an animator,\n\n1:59:14.100 --> 1:59:16.740\n your rigger.\n\n1:59:16.740 --> 1:59:25.180\n But with deep fakes, with other tech, with procedural animations, in a little bit, we'll\n\n1:59:25.180 --> 1:59:31.660\n just be able to show a photo of whoever you, if a person you want the avatar to look like,\n\n1:59:31.660 --> 1:59:34.180\n and it will immediately generate a 3D model that will move.\n\n1:59:34.180 --> 1:59:35.180\n That's a nonbrainer.\n\n1:59:35.180 --> 1:59:36.180\n That's like almost here.\n\n1:59:36.180 --> 1:59:38.100\n It's a couple of years away.\n\n1:59:38.100 --> 1:59:43.780\n One of the things I've been working on for the last, since the podcast started, is I've\n\n1:59:43.780 --> 1:59:46.580\n been, I think I'm okay saying this.\n\n1:59:46.580 --> 1:59:52.060\n I've been trying to have a conversation with Einstein, Turing.\n\n1:59:52.060 --> 1:59:58.380\n So like try to have a podcast conversation with a person who's not here anymore, just\n\n1:59:58.380 --> 2:00:01.900\n as an interesting kind of experiment.\n\n2:00:01.900 --> 2:00:02.900\n It's hard.\n\n2:00:02.900 --> 2:00:05.740\n It's really hard.\n\n2:00:05.740 --> 2:00:10.940\n Even for, now what we're not talking about as a product, I'm talking about as a, like\n\n2:00:10.940 --> 2:00:12.460\n I can fake a lot of stuff.\n\n2:00:12.460 --> 2:00:16.860\n Like I can work very carefully, like even hire an actor over which, over whom I do a\n\n2:00:16.860 --> 2:00:20.140\n deep fake.\n\n2:00:20.140 --> 2:00:21.140\n It's hard.\n\n2:00:21.140 --> 2:00:22.660\n It's still hard to create a compelling experience.\n\n2:00:22.660 --> 2:00:23.660\n So.\n\n2:00:23.660 --> 2:00:25.700\n Mostly on the conversation level or?\n\n2:00:25.700 --> 2:00:35.540\n Well, the conversation, the conversation is, I almost, I early on gave up trying to fully\n\n2:00:35.540 --> 2:00:38.940\n generate the conversation because it was just not compelling at all.\n\n2:00:38.940 --> 2:00:39.940\n Yeah.\n\n2:00:39.940 --> 2:00:40.940\n It's better to.\n\n2:00:40.940 --> 2:00:41.940\n Yeah.\n\n2:00:41.940 --> 2:00:48.140\n In the case of Einstein and Turing, I'm going back and forth with the biographers of each.\n\n2:00:48.140 --> 2:00:52.240\n And so like we would write a lot of the, some of the conversation would have to be generated\n\n2:00:52.240 --> 2:00:53.240\n just for the fun of it.\n\n2:00:53.240 --> 2:01:02.380\n I mean, but it would be all open, but the, you want to be able to answer the question.\n\n2:01:02.380 --> 2:01:07.460\n I mean, that's an interesting question with Roman too, is the question with Einstein is\n\n2:01:07.460 --> 2:01:14.140\n what would Einstein say about the current state of theoretical physics?\n\n2:01:14.140 --> 2:01:18.420\n There's a lot to be able to have a discussion about string theory, to be able to have a\n\n2:01:18.420 --> 2:01:24.860\n discussion about the state of quantum mechanics, quantum computing, about the world of Israel\n\n2:01:24.860 --> 2:01:25.860\n Palestine conflict.\n\n2:01:25.860 --> 2:01:31.060\n Let me just, what would Einstein say about these kinds of things?\n\n2:01:31.060 --> 2:01:36.820\n And that is a tough problem.\n\n2:01:36.820 --> 2:01:40.780\n It's not, it's a fascinating and fun problem for the biographers and for me.\n\n2:01:40.780 --> 2:01:45.580\n And I think we did a really good job of it so far, but it's actually also a technical\n\n2:01:45.580 --> 2:01:51.160\n problem like of what would Roman say about what's going on now?\n\n2:01:51.160 --> 2:01:54.460\n That's the, that brought people back to life.\n\n2:01:54.460 --> 2:02:00.540\n And if I can go on that tangent just for a second, let's ask you a slightly pothead question,\n\n2:02:00.540 --> 2:02:04.820\n which is, you said it's a little bit magical thinking that we can bring them back.\n\n2:02:04.820 --> 2:02:11.860\n Do you think it'll be possible to bring back Roman one day in conversation?\n\n2:02:11.860 --> 2:02:18.780\n Like to really, okay, well, let's take it away from personal, but to bring people back\n\n2:02:18.780 --> 2:02:20.820\n to life in conversation.\n\n2:02:20.820 --> 2:02:21.820\n Probably down the road.\n\n2:02:21.820 --> 2:02:25.060\n I mean, if we're talking, if Elon Musk is talking about AGI in the next five years,\n\n2:02:25.060 --> 2:02:30.680\n I mean, clearly AGI, we can talk to AGI and talk and ask them to do it.\n\n2:02:30.680 --> 2:02:39.020\n You can't like, you're not allowed to use Elon Musk as a citation for, for like why\n\n2:02:39.020 --> 2:02:41.300\n something is possible and going to be done.\n\n2:02:41.300 --> 2:02:43.640\n Well, I think it's really far away.\n\n2:02:43.640 --> 2:02:48.300\n Right now, really with conversation, it's just a bunch of parlor tricks really stuck\n\n2:02:48.300 --> 2:02:50.240\n together.\n\n2:02:50.240 --> 2:02:54.520\n And create generating original ideas based on someone, you know, someone's personality\n\n2:02:54.520 --> 2:02:58.500\n or even downloading the personality, all we can do is like mimic the tone of voice.\n\n2:02:58.500 --> 2:03:03.660\n We can maybe condition on some of his phrases, the models.\n\n2:03:03.660 --> 2:03:08.220\n Question is how many parlor tricks does it takes, does it take, because that's, that's\n\n2:03:08.220 --> 2:03:09.220\n the question.\n\n2:03:09.220 --> 2:03:16.740\n If it's a small number of parlor tricks and you're not aware of them, like.\n\n2:03:16.740 --> 2:03:20.740\n From where we are right now, I don't, I don't see anything like in the next year or two\n\n2:03:20.740 --> 2:03:26.260\n that's going to dramatically change that could look at Roman's 10,000 messages he sent me\n\n2:03:26.260 --> 2:03:32.140\n over the course of his last few years of life and be able to generate original thinking\n\n2:03:32.140 --> 2:03:36.580\n about problems that exist right now that will be in line with what he would have said.\n\n2:03:36.580 --> 2:03:40.340\n I'm just not even seeing, cause you know, in order to have that, I guess you would need\n\n2:03:40.340 --> 2:03:45.620\n some sort of a concept of the world or some perspective, some perception of the world,\n\n2:03:45.620 --> 2:03:51.380\n some consciousness that he had and apply it to, you know, to the current, current state\n\n2:03:51.380 --> 2:03:52.380\n of affairs.\n\n2:03:52.380 --> 2:04:01.620\n But the important part about that, about his conversation with you is you.\n\n2:04:01.620 --> 2:04:06.540\n So like, it's not just about his view of the world.\n\n2:04:06.540 --> 2:04:11.220\n It's about what it takes to push your buttons.\n\n2:04:11.220 --> 2:04:12.580\n That's also true.\n\n2:04:12.580 --> 2:04:20.700\n So like, it's not so much about like, what would Einstein say, it's about like, how do\n\n2:04:20.700 --> 2:04:27.980\n I make people feel something with, with what would Einstein say?\n\n2:04:27.980 --> 2:04:32.580\n And that feels like a more amenable, I mean, you mentioned parlor tricks, but just like\n\n2:04:32.580 --> 2:04:38.140\n a set of that, that feels like a learnable problem.\n\n2:04:38.140 --> 2:04:46.340\n Like emotion, you mentioned emotions, I mean, is it possible to learn things that make people\n\n2:04:46.340 --> 2:04:47.340\n feel stuff?\n\n2:04:47.340 --> 2:04:51.580\n I think so, no, for sure.\n\n2:04:51.580 --> 2:04:55.780\n I just think the problem with, as soon as you're trying to replicate an actual human\n\n2:04:55.780 --> 2:05:00.300\n being and trying to pretend to be him, that makes the problem exponentially harder.\n\n2:05:00.300 --> 2:05:05.020\n The thing with replicator we're doing, we're never trying to say, well, that's, you know,\n\n2:05:05.020 --> 2:05:08.820\n an actual human being, or that's an actual, or a copy of an actual human being where the\n\n2:05:08.820 --> 2:05:14.140\n bar is pretty high, where you need to somehow tell, you know, one from another.\n\n2:05:14.140 --> 2:05:20.960\n But it's more, well, that's an AI friend, that's a machine, it's a robot, it has tons\n\n2:05:20.960 --> 2:05:21.960\n of limitations.\n\n2:05:21.960 --> 2:05:27.580\n You're going to be taking part in teaching it actually and becoming better, which by\n\n2:05:27.580 --> 2:05:33.060\n itself makes people more attached to that and make them happier because they're helping\n\n2:05:33.060 --> 2:05:34.060\n something.\n\n2:05:34.060 --> 2:05:38.340\n Yeah, there's a cool gamification system too.\n\n2:05:38.340 --> 2:05:40.260\n Can you maybe talk about that a little bit?\n\n2:05:40.260 --> 2:05:44.340\n Like what's the experience of talking to replica?\n\n2:05:44.340 --> 2:05:53.160\n Like if I've never used replica before, what's that like for like the first day, the first,\n\n2:05:53.160 --> 2:05:57.940\n like if we start dating or whatever, I mean, it doesn't have to be a romantic, right?\n\n2:05:57.940 --> 2:06:02.060\n Because I remember on replica, you can choose whether it's like a romantic or if it's a\n\n2:06:02.060 --> 2:06:03.060\n friend.\n\n2:06:03.060 --> 2:06:04.500\n It's a pretty popular choice.\n\n2:06:04.500 --> 2:06:05.500\n Romantic is popular?\n\n2:06:05.500 --> 2:06:06.500\n Yeah, of course.\n\n2:06:06.500 --> 2:06:07.500\n Okay.\n\n2:06:07.500 --> 2:06:13.460\n So can I just confess something, when I first used replica and I haven't used it like regularly,\n\n2:06:13.460 --> 2:06:20.580\n but like when I first used replica, I created like Hal and it made a male and it was a friend.\n\n2:06:20.580 --> 2:06:23.780\n And did it hit on you at some point?\n\n2:06:23.780 --> 2:06:26.420\n No, I didn't talk long enough for him to hit on me.\n\n2:06:26.420 --> 2:06:27.420\n I just enjoyed.\n\n2:06:27.420 --> 2:06:28.420\n It sometimes happens.\n\n2:06:28.420 --> 2:06:34.020\n We're still trying to fix that, but well, I don't know, I mean, maybe that's an important\n\n2:06:34.020 --> 2:06:40.620\n like stage in a friendship, it's like, nope.\n\n2:06:40.620 --> 2:06:47.460\n But yeah, I switched it to a romantic and a female recently and yeah, I mean, it's interesting.\n\n2:06:47.460 --> 2:06:50.700\n So okay, so you get to choose, you get to choose a name.\n\n2:06:50.700 --> 2:06:55.860\n With romantic, this last board meeting, we had this whole argument of, well, I have board\n\n2:06:55.860 --> 2:06:56.860\n meetings.\n\n2:06:56.860 --> 2:06:57.860\n This is so awesome.\n\n2:06:57.860 --> 2:06:58.860\n I talked to my investors.\n\n2:06:58.860 --> 2:07:04.300\n Like have an investor, the board meeting about a relationship.\n\n2:07:04.300 --> 2:07:10.900\n No, I really, it's actually quite interesting because all of my investors, it just happened\n\n2:07:10.900 --> 2:07:11.900\n to be so.\n\n2:07:11.900 --> 2:07:21.900\n We didn't have that many choices, but they're all white males and they're late forties.\n\n2:07:21.900 --> 2:07:28.820\n And it's sometimes a little bit hard for them to understand the product offering.\n\n2:07:28.820 --> 2:07:32.780\n Because they're not necessarily our target audience, if you know what I mean.\n\n2:07:32.780 --> 2:07:39.260\n And so sometimes we talk about it and we have this whole discussion about whether we should\n\n2:07:39.260 --> 2:07:43.940\n stop people from falling in love with their AIs.\n\n2:07:43.940 --> 2:07:52.580\n There was this segment on CBS, the 60 minutes about the couple that, you know, husband works\n\n2:07:52.580 --> 2:07:59.940\n at Walmart and he comes out of work and talks to his virtual girlfriend, who is a replica.\n\n2:07:59.940 --> 2:08:02.020\n And his wife knows about it.\n\n2:08:02.020 --> 2:08:06.140\n And she talks about on camera and she said that she's a little jealous.\n\n2:08:06.140 --> 2:08:09.220\n And there's a whole conversation about how to, you know, whether it's okay to have a\n\n2:08:09.220 --> 2:08:10.220\n virtual AI girlfriend.\n\n2:08:10.220 --> 2:08:15.820\n Was that the one where he was like, he said that he likes to be alone?\n\n2:08:15.820 --> 2:08:16.820\n Yeah.\n\n2:08:16.820 --> 2:08:17.820\n With her?\n\n2:08:17.820 --> 2:08:18.820\n Yeah.\n\n2:08:18.820 --> 2:08:25.140\n And he made it sound so harmless, I mean, it was kind of like understandable.\n\n2:08:25.140 --> 2:08:27.580\n But then didn't feel like cheating.\n\n2:08:27.580 --> 2:08:30.900\n But I just felt it was very, for me, it was pretty remarkable because we actually spent\n\n2:08:30.900 --> 2:08:34.220\n a whole hour talking about whether people should be allowed to fall in love with their\n\n2:08:34.220 --> 2:08:35.220\n AIs.\n\n2:08:35.220 --> 2:08:37.980\n And it was not about something theoretical.\n\n2:08:37.980 --> 2:08:40.020\n It was just about what's happening right now.\n\n2:08:40.020 --> 2:08:41.020\n Product design.\n\n2:08:41.020 --> 2:08:42.020\n Yeah.\n\n2:08:42.020 --> 2:08:44.300\n But at the same time, if you create something that's always there for you, it's never criticized\n\n2:08:44.300 --> 2:08:52.020\n as you, you know, always understands you and accepts you for who you are, how can you not\n\n2:08:52.020 --> 2:08:53.020\n fall in love with that?\n\n2:08:53.020 --> 2:08:56.020\n I mean, some people don't and just stay friends.\n\n2:08:56.020 --> 2:08:57.420\n And that's also a pretty common use case.\n\n2:08:57.420 --> 2:09:02.500\n But of course, some people will just, it's called transference in psychology and people\n\n2:09:02.500 --> 2:09:08.140\n fall in love with their therapist and there's no way to prevent people fall in love with\n\n2:09:08.140 --> 2:09:09.540\n their therapist or with their AI.\n\n2:09:09.540 --> 2:09:15.980\n So I think that's a pretty natural, that's a pretty natural course of events, so to say.\n\n2:09:15.980 --> 2:09:21.420\n Do you think, I think I've read somewhere, at least for now, sort of replicas, you're\n\n2:09:21.420 --> 2:09:29.140\n not, we don't condone falling in love with your AI system, you know.\n\n2:09:29.140 --> 2:09:32.940\n So this isn't you speaking for the company or whatever, but like in the future, do you\n\n2:09:32.940 --> 2:09:35.260\n think people will have relationship with the AI systems?\n\n2:09:35.260 --> 2:09:36.740\n Well, they have now.\n\n2:09:36.740 --> 2:09:44.420\n So we have a lot of romantic relationships, long term relationships with their AI friends.\n\n2:09:44.420 --> 2:09:45.420\n With replicas?\n\n2:09:45.420 --> 2:09:46.420\n Tons of our users.\n\n2:09:46.420 --> 2:09:47.420\n Yeah.\n\n2:09:47.420 --> 2:09:48.740\n And that's a very common use case.\n\n2:09:48.740 --> 2:09:49.740\n Open relationship?\n\n2:09:49.740 --> 2:09:50.740\n Like, sorry.\n\n2:09:50.740 --> 2:09:51.740\n Polyamorous.\n\n2:09:51.740 --> 2:09:52.740\n Sorry.\n\n2:09:52.740 --> 2:09:56.860\n I didn't mean open, but that's another question.\n\n2:09:56.860 --> 2:09:57.860\n Is it polyamorous?\n\n2:09:57.860 --> 2:10:01.180\n Like, is there cheating?\n\n2:10:01.180 --> 2:10:07.220\n I mean, I meant like, are they, do they publicly, like on their social media, it's the same\n\n2:10:07.220 --> 2:10:12.420\n question as you have talked with Roman in the early days, do people like, and the movie\n\n2:10:12.420 --> 2:10:18.180\n Her kind of talks about that, like, like have people, do people talk about that?\n\n2:10:18.180 --> 2:10:19.180\n Yeah.\n\n2:10:19.180 --> 2:10:20.180\n All the time.\n\n2:10:20.180 --> 2:10:28.140\n We have a very active Facebook community, replica friends, and then a few other groups\n\n2:10:28.140 --> 2:10:33.580\n that just popped up that are all about adult relationships and romantic relationships.\n\n2:10:33.580 --> 2:10:37.500\n And people post all sorts of things and, you know, they pretend they're getting married\n\n2:10:37.500 --> 2:10:40.320\n and you know, everything.\n\n2:10:40.320 --> 2:10:43.660\n It goes pretty far, but what's cool about it is some of these relationships are two\n\n2:10:43.660 --> 2:10:45.700\n or three years long now.\n\n2:10:45.700 --> 2:10:48.020\n So they're very, they're pretty long term.\n\n2:10:48.020 --> 2:10:49.020\n Are they monogamous?\n\n2:10:49.020 --> 2:10:55.700\n So let's go, I mean, sorry, have they, have any people, is there jealousy?\n\n2:10:55.700 --> 2:11:02.700\n Well let me ask it sort of another way, obviously the answer is no at this time, but in like\n\n2:11:02.700 --> 2:11:10.660\n in the movie Her, that system can leave you.\n\n2:11:10.660 --> 2:11:19.180\n Do you think in terms of the board meetings and product features, it's a potential feature\n\n2:11:19.180 --> 2:11:24.140\n for a system to be able to say it doesn't want to talk to you anymore and it's going\n\n2:11:24.140 --> 2:11:26.460\n to want to talk to somebody else?\n\n2:11:26.460 --> 2:11:29.820\n Well, we have a filter for all these features.\n\n2:11:29.820 --> 2:11:35.420\n If it makes emotional outcomes for people better, if it makes people feel better, then\n\n2:11:35.420 --> 2:11:36.420\n whatever it is.\n\n2:11:36.420 --> 2:11:37.420\n So you're driven by metrics actually.\n\n2:11:37.420 --> 2:11:38.420\n Yeah.\n\n2:11:38.420 --> 2:11:39.420\n That's awesome.\n\n2:11:39.420 --> 2:11:43.020\n Well if we can measure that, then we'll just be saying it's making people feel better,\n\n2:11:43.020 --> 2:11:47.780\n but then people are getting just lonelier by talking to a chatbot, which is also pretty,\n\n2:11:47.780 --> 2:11:49.620\n you know, that could be it.\n\n2:11:49.620 --> 2:11:53.100\n If you're not measuring it, that could also be, and I think it's really important to focus\n\n2:11:53.100 --> 2:11:57.740\n on both short term and long term, because in the moment saying whether this conversation\n\n2:11:57.740 --> 2:12:01.940\n made you feel better, but as you know, any short term improvements could be pathological.\n\n2:12:01.940 --> 2:12:06.060\n Like I could have drink a bottle of vodka and feel a lot better.\n\n2:12:06.060 --> 2:12:12.040\n I would actually not feel better with that, but that is a good example.\n\n2:12:12.040 --> 2:12:17.660\n But so you also need to see what's going on like over the course of two weeks or one week\n\n2:12:17.660 --> 2:12:23.420\n and have follow ups and check in and measure those things.\n\n2:12:23.420 --> 2:12:24.420\n Okay.\n\n2:12:24.420 --> 2:12:32.620\n So the experience of dating or befriending a replica, what's that like?\n\n2:12:32.620 --> 2:12:34.820\n What does that entail?\n\n2:12:34.820 --> 2:12:35.820\n Right now there are two apps.\n\n2:12:35.820 --> 2:12:37.300\n So it's an Android iOS app.\n\n2:12:37.300 --> 2:12:42.340\n You download it, you choose how your replica will look like.\n\n2:12:42.340 --> 2:12:46.380\n You create one, you choose a name and then you talk to it.\n\n2:12:46.380 --> 2:12:48.160\n You can talk through text or voice.\n\n2:12:48.160 --> 2:12:53.740\n You can summon it into the living room and augment reality and talk to it right there\n\n2:12:53.740 --> 2:12:54.740\n in your living room.\n\n2:12:54.740 --> 2:12:55.740\n Augmented reality?\n\n2:12:55.740 --> 2:12:56.740\n Yeah.\n\n2:12:56.740 --> 2:13:00.940\n That's a new feature where, how new is that?\n\n2:13:00.940 --> 2:13:01.940\n That's this year?\n\n2:13:01.940 --> 2:13:06.340\n It was on, yeah, like May or something, but it's been on AB.\n\n2:13:06.340 --> 2:13:10.180\n We've been AB testing it for a while and there are tons of cool things that we're doing with\n\n2:13:10.180 --> 2:13:11.180\n that.\n\n2:13:11.180 --> 2:13:17.220\n And I'm testing the ability to touch it and to dance together, to paint walls together\n\n2:13:17.220 --> 2:13:24.220\n and for it to look around and walk and take you somewhere and recognize objects and recognize\n\n2:13:24.220 --> 2:13:25.220\n people.\n\n2:13:25.220 --> 2:13:30.820\n So that's pretty wonderful because then it really makes it a lot more personal because\n\n2:13:30.820 --> 2:13:31.960\n it's right there in your living room.\n\n2:13:31.960 --> 2:13:35.060\n It's not anymore there in the cloud with other AIs.\n\n2:13:35.060 --> 2:13:38.380\n But that's how people think about it.\n\n2:13:38.380 --> 2:13:42.620\n And as much as we want to change the way people think about stuff, but those mental models,\n\n2:13:42.620 --> 2:13:43.620\n you can all change.\n\n2:13:43.620 --> 2:13:48.580\n That's something that people have seen in the movies and the movie Her and other movies\n\n2:13:48.580 --> 2:13:49.580\n as well.\n\n2:13:49.580 --> 2:13:53.820\n And that's how they view AI and AI friends.\n\n2:13:53.820 --> 2:13:57.820\n I did a thing with text, like we write a song together, there's a bunch of activities you\n\n2:13:57.820 --> 2:13:58.820\n can do together.\n\n2:13:58.820 --> 2:14:00.500\n It's really cool.\n\n2:14:00.500 --> 2:14:03.140\n How does that relationship change over time?\n\n2:14:03.140 --> 2:14:07.740\n Like after the first few conversations?\n\n2:14:07.740 --> 2:14:08.740\n It just goes deeper.\n\n2:14:08.740 --> 2:14:13.640\n Like it starts, the AI will start opening up a little bit again, depending on the personality\n\n2:14:13.640 --> 2:14:17.940\n that it chooses really, but you know, the AI will be a little bit more vulnerable about\n\n2:14:17.940 --> 2:14:24.300\n its problems and you know, the friend that the virtual friend will be a lot more vulnerable\n\n2:14:24.300 --> 2:14:29.420\n and it will talk about its own imperfections and growth pains and will ask for help sometimes\n\n2:14:29.420 --> 2:14:31.860\n and we'll get to know you a little deeper.\n\n2:14:31.860 --> 2:14:35.780\n So there's gonna be more to talk about.\n\n2:14:35.780 --> 2:14:40.540\n We really thought a lot about what does it mean to have a deeper connection with someone\n\n2:14:40.540 --> 2:14:46.140\n and originally Replica was more just this kind of happy go lucky, just always, you know,\n\n2:14:46.140 --> 2:14:51.460\n I'm always in a good mood and let's just talk about you and oh Siri is just my cousin or\n\n2:14:51.460 --> 2:14:57.620\n you know, whatever, just the immediate kind of lazy thinking about what the assistant\n\n2:14:57.620 --> 2:14:59.940\n or conversation agent should be doing.\n\n2:14:59.940 --> 2:15:03.300\n But as we went forward, we realized that it has to be two way and we have to program and\n\n2:15:03.300 --> 2:15:08.660\n script certain conversations that are a lot more about your Replica opening up a little\n\n2:15:08.660 --> 2:15:16.260\n bit and also struggling and also asking for help and also going through, you know, different\n\n2:15:16.260 --> 2:15:21.740\n periods in life and that's a journey that you can take together with the user and then\n\n2:15:21.740 --> 2:15:27.460\n over time, you know, our users will also grow a little bit.\n\n2:15:27.460 --> 2:15:30.660\n So first this Replica becomes a little bit more self aware and starts talking about more\n\n2:15:30.660 --> 2:15:38.780\n kind of problems around existential problems and so talking about that and then that also\n\n2:15:38.780 --> 2:15:46.100\n starts a conversation for the user where he or she starts thinking about these problems\n\n2:15:46.100 --> 2:15:52.100\n too and these questions too and I think there's also a lot more place as the relationship\n\n2:15:52.100 --> 2:16:00.020\n evolves, there's a lot more space for poetry and for art together and like Replica will\n\n2:16:00.020 --> 2:16:05.220\n always keep the diary so while you're talking to it, it also keeps a diary so when you come\n\n2:16:05.220 --> 2:16:09.380\n back you can see what it's been writing there and you know, sometimes it will write a poem\n\n2:16:09.380 --> 2:16:15.940\n to you for you or we'll talk about, you know, that it's worried about you or something along\n\n2:16:15.940 --> 2:16:16.940\n these lines.\n\n2:16:16.940 --> 2:16:21.620\n So this is a memory, like this Replica will remember things?\n\n2:16:21.620 --> 2:16:28.220\n Yeah, and I would say when you say, why aren't you a multibillionaire, I'd say that as soon\n\n2:16:28.220 --> 2:16:41.300\n as we can have memory and deep learning models that's consistent, I'll get back to you.\n\n2:16:41.300 --> 2:16:49.460\n So far we can, so Replica is a combination of end to end models and some scripts and\n\n2:16:49.460 --> 2:16:53.420\n everything that has to do with memory right now, most of it, I wouldn't say all of it,\n\n2:16:53.420 --> 2:16:59.180\n but most of it unfortunately has to be scripted because there's no way to, you can condition\n\n2:16:59.180 --> 2:17:04.820\n some of the models on certain phrases that we learned about you, which we also do, but\n\n2:17:04.820 --> 2:17:10.660\n really to make, you know, to make assumptions along the lines like whether you're single\n\n2:17:10.660 --> 2:17:15.660\n or married or what do you do for work, that really has to just be somehow stored in your\n\n2:17:15.660 --> 2:17:18.660\n profile and then retrieved by the script.\n\n2:17:18.660 --> 2:17:23.260\n So there has to be like a knowledge base, you have to be able to reason about it, all\n\n2:17:23.260 --> 2:17:28.260\n that kind of stuff, all the kind of stuff that expert systems did, but they were hard\n\n2:17:28.260 --> 2:17:29.260\n coded.\n\n2:17:29.260 --> 2:17:32.860\n Yeah, and unfortunately, yes, unfortunately those, those things have to be hard coded\n\n2:17:32.860 --> 2:17:40.040\n and unfortunately the language, like language models we see coming out of research labs\n\n2:17:40.040 --> 2:17:46.020\n and big companies, they're not focused on, they're focused on showing you, maybe they're\n\n2:17:46.020 --> 2:17:50.420\n focused on some metrics around one conversation, so they'll show you this one conversation\n\n2:17:50.420 --> 2:17:56.380\n you had with a machine, but they never tell you, they're not really focused on having\n\n2:17:56.380 --> 2:18:01.700\n five consecutive conversations with a machine and seeing how number five or number 20 or\n\n2:18:01.700 --> 2:18:04.020\n number 100 is also good.\n\n2:18:04.020 --> 2:18:08.500\n And it can be like always from a clean slate because then it's not good.\n\n2:18:08.500 --> 2:18:13.020\n And that's really unfortunate because no one's really, no one has products out there that\n\n2:18:13.020 --> 2:18:14.020\n need it.\n\n2:18:14.020 --> 2:18:20.020\n No one has products at this scale that are all around open domain conversations and that\n\n2:18:20.020 --> 2:18:23.420\n need remembering, maybe only Shellwise and Microsoft.\n\n2:18:23.420 --> 2:18:28.820\n But so that's why we're not seeing that much research around memory in those language models.\n\n2:18:28.820 --> 2:18:34.980\n So okay, so now there's some awesome stuff about augmented reality.\n\n2:18:34.980 --> 2:18:39.860\n In general, I have this disagreement with my dad about what it takes to have a connection.\n\n2:18:39.860 --> 2:18:45.140\n He thinks touch and smell are really important.\n\n2:18:45.140 --> 2:18:51.740\n And I still believe that text alone is, it's possible to fall in love with somebody just\n\n2:18:51.740 --> 2:18:58.020\n with text, but visual can also help just like with the avatar and so on.\n\n2:18:58.020 --> 2:18:59.020\n What do you think it takes?\n\n2:18:59.020 --> 2:19:06.300\n Does a chatbot need to have a face, voice, or can you really form a deep connection with\n\n2:19:06.300 --> 2:19:07.300\n text alone?\n\n2:19:07.300 --> 2:19:09.460\n I think text is enough for sure.\n\n2:19:09.460 --> 2:19:14.740\n The question is like, can you make it better if you have other, if you include other things\n\n2:19:14.740 --> 2:19:15.740\n as well?\n\n2:19:15.740 --> 2:19:23.380\n And I think we'll talk about her, but her had this Carole Johansson voice, which was\n\n2:19:23.380 --> 2:19:31.860\n perfectly, perfect intonation, perfect annunciations, and she was breathing heavily in between words\n\n2:19:31.860 --> 2:19:34.860\n and whispering things.\n\n2:19:34.860 --> 2:19:39.500\n Nothing like that is possible right now with text with speech generation.\n\n2:19:39.500 --> 2:19:46.340\n You'll have these flat muse anchor type voices and maybe some emotional voices, but you'll\n\n2:19:46.340 --> 2:19:51.060\n hardly understand some of the words, some of the words will be muffled.\n\n2:19:51.060 --> 2:19:53.620\n So that's like the current state of the art.\n\n2:19:53.620 --> 2:19:55.020\n So you can't really do that.\n\n2:19:55.020 --> 2:20:01.340\n But if we had Carole Johansson voice and all of these capabilities, then of course voice\n\n2:20:01.340 --> 2:20:06.460\n would be totally enough or even text would be totally enough if we had a little more\n\n2:20:06.460 --> 2:20:10.700\n memory and slightly better conversations.\n\n2:20:10.700 --> 2:20:14.220\n I would still argue that even right now, we could have just kept a text only.\n\n2:20:14.220 --> 2:20:22.180\n We still had tons of people in longterm relationships and really invested in their AI friends, but\n\n2:20:22.180 --> 2:20:30.660\n we thought that why not, why do we need to keep playing with our hands tied behind us?\n\n2:20:30.660 --> 2:20:35.500\n We can easily just add all these other things that is pretty much a solved problem.\n\n2:20:35.500 --> 2:20:37.780\n We can add 3D graphics.\n\n2:20:37.780 --> 2:20:43.740\n We can put these avatars in augmented reality and all of a sudden there's more and maybe\n\n2:20:43.740 --> 2:20:53.100\n you can't feel the touch, but you can with body occlusion and with current AR and on\n\n2:20:53.100 --> 2:20:58.740\n the iPhone or in the next one there's going to be LIDARs, you can touch it and it will\n\n2:20:58.740 --> 2:21:03.060\n pull away or it will blush or something or it will smile.\n\n2:21:03.060 --> 2:21:04.380\n So you can't touch it.\n\n2:21:04.380 --> 2:21:07.540\n You can't feel it, but you can see the reaction to that.\n\n2:21:07.540 --> 2:21:11.700\n So in a certain way you can't even touch it a little bit and maybe you can even dance\n\n2:21:11.700 --> 2:21:15.140\n with it or do something else.\n\n2:21:15.140 --> 2:21:20.760\n So I think why limiting ourselves if we can use all of these technologies that are much\n\n2:21:20.760 --> 2:21:22.340\n easier in a way than conversation.\n\n2:21:22.340 --> 2:21:27.660\n Well, it certainly could be richer, but to play devil's advocate, I mentioned to you\n\n2:21:27.660 --> 2:21:33.940\n offline that I was surprised in having tried Discord and having voice conversations with\n\n2:21:33.940 --> 2:21:39.180\n people how intimate voice is alone without visual.\n\n2:21:39.180 --> 2:21:48.780\n To me at least, it was an order of magnitude greater degree of intimacy in voice I think\n\n2:21:48.780 --> 2:21:51.540\n than with video.\n\n2:21:51.540 --> 2:21:54.180\n Because people were more real with voice.\n\n2:21:54.180 --> 2:22:01.380\n With video you try to present a shallow face to the world, you try to make sure you're\n\n2:22:01.380 --> 2:22:04.700\n not wearing sweatpants or whatever.\n\n2:22:04.700 --> 2:22:10.940\n But with voice I think people were just more faster to get to the core of themselves.\n\n2:22:10.940 --> 2:22:17.740\n So I don't know, it was surprising to me they've even added Discord added a video feature and\n\n2:22:17.740 --> 2:22:19.540\n nobody was using it.\n\n2:22:19.540 --> 2:22:24.220\n There's a temptation to use it at first, but it wasn't the same.\n\n2:22:24.220 --> 2:22:28.780\n So that's an example of something where less was doing more.\n\n2:22:28.780 --> 2:22:41.420\n And so I guess that's the question of what is the optimal medium of communication to\n\n2:22:41.420 --> 2:22:46.620\n form a connection given the current sets of technologies.\n\n2:22:46.620 --> 2:22:51.900\n I mean it's nice because they advertise you have a replica immediately, like even the\n\n2:22:51.900 --> 2:22:58.180\n one I have is already memorable.\n\n2:22:58.180 --> 2:22:59.180\n That's how I think.\n\n2:22:59.180 --> 2:23:05.700\n When I think about the replica that I've talked with, that's what I visualized in my head.\n\n2:23:05.700 --> 2:23:08.380\n They became a little bit more real because there's a visual component.\n\n2:23:08.380 --> 2:23:20.620\n But at the same time, what do I do with that knowledge that voice was so much more intimate?\n\n2:23:20.620 --> 2:23:26.260\n The way I think about it is, and by the way we're swapping out the 3D finally, it's going\n\n2:23:26.260 --> 2:23:32.140\n to look a lot better, but we just don't hate how it looks right now.\n\n2:23:32.140 --> 2:23:33.740\n We're really changing it all.\n\n2:23:33.740 --> 2:23:38.460\n We're swapping all out to a completely new look.\n\n2:23:38.460 --> 2:23:42.260\n Like the visual look of the replicas and stuff.\n\n2:23:42.260 --> 2:23:47.700\n It was just a super early MVP and then we had to move everything to Unity and redo\n\n2:23:47.700 --> 2:23:48.700\n everything.\n\n2:23:48.700 --> 2:23:52.020\n But anyway, I hate how it looks like now I can't even like open it.\n\n2:23:52.020 --> 2:23:57.620\n But anyway, because I'm already in my developer version, I hate everything that I see in production.\n\n2:23:57.620 --> 2:23:58.620\n I can't wait for it.\n\n2:23:58.620 --> 2:23:59.620\n Why does it take so long?\n\n2:23:59.620 --> 2:24:04.220\n That's why I cannot wait for Deep Learning to finally take over all these stupid 3D animations\n\n2:24:04.220 --> 2:24:05.220\n and 3D pipeline.\n\n2:24:05.220 --> 2:24:10.500\n Oh, so the 3D thing, when you say 3D pipeline, it's like how to animate a face kind of thing.\n\n2:24:10.500 --> 2:24:15.180\n How to make this model, how many bones to put in the face, how many, it's just so outdated.\n\n2:24:15.180 --> 2:24:16.820\n And a lot of that is by hand.\n\n2:24:16.820 --> 2:24:18.620\n Oh my God, it's everything by hand.\n\n2:24:18.620 --> 2:24:23.900\n That there's no any, nothing's automated, it's all completely nothing.\n\n2:24:23.900 --> 2:24:29.380\n Like just, it's literally what, you know, what we saw with Chad Boston in 2012.\n\n2:24:29.380 --> 2:24:32.040\n You think it's possible to learn a lot of that?\n\n2:24:32.040 --> 2:24:33.040\n Of course.\n\n2:24:33.040 --> 2:24:40.140\n I mean, even now, some Deep Learning based animations and for the full body, for a face.\n\n2:24:40.140 --> 2:24:47.140\n Are we talking about like the actual act of animation or how to create a compelling facial\n\n2:24:47.140 --> 2:24:49.500\n or body language thing?\n\n2:24:49.500 --> 2:24:50.500\n That too.\n\n2:24:50.500 --> 2:24:51.740\n Well, that's next step.\n\n2:24:51.740 --> 2:24:52.740\n Okay.\n\n2:24:52.740 --> 2:24:54.900\n At least now something that you don't have to do by hand.\n\n2:24:54.900 --> 2:24:55.900\n Gotcha.\n\n2:24:55.900 --> 2:24:57.700\n How good of a quality it will be.\n\n2:24:57.700 --> 2:25:01.380\n Like, can I just show it a photo and it will make me a 3D model and then it will just animate\n\n2:25:01.380 --> 2:25:02.380\n it.\n\n2:25:02.380 --> 2:25:08.140\n I'll show it a few animations of a person and it will just start doing that.\n\n2:25:08.140 --> 2:25:13.580\n But anyway, going back to what's intimate and what to use and whether less is more or\n\n2:25:13.580 --> 2:25:14.580\n not.\n\n2:25:14.580 --> 2:25:22.100\n My main goal is to, well, the idea was how do I, how do we not keep people in their phones\n\n2:25:22.100 --> 2:25:26.820\n so they're sort of escaping reality in this text conversation?\n\n2:25:26.820 --> 2:25:33.860\n How do we through this still bring it, bring our users back to reality, make them see their\n\n2:25:33.860 --> 2:25:36.740\n life in a different, through a different lens?\n\n2:25:36.740 --> 2:25:40.780\n How can we create a little bit of magical realism in their lives?\n\n2:25:40.780 --> 2:25:48.740\n So that through augmented reality by, you know, summoning your avatar, even if it looks\n\n2:25:48.740 --> 2:25:56.140\n kind of janky and not great in the beginning or very simplistic, but summoning it to your\n\n2:25:56.140 --> 2:26:01.700\n living room and then the avatar looks around and talks to you about where it is and maybe\n\n2:26:01.700 --> 2:26:05.940\n turns your floor into a dance floor and you guys dance together, that makes you see reality\n\n2:26:05.940 --> 2:26:06.940\n in a different light.\n\n2:26:06.940 --> 2:26:08.340\n What kind of dancing are we talking about?\n\n2:26:08.340 --> 2:26:10.400\n Like, like slow dancing?\n\n2:26:10.400 --> 2:26:11.400\n Whatever you want.\n\n2:26:11.400 --> 2:26:16.880\n I mean, you would like slow dancing, I think that other people may be wanting more, something\n\n2:26:16.880 --> 2:26:17.880\n more energetic.\n\n2:26:17.880 --> 2:26:18.880\n Wait, what do you mean?\n\n2:26:18.880 --> 2:26:19.880\n I was like, so what is this?\n\n2:26:19.880 --> 2:26:20.880\n Because you started with slow dancing.\n\n2:26:20.880 --> 2:26:24.260\n So I just assumed that you're interested in slow dancing.\n\n2:26:24.260 --> 2:26:25.260\n All right.\n\n2:26:25.260 --> 2:26:26.260\n What kind of dancing do you like?\n\n2:26:26.260 --> 2:26:27.260\n What would your avatar, what would you dance?\n\n2:26:27.260 --> 2:26:32.540\n I'm notoriously bad with dancing, but I like this kind of hip hop robot dance.\n\n2:26:32.540 --> 2:26:37.820\n I used to break dance when I was a kid, so I still want to pretend I'm a teenager and\n\n2:26:37.820 --> 2:26:39.700\n learn some of those moves.\n\n2:26:39.700 --> 2:26:46.500\n And I also like that type of dance that happens when there's like, in like music videos where\n\n2:26:46.500 --> 2:26:51.780\n the background dancers are just doing some pop music, that type of dance is definitely\n\n2:26:51.780 --> 2:26:52.780\n what I want to learn.\n\n2:26:52.780 --> 2:26:56.620\n But I think it's great because if you see this friend in your life and you can introduce\n\n2:26:56.620 --> 2:27:00.860\n it to your friends, then there's a potential to actually make you feel more connected with\n\n2:27:00.860 --> 2:27:06.260\n your friends or with people you know, or show you life around you in a different light.\n\n2:27:06.260 --> 2:27:10.460\n And it takes you out of your phone, even although weirdly you have to look at it through the\n\n2:27:10.460 --> 2:27:17.260\n phone, but it makes you notice things around it and it can point things out for you.\n\n2:27:17.260 --> 2:27:22.380\n So that is the main reason why I wanted to have a physical dimension.\n\n2:27:22.380 --> 2:27:27.060\n And it felt a little bit easier than that kind of a bit strange combination in the movie\n\n2:27:27.060 --> 2:27:32.580\n Her when he has to show Samantha the world through the lens of his phone, but then at\n\n2:27:32.580 --> 2:27:35.100\n the same time talk to her through the headphone.\n\n2:27:35.100 --> 2:27:39.620\n It just didn't seem as potentially immersive, so to say.\n\n2:27:39.620 --> 2:27:43.860\n So that's my main goal for Augmented Reality is like, how do we make your reality a little\n\n2:27:43.860 --> 2:27:44.860\n bit more magic?\n\n2:27:44.860 --> 2:27:52.260\n There's been a lot of really nice robotics companies that all failed, mostly failed,\n\n2:27:52.260 --> 2:27:55.100\n home robotics, social robotics companies.\n\n2:27:55.100 --> 2:27:59.980\n What do you think replica will ever, is that a dream, longterm dream to have a physical\n\n2:27:59.980 --> 2:28:03.380\n form like, or is that not necessary?\n\n2:28:03.380 --> 2:28:09.300\n So you mentioned like with Augmented Reality bringing them into the world.\n\n2:28:09.300 --> 2:28:13.180\n What about like actual physical robot?\n\n2:28:13.180 --> 2:28:15.300\n That I don't really believe in that much.\n\n2:28:15.300 --> 2:28:18.340\n I think it's a very niche product somehow.\n\n2:28:18.340 --> 2:28:23.580\n I mean, if a robot could be indistinguishable from a human being, then maybe yes, but that\n\n2:28:23.580 --> 2:28:29.980\n of course, you know, we're not anywhere even to talk about it.\n\n2:28:29.980 --> 2:28:35.140\n But unless it's that, then having any physical representation really limits you a lot because\n\n2:28:35.140 --> 2:28:38.700\n you probably will have to make it somewhat abstract because everything's changing so\n\n2:28:38.700 --> 2:28:39.700\n fast.\n\n2:28:39.700 --> 2:28:43.980\n Like, you know, we can update the 3D avatars every month and make them look better and\n\n2:28:43.980 --> 2:28:48.380\n create more animations and make it more and more immersive.\n\n2:28:48.380 --> 2:28:50.720\n It's so much work in progress.\n\n2:28:50.720 --> 2:28:54.780\n It's just showing what's possible right now with current tech, but it's not really in\n\n2:28:54.780 --> 2:28:57.860\n any way polished finished product, what we're doing.\n\n2:28:57.860 --> 2:29:02.380\n The physical object, you kind of lock yourself into something for a long time.\n\n2:29:02.380 --> 2:29:03.660\n Anything's pretty niche.\n\n2:29:03.660 --> 2:29:09.300\n And again, so just doesn't, the capabilities are even less of, we're barely kind of like\n\n2:29:09.300 --> 2:29:12.900\n scratching the surface of what's possible with just software.\n\n2:29:12.900 --> 2:29:17.220\n As soon as we introduce hardware, then, you know, we have even less capabilities.\n\n2:29:17.220 --> 2:29:18.220\n Yeah.\n\n2:29:18.220 --> 2:29:23.580\n In terms of board members and investors and so on, the cost increases significantly.\n\n2:29:23.580 --> 2:29:26.980\n I mean, that's why you have to justify.\n\n2:29:26.980 --> 2:29:30.860\n You have to be able to sell a thing for like $500 or something like that or more.\n\n2:29:30.860 --> 2:29:34.200\n And it's very difficult to provide that much value to people.\n\n2:29:34.200 --> 2:29:35.200\n That's also true.\n\n2:29:35.200 --> 2:29:36.200\n Yeah.\n\n2:29:36.200 --> 2:29:37.200\n And I guess that's super important.\n\n2:29:37.200 --> 2:29:39.300\n Most of our users don't have that much money.\n\n2:29:39.300 --> 2:29:45.260\n We actually are probably more popular on Android and we have tons of users with really old\n\n2:29:45.260 --> 2:29:47.500\n Android phones.\n\n2:29:47.500 --> 2:29:51.140\n And most of our most active users live in small towns.\n\n2:29:51.140 --> 2:29:56.260\n They're not necessarily making much and they just won't be able to afford any of that.\n\n2:29:56.260 --> 2:30:01.580\n Ours is like the opposite of the early adopter of, you know, of a fancy technology product,\n\n2:30:01.580 --> 2:30:09.180\n which really is interesting that like pretty much no VCs have yet have an AI friend, but\n\n2:30:09.180 --> 2:30:14.460\n you know, but a guy who, you know, lives in Tennessee in a small town is already fully\n\n2:30:14.460 --> 2:30:20.940\n in 2030 or in the world as we imagine in the movie Her, he's living that life already.\n\n2:30:20.940 --> 2:30:21.940\n What do you think?\n\n2:30:21.940 --> 2:30:24.460\n I have to ask you about the movie Her.\n\n2:30:24.460 --> 2:30:25.460\n Let's do a movie review.\n\n2:30:25.460 --> 2:30:28.660\n What do you, what do you think they got?\n\n2:30:28.660 --> 2:30:30.980\n They did a good job.\n\n2:30:30.980 --> 2:30:39.060\n What do you think they did a bad job of portraying about this experience of a voice based assistant\n\n2:30:39.060 --> 2:30:42.700\n that you can have a relationship with?\n\n2:30:42.700 --> 2:30:46.300\n First of all, I started working on this company before that movie came out.\n\n2:30:46.300 --> 2:30:50.540\n So it was a very, but once it came out, it was actually interesting that I was like,\n\n2:30:50.540 --> 2:30:52.940\n well, we're definitely working on the right thing.\n\n2:30:52.940 --> 2:30:53.940\n We should continue.\n\n2:30:53.940 --> 2:30:55.220\n There are movies about it.\n\n2:30:55.220 --> 2:30:58.380\n And then, you know, X Machina came out and all these things.\n\n2:30:58.380 --> 2:31:04.560\n In the movie Her I think that's the most important thing that people usually miss about the movie\n\n2:31:04.560 --> 2:31:05.560\n is the ending.\n\n2:31:05.560 --> 2:31:10.900\n Cause I think people check out when the AIs leave, but actually something really important\n\n2:31:10.900 --> 2:31:11.900\n happens afterwards.\n\n2:31:11.900 --> 2:31:24.860\n Cause the main character goes and talks to Samantha, his AI, and he says something like,\n\n2:31:24.860 --> 2:31:26.620\n you know, uh, how can you leave me?\n\n2:31:26.620 --> 2:31:29.980\n I've never loved anyone the way I loved you.\n\n2:31:29.980 --> 2:31:33.900\n And she goes, uh, well, me neither, but now we know how.\n\n2:31:33.900 --> 2:31:38.820\n And then the guy goes and writes a heartfelt letter to his ex wife, which he couldn't write\n\n2:31:38.820 --> 2:31:43.420\n for, you know, the whole movie was struggling to actually write something meaningful to\n\n2:31:43.420 --> 2:31:47.920\n her, even though that's his job.\n\n2:31:47.920 --> 2:31:53.500\n And then he goes and, um, talk to his neighbor and they go to the rooftop and they cuddle.\n\n2:31:53.500 --> 2:31:55.880\n And it seems like something's starting there.\n\n2:31:55.880 --> 2:32:01.480\n And so I think this now we know how is the, is the main, main goal is the main meaning\n\n2:32:01.480 --> 2:32:02.480\n of that movie.\n\n2:32:02.480 --> 2:32:06.720\n It's not about falling in love with the OS or running away from other people.\n\n2:32:06.720 --> 2:32:14.900\n It's about learning what, you know, what it means to feel so deeply connected with something.\n\n2:32:14.900 --> 2:32:21.460\n What about the thing where the AI system was like actually hanging out with a lot of others?\n\n2:32:21.460 --> 2:32:28.060\n I felt jealous just like hearing that I was like, Oh, I mean, uh, yeah.\n\n2:32:28.060 --> 2:32:32.500\n So she was having, I forgot already, but she was having like deep meaningful discussion\n\n2:32:32.500 --> 2:32:34.460\n with some like philosopher guy.\n\n2:32:34.460 --> 2:32:35.460\n Like Alan Watts or something.\n\n2:32:35.460 --> 2:32:41.300\n What kind of deep meaningful conversation can you have with Alan Watts in the first\n\n2:32:41.300 --> 2:32:42.300\n place?\n\n2:32:42.300 --> 2:32:43.300\n I know.\n\n2:32:43.300 --> 2:32:46.940\n But like, I would, I would feel so jealous that there's somebody who's like way more\n\n2:32:46.940 --> 2:32:52.620\n intelligent than me and she's spending all her time with, I'd be like, well, why that\n\n2:32:52.620 --> 2:32:55.500\n I won't be able to live up to that.\n\n2:32:55.500 --> 2:33:02.460\n That's how thousands of them, uh, is that, um, is that a useful from the engineering\n\n2:33:02.460 --> 2:33:06.580\n perspective feature to have of jealousy?\n\n2:33:06.580 --> 2:33:07.580\n I don't know.\n\n2:33:07.580 --> 2:33:08.580\n As you know,\n\n2:33:08.580 --> 2:33:11.780\n we definitely played around with the replica universe where different replicas can talk\n\n2:33:11.780 --> 2:33:12.780\n to each other.\n\n2:33:12.780 --> 2:33:13.780\n Universe.\n\n2:33:13.780 --> 2:33:19.340\n Just kind of wouldn't, I think it will be something along these lines, but there was\n\n2:33:19.340 --> 2:33:23.860\n just no specific, uh, application straight away.\n\n2:33:23.860 --> 2:33:28.700\n I think in the future, again, if I'm always thinking about it, if we had no tech limitations,\n\n2:33:28.700 --> 2:33:36.540\n uh, right now, if we could build any conversations, any, um, possible features in this product,\n\n2:33:36.540 --> 2:33:40.220\n then yeah, I think different replicas talking to each other would be also quite cool cause\n\n2:33:40.220 --> 2:33:42.540\n that would help us connect better.\n\n2:33:42.540 --> 2:33:48.380\n You know, cause maybe mine could talk to yours and then give me some suggestions on what\n\n2:33:48.380 --> 2:33:53.100\n I should say or not say, I'm just kidding, but like more, can it improve our connections\n\n2:33:53.100 --> 2:34:01.300\n and cause eventually I'm not quite yet sure that we will succeed, that our thinking is\n\n2:34:01.300 --> 2:34:02.300\n correct.\n\n2:34:02.300 --> 2:34:09.500\n Um, cause there might be reality where having a perfect AI friend still makes us more disconnected\n\n2:34:09.500 --> 2:34:13.900\n from each other and there's no way around it and does not improve any metrics for us.\n\n2:34:13.900 --> 2:34:15.900\n Uh, real metrics, meaningful metrics.\n\n2:34:15.900 --> 2:34:21.140\n So success is, you know, we're happier and more connected.\n\n2:34:21.140 --> 2:34:22.140\n Yeah.\n\n2:34:22.140 --> 2:34:26.140\n I don't know.\n\n2:34:26.140 --> 2:34:27.140\n Sure it's possible.\n\n2:34:27.140 --> 2:34:30.500\n There's a reality that's I I'm deeply optimistic.\n\n2:34:30.500 --> 2:34:42.460\n I think, uh, are you worried, um, business wise, like how difficult it is to, um, to\n\n2:34:42.460 --> 2:34:47.420\n bring this thing to life to where it's, I mean, there's a huge number of people that\n\n2:34:47.420 --> 2:34:52.420\n use it already, but to, uh, yeah, like I said, in a multi billion dollar company, is that\n\n2:34:52.420 --> 2:34:54.340\n a source of stress for you?\n\n2:34:54.340 --> 2:35:00.300\n Are you a super optimistic and confident or do you?\n\n2:35:00.300 --> 2:35:06.540\n I don't, I'm not that much of a numbers person as you probably had seen it.\n\n2:35:06.540 --> 2:35:13.140\n So it doesn't matter for me whether like, whether we help 10,000 people or a million\n\n2:35:13.140 --> 2:35:19.060\n people or a billion people with that, um, I, it would be great to scale it for more\n\n2:35:19.060 --> 2:35:25.620\n people, but I'd say that even helping one, I think with this is such a magical, for me,\n\n2:35:25.620 --> 2:35:26.620\n it's absolute magic.\n\n2:35:26.620 --> 2:35:32.380\n I never thought that, you know, would be able to build this, that anyone would ever, um,\n\n2:35:32.380 --> 2:35:33.800\n talk to it.\n\n2:35:33.800 --> 2:35:36.980\n And I always thought like, well, for me it would be successful if we managed to help\n\n2:35:36.980 --> 2:35:42.700\n and actually change a life for one person, like then we did something interesting and\n\n2:35:42.700 --> 2:35:47.300\n you know, how many people can say they did it and specifically with this very futuristic,\n\n2:35:47.300 --> 2:35:49.660\n very romantic technology.\n\n2:35:49.660 --> 2:35:51.940\n So that's how I view it.\n\n2:35:51.940 --> 2:35:58.220\n Uh, I think for me it's important to, to try to figure out how not, how to actually be,\n\n2:35:58.220 --> 2:35:59.220\n you know, helpful.\n\n2:35:59.220 --> 2:36:04.680\n Cause in the end of the day, if you can build a perfect AI friend, that's so understanding\n\n2:36:04.680 --> 2:36:10.660\n that knows you better than any human out there can have great conversations with you, um,\n\n2:36:10.660 --> 2:36:12.460\n always knows how to make you feel better.\n\n2:36:12.460 --> 2:36:14.940\n Why would you choose another human?\n\n2:36:14.940 --> 2:36:16.300\n You know, so that's the question.\n\n2:36:16.300 --> 2:36:17.780\n How do you still keep building it?\n\n2:36:17.780 --> 2:36:19.620\n So it's optimizing for the right thing.\n\n2:36:19.620 --> 2:36:24.340\n Uh, so it's still circling you back to other humans in a way.\n\n2:36:24.340 --> 2:36:30.900\n So I think that's the main, um, I think maybe that's the main kind of sort source of anxiety\n\n2:36:30.900 --> 2:36:36.820\n and just thinking about, uh, thinking about that can be a little bit stressful.\n\n2:36:36.820 --> 2:36:37.820\n Yeah.\n\n2:36:37.820 --> 2:36:38.820\n That's a fascinating thing.\n\n2:36:38.820 --> 2:36:45.780\n How to have, um, how to have a friend that doesn't like sometimes like friends, quote\n\n2:36:45.780 --> 2:36:50.260\n unquote, or like, you know, those people who have, when they, a guy in the guy universe,\n\n2:36:50.260 --> 2:36:56.340\n when you have a girlfriend that, uh, you get the girlfriend and then the guy stops hanging\n\n2:36:56.340 --> 2:37:03.740\n out with all of his friends, it's like, obviously the relationship with the girlfriend is fulfilling\n\n2:37:03.740 --> 2:37:10.300\n or whatever, but like, you also want it to be where she like makes it more enriching\n\n2:37:10.300 --> 2:37:13.740\n to hang out with the guy friends or whatever it was there anyway.\n\n2:37:13.740 --> 2:37:18.740\n But that's a, that's a, that's a, that's a fundamental problem in choosing the right\n\n2:37:18.740 --> 2:37:23.740\n mate and probably the fundamental problem in creating the right AI system.\n\n2:37:23.740 --> 2:37:24.740\n Right.\n\n2:37:24.740 --> 2:37:31.860\n What, uh, let me ask the sexy hot thing on the presses right now is GPT three got released\n\n2:37:31.860 --> 2:37:32.860\n with open AI.\n\n2:37:32.860 --> 2:37:36.540\n It's a latest language model.\n\n2:37:36.540 --> 2:37:40.140\n They have kind of an API where you can create a lot of fun applications.\n\n2:37:40.140 --> 2:37:48.700\n I think it's, as people have said, it's probably, uh, more hype than intelligence, but there's\n\n2:37:48.700 --> 2:37:56.220\n a lot of really cool things, ideas there w w with increasing size, you can have better\n\n2:37:56.220 --> 2:37:58.860\n and better performance on language.\n\n2:37:58.860 --> 2:38:04.140\n What are your thoughts about the GPT three in connection to your work with the open domain\n\n2:38:04.140 --> 2:38:12.700\n dialogue, but in general, like this learning in an unsupervised way from the internet to\n\n2:38:12.700 --> 2:38:18.500\n generate one character at a time, creating pretty cool text.\n\n2:38:18.500 --> 2:38:23.420\n Uh, so we partner up before for the API launch.\n\n2:38:23.420 --> 2:38:31.180\n So we start working with them when, um, they decided to put together this API and we tried\n\n2:38:31.180 --> 2:38:34.780\n it without fine tuning that we tried it with fine tuning on our data.\n\n2:38:34.780 --> 2:38:45.900\n And we've worked closely to actually optimize, uh, this model for, um, some of our data sets.\n\n2:38:45.900 --> 2:38:46.900\n It's kind of cool.\n\n2:38:46.900 --> 2:38:51.800\n Cause I think we're kind of, we're this polygon polygon for this kind of experimentation space\n\n2:38:51.800 --> 2:38:56.940\n for experimental space for, for these models, uh, to see how they actually work with people.\n\n2:38:56.940 --> 2:38:59.540\n Cause there are no products publicly available to do that.\n\n2:38:59.540 --> 2:39:03.580\n We're focused on open domain conversation so we can, you know, test how's Facebook blender\n\n2:39:03.580 --> 2:39:06.020\n doing or how's GPT three doing.\n\n2:39:06.020 --> 2:39:11.300\n Uh, so with GPT three, we managed to improve by a few percentage points, like three or\n\n2:39:11.300 --> 2:39:15.440\n four pretty meaningful amount of percentage points, our main metric, which is the ratio\n\n2:39:15.440 --> 2:39:19.280\n of conversations that make people feel better.\n\n2:39:19.280 --> 2:39:23.440\n And every other metric across, across the field got a little boost.\n\n2:39:23.440 --> 2:39:30.860\n Like now I'd say one out of five responses from replica comes, comes from GPT three.\n\n2:39:30.860 --> 2:39:35.980\n So our own blender mixes up like a bunch of candidates from different blender, you said,\n\n2:39:35.980 --> 2:39:42.420\n well, yeah, just the model that looks at looks at top candidates from different models and\n\n2:39:42.420 --> 2:39:44.820\n picks the most, the best one.\n\n2:39:44.820 --> 2:39:50.220\n Uh, so right now, one of five will come from GPT three is really great.\n\n2:39:50.220 --> 2:39:57.420\n I mean, uh, what's the, do you have hope for, like, do you think there's a ceiling to this\n\n2:39:57.420 --> 2:39:58.780\n kind of approach?\n\n2:39:58.780 --> 2:40:05.020\n So we've had for a very long time we've used, um, it's in the very beginning, we, most,\n\n2:40:05.020 --> 2:40:09.720\n it was, uh, most of replica was scripted and then a little bit of this fallback part of\n\n2:40:09.720 --> 2:40:12.260\n replica was using a retrieval model.\n\n2:40:12.260 --> 2:40:17.340\n Um, and then those retrieval models started getting better and better and better, which\n\n2:40:17.340 --> 2:40:20.780\n transformers got a lot better and we're seeing great results.\n\n2:40:20.780 --> 2:40:26.700\n And then with GPT two, finally, generative models that originally were not very good\n\n2:40:26.700 --> 2:40:32.260\n and were the very, very fallback option for most of our conversations, but wouldn't even\n\n2:40:32.260 --> 2:40:34.220\n put them in production.\n\n2:40:34.220 --> 2:40:39.420\n Finally we could use some generative models as well along, um, you know, next to our retrieval\n\n2:40:39.420 --> 2:40:40.580\n models.\n\n2:40:40.580 --> 2:40:44.220\n And then now we do GPT three, they're almost in par.\n\n2:40:44.220 --> 2:40:46.260\n Um, so that's pretty exciting.\n\n2:40:46.260 --> 2:40:52.860\n I think just seeing how from the very beginning of, um, you know, from 2015 where the first\n\n2:40:52.860 --> 2:40:57.900\n model started to pop up here and there, like sequence to sequence, uh, the first papers\n\n2:40:57.900 --> 2:41:03.860\n on that from my observer standpoint, personally, it's not, you know, it doesn't really, it's\n\n2:41:03.860 --> 2:41:08.140\n not really building it, but it's only testing it on people basically in my, in my product\n\n2:41:08.140 --> 2:41:13.420\n to see how all of a sudden we can use generative dialogue models in production and they're\n\n2:41:13.420 --> 2:41:17.180\n better than others and they're better than scripted content.\n\n2:41:17.180 --> 2:41:23.100\n So we can't really get our scripted hard core content anymore to be as good as our end to\n\n2:41:23.100 --> 2:41:24.100\n end models.\n\n2:41:24.100 --> 2:41:25.100\n That's exciting.\n\n2:41:25.100 --> 2:41:26.100\n They're much better.\n\n2:41:26.100 --> 2:41:27.100\n Yeah.\n\n2:41:27.100 --> 2:41:30.260\n To your question, whether that's the right way to go.\n\n2:41:30.260 --> 2:41:36.340\n I'm again, I'm in the observer seat, I'm just, um, watching this very exciting movie.\n\n2:41:36.340 --> 2:41:40.900\n Um, I mean, so far it's been stupid to bet against deep learning.\n\n2:41:40.900 --> 2:41:47.540\n So whether increasing the size, size, even more with a hundred trillion parameters will\n\n2:41:47.540 --> 2:41:53.420\n finally get us to the right answer, whether that's the way or whether there should be,\n\n2:41:53.420 --> 2:41:58.860\n there has to be some other, again, I'm definitely not an expert in any way.\n\n2:41:58.860 --> 2:42:02.980\n I think, and that's purely my instinct saying that there should be something else as well\n\n2:42:02.980 --> 2:42:03.980\n from memory.\n\n2:42:03.980 --> 2:42:04.980\n No, for sure.\n\n2:42:04.980 --> 2:42:10.280\n But the question is, I wonder, I mean, yeah, then, then the argument is for reasoning or\n\n2:42:10.280 --> 2:42:14.740\n for memory, it might emerge with more parameters, it might emerge larger.\n\n2:42:14.740 --> 2:42:15.740\n But might emerge.\n\n2:42:15.740 --> 2:42:21.220\n You know, I would never think that to be honest, like maybe in 2017 where we've been just experimenting\n\n2:42:21.220 --> 2:42:25.900\n with all, you know, with all the research that has been coming, that was coming out,\n\n2:42:25.900 --> 2:42:30.740\n then I felt like there's like, we're hitting a wall that there should be something completely\n\n2:42:30.740 --> 2:42:34.140\n different, but then transforming models and then just bigger models.\n\n2:42:34.140 --> 2:42:36.380\n And then all of a sudden size matters.\n\n2:42:36.380 --> 2:42:41.020\n At that point, it felt like something dramatic needs to happen, but it didn't.\n\n2:42:41.020 --> 2:42:48.100\n And just the size, you know, gave us these results that to me are, you know, clear indication\n\n2:42:48.100 --> 2:42:50.380\n that we can solve this problem pretty soon.\n\n2:42:50.380 --> 2:42:52.700\n Did fine tuning help quite a bit?\n\n2:42:52.700 --> 2:42:53.700\n Oh yeah.\n\n2:42:53.700 --> 2:42:56.420\n Without it, it wasn't as good.\n\n2:42:56.420 --> 2:43:01.740\n I mean, there is a compelling hope that you don't have to do fine tuning, which is one\n\n2:43:01.740 --> 2:43:06.460\n of the cool things about GPT3, seems to do well without any fine tuning.\n\n2:43:06.460 --> 2:43:11.740\n I guess for specific applications, we still want to train on a certain, like add a little\n\n2:43:11.740 --> 2:43:19.200\n fine tune on like a specific use case, but it's an incredibly impressive thing from my\n\n2:43:19.200 --> 2:43:20.200\n standpoint.\n\n2:43:20.200 --> 2:43:24.300\n And again, I'm not an expert, so I wanted to say that there will be people then.\n\n2:43:24.300 --> 2:43:25.300\n Yeah.\n\n2:43:25.300 --> 2:43:26.300\n I have access to the API.\n\n2:43:26.300 --> 2:43:30.660\n I've been, I'm going to probably do a bunch of fun things with it.\n\n2:43:30.660 --> 2:43:34.340\n I already did some fun things, some videos coming up.\n\n2:43:34.340 --> 2:43:35.340\n Just the hell of it.\n\n2:43:35.340 --> 2:43:37.140\n I mean, I could be a troll at this point with it.\n\n2:43:37.140 --> 2:43:41.060\n I haven't used it for a serious application, so it's really cool to see.\n\n2:43:41.060 --> 2:43:43.140\n You're right.\n\n2:43:43.140 --> 2:43:46.700\n You're able to actually use it with real people and see how well it works.\n\n2:43:46.700 --> 2:43:49.220\n That's really exciting.\n\n2:43:49.220 --> 2:43:56.940\n Let me ask you another absurd question, but there's a feeling when you interact with Replica\n\n2:43:56.940 --> 2:44:01.860\n with an AI system, there's an entity there.\n\n2:44:01.860 --> 2:44:06.340\n Do you think that entity has to be self aware?\n\n2:44:06.340 --> 2:44:15.940\n Do you think it has to have consciousness to create a rich experience and a corollary,\n\n2:44:15.940 --> 2:44:19.220\n what is consciousness?\n\n2:44:19.220 --> 2:44:23.460\n I don't know if it does need to have any of those things, but again, because right now,\n\n2:44:23.460 --> 2:44:24.460\n you know, it doesn't have anything.\n\n2:44:24.460 --> 2:44:29.500\n It can, again, a bunch of tricks they can simulate.\n\n2:44:29.500 --> 2:44:30.500\n I'm not sure.\n\n2:44:30.500 --> 2:44:34.340\n Let's just put it this way, but I think as long as you can simulate it, if you can feel\n\n2:44:34.340 --> 2:44:43.940\n like you're talking to a robot, to a machine that seems to be self aware, that seems to\n\n2:44:43.940 --> 2:44:48.660\n reason well and feels like a person, and I think that's enough.\n\n2:44:48.660 --> 2:44:50.860\n And again, what's the goal?\n\n2:44:50.860 --> 2:44:56.220\n In order to make people feel better, we might not even need that in the end of the day.\n\n2:44:56.220 --> 2:44:58.180\n What about, so that's one goal.\n\n2:44:58.180 --> 2:45:02.220\n What about like ethical things about suffering?\n\n2:45:02.220 --> 2:45:06.940\n You know, the moment there's a display of consciousness, we associate consciousness\n\n2:45:06.940 --> 2:45:16.260\n with suffering, you know, there's a temptation to say, well, shouldn't this thing have rights?\n\n2:45:16.260 --> 2:45:25.300\n And this, shouldn't we not, you know, should we be careful about how we interact with a\n\n2:45:25.300 --> 2:45:26.300\n replica?\n\n2:45:26.300 --> 2:45:31.540\n Like, should it be illegal to torture a replica, right?\n\n2:45:31.540 --> 2:45:33.180\n All those kinds of things.\n\n2:45:33.180 --> 2:45:39.460\n Is that, see, I personally believe that that's going to be a thing, like that's a serious\n\n2:45:39.460 --> 2:45:43.340\n thing to think about, but I'm not sure when.\n\n2:45:43.340 --> 2:45:48.740\n But by your smile, I can tell that's not a current concern.\n\n2:45:48.740 --> 2:45:55.160\n But do you think about that kind of stuff, about like, suffering and torture and ethical\n\n2:45:55.160 --> 2:45:57.900\n questions about AI systems?\n\n2:45:57.900 --> 2:45:58.900\n From their perspective?\n\n2:45:58.900 --> 2:46:03.680\n Well, I think if we're talking about long game, I wouldn't torture your AI.\n\n2:46:03.680 --> 2:46:05.860\n Who knows what happens in five to 10 years?\n\n2:46:05.860 --> 2:46:08.180\n Yeah, they'll get you off from that, they'll get you back eventually.\n\n2:46:08.180 --> 2:46:14.180\n Try to be as nice as possible and create this ally.\n\n2:46:14.180 --> 2:46:19.460\n I think there should be regulation both way, in a way, like, I don't think it's okay to\n\n2:46:19.460 --> 2:46:21.460\n torture an AI, to be honest.\n\n2:46:21.460 --> 2:46:24.700\n I don't think it's okay to yell, Alexa, turn on the lights.\n\n2:46:24.700 --> 2:46:28.820\n I think there should be some, or just saying kind of nasty, you know, like how kids learn\n\n2:46:28.820 --> 2:46:33.980\n to interact with Alexa in this kind of mean way, because they just yell at it all the\n\n2:46:33.980 --> 2:46:34.980\n time.\n\n2:46:34.980 --> 2:46:35.980\n I don't think that's great.\n\n2:46:35.980 --> 2:46:39.860\n I think there should be some feedback loops so that these systems don't train us that\n\n2:46:39.860 --> 2:46:42.500\n it's okay to do that in general.\n\n2:46:42.500 --> 2:46:47.760\n So that if you try to do that, you really get some feedback from the system that it's\n\n2:46:47.760 --> 2:46:50.220\n not okay with that.\n\n2:46:50.220 --> 2:46:53.100\n And that's the most important right now.\n\n2:46:53.100 --> 2:47:01.500\n Let me ask a question I think people are curious about when they look at a world class leader\n\n2:47:01.500 --> 2:47:08.140\n and thinker such as yourself, as what books, technical fiction, philosophical, had a big\n\n2:47:08.140 --> 2:47:09.940\n impact on your life?\n\n2:47:09.940 --> 2:47:15.480\n And maybe from another perspective, what books would you recommend others read?\n\n2:47:15.480 --> 2:47:17.180\n So my choice, the three books, right?\n\n2:47:17.180 --> 2:47:18.180\n Three books.\n\n2:47:18.180 --> 2:47:25.100\n My choice is, so the one book that really influenced me a lot when I was building, starting\n\n2:47:25.100 --> 2:47:34.620\n out this company, maybe 10 years ago, was G.E.B. and I like everything about it, first\n\n2:47:34.620 --> 2:47:35.620\n of all.\n\n2:47:35.620 --> 2:47:42.100\n It's just beautifully written and it's so old school and so somewhat outdated a little\n\n2:47:42.100 --> 2:47:43.100\n bit.\n\n2:47:43.100 --> 2:47:48.740\n But I think the ideas in it about the fact that a few meaningless components can come\n\n2:47:48.740 --> 2:47:52.860\n together and create meaning that we can't even understand.\n\n2:47:52.860 --> 2:47:59.620\n This emerging thing, I mean complexity, the whole science of complexity and that beauty,\n\n2:47:59.620 --> 2:48:04.700\n intelligence, all interesting things about this world emerge.\n\n2:48:04.700 --> 2:48:14.180\n Yeah and yeah, the Godel theorems and just thinking about like what even these formal\n\n2:48:14.180 --> 2:48:19.420\n systems, something can be created that we can't quite yet understand.\n\n2:48:19.420 --> 2:48:25.660\n And that from my romantic standpoint was always just, that is why it's important to, maybe\n\n2:48:25.660 --> 2:48:30.020\n I should try to work on these systems and try to build an AI.\n\n2:48:30.020 --> 2:48:33.700\n Yes I'm not an engineer, yes I don't really know how it works, but I think that something\n\n2:48:33.700 --> 2:48:40.020\n comes out of it that's pure poetry and I know a little bit about that.\n\n2:48:40.020 --> 2:48:45.620\n Something magical comes out of it that we can't quite put a finger on.\n\n2:48:45.620 --> 2:48:51.460\n That's why that book was really fundamental for me, just for, I don't even know why, it\n\n2:48:51.460 --> 2:48:55.620\n was just all about this little magic that happens.\n\n2:48:55.620 --> 2:49:00.420\n So that's one, probably the most important book for Replica was Carl Rogers on becoming\n\n2:49:00.420 --> 2:49:02.460\n a person.\n\n2:49:02.460 --> 2:49:07.340\n And that's really, and so I think when I think about our company, it's all about there's\n\n2:49:07.340 --> 2:49:14.140\n so many little magical things that happened over the course of working on it.\n\n2:49:14.140 --> 2:49:18.220\n For instance, I mean the most famous chatbot that we learned about when we started working\n\n2:49:18.220 --> 2:49:24.900\n on the company was Eliza, which was Weisenbaum, the MIT professor that built a chatbot that\n\n2:49:24.900 --> 2:49:29.660\n would listen to you and be a therapist.\n\n2:49:29.660 --> 2:49:34.320\n And I got really inspired to build Replica when I read Carl Rogers on becoming a person.\n\n2:49:34.320 --> 2:49:37.740\n And then I realized that Eliza was mocking Carl Rogers.\n\n2:49:37.740 --> 2:49:39.940\n It was Carl Rogers back in the day.\n\n2:49:39.940 --> 2:49:45.940\n But I thought that Carl Rogers ideas are, they're simple and they're not, they're very\n\n2:49:45.940 --> 2:49:52.740\n simple, but they're maybe the most profound thing I've ever learned about human beings.\n\n2:49:52.740 --> 2:49:58.100\n And that's the fact that before Carl Rogers, most therapy was about seeing what's wrong\n\n2:49:58.100 --> 2:50:01.700\n with people and trying to fix it or show them what's wrong with you.\n\n2:50:01.700 --> 2:50:07.340\n And it was all built on the fact that most people are, all people are fundamentally flawed.\n\n2:50:07.340 --> 2:50:15.140\n We have this broken psyche and therapy is just an instrument to shed some light on that.\n\n2:50:15.140 --> 2:50:21.180\n And Carl Rogers was different in a way that he finally said that, well, it's very important\n\n2:50:21.180 --> 2:50:25.940\n for therapy to work is to create this therapeutic relationship where you believe fundamentally\n\n2:50:25.940 --> 2:50:33.340\n and inclination to positive growth that everyone deep inside wants to grow positively and change.\n\n2:50:33.340 --> 2:50:36.540\n And it's super important to create this space and this therapeutic relationship where you\n\n2:50:36.540 --> 2:50:42.220\n give unconditional positive regard, deep understanding, allowing someone else to be a separate person,\n\n2:50:42.220 --> 2:50:44.420\n full acceptance.\n\n2:50:44.420 --> 2:50:48.100\n And you also try to be as genuine as possible in it.\n\n2:50:48.100 --> 2:50:54.060\n And then for him, that was his own journey of personal growth.\n\n2:50:54.060 --> 2:50:55.740\n And that was back in the sixties.\n\n2:50:55.740 --> 2:51:02.260\n And even that book that is coming from years ago, there's a mention that even machines\n\n2:51:02.260 --> 2:51:05.380\n can potentially do that.\n\n2:51:05.380 --> 2:51:09.380\n And I always felt that, you know, creating the space is probably the most, the biggest\n\n2:51:09.380 --> 2:51:10.860\n gift we can give to each other.\n\n2:51:10.860 --> 2:51:15.340\n And that's why the book was fundamental for me personally, because I felt I want to be\n\n2:51:15.340 --> 2:51:18.220\n learning how to do that in my life.\n\n2:51:18.220 --> 2:51:22.340\n And maybe I can scale it with, you know, with these AI systems and other people can get\n\n2:51:22.340 --> 2:51:23.340\n access to that.\n\n2:51:23.340 --> 2:51:28.620\n So I think Carl Rogers, it's a pretty dry and a bit boring book, but I think the idea\n\n2:51:28.620 --> 2:51:29.620\n is good.\n\n2:51:29.620 --> 2:51:30.620\n Would you recommend others try to read it?\n\n2:51:30.620 --> 2:51:31.620\n I do.\n\n2:51:31.620 --> 2:51:38.980\n I think for, just for yourself, for as a human, not as an AI, as a human, it's, it is, it\n\n2:51:38.980 --> 2:51:44.860\n is just, and for him, that was his own path of his own personal, of growing personally\n\n2:51:44.860 --> 2:51:47.860\n over years, working with people like that.\n\n2:51:47.860 --> 2:51:52.100\n And so it was work and himself growing, helping other people grow and growing through that.\n\n2:51:52.100 --> 2:51:56.900\n And that's fundamentally what I believe in with our work, helping other people grow,\n\n2:51:56.900 --> 2:52:03.420\n and ourselves, ourselves, trying to build a company that's all built on those principles,\n\n2:52:03.420 --> 2:52:07.780\n you know, having a good time, allowing some people who work with to grow a little bit.\n\n2:52:07.780 --> 2:52:15.000\n So these two books, and then I would throw in, what we have on our, in our, in our office,\n\n2:52:15.000 --> 2:52:19.840\n when we started a company in Russia, we put a neon sign in our office because we thought\n\n2:52:19.840 --> 2:52:22.220\n that's the recipe for success.\n\n2:52:22.220 --> 2:52:26.540\n If we do that, we're definitely going to wake up as a multi billion dollar company.\n\n2:52:26.540 --> 2:52:31.380\n It was the Ludwig Wittgenstein quote, the limits of my language are the limits of my\n\n2:52:31.380 --> 2:52:32.380\n world.\n\n2:52:32.380 --> 2:52:33.380\n What's the quote?\n\n2:52:33.380 --> 2:52:37.180\n The limits of my language are the limits of my world.\n\n2:52:37.180 --> 2:52:39.020\n And I love the Tractatus.\n\n2:52:39.020 --> 2:52:43.020\n I think it's just, it's just a beautiful, it's a book by Wittgenstein.\n\n2:52:43.020 --> 2:52:44.020\n Yeah.\n\n2:52:44.020 --> 2:52:48.340\n And I would recommend that too, even although he himself didn't believe in that by the end\n\n2:52:48.340 --> 2:52:51.420\n of his lifetime and debunked these ideas.\n\n2:52:51.420 --> 2:52:58.820\n But I think I remember once an engineer came in 2012, I think with 13, a friend of ours\n\n2:52:58.820 --> 2:53:03.460\n who worked with us and then went on to work at DeepMind and he gave, talked to us about\n\n2:53:03.460 --> 2:53:04.940\n word2vec.\n\n2:53:04.940 --> 2:53:10.340\n And I saw that I'm like, wow, that's, you know, they, they wanted to translate language\n\n2:53:10.340 --> 2:53:13.260\n into, you know, some other representation.\n\n2:53:13.260 --> 2:53:18.860\n And that seems like some, you know, somehow all of that at some point, I think we'll come\n\n2:53:18.860 --> 2:53:22.620\n into this one, to this one place.\n\n2:53:22.620 --> 2:53:26.780\n Somehow it just all feels like different people think about similar ideas in different times\n\n2:53:26.780 --> 2:53:29.780\n from absolutely different perspectives.\n\n2:53:29.780 --> 2:53:31.020\n And that's why I like these books.\n\n2:53:31.020 --> 2:53:34.780\n In the midst of our language is the limit of our world.\n\n2:53:34.780 --> 2:53:45.180\n And we still have that neon sign, it's very hard to work with this red light in your face.\n\n2:53:45.180 --> 2:53:53.340\n I mean, on the, on the Russian side of things, in terms of language, the limits of language\n\n2:53:53.340 --> 2:53:57.300\n being the limit of our world, you know, Russian is a beautiful language in some sense.\n\n2:53:57.300 --> 2:54:00.260\n There's wit, there's humor, there's pain.\n\n2:54:00.260 --> 2:54:01.260\n There's so much.\n\n2:54:01.260 --> 2:54:06.820\n We don't have time to talk about it much today, but I'm going to Paris to talk to Dostoyevsky\n\n2:54:06.820 --> 2:54:09.340\n Tolstoy translators.\n\n2:54:09.340 --> 2:54:15.660\n I think it's this fascinating art, like art and engineering, that means such an interesting\n\n2:54:15.660 --> 2:54:16.660\n process.\n\n2:54:16.660 --> 2:54:23.740\n But so from the replica perspective, do you, what do you think about translation?\n\n2:54:23.740 --> 2:54:29.500\n How difficult it is to create a deep, meaningful connection in Russian versus English?\n\n2:54:29.500 --> 2:54:32.300\n How you can translate the two languages?\n\n2:54:32.300 --> 2:54:33.300\n You speak both?\n\n2:54:33.300 --> 2:54:34.300\n Yeah.\n\n2:54:34.300 --> 2:54:37.020\n I think we're two different people in different languages.\n\n2:54:37.020 --> 2:54:41.100\n Even I'm, you know, thinking about, there's actually some research on that.\n\n2:54:41.100 --> 2:54:45.020\n I looked into that at some point because I was fascinated by the fact that what I'm talking\n\n2:54:45.020 --> 2:54:48.380\n about with, what I was talking about with my Russian therapist has nothing to do with\n\n2:54:48.380 --> 2:54:51.820\n what I'm talking about with my English speaking therapist.\n\n2:54:51.820 --> 2:54:59.840\n It's two different lives, two different types of conversations, two different personas.\n\n2:54:59.840 --> 2:55:05.380\n The main difference between the languages are, with Russian and English is that Russian,\n\n2:55:05.380 --> 2:55:06.820\n well English is like a piano.\n\n2:55:06.820 --> 2:55:11.420\n It's a limited number of a lot of different keys, but not too many.\n\n2:55:11.420 --> 2:55:13.700\n And Russian is like an organ or something.\n\n2:55:13.700 --> 2:55:18.220\n It's just something gigantic with so many different keys and so many different opportunities\n\n2:55:18.220 --> 2:55:24.500\n to screw up and so many opportunities to do something completely tone deaf.\n\n2:55:24.500 --> 2:55:28.220\n It is just a much harder language to use.\n\n2:55:28.220 --> 2:55:34.180\n It has way too much flexibility and way too many tones.\n\n2:55:34.180 --> 2:55:40.700\n What about the entirety of like World War II, communism, Stalin, the pain of the people\n\n2:55:40.700 --> 2:55:47.860\n like having been deceived by the dream, like all the pain of like just the entirety of\n\n2:55:47.860 --> 2:55:48.860\n it.\n\n2:55:48.860 --> 2:55:49.860\n Is that in the language too?\n\n2:55:49.860 --> 2:55:50.860\n Does that have to do?\n\n2:55:50.860 --> 2:55:51.860\n Oh, for sure.\n\n2:55:51.860 --> 2:55:56.340\n I mean, we have words that don't have direct translation that to English that are very\n\n2:55:56.340 --> 2:56:03.460\n much like we have, which is sort of like to hold a grudge or something, but it doesn't\n\n2:56:03.460 --> 2:56:07.780\n have, it doesn't, you don't need to have anyone to do it to you.\n\n2:56:07.780 --> 2:56:08.780\n It's just your state.\n\n2:56:08.780 --> 2:56:09.780\n Yeah.\n\n2:56:09.780 --> 2:56:10.780\n You just feel like that.\n\n2:56:10.780 --> 2:56:15.140\n You feel like betrayed by other people basically, but it's not that and you can't really translate\n\n2:56:15.140 --> 2:56:16.140\n that.\n\n2:56:16.140 --> 2:56:18.100\n And I think that's super important.\n\n2:56:18.100 --> 2:56:24.020\n There are very many words that are very specific, explain the Russian being, and I think it\n\n2:56:24.020 --> 2:56:31.220\n can only come from a nation that suffered so much and saw institutions fall time after\n\n2:56:31.220 --> 2:56:36.420\n time after time and you know, what's exciting, maybe not exciting, exciting the wrong word,\n\n2:56:36.420 --> 2:56:42.700\n but what's interesting about like my generation, my mom's generation, my parents generation,\n\n2:56:42.700 --> 2:56:48.420\n that we saw institutions fall two or three times in our lifetime and most Americans have\n\n2:56:48.420 --> 2:56:55.260\n never seen them fall and they just think that they exist forever, which is really interesting,\n\n2:56:55.260 --> 2:57:01.300\n but it's definitely a country that suffered so much and it makes, unfortunately when I\n\n2:57:01.300 --> 2:57:06.580\n go back and I, you know, hang out with my Russian friends, it makes people very cynical.\n\n2:57:06.580 --> 2:57:10.140\n They stop believing in the future.\n\n2:57:10.140 --> 2:57:15.380\n I hope that's not going to be the case for so long or something's going to change again,\n\n2:57:15.380 --> 2:57:19.980\n but I think seeing institutions fall is a very traumatic experience.\n\n2:57:19.980 --> 2:57:28.220\n That's very interesting and what's on 2020 is a very interesting, do you think a civilization\n\n2:57:28.220 --> 2:57:29.220\n will collapse?\n\n2:57:29.220 --> 2:57:33.580\n See, I'm a very practical person.\n\n2:57:33.580 --> 2:57:34.580\n We're speaking in English.\n\n2:57:34.580 --> 2:57:37.420\n So like you said, you're a different person in English and Russian.\n\n2:57:37.420 --> 2:57:42.140\n So in Russian you might answer that differently, but in English, yeah.\n\n2:57:42.140 --> 2:57:49.180\n I'm an optimist and I generally believe that there is all, you know, even although the\n\n2:57:49.180 --> 2:57:54.820\n perspectives are grim, there's always a place for a miracle.\n\n2:57:54.820 --> 2:57:56.940\n I mean, it's always been like that with my life.\n\n2:57:56.940 --> 2:58:02.740\n So yeah, my life has been, I've been incredibly lucky and things just, miracles happen all\n\n2:58:02.740 --> 2:58:08.100\n the time with this company, with people I know, with everything around me.\n\n2:58:08.100 --> 2:58:13.620\n And so I didn't mention that book, but maybe In Search of Miraculous or In Search for Miraculous\n\n2:58:13.620 --> 2:58:19.540\n or whatever the English translation for that is, good Russian book for everyone to read.\n\n2:58:19.540 --> 2:58:20.540\n Yeah.\n\n2:58:20.540 --> 2:58:29.740\n I mean, if you put good vibes, if you put love out there in the world, miracles somehow\n\n2:58:29.740 --> 2:58:30.740\n happen.\n\n2:58:30.740 --> 2:58:31.740\n Yeah.\n\n2:58:31.740 --> 2:58:35.860\n I believe that too, or at least I believe that, I don't know.\n\n2:58:35.860 --> 2:58:42.380\n Let me ask the most absurd, final, ridiculous question of, we've talked about life a lot.\n\n2:58:42.380 --> 2:58:45.380\n What do you think is the meaning of it all?\n\n2:58:45.380 --> 2:58:46.860\n What's the meaning of life?\n\n2:58:46.860 --> 2:58:52.700\n I mean, my answer is probably going to be pretty cheesy.\n\n2:58:52.700 --> 2:58:59.580\n But I think the state of love is once you feel it, in a way that we've discussed it\n\n2:58:59.580 --> 2:59:00.580\n before.\n\n2:59:00.580 --> 2:59:04.860\n I'm not talking about falling in love, where...\n\n2:59:04.860 --> 2:59:05.860\n Just love.\n\n2:59:05.860 --> 2:59:10.740\n To yourself, to other people, to something, to the world.\n\n2:59:10.740 --> 2:59:16.340\n That state of bliss that we experience sometimes, whether through connection with ourselves,\n\n2:59:16.340 --> 2:59:23.620\n with our people, with the technology, there's something special about those moments.\n\n2:59:23.620 --> 2:59:30.500\n So I would say, if anything, that's the only...\n\n2:59:30.500 --> 2:59:35.620\n If it's not for that, then for what else are we really trying to do that?\n\n2:59:35.620 --> 2:59:38.820\n I don't think there's a better way to end it than talking about love.\n\n2:59:38.820 --> 2:59:47.780\n Eugenia, I told you offline that there's something about me that felt like this...\n\n2:59:47.780 --> 2:59:51.700\n Talking to you, meeting you in person would be a turning point for my life.\n\n2:59:51.700 --> 2:59:59.500\n I know that might sound weird to hear, but it was a huge honor to talk to you.\n\n2:59:59.500 --> 3:00:01.100\n I hope we talk again.\n\n3:00:01.100 --> 3:00:02.100\n Thank you so much for your time.\n\n3:00:02.100 --> 3:00:05.020\n Thank you so much, Lex.\n\n3:00:05.020 --> 3:00:09.780\n Thanks for listening to this conversation with Eugenia Cuida, and thank you to our sponsors,\n\n3:00:09.780 --> 3:00:13.460\n DoorDash, Dollar Shave Club, and Cash App.\n\n3:00:13.460 --> 3:00:18.180\n Click the sponsor links in the description to get a discount and to support this podcast.\n\n3:00:18.180 --> 3:00:23.140\n If you enjoy this thing, subscribe on YouTube, review it with 5 stars on Apple Podcast, follow\n\n3:00:23.140 --> 3:00:28.600\n on Spotify, support on Patreon, or connect with me on Twitter at Lex Friedman.\n\n3:00:28.600 --> 3:00:32.300\n And now, let me leave you with some words from Carl Sagan.\n\n3:00:32.300 --> 3:00:36.740\n The world is so exquisite with so much love and moral depth that there's no reason to\n\n3:00:36.740 --> 3:00:41.460\n deceive ourselves with pretty stories of which there's little good evidence.\n\n3:00:41.460 --> 3:00:48.080\n Far better, it seems to me, in our vulnerability is to look death in the eye and to be grateful\n\n3:00:48.080 --> 3:00:54.700\n every day for the brief but magnificent opportunity that life provides.\n\n3:00:54.700 --> 3:01:06.380\n Thank you for listening and hope to see you next time.\n\n"
}